

Alternating-current instruments and bridges
7.1 Alternating-current meters
Any system that measures direct current or potential difference can be adapted to measure the corresponding alternating quantity by inserting a rectifying circuit in front of it.
The term rectification refers to rendering the alternating current or potential difference unidirectional through removing or reversing it whenever it is one of its two possible polarities.
It should be clear that, with sufficient damping, a direct measuring system will respond to the mean level of a rectified alternating input.
Removal of alternating half-cycles is termed half-wave rectification.
Reversal of alternate half-cycles is described as full-wave rectification and is illustrated in figure 7.1(a) for a sinewave.
The neatest and most popular way of implementing full-wave rectification is by means of four diodes arranged in a Wheatstone bridge formation as shown in figure 7.1(b).
Understandably, this form of circuit is called a bridge rectifier.
As explained in section 2.3, a diode is a device that presents a very low resistance to current flow when appreciable potential difference of one sign, known as forward, is applied while it presents a very high resistance to current flow when appreciable potential difference of the opposite sign, known as reverse, is applied.
In the case of modern silicon P-N junction diodes, appreciable here means >0.6 V. The direction of the arrow head in the circuit symbol for the diode indicates the direction of easy current flow.
In the bridge rectifier circuit of figure 7.1(b), diodes D 2 and D 3 conduct well during those half-cycles over which the upper input terminal is positive with respect to the lower, diodes D 1 and D 4 being reverse biased and almost open circuit at such times.
During the other half-cycles, when the upper input terminal is negative with respect to the lower, it is the diodes D 1 and D 4 that conduct well, diodes D 2 and D 3 then being reverse biased.
Evidently, the current or potential difference applied to the direct measuring system is always right to left in the figure, the alternating input being full-wave rectified by the arrangement of diodes.
7.1 (a) Full-wave rectified sinewave and (b) bridge rectifier.
While the type of measuring system just discussed responds to the average rectified value of an alternating quantity, it is customary to describe the magnitudes of alternating quantities in terms of their r.m.s. values.
Now the average of an ideally full-wave rectified sinewave  is  whereas its r.m.s. value is .
Simple modification of the output scale of the direct measuring system that follows full-wave rectification by a factor  consequently leads to the r.m.s. value of a sinusoidal input being displayed at the output.
However, it is important to realise that, where this is done, the system will not display the r.m.s. value at its output for any other input waveform.
Another difficulty arises because, although the semiconducting diodes used in this type of circuit pass quite negligible current under reverse bias, they do drop an appreciable potential difference of a few tenths of a volt in typical operation under forward bias.
Clearly, the r.m.s. value will only be displayed by the type of system under discussion, even for a sinusoidal input waveform, as long as the amplitude of the input remains sufficiently large in relationship to the forward potential drop across the diodes.
To obtain the correct r.m.s. value of a small sinusoidal signal through use of a circuit such as that shown in figure 7.1(b), the signal must first be electronically amplified by a known factor up to a suitable level.
The output reading obtained with the enlarged input is then correspondingly scaled down.
Small signals can also be measured properly if the simple bridge rectifier is replaced by a more complicated electronic circuit that very much more closely approaches the ideal of 100% pass during forward half-cycles and 100% rejection or reversal during reverse half-cycles of the input.
The rectifier circuit of figure 7.1(b) also deteriorates in performance at high frequencies, typically above ∼10kHz, due to capacitive effects.
Current spikes at changeover from reverse to forward  bias are a particular source of trouble.
Naturally, remarks made in section 3.8 with respect to direct measuring systems, about the relevance of their resistance and the possibility of analogue or digital representation of the output, apply equally well to systems that measure alternating currents or potential differences.
While a moving-coil meter does not exhibit any steady deflection when sinusoidal current passes through it and must be preceded by some form of rectifying circuit before it can register such current, other forms of meter exist that respond usefully by themselves to sinusoidal current.
In a moving-iron meter, the current passes through a fixed coil to create a magnetic induction that magnetises a pivoted, shaped piece of ferromagnetic metal.
Since both the induction and magnetisation are proportional to the current, the force exerted on the pivoted element is essentially proportional to the square of the current.
Mechanical damping is provided and a steady deflection occurs when the mean deflecting force is balanced by gravity or a restoring spring.
The square law of force means that both alternating and direct currents are registered but there is an essentially square-law scale which is cramped at one end.
Actually the scale distribution can be modified somewhat by shaping the pivoted element.
Problems with the meter are magnetic hysteresis, magnetic shielding, low sensitivity and appreciable inductance of the fixed coil which restricts usage to frequencies below ∼300 Hz.
Moving-iron meters are mainly employed as robust instruments for measuring mains (50 Hz) current.
Since the moving element does not carry current, it is not susceptible to overload damage.
In thermocouple and hot-wire meters the current to be measured passes through a straight piece of resistance wire and heats it up.
The temperature rise is registered in the former case by an attached or adjacent thermocouple that delivers its thermoelectric e.m.f. to a moving-coil voltmeter of suitable sensitivity.
In the latter case, thermal expansion of the wire proportional to the heating is sensed by mechanical means.
Because the heating effect and therefore the temperature rise is proportional to the square of the current, both meters have a square-law output scale and, following calibration with a known direct input, give the true r.m.s. value irrespective of waveform.
They also work up to very high frequencies (∼50 MHz), because the heated wire exhibits negligible inductance, and are often used in the measurement of radio-frequency signals.
More sensitive versions of thermocouple meters have the heater element and thermocouple housed in an evacuated enclosure to reduce heat losses and enhance the temperature rise.
Yet another type of meter capable of registering either alternating or direct current is the electrodynamometer.
The current to be sensed and measured passes through two fixed coils in series with a movable coil.
An  approximately uniform magnetic induction B is produced by the fixed coils in which the movable coil is suspended as illustrated in figure 7.2(a).
The magnetic induction exerts a torque on the suspended coil according to equations (4.8) and (4.9) which rotates it until there is a balancing restoring torque provided by controlling springs.
Mechanical damping is again active.
The magnetic deflecting torque is proportional to both the current I in the suspended coil and the magnetic induction delivered by the fixed coils which in turn is also proportional to the same current I. Because the deflecting torque is proportional to I 2 , both alternating and direct currents cause a steady deflection of the suspended coil, the natural frequency of the suspended system being too low and the damping too great for any fluctuations in I 2 to be followed.
A deflection more linearly dependent on the current I than the square law can be achieved by making good use of the fact that the torque also depends on cos θ where θ defines the orientation of the suspended coil as shown in figure 7.2(a).
It is generally arranged that θ is zero at some suitable deflection such that the fall in cos θ at larger deflections significantly counteracts the scale spreading that would otherwise arise from the square-law dependence on current.
Appropriate shaping of the fixed coils can also help to linearise the scale.
7.2 (a) Arrangement of coils in an electrodynamometer and (b) connections of an electrodynamometer for power measurement.
Although the electrodynamometer is free of hysteresis, it is insensitive unless the coils have a large number of turns which makes both the resistance and inductance high, the latter severely restricting the frequency range of operation.
For these reasons it is seldom used for current measurement nowadays but it does find application in a modified form of operation that enables electrical power to be measured in both direct and alternating-current circuits at frequencies up to a few hundred hertz.
To measure the power in a load, whichever of the movable or pair of fixed coils has the lower resistance is connected essentially or actually in series with the load as indicated in figure 7.2(b), so that the load current is essentially or  actually carried.
The other is connected essentially or actually in parallel with the load through a large enough resistance R to swamp the inductive reactance, also as indicated in figure 7.2(b).
It therefore carries current essentially proportional to the potential difference across the load and the instantaneous couple acting on the suspended coil is proportional to the product of the instantaneous current and potential difference.
Connected in this fashion, the electrodynamometer once calibrated gives the mean power in the load.
An instrument of paramount importance that enables the precise nature of any potential difference to be determined is the cathode-ray oscillograph.
The screen of this complicated electronic instrument presents a stationary picture of the potential difference between its input terminals as a function of time.
Every facet of the signal can be studied at leisure, including amplitude, frequency, phase and detailed time dependence.
In particular, with respect to this section, it makes a very good alternating voltmeter, possessing calibrated potential difference and time scales and, as mentioned in section 5.2, an input impedance corresponding to resistance as high as ∼1 MΟ in parallel with capacitance as low as ∼30 pF.
7.2 Measurement of impedance by a.c. meters
In the title of this section, a.c. means alternating current while impedance implies complex impedance.
Such abbreviated language is standard practice and will be widely adopted in the remainder of this book.
Just as an unknown resistance can be determined using direct meters as described in section 3.8, so too can an unknown impedance be determined using a.c. meters.
The accuracy of determination again depends on the factors discussed in that section besides the calibration and reading accuracy.
Ideally, any alternating voltmeter should possess infinite impedance and any a.c. meter negligible impedance.
An alternating voltmeter is, of course, often just an a.c. meter in series with a suitable substantial resistance.
7.3 (a) Circuit for determining impedance from a.c. meter measurements and (b) phasor diagram for circuit (a) deduced from meter measurements of the r.m.s. magnitudes of potential differences across components of it.
Consider an unknown impedance Z =  connected in series with a sinusoidal e.m.f.  and a standard resistor having resistance  as shown in figure 7.3(a).
The r.m.s. current,, may be found by measuring the r.m.s. potential difference  with a suitable voltmeter from which .
If  is the r.m.s. potential difference across Z similarly measured  To find the resistance R and reactance X of the unknown impedance Z, the r.m.s. e.m.f., must also be measured with the voltmeter.
Armed with  , and , the phasor diagram for the series circuit can be completed as indicated in figure 7.3(b).
First the reference phasor OA, representing the potential difference across the standard resistor, is drawn with length in convenient proportion to .
The phasors representing the e.m.f. and potential difference across impedance Z then have lengths in the same proportion to  and  respectively.
To satisfy Kirchhoff's voltage law in the series circuit, the three phasors must complete a triangle as shown in figure 7.3(b).
This triangle is established by finding the intersection B of circles centred on O and A with radii in the same proportion to  and  respectively as OA is to .
To summarise up to this point, the r.m.s. magnitudes of phasors , and  have been measured by the voltmeter but not their phases.
Drawing the phasor diagram that satisfies the magnitudes of these three potential differences, however, establishes the relative phases.
Now because the potential difference across the resistance R of the unknown impedance Z must be in phase with the potential difference across the standard series resistance , the phasor representing it is the projection AC of AB along the direction of OA.
Similarly, because the potential difference across the reactance X of the unknown impedance Z must be in phase quadrature (90° out of phase) with the potential difference across the standard series resistance , the phasor representing it is the projection CB of AB perpendicular to the direction of OA.
The resistance R and reactance X therefore follow from application of the relations    For good accuracy, needs to be similar in magnitude to R and X. If not, small errors in the phasor diagram due to small measurement errors may lead to large errors in R and/or X. Of course, the r.m.s. current could be measured separately by inserting a suitable a.c. meter in series with the circuit.
As an alternative to drawing the phasor diagram, an analytic solution is possible for  and  in terms of the measurements.
Applying Pythagorus' theorem to figure 7.3(b) shows that   and subtracting these equations gives  in which all but  have been measured so that  can be calculated readily.
then follows from equation (7.5) and R and X from equations (7.2) and (7.3).
Where an unknown impedance is known to approximate closely to a pure reactance or pure resistance, it is only necessary to measure the r.m.s. current  through it and r.m.s. potential difference  across it with meters to determine its value as .
For a single inductor or capacitor of negligible loss, the latter being more common, the inductance or capacitance can be deduced from the measured impedance provided that the frequency of the current is known.
A useful alternative method of finding the capacitance of a low-loss capacitor is to compare the alternating potential drop across it with that across a standard capacitor connected in series, using a very-high-impedance voltmeter.
For the particular capacitance meter circuit of figure 7.4(a), the unknown capacitance C is given in terms of the standard capacitance Cs by the relation   
7.4 (a) A capacitance meter and (b) a Q meter.
Determination of inductance through comparison of inductors is not viable because there is usually a significant loss and also there may be a problem of mutual inductance between the two inductors.
The Q-factor meter, a version of which is shown in figure 7.4(b), is better for determining the inductance L and resistance R of an inductor.
With regard to the circuit of figure 7.4(b), the unknown inductor is connected between the terminals X and Y, V being a very-high-impedance voltmeter.
The capacitance C s of the variable standard capacitor is adjusted until the voltmeter V indicates resonance, when the inductance can be found from the theoretical expression (5.42) of section 5.6 for the resonant frequency.
Because the resistance r is very small compared with R, most of the current  goes through r and, in accordance with the theory developed in section 5.6, the resonant r.m.s. potential difference recorded by the voltmeter V is , where Q is the Q-factor.
Normally  is set to a preset level and the voltmeter V is calibrated to give Q directly, from which the loss resistance R of the inductor can be calculated if required.
An unknown capacitance can be determined by connecting it across YZ and finding the change in C s needed to return to resonance.
The power factor corresponding to the connected capacitance is obtained from the change in Q.
7.3 Measurement of impedance by the Wheatstone form of a.c. bridge
Most a.c. bridges are similar in form to the Wheatstone bridge for measuring resistance described in section 3.9.
However, in general, each arm of an a.c. bridge constitutes an impedance and an a.c. bridge is energised by an a.c. source while its balance is sensed by a detector that responds to the type of signal delivered by the a.c. source.
These essential features are illustrated in figure 7.5(a) where the impedances of the arms are labelled Z 1 -Z 4 .
Normally the source delivers a sinusoidal signal.
The vitally important balance condition of absolutely no current flowing through the detector corresponds to the potential difference across it being zero at all times.
With reference to figure 7.5(a), such perfect balance demands that the potentials of nodes B and D are identical at all times.
This only happens when both the amplitudes and phases of the potentials at B and D are equal.
Seemingly, two separate conditions must be satisfied to achieve proper balance.
Now if I 1 , I 2 , I 3 and I 4 denote the phasor representations of the currents in Z 1 , Z 2 , Z 3 and Z 4 respectively, then at balance  and  where  and   because no current is flowing through the detector.
Hence at balance  Although at first sight this may appear to be a single balance condition, in order to be satisfied, the real and imaginary parts of the two sides of the equation must be separately equal so that it is in fact a double balance condition as anticipated.
Considering the potentials at B and D to have components in phase and in quadrature with the supply, the double balance condition (7.8) is seen to correspond to these in-phase and quadrature components being separately equal which is equivalent to the amplitudes and phases of the potentials at B and D being the same.
7.5 (a) The general Wheatstone form of a.c. bridge and (b) the approach to its double balance condition through successive alternate attempts at nulling the in-phase and quadrature components of potential difference across the detector.
Normally several successive alternate balancings of the in-phase and quadrature components are needed before a sufficiently fine approximation to the perfect double balance condition is reached.
The reason for this may be understood with reference to figure 7.5(b) in which  is the phasor representation of the potential difference between nodes B and D, that is, across the detector, before balancing is commenced.
Now the usual type of detector only indicates the magnitude of the potential difference between B and D. Thus, if balance is approached by reducing the in-phase component  of , there will be a range of phasor potential differences across the detector, say, to , that corresponds to magnitudes of potential differences indistinguishable from the minimum .
Once this condition is reached, say with potential difference , balance is approached much better by adjusting the quadrature component  to reach a new range  to  that corresponds to magnitudes of potential differences indistinguishable from some new much lower minimum.
A return to  adjusting the in-phase component will now permit a better balance still to be achieved, especially if the sensitivity of the detector can be increased.
If the balance conditions are independent of the frequency of the supply then the use of a nonsinusoidal source poses no balancing problems, the harmonic components of potential being balanced whenever the fundamental components are (see section 11.1).
However, a sinusoidal source is always advisable in practice because the electrical parameter being measured might well be significantly dependent on frequency.
The most convenient form of source is a tunable electronic oscillator but the mains, through a suitable step-down transformer, permits measurements to be made at the frequency of the mains.
The detector can be a pair of headphones at audio frequencies, an a.c. meter or a cathode-ray oscilloscope.
In each case, the sensitivity of detection of the balance condition can be enhanced by preceding the detector with a suitable electronic amplifier of adjustable gain.
Sometimes while approximate balancing is carried out it is necessary to provide for a reduction in sensitivity of detection through incorporation of a suitable attenuation network.
Transformer coupling of the source and/or detector to the Wheatstone network is often adopted to match impedance levels or for isolation purposes.
In analogy with the direct Wheatstone bridge circuit, high sensitivity is obtained when the arm impedances Z 1 , Z 2 , Z 3 and Z 4 are all equal and the source and detector also present this same impedance.
Although it is impossible to maintain this condition all the time, it is important to keep the impedances involved similar in magnitude.
Components for use in a.c. bridges present problems.
As discussed in section 2.3, wirewound resistors possess considerable inductance and capacitance and, where resistors are required in a.c. bridges, it is best to use modern thin-film types.
At very high frequencies difficulties arise through the skin effect which restricts current flow to a region near the surface of a conducting medium.
Inductors exhibit inherent resistance and capacitance and are less convenient as standards than capacitors, particularly when continuous variation is required, as discussed in sections 4.1 and 4.2.
In variable resistors of the decade box type of construction, the varying capacitance and possibly inductance of the switching mechanism can be a nuisance.
Sometimes helpful in determining the values of unknown circuit components are substitution and difference techniques in which the value indicated from the balance of the bridge with a standard component is compared with that when the unknown is connected on its own or in parallel or series with the standard, whichever is more suitable.
At other than low frequencies (typically above ∼100Hz), screening precautions must be taken to avoid unintentional stray coupling, inductive  or capacitive (see sections 4.2 and 4.1 respectively), between various parts of the bridge circuit.
In implementing screening through incorporation of earthed metallic enclosures, either in the form of boxes round components or the braided outers of coaxial cables, care must be exercised to ensure that not more than one point of the circuit is earthed otherwise part of it will be shorted out.
Although the screening increases capacitances to earth, these capacitances are definite, and extraneous potential differences are excluded from the arms of the bridge.
What is more, the technique of a Wagner earth can be employed to eliminate the effect of the capacitances to earth on the balance point of the bridge.
In figure 7.6 the capacitances to earth are represented as lumped together from nodes A, B, C and D. Notice that if nothing is done about these capacitances, they act in pairs across the arms of the bridge; for example, the reactance of C A in series with that of C B is in parallel with the impedance Z 1 .
If large enough, these capacitive reactances would significantly reduce the impedances of the arms of the bridge.
7.6 Introduction of a Wagner earth into the Wheatstone form of a.c. bridge.
To implement a Wagner earth, an additional point E between extra arms of the bridge having impedances Z 5 and Z 6 is earthed as shown in figure 7.6.
A rough balance of the original bridge is obtained first with the detector connected between nodes B and D. The detector is then connected between B and E and another balance obtained through adjustment of Z 5 and/or Z 6 .
Alternate adjustments in this way bring points B, D and E to earth  potential although only E is actually connected to earth.
Capacitances CB; and C D cannot now affect the bridge because they carry no current.
Since node D is not actually connected to earth, capacitances C A and C C simply act in parallel with the supply and also do not affect the balance of the main bridge comprising arms Z 1 , Z 2 , Z 3 and Z 4 .
That C C acts in parallel with Z 6 and C A in parallel with Z 5 is irrelevant because the impedances of these arms do not need to be known when measuring a component through balancing the main bridge.
A number of particularly important a.c. bridges will now be described and their circuits analysed to find their individual double balance conditions.
Practical points concerning their use will also be made.
For a fuller treatment of a.c. bridges the reader should consult a specialist book such as Alternating Current Bridge Methods, Sixth Edition, by B. Hague and T. R. Foord, Pitman, London (1971).
7.4 A.c. bridges for determining inductance
7.7 (a) Maxwell's L-C bridge and (b) Owen's bridge.
The bridge arrangement depicted in figure 7.7(a) and attributed to Maxwell allows the inductance of an inductor to be measured in terms of the capacitance of a calibrated variable capacitor and the resistances of two fixed resistors.
In the circuit diagram, the inductor to be determined is represented as an inductance L in series with resistance R. When the bridge is balanced, equation (7.8) applies so that  Equating real and imaginary parts reveals that the double balance conditions are   and  Since R 1 and R 4 appear in both equations, independent achievement of the two balance conditions is only possible through variation of just R 2 and C 2 .
Notice that it is customary to indicate the parameters best varied to achieve balance by drawing an arrow through them where they appear in the double balance equations, as done here.
Equation (7.10) shows that the inductance may be calculated from the resistances R 1 and R 4 and the capacitance C 2 of the variable capacitor at balance, in accordance with the initial claim made for the bridge.
Equation (7.9) shows that the loss of the inductor is given by the same resistances R 1 and R 4 and the resistance R 2 of the variable resistor at balance.
Equations (7.9) and (7.10) combine to show that, when the time constant  of the inductor is very large, the time constant  must be just as large at balance so that it may not be feasible to reach the value of R 2 needed to achieve balance.
In these circumstances successful balancing can be achieved through a modification due to Hay in which the parallel combination of variable resistance and capacitance is replaced by a series combination of variable resistance and capacitance.
The parallel equivalent of the balancing series combination is then easily calculated to obtain L and R from equations (7.9) and (7.10).
Alternatively, the balance conditions of the Hay bridge can be derived to allow L and R to be calculated.
Attention is drawn to the fact that, while the balance conditions (7.9) and (7.10) for the Maxwell L-C bridge are independent of frequency, those for the Hay version are frequency dependent, so that for good results with this version an extremely pure sinusoidal source is needed and, ideally, a detection system that only responds to the same frequency.
A sound arrangement is an electronic oscillator and detection system employing ganged selective tuning.
It is more convenient to balance a bridge by adjustment of a calibrated variable resistor than by adjustment of a calibrated variable capacitor.
Owen's bridge, which is shown in figure 7.7(b) and is balanced by means of two variable resistors, is therefore very attractive for determining inductance.
Here the inductance L of an inductor having resistance R is found in terms of a standard fixed capacitance C 2 , a standard fixed resistance R 4 and a calibrated variable resistance R 1 .
Applying equation (7.8) to the bridge gives  and equating real and imaginary parts establishes that the double balance conditions are   and  Notice that these balance conditions are independent of frequency and independently achievable through adjustment of R 1 and R 3 .
Residual inductance of leads, resistors and terminals can be eliminated from the measurements by balancing the bridge first with the inductor included and then with it short-circuited.
If R 1 and R' 1 are the respective balance values then 
The various bridges considered can be modified to allow the inductance of an inductor to be measured as a function of the direct current carried.
This is important for inductors with cores of such as ferromagnetic materials where the incremental or small-signal inductance is strongly dependent on any direct current.
It turns out that Hay's bridge is highly convenient for such investigations.
7.5 The Schering bridge for determining capacitance
7.8 (a) The Schering bridge and (b) the Heydweiller bridge.
The particular bridge shown in figure 7.8(a) that was first suggested by Schering has proved to be extremely versatile and capable of high accuracy with respect to measuring capacitance.
In the bridge, capacitance C 2 is provided by a calibrated, variable, air capacitor because such a device exhibits an absolutely negligible power factor, while resistance R 2 is supplied by a calibrated, variable resistance box.
The capacitor undergoing measurement is represented conveniently by capacitance C in series with a small resistance loss R S .
From equation (7.8), balance occurs in the bridge  when  and equating real and imaginary parts reveals that the double balance conditions are  and  Since both conditions feature R 4 and C 1 , their independent satisfaction is only possible through variation of R 2 and C 2 .
Notice that the capacitance C is determined in terms of the fixed standard capacitance C 1 , the fixed standard resistance R 4 and the calibrated variable resistance R 2 .
Although capacitance C 2 must be varied to reach balance, its value need not be known unless it is also required to determine the loss resistance R S Because C is proportional to R 2 , the bridge can easily be made direct reading in capacitance through suitable marking of the resistance scale of R 2 .
Unfortunately, despite the fact that frequency does not appear explicitly in equation (7.14) or (7.15), these balance conditions are not entirely independent of frequency because R S depends on frequency to some extent.
Once more a good sinusoidal source and ganged, tuned detector are desirable.
For the majority of capacitors measured, the loss R S is small enough to express the power factor as  (refer back to section 5.8 if necessary).
Equations (7.14) and (7.15) show that, in such situations, the power factor is given by  Consequently, if balance is achieved through adjustment of C 2 and R 4 rather than C 2 and R 2 , the dials of C 2 and R 4 can be made direct reading in power factor and capacitance although only the scale of the former will be linear.
7.6 The Heydweiller bridge for determining mutual inductance
A method of measuring mutual inductance, devised originally by Carey Foster for use with a direct source and transient techniques, was adapted by Heydweiller for operation with an alternating source.
The bridge in question is shown in figure 7.8(b) and is not of the Wheatstone form.
In adapting it to a.c. operation, Heydweiller found it necessary to incorporate the extra variable resistor of resistance R 2 compared with the Carey Foster version.
The mutual inductor being measured is assumed to exhibit mutual inductance M, primary and secondary self inductances   and  and corresponding resistances  and .
Applying Kirchhoff's voltage law to the minimal meshes that include the detector gives  and  where , and  denote phasor representations of the mesh currents and  the phasor representation of the potential difference across the detector as indicated in the figure.
Now at balance  and , so that  Equating real and imaginary parts, the double balance conditions are seen to be  and 
First of all, note that the mutual inductance must be connected in the correct sense otherwise achievement of balance will be impossible.
Secondly, is required to allow the balance condition (7.18) to be achieved.
Any problem here can be overcome by swopping the primary and secondary windings.
Alternatively extra inductance can be added to the secondary circuit, taking care to avoid further mutually inductive couplings.
Once the foregoing points have been taken care of, independent achievement of the balance conditions is possible through variation of R 2 and R 3 .
Equation (7.17) shows that the mutual inductance is determined in terms of standard fixed capacitance C, standard resistance R 1 , and calibrated variable resistance R 3 .
Because of the finite resistance  of the secondary winding it will be necessary to balance the bridge for more than one value of R 1 in order to find M. Balancing for several values of R 1 permits a graph to be drawn of the balance value of R 3 versus .
From equation (7.17) so that the slope of this graph is  and the intercept on the R 3 axis is  from which both M and  may be obtained.
The secondary inductance can also be deduced from the balance condition (7.18).
One of many interesting alternative ways of measuring mutual inductance uses any bridge that measures self inductance together with the following technique.
When the primary and secondary coils of a mutual  inductor are connected in series, the self inductance exhibited by the combination is easily shown to be  the sign depending on the sense of the series connection of the two coils.
Measurement of the self inductance for the two series connections therefore yields the mutual inductance as a quarter of the difference between the self inductances.
7.7 A.c. bridges for determining the frequency of a source
Of the various bridges considered so far, only the Hay bridge mentioned in section 7.4 features balance conditions that exhibit an explicit dependence on frequency so that it can be used to measure the frequency of the source in terms of appropriate components.
A simple and popular bridge that exhibits frequency-dependent balance conditions and is widely used to measure the frequencies of sources is the Wien bridge shown in figure 7.9(a) comprising just resistors and capacitors.
Its essential circuitry is much used for the purpose of frequency selection in electronic equipment, for example, in controlling the output frequency of an electronic oscillator.
7.9 (a) The Wien bridge and (b) a series resonant bridge.
At balance of the bridge  or  Equating real and imaginary parts reveals that the double balance conditions are   and  Independent attainment of these balance conditions is not possible.
However, a neat way of operating the bridge was devised by Robinson.
He arranged for C 1 and C 3 to be fixed and equal, say , and R 1 and R 3 to be variable but equal, say , by employing ganged variable resistors to provide these resistances.
In these circumstances, equations (7.19) and (7.20) reduce to  and  Thus balance can be achieved by making the ratio  permanently equal to two and then adjusting the ganged resistances  for balance.
In Robinson's version, resistances R 1 and R 3 were special ganged conductances so that their dials carried a direct frequency reading, according to equation (7.22).
When an inductor and capacitor are arranged in a single arm, the bridge is best regarded as a resonance or tuned-arm bridge.
A simple bridge based on series resonance (see section 5.6) is shown in figure 7.9(b).
Resistance R 1 represents the total effective series resistance of the capacitor and inductor.
When  the branch containing the reactances is nonreactive and if also  the bridge is balanced.
Clearly the frequency of the source driving this bridge can be determined from the values of L 1 and C 1 at balance, the two balance conditions being easily achieved independently through variation of C 1 and one resistance.
The bridge is also sensitive and highly accurate for finding the loss of a capacitor or inductor from the value of R 1 indicated by  at balance.
It is particularly good for determining inductive loss since a capacitor of negligible loss is easily provided.
7.8 Transformer ratio-arm bridges
In sections 6.2 and 6.3 it was established that time-dependent potential differences across the secondary and primary windings of a unity-coupled, lossless transformer are in the same ratio as the turns ratio between these windings.
Thus if a close approximation to such a transformer features in the bridge circuit of figure 7.10(a) with its secondary winding tapped so that it divides into two portions having turns N 1 and N 2 , the ratio  of the potential differences across these secondary portions will be near enough .
In particular, for sinusoidal excitation, the ratio between the secondary phasor potential differences will be  But when the bridge is balanced as judged by null reading of the detector, say by varying Z 2 , so that Clearly, balancing the bridge circuit allows an unknown impedance Z 1 to be found in terms of a known impedance Z 2 and known turns ratio .
An important advantage of transformer ratio-arm bridges is that the turns ratio may be known to an accuracy as high as 1 part in 10 7 .
What is more, by including a number of suitable tapping points, the turns ratio  may be varied over an enormous range to permit the comparison of widely differing impedances.
Just how separate balances can be obtained for the real and imaginary parts of an unknown impedance in a transformer ratio-arm bridge is considered later (see figure 7.13).
7.10 (a) Simple, transformer, ratio-arm bridge and (b) the same except that an autotransformer is used.
Figure 7.10(b) presents a variation of the bridge circuit of figure 7.10(a) that employs an autotransformer to achieve the potential difference ratio .
It has the advantage that current drawn by the arms of the bridge is supplied by the source and so loading of the ratio windings and possible consequential disturbance of the potential difference ratio from  is avoided.
Actually, the potential difference ratio created by a winding is exactly equal to the turns ratio even when there is magnetic leakage, provided the winding consists of identical sections, each of which is identically coupled to any other, and the tapping point is taken between these sections.
This last fact is made use of in achieving highly accurate potential-difference ratios.
How such decade section windings can be interconnected to give fine subdivision of an alternating potential difference is illustrated in figure 7.11 for a three-decade divider.
Note that the load  each decade places on the previous decade is not serious because the output impedance of a section is very low and essentially resistive while the input impedance of a decade is large and inductive.
7.11 Three-decade, transformer, potential divider.
7.12 Essential circuit of a double-transformer, ratio-arm bridge.
A development of the single-transformer ratio-arm bridge, naturally known as the double-transformer ratio-arm bridge, is shown in its essential form in figure 7.12.
Here the detector is connected through a second closely coupled low-loss transformer, the primary of which has an adjustable tapping X' that divides it into sections with turns N' 1 and N' 2 .
With reference to figure 7.12, this arrangement acts as a current comparator for the upper and lower meshes.
The senses of winding of the primary turns N' 1 and N' 2 are such that when  there is no magnetic flux in the core of this second transformer and therefore no signal registered by the detector.
However, absence of magnetic flux in the core of the second transformer also means that points P' 1 , X' and P' 2 are virtually at the same potential.
Consequently, at balance, in addition to equation (7.28) applying, the mesh currents are given by  Now the potential differences V 1 and V 2 applied to the two meshes by the source transformer are again in the ratio given by equation (7.25) and  combining equations (7.25),(7.28) and (7.29) yields  as the balance condition for the double-transformer ratio-arm bridge.
The availability of two variable transformer ratios allows even more widely differing impedances to be compared than is possible with single-transformer bridges.
Crucially, although the impedances between P' 1 , X' and P' 2 are extremely tiny when the bridge is balanced, as soon as it goes out of balance the large primary inductance of the detector transformer comes into play so that the balance condition is very critical and the bridge consequently very sensitive.
Yet another attractive feature is that earthing XX' prevents stray capacitances to earth from interfering with component measurement.
Strays from P 1 and P 2 simply shunt the transformed supplies and, if the losses in the source transformer are low enough, merely reduce the sensitivity of measurement.
Stray capacitances to earth from P' 1 and P' 2 are shorted out by the primary of the detector transformer at balance.
The ease with which the effects of stray capacitances are dealt with renders the bridge suitable for making measurements at high frequencies and commercial versions are available that operate up to frequencies ∼100 MHz.
7.13 A practical, double-transformer, ratio-arm bridge.
The connections for one practical double-ratio bridge are outlined in figure 7.13.
Balance is reached by adjustment of the decade switches operating over the tappings of the secondary of the source transformer T 1 .
These control the amplitudes of potential difference applied to a bank of identical fixed standard capacitors and resistors in steps of one-tenth from zero to nine-tenths of a maximum , say.
The first resistor is connected to the extremity of the lower primary of the detector transformer T 2 , the second to the one-tenth tapping of the same winding and so on.
The first capacitor is connected through a switch to the extremity of the lower or upper primary of the detector transformer depending on whether the impedance Z being measured is capacitive or inductive.
The second capacitor is connected through a ganged switch to the one-tenth tappings of the same windings and so on.
Potential difference of amplitude  appearing across the entire secondary of the source transformer T 1 is connected through the unknown impedance Z 1 to the whole, one-tenth and so on tappings of the upper primary of the detector transformer T 2 through a range switch.
Thus the tappings of the secondary of the source transformer connected to successive capacitors and resistors give successive decades of the unknown capacitance or inductance and resistance.
Only two decades are shown for reasons of labour and clarity.
Note that when an inductance is responsible for the reactive part of the unknown impedance Z 1 , it is given by , where C is the effective value of all the standard capacitances taking into account the tappings of the source and detector transformers at balance and the position of the range switch.
7.14 Wheatstone bridge employing a unity-ratio transformer.
A transformer can also serve as a current comparator in a conventional Wheatstone bridge type of circuit as shown in figure 7.14.
It replaces arms that provide a simple resistance ratio, with much advantage.
At balance, the currents through the unity-ratio arms BC and CD of figure 7.14 are equal and the sense of the windings is such that the magnetic fluxes created in the core of the transformer by them cancel.
The potential differences between B, C and D are again very small, arising only from small losses in  the transformer.
Effects of stray capacitance to earth are removed by earthing B, C or D. Off balance, the currents in the coils are no longer equal and a large inductive reactance appears between B and C and between C and D so that the balance condition of the bridge is critical and the bridge consequently sensitive.
Attenuators and single-section filters
8.1 Attenuators
The term attenuation may describe any reduction in magnitude of an electrical signal but an electrical network is only called an attenuator if it reduces the magnitude of a signal without changing its time dependence.
Since Fourier analysis shows (see chapter 11) that all signals comprise certain combinations of pure sinusoidal signals, to perform as an attenuator, a circuit must reduce the amplitudes of all sinusoidal signals by the same factor irrespective of frequency and without changing their phases.
Attenuators that reduce the potential difference by a given factor are vastly more common than current attenuators and are often appropriately referred to as potential dividers.
Purely resistive circuits respond identically to sinusoidal signals of all frequencies and, since they only affect the amplitude, act as attenuators.
The simplest form of potential divider that gives a fixed attenuation between input and output is shown in figure 8.1(a).
It provides attenuation of potential difference represented by  when it is negligibly loaded.
Its design to avoid significant loading at the output or input has already been considered in section 3.7 for the special case of a direct input, which can be thought of as a sinusoidal input of zero frequency, but the discussion and conclusions reached apply equally well whatever the time dependence of the input signal.
The extended version of the basic potential-divider circuit shown in figure 8.1(b) provides a range of selectable stepped attenuations.
Designs giving decade or binary steps are popular, the latter enabling an indicating instrument connected to the output always to operate at a substantial fraction of full scale as the input signal changes, with attendant reading accuracy advantage.
A resistance  potentiometer connected as shown in figure 8.1(c) delivers a continuous range of potential division from unity to infinite.
Potentiometers having linear or logarithmic variation of resistance with position of the contact are available, the latter being, for example, well suited to the control of volume in audio systems since the response of the ear to sound is logarithmic.
8.1 Potential-divider circuits.
Unfortunately it is not possible to construct an absolutely purely resistive circuit in practice.
With reference to the circuit of figure 8.1(a), there will always be some capacitance in parallel with R 1 and R 2 .
The capacitance may be just stray or it may be associated with further circuitry or equipment connected to the potential divider.
Such capacitance has a detrimental effect on the attenuating performance, both changing the reduction in amplitude between input and output and introducing a phase shift at sufficiently high frequency.
Clearly, the range of frequencies over which a potential divider constructed solely from resistors acts as a satisfactory attenuator is restricted.
The detrimental effect on fast pulses is particularly serious, distortion of the types shown in figures 4.12(b) and 4.13(b) occurring on account of the transient response of the resistance-capacitance combinations.
To overcome the capacitive shorting problem, potential dividers for operation at high frequencies or for handling pulses are usually constructed as indicated in figure 8.1(d).
Perhaps surprisingly at first sight, additional variable capacitance is introduced in parallel with R 2 and additional fixed capacitance in parallel with R 1 .
Now if C 1 and C 2 represent total  capacitances in parallel with R 1 and R 2 respectively, the ratio between the output and input potential difference phasors of this circuit as a function of the pulsatance ο is readily shown to be  Consequently, if C 2 is adjusted such that which means that the time constants of the two parallel R-C combinations are the same, the potential difference division avoids phase shift, is given by equation (8.1) again and, in particular, is independent of frequency!
Adjustment of C 2 to procure division of potential that is independent of frequency may be carried out directly working with sinusoidal inputs over a wide range of frequencies or more conveniently through monitoring the distortion of fast pulses.
Some deliberate fixed capacitance is incorporated in parallel with R 1 , firstly to make the performance sufficiently independent of connections to the output and, secondly, to render the value of C 2 that satisfies equation (8.3) large enough to implement in practice, especially when the attenuation is large so that and .
Notice that the technique is extremely difficult to apply to the potentiometer divider of figure 8.1(c) because the resistance ratio can be varied continuously to alter the division of potential, and any introduced ratio of parallel capacitance would need to be capable of being varied in sympathy.
However, the technique is applicable to the step divider of figure 8.1(b) to provide variable if not continuous potential division.
When inserting an attenuator between a source and load in order to implement attenuation, it is often highly convenient if the loading of the source is unaltered by the insertion.
The advantage of this approach is that, whatever the impedance of the source, the signal fed to the input of the attenuator following its insertion is the same as that fed to the load prior to insertion.
Figures 8.2(a) and (b) illustrate the point, the potential divider exhibiting attenuation represented by  and input resistance equal to the load resistance R L .
In the case of the simple potential divider depicted in figure 8.2(c), the requirement of unaltered loading on insertion between a source and load resistance R L demands that  But the attenuation is     or through condition (8.4) From equations (8.4) and (8.5) it follows that to implement attenuation A through a simple potential divider without altering the loading of the source, the values of resistances R 1 and R 2 must be  Notice that to provide variable attenuation yet maintain unaltered loading, that is, input resistance equal to load resistance, both resistances R 1 and R 2 must be adjusted in such a way as to comply with equations (8.6).
When , equations (8.6) simplify to 
8.2 (a) and (b) Illustration of the introduction of attenuation between a source and load without altering the loading of the source.
(c),(d) and (e) Attenuators designed (see text) such that their input resistance equals the load resistance.
(f) A switchable ladder attenuator designed (see text) such that its input resistance equals half the load resistance.
In general, all that is needed to provide a given attenuation and an input resistance equal to the load resistance is a resistive network with two independently selectable resistances.
The symmetric T network of figure 8.2(d) comprising two equal resistances R 2 and a different resistance R 1 is therefore also suitable for the purpose.
For its input resistance to equal the load resistance R L while the attenuation is  Combining these last two equations shows that the values of R 1 and R 2 needed for the circuit to perform as required are 
The T network is actually the star network considered in the context of direct currents at the end of section 3.2 where it was shown that it transforms into an equivalent delta network.
One terminal of this equivalent is again common to the input and output and the delta network can be redrawn with a common line between its input and output and with its components arranged in a Π shape.
In such circumstances it is more appropriate to describe the delta network as a Π network and there is clearly a Π version of the attenuator just treated.
A snag with the T attenuator is that three resistors need to be adjusted to vary the attenuation yet maintain the input resistance equal to the load resistance.
This difficulty is overcome in the interesting bridged-T attenuator shown in figure 8.2(e).
The circuit plus load resistance R L is of the Wheatstone bridge type with arms WY, YZ, ZX and XW.
Insight into its  operation is gained by considering the balanced condition in which node-pair potential difference V 1 equals the attenuated output potential difference AV so that no current flows through the connecting branch XY.
Balance occurs when  equals  or  Thus the input resistance at balance comprising () in parallel with () amounts to  as required.
To achieve balance with attenuation A  or  in accordance, of course, with equation (8.9).
Notice that when A is very small, equation (8.10) reveals that  and  so that branch WX essentially provides the input resistance R L .
On the other hand, when , equation (8.10) reveals that  and  so that the load provides the input resistance R L .
An extremely attractive feature of attenuators having input resistance equal to load resistance is that identical ones may be cascaded to give compound attenuation yet still maintain the overall input resistance equal to the load resistance.
A switchable compound or ladder attenuator formed from three T sections is shown in figure 8.2(f).
The input resistance in this case is, of course, constant at  as the input switch is changed.
Ladder attenuators incorporating Π sections turn out to be more economical in components than those formed from T sections because adjacent pairs of shunt resistors can be merged into single resistors.
A basic high-frequency signal potential divider may be constructed from two low-loss capacitors as shown in figure 8.1(e).
The capacitive reactances are designed to be low over the operating range of frequencies compared with any incidental shunting capacitive reactance or resistance.
Stray capacitance now simply alters the high-frequency potential division obtained.
Whereas resistive potential dividers dissipate electrical power, capacitive dividers do not.
In chapters 6 and 7 it has been established that accurate reduction in the amplitude of alternating potential difference or current can be achieved using a transformer.
Here again there is negligible waste of power, but unfortunately the range of frequencies over which a transformer will act as a potential or current divider is restricted by the behaviour of the core, there being both a lower and upper limit.
Whenever the potential difference across a resistance is reduced to a fraction A of a previous value, the current through it is also reduced to the same fraction A and the attenuation of power is given by A 2 .
Because power can vary over such enormous ranges, it is customary to describe the attenuation of power in decibel units, the ratio of two powers P 1 and P 2 being described in terms of bels or  decibels.
Thus, making use of the abbreviation dB for decibel, when , for example, the power is said to be modified by  and when , the modification of power is described as  An alternative expression of the power change in these two cases would be that the power is reduced or attenuated by +20 dB and +6 dB respectively.
Common load resistances that attenuators are designed to operate into are 600Ο, 75Ο and 50Ο.
This is because certain instrumentation and connecting cables (see section 9.5) are arranged to match these impedances; 600Ο is the adopted standard in professional audio-frequency systems, 75Ο the standard in domestic television and 50Ο the standard in radio-frequency instrumentation.
8.2 Simple single-section filters
Selective reduction of the amplitudes of sinusoidal electrical signals as a function of frequency is described as filtering.
Naturally, networks that achieve such frequency-dependent reduction are termed filters.
Since any nonsinusoidal signal is the sum of a frequency spectrum of sinusoidal signals (see chapter 11), filtering generally alters the time dependence of a nonsinusoidal signal.
In electronics, filters are used, for example, to suppress an undesirable signal that occurs at some frequency, to extract sinusoidal signals over some particular frequency band from a wider range of sinusoidal signals and to convert a nonsinusoidal signal into a sinusoidal signal of the same period.
It should be clear from the basic theory of chapter 5 that, to implement filtering, a circuit must include at least one reactive component.
Inevitably, filtering action is accompanied by a frequency-dependent phase shift.
Filters are mostly of the low-pass, high-pass, band-pass or band-stop varieties.
Ideally, as the names imply, a low-pass filter passes signals up to some limiting frequency but not above it, a high-pass filter passes signals down to some limiting frequency but not below it, a band-pass filter passes signals over a range of frequencies but not outside it and a band-stop filter  only passes signals outside a range of frequencies.
Practical filters fall short of these ideals of course.
Two very simple C-R filters are shown in figure 8.3.
They have already been encountered in section 4.4 in connection with electrical transients but are reproduced here (in reverse order) for easy reference.
Consider their response to a steady sinusoidal input signal when a load resistance R L is connected across the output terminals.
The ratio of the phasor output to input potential difference,, is known as the transfer function and denoting this function by , for the circuit of figure 8.3(a), where  represents the resistance of R in parallel with R L .
At low-enough frequencies to satisfy , the transfer function becomes simply .
At higher frequencies the transmission clearly falls below this value so that the circuit behaves as a low-pass filter.
To approach the ideal of nearly 100% pass at low frequencies, the circuit must be designed such that.
Within this approximation    where φ is the phase shift between the input and output potential differences.
8.3 Basic C-R filters loaded with resistance R L ;(a) low pass and (b) high pass.
The performance of the simple low-pass C-R filter is best displayed over a large range of frequency in a plot of  versus .
Such a plot is  presented in figure 8.4(a) for the case where the time constant RC of the filter is 1 ms, as might be provided by ,, for example.
It is of course taken for granted that the loading is such that  always so that the response is given by equations (8.11)(8.13).
The transmission begins to cut off when ο reaches  and, as depicted in figure 8.4(b), an accompanying change in phase shift φ from about zero to a lag of about 90° takes place within a decade of pulsatance either side of .
When , and, for constant amplitude of input signal, the amplitude of the output signal falls linearly with frequency, that is, at a rate of 10 dB per decade.
The corresponding rate of fall of the output signal power is 20 dB per decade or very close to 6 dB per octave (an octave is the musical term for two notes, one of which is double the frequency of the other).
Actually when , the capacitive reactance  is very small compared with R and R L so that the input impedance of the filter is almost constant and equal to R. Consequently the amplitude of input signal delivered by a sinusoidal source may well remain constant as the frequency changes.
8.4 Responses of simple C-R filters showing the behaviour of the modulus of the transfer function,, and the phase shift, φ, as a function of the pulsatance ο;(a) and (b) for the low-pass filter of figure 8.3(a) and (c) and (d) for the high-pass filter of figure 8.3(b), when .
The simple form of C-R filter just discussed is widely used in conjunction with an operational amplifier, in circumstances where , to achieve electronic integration of a signal as mentioned in section 4.4.
This important practical circuit is treated in section 10.5.
A more mundane application is to the reduction of interfering mains-frequency signals accidentally picked up in circuits designed to operate at even lower frequency, for example in direct-current circuits.
In direct supplies derived by rectifying the alternating mains, a low-pass C-R filter is often used to reduce the residual alternating component of the output to an acceptable low level.
Here the filter normally follows a tank capacitor connected in parallel with the rectified mains.
This first capacitor charges to the peaks of the rectified sinewave potential during forward intervals but discharges somewhat through the load during reverse intervals as the rectified e.m.f. first falls from its peak value and then rises back to the potential difference retained on the capacitor.
The following filter incorporated to reduce the residual potential fluctuation may be C-R in type provided that the series resistance R introduces only an insignificant drop in the direct output potential difference.
Such a situation arises when the supply only delivers a small direct load current.
Yet another application of the simple low-pass C-R filter is in amplitude demodulation.
The information carried by an amplitude-modulated signal (see section 5.9) is recovered by rectifying it and filtering out the carrier wave to leave the amplitude-modulating wave.
In this case, the RC time constant of the filter must be long compared with the period of the carrier but short compared with the briefest period involved in the modulation.
Turning to the simple C-R circuit of figure 8.3(b)    where again R' represents the resistance of R in parallel with R L and φ the shift in phase of the potential difference between input and output.
To illustrate the behaviour of this type of filter, figures 8.4(c) and (d) respectively show plots of  and φ versus  for the case where the time constant R'C is 1 ms.
At high-enough frequencies to satisfy , there is virtually 100% transmission and negligible phase shift.
When the pulsatance falls to , the transmission begins to fall and reaches a cut-off rate of 6 dB per octave in power when .
This time the phase shift changes over from about zero to a lead of about 90° within a decade of pulsatance either side of .
The response of the C-R circuit of figure 8.3(b) is clearly complementary to that of figure 8.3(a); it acts as a high-pass filter.
At low-enough frequencies to satisfy , the input impedance is  virtually  which is becoming very large.
Thus the amplitude of input signal delivered to the filter by a sinusoidal source may well remain constant as the frequency changes in this range.
Very important electronic applications of the simple high-pass form of C-R circuit are to coupling a signal while blocking a direct potential difference and to differentiation of a signal as discussed in section 4.4.
Simple L-R filters that correspond to the simple C-R filters of figure 8.3 are shown loaded with resistance R L in figure 8.5.
The transfer function of the circuit of figure 8.5(a) is  where R' represents the resistance of R in parallel with R L , while the transfer function of the circuit of figure 8.5(b) is   or  Respective comparison of equations (8.11) and (8.14) with equations (8.17) and (8.18) reveals that the circuit of figure 8.5(a) responds similarly to that of figure 8.3(a) and acts as a low-pass filter while the circuit of figure 8.5(b) responds similarly to that of figure 8.3(b) and acts as a high-pass filter.
Notice that the frequency responses of the inductive circuits are characterised by the inductive time constant .
Because of the greater size and expense of an L-R filter compared with its C-R counterpart, not to mention the less-ideal behaviour of inductors compared with capacitors, the C-R version of a filter is usually preferred to the L-R version.
8.5 Basic L-R filters loaded with resistance R L ;(a) low pass and (b) high pass.
Replacement of the inductor of a simple L-R filter by a series or parallel  combination of an inductor and capacitor creates a band-pass or band-stop filter on account of the resonant response.
Series resonant versions of such filters together with sketches of their frequency responses are presented in figure 8.6.
The central frequency of the pass or stop band is, of course, given by  and the width of response by the Q-factor of the resonant combination.
8.6 Series resonant filters;(a) band-pass,(b) band-stop,(c) and (d) sketches of the frequency responses of (a) and (b) respectively.
To procure a steeper cut-off than is exhibited by the frequency responses of the simple C-R or L-R low and high-pass filters, further reactive components must be added to the network.
Actually, the band-pass and band-stop filters just treated illustrate this point nicely.
Consider next the unloaded low-pass L-C filter drawn in figure 8.7(a).
Enhanced performance stems from the capacitive reactance falling simultaneously with the inductive reactance increasing as the frequency increases.
The unloaded transfer function is  At sufficiently high frequencies to satisfy , falls off as  compared with the fall off as  for the simple C-R and L-R filters.
Figure 8.7(b) shows  plotted against  for the case .
The infinite singularity in the response would not occur in a practical circuit because of inevitable resistive loss.
The fall in  of 20 dB per decade when   is clear.
A particularly appropriate application of this form of circuit is to the filtering of rectified mains in mains-derived direct supplies.
The practical transfer function is very close to unity for the required direct component of the potential difference if low-loss reactors are incorporated yet is very tiny at the ripple frequency if  is made very small compared with the ripple pulsatance (200π for full-wave rectification, since the ripple to be smoothed is at twice the mains frequency).
Note that the input impedance of this filter is extremely dependent on frequency with a sharp minimum at series resonance.
8.7 (a) Low-pass, L-C filter (unloaded) and (b) its frequency response when .
8.3 Wien, bridged-T and twin-T rejection filters
The creation of highly selective band-pass or band-stop filters based on appropriate resonant branches has been alluded to in the previous section.
A problem arises with the design of such filters for passing or stopping low frequencies.
To obtain a low resonant frequency, the inductance has to be very large since it is difficult to achieve very high capacitance.
Even with capacitance of as much as , inductance of 0.1 H is needed to procure resonance at 50 Hz.
Components that provide such high inductance are inconveniently big and rather expensive.
Fortunately band-pass and band-stop filters can be constructed from just capacitors and resistors, thereby avoiding the inductive problem.
Band filters that can be tuned down to low frequencies are useful in a host of applications including electronic oscillators.
As already mentioned, they are useful for strong rejection of low-frequency interfering signals originating from the mains supply, which is absolutely essential in many instances.
Often band-stop filters are described alternatively as rejection filters.
8.8 (a) Wien band-stop filter,(b) Wien band-pass filter and (c) the frequency responses of these two filters.
One well-known band filter that is formed from resistors and capacitors  only is the Wien network shown in figure 8.8(a).
Its transfer function in the unloaded condition is   or  Hence its unloaded transmission is given by  from which it can be seen that the transmission approaches 100% as the frequency tends to zero or infinity, but reaches a minimum value of ⅔ when  .
Inspection of the circuit diagram reveals that the tendency to perfect transmission at high-enough frequencies is due to that capacitor which shorts the output to input in this range.
Almost perfect transmission at low-enough frequencies stems from both capacitors tending to become open circuit.
Clearly, the circuit behaves as a rejection filter and figure 8.8(c) gives its response over a range of frequencies either side of the rejection frequency .
Provided any loading impedance is high compared with resistance R, the response will stay close to that of figure 8.8(c).
Making the capacitance  and resistance  yields a time constant RC = 1 ms and leads to rejection at a frequency of 160 Hz, for example.
Notice that, according to equation (8.20), the output and input are in phase at the rejection frequency.
Most importantly, the plot of  in figure 8.8(c) reveals that the rejection provided by a Wien network is neither sharp nor strong.
The reason that a Wien bridge based on this network and already described in section 7.7 performs well is because the bridge arrangement achieves null potential difference across the detector at the rejection frequency, thereby enhancing the effect of rejection.
The Wien band-pass filter complementary to the rejection filter just considered is shown in figure 8.8(b).
This time the transfer function is    or  Hence  Now there is zero transmission when  and  with maximum transmission amounting to  when .
The asymptotic approach to zero transmission at high frequencies is associated with the capacitance in parallel with the output while the similar behaviour at low frequencies comes about because of the series capacitance between input and output.
Again the filtering action is far from sharp, as can be seen from the response plotted in figure 8.8(c).
Despite the somewhat diffuse action, satisfactory sinusoidal oscillators can be formed based on Wien filters as explained in section 10.6.
An irritating feature of Wien filters is that to vary  the pass or rejection frequency, ideally both capacitances or, as is rather easier, both resistances should be varied in sympathy.
8.9 (a) A bridged-T, R-C, rejection filter and (b) a bridged-T, L-C-R. rejection filter.
A simple bridged-T form of rejection filter is shown in figure 8.9(a).
Applying Kirchhoff's current law to the unloaded network, the phasor node-pair potentials , and  are found to be related by   Substituting for  in the second equation in terms of and  from the first yields  from which the transfer function is  Consequently the ratio of potential-difference amplitude between output and input is  When k = 1 this is the same transmission as provided by the Wien network of figure 8.8(a).
In general, equation (8.25) shows that the bridged-T filter of figure 8.9(a) exhibits minimum transmission when  amounting to   Making k larger gives better rejection.
Changing the rejection frequency by tuning only capacitance kC simultaneously varies the degree of rejection.
8.10 (a) Twin-T, R-C, rejection filter and (b) its frequency response.
An extremely popular R-C filter, that in its ideal form provides total rejection at the designed rejection frequency, is the twin-T filter shown in figure 8.10(a).
In practice the maximum attenuation is finite and depends on the quality of the components used to construct an approximation to the theoretical circuit of figure 8.10(a).
For a high degree of rejection, the capacitors must be very low loss and the resistors must exhibit very little capacitance.
Behaviour of the twin-T as a rejection filter is easily understood qualitatively on appreciating that it comprises a low-pass filter (R, R, 2C) in parallel with a high-pass filter (C, C, R÷2).
Treating the twin-T of figure 8.10(a) quantitatively by the method of node-pair analysis, Kirchhoff's current law applied at nodes X and Y respectively gives    On collecting terms these equations become   Now, provided that the twin-T is unloaded, or  Substituting for  from equation (8.30) in equation (8.29) and substituting for  from equation (8.28) Hence the transfer function for the unloaded twin-T is  and the ratio of potential-difference amplitude between the output and input is  The behaviour of  as a function of frequency according to equation (8.32) is plotted in figure 8.10(b).
There is much sharper rejection than obtained with the other filters described in this section and, very significantly, there is total rejection when  While the basic circuit of figure 8.10(a) is only really suitable for rejection at a fixed frequency, variants exist which are amenable to tuning.
Before leaving the topic of the twin-T filter, it is worth pointing out that it rejects at the frequency given by equation (8.33) no matter what the load.
Whenever , the output current is also zero and so, because the current is continuous between the input terminals, Rearranging terms, this gives  Through equations (8.28) and (8.29) under the condition , and  can be expressed in terms of.
Making use of this information in the last equation yields   or  While the imaginary terms of this equation balance, the real terms give equation (8.33) again.
Another interesting network that totally rejects signals of a certain frequency is the L-C-R bridged-T of figure 8.9(b).
Since  when the circuit is totally rejecting a signal, application of Kirchhoff's current law to nodes A and B reveals that total rejection occurs when the simultaneous equations   are satisfied.
Eliminating  between these equations gives  or on separately equating the real and imaginary parts   The second of these two relations simplifies to  and substitution of this condition into the first yields  Equations (8.34) and (8.35), representing the conditions that must be satisfied to procure total rejection, become much simpler if it is assumed that , for they then reduce to   Evidently, if  and , total rejection occurs at a frequency close to .
Making use of equations (8.36) and (8.37), the simplifying condition on  can be seen to be equivalent to  which in practice simply means that the coil providing impedance  must have a high Q-factor.
Apart from the applications already referred to in this section, filters that provide total rejection at some frequency are particularly useful for  measuring distortion.
A periodic signal with a waveform distorted from sinusoidal is equivalent to a Fourier spectrum of sinusoidal signals (see section 11.1).
Total rejection of the fundamental just leaves the harmonic content that represents the distortion and can be measured readily.
Although the single-section filters covered in this chapter are quite important, their treatment merely serves as an introduction to the vast subject of filters.
Multiple-section filters are analysed in the following chapter while the topic of active filters is broached in chapter 10.
The modern approach of filter synthesis features in chapter 12.
Before concluding the present chapter, a brief discussion of phase-shift networks is appropriate.
8.4 Phase-shift networks
Although all the filter networks treated so far in this chapter cause phase shift, in each case it is accompanied by attenuation.
What is more, should a component be varied to alter the phase shift, the attenuation also changes.
Many practical situations require the introduction of a variable phase shift, ideally with no attenuation but at least with fixed attenuation.
A fixed phase shift of π radians may be obtained without attenuation from a unity-ratio, close-coupled, low-loss transformer as explained in chapter 6.
Figure 8.11(a) depicts the derivation of signals of equal amplitude but separated in phase by π radians through the action of a centre-tapped transformer.
Provision of such phase-related signals is described as phase splitting and is widely used in electronics for various purposes.
One area of application is in null balancing methods of measurement such as the transformer ratio-arm bridges described in section 7.8.
Phase splitting also plays a vital role in the important variable phase-shift network to be considered in a moment.
Two alternatives to a transformer for splitting the phase of a signal are the potential-divider arrangement of figure 8.11(b), which attenuates the input signal by a factor two while splitting the phase, and the transistor phase splitter of figure 8.11(c), which has virtually unity gain provided R is large enough.
8.11 Phase splitting by (a) a centre-tapped transformer,(b) a resistive potential divider and (c) a transistor amplifier.
8.12 (a) Network that introduces a variable phase shift but preserves a constant output amplitude and (b) its analysis by a phasor diagram.
A very simple network, that while preserving a constant amplitude introduces a variable phase shift through adjustment of a single resistor, is shown in figure 8.12(a).
How this network operates is most easily explained by means of the phasor diagram presented in figure 8.12(b).
A phase-split signal  derived from any input, for example by one of the circuits appearing in figure 8.11, is applied between the terminal pairs BO and AO.
Thus the phasor potential difference between B and A is .
The phasor potential difference  across the capacitance C lags 90° behind the phasor potential difference VR across the resistance R, assuming negligible loading  of the output taken between terminals P and O, while  All of these aspects are maintained in the phasor diagram of figure 8.12(b) and its geometry is seen to be such that the point P moves over a circle, centre O, as the resistance R is varied.
But OP in the diagram represents the  phasor output potential difference  taken between terminals P and O. Consequently, through altering the resistance R, the output may be varied in phase by π radians with respect to the input while maintaining its amplitude constant.
Multiple-section filters and transmission lines
9.1 Ladder filters
The sharpness of filtering may be vastly improved by cascading individual filter sections to create what is known, rather appropriately, as a ladder filter because of its appearance.
One obvious approach is simply to cascade a number of identical sections.
The problem with such ladder filters is that, in general, each section loads the preceding one with a different impedance making it difficult to predict the overall performance of the ladder or to design a ladder to meet a given specification.
Avoidance of this difficulty is only possible by following the approach adopted in the design of ladder attenuators and arranging that the input impedance of any section is equal to its load impedance.
Cascaded identical sections that meet this criterion are all identically loaded and, therefore, behave identically.
In particular, if  is the transfer function of any such section, the overall transfer function of the ladder filter is  where n is the number of sections.
In the common case of a symmetric section, the load impedance that renders the input impedance equal to it is called the characteristic impedance.
While the identical symmetric sections of an infinite ladder would obviously be loaded with the characteristic impedance, this is an impractical arrangement.
A finite ladder of identical symmetric sections, which has the last section loaded with the characteristic impedance in order that all sections are so loaded, is said to be correctly terminated.
9.1 (a) A ladder network which may be considered as comprising cascaded identical T-sections, each of which is as shown in (b) or cascaded identical Π-sections, each of which is as shown in (c).
Consider now the form of ladder filter shown in figure 9. l(a), which has repeated series and parallel impedances Z 1 and Z 2 .
It can be thought of as comprising cascaded identical symmetric T or Π-sections, the circuit diagrams of which are presented in figures 9. l(b) and (c).
The characteristic impedances  and  of these T and Π-sections are respectively given by   or  which reduces to  and   which reduces to  If the mesh currents in the nth and (n + 1) th meshes of the ladder network are denoted by  and  as indicated in figure 9.1(a), then, provided the ladder is correctly terminated, the transfer functions of its T and n-sections can be expressed as  and   respectively, which are identical.
The result  is, of course, to be expected, since T and Π-sections are different ways of breaking the same network into repeated sections.
To find  in terms of, the network must be analysed.
Application of Kirchhoff's voltage law in the (n + 1) th mesh yields   in terms of or  in terms of.
That these two expressions relating  to  are equivalent is easily verified since it requires  or  The validity of this last relation is best seen by appreciating that, according to equations (9.1) and (9.2), the characteristic impedances obey  and  Making use of equations (9.1) and (9.5) and writing the ratio  as u, it follows from equations (9.3) and (9.4) that the transfer function of a T or Π-section of the form of ladder filter under consideration is given by  In general u and hence  will be complex and it is helpful at this juncture to put  where γ is known as the propagation constant.
The quantity  is the ratio between the amplitudes of currents in successive meshes or the ratio between the amplitudes of potential differences at the inputs of successive sections.
Accordingly, the parameter α is known as the attenuation constant.
The parameter β represents the phase shift introduced by a section.
From equations (9.9) and (9.10) that is, the propagation constant is given by the simple relation 
Attention will now be focussed on correctly terminated ladder filters in which Z 1 and Z 2 are pure reactances, for practical approximations to these networks are widely used.
When Z 1 and Z 2 are pure reactances, is  real and since  it follows that   The solution  to equation (9.13) implies that  or  which means that there is no reduction in amplitude through a section of the filter.
The solution  also implies that  and so from equation (9.14), there is a phase shift β given by  However, has to be in the range -1 to + 1.
Consequently the solution  and the associated absence of attenuation corresponds to u being in the range -1 to 0, that is, For particular reactive impedances, this last condition is satisfied over a certain range of frequency.
Thus any correctly terminated filter section with purely reactive elements perfectly passes signals over a certain range of frequency defined by the inequality (9.16) and appropriately known as the pass or transmission band but introduces a phase shift given by equation (9.15) in this frequency band.
The twin solutions to equation (9.15) of equal positive and negative phase shifts correspond to the possibility of feeding a signal in at either end of the symmetric section and loading it with its characteristic impedance at the other end.
The alternative solution  to equation (9.13) implies that  or .
In the first case, and so from equation (9.14) there is a reduction in amplitude given by  Since , this in turn implies that  The case  implies that , and so from equation (9.14) there is a reduction in amplitude given by  which in turn implies that  For given reactive impedances Z 1 and Z 2 , inequalities (9.18) and (9.20) define ranges of frequency over which the signal is attenuated, there being a phase shift of zero in one range and  in the other.
This time, the term  attenuation band is an apt description of each range of frequency.
Twin solutions to equations (9.17) and (9.19) of equal positive and negative values of a again correspond to the possibility of feeding the symmetric section at either end and terminating it at the other end.
9.2 Variation of the attenuation constant α and phase shift β with the parameter  for a correctly terminated section of a purely reactive ladder filter of the type shown in figure 9.1.
Figure 9.2 shows the variation of the attenuation constant α and phase shift β with the parameter u according to the theory just presented.
For a filter having n sections the total phase shift is, of course, and the total attenuation .
9.2 Constant-k filters
The theory of the foregoing section will now be applied to particular purely reactive filters.
As it is thereby illustrated and developed its implications should clarify.
Consider first a ladder filter of the type studied in the previous section in which each series impedance Z 1 is due to inductance L and each parallel impedance Z 2 to capacitance C as shown in figure 9.3(a).
Since the series impedances are small and the parallel impedances are high at low frequencies, while the opposite is the case at high frequencies, this network behaves as a low-pass filter.
Its quantitative response, when correctly terminated, is governed by the parameter  introduced in the last section and substitution of  and  establishes that  Because u cannot be positive at any frequency, there is no range of frequency that corresponds to inequality (9.18) and equation (9.17) is inapplicable.
In the range  which corresponds to  the attenuation constant α is zero and the phase shift β per section is given by equation (9.15) which becomes   In the range  which corresponds to  the phase shift is  and the attenuation is given by equation (9.19) which becomes   
9.3 (a) Low-pass, symmetric, L-C, ladder filter,(b) its attenuation constant α and phase shift β per section as a function of the pulsatance ο when correctly terminated,(c) correct termination where  is given by equation (9.28) and (d) correct termination where  is given by equation (9.29).
Figure 9.3(b) presents plots of the attenuation constant α and phase shift β per section according to the relations just deduced.
The most significant feature of the response is the existence of a critical pulsatance  which marks the end of an ideal pass band and the beginning of attenuation.
In terms of this critical pulsatance, at pulsatances above and below it respectively, the attenuation constant and phase shift per section are given by  The fact that the transfer function  becomes  when   establishes that, in the pass band, the output signal of a section lags in phase behind the input signal to that section.
According to equations (9.1),(9.2) and (9.26), the characteristic impedances that correctly terminate T and Π-sections of this low-pass filter are  and  respectively.
Figures 9.3(c) and (d) show the circuit arrangements needed for correct termination by  or .
Unfortunately, no combination of circuit components can produce an impedance with the required terminating frequency dependence of equation (9.28) for  or that of equation (9.29) for .
At best these dependences can only be approximated by complicated networks and the performance of any real filter must fall short of that represented by figure 9.3(b) for a correctly terminated filter.
The usual procedure adopted is to terminate with a fixed resistance  in place of or .
Such termination is very close to correct in the pass band until  approaches , say until  reaches .
Further, although incorrectly terminated, the input impedance of a section terminated with resistance  is much closer to the characteristic impedance than resistance .
Thus a ladder filter comprising several sections and terminated in resistance  tends to correct termination of sections rapidly along the ladder and responds overall quite closely to how it would respond if it were possible to correctly terminate the end section.
Figure 9.4 illustrates the point by comparing the input impedance of a low-pass, symmetric, L-C T-section terminated in resistance , which is  where , with its characteristic impedance given by equation (9.28).
An interesting application of the low-pass, L-C, ladder filter, apart from harnessing its filtering action, is its use to delay an electrical signal by a known time interval without attenuation or distortion.
To achieve this end, the filter is arranged to operate entirely in its pass band by designing it so that its critical frequency is well above the highest frequency present in the Fourier frequency spectrum of the signal being handled.
This being so, there is virtually 100% transmission of each Fourier component of the signal with  each component suffering a phase shift of β per section, where β is given by equation (9.23) or (9.27).
Because the frequencies of all the components are well below the critical frequency, the phase shift β is always small enough to make the approximation  or  Corresponding to the phase shift there is a time delay  per section given by  The crucial point to emerge from equation (9.33) is that the delay is almost independent of frequency so that all Fourier components of the signal experience virtually the same delay and the signal is transmitted, delayed but virtually undistorted, as well as virtually unattenuated.
Any network that behaves in this way is called a delay line.
In practice, a single-section, low-pass, L-C, delay line works reasonably well provided that the highest frequency present in the signal is less than one-half of the critical frequency.
Above this frequency, the attenuation ceases to be negligible and the phase shift ceases to be sufficiently proportional to frequency.
If individual sections are cascaded to form a delay line, the critical frequency must be correspondingly higher in relation to the frequencies present in the signal, otherwise unacceptable attenuation and distortion will again occur on account of the compound transfer function.
Thus from equation (9.33) the delay per cascaded section is correspondingly shorter and the longest delay that can be achieved by means of a low-pass, L-C, ladder filter is rather a small fraction of the fundamental period or pulse duration of the signal being handled.
9.5 (a) High-pass, symmetric, L-C, ladder filter,(b) its attenuation constant α and phase shift β per section as a function of the pulsatance ο when correctly terminated,(c) correct termination where  is given by equation (9.41) and (d) correct termination where  is given by equation (9.42).
9.4 The input impedance of a terminated T-section of a symmetric, low-pass, L-C, ladder filter.
Solid lines give values of the input resistance and reactance when terminated by fixed resistance  while dashed lines show values of these quantities when terminated by the characteristic impedance.
Interchanging capacitance C with inductance L in the low-pass, L-C, ladder filter creates the complementary, high-pass, L-C, ladder filter shown in figure 9.5(a).
Qualitatively, the high-pass filtering action stems from the series and parallel impedances being respectively low and high at high frequencies while the opposite is true at low frequencies.
Quantitatively, the series and parallel impedances are respectively  and  so that and equation (9.17) is again inapplicable because inequality (9.18) cannot be satisfied at any frequency.
In the range  which corresponds to  the attenuation constant is zero and the phase shift β per section is given by  equation (9.15) which becomes  In the range  which corresponds to  the phase shift is  and the attenuation is given by equation (9.19) which becomes  Figure 9.5(b) presents plots of the attenuation constant α and phase shift β as a function of pulsatance ο according to the results represented by relations (9.35)—(9.38).
This time the critical pulsatance separating the pass and attenuation bands is  In terms of the critical pulsatance, at frequencies below and above it respectively, the attenuation constant and phase shift per section are given by 
According to equations (9.1),(9.2) and (9.39), the characteristic impedances that correctly terminate T and Π-sections of this high-pass filter are  and  respectively.
Figures 9.5(c) and (d) show the circuit arrangements needed for correct termination by  or .
In the limit of sufficiently high frequencies to satisfy  the transfer function  reduces to  establishing that, in the pass band, the output signal of a section leads the input signal to that section in phase.
Once again it is impossible to correctly terminate the filter for all frequencies and the usual practice is to terminate with resistance  which is correct for most of the transmission band.
Thus terminated, a high-pass ladder filter tends to correct termination of sections rapidly along the ladder so that the overall response is quite close to that of a correctly terminated ladder.
The high-pass filter is unsuitable for use as a delay line because the delay in the pass band depends markedly on frequency.
For example, when  the phase shift β is always small enough to make the approximation   or  and the corresponding time delay per section is inversely proportional to .
The low and high-pass, L-C, ladder filters already discussed in this section are said to be constant-k filters because the product of the series and parallel impedances is independent of frequency, which fact can be expressed in terms of a constant k as  For the low and high-pass filters considered, k is just .
In general, two impedances satisfy equation (9.44) if the networks providing them are dual which means that the admittance of one network exhibits the same frequency dependence as the impedance of the other.
Writing the impedance of one network as  and the admittance of the other as , it is clear that equation (9.44) is satisfied if  For equation (9.45) to be applicable, the conductance G 2 and susceptance B 2 must exhibit the same frequency dependences as the resistance R 1 and negative reactance -X 1 respectively.
That such behaviour occurs for series and parallel resonant circuits has already been pointed out in section 5.7.
The concern in the present section is with purely reactive circuits and it is worth noting that in dual versions the frequencies at which the reactance becomes zero or infinite is the same, one circuit being resonant () whenever the other is antiresonant () and vice versa.
In addition, purely reactive dual networks exhibit opposite signs of imaginary impedance at all frequencies.
9.6 (a) T-section of a constant-k, band-pass, ladder filter and (b) its attenuation constant α and phase shift β per section as a function of the pulsatance ο when correctly terminated and ,.
Figure 9.6(a) shows a T-section of a constant-k, band-pass, ladder filter.
The series and parallel arms of the ladder are dual, resonant, reactive networks, their impedances being ; To make the product  independent of frequency requires  under which condition  Satisfaction of condition (9.47) causes the series and parallel arms to resonate at the same frequency and there is 100% transmission at that frequency.
At low frequencies the impedances of the series arms are high on account of series capacitance while the impedances of the parallel arms are  low on account of parallel inductance.
Consequently the transmission is low, with the circuit behaving like a high-pass filter.
At high frequencies, the impedances of the series and parallel arms are again high and low respectively but on account of series inductance and parallel capacitance.
Once more, the transmission is low, but now the circuit behaves like a low-pass filter.
Evidently, the overall response of this particular filter may be described as band-pass.
When correctly terminated, its quantitative response is governed by the parameter u, which from equations (9.46) and (9.48) is  Once more u cannot be positive at any frequency and there is no range of frequency that corresponds to inequality (9.18) so that equation (9.17) is inapplicable.
The condition  is conveniently expressed by  where  Taking the square root of both sides of equation (9.50), the quadratic equation   is obtained which has roots  or, since only positive pulsatances have physical meaning  Substituting for k from equation (9.48), these pulsatances are  and imposing condition (9.51) establishes that the pulsatance range corresponding to  is   In this range of pulsatance, the attenuation constant is zero, but from equation (9.15) there is a phase shift per section given by  In the range  which corresponds to pulsatances satisfying  and , where  and  are the critical pulsatances defined in condition (9.52), the phase shift is  but there is attenuation characterised by an attenuation constant α where  Perhaps surprisingly, condition (9.52) yields the simple relationship 
Figure 9.6(b) shows the attenuation constant α and phase shift β per section, according to the theoretical expressions just deduced, for a correctly terminated, constant-k, band-pass, ladder filter in which  and .
The characteristic impedance of a T-section of a constant-k, band-pass, ladder filter is from equations (9.1),(9.48) and (9.49) However, the usual procedure is to terminate such a ladder with resistance k given by equation (9.48), in which case the performances of its later sections depart somewhat from that indicated by figure 9.6(b).
Interchanging the series and parallel forms of resonant reactive circuit between the series and parallel arms of the band-pass filter just discussed, naturally creates a band-stop filter.
It is left as a useful exercise for the reader to show that if L 1 and C 1 represent the inductances and capacitances in the parallel resonant series arms, while L 2 and C 2 represent the corresponding  quantities in the series resonant parallel arms, and the critical pulsatances between which attenuation occurs are given by 
It is worthwhile recognising that in the attenuation bands of the purely reactive ladder filters considered, the characteristic impedances  are pure reactances because .
Thus, under correct termination, no electrical power is fed into these filters over the attenuation bands of frequencies.
The current and potential difference are everywhere 90° out of phase.
There is also, of course, no power in the reactive terminating loads.
In the pass bands, by contrast, u is in the range 0 to -1 so that and  are real resistances and, under correct termination, power is fed into the filters.
Obviously, since the filters are purely reactive, none of this power can be absorbed in them and it all reaches the terminating load in each case.
Purely reactive filters are, of course, impossible to achieve in practice and, in any approximation to them, the components inevitably exhibit resistive losses.
Such resistances raise the attenuation constant to a finite value in the pass bands and give rise to finite power dissipation in the filter.
They also adversely affect the rate at which the attenuation changes with frequency near critical frequencies.
It will be appreciated that ladder filters with configurations other than the one considered so far are possible.
Sometimes lattice filters are used in which each section is configured as shown in figure 9.7.
In this case, the characteristic impedance turns out to be simply  Particularly interesting behaviour arises when the choice , is made, for then  equals the fixed resistance  at all frequencies and correct termination is easy.
Such a correctly terminated low-pass lattice filter constitutes an extremely good delay line, the time delay per section being constant and equal to  at pulsatances well below .
9.3 m-Derived filters
Individual constant-k filter sections suffer from insufficient attenuation just outside the pass band and, although several identical constant-k sections may be cascaded to overcome this drawback, the resulting filter is rather unwieldy.
A much better way of achieving a  composite filter with strong rejection outside the pass band is to combine what is known as an m-derived section with a constant-k section.
As its name implies, the m-derived section is based on the constant-k section with which is cascaded and it is customary to refer to the undeveloped constant-k section as the prototype.
The m-derived section is arranged to exhibit the same characteristic impedance and critical frequency or frequencies as the prototype.
Enhanced attenuation over a suitable range of frequency outside the pass band is attained by making the shunt arm series resonant in the case of a T-type m-derived section, or the series arm parallel resonant in the case of a Π-type m-derived section.
Usually, the m-derived section is designed to resonate at a frequency just outside the pass band of the prototype so that its strong resonant attenuation coincides with the range of weakest attenuation of the prototype.
9.7 Section of a lattice filter.
How a T-type m-derived section is developed from a prototype T-section is shown in figure 9.8.
The impedances of the series components are multiplied by a factor m compared with the prototype where m lies between zero and unity.
To maintain the same characteristic impedance as the prototype, the shunt impedance Z' 2 of the m-derived section is arranged to satisfy  or  Thus the shunt arm of the m-derived section must be formed from the shunt impedance Z 2 of the prototype divided by m in series with extra impedance  as illustrated in figure 9.8(c).
The extra impedance, being of the kind Z 1 rather than Z 2 , has to be provided by extra components.
9.8 Development of an m-derived section from a T-section;(a) prototype,(b) series arms multiplied by m where , leaving the shunt arm to be determined and (c) complete T-type m-derived section with two series impedances in the shunt arm so as to achieve the same characteristic impedance as the prototype.
9.9 Development of an m-derived section from a Π-section;(a) prototype,(b) shunt arms divided by m where , leaving the series arm to be determined and (c) complete Π-type m-derived section with two parallel impedances in the series arm so as to achieve the same characteristic impedance as the prototype.
The design of a Π-type m-derived section based on a prototype Π-section is not the Π-section equivalent of the m-derived T-section just deduced, for this does not have the same characteristic impedance as the Π-prototype.
To form a Π-type m-derived section, the procedure is as illustrated in figure 9.9.
First the impedances of the shunt components are divided by a factor m compared with the prototype where m lies between zero and unity.
To maintain the same characteristic impedance as the prototype, the series impedance Z 1 of the m-derived section is chosen so as to satisfy  or  Thus  and the series arm of the m-derived section must be formed from the series impedance Z 1 of the prototype multiplied by m in parallel with extra impedance  as illustrated in figure 9.9(c).
Again, the extra  impedance, being of the kind Z 2 rather than Z 1 , has to be provided by extra components.
Making the characteristic impedances of the constant-k and m-derived filter sections identical also ensures that their critical frequencies are the same.
Inspection of the theory of sections 9.1 and 9.2 reveals the reason for this.
In particular, notice that the critical frequencies of m-derived T and Π-sections are determined by the general condition  which renders their characteristic impedance zero or infinite respectively.
Thus an m-derived section having the same characteristic impedance as a constant-k prototype involving series and parallel impedances Z 1 and Z 2 , that is, characteristic impedance  depending on whether the sections are T or Π-type, exhibits critical frequencies determined by .
This is precisely the condition that determines the critical frequencies of the prototype and so the critical frequencies of the m-derived and constant-k prototype sections are bound to be the same.
Checking this point, the critical frequencies of m-derived T and Π-sections are determined by , that is, by  and  respectively.
It is easily seen that these conditions are identical and reduce to just , the condition governing the critical frequencies of the constant-k prototype.
When the constant-k prototype is purely reactive, so that Z 1 and Z 2 are simply opposing imaginary quantities, it is easily appreciated that series resonance occurs in the shunt arm of the T-type m-derived section and parallel resonance in the series arm of the Π-type m-derived section.
Putting  in equation (9.60) and  in equation (9.61) further reveals that the resonant frequencies of both such derived sections are given by  In particular, for given Z 1 , Z 2 and m, the resonances of the T and Π-type sections are coincident in frequency.
Notice, however, that, while the attenuation of an m-derived section based on a purely reactive prototype would be infinite at resonance, any practical version of such a section actually exhibits strong but finite attenuation at resonance.
According to equation (9.63), a low-pass m-derived section with , resonates at pulsatance   where  is the critical pulsatance .
In the case of a complementary high-pass m-derived section with ,, equation (9.63) shows that the resonant pulsatance  is related to the critical pulsatance  by  the critical pulsatance being .
Since , resonance occurs in the attenuation band in either case.
Making m small sets the resonant frequency very close to the critical frequency so that the attenuation of the prototype is enhanced where it is weakest.
The parameter m is often chosen to be 0.3 which separates the resonant frequency by about 5% from the critical frequency.
Figure 9.10 shows the behaviour of the attenuation constant of a correctly terminated, low-pass, m-derived, filter section in which m = 0.3.
Also shown is the dependence of the attenuation constant of the corresponding prototype on frequency and the behaviour of the prototype and m-derived sections when cascaded.
Note that the low-pass, m-derived T-section corresponding to m = 0.3 has inductance 0.15L in each series arm compared with 0.5L in each series arm of the prototype and capacitance 0.3C in series with inductance of approximately 0.76L in the shunt arm compared with just capacitance C in the shunt arm of the prototype.
9.10 Attenuation constant α as a function of the pulsatance ο for a constant-k, low-pass, prototype, filter section, for the corresponding m-derived section having m=0.3 and for these two sections cascaded.
The problems of correct termination and providing constant input resistance in the pass band may both be eased by incorporating suitable m-derived half-sections at the input and output.
Consider first the T-type half-section shown in figure 9.11(a).
When this particular half-section is terminated in the characteristic impedance  of the prototype, its input  impedance is   which reduces to  on making use of equation (9.1).
Notice that if m = 0, equation (9.66) further simplifies to  which is just as expected, since the series and parallel arms of the half-section are then short and open circuit respectively.
At the opposite extreme of m = 1, the half-section is half of a constant-k T-section and equation (9.66) shows that in this case the load  gives rise to input impedance , the characteristic impedance of the corresponding Π-section.
Here the half-section is said to convert the load  to impedance  at the input.
For values of m between 0 and 1, the input impedance lies between  and  and is a function of  and m.
The dependence on  and m for a low-pass m-derived half-section of the form of figure 9.11(a) is shown in figure 9.12.
When m = 0.6, the input resistance remains close to  for frequencies up to 85% of the critical frequency.
Thus such a section placed in front of any number of correctly terminated constant-k or m-derived T-sections presents an almost constant input resistance of  over 85% of the pass band.
9.11 (a) An m-derived T-type half-section and (b) the same with input and output connections interchanged.
9.12 Input impedance of an m-derived low-pass half-section of the form of figure 9.11(a) with ,, as a function of the pulsatance ο and parameter m, when loaded with the characteristic impedance  of the prototype.
Now consider the other half of the T-type m-derived section shown in figure 9.11(b), which is of course just the same network as the first half already considered and shown in figure 9.11(a) but with the input and  output terminals interchanged.
Its input impedance when terminated in the impedance given by equation (9.66) is   On using equation (9.1) again, this relation reduces to  Thus the network of figure 9.11(b) terminated in the impedance given by equation (9.66) presents impedance  at its input terminals, precisely the required termination for constant-k or m-derived T-sections. since the impedance given by equation (9.66) is very close to  over 85% of the pass band when m = 0.6, the half-section of figure 9.11(b) with m = 0.6 interposed between a fixed resistance  and the output of a constant-k  or m-derived T-section will provide the T-section with virtually correct termination over most of the pass band.
An example of a composite low-pass filter terminated at its input and output with suitable m-derived half-sections is shown in figure 9.13.
It is of course possible to design Π-type m-derived half-sections to fulfil corresponding roles to those of the T-type m-derived half-sections.
Better performance still than that provided by the m-derived sections that have been described is available from what are known as double m-derived sections.
9.4 Asymmetric sections
9.13 Multiple-section low-pass filter comprising a constant-k section, an m-derived section and terminating half-sections.
The term iterative impedance is applied to a load that renders the input impedance of an asymmetric section equal to it.
There are of course two differing iterative impedances for any asymmetric section corresponding to the possibility of loading either end.
For the asymmetric T-section shown in figure 9.14(a), the two iterative impedances are given by  and  which readily rearrange into the quadratic equations  and  Thus  Of the two solutions to each of the equations (9.68), those having positive components of iterative resistance are appropriate and these normally  correspond to taking the positive root in each case.
For any symmetric section, one possibility being a section of the form of figure 9.14(a) with , the two iterative impedances are equal and the common impedance is said to be the characteristic impedance as stated earlier.
9.14 (a) An asymmetric T-section and (b) a source matched to a load through alternately reversed image sections.
Clearly, maximum transfer of power will not be achieved by cascading identical asymmetric sections between a source and correctly terminating iterative impedance.
However, any asymmetric section also has two image impedances  and  such that, if one pair of terminals is terminated in  and the input impedance at the other pair is , then, if that other pair is terminated in , the input impedance at the first pair is .
Maximum transfer of power does occur between a source and load, if their impedances are the image impedances of identical asymmetric sections connected in cascade between them such that alternate sections are reversed as illustrated in figure 9.14(b).
For the T-section of figure 9.14(a), the image impedances are given by  and  Rearranged, these equations become    Subtracting yields  while adding gives  Hence   Interestingly, the image impedances of a section can be more neatly expressed in terms of its input impedances under open and short-circuit termination.
Representing open and short-circuit terminating conditions by subscripts o and s respectively, these extreme cases of input impedance for the T-section of figure 9.14(a) are    Hence from equations (9.69) and (9.70) In the particular case of a symmetric section, the two image impedances are identical, the common image impedance being, of course, just the characteristic impedance.
Putting  in equations (9.68) and (9.69) bears this out, yielding  for the section of figure 9.14(a) with .
In comparing this particular expression for the characteristic impedance with equation (9.1) relevant to the circuit of figure 9.1(b), do not forget to replace  by .
One interesting asymmetric section is that L-section which back-to-back with itself forms the symmetric T or Π-section of figure 9.1 as illustrated in figure 9.15.
From equations (9.71) the image impedances are   The characteristic impedance  of the symmetric T-section formed by following the L-section of figure 9. 15(a) with that of figure 9.15(b) is clearly going to be  given by equation (9.72) which is in agreement with equation (9.1).
Similarly, the characteristic impedance  of the symmetric Π-section formed by following the L-section of figure 9.15(b) with that of figure 9.15(a)  is going to be  given by equation (9.73) which is in agreement with equation (9.2).
As noted previously in section 9.3, terminal impedance can be converted between  and  by introducing an appropriate half-section.
9.15 (a) An L-section which when cascaded with itself with reversed input and output connections as depicted in (h) forms the symmetric T-section of figure 9.1(b).
Note that reversing the order of cascading these two sections leads to the symmetric Π-section of figure 9.1(c).
9.5 Transmission lines
An arrangement consisting of a delivery and return conductor by means of which an electrical signal can be efficiently conveyed between two points is known as a transmission line.
Transmission lines vary in length from centimetres to thousands of kilometres, and to achieve satisfactory transmission it is essential for the delivery and return conductors to be of low-enough resistance and sufficiently insulated from each other.
The simplest type of transmission line comprises just a pair of parallel wires kept a uniform distance apart by suitably inserted insulating spacers.
However, a much more convenient and popular type of transmission line, generally referred to as a coaxial cable, essentially consists of a central conducting lead wire insulated from a coaxial outer return conductor.
In the usual form of construction both the lead and return conductors are made of copper to minimise resistive loss, the outer return is braided for flexibility and the entire space in between is filled with highly insulating material such as polythene, polythene foam or polytetrafluoroethylene.
The whole coaxial arrangement is enclosed within an outer protective insulating jacket.
There are two great advantages associated with the coaxial geometry.
Because the magnetic fields due to the delivery and return currents cancel outside the braided outer conductor, there is no loss of signal power through electromagnetic radiation as a signal passes along the cable.
In addition, if the outer braid is earthed, as is common practice, the inner lead wire is electrostatically screened from interfering signals due to extraneous external sources.
Fluctuating fields cannot exist inside a fixed equipotential  surface (that of the braid here) on account of fluctuating external charge.
It will be appreciated that the conductors of a transmission line inevitably exhibit some series inductance and some capacitance between each other besides some series resistance and some conductance between each other.
Moreover, all the circuit properties of a line are distributed along its length, uniformly so in the ideal situation of a uniformly constructed line.
The distributed aspect contrasts sharply with the lumped nature of circuit representation of discrete components that has been adopted in all networks considered so far.
In view of the distributed nature of a transmission line, to determine its behaviour it will generally be necessary to consider the response of an infinitesimal element of it.
As will be confirmed by such analysis in a moment, the necessity to consider an element strictly depends on the length l of the line compared with the wavelength λ of the signal, for there is a phase difference  between the line's extremities.
If this phase difference is negligibly small, say, less than a few degrees, then the line may as well be represented in terms of lumped components corresponding to the total series and parallel impedances.
This means that, in the case of a signal of mains frequency, 50 Hz, for which the wavelength is  = 6000 km in air, the line has to exceed around 60 km in length before its distributed nature needs to be taken into account.
For signals of ultra-high radio frequency, on the other hand, say, 300 MHz, the air wavelength is 100 cm and the distributed nature of the line needs to be taken into account whenever its length exceeds around 1 cm.
Note in passing that the actual wavelength in a transmission line is a little less than that in air on account of the dielectric constant of the plastic insulating material but this does not significantly affect the foregoing order of magnitude estimates.
An important corollary of the present discussion is that circuit components of centimetre dimensions can properly be regarded as discrete until the frequency gets as high as about 300MHz (recall discussion of this topic near the beginning of section 4.3).
Consider now, with reference to figure 9.16(a), an elementary length dx of a transmission line.
Let the total series resistance and inductance of the lead and return per unit length be R and L respectively.
Similarly, let the total shunt conductance and capacitance between the lead and return per unit length be G and C respectively.
The shunt aspect of any element is illustrated in the blow-up of figure 9.16(b) and application of Kirchhoff's current law to this aspect gives  or   where I is the phasor representing series current in the lead or return and V the phasor representing potential difference between them, both at distance x along the line.
Note that the full derivative is appropriate here because I and V being phasors are independent of time.
Also, the change in the potential difference phasor V over the infinitesimal element has been neglected in arriving at equation (9.74) since it only gives rise to terms that are second order in smallness.
The series aspect of any element is illustrated in the blow-up of figure 9.16(c) and application of Kirchhoff's voltage law to this aspect gives  or  This time note that it has been possible to neglect the change in the current phasor I over the infinitesimal element as it only leads to terms that are second order in smallness.
Combining equations (9.74) and (9.75) yields  where the parameter γ is given by  and is known as the propagation constant for reasons that will emerge in a moment.
9.16 (a) Illustration of a transmission line connected between a load impedance Z L and a source represented by e.m.f.  in series with impedance Z S ,(b) blow-up of an element dx showing the shunt aspect and (c) blow-up of an element dx showing the series aspect.
The solutions of equations (9.76) are    the physical meaning of which becomes clear on appreciating that the propagation constant is complex, say, and that ,, and  are phasors relating to quantities of the form .
The first term in each equation represents a wave travelling in the positive x direction and the second term a similar wave travelling in the negative x direction.
Clearly α is the attenuation constant and β the phase constant related to the phase velocity .
Overall, equations (9.78) and (9.79) allow for a signal being fed in at one end of a transmission line, propagating along it and being partially reflected at the other end to give a wave travelling in the opposite direction.
The next important point to notice is that ,, and  are not independent.
Inserting equations (9.78) and (9.79) for I and V into equation (9.75) establishes that  Hence  where from equation (9.77) For a transmission line of infinite length, and  are zero in equations (9.78) and (9.79) respectively because it is physically impossible for I or V to be infinite as x goes to infinity.
Thus  From this it will be seen that the impedance between the lead and return at any point, including the input, along an infinite transmission line is the same, namely Z k .
Apparently Z k corresponds to the characteristic impedance concept already introduced in this chapter in connection with ladder filters.
Terminating a finite line of length I with this characteristic impedance forces  But from equations (9.78),(9.79) and (9.80) To satisfy equations (9.83),(9.84) and (9.85) simultaneously, the current  must be zero and so equation (9.82) applies again.
This means that, just as for a ladder filter, a finite transmission line terminated in the characteristic impedance Z k exhibits impedance Z k at all elements.
Because the elements are now infinitesimal, the impedance is everywhere Z k .
Resistive losses are often very small in transmission lines in comparison with corresponding reactive effects.
This is certainly the case for coaxial cables designed to carry radio-frequency signals (1–300 MHz).
Completely neglecting R compared with  and G compared with  in the interest of simplicity, it follows from equations (9.77) and (9.81) that   Observe that the characteristic impedance is purely resistive in the lossless approximation while the attenuation constant, α, is zero and the phase velocity,, is  which is independent of frequency so that dispersion is absent.
When present, dispersion causes unwanted distortion of propagating signals.
The properties just deduced are entirely those expected from the theory of section 9.2.
A lossless transmission line can be regarded as a multiple-section low-pass filter with sectional inductance and capacitance  and  respectively.
The multiple-section treatment yields a cut-off pulsatance of  which tends to infinity as dx tends to zero.
Consequently all frequencies are passed without attenuation and, from either equation (9.28) or equation (9.29), the characteristic impedance is .
The delay per section is from equation (9.33) equal to  so that the phase velocity is confirmed as .
Insertion of the theoretical expressions for L and C for a coaxial transmission line reveals that the phase velocity is alternatively  where Ε and µ are the permittivity and permeability of the medium between the lead and coaxial return.
This is precisely the velocity of light in the medium.
In the case of a lossless transmission line, equations (9.78) and (9.79) become, through incorporation of the results of equations (9.80),(9.86) and (9–87), When such a line is terminated by impedance Z L at  as depicted in figure 9.16(a)  Hence  or  It follows that the input impedance of a lossless transmission line of length l  terminated by impedance Z L is    or 
In discussing equation (9.91), firstly notice that, when the line is loaded by the characteristic impedance, that is, when , it reduces to just  as expected.
When the lossless line is short circuited so that the input impedance is apparently  Under open-circuit loading, that is, when , the input impedance becomes  Combining equations (9.92) and (9.93) gives   from which it is apparent that the values of Z k and β can be determined for a line from measurements of  and .
Equation (9.95) is in agreement with the earlier equations (9.71) of course.
Turning to the particular case of a quarter-wavelength line,, so that and equation (9.91) reduces to the simple result  Thus a quarter-wavelength line can easily be used to transform one impedance into another.
In particular, choice of the magnitude of the characteristic impedance  allows a quarter-wavelength line to match two impedances.
Notice that a short-circuited quarter-wavelength line provides open-circuit conditions at its input.
Correspondingly an open-circuited quarter-wavelength line provides short-circuit conditions at its input.
The former of these last two arrangements permits connections to lines without loading them.
Regarding reflection at the end of a transmission line, naturally the ratio of the potential difference of the immediate reflected wave to that of the  incident wave is called the reflection coefficient.
Equation (9.89) shows that the reflection coefficient of a lossless line is  or using equation (9.90) This result reveals that when the line is terminated in the characteristic impedance  there is no reflection.
Any other termination causes reflection.
One consequence of reflection is the existence of standing waves on the line.
In terms of the reflection coefficient Γ, equation (9.89) becomes  For a general load impedance Z L , the reflection coefficient Γ is complex and writing it as , the positional dependence of the magnitude of V is given by     This expression shows that the magnitude of V passes through maxima and minima as x varies.
The ratio S of the maximum to minimum of these standing waves, known as the voltage standing wave ratio, is evidently  Nodes, that is minima, of the standing wave occur when  where n is any integer.
However, and so nodes exist at positions given by  showing that adjacent nodes are separated by .
The impedance of a lossless transmission line may be neatly expressed in terms of the voltage standing wave ratio S at positions where there is a maximum or minimum of the voltage standing wave.
In terms of the reflection coefficient Γ, equation (9.88) becomes  Dividing the corresponding equation (9.99) for V by this equation and putting  as before shows that the impedance of the line at any  position x is expressible as  Since voltage nodes or minima occur when , equation (9.104) reveals that the impedance at such points is simply  Similarly, voltage peaks or maxima occur when  so that the impedance at these points is simply  Apparently the impedance is purely resistive at voltage maxima or minima and is respectively a maximum and minimum at such positions.
At some point between an adjacent maximum and minimum the real part of the impedance is  but there is an associated reactive component.
Now equations (9.92) and (9.93) show that an open or short-circuited line of length less than half a wavelength can provide any desired reactance or susceptance.
Thus by connecting a subsidiary section of open or short-circuited line of suitable length () across a main transmission line at a point where the conductance is , the associated susceptance or reactance can be neutralised.
The subsidiary section connected for such purpose is called a stub and the procedure renders the main line correctly terminated at the stubbing point.
Such impedance transformation is more flexible than that achieved through the use of quarter-wavelength sections.
In practice, signal attenuation in radio-frequency coaxial cables is caused by skin effect losses, which are proportional to the square-root of the frequency, and by dielectric losses, which are proportional to the frequency.
Temperature and cable ageing also affect the attenuation.
Dimensional or material irregularities incorporated during manufacture and badly assembled connectors all cause deviations in the impedance relative to the nominal characteristic impedance.
All such deviations, like incorrect termination, cause a portion of the radio-frequency signal to be reflected and impair the quality of the transmitted signal.
Signal analysis of nonlinear and active networks
10.1 Two-terminal nonlinear networks
The signal responses of two and four-terminal passive linear networks have been considered extensively in the previous six chapters.
Attention is now turned to deducing the signal responses of both active and passive nonlinear networks, a topic of great importance in view of the key roles that nonlinear devices play in electronics.
The topic has already been briefly broached, of course, in section 5.9, where certain consequences of nonlinearity were established by examining a few illustrative passive circuits.
At this juncture the objective is to treat the analysis of nonlinear circuits in a much wider context and in a much more general manner.
Graphical analysis of the response of any nonlinear network can be achieved through its terminal static characteristic or characteristics irrespective of the magnitudes of the signals involved.
This approach is, however, clearly most appropriate under large-signal conditions.
At the opposite extreme, whenever the signals in a nonlinear network are small enough, the network is effectively linear with respect to the signals so that the methods developed for linear network analysis may be applied with advantage.
Although maintenance of such small-signal conditions may appear somewhat restrictive, their occurrence is quite widespread.
Electronic systems are very often concerned with processing weak signals and sometimes the nonlinearity involved is sufficiently slight for quite large signals to qualify as small enough for the purpose of linear analysis.
10.1 (a) A circuit comprising a signal source capacitor coupled to a biased nonlinear network and (b) its graphical solution using load lines.
Explanation of the methods of large and small-signal analysis of nonlinear networks is best undertaken initially in terms of two-terminal networks.
Graphical determination of the steady-state response of a two-terminal nonlinear component to connection of a direct source has already been treated in section 3.10 where the concepts of load line and operating point were introduced.
With a two-terminal nonlinear network rather than a two-terminal nonlinear component, the same procedure applies except that the relevant static characteristic is that of the network.
Referring to figure 3.22(a), if the applied direct e.m.f.  is replaced by a signal e.m.f. , then the intercept of the load line on the potential V axis of figure 3.22(b) varies with time accordingly.
Thus the time dependences of the current I and potential difference V are given by the time dependence of the intersection of the load line with the characteristic, provided the frequency of the source is not so high that reactive effects render the static characteristic inappropriate.
With a signal e.m.f. included in series with the direct bias e.m.f. , a similar solution follows, the time-dependent intercept of the load line on the potential V axis now being equal to the total e.m.f.
Notice that the presence of the signal e.m.f. in both these cases causes the load line to move parallel to itself with time.
Another interesting and common circuit arrangement has a signal source , capacitor-coupled to a biased nonlinear network as shown in figure 10.1(a).
The capacitor segregates the direct bias circuit , so that the bias load line is as shown in figure 10.1(b) with intercept  on the V axis and slope .
Intersection of this load line with the characteristic occurs at some point O  representing the operating bias , of the nonlinear network.
The coupled signal causes the current I and potential difference V to fluctuate about the values  and  corresponding to the point O. Assuming that the capacitor exhibits negligible reactance at the operating frequency so that it couples the signal properly, Thévenin transformation reveals an effective signal circuit connected to the nonlinear network terminals comprising e.m.f.  in series with resistance .
Consequently the slope and intercept of the signal load line are as shown in the figure and, as  varies, the displacement of the intersection P of the signal load line with the characteristic gives the signal potential difference  and signal current .
In general, the waveform of the signal  will be completely different from that of the signal source e.m.f.
. However, if the amplitude of the signal source e.m.f.  becomes small enough for the excursion of the intersection point P to be over an effectively linear region of the characteristic, then the signals  and  will be proportional to .
In other words, the nonlinear network will respond linearly to the signal source.
Whatever the time dependences of the signals in a two-terminal nonlinear network, its terminal behaviour can be represented by  Moreover, the relationship between sufficiently small signals  and , denoted according to convention by lower-case letters i and v, is  or  where (,) is the bias operating point.
If the signals only vary slowly, and  respectively represent the small-signal conductance and resistance at the operating point and are given by the slope of the static characteristic and its inverse at the operating point.
When the terminal potential difference varies more rapidly, reactive effects arise.
With regard to sinusoidal signals that are small enough in amplitude for the network response to be effectively linear, whatever the frequency the result embodied in equations (10.2) is conveniently expressed in terms of phasors.
Thus writing the terminal small-signal current and potential difference phasors as i and v respectively  The terminal, small-signal complex admittance Y or impedance Z introduced here may be found at any particular frequency from measurements of the phasors i and v with the appropriate bias applied.
As equations (10.2) clearly demonstrate, the small-signal impedance of a nonlinear network depends on its operating bias.
Armed with the  appropriate value of the small-signal complex impedance, the signal response of a nonlinear network to any small input may be found in just the same way as the response of a linear network to an input of any magnitude.
As pointed out at the beginning of this section, some of the interesting responses that arise on applying somewhat larger sinusoidal e.m.f.s to nonlinear resistive circuits such that the signal behaviour is governed by the nonlinear relation  have been considered in section 5.9.
The reader is referred back to that section on this point but is again reminded that phasor and complex algebraic methods of linear circuit analysis are inapplicable to situations where an effective nonlinearity exists.
10.2 Four-terminal nonlinear networks
Many circuits and electronic systems process a signal between a pair of input terminals and a pair of output terminals as indicated in figure 10.2.
Such networks are aptly described as four-terminal networks.
Numerous four-terminal networks of the passive linear type have been considered in the earlier chapters, for example, transformers, attenuators, filters and phase-shift networks.
A prime active example of a nonlinear four-terminal network is an electronic amplifier which increases the power of a signal between its input and output terminals.
Three-terminal devices and networks often function as four-terminal networks with one terminal common between the input and output.
Nonlinear devices such as triode thermionic valves and various kinds of transistor belong to this latter category.
Now consider nonlinear four-terminal networks in general.
10.2 Four-terminal network.
A four-terminal network responds to external input circuit connections and drives external load circuits through the terminal input and output potential differences and currents V i , I i , V o and I o and its behaviour is specified by the interdependences of these terminal variables.
Once these dependences are determined, the response of the network to input and output connections can be deduced independently of any knowledge of the internal action or circuitry.
Interdependences of the terminal variables are  usually presented in the form of static characteristics.
Notice that a convention is normally followed in which the current at a terminal is regarded as positive if it flows into that terminal.
The labelling of the terminal variables I i and I o in figure 10.2 conforms with this convention.
Of the four terminal variables V i , I i , V o , I o , any two may be regarded as independent and the other two may then be determined or expressed in terms of them.
Plots of I o versus V o for sets of values of V i or I i are known appropriately as output characteristics.
Correspondingly, graphs of I i versus V i for sets of values of V o or I o are described as input characteristics.
Plots of an output terminal variable as a function of an input terminal variable or vice versa for various values of one of the other two variables are termed transfer or mutual characteristics.
10.3 Examples of static characteristics for the four-terminal active network formed by arranging a bipolar junction transistor in the common-emitter configuration;(a) output,(b) input,(c) forward transfer and (d) reverse transfer characteristics.
Note that  and .
Figure 10.3 shows examples of each type of static characteristic for the particularly important, four-terminal, nonlinear, active network of a three-terminal, N-P-N, bipolar, junction transistor operating in what is known as the common-emitter configuration.
Of the three terminals, collector, emitter and base, the emitter is common to the input and output in this configuration, with the output taken between the collector and emitter and the input applied between the base and emitter.
In labelling the axes of the characteristics, subscripts c, e and b have been used to denote the collector, emitter and base.
Thus, for example, and  respectively represent the  collector current and potential difference between the collector and emitter.
With respect to input and output notation,,, and .
For reasons that will emerge shortly, it is customary to present the output and reverse transfer characteristics for various base currents and the input and forward transfer characteristics for various potential differences between the collector and emitter.
Notice that the output depends on the input and vice versa.
Moreover, although the characteristics are markedly nonlinear overall, certain characteristics are virtually linear over substantial ranges.
10.4 (a) Simply biased, capacitor-coupled, common-emitter amplifier,(b) output characteristics of amplifying transistor with load lines corresponding to circuit (a) superimposed and (c) input characteristics of amplifying transistor also with load lines corresponding to circuit (a) superimposed.
Just as for two-terminal networks, the large-signal response of a four-terminal network may be determined by graphical analysis of the static characteristics.
Consider, for example, the simple capacitor-coupled common-emitter amplifier circuit of figure 10.4(a) in which the terminals of the standard symbol denoting the N-P-N transistor are labelled.
The bias  circuit, segregated by the coupling capacitors C c and C b , comprises just the e.m.f.  and resistors R b and R c .
Consequently the direct load lines for the output and input are as shown in figures 10.4(b) and (c) respectively.
To find the output operating point, the input bias current is needed.
Fortunately, the direct e.m.f.  is usually very large compared with the input potential difference  (; 0.6 V for a silicon transistor) so that to a fair approximation .
Whatever the magnitude of , because  only depends slightly on , without proper knowledge of  a better approximation to  can be obtained from intersections of the input load line with input characteristics for which .
The intersection of the appropriate output characteristic with the output load line then gives a good approximation to  which in turn leads to a better value of  from the input characteristics and input load line.
Such iteration is rapidly convergent and soon yields accurate values of both the input and output operating bias if needed.
The coupling capacitors are chosen to be of sufficiently large capacitance to present negligible reactance to signals over the operating bandwidth (frequency range) of the amplifier.
Thus, just as for a two-terminal network with capacitor-coupled signal source, the input-signal load line behaves as shown in figure 10.4(c), its changing intersection giving the input signal current .
Once more, this information in conjunction with the output characteristics and output-signal load line of figure 10.4(b) gives the output signal current  and potential difference .
If high accuracy is needed, another iterative process will take care of the effect of the output signal  on the input signal current and vice versa.
As with two-terminal networks, when the signals become sufficiently small, the response becomes linear and signal analysis is better conducted in terms of suitable small-signal parameters rather than graphically.
Choosing the input and output currents of the four-terminal network as independent variables, its behaviour can be represented by   and so sufficiently small signals ,, and  in the network are related by   Since the derivatives appearing in equations (10.5) have the dimensions of impedance, it is normal to put      for easy reference.
In terms of these Z-parameters, equations (10.5) are just   and, because of the linear relationship between small signals, the response to small sinusoidal signals is governed by corresponding phasor equations  
When the signals involved are of low-enough frequency for reactive and other frequency-dependent effects to be negligible, the Z-parameters are given by the slopes of appropriate static characteristics at the operating bias levels.
From equations (10.6), is the reciprocal of the slope of the input characteristic  versus  for constant output current  while  is the slope of the reverse transfer characteristic  versus  for constant input current .
Also, is the slope of the forward transfer characteristic  versus  for constant output current  and  is the reciprocal of the slope of the output characteristic  versus  for constant input current .
While the Z-parameters relevant to low-frequency operation may be obtained from static characteristics, they may be determined at any frequency by measuring certain small signals of the network under suitable open-circuit conditions.
In accordance with equations (10.8), is the small-signal, complex, input impedance ; when the output is open circuit to signals so that .
Similarly  is the ratio of the small, input, signal voltage to small, output, signal current when the input is open circuit to signals and  is the ratio of the small, output, signal voltage to small, input, signal current when the output is open circuit to signals.
Finally, is the small-signal, complex, output impedance  when the input is open circuit to signals.
An alternative choice of independent variables that is more convenient for certain types of four-terminal network is the input current  and output voltage .
In terms of these particular variables the behaviour is expressible as    and so sufficiently small signals are related by   where ;; Again, the small-signal linearity means that the small-signal sinusoidal response is governed by corresponding phasor equations   Symbols  are universally adopted to denote the differential parameters involved here because they have hybrid dimensions.
Such dimensions are, of course, a direct consequence of selecting hybrid independent variables and the differential parameters are appropriately known as hybrid or h-parameters.
Parameters  and  are in fact dimensionless while  and  respectively exhibit impedance and admittance dimensions.
At low-enough frequencies the parameters are again given by the slopes of characteristics.
For example, is the slope of the forward transfer characteristic  versus  at constant  and  is the slope of the output characteristic  versus  at constant input current .
To determine a set of h-parameters at any frequency from small-signal measurements demands both short-circuit and open-circuit signal terminations.
For instance, is the small-signal, complex, input impedance ; when the output is short circuited for signals so that .
On the other hand, is the reciprocal of the small-signal voltage gain  when the input is open circuit to signals so that .
Remember that, in general, the set of Z-parameters to be used in equations (10.7) or (10.8) and the set of h-parameters to be used in equations (10.10) or (10.12) will depend on the operating bias.
Just how small the signals must be for the Z and h-parameter equations to apply with constant sets of parameters depends on the particular case.
For a bipolar junction transistor, the output and current transfer characteristics are almost linear over substantial parts of the normal operating range but the input characteristics are markedly nonlinear (recall figure 10.3).
Thus the output signals can be quite large without violating the approximate applicability of the second of the two h-parameter equations with constant parameters.
However, the input signals must be extremely small for the first of these two equations to apply with constant parameters.
Signal measurements to determine the small-signal parameters of four-terminal networks must be executed under particular bias conditions implemented by direct circuits connected between the input terminals and between the output terminals.
The relative merits of measuring Z or h-parameters rests on which of the signal termination conditions is the easier to provide.
To effectively present open-circuit signal conditions between terminals requires the external impedance to be high compared with the internal impedance.
Thus the open-circuit conditions needed for Z-parameter determination are more easily arranged when the input and output impedance of the four-terminal network concerned are both low.
For effectively open-circuit operation the resistance of the bias circuit has to be high enough or a choke of high enough reactance has to be connected in series with it.
On the input side, the signal source can be introduced without disturbing the bias conditions or effectively open-circuit signal operation by simply connecting it in series with the bias circuit or by capacitor coupling it to the input through a high series resistance.
Measurement of h-parameters demands that the input terminals are effectively open circuit with respect to signals while the output terminals are effectively short circuited as far as signals are concerned.
The latter is readily achieved in practice without disturbing the bias arrangements by connecting a capacitor of large capacitance across the output terminals.
Four-terminal networks for which the input impedance is low and the output impedance is high are clearly well suited to the achievement of the termination conditions needed for h-parameter measurement.
A junction transistor in the common-base or common-emitter configuration is a good example of a network exhibiting such input and output impedances.
Since the small-signal behaviour of any four-terminal network is represented by equations (10.8) in terms of Z-parameters and by equations (10.12) in terms of h-parameters, the Z and h-parameters of a given four-terminal network are always interrelated.
Comparison of the second equation of the pair (10.8) with the second equation of the pair (10.12) immediately reveals that for a given network   Also, elimination of  between equations (10.12) and comparison of the resulting equation with the first equation of the pair (10.8) establishes that for a given network    It is a matter of simple algebraic manipulation to show that the inverse relations to equations (10.13) and (10.14) are ;;
Now consider the Z-parameters for the very simple passive linear T-network of figure 10.5(a).
Applying Kirchhoff's voltage law to the input and output meshes gives   Thus    The results obtained for this particular network are illustrative of the fact that  or  in all passive networks.
In active networks .
If a passive network is also symmetric, that is, if the same response is obtained with the output and input connections interchanged, also.
The simple network of figure 10.5(a) is symmetric of course if  and equations (10.16) confirm that  in this particular case.
Notice that from equations (10.13) and (10.14), is equivalent in terms of h-parameters to .
10.3 Small-signal equivalent circuits and analysis
10.5 (a) Passive linear T-network and (b) Z-parameter, small-signal, equivalent circuit.
Networks that exhibit the same terminal behaviour as some device, system or more complicated network are naturally known as equivalent circuits.
This section is concerned with the introduction and application of certain particularly useful types of equivalent circuit that display the same form of linear small-signal response as any nonlinear four-terminal network.
Consider first the four-terminal network shown in figure 10.5(b).
Application of Kirchhoff's voltage law to its input and output circuits  generates equations (10.8).
It therefore reproduces the linear small-signal response of any four-terminal network and is appropriately referred to as the Z-parameter equivalent circuit.
In accordance with Thévenin's theorem both the input and output circuits comprise a signal e.m.f. in series with an impedance.
However, beyond that, each signal e.m.f. is related to the signal current in the other circuit.
Especially note that the senses in which the signal e.m.f.s act are related to the senses of the input and output signal currents.
10.6 (a) General, small-signal, hybrid, equivalent circuit and (b) small-signal, low-frequency, equivalent circuit of a bipolar junction transistor connected in the common-emitter configuration to a source of e.m.f.
, R S and load resistance R L .
The four-terminal small-signal equivalent circuit based on the h-parameter relations (10.12) and therefore called the hybrid equivalent circuit is shown in figure 10.6(a).
Notice that here the input representation satisfies Thévenin's theorem while the output representation satisfies Norton's theorem.
Again the signal sources in the input and output circuits relate in both magnitude and sense of action to the output and input conditions respectively.
Labelling the parameters ,, and  is neater and, compared with matrix style subscripts, perhaps more directly infers the nature of each parameter in that i stands for input, r for reverse, f for forward and o for output.
It is left as a simple exercise to show that application of Kirchhoff's laws to the circuit does indeed yield relations (10.12).
Although through appropriate complex parameters the Z and h-parameter equivalent circuits can reproduce the small-signal sinusoidal response of any four-terminal network at any frequency, it is more usual to represent just the low-frequency behaviour by such an equivalent circuit  with real parameters.
Corresponding small-signal behaviour at high frequencies is then covered by adding reactive components to the equivalent circuit that directly relate to the particular physical mechanisms that cause the differing response at such frequencies.
To illustrate how equivalent circuits may be applied to analyse the small-signal responses of nonlinear systems, the low-frequency response of a basic junction transistor amplifier will now be examined.
The hybrid equivalent circuit is especially suited to representing the small-signal amplifying behaviour of a bipolar junction transistor since its parameters are easily determined for the most useful common-emitter configuration by appropriate small-signal measurements.
Sometimes the transistor is operated with advantage as an amplifying four-terminal network with the collector or base rather than emitter common between input and output, giving the so-called common-collector and common-base configurations.
Hybrid parameters relevant to the three configurations are distinguished by adding a second subscript so that, for example , the common-emitter h-parameters are denoted by ,, and .
Figure 10.6(b) shows the low-frequency, small-signal, equivalent circuit of a bipolar junction transistor connected in the common-emitter configuration to a source of e.m.f. , and a load resistance .
All the h-parameters are real here with  and  denoting resistances and  and  pure numbers.
Typical values for a low-power transistor would be ,, and .
Note that, due to the common connection of the emitter to input and output, there is now a common rail compared with figure 10.6(a).
Applying Kirchhoff's voltage and current laws respectively to the input and output circuits of figure 10.6(b) yields   However, and so from equation (10.18) the small-signal current gain between input and output is  while the input resistance presented to small signals is from equation (10.17) Making use of equation (10.19), the latter becomes   Proceeding further, the small-signal voltage gain between input and output is  and, on substituting for  and  from equations (10.19) and (10.20), it is seen that  To obtain an expression for the output resistance, observe that in the input circuit  Eliminating  through equation (10.18) gives  and rearranging this equation in the form  establishes that the output resistance is 
Notice that when , and, since  is very small,.
The negative sign here simply means that the signal voltage is inverted between the input and output, that is, a small sinusoidal signal voltage is shifted in phase by 180° between the input and output.
With a typical load resistance of a few kΟ, the magnitude of the signal voltage gain  is around 100.
Combined with the simultaneous signal current gain,, this means that a vast signal power gain  is achieved.
Attainment of such huge signal power gain is of the greatest electronic significance.
Whenever a signal experiences power gain, amplification is said to occur and the network achieving it is described as an amplifier.
Such networks are also said to be active in the spirit of the application of the term active at the end of chapter 2.
In simple language, the signal becomes vastly more powerful as it passes through this type of network.
Recall that although either signal voltage gain or signal current gain can be obtained separately with a transformer, there is always attenuation of signal power through one.
Signal voltage gain is always accompanied by greater signal current attenuation and vice versa with a transformer.
A casual glance at the equivalent circuit of figure 10.6(b) might suggest that the output resistance of the common-emitter amplifier is  and that  maximum signal power gain arises with this network when the load resistance  equals .
Neither of these conclusions is correct.
To begin with, the signal current source  in the output is only constant if the input signal current  is constant.
In general, as  varies, varies and so  changes because of the signal e.m.f.  in the input circuit.
Although with  held constant in some way (making  infinite in equation (10.22)), the output resistance is indeed  and maximum signal power is transferred between the output signal source and load when , the input signal power then depends on  through  because the latter affects the reverse transfer e.m.f.  and hence .
Again it is clear that maximum signal power gain does not correspond to .
In practice, because  is very small, the maximum signal-power-gain condition is not far removed from .
Furthermore, the availability of cheap transistors makes obtaining maximum power gain through each transistor rather unimportant in any case.
With respect to the input and output resistance of the common-emitter configuration, equations (10.20) and (10.22) reveal that, no matter what the magnitude of the load resistance  or source resistance , and .
Thus for a low-power transistor, is typically 3 kΟ and  is typically 50 kΟ.
10.7 The origin of the Miller effect.
A common cause of deterioration in the performance of amplifiers at high frequencies is the presence of capacitance between the output and input.
Such capacitance is, of course, kept to a minimum, but some is inevitable through the device involved in the amplification and due to the external wiring of the circuit.
The situation is depicted schematically in figure 10.7 where the triangular symbol represents the amplifier of gain, say -A, between the input and output terminals.
Extra input current drawn through the troublesome capacitance C amounts to  From the point of view of the input terminals, the presence of capacitance C  makes it appear that there is additional reactive impedance  bridging the input terminals.
In other words, an amplified version  of the capacitance C appears to exist across the input terminals.
This interesting phenomenon is known as the Miller effect.
At sufficiently high frequencies, the capacitive reactance becomes small enough to reduce the magnitude of the input signal  delivered from any practical source of finite internal impedance.
10.4 Feedback
An extremely valuable electronic technique is to return a fraction β of the output signal  of an amplifier of gain A to the input in such a way that the net input signal to the amplifier becomes  where  is the input signal intended for amplification.
Since  it follows that the overall gain under such feedback conditions is  Notice that, in this broad introductory description of the feedback technique, the symbol s has been deliberately introduced to signify any signal current or voltage.
The fedback gain represented by expression (10.26) is aptly referred to as the closed-loop gain and quite naturally corresponding descriptions open-loop gain and loop gain are often applied to the quantities A and  respectively.
While both β and A may be complex quantities in general, it will be assumed for the purposes of the present section that β and A are just positive or negative real quantities.
Positive or negative signs simply imply, of course, phase shifts of zero or 180° for sinusoidal signals through the feedback network or open-loop amplifier.
If the fedback signal opposes the input signal then the feedback is said to be negative.
In a similar way, if the fedback signal augments the input signal then the feedback is said to be positive.
Observe, however, that negative and positive feedback respectively correspond to the loop gain  being positive and negative in equation (10.26).
Of enormous significance is the fact that when the feedback is negative such that then  and the overall gain is virtually independent of A!
In other words, through the introduction of suitable negative feedback, amplification that is  virtually independent of the open-loop amplifier can be achieved.
In particular, the negative feedback technique enables very linear amplification to be attained despite substantial nonlinearity in the open-loop amplifier.
Moreover, through it, the same predictable behaviour can be obtained irrespective of the particular active device incorporated in the open-loop amplifier even when the characteristics of the devices concerned vary greatly.
Other important effects of negative feedback are changes in the input and output impedances and improvement of the frequency response (gain constant over a greater range of frequency).
It is, of course, vital to appreciate that the changes described occur at the expense of gain; the closed-loop gain under negative feedback is always less than the open-loop gain.
Provided that the negative feedback is implemented in a manner suited to a particular application, all the changes will normally be beneficial and the reduction in magnitude of gain worthwhile.
Deliberate, controlled positive feedback also has some application in connection with amplifiers but accidental, uncontrolled positive feedback is often troublesome in amplifiers leading to instability.
The main application of positive feedback is in the attainment of oscillation and switching.
Instability and oscillation will be discussed in sections 10.6 and 10.7.
Consider now the four basic circuit connections by means of which feedback is implemented.
These are shown in figure 10.8.
In each case the input and output impedances of the open-loop amplifier are represented by Z i and Z o respectively while its gain is denoted by a suitable parameter A. Observe that while the fedback signal is derived in parallel with the output in the circuits of figures 10.8(a) and (c), it is derived in series with the output in the circuits of figures 10.8(b) and (d).
In a similar way, the fedback signal is inserted in series with the input in the circuits of figures 10.8(a) and (b) but in parallel with the input in the circuits of figures 10.8(c) and (d).
Thus convenient descriptions of the basic arrangements of circuits 10.8(a),(b),(c) and (d) are respectively series-inserted, voltage-derived; series-inserted, current-derived; parallel-inserted, voltage-derived and parallel-inserted, current-derived feedback.
For easy reference these four forms of circuit may be referred to by the more economical descriptions series-voltage, series-current, shunt-voltage and shunt-current feedback respectively.
10.8 (a) Series-voltage,(b) series-current,(c) shunt-voltage and (d) shunt-current type of feedback network.
Analysing the series-voltage case first, the open-circuit and loaded voltage gains of the open-loop amplifier are defined as  and  respectively.
With reference to figure 10.8(a), application of Kirchhoff's voltage law to the input circuit yields  But   and so the closed-loop gain is  in accordance with equation (10.26).
The closed-loop input impedance is easily found as  To find the closed-loop output impedance, a source , is considered to be connected to the input in which case  Assuming for simplicity that the feedback network negligibly loads the output  and so  from which the closed-loop output impedance is   If further  as is often the case,
In the case of series-current feedback, it is convenient to describe the gain of the open-loop amplifier in terms of mutual conductance.
To this end the output of the open-loop amplifier is represented by a load-independent, signal, current source  in parallel with impedance Z o while the output signal current through the load and series-connected feedback network is written .
A complementary nomenclature expresses the series-inserted, fedback, signal voltage as , the subscript z on β indicating impedance dimensions.
With reference to figure 10.8(b), application of Kirchhoff's voltage law to the input circuit yields  and since  the closed-loop gain may be represented as  This time the closed-loop input impedance is  With regard to the output impedance, if  is the input impedance of the feedback network, Kirchhoff's laws applied to the output circuit give  Assuming that the impedance of a source of e.m.f.  connected to the input is negligible compared with , Kirchhoff's voltage law applied to the input circuit yields  Hence  from which the closed-loop output impedance is  Often the first term of this expression is negligible compared with the second in which case 
In shunt-voltage feedback it is convenient to express the gain of the open-loop amplifier in terms of the gain between output signal voltage and input signal current.
Writing this gain as  off load and  on load and representing the fedback signal current  as  because the feedback fraction has conductance dimensions, the situation is as depicted in figure  10.8(c).
Application of Kirchhoff's current law at the input gives  where  Hence the closed-loop gain can be expressed as  while the closed-loop input impedance is  With shunt-inserted feedback it is easier to find the output impedance when the input is connected to a source of infinite internal impedance, that is, to a constant-current source is so that .
Applying Kirchhoff's voltage law to the output circuit and assuming that the feedback network negligibly loads it  However, Kirchhoff's current law applied at the input gives  and so  from which the closed-loop output impedance is 
In the final case of shunt-current feedback it is helpful to adopt the Norton equivalent of the output circuit of the open-loop amplifier as shown in figure 10.8(d).
The short-circuit and generally loaded current gains of the open-loop amplifier are written  and .
It is left as an exercise to show that in terms of the overall notation of figure 10.8(d), the closed-loop current gain is  the closed-loop input impedance is  and that fed from a source of infinite internal impedance, the closed-loop output impedance is  neglecting loading of the output by the feedback network.
The analysis of this section culminating in equations (10.28)—(10.39) establishes that the magnitude of the effect of feedback always depends on the appropriate loop gain .
However, while the nature of the effect of feedback on gain is similar for each circuit arrangement, occurrence of a  decreased or increased gain simply depending on whether the feedback is negative or positive, the character of the effect of feedback on the input and output impedance depends on whether the relevant circuit connection is series or parallel as well as on whether the feedback is negative or positive.
Thus the effect on the input impedance depends on whether the feedback is series or parallel-inserted while the effect on the output impedance depends on whether the feedback is series or parallel-derived.
Negative parallel-derived, that is, voltage, feedback always lowers the output impedance while negative series-derived, that is , current, feedback raises it.
Negative series-inserted feedback always raises the input impedance while negative shunt-inserted feedback reduces it.
In each case, positive feedback has the opposite tendency but important behaviour of a very different nature arises if  becomes -1.
Discussion of this aspect will be pursued in the last two sections of this chapter as already promised.
For the moment, the enormous value of negative feedback will be illustrated by considering one fascinating area of application.
10.5 Operational amplifiers
Amplifiers that are well suited to performing mathematical operations on input signals when negative feedback is applied are termed operational amplifiers.
An ideal operational amplifier would at all frequencies exhibit infinite gain, no electrical noise, zero output impedance and infinite input impedance so that the mathematical operation would be completely determined by the feedback network.
Although real operational amplifiers can never provide such properties, a modern operational amplifier formed within a single chip of silicon comes impressively close to meeting the ideal specification.
To maintain high gain down to zero frequency, the amplifier is directly coupled and to overcome the resulting problem of distinguishing between real and pseudo signals, due to, for example , bias or thermal variations, differential circuit techniques are adopted.
The differential aspect means that an operational amplifier possesses a noninverting and an inverting input terminal, the sign of any signal applied between these terminals and the common rail being respectively preserved and reversed at the output.
In principle only the difference signal between the noninverting and inverting inputs is amplified; like input signals at the two inputs create cancelling signals at the output.
The degree of rejection of so-called common-mode signals is indicated by the common-mode rejection ratio which is just the ratio of the output signals obtained when a given input signal is applied first to one input only and then to both.
Thermal and bias variations tend to create equal signals at the two inputs and therefore negligible output.
High gain is achieved at low frequencies through incorporation of several differential stages of amplification.
However, stability demands that the gain falls off at high frequency (see next section).
Typically the gain becomes too small to be useful at frequencies above ∼100 kHz.
The input impedance also deteriorates at high frequencies.
In the following analysis of the behaviour of operational amplifiers subjected to various forms of negative feedback, the open-loop amplifier will be assumed effectively ideal for simplicity.
Clearly this analysis will only give the performance of corresponding practical circuits up to some critical frequency beyond which their response will be influenced by the significant departure of the operational amplifier from ideal behaviour.
10.9 (a) Inverting and (b) noninverting configuration of an operational amplifier.
Consider the basic so-called inverting and noninverting operational amplifier configurations featuring negative feedback that are depicted in figures 10.9(a) and (b) respectively.
Following standard practice the operational amplifier of gain A is denoted by a triangular symbol with the noninverting and inverting inputs marked by positive and negative signs respectively.
Applying Kirchhoff's current law to node S of the inverting configuration and assuming that the input impedance between the inverting and noninverting terminals of the operational amplifier is high enough to neglect current through them compared with that through Z 1 and Z 2 Consequently provided that A is large enough  With respect to the noninverting configuration of figure 10.9(b), neglecting the current through the inverting terminal of the operational amplifier again compared with that through Z 1 and Z 2 so that if A is large enough 
Notice that, while the theory of this section has been developed in terms of small signals  and , the fact that the input and output signals are related through the linear feedback components Z 1 and Z 2 means that the gains given by equations (10.40) and (10.41) apply to any magnitude of signal that does not swing beyond the fixed potentials of the bias supply.
Moreover, because the amplification is maintained down to zero frequency and the output can be nulled for zero input, the right-hand sides of equations (10.40) and (10.41) give the ratios between the total output and input potential differences.
In terms of the general feedback models of the preceding section, the inverting configuration is an example of shunt-voltage feedback while the noninverting configuration is an example of series-voltage feedback.
Applying equation (10.28) to the latter case with  gives equation (10.41) again since .
According to equation (10.34), for shunt-voltage feedback round an open-loop amplifier of high gain.
But, for the inverting configuration, and  so that equation (10.40) is again obtained.
When Z 1 and Z 2 are resistances R 1 and R 2 , both configurations execute a scaling operation between their input and output.
However, although the output impedances of both configurations are very low, the input impedance of the noninverting configuration is very high while the input impedance of the inverting configuration is virtually Z 1 since the signal  at S is negligible compared with .
The smallness of  causes the point S to be referred to as a virtual earth.
In view of the virtual earth property, other signal currents can be introduced at the node S without disturbing the signal current through Z 1 .
In particular the various signal sources in the circuit of figure 10.10(a) act independently and for an effectively ideal operational amplifier  That is, the circuit of figure 10.10(a)  fulfils the role of a scaling adder.
In the special case when   and the circuit becomes just an adder.
If, on the other hand,, the circuit performs as an averager.
The circuit of figure 10.10(b) is a version of the circuit of figure 10.9(b) in which  and .
Therefore, in accordance with equation (10.41), but, for the reasons already given above, the equality extends to  much larger signals and, when properly nulled  Naturally this particular circuit is known as a voltage follower.
The parallel-derived, series-inserted feedback with unity feedback fraction makes it a very valuable circuit that is much used as a buffer in electronics.
Its high input impedance means that it does not load a signal source which it copies at its output.
Because of the low output impedance, the output can deliver a substantial signal current without being altered.
10.10 (a) Scaling adder and (b) voltage follower.
10.11 (a) Operational amplifier integrator and (b) operational amplifier differentiator.
While the sinusoidal responses of the circuits of figures 10.11(a) and (b) are represented by equation (10.40) with , and , respectively, their behaviour is better appreciated by returning to fundamentals.
If in the circuit of figure 10.11(a) the input current of the operational amplifier is negligible compared with the current through resistance R, then  Now for a sinusoidal signal of pulsatance ο, the amplitude of  is ο times that of .
Therefore, as long as for the sinusoidal component of lowest frequency present in  the first term on the right-hand side of equation (10.45) can be neglected compared with the first term  on the left-hand side.
Consequently assuming  as usual and the circuit behaves as an integrator.
Notice that it is much easier to satisfy the condition,, for this active circuit to act as an integrator, than it is to satisfy the condition,, for the corresponding passive circuit of figure 4.11(b) to act as an integrator.
One problem with the circuit is that when the input is a low-frequency signal, the output amplitude becomes large and limiting may occur at the potentials of the bias supply.
Another problem is drift of the output, in the absence of an input , due to tiny bias currents at the input of the amplifier.
Neglecting the input current of the operational amplifier in the circuit of figure 10.11(b) compared with the current through resistance R  This time, if  and  for the sinusoidal component of highest frequency present in  the equation reduces to  Clearly the circuit of figure 10.1 l(b) acts as a differentiator when , which condition is much more easily satisfied than the condition  for the corresponding passive circuit of figure 4.11(a) to act as a differentiator.
Differentiators based on operational amplifiers do not suffer from drift.
However, because their gain is high at high frequencies they do tend to exhibit high-frequency instability.
A small capacitance in parallel with the feedback resistance R and a small resistance in series with the capacitance C helps to overcome this problem.
In general the circuits of figures 10.11(a) and (b) behave as low and high-pass filters respectively, the responses being given by equation (10.40) with the appropriate values of Z 1 and Z 2 inserted in each case.
Forming the impedances Z 1 and Z 2 of the inverting or noninverting configuration from more complicated combinations of reactances and resistances yields more intricate filtering.
For example, bridging the capacitor of the integrator with a resistor restricts the gain to some reasonable maximum at low frequencies and inclusion of a resistor in series with the capacitor maintains a finite rather than negligible gain at high frequencies.
10.6 Nyquist's criterion and oscillators
Sinusoidal signals passing through an open-loop amplifier or feedback network generally experience a phase shift as well as a change in amplitude.
Thus, as stressed near the beginning of section 10.4 when  introducing the topic of feedback, the open-loop gain and feedback fraction are frequency-dependent complex quantities in general.
Representing complex character by an asterisk, the closed-loop gain is expressible as  where  is the complex feedback fraction and  the complex open-loop gain.
In this notation positive feedback corresponds to  or  so that the gain is increased.
Especially significant is the fact that the closed-loop gain becomes infinite if  that is, if the loop gain  equals -1.
Under this condition a spurious infinitesimal input signal quickly grows to create a substantial periodic output signal.
Such electrical behaviour is described very appropriately as oscillation.
Amplifier circuits that oscillate parasitically through accidental positive feedback are said to be unstable and, unless their design can be modified to render them stable, are useless for amplification purposes.
Circuits which oscillate as a result of suitable positive feedback being applied deliberately round an open-loop amplifier are termed oscillators.
10.12 Nyquist plot of the loop gain  in the complex plane.
The critical condition regarding stability is embodied in Nyquist's criterion.
This states that a closed-loop amplifier is stable if, in a plot of its loop gain in the complex plane, the locus of the tip of the  vector does not enclose the coordinate point (-1, 0) as the frequency changes.
Conversely, for oscillation to occur, the plot of the loop gain must enclose the point (-1, 0) as the frequency changes.
The frequency scale is marked along the locus, of course.
With respect to the examples of Nyquist plots shown in figure 10.2 locus L passes through the point P = (-1, 0) and the corresponding circuit therefore oscillates at the frequency corresponding to this point.
Locus M corresponds to a circuit that exhibits real positive feedback at a frequency represented by the point Q but, as the length of OQ  is less than unity, oscillation cannot occur.
The circuit corresponding to locus N exhibits real positive feedback at a frequency corresponding to the point R where  and so oscillation can build up in amplitude in this circuit until some nonlinearity reduces the magnitude of  below unity.
If the condition for oscillation is met at only one frequency then essentially sinusoidal oscillation will occur at that frequency.
Clearly, the nearer the magnitude of the loop gain is to unity for small signals that grow in amplitude, the less will be the distortion introduced by the amplitude limiting nonlinearity.
A neat example of a sinusoidal oscillator is the Wien bridge oscillator shown in figure 10.13.
It is convenient to regard the open-loop amplifier of this oscillator as the noninverting combination of the operational amplifier and negative feedback resistors R 1 and R 2 , so that the open-loop gain is .
Positive feedback between the open-loop output and noninverting input is provided by the Wien band-pass filter comprising components C and R. The transfer function of this filter has already been derived in section 8.3 and reference to equation (8.22) together with equation (8.23) or figure 8.8 establishes that the modulus of the feedback fraction reaches a maximum of 3 and there is no phase shift when .
Consequently, adjustment of the negative feedback loop R 1 , R 2 such that the gain before positive feedback just exceeds three yields a close approximation to sinusoidal oscillation at frequency  As an alternative to determining the frequency of oscillation through R-C filters as in the Wien bridge oscillator, sinusoidal oscillators can be constructed using series or parallel-resonant L-C filters in conjunction with positive feedback.
10.13 Circuit diagram of a basic Wien bridge oscillator involving feedback round an operational amplifier.
In a different class of important circuits, positive feedback is applied over a band of frequencies from zero frequency upwards.
When such circuits  oscillate, the waveform is far from sinusoidal, often being approximately rectangular or square.
To understand the operation of these multivibrators or relaxation oscillators, consider first the comparator shown in figure 10.14(a) from which they can be derived.
In the comparator if the input potential difference  is greater than the derived potential difference  by any appreciable amount, the output is driven into negative saturation, that is,.
Complementarily, if  is slightly less than  the output is driven into positive saturation,.
Note that the saturation potential differences  are close to the supply e.m.f.s  biasing the operational amplifier.
In general terms the circuit acts as a threshold detector but if  it acts as a zero-crossing detector.
10.14 (a) Comparator,(b) Schmitt trigger,(c) astable multivibrator and (d) bistable multivibrator, each based on an operational amplifier.
Application of positive feedback to the comparator as shown in figure 10.14(b) creates a regenerative switch with hysteresis called the Schmitt trigger.
Using Kirchhoff's current law at the noninverting input of this trigger gives  so that Hence the output switches over to the opposite saturation state from positive and negative saturation when respectively   It is said that the circuit acts as a discriminator.
It can, for example, generate a very rectangular wave from a noisy fluctuating input signal so that one use is at the inputs of logic circuitry.
Notice that the presence of positive feedback makes the speed of switching independent of the rate of change of the input potential.
Another derivative of the comparator is the astable multivibrator shown in figure 10.14(c).
Suppose that the capacitor C in this circuit is initially uncharged and, at switch on of the bias supplies to the operational amplifier, the positive feedback drives the output into positive saturation,.
The positive feedback holds the output at  while capacitor C charges through resistor R until the potential at the inverting input exceeds that, at the noninverting input when the positive feedback causes the output to be driven into negative saturation,.
Capacitor C now charges in the opposite sense while the positive feedback holds the output at  until the potential at the inverting input falls below  causing the circuit output to switch back into positive saturation.
This cycle of events continually repeats to create an essentially rectangular or square-wave output signal, the frequency of which is controlled by the time constant RC.
Connecting a diode in parallel with the capacitor C converts the astable multivibrator into a monostable multivibrator with one stable state.
When the output is at that saturation level for which the diode is biased forward, the capacitor cannot charge and the output therefore remains at that saturation level.
An input pulse at the noninverting input of such a sign and amplitude as to reverse the input signal to the open-loop operational amplifier, will cause the output to switch over to the opposite saturation level.
Now the diode is reverse biased and the capacitor can charge until the feedback makes the output switch back to its original saturation level where it remains in the absence of a further trigger pulse.
Evidently, in response to a suitable input triggering pulse, a monostable multivibrator creates a rectangular output pulse of amplitude  and duration related to the time constant RC.
The bistable multivibrator or flip-flop shown in figure 10.14(d) has two stable states corresponding to the two possible saturated output levels  .
Normally the circuit exhibits a preference for one of them because of some asymmetry and is held in that state by the positive feedback network R 1 , R 2 in the absence of an input triggering signal.
Again an input trigger pulse of appropriate sign and amplitude will switch the circuit from one stable state to the other.
Two suitable trigger pulses take the output through a complete cycle and the relevance to binary counting is abundantly clear.
10.7 Amplifier instability and Bode diagrams
Turning to the question of accidental positive feedback in amplifiers, it is important to appreciate the difficulties encountered in trying to form stable amplifiers through the incorporation of negative feedback.
The network designed to provide negative feedback over the required operational frequency range can itself introduce positive feedback at other frequencies.
Such positive feedback can occur because the original design was not sufficiently careful or because of additional phase shifts that could not reasonably be foreseen.
Stray capacitance and inductance are especially troublesome with respect to stability at high frequencies where capacitive reactance is small and any mutual coupling induces relatively large e.m.f.s.
Another possible origin of positive feedback is the finite internal impedance of the bias supply.
How the negative-feedback loop can be designed to prevent its presence giving rise to instability will now be demonstrated in the context of operational amplifiers.
A convenient alternative presentation of the information inherent in a Nyquist plot is one in which the logarithm of the modulus of the loop gain,, and the phase shift, φ, round the loop are plotted separately as a function of the logarithm of the pulsatance,.
Figure 10.15 presents an example of such a Bode plot.
Recall that parasitic oscillation takes place if the magnitude of the loop gain is greater than or equal to unity at the frequency at which the phase shift becomes .
Thus, with reference to the figure, the degree of stability can be expressed as the gain margin,, which is a measure of the reduction in loop gain below unity at the frequency at which the phase shift is .
Alternatively, the degree of stability can be expressed by the phase margin,, which is the phase separation from  at the frequency at which the magnitude of the loop gain is unity.
While production of a Bode plot from separate knowledge of  and  can be awkward, linear approximations to  and  and to  and  are easily added to yield linear approximations to  and φ.
For many circuits simplification of the Bode plot is feasible because the dependences of gain and phase on frequency are not independent.
For   
10.15 Illustrative example of a Bode plot.
instance, in the frequency range where a first-order network gives a gain variation of ±6 dB per octave, the phase shift is .
In such cases the phase information is superfluous because it is implied in the plot of the amplitude behaviour and only the latter is required.
In particular, since oscillation is avoided if the phase shift is less than  at the frequency at which  falls to unity, it follows that a negative-feedback amplifier involving just first-order networks is stable if the slope of the plot of  versus  is less than 12dB per octave as the condition  is approached.
Now, if  and  are presented on the same plot, their separation is the required  as illustrated in figure 10.16(a) and where they cross corresponds to the crucial condition .
Hence amplifiers involving first-order networks are stable if the closing angle between plots of  and  is less than 12 dB per octave as crossover is approached.
When the negative feedback is large enough to satisfy  as is usually the case at least over the intended, operational frequency range, the closed-loop gain is  and .
In such cases stability just requires that the closed-loop gain approaches the open-loop gain at less than 12 dB per octave.
Of course, stability is alternatively assured if the closed and open-loop plots intersect at a frequency at which the open-loop gain is less than unity.
As an example of the use of a Bode plot to ensure the stability of a negative-feedback amplifier, consider the operational amplifier differentiator of figure 10.11(b).
If the plot of  representing the magnitude of the open-loop gain is as shown in figure 10.16(b), the  differentiator can be made stable if R and C are chosen so that the plot representing the magnitude of the closed-loop gain is like  in the same figure.
If R and C were to be chosen such that the closed-loop plot was like  approaching crossover with the falling portion of the  plot, the differentiator would be unstable.
As suggested in section 10.5, insertion of resistance  in series with the capacitance C limits the closed-loop gain at high frequencies that satisfy  and if the closed-loop Bode plot is like that of  with an approach to the open-loop plot at 6 dB per octave, the amplifier is likely to be stable.
For really reliable stability a design should have a rate of closure in the Bode plot of less than 6 dB per octave and all break points of the linear approximation should be at least a decade in frequency away from the intersection corresponding to .
Further addition of suitable capacitance in parallel with resistance R of figure 10.11(b), also as suggested in section 10.5, reduces the closure in the Bode plot to well below 6 dB per octave and thereby assures stability.
10.16 (a) Bode plots of open-loop gain and feedback fraction yielding Bode plot of loop gain.
(b) Bode plots in connection with the stability of an operational amplifier differentiator.
Fourier and Laplace transform techniques
11.1 Fourier analysis of periodic nonsinusoidal signals
Quite often the signal appearing in an electrical network is not sinusoidal.
Such a signal can arise as a result of a nonsinusoidal input signal being applied or through the response of a nonlinear component to a sinusoidal signal.
Examples of commonly occurring nonsinusoidal periodic waves in electrical networks include periodic square, ramp and exponentially decaying step functions and half and full-wave rectified sinewaves.
Fortunately, all such waves can be expressed as the sum of a constant term and an infinite set of harmonic sinewaves, the sinewave of lowest frequency in the harmonic set being known as the fundamental and having the same period as the original nonsinusoidal wave.
That is to say, any wave of period T can be represented by the Fourier series  where , n is any integer and a n and b n are constants.
Turning to the specific example of a continuous square wave of amplitude a and period T, it can be represented in terms of by  The validity of this particular harmonic representation is demonstrated in figure 11.1 where it is shown that summing the first three terms of expression (11.2) produces a waveform not far removed from square.
Addition of successively higher odd harmonics steepens the wings and reduces the amplitude of the fluctuations in between.
Notice that periodic waves that are even functions of time, that is, symmetric about the time origin, can be represented by a constant and just cosine waves, while waves that are odd functions of time, that is , reversed in sign about the time origin, can be represented by just sine waves.
Accordingly, the time origin of the  square wave has been taken at one of its leading edges in arriving at the representation given by expression (11.2).
A constant or direct component a only appears in a representation of a periodic wave if the positive and negative excursions are unbalanced so that the mean is nonzero.
11.1 Addition of the first three terms in the Fourier harmonic series representation of a square wave.
The usefulness of expressing a nonsinusoidal periodic voltage or current as an equivalent harmonic Fourier series has been alluded to on various occasions in the previous chapters.
Once the Fourier spectrum of a signal is known, the overall response of any linear circuit to it can be found readily by superposing the responses to each harmonic component.
Even when such a calculation is not followed through, the insight obtained from the Fourier series concept is often helpful.
Expressions for the amplitudes a n and b n of the harmonic components of any Fourier series are obtained by multiplying both sides of equation (11.1) by  or  and integrating over a complete period .
In the former case   When m = 0, all integrals on the right-hand side except the first are zero and therefore  This result just confirms, of course, that the steady component is the time  average of the signal.
When m = n, all integrals on the right-hand side of equation (11.3) are zero except that in which the integrand is , and since    it follows that for  to   Multiplication of equation (11.1) by  followed by integration over a period T similarly gives  When , all integrals on the right-hand side are zero except that in which the integrand is .
Hence for  to    
11.2 (a) Half-wave rectified sinewave and (b) its harmonic frequency spectrum.
Calculation of the Fourier coefficients a n and b n from equations (11.4)—(11.6) will now be illustrated by finding their values for a half-wave rectified sinewave of pulsatance ο and amplitude a.
It is convenient to make the wave an even function of time by choosing the time origin as shown in figure 11.2(a).
Thus the wave is zero during the time interval  — while it is  over the time intervals  — and  —.
From equation (11.4) it follows that       Also for  to , from equation (11.5) When n is odd other than unity,, since the sine function of an even number of  is zero.
The result for n = 1 is found by letting n tend to unity which shows that the second term in the expression is  while the first term is zero.
Hence  When n is even, a n is finite.
In particular and  Since all the b n coefficients are zero through having chosen the time origin so as to make the function even in time, the half-wave rectified sinewave of figure 11.2(a) is evidently equivalent to  In other words, the half-wave rectified sinewave shown in figure 11.2(a) is  equivalent to the harmonic spectrum of pure cosinewaves shown in figure 11.2 (b).
Every periodic wave is equivalent to some unique harmonic spectrum and it is suggested that the reader should draw the spectrum corresponding to a square wave as an exercise.
11.2 Fourier analysis of pulses
Besides being subjected to periodic signals, electrical networks often process nonperiodic signals or pulses.
For the purpose of Fourier analysis, such pulses can be regarded conveniently as periodic nonsinusoidal signals of infinite period or zero frequency.
As the frequency of a periodic nonsinusoidal signal becomes lower and lower, it can be seen with reference to figure 11.2(b) that its harmonic spectral components become bunched closer and closer together.
Clearly in the limit of the frequency going to zero, the frequency separation of the harmonic components becomes infinitesimal.
Thus it emerges that a pulse is equivalent to a continuous frequency spectrum of sinusoidal signals.
Before obtaining an expression for the continuous frequency spectrum corresponding to a nonperiodic signal, it is helpful to reformulate the theory of the previous section regarding the Fourier spectrum of a periodic signal in terms of complex exponential functions.
To begin with, the harmonic Fourier series of equation (11.1) is equivalent to  where n takes all integral values between  and ,, and .
Multiplying both sides of equation (11.8) by  and integrating over a period of the fundamental,, that is, from  to    Hence the equivalent expression to equations (11.4)—(11.6) giving the amplitudes of the harmonics of a Fourier series is 
Thinking, as already explained, of a nonperiodic signal as a periodic signal of zero frequency, it is apparent that its Fourier spectrum is given by the limit of equations (11.8) and (11.9) as the fundamental pulsatance ο goes  to zero, that is, as the period  goes to infinity.
Thus, with the help of a dummy variable t' for clarity, a nonperiodic signal may be represented by  Now the pulsatances of the nth and (n + 1) th harmonics are   and so  Hence   or  where, dropping the primes, since they are no longer necessary for clarity, The function G( ο); giving the amplitude distribution in the equivalent continuous spectrum of the nonperiodic function F(t) is said to be the Fourier transform of F(t).
In a similar way, F(t) may be described as the inverse Fourier transform of G( ο).;
Equation (11.11) will now be used to find the equivalent continuous spectrum of a rectangular pulse of height h and duration 1.
In this case, with reference to the depiction of the pulse in figure 11.3(a), Thus  Figure 11.3(b) presents the frequency spectrum of the pulse, that is, G( ο); as a function of ο, according to equation (11.12).
Negative pulsatances are to be regarded as arising from the mathematical processes and do not, of course, have physical significance.
Most of the spectral distribution is confined to the central maximum which has a positive upper frequency boundary of .
Thus an electronic system that passes signals at frequencies up to only modestly distorts a rectangular pulse of duration τ between its input and output.
To render any distortion of such a pulse trivial, the bandwidth of the electronic system handling it will have to be greater than or equal to .
It is clear that the narrower a pulse becomes, the greater the bandwidth a system must possess in order to handle it properly.
At the opposite extreme of a pulse of extremely long duration, the Fourier spectrum only contains extremely low frequencies.
Indeed, in the limit, when the duration becomes infinite, only the zero frequency or direct component exists.
11.3 (a) A rectangular pulse of amplitude h and duration τ and (b) its continuous Fourier spectrum.
Determination of the response of a four-terminal network to an input pulse by means of the Fourier transform technique generally involves a mathematically difficult inverse Fourier transformation.
However, the approach to such analysis will now be set out and the method illustrated by applying it to a trivial case for which the solution is already known from section 4.4.
Suppose that an input signal  with Fourier transform  is applied to a four-terminal network for which the transfer function is .
The output response to the input spectrum  is  where  Therefore the time dependence of the output signal is given by 
To see this method in action let the pulse of figure 11.3(a) be applied to the basic C-R low-pass filter of figure 4.11(b) with the capacitor initially uncharged.
In this case   and if the time constant RC also happens to equal the pulse duration τ  Thus  As anticipated, this integral is difficult to evaluate but it does reduce to the solution expected from chapter 4 of  when   when   when  Help with difficult inverse Fourier transforms is often available from special tables.
11.3 The Laplace transform
11.4 (a) The unit step function and (b) the exponentially decaying step function which becomes the unit step function in the limit as the positive real decay constant σ goes to zero.
A difficulty arises with the Fourier transform integral of equation (11.11) because it is indefinite for certain important time-dependent functions F(t) such as the unit step function shown in figure 11.4(a).
The problem can be overcome in the case of any straight step function by evaluating the Fourier transform of the corresponding exponentially decaying step function and then finding its limit as the rate of decay goes to zero.
The exponentially decaying step function corresponding to unit step function is depicted in figure 11.4(b).
It is defined by  when  and by  when , where a is real and positive.
Thus its Fourier transform is just   and F(t) is represented by  .
Both imaginary integrands in this expression are odd functions of ο and so the corresponding integrals between  and  are zero.
Clearly, unit step function is equivalent to  and involves just real integrals as would be expected.
Regarding the required limiting value of the first of these two integrals, when ο is sufficiently positive or negative to satisfy , that is, at all finite ο, the integrand is zero.
On the other hand, when ο is small enough to satisfy  and putting  the integral becomes  In spectral terms the first integral corresponds to a narrow line of infinite amplitude centred on zero frequency and it provides the mean level or direct component of the signal over all time,.
The limiting value of the second integral is, from equation (11.16), which represents the combined effect of a continuous spectrum of sinewaves with the amplitude inversely proportional to frequency.
Introducing the variable , it is seen that when  this second contribution is  but when  it is  To summarise, the foregoing analysis has established that the complete Fourier spectrum of a unit step function comprises a delta function centred on zero frequency that provides the mean direct level of one-half and a  continuous spectrum of sinewaves with amplitude  that provides the unit step about the mean.
Notice that effectively the spectrum of the unit step function has been derived by multiplying it by a factor  which makes the Fourier integral converge.
Fourier transform integrals of many other waveforms can also be rendered convergent by this means although it must be appreciated that the technique is not universally successful.
Naturally, the technique fails whenever the function grows too rapidly with time compared with the decay of .
The technique also fails if the signal concerned extends through all time because , where a is positive, grows without limit as the time t becomes more negative.
A corollary of this last point is that the technique is likely to succeed when the signal is switched on at some moment to which the time origin may be ascribed, the inference being that the signal is zero up to time .
Introducing the convergence factor , where , in the general case of a signal F(t) which is zero before time , leads to a modified transform  which it is customary to express in terms of the complex variable  as  This particular transform is known as the Laplace transform.
Just as the Fourier transform defined by equation (11.11) involves analysing the signal F(t) in terms of an infinite set of imaginary exponential terms , that is, in terms of infinite sets of sine and cosine waves, so the Laplace transform defined by equations (11.18) and (11.19) corresponds to analysing the signal in terms of an infinite set of functions of the form  where s is complex.
These complex functions represent growing and decaying sine and cosine waves and growing and decaying exponentials as well as just sine and cosine waves of constant amplitude.
Making the complex variable purely imaginary by putting  in the Laplace transform means that the signal is again being analysed into just sine and cosine waves.
11.4 Commonly required Laplace transforms
Let the unit step function for which the step occurs at time  as depicted in figure 11.4(a) be denoted by U(t).
Representing the operation of  Laplace transformation by , it immediately follows that   11.5 (a) Unit step function delayed by time  with respect to the origin of time,(b) unit pulse thought of as the difference between two unit step functions with differing delays  and ,(c) unit square wave thought of as a combination of unit step functions with delays that are multiples of half the period and (d) unit impulse function (see text).
Next consider a unit step function delayed by some time  as depicted in figure 11.5(a) and denote it by .
Thus  for  or   for  or  If t' represents the time with respect to a new origin taken at time  so that, then  and of course But   Hence  
From the point of view of finding its Laplace transform, a unit rectangular pulse may be conveniently regarded as the difference between two unit steps occurring at times  and  as shown in figure 11.5(b).
Thus unit rectangular pulse is  and its Laplace transform is  or  Treating the unit square-wave signal of figure 11.5(c) similarly, it is representable as  where T is the period.
Consequently its Laplace transform is  or  The unit impulse function  is infinite for an infinitesimal time as indicated in figure 11.5(d) and its integral over all time is unity.
Considering U(t) to be  in the time interval , yields  in the same time interval.
Hence the Laplace transform of unit impulse is  or   The Laplace transform of a delayed unit impulse is of course 
For a signal of the exponential form  from time  but zero before, the Laplace transform is  Provided α is either negative, or is positive and less than s, the integral is convergent and 
Considering  to be the imaginary part,, of , it immediately follows that  Similarly 
Other useful transforms are those of differential and integral functions.
In the former case  and assuming that  is zero when   With regard to the Laplace transform of an integral function   and assuming that when   the required transform is   Note that  is to be interpreted as the initial value of the integral quantity.
11.5 Inverse Laplace transforms
One source of inverse Laplace transforms is of course direct comparison with known Laplace transforms.
Expressing the operation of inverse Laplace transformation by , particularly useful results are     where the first three represent the inverse forms of equations (11.27),(11.28) and (11.29) obtained in the previous section.
The last result follows from  which becomes on substituting x for  
Where it is required to find the inverse Laplace transform of a function G(s) which may be expressed as the ratio of two polynomials, the problem is readily solved if the function can be split into partial fractions.
Such splitting is feasible if the polynomial on the numerator is of lower degree than that on the denominator.
Thus if  where the quantities a i and b i are constant coefficients then  or  where the numerators A i are constants.
Once the function G(s) is expressed in the form of equation (11.36), equation (11.32) can be used to find the  inverse Laplace transform of each partial fraction.
If the denominator of G(s) contains repeated factors, the partial fraction expansion is slightly modified.
Should, say, the factor () be repeated r times, then in terms of a set of constants B i the expansion is expressible as  Restoration to a common denominator and comparison of the coefficients of powers of s in the numerator with those in the original numerator determines the constants B i in equation (11.37) or A i in equation (11.36).
To illustrate the partial fraction method, suppose that the inverse Laplace transform of the simple function  is needed.
Splitting this function into its partial fractions  where  Now comparison of coefficients of s shows that , or , Hence  and application of equation (11.32) reveals that  In a similar way   from equations (11.32) and (11.35).
In general in network analysis, the parameters  appearing in the partial fraction representation of equation (11.36) are either real, as in the examples just considered, or occur as complex conjugate pairs.
Consider, for example, the Laplace transform  This function factorises into  where .
Thus, when , ο is real and complex conjugates appear in association with s in the denominators of the partial fractions.
The inverse Laplace transform of this last expression is  and so  if  where 
An alternative means of finding the constant coefficients A i in the partial fraction expansion of equation (11.36) emerges upon multiplying through that equation by the factor () to give  which reveals that  Although this relation is not immediately helpful because the factor () is zero when , it must be appreciated that G(s) here is the ratio,, of a numerator to denominator polynomial in s in which  where Q(s) is another polynomial in s.
Thus  But   Hence a useful alternative expression for the partial fraction coefficients is  in terms of which   and  The final result here is referred to as the Heavyside expansion theorem.
Applying it to the particular example, already considered, and  so that as before.
The Heavyside theorem also works when complex conjugate pairs of parameters  exist.
Consider the transform  Notice that the two numerators must also be complex conjugates in order for G(s) to be real and its inverse Laplace transform correspondingly a real function of time.
Both the real and imaginary coefficients A and A' in the partial fraction expansion are given by the Heavyside expansion theorem.
Thus  and   or  where .
When the denominator of G(s) contains repeated factors, the Heavyside expansion theorem must be modified.
Consider the transform  Multiplying through by  it will be appreciated that  Furthermore    and in general 
11.6 Network analysis by Laplace transformation
In section 11.3 it was stressed that the Laplace transform of a signal is pertinent to practical situations in which the signal is switched on at some instant.
Because of this the technique of Laplace transformation is relevant to deducing the transient responses of networks.
In fact, Laplace transformation of an entire equation that has been obtained by invoking one of Kirchhoff's laws converts it from integro-differential form into algebraic form.
Consequently the solution of awkward integro-differential equations, something of a stumbling block in the straightforward deduction of transient response, is avoided upon Laplace transformation, just as the solution of such equations is avoided in steady-state alternating current theory through the introduction of the phasor technique.
In this section the facility of the Laplace transformation technique will be demonstrated by applying it to find the transient response in a few illustrative cases.
To begin with, consider just a simple series circuit embracing total inductance L and resistance R into which a steady e.m.f.  is suddenly introduced at time .
Application of Kirchhoff's voltage law gives  for the current I. Taking the Laplace transformation with the help of relations (11.20) and (11.30) Hence, assuming that the current is zero up to time   and making the inverse Laplace transformation with the aid of relations (11.20) and (11.32) when , in accordance with equations (4.19) and (4.21) of section 4.3.
Next consider the situation when a switch is closed at time  to connect a steady e.m.f.  to a series circuit comprising just capacitance C and resistance R. In these circumstances Kirchhoff's voltage law gives   and taking the Laplace transform with the aid of relations (11.20) and (11.31), the corresponding equation  is obtained.
Therefore if there is no initial capacitive charging  and making the inverse transformation through relation (11.32) when , again in agreement with the theoretical result of section 4.3.
The two cases analysed so far have been chosen so as to clearly reveal, in a very simple context, the method of determining transient response through Laplace transformation.
While little benefit is gained from the transformation in these trivial cases, great benefit accrues from transformation in more difficult cases where there is a more complicated network or input stimulus.
Notice, too, that the Laplace transform of a relevant Kirchhoff equation can be written down immediately when there is no energy stored in the circuit initially.
In this respect equations (11.47) and (11.49) reveal that inductance L and capacitance C respectively act like reactances of  and  with respect to the transformed current  compared with reactances of  and  with respect to the actual current I.  
11.6 (a) Two-mesh circuit analysed with the aid of Laplace transformation in the text and (b) the solutions for I 2 and V as a function of time for certain network parameters.
Turning to the circuit shown in figure 11.6(a), the Laplace transformation of Kirchhoff's voltage law in the two meshes gives    assuming that the capacitors are initially uncharged.
Thus, writing C for the capacitance of C 1 in parallel with C 2 and eliminating  between the two equations  or    where , and  In terms of partial fractions it is convenient to express the Laplace transform of I 2 as  so that taking the inverse Laplace transformation  where  Note that  and  are both positive and real since  and  The latter result follows because  From equation (11.51) the time dependence of the output voltage is given by  But  when  assuming capacitor C 2 is uncharged initially.
Hence   and  Typical forms of response represented by equations (11.51) and (11.53) are shown in figure 11.6(b).
The Laplacian derivation of the response of a series resonant circuit comprising resistance R, inductance L and capacitance C, to an e.m.f.  suddenly applied at time , is worthy of comparison with the direct derivation of the same response carried out in section 4.5 through the solution of appropriate differential equations.
Kirchhoff's voltage law for the circuit means that  assuming that there is no initial stored energy, that is, that there is no current in the circuit or charge stored on the capacitor at time .
Hence  where  and it should be recognised that  represents the natural resonant pulsatance.
When , that is, when   where  is real.
Consequently, in accordance with equation (11.38), which agrees with the expression for current obtained from the earlier equation (4.47).
Equation (11.56) clearly represents damped oscillations at pulsatance .
However, if the Q of the circuit,, is large compared with ½, that is, if , then  is close to .
In the limit when R = 0, α is zero and undamped continuous oscillation takes place at the resonant pulsatance .
While the potential difference across the resistance R is just , that across the capacitance C is .
It is left as an exercise for the reader to show that  where , again in agreement with equation (4.47) obtained before.
Evidently, as pointed out in section 4.5, approaches  via damped oscillations which are often referred to as ringing.
When , that is, when   so that from equation (11.35) and   Assuming again that  when , the constant is .
Consequently  in accordance with equation (4.49) obtained before.
Oscillation is clearly just prevented and there is said to be critical damping (refer back to figure 4.15(b))
When  the quantity  becomes imaginary.
Putting   and making the inverse transformation via equation (11.32) or  Again there is an absence of oscillation and the circuit in this condition is said to be overdamped (refer back to figure 4.15(b) again).
The final circuit example that will be analysed in this section is that of an e.m.f.  being suddenly applied to a series resonant circuit at time .
With the usual notation, and taking both the current in the circuit and the charge associated with the capacitance to be initially zero as before, Kirchhoff's voltage law gives  Thus, making use of the Laplace transform of  given in equation (11.28), the Laplace transform of the current is   where again  and .
Expanding into partial fractions  and comparison of coefficients in the numerators establishes that     or, following suitable algebraic manipulation, that     Consequently  and taking the inverse transform with the help of equations (11.33),(11.34) and (11.38) where  as in the series, resonant, step response.
Evaluating the remaining inverse transform      where  Finally, substituting for A 1 leads to  or  The second term here gives the decaying transient which is oscillatory if  is real, that is, if , while the first term represents the steady-state response deduced way back in section 5.6.
11.7 Pole-zero plots in the complex s-plane
With regard to a Laplace transform function of the form  there are values of the complex frequency ,,…, which make it infinite and other values ,,…, which make it zero.
Such values are respectively known as the poles and zeros of the function and they obviously determine its essential form.
In network analysis, because G(s) relates to a signal that is a real function of time, the poles and zeros are  either real or they occur as complex conjugate pairs.
Their values may be depicted on an Argand diagram and it is normal practice to denote zeros by drawing circles and poles by marking crosses at relevant points.
Such diagrams are graphically referred to as s-plane diagrams.
Figure 11.7(a) shows the s-plane diagram of the function , by way of an example.
11.7 (a) The s-plane diagram of the function  and (b) visualisation of the Fourier spectrum of an exponentially decaying unit step function through the behaviour of the vector between the pole  and the point  in the s-plane.
To appreciate how an s-plane diagram can reveal the Fourier spectrum of a signal, first consider for simplicity the Laplace transform  corresponding to an exponentially decaying signal.
The Fourier spectrum G( ο); follows from replacing s by  so that for the particular signal under consideration .
Now, as depicted in figure 11.7(b),() is represented in the s-plane diagram by the vector which lies between the pole  on the real axis and the point  on the imaginary axis.
The length of this Argand vector representation of () gives the magnitude of the denominator of G( ο); while its orientation gives the corresponding phase.
Of course, the magnitude of G( ο); is just the reciprocal of the magnitude of () and the phase of G( ο); is just that of () but with opposite sign.
Thus by considering how the vector representation of () changes in the s-plane diagram as ο varies, the frequency dependences of both the magnitude and phase of G( ο); can be visualised.
For the case under consideration, as ο goes from zero to infinity, the frequency spectrum features a fall in amplitude from  to zero and a phase shift that changes from zero to -90°.
When there are several poles and zeros, the strength of the spectrum at a particular pulsatance ο is obtained by taking the product of the lengths of the various vectors drawn from the zeros to the point  on the imaginary axis and dividing this by the product of the lengths of the several vectors drawn from the poles to the same point on the imaginary axis.
Similarly the overall phase is the sum of the phases of the  vectors drawn from the zeros minus the sum of the phases of the vectors drawn from the poles.
Clearly a zero near the imaginary axis gives a minimum in the frequency spectrum at a pulsatance equal to the imaginary part of the zero point, while a pole close to the imaginary axis causes a similar maximum in the spectrum.
Evidently the locations of the poles and zeros in the s-plane determine which frequency ranges are most significant in the spectrum of the signal.
Notice that, since functions do not grow without limit in the real physical world, poles are restricted to the left-hand half of the s-plane in network analysis.
11.8 Plot in the s-plane of the poles of the Laplace transform of the current in a series resonant circuit subjected to a step e.m.f.
The poles,, of the Laplace transform of the current in a series resonant circuit subjected to a step e.m.f., which were deduced in the previous section, exhibit interesting behaviour.
With reference to figure 11.8, their distance along the negative real axis of an s-plane plot gives the degree of damping while their separation from the real axis in the imaginary direction constitutes the ringing pulsatance.
With the same notation as earlier, since , where  and , as α becomes larger corresponding to more damping, gets smaller and the poles converge on the real axis until when , which is the critically damped condition and the poles coincide on the real axis.
As α increases even further, the poles split again but now separate along the real axis which corresponds to the overdamped situation.
With no damping, the poles simply lie on the imaginary axis.
Finally, note that arranging the poles and zeros to be coincident makes the Laplace transform independent of s so that the network behaves as an attenuator.
Filter synthesis
12.1 Introduction
An ideal filter would perfectly transmit signals at all desired frequencies and completely reject them at all other frequencies.
In the particular case of an ideal low-pass filter, for example, the modulus of the transfer function,, would behave as shown in figure 12.1(a).
Up to a certain critical pulsatance , would be unity but above this pulsatance, would be zero.
Any practical filter can only approximate to such an ideal, of course.
In section 8.2 it was pointed out how  for a simple single-section L-R or C-R filter comprising just one reactive component only reaches a maximum rate of fall-off outside the pass band of 20 dB per decade of frequency compared with an infinite rate of fall-off for an ideal filter.
Remember that the significance of  is that it indicates the power in the load for a fixed amplitude of input signal.
Increasing the number of reactive components in the filter stage to two, as in the simple low-pass L-C filter of figure 8.7(a), causes  to reach a maximum rate of fall-off outside the pass band of 40 dB per decade of frequency.
With n reactive components in the filter stage, the maximum rate of fall-off of  outside the pass band becomes 20n dB per decade of frequency and the filter is accordingly said to be of nth order.
Further improvement in the sharpness of the cut-off response of practical filters can be achieved by cascading sections and the design of filters comprising multiple identical sections was considered at some length in chapter 9.
In particular, simplification of the design of such ladder filters through the technique of loading the last section with the characteristic impedance was discussed.
As pointed out before, this procedure ensures that every section is so loaded.
Consequently each identical section  responds in the same way and, if  is the transfer function of one section, the transfer function of the complete ladder of m sections is .
12.1 (a) Amplitude response of an ideal low-pass filter and (b) comparison of the amplitude responses of differing orders of Butterworth filter with the ideal.
Especially note that the forms of frequency dependence of the transfer functions of filters considered in previous sections were simply accepted for what they were.
In a radically different approach to filter design, a filter is synthesised so as to provide some preconceived functional form of frequency response that exhibits certain desirable features.
12.2 Butterworth filters
One way of describing the ideal low-pass response depicted in figure 12.1(a) is through the relation  This suggested to Butterworth that  where n is a large integer, ought to constitute a good response to synthesise from the point of view of creating high-performance low-pass filters.
Figure 12.1(b) displays the frequency response of  represented by equation (12.2).
A very valuable feature of this Butterworth response is its maximal initial flatness.
Notice that when , falls off as , that is, at a rate of 20n dB per decade of frequency.
Consequently the integer n is just the order of filter needed to synthesise the response of equation (12.2).
In order to gain an understanding of the synthesis procedure, consider first the elementary problem of designing a first-order Butterworth filter for which, from equation (12.2) or in terms of the parameter    It is required to find the physically realisable transfer function  which will yield the first-order, Butterworth, amplitude-squared response represented by equation (12.3) or (12.4).
This can be achieved through consideration of the poles of  although these poles cannot of course be reached through variation of the real pulsatance ο.
The general procedure for finding the physical function  corresponding to  is to reject poles of  in the positive half of the s-plane and construct a function that possesses just those poles of  that lie in the negative half of the s-plane.
In the present case the poles of  are from equation (12.4) simply  and rejecting the pole  the procedure for finding  yields  This being the physically realisable transfer function, in it is restricted to being imaginary and, checking back, when expression (12.6) is indeed the transfer function  in agreement with equation (12.3).
Having obtained the appropriate transfer function, the next step is to appreciate that first-order response is provided by a filter incorporating just one reactive component.
Noting that the transfer function relevant to some filtering inductance L in series with load resistance R is  it is seen that all that is needed to synthesise the transfer function of equation (12.6) is to introduce series inductance related to the load resistance R and desired critical pulsatance  by 
Turning to the design of a second-order Butterworth filter, according to equation (12.2) is required.
since the poles of this function are given by  where p is any integer including zero, which is equivalent to  rejecting poles in the positive half of the s-plane reveals that the transfer function to be provided is   or  Two reactive components are needed to achieve second-order response and so the relevant low-pass filter in conjunction with the load resistance R is as shown in figure 12.2(a).
The transfer function between the input and output of this network is   Consequently, second-order Butterworth response is achieved with it provided that 
12.2 (a) Second-order and (b) third-order low-pass filter.
For a third-order Butterworth filter  the poles of which are given by  where p is any integer including zero, or by  where p = 0, 1, 2.
Forming the transfer function incorporating just those poles in the negative half of the s-plane.
or  An appropriate form of third-order low-pass filter is displayed in figure 12.2(b).
With a little effort, the transfer function between its input and load  resistance R may be shown to be  Thus it performs as a third-order Butterworth filter when   
Often expressions for the values of the reactive components of Butterworth filters are quoted corresponding to unit load resistance and unit cut-off pulsatance.
Inspection of equations (12.8),(12.13),(12.14),(12.19),(12.20) and (12.21) reveals that inductances must be scaled by  and capacitances by  when the load resistance is R rather than unity and the cut-off pulsatance  rather than unity.
12.3 Chebyshev filters
A very useful alternative approximation to the ideal low-pass filter response has been devised by Chebyshev.
It is  where  is a small constant and  is a Chebyshev polynomial of order n defined by   In this definition of , is the cut-off pulsatance as before.
Particularly note that because  is expressible as a polynomial of order n in , is a polynomial of order n in .
Consequently, when , n, which means that the fall-off in response is once again 20n dB per decade of frequency and the order n corresponds to the order of practical filter needed to synthesise the Chebyshev response.
Now consider the nature of the Chebyshev response defined by equations (12.22) and (12.23) in more detail.
If , is simply , which is independent of frequency and therefore not of interest.
When   so that if the parameter  were to be unity, the response would be identical to first-order Butterworth.
With  small, decreases monotonically with ο, from unity when , passing through the value  when , as depicted in figure 12.3.
12.3 First, second and third-order Chebyshev responses compared with the third-order Butterworth and ideal low-pass responses.
When , if    and similarly if    Hence  which is  at  and at  and reaches a maximum of unity in between at , as shown in figure 12.3.
For  the fall-off in  with ο is more rapid than that for first order.
Similar analysis establishes that when   and since  it follows that the third-order response exhibits maxima of unity at  and at  and a minimum of  at .
Once again the third-order Chebyshev response is presented in figure 12.3.
From the responses just deduced for the first three Chebyshev orders it may be appreciated that, for all orders, the transfer function ripples between unity and  in the pass band.
Clearly higher-order filters have a steeper cut-off.
As already stated, well beyond cut-off their attenuation increases at a rate of 20n dB per decade of frequency.
The smaller , the smaller the ripple in the pass band but the less the attenuation in the stop band.
Compared with a Butterworth filter of the same order, the cut-off  may be steeper near the cut-off frequency but this is at the expense of slightly oscillating transmission in the pass band.
To create a Chebyshev filter, equation (12.22) shows that the poles of  must be arranged to satisfy  Making the helpful substitution  so that the required condition (12.27) becomes  or on equating real and imaginary parts   Since  cannot be zero, and  and it follows that the poles of  are given by equation (12.28) subject to the two conditions  where p is any integer (positive or negative) including zero, and  Of course, the poles can also be obtained through similar substitution for  rather than .
Having obtained the poles of , the relevant physical transfer function  is deduced by rejecting poles in the positive half of the s-plane and a network is synthesised so as to generate that transfer function.
To illustrate the synthesis procedure, consider the synthesis of a second-order Chebyshev network for which  as in the plots of figure 12.3.
In this case  and equation (12.29) gives  so that and .
Also from equation (12.30),.
The poles of  are therefore given by  and the appropriate transfer function is consequently  or  Comparison of this response with that of equation (12.12) establishes that the network of figure 12.2(a) achieves second-order Chebyshev response corresponding to  provided that and .
As an alternative to finding the transfer function (12.32) from the general results of equations (12.28),(12.29) and (12.30), it may be found from the  particular second-order form of  given in equation (12.25).
According to this particular result, the required poles of  are given by  or since   where  or 243.43°.
Hence   in agreement with equation (12.31) obtained before.
12.4 Synthesis of high-pass filters
The low-pass Butterworth and Chebyshev filter designs of the previous two sections can readily be adapted to create corresponding high-pass filters.
Firstly notice that replacing  by its inverse  in equation (12.2) or (12.23) converts the modelled pass approximation from low pass to high pass while maintaining the cut-off pulsatance at  C and the dependence of transmission on  just what it was on ο.
A filter to provide such high-pass transmission can again be synthesised.
Compared with a low-pass filter of given order and type, the corresponding high-pass version will feature a capacitor in place of each inductor and an inductor in place of each capacitor.
To discover how to find the component values of a synthesised high-pass filter, consider the particular case of a second-order type.
Let the prototype low-pass transfer function be  so that the planned high-pass transfer function is  where a and b are certain constants, for example for the Butterworth type, and  (see equation (12.11)).
The transfer function of the second-order low-pass filter shown in figure 12.2(a) is (see equation (12.12)) while that of the corresponding high-pass filter with capacitance C' in place of inductance L and inductance L' in place of capacitance C is    From equations (12.33) and (12.35) it is apparent that to synthesise the prototype low-pass response with unit cut-off pulsatance, the inductance L and capacitance C must satisfy   Equations (12.34) and (12.36) similarly show that to synthesise the planned high-pass response with cut-off pulsatance  the capacitance C' and inductance L' must satisfy   Combining equation (12.37) with equation (12.39) and equation (12.38) with equation (12.40) reveals that   Thus high-pass filters are easily derived from low-pass designs.
The results of equations (12.41) and (12.42) are particularly neatly expressed and generalised by saying that the reactances of a synthesised high-pass filter at the cut-off pulsatance must equal the reactances of their counterparts in the prototype low-pass filter at unit pulsatance.
In the case of a second-order filter, and .
12.5 Band filter synthesis
Consider Butterworth and Chebyshev low-pass filters designed to cut off at unit pulsatance, that is, at  or , theoretically, where the negative value does not have physical significance.
Suppose now that s is replaced by  in the transfer function.
This will cause the cut-off to be shifted to pulsatances that satisfy  or  which has solutions  Again the negative solutions are not physically meaningful of course.
The positive solutions represent the two cut-off pulsatances of a band-pass response.
This may be appreciated from the fact that when ο is the  geometric mean pulsatance , expression (12.43) is zero and therefore  is unity or near unity.
To synthesise such band-pass response, notice that if an inductance of the prototype low-pass filter with unit cut-off pulsatance was  then its reactance  must become  where   Thus it is clear that an inductance  of the low-pass prototype must be replaced by a series combination of an inductance  and capacitance , the values of which are given by equations (12.45) and (12.46).
In a similar way, the reactance  of a capacitance  of the prototype low-pass filter must be replaced by  which is of the form  where   Apparently, to synthesise the band-pass response, any capacitance  of the prototype must be replaced by capacitance  in parallel with inductance , the values of which are given by equations (12.47) and (12.48).
Note that the combinations , and , have the same resonant pulsatance  which is the geometric mean of the pass-band limits  and .
To further illustrate synthesis of a band-pass filter, consider development of the second-order low-pass filter of figure 12.2(a) into the band-pass form of figure 12.4.
It is abundantly clear that the network of figure 12.4 passes signals in the vicinity of the resonant frequencies of the series and parallel LC combinations but rejects at both low and high frequencies.
The transfer function of the low-pass prototype is given by equation (12.12) and substituting expression (12.43) for s generates the modified transfer function  On the other hand, direct analysis of the network of figure (12.4) yields  or   which is of course of the same form.
Comparison of coefficients of , s, and  in the denominators of the two expressions for  confirms equations (12.45)—(12.48).
12.4 Band-pass filter.
Replacing s by  in the low-pass transfer function creates a band-stop form of response with cut-off pulsatances satisfying  when the low-pass cut-off occurs at unit pulsatance.
The physical cut-off pulsatances are once again and  but, to synthesise the band-stop response, inductive reactance  in the low-pass prototype must become reactance  This represents the reactance of inductance  in parallel with capacitance  where   Similarly, capacitive reactance  in the prototype becomes reactance  which represents the reactance of inductance  in series with capacitance  where  