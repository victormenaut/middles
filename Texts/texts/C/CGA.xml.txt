

Hypertext writing and document reuse: the role of a semantic net
ROY RADA 
SUMMARY
When document components are classified and then recombined during document reuse, a semantic net may serve as the classification language.
A theory of analogical inheritance, applied to this semantic net, guides the reorganization of document components.
Authors index paragraphs from various sources with node-link-node triples from a semantic net and then use programs to traverse the semantic net and generate various outlines.
The program examines node and link names in deciding which path to take.
This paper describes how these techniques helped the author to reuse parts of an existing book to write a new one.
INTRODUCTION
One of the most salient differences between text and hypertext is the abstraction of the text as a network.
This paper explores the utility of an approach in which the network is viewed as a semantic net and in which traversals of the network produce new documents.
In particular, this approach is applied to the problem of document reuse.
Computer writing tools should be tuned to certain users and tasks.
The basic strategy of reusing information to create new information is well accepted and has been applied to writing.
In order to successfully reuse document material, some kind of classification of existing material is vital.
Secondary information services typically index a document into terms of an indexing language which can be considered a semantic net.
One hypothesis of this paper is that a semantic net can be a useful representation in document reuse.
Secondary information services answer queries by returning a set of document citations.
For document reuse something more particular is wanted.
Namely, the retrieved material must be organized into a sequential, cohesive document.
The second hypothesis of this paper is that patterns of regularity in the semantic net can be exploited so as to generate meaningful, linear documents.
REPRESENTATION
The notion of a network is fundamental to hypertext.
Since the first half of the century, people have dreamed of hypertext systems, but the best representation for hypertext remains unclear.
Some researchers focus on a logic-based approach to hypertext, some build a hypertext model on top of Petri net formalisms, but the basic structure remains that of nodes and links with attributes.
Semantic net infrastructure
A semantic network is a graph where natural language terms have been used to label the nodes and links.
In a semantic network concepts are represented by terms and their relationships to other terms in the network.
For example, to place the concept ‘hypertext’ in a semantic net, one might begin by saying that it contains documents, runs on computers, and serves users.
The link types are ‘contains’, ‘runs on’, and ‘serves’; the nodes are ‘hypertext’, ‘documents’, ‘computers’, and ‘users’(see Figure 1).
A semantic net lends itself to graphic display, and its meaning tends to be intuitively, if not formally, clear.
Above: Sketch of independent semantic net a level above the document itself.
A Text Block is associated with the link which connects the two nodes.
Below: Sketch of semantic net embedded within the document.
A Text Block is associated with the node ‘virus’ which is also a word embedded within another Text Block.
Figure 2.
Independent versus embedded semantic net
Some semantic links manifest inheritance.
For instance, if the network connects the node ‘student’ to the node ‘person’with the link ‘is a’, then one can infer that the properties of ‘student’are inherited from those of ‘person’.
Inheritance conveys transitivity.
If a person is an animal, then by transitivity a student is an animal.
The semantic net of hypertext may be independent or embedded .
In the ‘independent’ case the nodes and links are tagged with terms.
The nodes or links point to text blocks, but the semantic net can be seen without necessarily seeing the text blocks.
In the ‘embedded’ case a text block is at the end of a link (see Figure 2).
In traversing an embedded semantic net hypertext, the user has to visit a text block.
This analysis can be significantly extended as any quantity of information may be identified as a node.
Translation into a database management system
The independent semantic net representation was implemented in a relational database system, as a book was imported into the database.
Two classes of students at George Washington University over two semesters worked with the database and augmented the semantic net on-line.
A computer program was developed to read a book (called Machine Learning: Expert Systems and Information Retrieval ), exploit the markup language (the Unix Document Workbench), and translate the book into a relational database management system (SQL/DS).
One relation in the database was for paragraphs, and another was for a semantic net that included the book's outline.
The semantic net supported hierarchical and non-hierarchical relations between terms.
Each relation had two fields, as in Hierarchy (term&sub1;, term&sub2;) Another relation, the Point relation, associated a paragraph with a term and took the form Point (term, unique identifier).
Through a combined view of the Hierarchy and Point relations, a user could follow a network term to the text about that term.
An interface program helped students add paragraphs to the database and manipulate the semantic net.
The students had difficulty augmenting the semantic net.
In particular the meaning of a term or link in the semantic net was often unclear to them.
To provide further guidance a Definition Table was created.
For each term, students were asked to provide a definition, an example of its use, or explanations of the term's relations to other terms.
For example, the term ‘expert system’ was described in the Definition Table with hierarchically and non-hierarchically related terms (see Figure 3).
expert system
Hierarchically more general term is artificial intelligence (see paragraph 127 for text that discusses artificial intelligence and expert systems).
Non-hierarchically related term is machine learning (see paragraph 456 about acquiring rules through interaction with user).
Figure 3.
The Definition Table in the hypertext database contained a free-text field similar to this one (the authentic version is not worded this carefully)
The ‘quality’ of the links which had been created in the semantic net were compared for the situation in which no Definition Table existed and for the situation in which a Definition Table did exist.
This comparison was made by two scientists studying the node-link-node triples and assigning a quality score to each triple.
The use of the Definition Table led to better node-link-node triples.
Paragraphs on edges
In the next phase of the investigation, paragraphs were extracted from many other documents and indexed by node-link-node triples.
In this way the indexed paragraph provides an example or definition of what the node-link-node triple means.
A node-link-node triple is a richer index for a paragraph than just a node.
By placing paragraphs on the links, one can say that a paragraph is about a certain relation between two nodes — not just about a node.
Arbitrary link or relation names were allowed — not just hierarchical and non-hierarchical relations.
The semantic net model may be seen as a set of link objects.
Each link object specifies some source node, link type, target node, pointers to paragraphs, and perhaps other attributes.
A group of link objects with the same source node form a frame (see Figure 4).
Figure 4.
Graphical and frame representation are given side-by-side to show the frame representation
Models of the domain
In the top-down approach to indexing, the semantic net is first elaborated and then the paragraphs are indexed.
In the bottom-up approach the paragraphs are first collected, and the semantic net is built as the paragraphs are indexed.
The better approach is a combination of the top-down and the bottom-up approach.
To build and maintain a semantic net, indexing of paragraphs and semantic net construction go hand-in-hand.
If a paragraph is to be indexed but no component of the semantic net relates to that paragraph, then the semantic net is augmented.
The purpose of the semantic net is to give people an overview of or handle on the content of the text.
To this end, the semantic net must itself convey a meaningful model of the world or must somehow present patterns to the user that are easily understood.
The user must be able to predict from one part of the semantic net what is likely to be in another, analogous part of the semantic net.
In studies of the indexing languages of secondary information services, patterns of analogical inheritance have been observed.
Analogical inheritance extends the notion of inheritance by saying that the attributes of a node should be related to the attributes of its parent in some systematic way.
If the attributes were the same, then simple inheritance would attain.
A semantic net may be formally represented as a directed, labeled graph with nodes  and links  where  The predicate  is true, if and only if  and  are connected by a path  of labels.
Analogical inheritance on paths  is present to the extent that  is true.
If two nodes are related by f and are source nodes for the path of labels h , then the target nodes for the path h should be related by g .
Three examples of fuzzy analogical inheritance can be seen in the outline of Figure 5.
Manifested here are three examples of analogical inheritance along the f, g, and h functions:
Figure 5.
‘Outline’: example of an outline viewed as a semantic net’
Analogical inheritance can be used to guide the augmentation of a semantic net.
For instance, if the existing semantic net notes that ‘hypertext includes text’, ‘hypertext has principles’, and ‘principles include database principles’, then an analogical inheritance guide might note that the addition of ‘text has database principles’ would increase the amount of analogical inheritance or regularity in the network.
EXPERIENCES WITH SEMANTIC NET CONTENT
The paragraphs being added to the database became part of a new book on hypertext entitled Hypertext: from Text to Expertext .
When either looking for blocks of text from other documents to include in the new document database or when considering new additions to the semantic net itself, preference was given to additions that would make the semantic net manifest more analogical inheritance.
One of the difficulties in applying the structuring principle was the diversity of disconnected link and node types present in the semantic net.
To this end efforts were made to control this diversity.
From Roget's Thesaurus 
One source of structuring information is Roget's Thesaurus .
Roget's contains over 1000 word types, and for each type different forms of speech and numerous synonyms are offered.
Furthermore, the thesaurus embeds each word type in a hierarchy.
Imagine that one wants to say that ‘hypertext includes text’ but is uncertain about the wording.
One can go to Roget's index and under the word ‘include’ find an alphabetically sorted list of words that are alternatives to ‘include’.
The words listed under ‘include’ in Figure 6 are distributed in Roget's hierarchy as illustrated in Figure 7.
With this hierarchy one can determine commonalities among terms.
If, for instance, one wanted a word related to ‘2.
II.C.236’, one could move upward in the classification to ‘2.
II.C.’, and then look at the descendants of that category; or go still higher to ‘2.
II.’.
Figure 6.
The index at the back of Roget's lists over 1000 words, each of which has indented underneath it another list of words.
The number after a word refers to its location in the hierarchy of words which Roget's contains
Figure 7.
Roget's hierarchy is meant to cover the universe of word types.
A small extract from the hierarchy is shown here so that one can see the path from the root of the hierarchy to each of the words in Figure 6
In one phase of semantic net development, every new link label was also created as a node label.
These node labels were further connected in a hierarchy that duplicated that in Roget's .
In this way the author can create any link labels but still look for patterns of analogical inheritance by mapping the link into similar links according to the hierarchy in Roget's .
While several person-months were invested in the development of a semantic net whose links were labeled with terms from Roget's , the profit from this investment was not substantial.
This poor performance may be due to a paucity of tools.
For one, the researcher did not have Roget's on-line and needed to manually enter into the computer the relevant relations from Roget's .
For another, the computer programs which analyze semantic nets for patterns of inheritance were not usable, while this version of the semantic net was being developed.
Detecting patterns in a large, complex semantic net is difficult to do without the aid of computer programs.
Patterns in names
In other exercises, the goal was to reduce the variety of link types so that visual inspection of the semantic net would more readily lead to recognition of repeating patterns.
In one version of the semantic net the most common links were ‘include’, ‘use’, and ‘has’, in that order (see Figure 8).
These link types do not correspond to those developed either for other subject areas, like toxicology, or for other activities, such as discussion.
In the area of toxicology, a hypertext has been prepared, and each toxin is described along with the following attributes: common name, molecular weight, molecular formula, characteristics, source, and toxicity.
For ‘discussion’ systems, certain node and link types may be identified; for instance, an ‘Argument’node may have a ‘respond’link to an ‘Issue’node.
The work with the Hypertext book did not necessarily identify a set of link types that were either generic to producing a book or to the topic of hypertext.
The set of relevant link types will depend on the model of the domain to be conveyed.
Figure 8.
Only 12 types of links were used in the semantic net that supported the final draft of the Hypertext book.
The complete listing of linknames and their frequency is shown here
The frequency distribution of source and target node names served as a guide to augmentation of the paragraph database and of the semantic net.
As a rule of thumb no source node name should occur in just one link object nor in many link objects.
This follows the traditional wisdom that a menu of about 4 to 13 items is most manageable by people.
A survey of node names revealed about 200 unique source node names (see Figure 9).
The average frequency of occurrence was about 3, and the most frequently repeated name was ‘microtext exercises’ which occurred 12 times.
(‘Microtext’ is a neologism which means ‘small-volume hypertext’.)
An analysis of the target node names revealed about 600 unique target node names with most occurring just once (see Figure 10).
The average frequency of occurrence of a source node is greater than that of a target node, and a source node always has more than one target.
The names of nodes revealed an interesting pattern.
Several ‘source node names’ were prefixed to other ‘source node names’.
For instance, the semantic net contained a source node called ‘Microtext’ and another called ‘Macrotext’.
(‘Macrotext’ is a neologism for ‘large-volume hypertext.)
For each corresponding frame, most of the ‘target node names’ were prefixed by the ‘source node name’(see Figure 11).
Such patterns, once detected, suggest guidelines for other parts of the semantic net.
For instance, sibling nodes (nodes which have some hierarchical relation to the same node) might be expected to have the same pattern of ‘target node names’.
By example, source nodes that are siblings to Microtext and Macrotext might be expected to have target nodes with suffixes including ‘history’, ‘principles’, and ‘systems’, and exactly this happened.
The nodes ‘grouptext’ and ‘expertext’were siblings to ‘microtext’and ‘macrotext’and had frame representations that repeated the patterns of ‘history’, ‘principles’, and ‘systems’.
Figure 9.
An excerpt from the list of source node names which shows some of the most and least frequent names
Figure 10.
An excerpt from the list of target node names which shows some of the most and least frequent names
Figure 11.
Source and target node names for frames for Microtext and Macrotext
LINEARIZATION
The success of the document reuse was measured by its support for the production of a new book entitled Hypertext .
While the new book can be viewed as a hypertext because it has a semantic net to which paragraphs are attached, print on paper remains the dominant medium for the delivery of books, and Hypertext has also been generated in paper, linear form.
The value of printing a linear document from a database has been appreciated for a long time.
The FRESS system of the 1970s supported printing from a document database.
The commercial hypertext systems KMS, Guide, and Hyperties all support print features.
This paper presents a method for automatically generating a document by a traversal of the semantic net.
The method has been automated because
the semantic net is so large that to traverse it by hand would be laborious, and
in the process of revision one wants to see the semantic net and see the linear form repeatedly.
A program allows one to frequently modify the hypertext database and test its consequences for the linear form.
Depth-first traversal
The obvious methods of traversing a graph are breadth-first and depth-first.
A breadth-first traversal goes from one node to all the nodes directly connected to it and then resumes the process at one of those connected nodes.
A depth-first traversal goes from a node to one of the nodes directly connected to it and then immediately continues by visiting a node that is connected to the last visited node (see Figure 12).
In these traversals, which target node to visit next of those in one frame and not yet visited is determined randomly.
Since this random approach may be inadequate, the Link Objects have an attribute called ‘Order’.
With the numeric value assigned to this ‘order’ attribute, the traversal algorithm decides which target to visit next.
The traversal algorithm also allows users to specify link-type priorities.
The traversal algorithm will visit the link objects in a frame in the order of their priorities.
No node is visited twice.
A paragraph is associated with each node-link-node; for instance, paragraph p4 is about ‘text includes history’.
The breadth-first traversal from ‘hypertext’ visits the nodes text, microtext, macrotext, history, principles, and systems, in that order.
The depth-first traversal goes from ‘hypertext’ to text, history, principles, systems, microtext, and macrotext, in that order.
Figure 12.
Portion of semantic net with attached paragraph pointers
The first program for traversing the semantic net was a combined breadth-first, depth-first one.
This combined traversal first collected all the paragraphs from links emanating from a node (this is the breadth-first part) and then chose the next node by a depth-first principle.
From each selected node, the process repeated itself; namely, all paragraphs on links from that node were printed, and then the next ‘depth-first’ node was visited.
For instance, while traversing the semantic net in Figure 12, the breadth-depth traversal prints paragraphs in the order p1, p2, p3, p4, p5, p6.
This combined depth—breadth approach has the advantage of giving the reader an overview of what is to come, but the disadvantage of an uncomfortable jump.
This jump occurs after the paragraph corresponding to the last link from a node and before the first paragraph associated with the next node.
In the preceding example, by seeing p1, p2, and p3 the reader gets a good overview of hypertext.
However, when p4 is reached the reader has just finished reading about some other aspect of hypertext than text.
The paragraph p1 would be the natural one to be read before reading p4.
To address this difficulty the algorithm was changed to a depth-first one.
The depth-first traversal has, of course, its own shortcomings.
In the depth-first traversal for the above example the paragraphs would appear in the order p1, p4, p5, p6, p2, p3.
This ordering is fine for the progression from p1 to p4 to p5 to p6.
But the jump from p6 to p2 is large and difficult.
To compensate for this the author might include remarks in p6 which somehow introduce p2.
Furthermore, the hierarchical structuring of the book is typeset so as to emphasize to the reader that p2 is at the same level as p1 and not a continuation of p6.
When the semantic net is built, connections may be made which have a secondary significance.
For instance, the semantic net includes a link from ‘text’ to ‘ancient history’.
This link is associated with a paragraph about the ancient origins of text.
In a reasonable sequence the paragraph about the history of text in the Middle Ages would come next.
If the graph traversal were to follow the target node ‘ancient history’ to a source node ‘ancient history’and delve into other details in the book germane to ancient history, it might lead the reader astray from the theme.
How can the author have the freedom to connect two nodes for the benefit of hypertext browsers without forcing the traversal algorithm to follow that path?
A related solution was available years ago in the FRESS system which allowed keywords to be chosen by the user and then determined which paths could be followed and which could not.
For this research a modified depth-first traversal was introduced and allowed authors to mark links as non-traversable.
Internally, this amounts to another attribute for a link in the frame representation called the ‘dead-end’ attribute.
If the author elects to say that a given link is a dead-end, then the traversal algorithm will not follow that link.
For instance, if the author wants one tangential paragraph about the relationship between ‘microtext and ‘Vannevar Bush’ but wants a major section about ‘Vannevar Bush’connected to ‘macrotext’, then the ‘microtext’to ‘Vannevar Bush’link would be marked as a ‘dead-end’.
Deeper models
Medicine has many well-established models.
In medical books one can anticipate that a description of a disease will be decomposed into first a subsection on the etiology, then a subsection on the diagnostic signs, then a subsection on the treatment, and finally a subsection about prognosis.
This organization reflects a time sequence and is the basis of the disease model of medicine.
In a biology text, one might expect that a section about mammals would have subsections about particular mammals, and the organization of those subsections would reflect that of the introductory section about mammals.
In the introduction to the Macrotext chapter of the Hypertext book, word-based and indexing language approaches are emphasized.
Accordingly, the Principles and Systems sections of the chapter inherit this pattern (see Figure 13).
Detecting these patterns and helping them be most noticeable in the book has been facilitated by the programs to traverse the document and programs which give summaries of the characteristics of the node names.
Looking at the top-level outline of two chapters in the book one sees an attempt to model in a consistent fashion concerns in the real world.
The only non-identical parts in the top-level outlines of the Microtext and Macrotext chapters are the parts on translations —‘Text to Microtext’ and ‘Hypertext to Hypertext’(see Figure 11).
‘Text to Microtext’ is about the semi-automatic connection of text to hypertext and ‘Hypertext to Hypertext’is about the semi-automatic connection of one hypertext with another hypertext.
These sections naturally follow one from the other, and thus the organization of the headings in these two chapters follows patterns.
Figure 13.
Patterns in the Macrotext subsections inherit the attributes of macrotext.
(The outline comes from the semantic net but the link labels are not printed here)
Titles and captions
After the traversal program has determined the order in which links will be crossed, a printing program takes the semantic net and the paragraphs and produces a camera-ready document.
The traversal has produced an ordered tree which the printing program labels as an outline.
For instance, the first subsection of Chapter 2 is tagged as Section 2.1.
Additionally, the name of the tree node is printed as a heading.
If Chapter 2 begins with the source node ‘microtext’, then the program actually prints ‘Chapter 2.
Microtext’.
In an early version, at the beginning of each paragraph the relevant node-link-node triple was printed.
For instance, the paragraph attached to ‘hypertext has history’ would be preceded by that triple in the paper document.
After the first draft of the book was distributed to people for criticism, a common complaint was that these triples were annoying.
The triples did not add significant meaning to the document and they interfered with the flow of thought.
For the authors, the semantic net had been so important that to see node-link-node triples before each paragraph provided a kind of unity to the document.
But to outside observers this was not so.
This conflict between what the creators of the system like and what others like is common.
Douglas Engelbart's group published a paper in which each paragraph was prefaced by a number that exactly specified that paragraph's position in the outline.
For instance, the number 1.3.2 would indicate that the paragraph was in section 1, subsection 3, and subsubsection 2.
While the original version of Engelbart's famous paper showed this structure, subsequent reprintings of the paper have removed that feature — this despite the claims by Engelbart that his group found such presentation extremely helpful.
One helpful critic suggested that rather than remove the node-link-node triples that they be placed in the margins.
That approach has now been adopted with a twist.
Since the node-link-node triples are not as meaningful to readers as they are to those who made the semantic net, the author may place any phrase in the margin.
The caption is printed in the margin with the paragraph.
While often the caption is the target node name, sometimes an attractive caption does not fit the semantic net paradigm.
For instance, if the paragraph associated with ‘word frequency has principle’ emphasizes that ‘frequency times rank equals a constant’, then that equation should be the caption.
Fitting that equation into a semantic net would be difficult.
In the representation of the extended semantic net in the computer a caption attribute is added.
Printing a section heading as a node name of the semantic net also sometimes seemed inappropriate for the printed form.
In the semantic net, each distinct node must have a distinct name.
Thus, if there is to be a section about ‘microtext history’ and another section about ‘macrotext history’, they cannot both go by the name ‘history’.
Yet, to begin a chapter whose title clearly says ‘Microtext’ with a section called ‘Microtext History’seems redundant.
Given the context it would be enough to tell the reader that he is entering the ‘History’ section.
The reader of the linear document will know that this must mean the ‘history of microtext’.
The semantic net does not have a particular linear version burnt into it and must distinguish different history subsections by giving them distinct names.
Accordingly, the representation of a link object was expanded to include the attribute ‘title’.
As the printing program traverses the semantic net and generates headings on paper, it first looks for a ‘title’ attribute.
If there is no ‘title’ attribute, then the node name is used.
Since the proper title to print depends on the linear context, a more sophisticated system would note the path followed to a node and print the title which suited the context.
Local cohesion
The greatest criticism which reviewers made of the early drafts of the book was that it lacked cohesiveness.
The book read as though it were a collection of notes rather than a single document.
Some speculated that this may have been a product of trying to create a hypertext and converting that into text.
As one attaches the paragraphs to the semantic net, one cannot be certain from which direction the paragraph will be visited.
Accordingly, one is constrained in the way which one can refer to the preceding paragraph in the printed document — because one does not know what the preceding paragraph will be.
One might argue that this feature of hypertext will forever prevent it from being convertible into cohesive linear form.
Language is richly composed of many references which set up a commonality of theme between different parts of text or speech.
There exist many different types of cohesive tie, but one of the most common is the pronoun.
Pronominal substitution is one of the several methods to link sentences and paragraphs and to allow the perception of an overall text.
For example:The batter hit the ball well.
It soared into the air.
Within these two sentences, the situation is easily understood and explained.
The it in the second sentence refers back to the ball .
The two sentences are bound together by a cohesive tie.
By studying the number of occurrences of cohesive ties and their locations, one can begin to gain an indication of how well-formed a text is.
One approach to the hypertext-to-text coherence problem is a labor-intensive one and treats the hypertext form as a rough draft.
In the final phase of the document production the hypertext is forgotten, the document becomes exclusively a linear phenomenon, and references to linearly preceding paragraphs may be directly introduced.
For instance, if one paragraph discusses the history of World War II and the preceding paragraph discusses the history of World War I, then the second paragraph may be modified to include some introductory sentence such as , ‘The next world war…‘.
Another approach to the local coherence problem benefits from having the paragraphs on the node-link-node triples rather than on the nodes.
Built into the network are transition paragraphs for many possible traversals.
For instance, the paragraph connected to the ‘hypertext include microtext’ triple introduces ‘microtext’from the perspective of ‘hypertext’.
The paragraph connected to the ‘principles apply microtext’ triple introduces ‘microtext’from the perspective of ‘principles’.
Thus when the traversal reaches ‘microtext’ from ‘hypertext’, a different story is told, than when the traversal reaches ‘microtext’from ‘principles’.
The traversal algorithm will place the appropriate transition paragraph in the linear document, and a certain, local cohesiveness will be maintained.
This approach does not solve the problem of continuity that depends on more than the single preceding node.
Furthermore, a dense, hypertext, semantic network, from which a single printed document was to arise, would include many transition paragraphs that would not appear in the printed document.
DISCUSSION
In the common approach to hypertext a block of text has a button which corresponds to an unlabeled link from the button to another text block.
The approach advocated here has a semantic net whose link objects or ‘node-link-node’ triples point to paragraphs.
Several experiences have been described to show how a textbook was prepared on a hypertext system with a semantic net underpinning and through document reuse.
The authors are able to grab paragraphs from various sources and index them into the semantic net.
Indexed paragraphs are reused in various traversals of the semantic net.
The finished book has been automatically generated and typeset directly from the database of paragraphs and link objects.
At times authors may want to express concepts and relations that a semantic net does not support.
For instance, one might want to say that ‘for all x there exists a y such that f(x) equals y’, but a semantic net does not support such statements.
If, however, one introduces more robust representation schemes, then one may also increase the cognitive load on the author.
A semantic net has the virtue of simplicity.
As the semantic net grows, understanding it becomes a challenge.
Furthermore, the content of an indexed paragraph is not obvious from its reflection in the semantic net.
By having the paragraphs indexed as node-link-node triples, one gets better insight into the relationship between the paragraph and the semantic net than when the paragraph is indexed by just a node name.
By placing the paragraphs on the node-link-node triples, the traversal of the semantic net and the generation of cohesive linear documents is also facilitated, as paragraphs are invoked only when the two nodes which they connect are simultaneously considered.
The semantic net has been studied and modified based on principles of analogical inheritance.
But while the patterns in the net identified by analogical inheritance have proved useful, simpler patterns have also made a difference.
Simply noting how often node names occur and looking for repeating patterns has been useful.
The study of node names suggests generic, semantic attributes for a book about information systems.
For instance, any such book might meaningfully have sections on ‘Principles’ and ‘Systems’and the ‘Principles’section might be decomposed into subsections on ‘Computer Principles’and on ‘Human Principles’.
Alternatively, these topics might be reflected in a set of link types, such as‘principles’ and ‘systems’.
In many practical settings, the same body of information has to be included in different documents.
The opportunity to see a semantic net and dynamically generate outlines from it may help authors mold the desired document.
This kind of interaction is consistently recognized as important for the authoring of documents and seems likely to be useful for document reuse as well.
From the experiences described in this paper requirements for a new hypertext system arose.
The ongoing experiments in this research project are taking place on a network of Unix workstations with a prototype document reuse tool that has a relational database back-end and an X-windows interface.
The system supports both creation and accessing of hypertext and text.
Users can register complex discussions and annotations within the system.
Search facilities as well as browse facilities are available.
Rough notes may be entered and do not need to be attached to the semantic net.
As all entries in the database are tagged with the name of the person who entered them and the date of entry, certain types of retrieval can be done independently of the semantic net.
Text-to-hypertext and hypertext-to-text tools have been incorporated in the prototype.
The direct-manipulation interface allows users to select a link object and be shown a paragraph or conversely.
The outline is dynamically generated, and users can select a topic in the outline and see the paragraphs associated with the corresponding link object.
The role of the semantic net is being explored in this new environment.
The referees have made many valuable suggestions.
Database support for very large hypertexts
B. N. ROSSITER AND T. J. SILLITOE&M.
A. HEATHER 
SUMMARY
Current hyper-text systems have been widely and effectively used on relatively small data volumes.
The potential of data-base technology is explored for aiding the implementation of hyper-text systems holding very large amounts of complex data.
Databases meet many requirements of the hyper-medium: persistent data management, large volumes, data modelling, multi-level architecture with abstractions and views, meta-data integrated with operational data, short-term transaction processing and high-level end-user languages for searching and updating data.
To illustrate the potential for the use of data-bases, a system implementing the storage, retrieval and recall of trails through hyper-text comprising textual complex objects is described.
Weaknesses in current data-base systems for handling the complex modelling required are discussed.
KEYWORDS
Databases Hypertext Paths Trail management Composite objects
INTRODUCTION
The hyper-medium is an information space representing a high-level abstraction of data.
It represents an idealized view of the information needs of an area of particular human interest or activity.
Information usually amounts to connections between different items to be found in human experience.
These may be physical things or they may be ideas.
The significant feature of the hyper-medium is the nature of this connection between data.
It consists of an ordering but an ordering that is not unique.
Many possible orderings may exist.
While the computer is an obvious tool for handling and organizing large quantities of data in the hyper-medium, straight-forward procedural methods cannot cope with the complexity of the organization.
The experience of early workers in data-bases is being repeated in the hyper-medium by those engaged in developing hyper-text.
To progress beyond small simple systems requires the writing of what amounts to a customized data-base system.
However, in adopting a customized solution, there is an immediate loss of generality and of functionality and a deterioration in quality.
The hyper-bases so developed may only be usable in their home environment whereas a generalized data-base implementation would provide the basis for the use of the same information for many other purposes [1].
There is the matching and retrieval capabilities of information retrieval systems, the document segmentation and word indexing of free text products, the display of mark-up languages, the layouts and layers to be found in the Office Document Architecture, the use of metadata for data exchange, and the application of a body of rules as in the field of AI and expert systems.
It therefore seems better to make use of the experience of the data-base community in building large hyper-bases but it cannot be pretended that the benefits of one technology to the other are all in one direction.
As will be seen later, data-base technology in its present form has some deficiencies in modelling complex objects and events, the solution of which will be given greater impetus by involvement in new challenging areas.
The authors therefore see the relationship between data-base and hyper-text technologies as symbiotic rather than parasitical.
The hope is that data-base technology is both extending the hyper-medium and being extended by it.
For reasons of continuity from the old, a fundamental unit of data in the new hyper-medium is a document.
Present hyper-text provides mainly for small, simply structured documents and, in the way that it concentrates on factors at the human — machine interface, it gives good insight into the capabilities needed for a full hyper-medium system.
Three main types of link are recognized in hyper-text systems:
1.
explicit inter-document links representing citations,
2.
lexical links in which the meaning of words is resolved,
3.
conceptual links in which implicit semantic connections are made between one document and another.
The work described later is mostly concerned with symbolic links between one document and another.
Lexical links pose greater difficulties in implementation because of frequent ambiguity in finding the definition of a word amongst its many usages in a text.
Implicit links have proved to be difficult for the machine to locate automatically but can be entered manually by the user in most hyper-text systems and in small-scale applications can provide very rich structures.
It is unlikely that such richness can be achieved in large hyper-bases where automated authoring is likely to prevail.
In traditional document systems, there is often a very arbitrary division in information [2]because of the rigidity enforced by predefined document sizes.
In hyper-text systems, this is overcome to some extent through various composition techniques for representing isPartOf relationships.
Through such aggregation, logical documents can be defined which are a synthesis of what may be many diverse physical documents.
The view of the authors is that these ideas need developing further to represent a document as a complex data object holding information in the form of structured data.
The representation of document structures in data-base models is investigated more fully later.
LIMITATIONS OF CURRENT HYPERTEXT SYSTEMS
Present hyper-text systems concentrate on the human — computer interface and rely on semi-automated or manual techniques to represent links between one document and another.
This is satisfactory for small, simple document structures but otherwise there are a number of problems:
The use of symbolic addressing is not fully exploited to cope with pre-existing forms of citation and for automated authoring of large quantities of text.
There is no independent level of control that can test or validate the data and that can track the navigation through documents: the design and construction of maintainable links is a major problem.
There is a lack of the concept of referential integrity.
Methods of management of persistent data are relatively primitive.
It is not easy for a hyper-base to be used concurrently by a number of different readers or for multiple authorship.
Progress in this area is currently being achieved by very active research in the area of Computer Supported Cooperative Work (CSCW).
Access methods, in general, are designed for handling small amounts of persistent data.
Searching facilities are specialized.
There is an emphasis on browsing through nodes via links rather than on con-tent addressing where the facilities are often quite limited.
However, there are exceptions.
Hyperties [3]is an early example of a system paying much attention to string searching within a fine data structure.
Other workers have used relational data-base systems to augment searching facilities as mentioned later.
Indexing is based on surrogates such as tables of contents rather than the full contents of a node.
There is no consensus on the nature of the formal data model which is necessary to provide an integrated framework for data structuring and manipulation.
Recent work employing set theory [4,5], Petri nets [6]and Z [7]shows the urgency with which this area is now being tackled.
It is important for large complex applications that current hyper-text practice involving the use of directed graph (general network) structures, inheritance hierarchies and object-oriented scripts be underpinned by a greater body of theory.
A formal storage model using network structures has been developed [8]but this omits many of the activities.
Node data is WYSIWYG.
There is limited opportunity for mapping and indirection between user views and storage structures.
There tends to be one fixed view — that of the author — with little scope for the preferences of individual readers.
Hypertext systems are generally self-contained and cannot be easily integrated with other programs and data.
It is difficult for another application to use the hyperbase.
These problems are emphasized with large data volumes, multiple authorship, complex inter-node and intra-node relationships, need for multiple views of same hyper-medium, and a desire to integrate the hyper-base with other types of application within the organization.
POTENTIAL OF DATABASE TECHNOLOGY
Database technology has significance as it can assist in many of these problem areas: high-level end-user languages such as SQL can be embedded in standard programming languages to integrate data-base facilities with other functional aspects; management of large volumes of persistent data, including such aspects as security, integrity, concurrency and optimization of access, is a central tenet of the technology; multi-level architectures with mappings from logical to physical levels provide different views of the same stored data; content-addressing can be integrated with navigation to give facilities as sophisticated as those found in information retrieval systems.
The use of data models requires more detailed discussion.
Database technology depends on the development of an appropriate data model for structuring and manipulating the data.
It could be argued that the use of any model is reductionist, resulting in a loss of information.
However, a data model does provide a rigorous framework within which an application can be developed.
It therefore seems necessary, to exploit the full power of hyper-text, to have some machine model expressing semantic detail of the documents held with a full abstract specification of the data-types involved and a multi-level architecture similar to that of a DBMS.
A clear problem is the kind of model that is most suitable for representing the architecture of documents and multimedia data and for providing usable query languages.
As will be seen later, current DBMS models are inadequate in some respects.
The manner in which cross-references are realized and checked is crucial for a consistent hyper-base.
Database systems employing symbolic keys for identification of objects have an inherent advantage over less conceptual approaches in handling text whose content is continuously changing.
In first generation hyper-text systems with physical node addressing, cross-references must in advance be fully identified as in a net-work data-base.
In a value-oriented data-base approach to hyper-text, links are made dynamically at run-time using symbolic key matching techniques.
Both means provide for display and navigation through documents.
The physically oriented approach uses less resources but the early binding of identifier to data is more of a static method which allows less flexibility if, for example, data is being loaded in an uncertain order or key values are being changed or deleted.
The greater flexibility obtained through the dynamic power of lazy evaluation using data-base technology is not the only advantage in this area.
Constraints like referential integrity can be placed automatically on new data entered into the system and on updates to existing records.
Potential cross-references in symbolic form are checked against the current data-base and must succeed for the new or changed record to be accepted without reservation.
At the programmer's discretion, errors resulting from dangling cross-references can result either in the new data being rejected or accepted with reservation.
Such reservations include a warning message, flagging of the citing field or a setting of the citing field to null.
The various levels of verification of links makes the construction of large hyper-bases a very much easier and rigorous process through a multi-stage commit process.
During the addition of user data, dangling cross-references, perhaps reflecting the order in which data is added, are flagged in the first pass and only after a second pass to re-check citations is the possibility of rejection considered.
In any event, cross-references which cannot be resolved will remain flagged as such so that the system is always consistent with respect to which references are navigable.
Finally the concept of referential transparency should be raised.
In a data-base environment, the entire management of the links will be automatically handled by the system to relieve the user of all responsibility for maintaining referential integrity.
RELATED WORK
To enable larger amounts of data to be handled, some hyper-text systems have already been augmented by a conventional relational data-base system as for example with the commercial system OWL [9].
Another attraction of relational systems has been to enhance the searching facilities as with the work by Gallagher et al .
[10]in storing HyperCard objects in the data-base system ORACLE.
At Texas Instruments, an experimental system, PANORAMA, based on the object-oriented data-base, ZEITGEIST, has been built to augment navigation facilities with searching functions [11].
These approaches have promise but are restricted by poor complex object modelling with the relational approach and a complex user interface compared to those in contemporary hyper-text systems for PANORAMA.
Work by Raymond and Tompa [12]has indicated the need for an accurate representation of the fine structure of documents to allow fragments of documents to be referenced and treated as objects of data in their own right.
Tompa's model [4]satisfactorily treats some aspects of the hyper-media such as multiple readership and symbolic labels through using a 6-tuple structure recording nodes, pages, readers, mapping from nodes to pages, labels and hyper-edges.
However, there is a major problem with the model for real textual data: all references are between nodes mapped statically to a number of data pages with no scope for dynamic variation of unit size in the source and target objects.
The model thus fails to capture the inherent complex object structure of multi-media data including the fragmentation features discussed by Tompa in his earlier work.
AN EXAMPLE DOCUMENT ARCHITECTURE
In order to examine document architectures, the example of English legal statutes will be used in this paper.
In England, Parliament enacts statutes and Figure–1 shows related documents which have a bearing on the meaning of a particular section in an Act of Parliament.
A section represents the smallest self-contained free-standing unit of text although subsections may be directly cited sometimes.
A section is a mere point in the textual hyper-medium and can rarely be consulted alone or understood without reference to other documents.
For many purposes, sections are grouped together into parts or para-graphs into schedules.
As any of the information in the Figure 1 may have a bearing on a section in question, it can readily be seen that advanced hyper-text features are needed if all the relevant subject matter is to be available and easily reached in the electronic medium.
Our work can be contrasted with that of Yoder and Wettach [13]who have also developed a hyper-text system for the law.
Their system is very flexible in the forms of data accepted but lacks a formal data model for controlling structures and for providing a general means of manipulating the data.
Figure 1.
A Section of statute set in the European legal hypermedium
TRAILS AND PATHS
The existence of conceptual paths through textual documents was first recognized by Bush in 1945 [14].
Treu [15]considered the existence of trails through bibliographic citations and thought they should be preserved for a searcher to retrace his steps at a later date.
At Newcastle, the need to provide a conceptual framework for the machine to assist the human in his data-base searching and navigation was recognized in 1987 [16]with a prototype implementation of the recording of trails in data-base tables as persistent data fully integrated with the hyper-text data.
The main objective of the trails was to assist the human in communication with the machine by removing the need to memorize backward and forward references, unsuccessful routes through the data-base, search terms used and the search and navigation strategy.
Also in 1987, Conklin [17]identified one of the major difficulties in current hyper-text systems as the user becoming ‘lost in hyper-space’ as a result of losing his way along a trail as a result of the demands made during navigation.
Zellweger [18]has classified the various kinds of path and emphasized the importance of implementing paths as first-class data.
Although the implementation of the paths as scripts is satisfactory for single-user systems, there are problems with sharing of the path data in multi-user environments.
There is general agreement in the work quoted above that path information should be first-class data, replayable with or without variation and an essential part of the user inter-face.
Before considering the required structures in more detail, we will first consider data-base models for representing the internal structure of the statute.
DATABASE MODELS AND TEXTUAL STRUCTURES
The basic DBMS models such as the relational are not suitable for manipulation of the fine structure of documents mainly due to the problems of normalization and aggregation of textual data [1]which in general terms result from an inadequate representation of complex objects [19].
At least for representing ideas, it is necessary to move on from the classical models to the semantic models because the required emphasis is on capability, expressiveness and abstraction.
A range of semantic models incorporating more features and constraints than in the basic models has been proposed in an attempt to model more closely the real world.
These include the Entity-Relationship (E-R) Model [20]and Taxis [21], both of which have been employed in this work.
CLASS STRUCTURES
A Chen E-R model of English statutes and the corresponding diagram showing the class structures have been presented elsewhere [1].
Two types of hierarchy are embedded within the class structure:
An essential inheritance hierarchy to indicate the inheritance of properties (attributes) automatically by lower level objects from higher ones through ‘isA’ relationships.
An aggregation hierarchy to indicate potential groupings of data through ‘isPartOf’ relation-ships.
This hierarchy provides the framework upon which textual units are dynamically aggregated to satisfy varying user requirements.
The aggregation hierarchy has as its root a highly abstract object node which has some similarity to a node in hyper-text terminology comprising a chunk of data for presentation to the user.
There are thus clear similarities between the two approaches.
However, there are important differences:
in hyper-text systems, nodes are static structures at run-time whereas in our approach, a node can be dynamically generated at any time from any of the underlying text objects by aggregation.
This dynamic composition is an important feature of the Dexter model [7]mentioned earlier.
in hyper-text systems, the internal structure of the nodes can be left undefined whereas in data-base technology there is a clearly defined structure for each specific text object at lower levels of the class hierarchy.
the aggregation of node in our approach is always made in the context of symbolic identifiers (see Figure 2) rather than record or card numbers.
SYMBOLIC ADDRESSING FOR HYPERTEXT
For navigation in the hyper-medium, it is important to be able to identify uniquely individual units of text so that cross-references can be resolved.
With the complex object structure employed in this study, it has been found that the optimal solution is to employ a generic symbolic key all.unit.id for the abstraction node as shown in Taxis-like form in Figure 2 [1].
The key all.unit.id effectively defines a generic heading which contains an integer value for each possible component of a textual identifier.
The form of the key is application-dependent: in our work, nine different components have been identified such as section, subsection and footnote.
For a given instance of a text, the values of some components are inapplicable.
Such components have a value of zero: all other components have positive values, for example,section num would be assigned the value 6 in the heading of the sixth section of an act.
This provides a completely general mechanism for addressing all objects in the inheritance hierarchy.
The values for the attributes of node are constrained by the variables such as ssmin and ssmax which specify the minimum and maximum values permitted for subsection numbers.
The class text is a specialization of node representing an abstraction of the main body of text.
As shown in the definition of text.id , a subset of the components of the generic key all.unit.id is required to address the main text.
Specific features included in text but not in node are attributes representing various details of the internal structure of an item of text.
Cross-references are represented by the class XRef with each citation held in ref.id comprising a pair of symbolic identifiers for the citing and cited text units, respectively.
The constraint is specified that the citing and cited objects must be members of the set text : therefore, the identifiers of the text units must conform to the structure of text.id and the text units must be instances of the class text to enforce referential integrity.
MODELS FOR EXPRESSING DYNAMIC ASPECTS OF TRAIL MANAGEMENT
Figure 3 shows a Data Flow Diagram (DFD)[22]for the trail management which indicates the control of events required in searching and navigating.
The diagram shows an over-view of the processes involved and how they reference three types of information: the hyper-medium itself, the names of the trails made by each user held in path and a complete history held in pathitem of each path comprising an initial content-based search followed by a series of navigational commands.
Whilst execution of a particular process is not complicated, it is a matter of integrated management of the very large number of processes that are possible and their complex inter-relationships.
Also shown is a description of the main data flows on the input side to illustrate the nature of the commands passed to the system for action.
Only the top-level of the DFD is shown.
This could be decomposed further into lower-level diagrams, each holding more detail of how each process operates.
It is interesting to note that such detailed diagrams have similarities to the Petri nets of Furuta and Stotts [6].
Both approaches employ process models: DFD are business-oriented but Petri nets have the better formal basis.
Figure 3.
DFD for trail management in navigation of hypertext
MODELS FOR EXPRESSING STATIC ASPECTS OF TRAIL MANAGEMENT
As companion to the DFD of Figure 3, there is an E-R diagram in Figure 4 to show the relationships between the entities holding the trail information path and pathitem and other entities relevant to trail management.
Each user can hold many paths each of which holds many path items.
For branching trails [18], it is necessary to introduce the involuted relationship cites to indicate that a single path item can branch to many other path items during navigation through the user backtracking.
For linear trails, the relationship cites is not required.
The entity-type Current.Record.Position has been introduced to explicitly indicate the current selected object.
Many users can be active at a given time but it is an assumption at present that each user holds a single current record position at any given time.
The entity-type hyper-medium is in a 1 N relationship with pathitem indicating that each hyper-medium object can appear many times as a path item but that each path item refers to only one hyper-medium object.
The importance of the relationship item.found.in for integrity of the trail is described later.
IMPLEMENTATION OF TRAIL MANAGEMENT SYSTEM
The system was implemented on the non-standard SPIRES DBMS run on an Amdahl 5860 of the NUMAC service.
The textbase STATLT holding the statutes for England has been developed and refined in a series of projects since 1980 and at the start of the project described here already provided a very detailed definition of the data structure [1], full text-searching facilities, symbolic addressing in the manner of Figure 2 and a multi-valued attribute marg-note-xref in each text unit to record cross-references made to other parts of the text [23].
The current work is concerned with the implementation of the dynamic aspects shown in Figure 3 and the static aspects of Figure 4.
The additional tables created to record the status of navigation will first be described.
Figure 4.
E-R diagram for static aspects of trail management
TABLES TO RECORD THE NAVIGATIONAL STATUS
The entity-types path and pathitem shown in Figure 4 hold all information on the trails made by users through the textbase.
The attributes describing this information are shown below (key attributes in bold):
path (user.id, trail.num,trail.label)
pathitem (user.id, trail.num, command.num,command, citing.text.id, cited.text.id, current.unit, link.status, relevance)
Each trail is labelled with a string trail.label for identification by the user.
In pathitem ,cited.text.id holds the symbolic key of the current record after the command held in command has been both executed and successful.
Success or failure is indicated by the value for the logical attribute link.status .
The current unit size, indicating the extent to which the complex object structure has been aggregated to provide results to the user, is indicated by the value for current.unit .
The attribute relevance can be used to record the desirability of taking a particular route.
The attribute citing.text.id represents the involuted relationship cites of Figure 4 and is used as a backward reference point to enable the user to perform backwards and for-wards tracking through the text.
The attribute pair citing.text.id and cited.text.id is exactly equivalent to ref.id defined earlier in the Taxis-like symbolic key definition of Figure 2.
The tables and their attributes are extensively used by the processes described in the DFD of Figure–3.
DYNAMIC ASPECTS AND THE USER INTERFACE
The DFD of Figure 3 was converted to a structure chart [24]by transaction analysis.
The process Examine.Request was considered to be the transaction centre as it triggers many courses of actions in the system.
The functions were implemented using the SPIRES Protocols language.
Two types of command are recognized by the system.
SPIRES system commands are passed to the data-base kernel without modification.
Other commands to validate and execute either a search, navigation or trail request are parsed and then sent to the appropriate process.
It should be emphasized that the interpretation of users' actions is to some extent context-driven.
Thus if the variable status holds the value REPLAY, the users' actions will be interpreted as far as possible as involving the recall of a trail.
If the value is ACTIVE, the user is thought to be navigating and if INACTIVE (from the navigation perspective) performing an initial search to locate a record on content prior to navigation.
However, if it is unambiguous that a user wishes to change his mode of operation from, say, navigation to content search, his status will be changed transparently from, in this case, REPLAY to INACTIVE.
This flexibility is very important as it is only by changing mode in the middle of a session that a user can vary an earlier trail to explore the text in a new manner.
The facilities available to the user under each status value are as follows:
INACTIVE: A search command creates an initial result stack of items.
This is followed by iterative searching with Boolean logic on the current stack.
Navigation can only sensibly proceed when the user has identified a single record as of initial importance from content-searching.
The ideal is probably an initial list of ranked records as described by Croft and Turtle [25].
ACTIVE: Navigation commands available are of three main types:
entering a positive or negative number enables the user to browse backwards or forwards through the text in logical sequence of the textual units.
This command is typically used for browsing in either direction through sections within a part or paragraphs within a schedule at a constant textual unit size.
entering the command ref directs the system to find the record referenced by the current record.
If several records are referenced from a single record, the user will be given a choice as to which one is required.
If the reference is to a high-level unit such as a part , objects will be aggregated to retrieve a complete part for the user.
This command can therefore dynamically change the current textual unit size.
entering values for the identifiers of sub-objects of the symbolic key defined in Figure 2 finds the record with symbolic key with new values for the designated sub-objects and current values for other components.
The current textual unit size is adjusted accordingly.
With all three forms of the navigation command, execution results in updating the table pathitem defined earlier and, if successful, making the object found the current item.
REPLAY: for the replay of trails established earlier, the user first provides a string trail string for identifying the required trail held in the table path .
If the trail exists, the first action held for the path in pathitem will be executed and the system status will be changed to REPLAY.
During the replay of a trail, a user can enter any of the following:
first finds the key of the record found at the beginning of the selected trail and establishes it as the current record.
last finds the key of the record found by the end of the selected trail and establishes it as the current record.
fwd[n] takes the navigation n steps forward from the current position.
bwd[n] returns the navigation back n steps.
end causes the status of the system to be changed from REPLAY to INACTIVE.
DISCUSSION
We have used current data-base techniques to satisfy our requirements.
Of particular interest is the availability of both powerful browsing and searching facilities, the recording of all information concerning user trails as persistent data in fully-fledged data-base tables, and the dynamic variation of text unit size to meet changing user demands.
However, our task was relatively hard in two areas:
1.
the dynamic adjustment of unit size; and
2.
the integration of dynamic and static models.
In our implementation, aggregation was achieved at run-time through masking out components of the primary key and assembling, using the Protocols language, the series of text objects meeting the criteria implied by the user's current request.
Reasonable performance was achieved in this task but the aggregation is being achieved by external operations on the objects rather than by the more conceptual approach of aggregation abstraction: new object classes with aggregation methods are defined to represent the various unit sizes.
Database technology does not provide a completely satisfactory solution to this problem.
The definition of abstract data types as in Postgres [19]to represent the various aggregation possibilities may give problems with closure: the return of a multi-valued set produces an unnormalized relation.
Alternatively, an object-oriented data-base system such as GemStone [26]could have been employed.
This would have modelled well the inheritance abstractions but aggregation is achieved by external operations on objects as in our current implementation.
The dynamic and static aspects have been implemented using different models which are weakly integrated.
This lack of integration is found in all conventional data-base systems in current use [27].
It is an inherent feature of object-oriented data-bases that methods form part of the class definition.
Some semantic data-base models such as Taxis also provide this capability and their expressiveness has been examined for text [1].
Although these integrated models are currently at the experimental stage for realistic amounts of data, their usage in future large hyper-base systems seems very necessary.
The object-oriented model of hyper-text developed using the Vienna Development Method [28]shows the potential of the paradigm in this area.
In addition, there is also a number of areas where further work is required:
1.
The interface provided to users.
Layered object-oriented techniques employing multi-windowing need to be front-ended onto the present system.
2.
Investigation of the semantics of trail integrity.
The integrity of trails depends during their existence on no component object being deleted during maintenance of the hyper-media data-base.
There is therefore a need for restrictions on the actions that are permitted on objects that participate in trails.
Operations such as deletion on any hyper-medium object participating in the relationship item.found.in should perhaps be constrained.
Further work is needed at the conceptual level in this area to determine the exact nature of the constraints required.
CONCLUSIONS
Hypermedia systems are very complex: events have to be controlled over long periods, as in the design, control, maintenance and integrity of linear and branching trails used for navigation; text and graphical information comprises complex data objects with the need for aggregation and inheritance abstractions; and interfaces must employ multi-windowing techniques and be natural according to psychological models.
A natural extension of the present work on hyper-text at Newcastle is to investigate the use of object-oriented data-bases with their claimed suitability for large-scale complex applications.
In effect, what is required is to place under a contemporary hyper-text interface, data-base models which are very powerful, yet can provide a high level of abstraction to the end-user.
It is to be hoped that data-base technology can be developed quickly enough to meet the imminent requirements for data management in very large hyper-bases.