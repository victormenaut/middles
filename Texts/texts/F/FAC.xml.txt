

1
A contextual approach to lexical semantics
1.1 Introductory
Before embarking on a study of lexical semantics, even one which is avowedly descriptive rather than theoretical in orientation, it is necessary to make explicit certain basic assumptions concerning meaning, and to establish, as far as possible, a consistent method of studying it.
The approach which is adopted in this book, and which is described in this introductory chapter, is a variety of ‘contextual’ approach: it is assumed that the semantic properties of a lexical item are fully reflected in appropriate aspects of the relations it contracts with actual and potential contexts.
The full implications of this will become clearer as the exposition proceeds.
In theory, the relevant contexts could include extra-linguistic situational contexts.
But there are good reasons for a principled limitation to linguistic contexts: first, the relation between a lexical item and extralinguistic contexts is often crucially mediated by the purely linguistic contexts (consider the possible relations between horse and the extra-linguistic situation in That's a horse and There are no horses here ); second, any aspect of an extra-linguistic context can in principle be mirrored linguistically; and, third, linguistic context is more easily controlled and manipulated.
We shall therefore seek to derive information about a word's meaning from its relations with actual and potential linguistic contexts.
However, the combinatorial characteristics of words in utterances are constrained not only by their meanings, but also by their grammatical properties.
Grammatical constraints may overlap and reinforce semantic ones, but they may also be semantically arbitrary.
In order to be able to use contextual relations for semantic purposes, therefore, we need to be able to recognise and discount combinatorial peculiarities which are purely grammatical in nature.
1.2 Meaning and grammar
Drawing a clear-cut distinction between meaning and grammar  is not an easy task, because the two are so intimately interwoven (this is hardly surprising: ultimately, the only purpose of grammar is to serve the conveyance of meaning).
However, they can be disentangled sufficiently to allow our study of lexical semantics to proceed.
The distinction between grammar and meaning has a strong intuitive basis (notwithstanding difficulties of characterisation, and regions of uncertainty).
Few, I imagine, would dispute that 1 is odd by virtue of its meaning, and 2 by virtue of its deviant grammar:
1.
He harvested a magnetic puff of amnesia.
2.
Them yesterday goed to home.
However, while every effort will be made to found arguments on intuitively clear cases of semantic deviance, it is only prudent to have some notion of what is involved in distinguishing this from syntactic deviance.
Let us then take the discussion a stage further.
Consider the following sentences:
3.
It's too light for me to lift.
4.
I've nearly completed.
—(in answer to How are you getting on with those jobs I asked you to do ?)
Both are, of course, deviant.
But in attempting to decide whether the deviance in either case is grammatical or semantic, we are not wholly dependent on unaided intuition: reasoned arguments can be deployed.
In 3, for instance, the deviance disappears completely if light is substituted by the semantically distinct, but syntactically identical,heavy .
There would seem, therefore, to be ample justification for describing the deviance of 3 as semantic.
In the case of 4 the deviance can be cured by inserting them after completed .
This alters the syntactic nature of the sentence, but is (almost) semantically empty.
We can also point to the difference in degree of deviance between 4 and 5, which is out of all proportion to any difference of meaning between complete and finish .
5.
I've nearly finished.
It would seem perverse, therefore, to see the deviance of 4 as anything other than syntactic.
These examples suggest that there is a possible principled basis for the distinction between semantic and syntactic deviance.
A frequently mentioned, and as often criticised, criterion is that of ‘corrigibility’: the idea is that syntactic deviances can be readily corrected, whereas semantic deviances cannot.
Consider sentences 1 and 2, for example: it is perfectly obvious what 2 ‘should be’—They went home yesterday ; but what is to be done with 1?
So far, so good.
However, it is not difficult to find semantically ill-formed sentences which are easy to straighten out.
We need look no further than 3 — it is obvious enough what it ‘should be’.
Moreover, the notion of corrigibility is itself suspect: strictly speaking, one can only correct an utterance when one knows what the speaker intended to say, and this is not the case with the specially constructed sentences used in semantic analysis.
A more promising strategy is to ask not how or whether a deviant sentence can be corrected, but what the minimal changes are that will render it normal; then we examine the nature of the changes.
If a deviant sentence can be normalised by adjusting its grammatical structure — for instance, by changing the order or syntactic category of elements, or by adding, substituting or deleting one or more grammatical elements — then it would seem reasonable to suppose that its deviance is grammatical in nature.
If, on the other hand, the minimal change required is one necessarily involving one or more full lexical items, then it would seem justifiable to diagnose the deviance as semantic.
This procedure would be more informative if we were able to characterise grammatical and lexical elements more explicitly.
This is, in fact, possible in terms of what are called closed set items and open set items .
The closed set elements in a sentence are those belonging to classes whose membership is virtually constant during the lifetime of an individual speaker (on a longer time-scale they do, of course, change).
Typically they have few or no possibilities of substitution in an actual sentence:
6.
John' s kind ness amaze d Mary.
They comprise affixes (dis like, kind ness , John' s , wait ed , com ing , black en , etc.) and independent words (sometimes called markers ), such as articles, conjunctions, prepositions and so on, a major part of whose linguistic function is to signal the grammatical organisation of sentences.
The open set elements, on the other hand, are those which belong to classes which are subject to a relatively rapid turnover in membership, as new terms are coined and others fall into obsolescence.
They are the lexical roots — the principal meaning-bearing elements in a sentence.
(The open set elements in 6 are John ,kind ,amaze and Mary .)
They typically have numerous possibilities of substitution in a sentence: It is with words containing open set elements that lexical semantics is principally concerned.
We can now formulate a provisional test to determine whether a deviance is grammatical or semantic ('provisional', because, as we shall see, things are not so simple): if the minimal change required to ‘cure’ an anomaly in a sentence involves one or more closed set items, then the deviance is grammatical; if, however, the sentence can most easily be normalised by replacing one or more open set elements, then the deviance is semantic.
With this test, sentences 1 and 2 are correctly diagnosed (that is to say, in accordance with strong intuition) as semantically and grammatically deviant, respectively.
To normalise 1, the lexical roots must be altered, as no adjustment of closed set items has a noticeable effect:He exhaled a carcinogenic puff of smoke .
All the changes needed to normalise 2, on the other hand, involve closed set items.
A correct diagnosis is also obtained for 3: since it can be normalised by a simple substitution of an open set item, the test diagnoses its deviance as semantic.
It is, of course, perfectly possible for a sentence to exhibit semantic and grammatical deviance simultaneously:
7.
The green idea sleep.
Two separate operations are needed to normalise this sentence, one involving closed set items:
8a.
The green idea is sleeping.
and the other an open set item:
8b.
The green lizard is sleeping.
What is more disturbing if we wish to achieve a simple separation of grammar and semantics is that on occasions one and the same deviance may be cured either by adjustment of closed set items, or by the replacement of open set items.
Sentence 9a, for instance, can be normalised either as in b or as in c:
9a.
The table saw Arthur.
b.
The table was seen by Arthur.
c.
The rhinoceros saw Arthur.
Similarly, 10a can be normalised as in b or c:
10a.
I visited Arthur next week.
b.
I shall visit Arthur next week.
c.
I visited Arthur last week.
Are 9a and 10a, then, grammatically or semantically deviant?
It will be argued that basically these sentences are semantically deviant; however, it must also be recognised that it is not possible to disentangle semantics from grammar completely.
One reason for this is that many grammatical elements are themselves bearers of meaning — this is true, for instance, of the past tense affix —ed , and the plural affix —s .
Because grammatical elements typically need to have the capacity to combine normally with semantically very various roots, their meanings tend to be of a very general sort: the notion of past tense, for instance, can combine without anomaly with virtually any conceivable verbal notion.
But otherwise the meaning they carry is not of a radically different sort from that carried by lexical roots, and grammatical and lexical elements frequently interact semantically.
This is what happens in 10a.
Since the anomaly arises here from a clash between the meaning of a closed set item and the meaning of an open set item, it can be cured by changing either.
Sentence 9a illustrates another type of meeting point between grammar and semantics.
Here we have a semantic clash between two open set items (table and see ); however, this is mediated in a crucial way by grammar.
The grammar of English provides the verb see with two points of interaction with noun phrases:
X — see —Y 
A noun phrase in the X-position interacts semantically with see in a different way from a noun phrase in the Y-position (the exact nature of these interactions can be considered part of the meaning of see ).
Sentence 9a is odd because table does not combine normally with see if it occupies the X-slot; it does, however, function as a perfectly normal occupant of the Y-slot (Arthur saw the table ).
This is why changing the voice of the verb in 9a from active to passive — which has the effect of interchanging the valency slots that the noun phrases occupy — removes the anomaly as effectively as replacing see or table .
Does this mean that, whenever we encounter a deviance that can be cured either by adjustment of grammar or lexical content, we can take it that semantics is involved?
Unfortunately, no: such a deviance may be purely grammatical.
Sentence 11a, for instance, can be normalised either by grammatical adjustment (11b) or by lexical adjustment (11c):
11a.
The cake was baken. b.
The cake was baked.
c.
The cake was taken.
We are led to the conclusion that 11a is grammatically but not semantically deviant by the fact that substitutes for bake which normalise the sentence (e.g. shake ,forsake ), as a class, have no distinctive semantic attributes (that is to say, members of the class share no characteristic patterns of co-occurrence with other open set elements that differentiate them from non-members); however, they do share a grammatical peculiarity, which is that they form their past participles with —en .
The deviance of 11a is thus different from that of 9a: the substitutes for table in the latter which remove the anomaly can be distinctively characterised in semantic terms.
The point concerning 11a can be made with greater force in respect of 12a, which can also be rendered normal by changing either a closed set item (12b) or an open set item (12c).
In this case it is clearer, because of the greater number of possibilities, that the substitutes for table which normalise the sentence (lit ,buffet ,journal ,balcon , etc.) have no common semantic properties which distinguish them from items (such as chaise ,bibliothèque ,revue ,assiette ) which do not remove the oddness:
It is also significant that the oddness of 9a can be reduced by modifying table semantically:The table with the electronic eye saw Arthur (we know that it is the meaning of the modifying phrase which is important because the reduction in oddness depends on the open set items the phrase contains — compare The table with the melamine top saw Arthur ); no similar modification of bake in 11a, or table in 12a, can reduce the degree of deviance of these sentences.
We are now in a position to re-formulate our criteria for deciding whether an anomalous sentence is semantically or grammatically deviant:
(i) an anomaly which can only be removed by replacing one or more open set items is semantic;
(ii) an anomaly which cannot be removed by replacing one or more open set items, but can be removed by changing one or more closed set items, is purely grammatical;
(iii) an anomaly which can be cured either by changing one or more closed set items or by replacing one or more open set items is semantic (albeit with grammatical implications) if the open set replacements are distinguished by the possession of certain semantic properties; otherwise, it is purely grammatical.
The concept of normalisability also forms the basis of a rather different way of determining whether an anomaly has a grammatical or semantic origin.
Without tampering with the deviant sentence itself, we can investigate the effects of placing it in variously elaborated discourse contexts.
If, by contextual manipulation, we can reduce the apparent oddness, or at least cause it to be perceived as communicatively appropriate, then we can take it that we are dealing with a semantic deviance (although the involvement of grammatical elements cannot be ruled out).
A purely syntactically ill-formed sentence, on the other hand, is irredeemably deviant, and the only contexts which can accommodate it are those which induce a tolerance for grammatical incompetence or, at any rate, nonconformity:
As my two-year-old son said the other day: ‘…’
As our Portuguese plumber remarked: ‘…’
A poetic context can also condition the reader or hearer to accept grammatical deviance, especially if syntactic well-formedness is clearly being sacrificed to some higher aesthetic end, such as the maintenance of rhyme, or metre, or some other patterning.
The difference is that whereas a syntactic deviance may be tolerated, only a semantic deviance can be directly interpreted.
A syntactically deviant sentence can be interpreted only by reference to a non-deviant sentence: a speaker, in other words, is not free to create his own grammar.
Another way of formulating this criterion is to say that only a semantic deviance can be taken as a ‘figure of speech’.
By this test, sentence 2 is clearly grammatically odd — no context can improve it.
Likewise, 13:
13.
The old peasant's only possessions were three goat.
Sentence 9, on the other hand, can be seen as a sort of ironic hyperbole:
Arthur is paranoiac.
He believes all his accidents are due to a cosmic conspiracy.
No doubt the table saw him, computed his path across the room, and placed itself just where he would trip over it!
This is therefore a semantic oddity, according to the test.
(A fairy-tale or science-fiction context could also normalise it.)
What of sentence 1?
It can be construed figuratively.
Imagine a newly discovered plant, whose leaves when dried and smoked cause a temporary loss of memory; imagine, too, that it is highly addictive…
I am irresistibly drawn to a magnetic puff of amnesia .
Even a sentence like I finished mine tomorrow morning can be contextualised so as to present itself in the guise of a jocular paradox:
A: Have you all finished the jobs you were assigned?
B: Er…yes.
Tom and Dick finished theirs yesterday; Bill and Arthur finished this morning; and I…er…well, I finished mine tomorrow morning, I promise!
Notice that the two tests agree pretty well in their diagnoses, except that the contextualisation test reveals only syntactic deviance in sentences like 7, since they resist normalisation.
Objections can be raised to both these tests, and trickier examples unearthed.
What seems indisputable, however, is that there are good grounds for attempting a separation of meaning and grammar.
Furthermore, enough insight has been achieved in mapping their respective domains to allow us henceforth to set the problem of demarcation to one side.
1.3 The data of semantics
Any empirical study (a category to which lexical semantics, as outlined in this book, undoubtedly belongs) must rest, at some point, on a body of primary data, whose factuality is not questioned, and which is not subjected to further analysis.
For a study of lexical semantics, there would seem to be two principal sources of primary data; needless to say, the native language-user is central to both of them.
One source is the productive output, spoken or written, of native users of the language.
Clearly much insight into word-meaning is to be gained by observing the ways in which words are strung together by competent practitioners of a language.
However, the approach has its limitations.
Semantics done this way has more of the character of an ‘observational science’, like geology, than that of an ‘experimental science’, such as physics or chemistry.
Scientists of the former type are, in a sense, at the mercy of the phenomena they study; what happens, and when, and under what conditions is largely beyond their control.
An experimental scientist, on the other hand, arranges matters so that what happens will give him the greatest possible amount of information.
Not surprisingly, the experimental sciences advance more rapidly than observational sciences, and achieve more sophisticated hypotheses and, ultimately, theories within a shorter space of time.
A good example of this imbalance can be seen in psycholinguistics, where the study of language comprehension, being more experimental, is markedly more advanced than the study of language production, in which the investigator has less control over what happens.
Probably the most disadvantaged researchers in this respect in the field  of linguistic semantics are those who study ‘dead’ languages.
Often virtually the only direct evidence available to them is a corpus of written utterances, of somewhat fortuitous make-up, and now probably fixed for eternity.
Speakers' utterances can be made semantically more informative if the investigator is able to constrain their production in various ways — for instance, by elicitation in tightly controlled situational contexts.
An example might be to show informants a series of drawings, models, or other stimuli, and ask them to name them.
If the materials are properly prepared and used, the procedure can have all the advantages of an experimental study.
It is not, however, ideal as a general methodology for lexical semantics: it is far too cumbersome, many areas of meaning do not lend themselves to illustration in this fashion and, in any case, production only taps active competence.
The second principal source of primary data on which a study of lexical semantics can be based is furnished by intuitive semantic judgements by native speakers of linguistic materials of one kind or another.
The investigator can, of course, exercise full control over the nature of these materials, and is thus in a position to elicit whatever information he needs.
In essence, this is the strategy we shall adopt (except that the reader will be invited to act as his own informant: we shall not be concerned with problems and methods of field investigation).
Two important questions arise from this decision.
The first is: what sort of linguistic items should native speakers be asked to pass judgement on?
The second is: what sort of judgements should they be asked to make?
It might seem obvious that, if one is studying word-meanings, one ought to find native speakers' intuitions concerning the meanings of words the most informative.
However, this is not so.
We shall inquire presently whether we should ask informants what things mean; let us first consider whether words are the most appropriate items of language on which to elicit judgement.
As a matter of fact, there is no reason why language-users should be specially attuned to the semantic properties of words.
We do not communicate with isolated words; words are not the bearers of messages; they do not, of themselves, ‘make sense’; they cannot, taken singly, be true or false, beautiful, appropriate, paradoxical or original.
A linguistic item must in general have at least the complexity of a simple sentence to show such properties.
Words contribute, via their own semantic properties, to the meanings of more complex units, but individually they do not occasion our most vivid and direct experiences of language.
We communicate with utterances; it seems reasonable to suppose, therefore, that  our intuitions concerning utterances will be sharper, clearer and more reliable than those concerning individual words.
Consequently, in this book arguments about the meaning of a word will be made to rest, as far as possible, on facts concerning utterances which contain the words in question.
The intuitions most relevant to a study of meaning would seem at first sight to be intuitions about what things mean.
However, the reader is invited to try to formulate an explanation of the differences in meaning between the members of the following pairs of sentences:
14a.
He watched it with intense concentration for a few moments, then left the room.
b.
He looked at it with intense concentration for a few moments, then left the room.
15a.
However, she got the job in the end.
b.
Nevertheless, she got the job in the end.
It is safe to predict that many will find this task quite difficult.
The fact seems to be that the ability to ‘explain' meanings is an uncommon skill.
This is not to suggest that the average speaker of English does not understand the differences of meaning.
But it does appear that asking people what things mean is not necessarily the best way of tapping their semantic knowledge.
How, then, is this to be done?
The answer is to elicit not intuitions OF meaning, but intuitions ABOUT meaning, which, although they are one step removed from the primary object of interest, can, if properly chosen, be clear and reliable.
Not all ‘secondary semantic intuitions’ are equally suitable as a basis for semantic analysis.
Suppose, for example, one asks whether 16a and b have precisely the same meaning:
16a.
The reign of William V commenced in the year 1990. b.
The reign of William V began in the year 1990.
In a typical class of linguistically innocent students, some will reply ‘Yes,’ some ‘No,’and most of the rest will be unable to make up their minds.
Whether two expressions do or do not mean the same is a matter of some importance, but, again, it is evidently not something we should expect informants to tell us directly.
What the most appropriate intuitions are, and how they are best used, form the topics of the next section.
1.4 Disciplining intuitions
No empirical science can operate without human intuitive judgement intervening at some point.
This may be no more than a judgement  of which line on a graduated scale a movable needle is nearest to.
Equally, science would be much less advanced than it is if the only available data were intuitive estimates of quantities.
What would be the chances of arriving at the principle of a constant coefficient of expansion in metals (the notion that for a given metal there is a fixed relationship between amount of change of temperature and amount of change of length) if the only data to hand concerning temperature and length were estimates based on unaided touch and sight?
Although we can judge and compare lengths and temperatures to some extent, our naked intuitions of these properties are simply not accurate or reliable enough.
However, matters can be arranged so that the judgements required of human observers are only those which they can make reliably and accurately.
In studying the expansion of metals when they are heated, it is more profitable to limit the role of observers' intuitions to, for instance, judgements of the position of the top of a column of mercury relative to a graduated scale.
A parallel strategy is open to the semanticist.
The things we really want to know are too difficult for straightforward intuition; we must therefore ask our informants questions that they CAN answer reliably and accurately.
Unreliable, complex intuitions must be reduced to reliable, simple ones.
There is, of course, no inventory of appropriate intuitive judgements given in advance: candidates have to prove themselves by their effectiveness in analysis.
On the other hand, a fairly circumscribed set of possibilities suggest themselves.
The list offered here is not a closed one; the items put forward are simply those which have been found useful.
One of the simplest and most basic semantic judgements one can make concerning an utterance in one's native language is whether it is to some degree odd or not.
Extensive use will be made of normality judgements in the course of this book.
Each of the following pairs of sentences illustrates a difference of normality:
17a.
? This is a club exclusively for married bachelors. b.
This is a club exclusively for married men.
18a.
? Kicking with the feet incurs a penalty of 25 points.
b.
Kicking with the left foot incurs a penalty of 25 points.
19a.
? Let's sit by the stream and have a drink of time.
b.
Let's sit by the stream and have a drink of tea.
20a.
? The ant devoured the buffalo.
b.
The ants devoured the buffalo.
21a.
? We took the door off its hinges then went through it.
b.
We smashed the window then climbed through it.
Informants cannot, of course, be expected to quantify degrees of abnormality; but what they can do is distinguish a fully normal sentence from one which is to some degree odd.
They can also very often rank sentences in order of normality.
The sentences in 22 and 23 are arranged in order of normality:
22a.
It's tea-time for my pet rabbit.
b.
It's tea-time for my pet scorpion.
c.
It's tea-time for my pet amoeba. 23a.
The harpsichord needs re-tuning. b.
The jam-jars need re-tuning. c.
The banana needs re-tuning.
It perhaps ought to be pointed out here that an odd sentence is not necessarily meaningless, or incapable of conveying a message; nor is it the case that such sentences never occur naturally.
On the contrary, an oddness of one sort or another is frequently a signal that an expression is being used creatively, in a novel extension of its usual sense.
A great deal can be done using only an undifferentiated notion of abnormality, especially in conjunction with suitable ‘diagnostic frames’(see below); but it will not have escaped the notice of the attentive reader that the (a) sentences in 17–21 above are all odd in different ways.
Perhaps, therefore, a more delicate and sophisticated analysis would be possible if different types of oddness were recognised?
The following are the principal varieties of semantic anomaly which can be easily recognised by direct intuition.
As potential primitive terms, not to be subjected to further analysis, they are here defined ostensively, that is to say by exemplification:
A.
Pleonasm Kick it with one of your feet.
A female mother.
He was murdered illegally.
B.
Dissonance Arthur is a married bachelor.
Let us drink time.
Pipe…ditties of no tone.
(Keats:Ode on a Grecian Urn ) Kate was very married.
(Iris Murdoch:The Nice and the Good )
C.
Improbability The kitten drank a bottle of claret.
The throne was occupied by a pipe-smoking alligator.
Arthur runs faster than the wind.
D.
Zeugma They took the door off its hinges and went through it.
Arthur and his driving licence expired last Thursday.
He was wearing a scarf, a pair of boots, and a look of considerable embarrassment.
Intuitive judgements of the kind listed above are undoubtedly more informative than gross judgements of abnormality.
However, the more subtle the judgement, the greater the dangers inherent in reliance on unaided intuition.
Many instances of abnormality fall clearly into one or other of the four types; but, equally, there are certain uncertainties of application.
Prudence might suggest that we should dispense with subdivisions of oddness: they are not needed, for instance, in connection with most diagnostic frames (see below).
However, it would be a pity to ignore a potentially valuable source of information, and, in fact, some use will be made of them.
It is a matter of normal practice in the natural sciences for the human judgement involved in a measurement to be only indirectly related to the variable property which is the primary focus of interest.
In measuring temperature, for instance, one uses a thermometer, in which temperature is reflected in the length of a column of mercury in a glass tube; the length of the mercury column, in turn, is estimated by lining up the mercury meniscus with one of a set of lines engraved on the glass.
It is this last operation which is performed by the human observer, using only the equipment he was born with.
A transformation is carried out by the measuring instrument: it can be viewed as a device for converting properties that unaided human intuition cannot deal with into ones that it can.
The use of litmus paper furnishes another example of such a transformation.
Humans are not very sensitive to the acidity or alkalinity of liquids, but they are perfectly capable of deciding whether a piece of red paper has turned blue, or vice versa.
There is a parallel to this process of transformation in semantic analysis.
By the use of what will be called ‘diagnostic frames’, semantic properties we wish to diagnose, but cannot leave to naked intuition, are converted into properties concerning which straightforward intuitive judgements are relatively reliable.
Consider the frame Xs and other Ys .
This can be used, in the manner of litmus paper, for  the diagnosis of a particular relation between X and Y (relations of this sort are discussed in chapter 4).
The judgement required of the informant is one of normality:
dogs and other cats (odd) animals and other dogs (odd) dogs and other animals (normal)
A very useful intuition for semantic analysis is that of entailment .
A proposition P is said to entail another proposition Q when the truth of Q is a logically necessary consequence of the truth of P (and the falsity of P is a logically necessary consequence of the falsity of Q).
Although the fundamental relation of entailment holds between propositions, we shall use the term to refer to an analogous relation between sentences.
A sentence like That's a dog can be used to express an indefinitely large number of propositions (every distinct referent for that creates a different proposition).
When it is said (as we shall say) that the sentence That's a dog entails the sentence That's an animal , what is meant is that in any conceivable situation in which That's a dog can (with appropriate reference) express a true proposition, there exists a corresponding proposition (i.e. with no change in the referents of referring expressions) expressible by That's an animal , whose truth is a necessary consequence of the truth of the first proposition.
The intuition of entailment can be used directly, and it will be so used in this book.
But it is arguable that its deepest roots are to be sought in patterns of normality and abnormality in a family of ordinary language expressions (which could be formulated as a set of diagnostic frames).
Thus the statement that That's a dog entails That's an animal can be viewed as a kind of shorthand for a pattern of normality like the following:
It can't possibly be a dog and not be an animal.
It's a dog therefore it's an animal.
If it's not an animal, then it follows that it's not a dog.
? It's a dog, so it must be a cat.
? It's not an animal, but it's just possible that it's a dog.
? It's a dog, so it might be an animal.
etc.
The most interesting entailments from the point of view of lexical semantics are those which hold between sentences which differ only in respect of the lexical fillers of a particular syntactic slot (e.g. It's a dog ,It's a cat ;It's a rose ,It's a flower ).
In appropriate cases, the logical relations  between the sentences can be correlated with meaning relations between the differentiating lexical items.
The intuition of entailment may be used to establish four logical relations between sentences:
1.
Unilateral entailment:It's a dog unilaterally entails It's an animal 
2.
Mutual entailment, or logical equivalence:The meeting began at 10.00 a.m. entails and is entailed by The meeting commenced at 10.00 a.m.
3.
Contrariety:It's a cat and It's a dog stand in a contrary relation:It's a cat unilaterally entails It's not a dog 
4.
Contradiction:It's dead and It's alive stand in a contradictory relation:It's dead entails and is entailed by It's not alive (and It's alive entails and is entailed by It's not dead ).
Another useful and reliable intuition is that of recurrence of semantic contrast, or semantic proportion.
For instance, speakers are well able to judge that the contrast between 24a and b is the same as that between 25a and b, but different from that between 26a and b, and 27a and b:
24a.
I like him.
b.
I dislike him.
25a.
They approved of the idea.
b.
They disapproved of the idea.
26a.
We appointed her.
b.
We disappointed her.
27a.
You must embark now.
b.
You must disembark now.
This, too, will be used as an elementary intuitive judgement (especially in chapters 2 and 5).
But it is a relatively complex judgement, and, like entailment, will probably prove to be derivable from more elementary intuitions (e.g. from patterns of normality and abnormality), although it is not at present clear how this is to be done.
1.5 The meaning of a word
It is taken as axiomatic in this book that every aspect of the meaning of a word is reflected in a characteristic pattern of semantic normality (and abnormality) in grammatically appropriate contexts.
That which  is not mirrored in this way is not, for us, a question of meaning; and, conversely, every difference in the semantic normality profile between two items betokens a difference of meaning.
The full set of normality relations which a lexical item contracts with all conceivable contexts will be referred to as its contextual relations .
We shall say, then, that the meaning of a word is fully reflected in its contextual relations; in fact, we can go further, and say that, for present purposes, the meaning of a word is constituted by its contextual relations.
In its basic form, this conception of the meaning of a word is of limited usefulness: much important information concerning word-meaning remains, as it were, latent.
The picture can be made more revealing and informative in various ways.
For instance, we can picture the meaning of a word as a pattern of affinities and disaffinities with all the other words in the language with which it is capable of contrasting semantic relations in grammatical contexts.
Affinities are of two kinds, syntagmatic and paradigmatic.
A syntagmatic affinity is established by a capacity for normal association in an utterance: there is a syntagmatic affinity, for instance, between dog and barked , since The dog barked is normal (a syntagmatic affinity always presupposes a particular grammatical relationship).
A syntagmatic disaffinity is revealed by a syntagmatic abnormality that does not infringe grammatical constraints, as in ?
The lions are chirruping .
Paradigmatically, a semantic affinity between two grammatically identical words is the greater the more congruent their patterns of syntagmatic normality.
So, for instance,dog and cat share far more normal and abnormal contexts than, say,dog and lamp-post :
Arthur fed the dog/cat/? lamp-post.
The dog/cat/? lamp-post ran away.
The? dog/? cat/lamp-post got bent in the crash.
We painted the? dog/? cat/lamp-post red.
An extremely useful model of the meaning of a word, which can be extracted from the contextual relations, is one in which it is viewed as being made up, at least in part, of the meanings of other words.
A particular word-meaning which participates in this way in the meaning of another word will be termed a semantic trait of the second word.
To render this picture more informative, it is necessary to distinguish degrees and modes of participation.
We shall do this initially by defining a number of statuses (degrees of necessity) of semantic traits:criterial ,expected ,possible ,unexpected and excluded .
Criterial and excluded traits can be diagnosed by means of entailment  relations between sentences: for instance, ‘animal’ is a criterial trait of dog because It's a dog entails It's an animal ; ‘fish’is an excluded trait of dog because It's a dog entails It's not a fish .
For the diagnosis of expected, possible and unexpected traits, the but -test is extremely useful.
This utilises the normality or abnormality of sentences of the form P, but Q .
Consider the status of ‘can bark’ as a trait of dog.
First of all,It's a dog does not entail It can bark (since a dog may have a congenital malformation of the larynx, or some such); hence, ‘can bark’ is not a criterial trait.
However, the following two sentences show it to be an expected trait:
28.
It's a dog, but it can bark.
(odd) 29.
It's a dog, but it can't bark.
(normal)
The sort of oddness exhibited by 28 may be termed expressive paradox , since the expressive meaning carried by but is inappropriately deployed.
The pattern of oddness is reversed in 30 and 31, showing that ‘can sing’ is an unexpected trait of dog :
30.
It's a dog, but it can sing.
(normal sentence, unusual dog) 31.
It's a dog, but it can't sing.
(expressive paradox)
(It is of course necessary to ascertain that ‘can sing’ is not an excluded trait of dog ; the fact that It's a dog does not entail It can't sing confirms this.)
A possible trait is signalled when both test sentences exhibit expressive paradox, and P and Q is normal:
32.
It's a dog, but it's brown.
(Why shouldn't it be?) 33.
It's a dog, but it isn't brown.
(Why should it be?) 34.
It's a dog and it's brown.
(normal)
At first sight, the picture of word-meaning given by patterns of affinity and disaffinity is, at least in some respects, different from the picture given by semantic traits.
For instance,cat and dog have a fairly high degree of paradigmatic affinity, as they are equi-normal in a wide range of contexts:
I stroked the cat/dog.
We have a cat/dog at home.
The cat/dog died.
The children love the cat/dog.
But ‘cat’ is an excluded trait of dog , since It's a dog entails It's not a cat .
The two pictures are not, however, incompatible, they merely highlight  different aspects of meaning.
The affinity between dog and cat reveals itself in the number of equi-status or near-equi-status traits they have in common; and the differences between dog and cat appear more sharply when the affinity patterns are articulated in greater detail by means of diagnostic frames.
Although we have distinguished five discrete statuses, it must be borne in mind that the reality being described is a continuum — any discreteness is an artefact of the definitions.
This is true even within the statuses that we have chosen to define by means of entailment.
Probably most speakers of English would accept both of the following entailments:
It's a triangle entails It has three angles Lesley is Arthur's mother entails Lesley is female 
Although we shall continue to regard ‘three-angled’ as a criterial trait of triangle and ‘female’as a criterial trait of mother , it must be conceded that there is a palpable difference in the degree of necessity of these two traits.
A four-angled triangle is totally inconceivable — but a male mother?
Is it beyond imagination, in these days of biological engineering, to conceive of a time when embryos will be implanted in a man's body, and develop, and be born — perhaps by caesarian section?
Surely not TOTALLY?
No systematic use will be made here of a ‘more criterial'/'less criterial’ distinction.
However, there is a distinction that can be made within ‘expected’ status which is of some significance in lexical semantics.
Consider the relation between ‘adapted for flight’ as a semantic trait of bird , and ‘possesses four legs’as a trait of dog .
They are alike in that neither is criterial, both are expected:
It's a bird does not entail It is adapted for flight 
(There are birds such as the ostrich and the kiwi which are not adapted for flight.)
It's a dog does not entail It has four legs 
(A dog may have a birth abnormality, or may lose a leg in an accident.)
It's a bird, but it's adapted for flight.
(odd) It's a bird, but it's not adapted for flight.
(normal) It's a dog, but it has four legs.
(odd) It's a dog, but it doesn't have four legs.
(normal)
There is, however, a difference in the status of these two traits.
There is a sense in which a dog ought to have four legs — if it does not, it is  imperfect, ill-formed, not fully functional.
There is no recognised sub-category of dogs for which the possession of a number of legs other than four is the norm (as there is a sub-category of cats for which the absence of a tail is the norm).
Species of birds which are not adapted for flight, on the other hand, are not ill-formed — they are merely atypical.
Semantic traits whose absence is regarded as a defect will be called canonical traits .
Canonical traits can be distinguished from non-canonical expected traits in a number of ways:
?
The typical dog has four legs.
? Dogs typically have four legs.
The typical bird is adapted for flight.
Birds are typically adapted for flight.
? A dog that does not have four legs is not necessarily defective.
A bird that cannot fly is not necessarily defective.
? What kinds of dog have only three legs?
What kinds of bird are not adapted for flight?
Canonical traits are not only to be found in words denoting living things.
We could say, for instance, of le table ronde that it lacked a canonical trait of noun phrases in French, namely, concord in respect of gender.
Likewise, a command enjoining some action which was logically impossible, or which had already been carried out, or a lie that through ignorance on the part of the perpetrator turned out to be objectively true, can both be considered defective through the lack of a canonical trait.
The adoption of the contextual approach to word-meaning outlined in this chapter has certain inescapable consequences that some might consider to be disadvantages.
One is that any attempt to draw a line between the meaning of a word and ‘encyclopaedic’ facts concerning the extra-linguistic referents of the word would be quite arbitrary; another is that there is no motivation for isolating ‘pragmatic meaning’as a separate domain of lexical meaning.
Perhaps most importantly, it would seem that we have no grounds for believing that the meaning of a word, when viewed in this fashion, is finitely describable — without severe circumscription it is an unpromising candidate for formalisation, or representation in terms of logical or quasi-mathematical formulae.
However, our conception of word-meaning has the advantage of being intuitively plausible: its scope coincides well with the pre-theoretical notion of word-meaning that anyone with a practical interest in meaning — a lexicographer, translator, or language teacher, or even a novelist or poet — is likely to have.
Unwieldy it may be in certain respects, but it is surely better for a model of meaning  destined to serve a descriptive as opposed to a theoretical study to err on the side of generosity of scope, rather than on the side of austerity.
While the contextual method is well-suited to the exploration of the infinite subtlety and particularity of word-meanings, it is nonetheless more particularly the aim of this book to seek out and highlight anything which lends itself to generalisation, even of a limited sort, any tendency towards structure, system and recurrence, in the domain of word-meaning.
2
The syntagmatic delimitation of lexical units
2.1 Introductory
Now that we have the outline of an approach to the study of the meanings of words, we can turn our attention to the task of providing a more exact characterisation of the linguistic units which will form the objects of our study.
As a beginning, it may be said that the conception of a lexical unit which will be adopted here is not very different from that of a traditional lexicographer, although we shall try to be more explicit than lexicographers are wont to be.
An ordinary dictionary characterises a lexical item in three distinct, though intimately inter-connected, ways: first, its form (graphic and phonological); second, its grammatical function; and, third, its meaning.
Correspondingly, we shall have to consider three aspects of the delimitation of a lexical item.
First of all, we must delimit the form of a lexical item syntagmatically; that is to say, we must be able to state in any sentence where the boundaries between lexical items are (we shall assume that any well-formed sentence consists of a whole number of such units).
Second, having set up syntagmatic units, we shall observe that many of them appear to operate in a variety of grammatical environments, and we shall have to ask ourselves whether some differences of grammatical usage of a particular form do not merit recognition as separate lexical items.
Take, for instance, the word form open :The Concise Oxford Dictionary (C.O.D.)
has two separate main entries for this, corresponding to its occurrence in The sky-light was open and The duchess refused to open the safe .
Lest anyone should think that the matter is totally unproblematical, it is perhaps worth pointing out that the same dictionary gives no separate recognition to the parallel occurrences of shut .
Finally, it is clear that besides having a variety of grammatical uses, a word form may well display a split semantic personality, too, even within a constant grammatical frame.
Consider bank in We finally reached the bank .
There is here a choice of readings which is in some ways not so very different from the sort of choice available in 
John saw the cat carpet cushion etc.
There is, of course, one important difference, namely, that in the latter case the meaning options are paralleled by differences of form, and so it is easy to individuate and enumerate the elements from which the choice must be made.
However, there is at least a prima facie case for believing that a word form like bank should be considered to represent more than one lexical unit.
The criteria for deciding how many lexical units we are dealing with in cases like open and bank will be discussed in chapter 3.
The principal concerns of the present chapter are the criteria for establishing lexical units syntagmatically, and to these we now turn.
The basic syntagmatic lexical units of a sentence will be defined as the smallest parts which satisfy the following two criteria;
(i)
a lexical unit must be at least one semantic constituent
(ii)
a lexical unit must be at least one word.
These criteria need careful elaboration, but the following will serve as a preliminary illustration of the points:
— the prefix dis — of disobey is not a lexical unit because, although it is a semantic constituent, it is smaller than a word.
— the pulled of Arthur pulled a fast one is not a lexical unit because, although it is a word, it is not a semantic constituent.
Let us now examine the notion of semantic constituent.
2.2 Semantic constituents
The meaning of a typical sentence in a natural language is complex in that it results from the combination of meanings which are in some sense simpler.
(The fact that the meanings of sentences are more accessible to intuition than the meanings of words does not alter this.)
These simpler meanings (which does not necessarily mean ‘simple’) are carried by identifiable parts of the sentence; and the way they must be combined to yield the global meaning of the sentence is indicated by the syntactic structure of the sentence.
Thus, the meaning of The cat sat on the mat is ‘the’ + ‘cat’+ ‘sat’+ ‘on’+ ‘the’+ ‘mat’, combined in the ways signalled by the syntactic structure, which tells us, for instance, that ‘on’goes with ‘the mat’, rather than with ‘the cat’, and so on .
The syntactic structure also defines intermediate complexes, such as‘the cat’ and ‘on the mat’, which, when appropriately combined, yield the global meaning of the sentence, but which themselves can be decomposed into more elementary parts.
Any constituent part of a sentence that bears a meaning which combines with the meanings of the other constituents to give the overall meaning of the sentence will be termed a semantic constituent .
A semantic constituent which cannot be segmented into more elementary semantic constituents will be termed a minimal semantic constituent .
Thus on the mat is a semantic constituent of the cat sat on the mat , but not a minimal one, as it ultimately divides further into the ,on and mat ; the latter, on the other hand, are incapable of further subdivision, and are therefore minimal semantic constituents.
Notice that the term semantic constituent is not used to refer to a meaning only, but to a form-plus-meaning complex; that is to say, a semantic constituent is a meaningful form (the precise sense of meaningful intended here will be clarified below) with a determinate grammatical function.
In most cases it is immediately clear what the semantic constituents of a sentence (or part thereof) are.
But to be able to handle borderline or other problematic cases with any degree of confidence we need a firmer characterisation, grounded in more basic intuitive judgements of the kind introduced in the previous chapter.
However, before going on to propose a test for semantic constituency, it might be useful to clarify the notion further in an informal way.
An important indication (although, as we shall see, not a sufficient one) that a portion of a sentence is a semantic constituent is that its semantic contribution to the sentence is the same as that which it makes to other, different sentences; in other words, it carries what is in some sense a constant meaning from context to context.
Consider sacks in the following sentences:
1.
The sacks had been hung out to dry.
2.
A woman was repairing sacks.
3.
Everywhere there were sacks full of potatoes.
Sentences 1, 2 and 3 all contain the meaning ‘sacks’; the only formal element they have in common is the graphic sequence sacks .
We can therefore be reasonably confident in identifying sacks as the bearer of the meaning ‘sacks’.
However, this is not sufficient to guarantee semantic constituency.
Take black in 4 and 5:
4.
A blackbird sang softly in the willow-tree. 5.
A black bird sang softly in the willow-tree.
Intuitively, it would be difficult to deny that there was a connection between the semantic contributions of black in the two sentences: blackness is not irrelevant to blackbirds (even if it is true that not all blackbirds are black)— this is proved by the normality of blackbirds, crows and other black birds .
Yet equally clearly there is a difference.
Put simply, the meanings of black and bird do not add up to the meaning of blackbird , but do yield that of black bird .
In other words,black in 4, although not devoid of meaning, is not a semantic constituent: it does not carry one of the set of simpler meanings which on combination yield the global meaning of the sentence.
To arrive at the overall meaning of 4,blackbird must be taken as a minimal semantic constituent.
On the other hand,black is, of course, a semantic constituent of 5.
An important diagnostic test for semantic constituency, and one which utilises one of the basic intuitive judgements introduced in the previous chapter, is the test of recurrent semantic contrast .
Suppose we take our previous sentence The cat sat on the mat and substitute for one of its constituent parts,cat , a different, but syntactically identical, element such as dog .
The result of this substitution is of course change in the meaning of the sentence.
Now it so happens that we can make the same substitution of forms in an otherwise completely different sentence, producing an exactly parallel change of meaning:
This test precisely locates the form responsible for a given meaning, and at the same time ensures that its role is that of a semantic constituent; from 6 we can therefore conclude that cat is a semantic constituent of The cat sat on the mat .
Observe now what happens when we attempt to set up an equation like 6 using a portion of a sentence which is clearly not a semantic constituent.
Suppose we replace the —at of mat by —oss .
The result is certainly a change of meaning:The cat sat on the moss ; but in this case it is impossible to find a different sentence in which the same substitution of forms produces a parallel change of meaning.
In other words, we cannot show a recurrent semantic contrast, although it is, of course, possible to find sentences where the substitution of forms can be made without a recurrence of the semantic contrast:
It may be thought that in 8 we have an equation which indicates (wrongly) that —at is a semantic constituent:
It is true that 8 exemplifies a recurrent semantic contrast, but this is possible only because of the presence of m — in both sentences.
It is essential, in carrying out the test, to use sentential frames which ideally do not share any elements (although in practice it is usually sufficient if the immediate pre- and post-environments of the substituted items are distinct).
It is also important that the substituted items should belong to the same syntactic class; that is, there should be no change in the syntactic structure of the frame as a result of the substitution.
The reason for this is that we want to be able to attribute all changes of meaning on substitution to differences in the semantic properties of the items being substituted.
We are now in a position to spell out precisely the basic form of the recurrent contrast test for semantic constituency:
A part X of a grammatically well-formed and semantically normal sentence S; is a semantic constituent of S 1 if
(i)
X is either omissible or replaceable by some other element Y, yielding a grammatically well-formed and semantically normal sentence S 1 which is syntactically identical to S 1 but distinct in meaning from S 1 
and (ii)
there exists at least one other grammatically well-formed and semantically normal sentence S 3 , containing X, but otherwise having no other elements in parallel syntactic positions in common with S 1 , in which X is similarly omissible or replaceable by Y, yielding a syntactically identical but semantically distinct sentence S 4 
and (iii)
the semantic contrast between S 1 and S 2 is identical to that between S 3 and S 4 .
Strictly speaking, only two sentential contexts are required to prove semantic constituency, but of course a constituent limited to only two specific contexts would necessarily play only a minor role in a language.
For a typical semantic constituent, there is an unlimited number of possible sentential frames.
Before going on to consider more problematic aspects of semantic constituency, let us look at a few more examples of the recurrent semantic contrast  test in action.
Take the prefix in — in inhale ,inconspicuous and impertinent .
For inhale and inconspicuous , the semantic constituency of in — is easily established, although the semantic identity of in — is different in the two cases:
(Here,in — and im — represent the same grammatical element: the prefix merely adapts itself phonetically to the initial consonant of the root.)
Turning now to impertinent , we can readily see that although the im -is replaceable by zero, it does not qualify as a semantic constituent:
It is not possible to discover even one other sentential context in which the im — /zero alternation can reproduce the contrast we find with impertinent .
This means that unless the im — of impertinent can be ‘rescued’ by any of the procedures detailed in the next section (and, in fact, we shall find that it cannot), it fails to satisfy the criteria for semantic constituency.
Those who detect a ‘negative emotive force’ in the (apparent) negative prefix not only of impertinent , but also of impudent ,indignant ,indifferent and possibly inane (in none of which is it a true semantic constituent), may be reluctant to accept this result.
However, as we shall see, it is necessary to recognise several ‘lesser’ semantic roles besides the central one of being a semantic constituent, so that to deny semantic constituency to an element is not necessarily to deny it any semantic role whatsoever: the ‘negative emotive force’can, in fact, be accommodated.
It was claimed earlier that black — in blackbird was not a semantic constituent; we can now verify the claim by subjecting it to the recurrent contrast test:
This example is useful for understanding how the test works.
If, in replacing black — in blackbird by blue —, one merely replaced ‘black’ by ‘blue’, then the contrast would be found to recur.
But at least some of the meaning of blackbird belongs to the whole complex, and is not attributable to either black — or bird separately; so, when black is replaced, this additional meaning is lost, along with‘black’.
Since the additional meaning is unique to blackbird , no recurrence of the resulting contrast is possible.
2.3 Semantic constituents which fail the test
The vast majority of items for which there is a strong intuition either of meaningfulness or meaninglessness respond in the appropriate way to the test of recurrent semantic contrast.
We may confidently say that the typical semantic constituent passes the test.
However, there are certain peripheral types of semantic constituent which cannot be directly subjected to the test.
This may be because they occur only in association with a particular element, like the cran — of cranberry , or because they occur with a particular semantic value only in the context of one other element, like the —en of oxen , the ab — of abnormal , or foot in foot the bill ; in a case of collocational uniqueness of either of these types, no contrast in which the unique element participates can be tested in a distinct linguistic environment.
Or a semantic constituent may be untestable because it is completely determined syntactically, like —ness in His kindness was overwhelming , and thus does not participate in any contrasts at all.
For some of these items — for instance,foot in foot the bill — there is a strong intuition of meaningfulness; for others, like cran —, intuition is less certain.
Clearly, some way of deciding is needed.
There are two principal strategies for proving that a collocationally unique item is a semantic constituent.
The first consists in demonstrating that the element in question participates in the same semantic contrast with a third element as a proven semantic constituent.
For the purpose of this test a contrast with zero is valid.
Take the —en of oxen : this contrasts with its own absence just like the —s of cows , and with a precisely parallel semantic effect:
The —s of cows can be shown to be a semantic constituent by the normal test:
From this it seems eminently reasonable to conclude that —en , too, is a semantic constituent.
Similarly, 15 and 16 show ab — in abnormal to be a semantic constituent:
The same technique can be used for foot in foot the bill and red in red hair , although perhaps marginally less convincingly.
The case for foot rests on the presumed equivalence of contrast between foot and query, in 17:
However, some may feel that there is more to footing a bill than merely paying it: there is a hint of reluctance, of the imposition of an unwelcome demand for money on the payer, which renders the equivalence of the contrasts in 17 slightly suspect.
Another way of approaching foot the bill will be suggested below.
The reason why red in red hair is unique is that the colour it refers to would not be labelled red if anything other than hair were being described.
(Current fashions make a ‘true’ red for hair not impossible, so that red hair is now ambiguous.
We are here discussing the more traditional usage.)
It is not an easy colour to describe, but let us assume that, say, a carpet the colour of red hair would be described as light reddish-brown .
We can then establish red as a semantic constituent via an equivalent contrast with black :
A slightly more oblique approach to the problem of determining whether a contextually unique item is a semantic constituent is to see whether it is normal in the language to treat it in parallel with unquestionable semantic constituents.
The most obvious type of ‘treating in parallel’ is  coordination: in general, a non-constituent cannot be coordinated with a constituent without oddness:
19.
? Arthur kicked the detonator of the bomb, and, consequently, the bucket.
The normality of the following sentences is therefore evidence that the collocationally unique elements gnash and purse are semantic constituents of the expressions gnash the teeth and purse the lips , respectively:
20.
He kept baring and gnashing his teeth.
21.
Samantha was pursing, licking and biting her lips.
The parallelism may be less transparent: in 22 foot and scrutinise have a parallel relation to bill , and in 23 foot and add up have a parallel relation to bill .
Scrutinise and add up are clear semantic constituents, so the parallelism is sufficient to establish foot as a semantic constituent too:
22.
Arthur agreed to foot the bill only after scrutinising it carefully first.
23.
I'm expected not only to foot the bills, but to add them up as well.
Certain uniquely determined grammatical elements present special problems.
Some clearly fail the recurrent contrast test, and rightly so.
For instance, the —s of books in those books does not contrast with anything, so there is no question of recurrence.
This is a correct result: semantically speaking, the element ‘plural’ occurs only once in the phrase those books .
Thus the —s here does not independently signal plurality, but only in conjunction with the exponent of plurality in those .
We may perhaps speak here of a discontinuous semantic constituent .
More difficult are elements like —ness in 24:
24.
His kindness amazed us all.
In spite of the fact that nothing can be substituted for —ness , and it therefore participates in no contrasts, recurrent or otherwise, it is different from —s in those books , and arguments can be put forward that it should be regarded as a semantic constituent.
One such argument runs as follows:kind — in 24 has normal recurrent contrasts (e.g. with cool —), and is thus a semantic constituent; so also is kindness — it contrasts, for instance, with hat ; since kind — is not synonymous with kindness ,—ness must signal the semantic difference between them.
The meaning(s) of —ness can, moreover, be glossed: ‘the degree to which (he was kind)’ or ‘the fact that  (he was kind)’; also, these meanings are recurrent — they appear also in coolness and foolishness (notice that if the two meanings had been signalled by two different affixes, there would be no problem about their status as constituents).
It would seem reasonable, in general, that if a sequence of elements AB can be shown to be a semantic constituent, and one of the parts of the sequence satisfies the recurrent contrast criterion, then the status of semantic constituent should be accorded to the remaining part of the sequence, even if it does not satisfy the recurrent contrast criterion.
This is the view we shall adopt.
2.4 Indicators, tallies and categorisers
There are several types of element which fail the straightforward version of the recurrent contrast test, and cannot be rescued by any of the strategies suggested in the previous section, but which cannot, unlike the —oss of moss , be dismissed as having no semantic relevance.
One type is exemplified by the cran —,bil —,rasp —,goose — of cranberry ,bilberry ,raspberry and gooseberry ; the bull — of bullfinch , the missel of missel thrush , the dor — of dormouse ; also the pad — of padlock and gang of gangway — and many more.
In none of these cases does either the first or the second element qualify as a semantic constituent:
Such semantic contrasts are impossible to duplicate; for the second elements of these words, it is usually impossible even to find a recurrence of the form contrast.
Where the elements are two separate words, the first can often be coordinated with other elements:
blue and hump-backed whales missel and song thrushes
However, this does not prove semantic constituency, because coordination is normal only with other elements of the same sort — i.e. elements which similarly fail the recurrent contrast test.
They do not coordinate with normal semantic constituents:
? blue and carnivorous whales
The expression herring and common gulls illustrates this point well, because it is normal if common is taken to identify a particular species of gull (in which case it is not a semantic constituent), but odd if it is taken to mean ‘not rare’.
It might be argued that the test procedure is thus  shown to be at fault, since in all the above cases the first element can be shown to have a clear semantic function relative to the second element: in fact, it signals a sub-variety of the general category denoted by the second element.
Thus, a raspberry is a type of berry, a bullfinch a type of finch, a dormouse a type of mouse, a padlock a type of lock, etc.
As proof, it is sufficient to point to the following entailment relations:
It's a bilberry unilaterally entails It's a berry 
It's a dormouse unilaterally entails It's a mouse 
However, let us consider, for instance,cranberry more carefully.
Granted that a cranberry is a variety of berry, what exactly does cran -mean?
It is a curious fact that native speakers are unwilling to attempt even an approximate gloss of the meaning of cran —, yet there is no such hesitation with foot in foot the bill .
Nor does cran — seem to carry any meaning into newly coined forms: we can make sense, for instance, of billy-giraffe and nanny-giraffe by analogy with billy-goat and nanny-goat , and also of foot the fees ; but creations like cranbeads and bilbeads convey nothing, although one might have expected some interpretation such as ‘small round red beads’ and ‘small round purple beads’.
The fact is that elements like cran — and bil — do not carry any meaning at all, in the normal sense — they merely distinguish; they are equivalent to numbered or lettered labels: ‘(berry) type A/type B/type C…’.
We shall call such elements semantic tallies and their partner elements which indicate a general category will be termed semantic categorisers .
A semantic tally in combination with a semantic categoriser constitutes a minimal semantic constituent.
All the semantic tallies we have considered so far have been what might be termed pure tallies , in that they have no perceptible semantic connection with any other elements in the language.
However, there exist many examples of semantic tallies which do have a clear semantic connection with normal meaningful elements, without themselves being semantic constituents.
Examples of this category are black — in blackbird ,blue in blue-tit , and red in red wine (it must not be thought that red here is merely a colour term: a red wine is a type of wine, whereas a red dress is not a type of dress).
This type of tally will be described as impure .
It would be useful to have a general term for elements which fall short of being constituents, but which nonetheless have a semantic function relatable to the meanings the same forms carry when they are semantic constituents.
We shall call these semantic indicators .
A distinction may be made between full indicators , which retain the whole of their normal  constituent meaning, like black — and —bird in blackbird (it is true that female blackbirds are brown, but black — here still relates to ‘black’, which is a salient characteristic of the species), and partial indicators , like —house in greenhouse (a greenhouse is not a house; but, like a house, it is a building).
As we have defined it, the category of semantic indicator overlaps with that of semantic tally, impure tallies being those which are at the same time indicators (full or partial); it includes that of semantic categoriser — a categoriser is necessarily a full indicator.
We can perhaps include in the category of semantic indicator such cases as the dis — of disappoint ,disgust ,dismay , etc., and the im — of impertinent ,impudent , etc., if the former is felt to be related to the dis — of dislike and disapprove , and the latter to the im — of impolite ; the segments —appoint ,—gust ,—may ,—pertinent and —pudent have no discernible semantic function, and do not need a label.
2.5 Phonetic elicitors of semantic traits
The vast majority of meaningful elements in a language, whether they are full constituents or have some lesser status, are at the same time grammatical elements.
Since the principal function of grammar is to indicate how units of meaning are to be combined, this is scarcely surprising.
But there are some phonetic sequences which seem to have semantic value of a sort, yet they do not correspond to grammatical elements: there seems to be a direct pathway from sound to meaning, bypassing grammar.
Such elements are of two kinds.
Firstly there are what are usually termed onomatopoeic phonetic sequences: with these it is often difficult to define their exact limits.
The following are examples of words which contain (and in some cases, perhaps consist of) onomatopoeic sequences:hum ,buzz ,hiss ,gong ,splash ,crack ,whip ,bump ,clank ,tinkle ,hoot ,coo ,miaow .
Onomatopoeic words are held to ‘resemble’ their referents auditorially, but the degree of objective similarity may be very low (perhaps no lower, however, than the perceived visual resemblance between a cartoonist's representation of a political figure and its subject).
The second type of ‘meaningful’ phonetic sequence is exemplified by the initial consonant clusters in
(i)slimy ,sleazy ,slut ,slouch ,slovenly ,slob ,slattern ,slither ,slink , etc. (ii)glow ,glimmer ,gleam ,glisten ,glitter ,glare , etc. and possibly the vowel in (iii)coon ,goofy ,goon ,loony ,fool ,drool ,moon (around),noodle (fig.), etc.
This phenomenon is distinct from onomatopoeia — it is sometimes called sound symbolism : there is no question of auditory resemblance.
Although not all words containing these sounds manifest the (usually somewhat indeterminate) meaning, it is capable of transferring to new coinages.
For instance, a new breakfast food marketed under the brand name of SLUB would stand little chance of success; on the other hand, a flashing beacon called a GLEEPER (on the analogy of bleeper ) might have some chance of succeeding.
Sound symbolism is not just a matter of a certain number of words containing certain sounds happening also to fall into the same semantic area.
No meaning attaches, for instance, to the /ei/ vowel in plate ,plane ,plain ,pane ,blade ,table , etc., which all contain the semantic trait ‘flat’.
The phonetic sequences involved in either onomatopoeia or sound symbolism are clearly not to be considered semantic constituents.
It is generally difficult to find recurrent contrasts of form in which they participate, let alone recurrent semantic contrasts — and they do not respond to any of the rescue strategies.
We shall call them phonetic elicitors of semantic traits.
2.6 Words
Our discussion of semantic constituency has taken no account of whether the elements under consideration are parts of words, words, or sequences of words.
However, the second criterion for a lexical unit was that it should be ‘at least one word’.
We must now therefore examine what this entails.
A great deal of scholarly discussion has centred on the linguistic status of the word.
It would not be appropriate to review this in detail here.
For our purposes it will be sufficient to draw attention to two fairly general and constant characteristics of words across a wide range of languages.
The first is that a word is typically the smallest element of a sentence which has positional mobility — that is, the smallest that can be moved around without destroying the grammaticality of the sentence (ignoring any semantic effects):
John saw Bill.
Bill saw John.
Bill, John saw.
by no means all words are equally mobile in this sense, but with very few exceptions, the smallest mobile units are words.
The morphemes constituting a single word have a rigidly fixed sequential order: we find unwillingly but not lywillingun or unlywilling etc.
The second major characteristic of words is that they are typically the largest units which resist ‘interruption’ by the insertion of new material between their constituent parts.
Consider the following sentence, and observe where extra material can be inserted:
The possible insertion points clearly represent word-boundaries.
In a language such as Turkish, in which words composed of a relatively large number of basic grammatical units (morphemes) are common, this characteristic of words may seem less salient.
(Turkish, incidentally, also shows a very small degree of optionality in the order of morphemes within a word.)
Take, for instance, the word öl-dü (the morphemes of the word are separated for illustration).
This means ‘he/she/it died’, the final —dü indicating third person singular, past tense.
Quite a lot can be inserted between the root öl — and the past tense element, as the following word shows:
öl-dür-ül-e-mi-yecek-ti
(This can be translated as ‘He would be unable to be killed’: the final —ti represents the same morpheme as —dü ).
However, there is a marked difference in the degree of interruptibility between words and phrases.
In the Turkish example, although several grammatical elements can be inserted within the word, they are strictly determinate in number and identity; whereas between words, if one takes into account coordinations and parenthetical insertions, the possibilities are infinite.
This can be illustrated from English; Turkish is no different in principle:
HIS great courage and imperturbable COOLNESS in the face of what must at times have seemed to him to be insuperable odds WAS, I must confess — although I do not really like him — quite UNBELIEVABLE.
We shall not pursue the matter any further here.
it will be henceforth assumed that the typical unit of lexicology is the word (this statement is so obvious as to have an air of tautology).
However, there do exist, and not so uncommonly that they can be safely ignored, minimal semantic constituents which consist of more than one word.
To these we now turn.
2.7 Idioms
It has long been recognised that expressions such as to pull someone's leg ,to have a bee in one's bonnet ,to kick the bucket ,to cook someone's goose ,to be off one's rocker ,round the bend ,up the creek , etc. are semantically peculiar.
They are usually described as idioms .
A traditional definition of idiom runs roughly as follows: an idiom is an expression whose meaning cannot be inferred from the meanings of its parts.
Although at first sight straightforward, there is a curious element of circularity in this definition.
Does it indicate that the meaning of an idiom cannot be inferred from (or, more precisely, cannot be accounted for as a compositional function of) the meanings the parts carry IN THAT EXPRESSION?
Clearly not — so it must be a matter of their meanings in other expressions.
But equally clearly, these ‘other expressions’ must be chosen with care: in considering to pull someone's leg , for instance, there is little point in referring to pull in to pull a fast one , or leg in He hasn't a leg to stand on .
The definition must be understood as stating that an idiom is an expression whose meaning cannot be accounted for as a compositional function of the meanings its parts have when they are not parts of idioms.
The circularity is now plain: to apply the definition, we must already be in a position to distinguish idiomatic from non-idiomatic expressions.
Fortunately it is possible to define an idiom precisely and non-circularly using the notion of a semantic constituent.
We shall require two things of an idiom: first, that it be lexically complex — i.e. it should consist of more than one lexical constituent; second, that it should be a single minimal semantic constituent.
Consider 26:
26.
This will cook Arthur's goose.
The test of recurrent semantic contrast reveals that this ,will and Arthur are regular semantic constituents; the rest, however, i.e. cook —‘s goose , constitutes a minimal semantic constituent, which as a whole contrasts recurrently with, say,help or destroy .
Cook —‘s goose is therefore an idiom.
An idiom may be briefly characterised as a lexical complex which is semantically simplex.
We shall regard as non-idiomatic (or semantically transparent ) any expression which is divisible into semantic constituents, even if one or more of these should turn out on further analysis to be idioms.
Most idioms are homophonous with grammatically well-formed transparent expressions.
A few are not in this sense well-formed, although some grammatical structure is normally discernible.
Such cases, of which by and large and far and away are examples, are often called asyntactic idioms .
From our point of view, all idioms are elementary lexical units.
It is interesting that although idioms consist of more than one word, they display to some extent the sort of internal cohesion that we expect of single words.
For instance, they typically resist interruption and re-ordering of parts.
Some of the restriction of syntactic potential of idioms is clearly semantically motivated.
For instance, the reason that to pull someone's left leg and to kick the large bucket have no normal idiomatic interpretation is that leg and bucket carry no meaning in the idiom, so there is nothing for left and large to carry out their normal modifying functions on (in general , a modifier needs a semantic constituent to modify).
However, idioms also tend to resist interruption by material which, as long as it remains ‘outside’ the idiom, is semantically compatible:
27a.
Arthur apparently has a chip on his shoulder.
b.
? Arthur has a chip, apparently, on his shoulder.
28a.
After a shaky start, we took them to the cleaners.
b.
? We took them, after a shaky start, to the cleaners.
The same is true of re-ordering.
Many grammatical processes involving re-ordering of constituents are ruled out for semantic reasons, particularly those whose semantic function is to highlight a specific semantic constituent: thus,What John pulled was his sister's leg has no idiomatic reading, whereas What John did was pull his sister's leg , which leaves the idiom ‘physically’ intact, has.
But semantically innocuous re-orderings are also to some extent resisted:
29a.
John has a bee in his bonnet about it.
b.
? John has a bee about it in his bonnet.
At the same time, idioms show their status as phrases in various ways, too.
For example, if an idiom may be inflected, the inflectional affixes are carried by the grammatically appropriate elements within the idiom, whether or not they are semantic constituents; that is to say , the elements of an idiom retain at least some of their grammatical identity:
30a.
John has bees in his bonnet about many things.
b. *John has bee-in-his bonnets about many things.
Likewise, in certain regular grammatical re-formulations the parts of an idiom may behave as they would in a transparent expression: thus we have a leg-pull , formed on the same pattern as hand-shake .
For these  reasons, it would not be appropriate to assimilate idioms to the category of words.
The question of precisely which syntactic processes a particular idiom will undergo is an extremely complex one, and is not strictly relevant here.
In some respects it seems to be idiosyncratically determined, and in other respects predictable.
As a first approximation, we may say that an idiom's syntactic behaviour is broadly determined by two factors: the syntactic structure of the literal counterpart of the idiom (if it has one), and the fact that distinguishable syntactic constituents are not semantic constituents, and therefore are not open, for instance, to adjectival and adverbial modification, nor can they be isolated for emphasis, etc.
2.8 Degrees of opacity
A semantically non-transparent expression may be described as semantically opaque .
It is important to emphasise that, as we have defined it, transparency is the end-point of a continuum of degrees of opacity, much as ‘cleanness’ is the end-point of a continuum of ‘degrees of dirtiness’(see chapter 9).
We have located the decisive break in semantic character between ‘fully transparent’ and ‘to some degree opaque’, rather than between ‘completely opaque’and ‘not completely opaque’, as this groups together more satisfactorily elements with significantly similar properties.
The idea of semi-opaque expressions is already implicit in the notion introduced earlier of ‘semantic indicator’: a semi-opaque expression must contain at least one semantic indicator.
We must now be somewhat more precise concerning the concept of ‘degree of opacity’.
There would seem to be two components to this notion.
The first is the extent to which constituents of opaque expressions are ‘full’ semantic indicators: clearly blackbird , with two full indicators, is less opaque than ladybird , with one partial indicator only (—bird ), which in turn is less opaque than red herring or in a brown study , neither of which contains any indicators at all.
The other factor affecting degree of opacity is the discrepancy between the combined contribution of the indicators, whether full or partial, and the overall meaning of the idiom.
It is of course difficult to measure such a discrepancy objectively, but it does seem that, for instance, some of the so-called' irreversible binomials ' such as fish and chips are less opaque than, say,blackbird , even though both contain only full semantic indicators.
It may even come as a surprise to some to learn that fish and chips is opaque at all; but one needs only to consider that not any kind of fish, nor any method of cooking and presentation, will qualify for the description, and that this is not true of, say,chips and fish or  even fish with chips , both of which are transparent.
(It is probable that fish and chips is ambiguous, with one opaque and one transparent reading, the two being optionally distinguishable in pronunciation;chips and fish , on the other hand, is not ambiguous, and does not have the two pronunciation options.)
As degree of opacity diminishes, we approach the somewhat indeterminate transitional zone between opacity and transparency: indeed, some of the irreversible binominals are hard to categorise as one or the other:salt and vinegar (in chip-shop parlance),soap and water , etc.
In principle, all opaque sequences are minimal lexical units and therefore should be listed separately in an ideal dictionary.
A practical lexicographer, however, would probably draw his line in a different place from ours: he might well argue that phrases such as fish and chips ,bread and butter , etc., while undoubtedly slightly opaque in the technical sense, present few problems of interpretation to speakers familiar with the normal constituent meanings of the parts, and are thus not worth listing.
2.9 Idioms and collocations
The term collocation will be used to refer to sequences of lexical items which habitually co-occur, but which are nonetheless fully transparent in the sense that each lexical constituent is also a semantic constituent.
Such expressions as (to pick a semantic area at random)fine weather ,torrential rain ,light drizzle ,high winds are examples of collocations.
These are of course easy to distinguish from idioms; nonetheless, they do have a kind of semantic cohesion — the constituent elements are, to varying degrees, mutually selective.
The semantic integrity or cohesion of a collocation is the more marked if the meaning carried by one (or more) of its constituent elements is highly restricted contextually, and different from its meaning in more neutral contexts.
Consider the case of heavy in heavy drinker .
This sense of heavy requires fairly narrowly defined contextual conditions: one may speak of a heavy smoker , or a heavy drug-user , a car may be heavy on petrol , etc.
For this sense of heavy to be selected, the notion of ‘consumption’ in the immediate environment seems to be a prerequisite.
In a neutral context like It's —,heavy has a different meaning.
We are still, however, in the realms of transparent sequences, because each constituent produces a recurrent semantic contrast:
Semantic cohesiveness is even tighter if the meaning of one of the elements of a collocation requires a particular lexical item in its immediate context (cases where all the elements are uniquely selective in this way seem not to occur).
Such is the case with, for example,foot the bill and curry favour .
With expressions such as these, we are obviously approaching another transitional area bordering on idiom.
It has already been argued in some detail that foot the bill is semantically transparent.
It is also un-idiom-like in the fact that bill is fairly freely modifiable:
I'm expected to foot the bill.
the electricity bill.
all the bloody bills!
Yet it has some distinctly idiom-like characteristics, too.
One of these is that foot (in the relevant sense) demands the presence of a specific lexical partner; pronominal anaphoric reference to a previously occurring bill apparently will not do:
Son: I've just got the bill for the car repairs.
Father:?
I hope you don't expect me to foot it.
Furthermore, it resists interruption:
?
I'm expected not only to foot, but also to add up, all the bills.
Collocations like foot the bill and curry favour , whose constituents do not like to be separated, may be termed bound collocations .
Although they display some of the characteristic properties of idioms, bound collocations are nevertheless, as far as we are concerned, lexically complex.
2.10 Idiom and ‘dead’ metaphor
There is a type of expression which is frequently included in the category of idiom, but which, it will be argued, ought to be kept distinct, and that is what is sometimes called ‘frozen’ or ‘dead’metaphor.
The topic of metaphor is too broad to receive a detailed treatment here; let us simply say that a metaphor induces the hearer (or reader) to view a thing, state of affairs, or whatever, as being like something else, by applying to the former linguistic expressions which are more normally employed in references to the latter.
In, for instance,The huge locomotive snorted and belched its way across the plain we are invited to look at  the locomotive as if it were a gigantic animal.
This, of course, changes our perception of it, and it seems to take on characteristics such as ‘temperamental’, ‘dangerous when roused’, ‘difficult to control’, and so on .
The metaphorical strategy of interpretation is most likely to be triggered off by a perception of incongruity or inappropriateness in the sentence when interpreted literally.
If, however, a metaphor is used sufficiently frequently with a particular meaning, it loses its characteristic flavour, or piquancy, its capacity to surprise, and hearers encode the metaphorical meaning as one of the standard senses of the expression.
Interpreting it then no longer requires the activation of the metaphorical strategy, working through the literal meaning, but merely requires the looking up, as it were, of a dictionary entry, in much the same way, presumably, that idioms are interpreted.
However, very often the link with the original ‘live’ metaphor, and hence with the literal meanings of the parts, is not wholly lost.
Dead metaphors for which this is true can be ‘revived’ by substituting for one or more of their constituent parts elements which (in their literal uses) are near-synonyms, or paraphrases.
Consider the following pairs of sentences:
33a.
They tried to sweeten the pill.
b.
They tried to sugar the medicine.
34a.
You must have taken leave of your senses! b.
You must have left your senses behind! 35a.
We shall leave no stone unturned in our search for the culprit.
b.
We shall look under every stone in our search for the culprit.
The first sentence in each pair contains a dead metaphor; in the second sentence, the metaphor is revitalised by the substitution of a near-synonym or paraphrase.
The same process carried out on true idioms dramatically demonstrates the difference between the two types of expression:
36a.
John pulled his sister's leg.
b.
John tugged at his sister's leg.
37a.
Tonight we're going to paint the town red.
b.
Tonight we're going to colour the city scarlet.
38a.
They took us to the cleaners.
b.
They took us to the laundry.
Something similar happens on translation.
A literal rendering of an idiom is very rarely capable of serving as even an approximate translation; it is most likely to be either uninterpretable, or quite unrelated in meaning to the original expression.
Consider the French idioms   and .
A literal translation of the first is scarcely interpretable:to make warm throats of something ; the second translates into something a little easier to construe: t o give one's tongue to the cat .
But neither of these translations gives the slightest clue to the idiomatic meaning of the original French expression; the first means ‘to laugh loudly and maliciously at something’ and the second ‘to give up’(e.g. when asked a riddle).
(It is by no means uncommon for an idiom in one language to be at least roughly equivalent to a lexically unrelated idiom in another language: the French  is quite close to to pull someone's leg , or to have someone on .
Whether lexically unrelated idioms can ever be considered exact translation equivalents, however, is debatable.)
Literal translation fares rather better with dead metaphors; the results are usually a little odd, but are nonetheless interpretable in the manner of live metaphors.
In the following, the (a) sentences are dead metaphors, and the (b) sentences are literal translations:
39a.
Why keep a dog and bark yourself? b.  40a.
You're barking up the wrong tree.
b.  41a.  b.
He has changed his one-eyed horse for a blind one.
42a.  b.
He was ready to go and unhook the moon for her.
Interestingly, a high proportion of dead metaphors have similar (although not often identical) dead metaphor equivalents:
43a. to put the cat among the pigeons. b.  44a.
A cat may look at a queen.
b.  45a.
Let sleeping dogs lie.
b.  46a. to call a spade a spade.
b.  47a.
It's enough to make a cat laugh.
b.
These close equivalents among dead metaphors can present the translator with a dilemma (one of many!).
If he translates word-for-word, he will achieve greater fidelity in one respect (, for instance, evokes the same picture as put the cat among the pigeons ), but to the detriment of fidelity in another respect (is a live metaphor, while  is not); if, however, he puts a greater value on the latter type of fidelity, then he must sacrifice the former.
Not surprisingly, dead metaphors as a rule present fewer problems to foreign learners of a language than idioms do.
Their interpretability, however, must not be exaggerated; their meanings are not necessarily wholly predictable on first acquaintance.
Indeed, some can only be appreciated as metaphors with hindsight, as it were; it is only when the figurative meaning is pointed out that the path from the literal to metaphorical meaning becomes traceable.
While idioms and dead metaphors must be distinguished, it should also be recognised that they have certain characteristics in common.
(It is probable that the majority of idioms began their lives as metaphors; and synchronically, transitional cases, which are idioms for some and metaphors for others, are not uncommon.
Dead metaphors have in common with idioms that their constituent elements do not, in the straightforward sense, yield recurrent semantic contrasts: consider, for instance, the contrast stone /knob in We shall leave no — unturned .
They are not, therefore, semantically transparent.
On the other hand, the effect of synonymous substitution and the continuing relevance of their literal meanings make it unsatisfactory simply to call them ‘opaque’.
We shall therefore describe them as ‘translucent’.
(It should be noted that translucency is not the same as the semi-opacity of, for example,fish and chips .)
Dead metaphors also have a certain syntactic rigidity; the quality of being ‘dead’ is closely tied to a particular syntactic form, and with any modification the metaphor springs to life: compare He has one foot in the grave and One of his feet is in the grave .
Even if translucency and opacity can be satisfactorily distinguished, it is not necessarily the case that a particular expression can be unambiguously characterised as one or the other.
This is because the two properties may coexist in one and the same expression.
Take the case of She gave him a piece of her mind .
A good part of the meaning of this expression is accessible via normal metaphorical interpretation — it may be inferred that some opinion has been communicated.
But a crucial element of meaning cannot be construed in this way, namely, the negative, scolding aspect; because of this, the expression to give someone a piece of one's mind must be considered semi-opaque — and, by the same token, only semi-translucent.
Because of their non-transparency and syntactic frozenness we shall consider dead metaphors to be minimal lexical units.
3
The paradigmatic and syntactic delimitation of lexical units
3.1 Introductory
In the previous chapter a number of important decisions were taken which enable us to establish the location of lexical elements within sentences, that is to say, to delimit them syntagmatically.
We must now confront the rather more daunting problems of differentiating lexical units paradigmatically.
It will be necessary to introduce a distinction, which has up to now not been needed, between two kinds of element relevant to lexical semantics.
The two types will be called lexical units and lexemes .
In this book our main, although by no means exclusive, concern is with the former.
Lexical units are those form-meaning complexes with (relatively) stable and discrete semantic properties which stand in meaning relations such as antonymy (e.g. long :short ) and hyponymy (e.g. dog :animal ), and which interact syntagmatically with contexts in various ways to produce, for instance, the different sorts of anomaly discussed in chapter 1.
A particular lexical unit, of course, expresses its semantic identity through such relations, but its essence cannot be exhaustively characterised in terms of any determinate set of such relations.
The meaning aspect of a lexical unit will be termed a sense .
Lexemes, on the other hand, are the items listed in the lexicon, or ‘ideal dictionary’, of a language; these will be discussed in 3.10.
It may be wondered why it is necessary, or even advantageous, to have two sorts of unit for lexical semantics.
The reason is that they have different functions, which impose different constraints on their nature.
Senses need to represent unitary ‘quanta’ of meaning, but they do not need to be finite in number.
There is nothing in the notion of oppositeness, for instance, which dictates that there should necessarily be only a finite number of opposite pairs in a language.
A lexeme, on the other hand, may well be associated with indefinitely many senses, but the set of lexemes must be finitely enumerable.
Consider, by way of illustration, the example of topless .
We may speak of (a)a topless dress or (b)a topless dancer .
Each of these is lexically distinct, in that it has, for instance, different typical contrasts (e.g. long-sleeved for (a) and nude for (b)), and the two readings are called forth by different types of context.
They are also relatively stable across contexts: for instance,a topless swim-suit would seem to exemplify the same sense of topless as (a), and a topless barmaid the same as (b).
Why then can we not simply say that topless (a)and topless (b)are different (although perhaps related) lexemes?
One important reason is that the number of possible distinct uses of topless seems to be, in principle, open; so any attempt to draw up a determinate closed list would be of questionable validity.
In addition to the examples mentioned above, one might also encounter a topless bar ,I hear Torquay has gone topless .
And can we entirely rule out topless by-laws , or the topless watchdog committee (with the function of monitoring the behavioural effects of toplessness)?
Another example of such openness is provided by what we shall call the unit-type ambiguity.
For instance,jacket in I like this jacket may be understood to refer to a particular individual jacket (the unit), or to a type of jacket.
However, there seems, in principle, to be no limit to the number of possible type readings in such cases.
Suppose someone in a greengrocery picks up an apple and says:Is this the fruit you mean ?
Besides the unit reading, the speaker may be intending to refer, among other possibilities, to: that variety of apple (e.g. Cox's Orange Pippin); apples in general; fruit from a particular supplier; home-grown apples; etc., etc.
While in particular contexts some readings may well be much more likely than others (if this were not the case, many utterances would be harder to understand than they are), the number of possible readings is clearly limited only by imagination.
(Except, of course, that the type cannot be more general than the lexical item used to refer to it:this apple cannot refer to fruit in general .)
It seems that there is a high degree of creativity in the lexicon which we must take account of.
The creativity inherent in the grammar of a language has often been pointed out: an unlimited number of sentences may be produced from a finite set of elements together with rules for their combination.
Lexical creativity is probably of a similar order and, like syntactic creativity, must have a finite aspect.
It will be assumed in this book that a (relatively) closed set of lexical units is stored in the mental lexicon, together with rules or principles of some kind which permit the production of a possibly unlimited number of new (i.e. not specifically stored) units.
3.2 Selection and modulation of senses
One of the basic problems of lexical semantics is the apparent  multiplicity of semantic uses of a single word form (without grammatical difference).
There seems little doubt that such variation is the rule rather than the exception: the meaning of any word form is in some sense different in every distinct context in which it occurs.
However, that does not mean that the ‘word-form-in-context’ is the appropriate unit for lexicological purposes.
There are two distinct types of variation in the semantic contribution that a word form makes to different sentences — or, to look at it from a different point of view, two ways in which the sentential context of a word form may affect its semantic contribution to the sentence.
It will be argued that one of these types of variation involves the selection, by the context, of different units of sense, while the other type is a matter of contextual modification of a single sense.
The difference between the two contextual effects can perhaps be approached initially by considering two corresponding ways in which a word form, in a single context, may be open to more than one interpretation.
Cousin and bank in 1 and 2, respectively, illustrate the difference:
1.
Sue is visiting her cousin.
2.
We finally reached the bank.
Cousin in 1 can, of course, refer to either a male or a female cousin.
But the sentence can function as a satisfactory communication without either the hearer perceiving, or the speaker intending to convey, anything concerning the sex of the person referred to.
This is because cousin has a general meaning which covers all the more specific possibilities (not only with regard to sex, but also with regard to an indefinitely large number of other matters, such as height, age, eye-colour, etc.).
Bank in 2 can also be interpreted in more than one way (e.g. ‘margin of river’ or ‘establishment for the custody of money’); but it has no general meaning covering these possibilities.
Furthermore, the interpretation cannot be left undecided: both speaker and hearer must select a reading (the same reading) if the sentence is to play its part in a normal conversational exchange.
We shall say that the word form cousin is general with respect to the distinction ‘male cousin’ /’female cousin’;bank , on the other hand, will be said to be ambiguous with respect to the sense distinction ‘financial institution’/’side of river’.
In other words, the two meanings ‘male cousin’ and ‘female cousin’are both associated with the same lexical unit cousin , whose meaning is more general than either; they therefore do not represent distinct senses of cousin .
The meanings ‘financial institution’ and ‘side of river’, on the other hand, do represent two distinct  senses, so there are two lexical units bank corresponding to these senses.
(Every word form is general with respect to some semantic distinctions, and (at least potentially) ambiguous with respect to others.)
Let us now examine in greater detail the different ways in which contexts exert a restrictive influence on the meanings associated with word forms which occur within them.
There are two fundamental ways in which the effective semantic contribution of a word form may vary under the influence of different contexts.
First, a single sense can be modified in an unlimited number of ways by different contexts, each context emphasising certain semantic traits, and obscuring or suppressing others; just as a dirty window-pane will allow some parts of the scene beyond it to be seen clearly, and will partially or completely obscure other parts — and a different pane will affect the same scene differently.
This effect of a context on an included lexical unit will be termed modulation ; the variation within a sense caused by modulation is largely continuous and fluid in nature.
The second manner of semantic variation concerns the activation by different contexts of different senses associated with ambiguous word forms.
This will be termed contextual selection (of senses); in the nature of things, this sort of variation proceeds in discrete jumps rather than continuously.
The two types of variability are normally operative together; that is, a selected sense is also subject to modulation by the context which forced its selection.
Let us first look a little more closely at modulation.
We shall discuss sense modulation under two main headings: first, changes in the status of semantic traits along the dimension of necessity — which will be termed promotion and demotion ; and second, the highlighting and background of traits.
As an example of promotion and demotion, consider the semantic traits associated with nurse in 3 and 4:
3.
A nurse attended us. 4.
A pregnant nurse attended us.
In 3, the trait ‘female’ is expected, and the trait ‘male’unexpected; but in 4, although nurse represents the same lexical unit as in 3, ‘female’is at the very least canonical (if not criterial), while ‘male’is demoted to anomalous or impossible status.6 As a further example, consider 5:
5.
Arthur poured the butter into a dish.
Out of context, or in a neutral context, ‘liquid’ is either a possible or unexpected trait of butter .
But in 5 it is at least canonical.
Sentence 5 also illustrates another aspect of modulation, which we shall call linkage of traits.
It is clear that the butter referred to in 5, if it is normal, is not only liquid, but also hot; ‘hot’ is therefore a canonical trait.
Now, ‘hot’ is merely a possible trait of butter in, for instance,Arthur put the butter into a dish ; and it is certainly not the case that any lexical unit functioning as the direct object of pour has ‘hot’as a canonical trait — in Arthur poured the milk into a dish , for instance , ‘hot’is, again, merely possible.
It is the combination of pour with butter (in direct object position)— or, more directly, the interaction of the traits ‘butter’ and ‘liquid’— which promotes ‘hot’from possible to canonical status.
This is a very simple example; it is easy to conceive of extremely varied and complex patterns of linkage appearing in various contexts.
This will not, however, be elaborated on here; we shall merely note that it is an important aspect of modulation.
Another effect of contextual modulation on the sense of a lexical unit involves the relative highlighting or backgrounding of semantic traits.
Different sorts of trait can be affected in this way.
Two examples will suffice.
First, some part of an object (or process, etc.) may be thrown into relief relative to other parts.
For instance,The car needs servicing and The car needs washing highlight different parts of the car.
(This is not to say that car refers to something different in each of these sentences — in both cases it is the whole car which is referred to.)
Second, it is commonly the case that what is highlighted or backgrounded is an attribute, or range of attributes, of the entity referred to.
For instance,We can't afford that car highlights the price of the car,Our car couldn't keep up with his highlights its performance, and The car crushed Arthur's foot its weight.
It is in respect of‘contextually modulated sense’ that a lexical unit may be justifiably said to have a different meaning in every distinct context in which it occurs.
We have been speaking, so far, of the effects of context on the meaning of a single lexical unit.
But a context normally also acts in such a way as to cause a single sense, from among those associated with any ambiguous word form, to become operative.
When a sentence is uttered, it is rarely the utterer's intention that it should be interpreted in two (or more) different ways simultaneously.
It is probable that deliberate equivocation in respect of the intended sense of word forms is always to some extent odd.
This means that, for the vast majority of utterances, hearers are expected to identify specific intended senses for every ambiguous word form that they contain.
The process of sense selection is, of course, extremely complex, with many interacting factors.
However, in general, one can say that a hearer selects that combination of lexical readings which leads to  the most normal possible utterance-in-context.
In other words, a hearer will generally assume that the producer of an utterance wants to communicate something, and has chosen the linguistic context of his utterance with a view to furthering this aim.
Broadly speaking, we can identify two types of normality — sentence-internal normality and contextual normality (it is probably the case that the latter is the stronger determinant of sense selection).
Very often a sentence contains more than one ambiguous word form; in such cases, there will occur a kind of mutual negotiation between the various options so as to achieve the most normal combination.
This process is illustrated in 6:
6.
Several rare ferns grow on the steep banks of the burn where it runs into the lake.
It is highly unlikely that any reader of this sentence will interpret rare in the sense of ‘undercooked’(as in a rare steak ), or steep in the sense of ‘unjustifiably high’(as in steep charges ), or bank in the sense of ‘financial institution’, or burn in the sense of ‘injury caused by fire’, or run in the sense of ‘progress by advancing each foot alternately never having both feet on the ground simultaneously’, etc.
There is only one selection of senses here which yields a normal sentence (i.e. the sentence form is not ambiguous).
Contextual normality involves such matters as relevance, informativeness and consistency.
Consider 7:
7.
A: It's dark in here, isn't it?
B: Yes.
Aren't there any lights?
B's utterance (in the context of A's) is normal if lights is interpreted to mean ‘sources of illumination’, but would be of, at best, obscure relevance if interpreted to mean ‘lungs of sheep’.
(Notice, however, that B's utterance does not display internal abnormality on either interpretation.)
So far we have taken it for granted that the distinction between ambiguity and generality is intuitively obvious.
In some cases it is, but in others it is not; this judgement certainly does not figure amongst the basic set of intuitive judgements on which we base our analyses.
We must now, therefore, consider in some detail the question of explicit diagnostic tests for ambiguity and generality.
3.3 ‘Indirect’ tests for ambiguity
One approach to the diagnosis of ambiguity relies on finding, for two occurrences of a word form, different relations of meaning with other items.
These relations may be of the paradigmatic variety (e.g.  oppositeness, synonymy, etc.) or they may be of the so-called paronymic sort (that is to say, involving identity of root, but difference of syntactic category, as, for instance , with act :actor ,race :racy .
We shall describe evidence of this type as ‘indirect’; arguments will be put forward that indirect evidence has severe drawbacks as a method of diagnosing ambiguity.
The following three ‘tests’ for ambiguity will serve to illustrate the approach.
I.
If there exists a synonym of one occurrence of a word form which is not a synonym of a second, syntactically identical occurrence of the same word form in a different context, then that word form is ambiguous, and the two occurrences exemplify different senses.
Thus, for example, one might suggest lucifer as a synonym for match in 8 (but not in 9), and contest as a synonym in 9 (but not in 8):
8.
Guy struck the match.
9.
The match was a draw.
From this, the principle expressed in 1 would allow us to conclude (correctly, in this instance), that match was ambiguous, and in 8 and 9 represented different senses.
II.
If there exists a word or expression standing in a relation of oppositeness to one occurrence of a word form, which does not stand in the same relation to a second, syntactically identical occurrence of the same word form in a different context, then that word form is ambiguous, and the two occurrences exemplify different senses.
In 10, for instance,dark (but not heavy ) stands in a relation of oppositeness to light , whereas in 11 heavy is a satisfactory opposite, but dark is not:
10.
The room was painted in light colours.
11.
Arthur has rather a light teaching load.
Light is therefore, according to the test, an ambiguous lexical form, and 10 and 11 manifest different senses.
III.
If there exists a word which stands in a paronymic relation to one occurrence of a word form, but does not stand in the same relation to a second, syntactically identical occurrence of the same word form in a different context, then that word form is ambiguous, and the two occurrences exemplify different senses.
Consider race in 12 and 13:
12.
The race was won by Arkle. 13.
They are a war-like race.
The verb to race and the noun racing are paronymically related to the occurrence of race in 12, but not to that in 13; on the other hand,racial and racist are related to race in 13, but not in 12.
Hence race according to the test, is an ambiguous lexical form, and 12 and 13 manifest different senses.
Once again, the diagnosis seems intuitively correct.
Other tests of the same general type may be proposed, but none bring anything radically new to the picture.
They all suffer from a major weakness, which is that for every instance in which a word form possesses different synonyms, opposites, morphological derivatives, or whatever, in different contexts, there are several possible explanations, only one of which involves ambiguity of the word form; hence, further evidence of a different sort is required to determine which explanation is correct in any given instance.
Suppose there exists a word form W, which in context C(1) stands in a particular meaning relation to another element A(1), but in context C(2) stands in the same meaning relation not to A(1), but to A(2):
There are at least three possible reasons why W should have different relational partners in C(1) and C(2).
One is, of course, that W is ambiguous, and C(1) and C(2) select different senses.
This is presumably what happens in the cases of light ,match and race discussed above.
Another possibility is that C(1) and C(2) modulate a single sense of W in mutually exclusive ways.
Thus monarch in 14 has queen but not king as a synonym, whereas in 15 it has king but not queen :
14.
The Ruritanian monarch is expecting her second baby.
15.
The child's father is the reigning monarch.
In such a case there would be no evidence of ambiguity.
A third possibility is that A(1) and A(2) are sensitive to differences between C(1) and C(2) to which W is indifferent.
Consider the following case of thin and its opposites:
It does not seem illuminating to say either that thin is ambiguous, or that these contexts restrict its meaning in mutually exclusive ways.
It is clear that nothing can be reliably inferred from the mere fact that a word form has different meaning relations in different contexts, and independent evidence concerning ambiguity or generality is required.
But if such evidence is available, then it is superfluous to appeal to differential relations.
Indirect tests can be used in another way, which in some cases can seem more reliable.
Instead of looking for different relations in different contexts to prove ambiguity, one may adduce sameness of relations as evidence of generality.
Thus, the fact that thin in both of the contexts illustrated above has slender as a  synonym could be cited as evidence that it is not ambiguous after all.
However, using indirect criteria in this way is no more reliable: one simply falls into a different trap, because the item which stands in the ‘same’ meaning relation in different contexts to the lexical form being tested may itself be ambiguous.
There is an intuitively clear example of this involving thin :
It is of course true that one of the main purposes of distinguishing discrete senses is to have available a unit which can stand in relations such as synonymy and oppositeness.
However, it seems clear that these units must be established in some other way.
Fortunately there are more successful and reliable ways of distinguishing ambiguity from generality, and to these we now turn.
3.4 Direct criteria for ambiguity
Three different types of criteria for ambiguity will be proposed.
It may ultimately be possible to show that they all reduce to a single basic criterion, but here they will be presented separately.
Generally speaking, unless there are specific reasons why one or other of the criteria should be inapplicable (some of these reasons will be discussed below), we shall expect an ambiguous item to satisfy all the criteria.
The first criterion is frequently difficult to apply in practice, but it is conceptually important.
It is that the senses of an ambiguous word form should not in every case be totally conditioned by their contexts, unlike the interpretations which arise as a result of contextual modulation.
This means that an ambiguous word form set in a disambiguating context may well carry more information than can be accounted for in terms of interaction between the context-independent meaning of the word form, and the semantic properties of the context.
In cases of contextual modulation, on the other hand, ALL information is derived from these sources.
Consider sentences 16 and 17:
16 Arthur washed and polished the car.
17.
John lubricated the car.
The most likely interpretation of 16 is that not every part of the car underwent washing and polishing, but the exterior surface only.
What is the basis for this conclusion?
It is derived entirely from the general meaning of car , together with the semantic properties of the context (remember that general knowledge concerning cars and operations carried out on them is, on the view of meaning adopted in this book, embedded in the meanings of car ,wash ,polish , etc.).
A similar account can be given of the most likely interpretation of car in 17.
Or take the case of monarch in 14 (repeated here for convenience):
14.
The Ruritanian monarch is expecting her second baby.
We can be virtually certain that the monarch in question is a queen, because of the restricting effect of the context on the general meaning of monarch .
Notice that a similar interpretation would arise, and no loss of information would result, if monarch were replaced by a synonym or paraphrase such as sovereign , or crowned head (and automobile would interact in the same way with the context if it were substituted for car in 16 and 17).
Contrast these, however, with bank in 18 and 19:
18 Her husband is the manager of a local bank.
19.
At this point, the bank was covered with brambles.
Let us try to account for the (most probable) different interpretations of bank in the way that we did for car .
It is first necessary to decide on a synonym or paraphrase of the context-invariant meaning of bank .
This already poses problems, but let us say, for the sake of argument, that it is equivalent to place .
We can then observe the effect of substituting place for bank in 18 and 19:
20.
Her husband is the manager of a local place.
21.
At this point, the place was covered with brambles.
There is quite clearly a loss of information, so we have failed to show that the interpretations of bank are the result of contextual modulation of a general meaning.
It may be concluded, therefore, that the different contexts are selecting discrete senses of bank .
Another instance of incomplete contextual determination is to be observed with dog .
Let us for the moment take it as established that dog has a general sense, denoting the whole species, irrespective of sex.
In sentences such as 22, however,dog has a more specific meaning, and refers only to males:
22.
John prefers bitches to dogs.
Now it might be argued that the resultant sense of dog here is caused by contextual modulation of the general sense:dog cannot in this context refer to females if logical consistency is to be preserved, which leaves only males as possible referents.
Consider now, however, 23:
23.
Incredibly, John prefers an aged, half-blind bitch to a dog, as his canine companion.
If the interpretation of dog in this sentence were the result of contextual modulation of the general sense, it ought to include reference to, for instance, young females with good eyesight.
But once again, it refers to male dogs only.
This reading cannot be explained by contextual modulation, so it must be the result of selection from a set of discrete possibilities.
In fact, the same is true of 22.
That contextual modulation of the general sense of dog cannot explain the specific interpretation in 22 is shown by the lack of a parallel specific interpretation of canine (in its jocular use as a noun) when it is substituted for dog :
24.
? John prefers bitches to canines.
(We shall consider below why 24 should be anomalous.)
Some understanding of the way the semantic effects of selection may be independent of, and indeed may transcend, those properties of the  context which are responsible for the selection can be gleaned from the following analogy.
Suppose that it is known that a certain event is to occur on a certain day, but may take place at only one of two possible times, namely, 12.00 noon or 12.00 midnight.
If one were subsequently to receive a report that when the event occurred, the sun had set, one would be able to infer that it had taken place at exactly 12.00 midnight.
The precision of this inference goes well beyond what is explicitly present in the report, which acts rather like a trigger setting off one of two pre-existing possibilities.
In a similar manner, the context of dog in 22 and 23 acts like a trigger which activates one of a set of pre-existing bundles of semantic properties, each having a precision and richness not directly sanctioned by the context.
In principle all ambiguous items should be capable of manifesting these characteristics.
Our second criterion for ambiguity is that separate senses should be independently maximisable .
Under certain conditions, the application of certain terms must be maximised within the current universe of discourse, even at the expense of oddness.
Consider 25 (which resembles 24):
25.
? Mary likes mares better than horses.
One might have thought that the context makes it clear that horses is to be interpreted as ‘stallions’; however, such an interpretation is not available for this type of sentence.
The reason is that since mares have been mentioned, they fall within the current universe of discourse, and by the rule of maximisation (the details of which are not entirely clear) must be included in the reference of horses .
This, of course, leads to logical inconsistency, and hence oddness.
(Notice, however, that there is no anomaly if the reference of horses is EXPLICITLY restricted:Mary prefers mares to horses which can sire foals or Mary prefers mares to these horses uttered in a situation where only stallions are present.)
On the other hand, 26, unlike 25, is perfectly normal:
26.
John prefers bitches to dogs.
The general sense of dog would of course give rise to anomaly in 26, because of the rule of maximisation.
The reason 26 is not odd is that dog has another sense, which even when maximised excludes bitches, and this is automatically selected by the context.
By contrast, 27 selects the general reading of dog (the specific reading would be odd here, but not for reasons connected with maximisation):
27.
Arthur breeds dogs.
Thus 26 and 27 taken together constitute strong evidence that dog is ambiguous.
The existence of two independent senses of dog each independently maximisable, is responsible for the fact that A's question in 28, if the dog in question is female, can be truthfully answered either ‘Yes’ or ‘No’(depending on which sense the respondent believes the questioner to be intending):
28.
A: Is that a dog?
B:(i) Yes, it's a spaniel.
(ii) No, it's a bitch.
There is no parallel set of circumstances in which the question in 29 can be truthfully answered ‘Yes’ or ‘No’:
29.
A: Is the subject of this poem a monarch?
B:(i) Yes, it is a queen.
(ii)?
No, it is a king.
Because there is only one sense of monarch , namely, the general one, and because its reference must be maximised, if the subject of the poem was a king or a queen, then ‘Yes’ is the only truthful answer.
As with 28, situations can be imagined in which the questions in 30 and 31 can be truthfully answered either negatively or positively:
30.
A: Has Charles changed his position?
B:(i) Yes, he's now sitting next to the chairman.
(ii) No, he still supports corporal punishment.
31.
A: Did Arthur make it to the bank?
B:(i) Yes, he's a strong swimmer.
(ii) No, he was arrested as soon as he came out of the water.
The same should be true, in principle, of any truly ambiguous expression.
Ambiguity tests of the third kind utilise the fact that independent senses of a lexical form are antagonistic to one another; that is to say , they cannot be brought into play simultaneously without oddness.
Contexts which do activate more than one sense at a time give rise to the variety of oddness we have labelled zeugma:
32.
? John and his driving licence expired last Thursday.
The simultaneous bringing into play of two senses can be effected either  by coordination, as in 32, where John and his driving licence select different senses of the verb expire , or by anaphora, as in 33:
33.
? John's driving licence expired last Thursday; so did John.
So did is an anaphoric verb phrase; that is to say, its referential properties operate not directly, but indirectly, through a previously mentioned verb phrase, in this case expired last Thursday , which must be re-applied, this time with John as subject.
But since this demands a different sense from the one appropriate to its first occurrence, the result is zeugma.
A general term cannot give rise to zeugma in this way:
34.
My cousin, who is pregnant, was born on the same day as Arthur's, who is the father.
Arthur's refers anaphorically through cousin .
The context makes it clear that the two cousins are of different sexes; however, the sentence is not zeugmatic, so we may conclude that cousin does not have two senses ‘male cousin’ and ‘female cousin’.
Antagonism of senses also lies behind the so-called identity test for ambiguity.
In 35, each part of the sentence contains an occurrence, either direct, or indirect via anaphora, of the ambiguous adjective light , and can therefore in theory be interpreted in two ways:
35.
Mary is wearing a light coat; so is Sue.
However, the whole sentence does not have four (i.e. 2×2) interpretations, but two only.
This is because the same reading of light must be selected in each part: either both ladies are wearing ‘undark’ coats, or both are wearing ‘unheavy’coats.
What is termed the crossed interpretation , with each part of the sentence manifesting a different sense, is prohibited.
This prohibition is not a mysterious property of the grammatical process of anaphora; it is simply a consequence of the fact that light resists, as it were, the simultaneous activation of more than one of its senses.
General terms allow crossed interpretations:
36.
Mary has adopted a child; so has Sue.
There are four possible distributions of sexes compatible with this sentence, since there is no requirement that the two children should be of the same sex.
3.5 Some difficult cases
In this section the operation of ambiguity tests will be illustrated  by applying them to a selection of difficult cases.
The difficulties mostly concern tests based on the antagonism of sister-senses (i.e. senses associated with a single lexical form).
It is not possible simply to dispense with such tests, because there are occasions, especially when dealing with highly context-bound readings which do not appear in ambiguous sentences, when they are the only practicable way of diagnosing ambiguity.
I
The first example involves the unit-type ambiguity.
This is quite easy to demonstrate by means of the Yes /No -test:
37.
A: Is this the jacket you want?
B:(i) Yes.
(it's the type I want)(ii) No. (this particular one is shop-soiled)
But it is much more difficult to show antagonism: many contexts which might be expected to manifest it do not:
38.
This is our best-selling jacket: do try it on.
Jacket in the first clause clearly must have a type reading — one cannot repeatedly sell the same individual jacket.
One might have thought that only a particular unit of the type could be ‘tried on’, but that seems not to be the case.
One must beware of drawing hasty conclusions in this area.
As it happens, it is possible to find contexts which isolate the two readings, and when these are yoked together, zeugma results.
Sentence 39 allows only the ‘unit’ reading for skirt (this seems to be a property of belong ):
39.
That skirt belongs to Mary.
Sentence 40 can only bear a type reading:
40.
My sister has the skirt Sue is wearing now.
Try to link these two readings together anaphorically, and the antagonism becomes plain:
41.
? The skirt Sue is wearing belongs to Mary; my sister has it, too.
II
It not infrequently happens that ambiguous readings are related in such a way that in certain contexts one reading entails the other.
Such cases are a common cause of apparent failure of the zeugma-test (often called the ‘pun-test’) or the identity test.
The two readings of dog are a case in point.
In 42, for example, it appears that a crossed interpretation is possible, in that Mary's dog could well be male, and Bill's female:
42.
Mary bought a dog; so did Bill.
Does this contradict the evidence presented above that dog is ambiguous?
The answer is that it does not.
When dog occurs in a sentential context in which the specific interpretation entails the general interpretation, we cannot be sure which sense is operative when reference is made to a male dog: the two senses under these circumstances are effectively inseparable.
Hence the normality of 42 when the dogs referred to are of opposite sexes cannot be used as evidence against the existence of two senses of dog , since it can be fully accounted for by claiming that only the general sense is operative.
However, the situation is much clearer when dog occurs in a context where neither sense entails the other, as in 43:
43.
Arthur wants to know if that is a dog; so does Mike.
A moment's thought will convince the reader that the crossed reading is prohibited here: this sentence cannot be used to describe a situation where Arthur knows that the animal in question is an alsatian, but is unsure of its sex, while Mike knows that it is female, but thinks it might be a wolf.
The pun-test, too, demands non-entailing contexts:
44a.
Dogs can become pregnant at 12 months.
(general sense only) b.
Dogs mature later than bitches.
(specific sense only) c.
? Dogs can become pregnant at 12 months, but mature later than bitches.
III
Entailment between readings also bedevils attempts to demonstrate antagonism between the ‘exactly’ and ‘at least’interpretations of numerals and other expressions of quantity.
The Yes /No -test suggests that this is a genuine ambiguity:
45.
A: Have you got £10 in your wallet?
B:(i) Yes.
In fact, I've got £12. (ii) No, I've got £12.
However,John has (exactly) £10 entails John has (at least) £10 , which perhaps explains why 46 is not zeugmatic:
46.
You need £100 in your account to qualify for free banking.
Arthur has it, now that he has added £50 to the £50 that was already there.
The first mention of £100 clearly demands an ‘at least’ interpretation; what Arthur has is ‘exactly’£100; one might therefore not expect the it of the second sentence to be able to refer anaphorically to £100 in the first sentence without antagonism.
However, because of the entailment  referred to above, the original and anaphoric occurrences of £100 can both be given the ‘at least’ interpretation, thus avoiding antagonism.
It is possible to construct isolating contexts which reveal antagonism, but they are extremely cumbersome:
47a.
John, with £11, and Bill, with £12, both have the £10 necessary to open a savings account.
(’ at least’) b.
Tom, too, now has £10, having spent £2 out of his original £12. (’ exactly’reading forced by now) c.
? John, with £11, has the £10 necessary to open a savings account; Tom, too, now has it, having spent £2 out of his original £12.
IV
The case of door is interesting (a group of related words such as window ,hatch ,sky-light , etc. behave similarly).
Two senses of door may be observed in 48, which can be truthfully answered either ‘Yes’ or ‘No’in the following situation: the door in question has a ‘cat-flap’, and is standing open; the cat goes through the cat-flap, but not through the doorway:
48.
Did the cat go through the door?
Once again, difficulties arise with the antagonism criteria.
It might be predicted, for instance, that 49 would be zeugmatic, since what is smashed (the door-panel) is different from what is bricked up (the doorway):
49.
The door was smashed in so often that it had to be bricked up.
But there is no anomaly of any kind.
Again, it appears that contexts of a particular kind must be avoided if the test is to succeed.
In this case it is the part-whole relationship which is to blame.
For certain predicates, applicability to parts entails applicability to wholes corresponding to the parts.
Thus, if I touch the table-leg , by doing so I necessarily touch the table ; if the tea-pot handle is broken, so is the tea-pot , and so on.
It seems likely that this entailment is interfering with antagonism in 49 — both events are interpreted as happening to the ‘global door’, of which the door-panel is a part.
The remedy, as before, is to avoid such contexts, and to use, to isolate the senses, only those contexts in which part does not entail whole (or, better still, contexts where part entails not-whole).
When this is done, the antagonism of the senses is easily seen:
50.
? We took the door off its hinges and then walked through it.
The moral to be drawn from these examples is that apparent compatibility of readings must not be too hastily accepted as proof of generality: each case must be examined carefully to determine whether there are special factors preventing the appearance of zeugma.
It may be reasonably confidently assumed that the different criteria for ambiguity which have been described in fact are sensitive to the same underlying semantic property, and that in the absence of ‘special factors’ will provide identical diagnoses.
3.6 Non-lexical sources of ambiguity
It is important to realise that not all sentence ambiguity originates in lexical ambiguity; furthermore, our tests for ambiguity are not, in general, capable of discriminating between lexical and non-lexical varieties.
Usually this is not a serious source of practical difficulty, since most cases are intuitively clear; but it is unfortunately not easy to formulate explicit criteria for recognising lexical ambiguity.
We shall adopt a ‘default’ definition and characterise as lexical all ambiguities for which there is no convincing non-lexical explanation.
This means that something at least must be said about alternative types of ambiguity, although a detailed treatment would be well beyond the scope of this book.
We can crudely classify the sorts of ambiguity found in sentences as follows:
1.
Pure syntactic ambiguity: old men and women French silk underwear
2.
Quasi-syntactic ambiguity: The astronaut entered the atmosphere again a red pencil
3.
Lexico-syntactic ambiguity: We saw her duck.
I saw the door open.
4.
Pure lexical ambiguity: He reached the bank What is his position?
Types 3 and 4 are of direct relevance to us, and are discussed in some detail in the present chapter; types 1 and 2, on the other hand, are irrelevant, and we need to know how to exclude them.
By ‘pure syntactic ambiguity’ is meant ambiguity in which the variant readings of a sentence involve identical lexical units; the ambiguity is thus necessarily a matter merely of the way the elements are grouped together.
For instance, the meaning of old men and women differs according to whether old goes with men only:
(old men) and women
or with men and women :
old (men and women)
Likewise,French silk underwear may be underwear made of French silk ((French silk )underwear ) or French underwear made of silk (French (silk underwear )).
Such cases are characteristically very insensitive to the semantic properties of the constituent lexical items:melodious trills and scales ;porcelain egg container .
The so-called ‘ambiguities of scope’ can be included in this category; although they are often lexically restricted, they can be fully accounted for in terms of‘what goes with what’.
Take, for example, sentence 51:
51.
I don't like him.
Innocuous though it may seem at first sight, this can be interpreted (at least in the written form) in two ways: either ‘I dislike him’(the most usual reading), or, in suitable contexts, ‘It's not true that I like him’(for instance, in I don't dislike him, but I don't like him either ).
There is no need to postulate different negative elements, or different meanings of like: it is enough to allow the negative element either to take the whole of the rest of the sentence as its scope (Neg (I like him )), in which case the meaning will be ‘It's not true that I like him,’ or the single element like (I Neg-like him ), in which case the meaning will be ‘I dislike him.’’
‘Quasi-syntactic’ ambiguities require careful consideration because there may be a temptation to diagnose them as cases of lexical ambiguity.
This is because there is no straightforward syntactic explanation of the ambiguity: not only are the lexical units identical for the two interpretations, but they are identically grouped, too.
And yet this type of ambiguity bears a striking resemblance to the scope ambiguities described above.
Consider the case of The astronaut entered the atmosphere again .
The two meanings are (i)‘the astronaut entered the atmosphere for (at least) the second time’ and (ii)‘the astronaut returned to the atmosphere (after what could have been his/her first trip into space)’.
This ambiguity can be accounted for without the need either for two different elements enter , or two different elements again , if we regard the meaning of enter as being constituted out of more elementary semantic entities which are related quasi-syntactically:
‘enter’ = [COME TO BE][IN]
The two readings can then be represented as follows:
(i)([COME TO BE][IN])[AGAIN](ii)[COME TO BE]([IN][AGAIN])
The availability of an explanation along these lines (however it might be formalised in relation to the syntax) renders a lexical solution unnecessary.
Another example is a red pencil , which has the two readings (i)‘a pencil painted red’ and (ii)‘a pencil which writes red’.
It may be thought that in reading (ii),pencil should be taken to refer only to the core of the pencil.
This is not so, however: there is little doubt that in both interpretations pencil refers to the whole object (or at least potentially does so).
Notice that I have a red pencil and a blue one has no crossed interpretation, which is what we expect from a genuine ambiguity.
Yet The red pencil is the chewed one is quite normal on both readings, which would not be expected if on one of the readings pencil referred only to the core.
It seems that the adjective red can apply either to the whole of the referent of the noun that it accompanies, or to a salient, or major functional, part of it.
The same potential ambiguity is present in a stainless steel hammer , and even (although pragmatically less likely)a felt pen .
It is not clear at present exactly what the rules are in such cases, nor whether the choices of readings are as clear-cut as they at first seem.
What is clear, however, is that we are not dealing with lexical ambiguity.
3.7 Establishment of senses
A lexical form may well be associated with an unlimited number of possible senses, but these are not all of equal status.
If we take seriously the notion of ‘unlimited number’, there must be, for any lexical form, potential senses which have never been realised in use: equally, every lexical form has at least one relatively well-utilised sense.
We may thus envisage a gradient of what we shall term establishment of senses.
(Individual speakers may, of course, differ markedly in respect of the degree of establishment of different senses, but a substantial measure of consensus may be assumed.)
The difference between established senses and potential senses is not merely one of frequency of use, although this is undoubtedly an important component of the difference: established senses are presumably represented differently in the mind's lexicon.
It seems appropriate to distinguish two kinds of contextual selection, according to whether the selected sense is established or not.
In the former case, where selection is from among pre-established senses, the context acts merely as a kind of filter: we shall  refer to this as passive selection .
Where, on the other hand, the selected sense is not established, the context acts rather as a stimulus for a productive process, namely, the activation of a set of rules or principles which ‘generate’ the sense in question.
The latter type of selection will be called productive .
The difference between the two types of selection may be assumed to be of psycholinguistic importance.
There is a possible test for the establishment of a sense, which has consequences for the second family of tests for ambiguity described earlier.
It appears that it is possible to assert one of the senses of a lexical form, using the bare form, while at the same time denying (explicitly or implicitly) another of the senses, only if the asserted sense is fully established.
A few examples will make this clear.
Take the case of novel , which can have the readings (i)‘narrative text’ or (ii)‘physical object (embodying a narrative text)’.
The two readings may be observed in 52 and 53 respectively:
52.
His new novel will be published next spring.
53.
Why is your desk always piled high with novels?
Now consider 54 and 55:
54.
I'm not interested in the cover design, or the binding — I'm interested in the novel.
55.
? I'm not interested in the plot, or the characterisation, or anything of that nature — I'm interested in the novel.
Notice that 54 is more or less normal: the ‘physical object’ reading is explicitly denied, and novel is consequently understood with the ‘text’interpretation.
Sentence 55, on the other hand, is uninterpretable: since the ‘text’ reading has been excluded, it appears that there is no other possible reading, so the sentence is anomalous.
It would make sense if we were free to take novel to refer to the physical object; but in this sentence such an interpretation is not available.
It seems reasonable to conclude that only the ‘text’ reading is fully established.
In the case of the numerals, it is the ‘exactly X’ reading which is fully established according to this test.
Thus the final £10 in 56, if it carries the main sentence stress, can only mean ‘exactly £10’:
56.
A: I would earn at least £10 an hour there.
B: Well, here you'll earn £10.
However, the bare mention of £10 cannot carry the ‘at least’ interpretation in contrast to an explicitly expressed ‘exactly £10’:
57.
A: I would earn just £10 an hour there.
B:?
Well, here you will earn £10.
If the ‘at least’ reading had been available, the sentence would not be odd.
From this we may conclude that the ‘at least’ sense of numerals is not established.
In the case of the unit-type ambiguity, it is the unit readings which pass this test (cf. 58), while the ‘type’ readings fail (cf. 59):
58.
I don't want that type of jacket, I want that jacket.
59.
? I don't mean that individual dog, I mean that dog.
In all the above cases, the lexical form in question has only one established sense.
This, however, is not a rule: more than one sense may be established, as the normal interpretability of all the following examples shows:
60a.
I'm not only interested in male dogs, I'm interested in dogs.
b.
I'm not interested in all members of the canine race irrespective of sex — I'm interested in dogs.
61a.
I didn't put my money in the side of a river, I put it in the bank.
b.
I didn't moor the boat to a financial institution, I moored it to the bank.
62a.
Charles has moved to another seat in the conference hall, but he has not changed his position.
b.
Charles hasn't changed his mind on EEC membership, but he has changed his position.
These examples point to a limitation on one of the tests for ambiguity elaborated earlier.
It appears that certain ways of applying the criterion of independent maximisability are valid only for established senses.
Sentences of the form of 26, for example, require established senses.
Negative results in such cases must therefore be checked either against other criteria, or against other ways — such as the Yes /No -test — of applying the same criterion.
(Positive results, of course, present no problems.)
The number of fully established senses is presumably finite at any one time (though it may differ for different members of the language community, and at different times for the same speaker).
It might therefore be thought advantageous to limit the class of lexical units to these.
However, although our attention will naturally be more strongly drawn to established senses, to limit the discussion in principle to these would lead to a distorted picture of word-meaning.
This is because less-than-fully-established senses  are lexicologically almost indistinguishable from fully established ones, in that they enter largely the same range of syntagmatic and paradigmatic relations of meaning (the sentences cited above, of course, show that they are not absolutely identical).
We shall therefore not limit our investigations in any principled way to established senses; whether a sense is established or not is, however, of significance for lexicography.
3.8 Sense-spectra
It has been argued up to now that although word-meaning is in a sense infinitely variable, nonetheless discrete units —‘atoms’ or ‘quanta’of sense — can be identified which at least in some respects are stable across contexts, and which are the appropriate basic units for lexical semantics.
Certain aspects of word-meaning, however, are difficult to reconcile with this view: particularly awkward are what we shall term sense-spectra .
There are cases where variant readings of a single lexical form would seem to be more appropriately visualised as points on a continuum — a seamless fabric of meaning with no clear boundaries.
This would not necessarily conflict with the picture of word-meaning developed so far if a single superordinate sense could be found which covered all the variants.
However, there do appear to exist examples of gradual variation which cannot be made to share a superordinate; in such cases the absence of boundaries between senses is an embarrassment.
The appearance which sense-spectra present can be compared with a so-called ‘dialect continuum’: speakers from village A can communicate with those from village B, who are able to converse with speakers from C; these, in turn, can communicate with speakers from village D. However, speakers from A cannot hold a conversation with speakers from D, and without the evidence of the intervening stages, one would be tempted to say that they spoke different languages.
But it is impossible to say at what point along the continuum the change from one form of the language to another occurs, or to determine how many distinct forms there are.
Another analogy is with the evolutionary biologist's notion of a ‘ring-species’: a population A, of some species, interbreeds with a neighbouring population B, B with C, C with D, and so on, round the world, until population X is reached, whose territory adjoins that of the original A. But A and X do not interbreed: they give every appearance of being distinct species.
Again it is impossible to say where the change-over from one species to the next occurs, and how many species there are.
The fact seems to be that in such cases it is inappropriate to think in terms of discrete variation.
In the semantic analogues to these  continua, two readings which are close together on the continuum can be coordinated without zeugmatic incompatibility (this is the semantic parallel to mutual intelligibility and interbreeding), whereas readings which are far apart are incompatible.
Examples of this are far from rare: on the contrary, this state of affairs would seem to be the norm, for example, for senses which have undergone ‘metaphorical extension’.
As an example of this sort of semantic continuum, which we shall call a sense-spectrum , consider the following use of mouth:
63.
John keeps opening and shutting his mouth like a fish.
64.
This parasite attaches itself to the mouths of fishes, sea-squirts, etc. 65.
The mouth of the sea-squirt resembles that of a bottle.
66.
The mouth of the cave resembles that of a bottle.
67.
The mouth of the enormous cave was also that of the underground river.
Allowing for a degree of non-anomalous unusualness in the sentences (such sequences are, for various reasons, rather difficult to construct) it seems that we have got from John's mouth to the mouth of the river without encountering zeugmatic incompatibility.
The normal conclusion from this would be that the readings of mouth in 63–67 were contextual modulations of a single superordinate sense.
This is ruled out, however, not only by the difficulty of finding a paraphrase of the supposed superordinate sense, but also by the clearly zeugmatic nature of 68:
68.
? The poisoned chocolate entered the Contessa's mouth at the same instant that the yacht entered that of the river.
This is, of course, a simplified picture of a sense-spectrum: it should be thought of as having, at least potentially, many dimensions, and as continually growing, amoeba-like.
One of the points on the sense-spectrum presented above — and this is typical of the metaphorical variety — has a special status, which manifests itself in two principal ways.
First, it is the only sense which can appear in a neutral, or minimal context, as in 69:
69.
At school, we are doing a project on mouths.
It seems unlikely that 69 could be taken to include river mouths.
All the other possibilities are highly context-bound, in that they can only appear in relatively explicit contexts-compare the a and b sentences in the following:
70a.
? The body was found near the mouth.
b.……the mouth of the cave.
71a.
? This bird is often to be seen near mouths.
b.……the mouths of rivers.
(cf. also:……near estuaries.) 72a.
? The candle was stuck in the mouth.
b.……the mouth of the bottle.
The independent sense is often also the ‘literal’ sense, in that it is the only one, or at any rate the most plausible one, from which all the others can be derived by metaphorical interpretation.
(It may sometimes happen that of two senses, either one could plausibly be a metaphorical extension of the other, as with, for example,expire (driving licence, etc.) and expire (person).)
In the case of mouth , if one knew what an animal's mouth was, and one were to hear, for the first time, a reference to the mouth of a river , I surmise that there would be little difficulty in construing the meaning; but suppose one were familiar only with mouth used to refer to the mouth of a river, and one heard a reference to the horse's mouth , it is by no means certain that one's attention would be directed to the appropriate end of the horse!
The proper descriptive treatment of sense-spectra, and points along them, is somewhat problematical.
A full sense-spectrum is not a satisfactory lexical unit: it does not, for instance, enter into any recognised lexical relations.
Individual points along a spectrum, on the other hand, seem at first sight to be insufficiently distinguished from one another.
However, there are reasons for believing that these are the most appropriate lexicological units.
Although when viewed as part of a spectrum their distinctness is questionable, they typically function in widely different semantic fields, and within these their discreteness and stability are not in question.
Take the case of mouth of river: it participates in a significant number of meaning-relations:
mouth:source (opposites) mouth: river (part-whole) mouth: bed (coordinate parts) mouth:estuary (superordinate-hyponym)
None of these relations are shared by, for instance,mouth of bottle .
Furthermore, the sense of mouth (of river ) is stable across a variety of contexts (i.e. subject only to modulation) provided that‘of river’ is understood.
So far, so good.
But here we are faced with a dilemma.
If we allow the existence of distinct sets of lexical relations to individuate senses along  a sense-spectrum, we are re-instating the indirect criteria dismissed earlier as being inadequate.
If, on the other hand, we adopt a complex unit such as mouth of river as a basic lexical unit, this would be inconsistent with our earlier decision not to regard, for instance,foot the bill as a single unit.
We shall adopt here the first of these solutions, as being the least objectionable of the two.
That is to say, we shall recognise sense-units along a sense-spectrum — to be called local senses — by their participation in distinct lexical fields (here, to be understood merely as sets of lexical items interrelated by determinate meaning relations such as oppositeness, hyponymy, part-whole, etc.).
This method of delimiting senses will be confined to sense-spectra.
The true extent of the phenomenon is not at present clear, but not all sense-spectra are of the metaphorical sort.
It seems likely, for instance, that the senses of handle form a spectrum:
handle of door
of drawer
of suitcase
of umbrella
of sword
of knife
of spoon
There is more than a suspicion of zeugmatic tension when the end-items are yoked together:
?
He grasped the handle of the door in one hand, and that of the spoon in the other.
The different senses of handle can be delimited in the manner suggested above for mouth .
3.9 Syntactic delimitation
Lexicological units must not only be delimited paradigmatically, that is, within a constant syntactic frame: we want also to be able to say of two occurrences of a lexical form in different syntactic environments whether they are occurrences of the same lexical unit, or two different units.
Consider the occurrences of open in the following:
73a.
The open door b.
The door is open.
c.
The door won't open.
d.
John will open the door.
How many different items open are represented here?
The sort of criteria which we used for paradigmatic delimitation are of no help here.
It would seem reasonable to adopt as a general principle that any two occurrences of a lexical form which represent two different grammatical elements should be regarded,ipso facto , as lexically distinct.
However, there does not seem to exist an accepted notion of ‘grammatically different element’ which is sufficiently well-defined to carry the whole burden of distinguishing lexical units.
Mere occurrence in syntactically different environments is not a sufficient criterion for the grammatical distinctness of two elements.
For instance, the following two occurrences of man can be said to be in syntactically different environments:
74a.
Arthur saw the man.
b.
The man's brother was here.
However, there are various reasons for saying that man is the same grammatical element in 74a and b.
An important one is that the possible substitutes for man (preserving grammaticality, but not necessarily semantic normality) are virtually identical in the two positions.
We might therefore demand difference of grammatical paradigm as a minimum requirement for distinctness.
However, this is not sufficient, either, although it may well be necessary.
Consider the following examples:
It is extremely dubious, in spite of the differences in grammatical paradigm, whether anything would be gained by classifying the two occurrences of old , or those of eat , as grammatically, hence lexically, distinct.
Other purely grammatical criteria may be suggested, but none seem capable of guaranteeing the desired results.
A more satisfactory way of delimiting lexical units is to look for grammatical  differences which correlate with differences of meaning.
Take, for example, the occurrences of open cited above (73a-d).
Grammatically distinctive traits can be found for each of these.
Looking, for instance, at grammatically equivalent substitutions,main is possible only in a,ajar only in b,disappear only in c, and hit only in d.
Other differences may be cited: only in c and d can open take —s as an affix, and only in a and b can open be modified by wide ; c and d differ in that the noun phrases which form normal subjects of open in c are those which form normal objects of open in d (and similarly with odd subjects in c), so that, for example , the normality of The book opened is paralleled by that of John opened the book , and the oddness of?
The page opened by that of?
John opened the page .
Most, but not all, of these grammatical differences are correlated with semantic differences.
Taking the meaning of open in 73b as basic, we can paraphrase 73c (not exactly, but quite closely) as ‘the door came to be open’, and 73d as ‘John caused the door to come to be open.’
In any sentence, the appropriate interpretation of open can be determined from its grammatical nature (i.e. whether it is adjective, transitive or intransitive verb, etc.).
The fact that the occurrences of open in 73b, c and d exemplify a regular correlation between semantic and grammatical properties provides a justification for regarding them as lexically distinct.
However, there is no similar way of differentiating 73a and b semantically, so, in spite of grammatical evidence of distinctness, they are to be considered lexically identical.
3.10 Lexemes
One of the most remarkable features of language is the fact that it ‘makes infinite use of finite resources’.
This dictum is more familiar in its application to grammar.
But it is valid also for the lexical domain.
We have already had glimpses of the indeterminate multiplicity of lexical senses: a lexicographer, however, needs a finitely enumerable set of lexical elements with which to work.
The appropriate unit for this purpose is the lexeme : a dictionary contains (among other things) an alphabetical list of the lexemes of a language.
We shall characterise a lexeme as a family of lexical units.
However, before outlining the principles governing the assignation of lexical units to lexemes, it is necessary to introduce a refinement into our conception of a lexical unit.
We have so far assumed that it is a word form associated with a single sense, and that a difference of word form entails a difference of lexical unit.
But this is not quite satisfactory.
Strictly speaking, we would be obliged, on this view, to regard, for instance,obey ,obeys and obeyed as representing different lexical units.
It would, however, be more advantageous for our purposes to be able to say that they were alternative manifestations of the same lexical unit obey .
To characterise the form aspect of a lexical unit, therefore, we need to generalise across — or abstract from — a set of word forms.
In order to characterise this more abstract notion of lexical unit more precisely, a distinction must be made between inflectional and derivational affixes.
An affix is a grammatical element, belonging to a closed set, which can only function as a component of a word:dis —,un —,—ment ,—ise ,—ed ,—s are all affixes.
Each affix is obligatorily attached to a stem containing or consisting of an open set item:dis-obey ,un-popular ,central-ise ,dismount-ed ,long-er , etc.
A stem may be simple (as obey in dis-obey ), or complex (as disobey in dis-obeyed ).
Affixes are of two sorts — derivational and inflectional.
Derivational affixes produce new lexical units:true :untrue ,kind :kindness ,help :helpful ,lion :lioness , etc.
They play no direct role in the syntax of a sentence, and can be recognised by the fact that words containing them (derived words ) can typically be replaced in any sentence, without syntactic change, by a word which does not contain the affix:
Her kindness (voice) was overwhelming.
I found them extremely helpful (stupid).
Typically, derived words are listed as separate items in a dictionary.
Inflectional affixes, on the other hand, do not produce new lexical units:book :books ,obey :obeyed ,long :longer .
In principle for any word bearing an inflectional affix, it is possible to find contexts where all possible substitutes must contain either the same affix, or one belonging to the same closed set: consider the possible substitutes for walked in Cedric walked home ,longer in Mine is longer than yours or books in those books .
We can now re-define a lexical unit.
First, we may call the abstract unit of form which is realised in actual sentences as the appropriate member of a set of word forms differing only in respect of inflections a lexical form ; and we can extend the notion of lexical form to cover an abstraction from the variously inflected manifestations of an idiom or dead metaphor.
A lexical unit is then the union of a lexical form and a single sense.
Let us now return to the question of assigning lexical units to lexemes.
For lexical units with identical grammatical properties, two alternative criteria for membership of the same lexeme will be proposed.
The first is the most important.
It is that two lexical units will be assigned to the same lexeme if there exists a lexical rule which permits the prediction of the existence of the sense of one of them from the existence of the  sense of the other.
The existence of a rule presupposes that senses associated with more than one lexical form fall within its scope (otherwise there would be no rule).
Hence, we shall accept as evidence of the presence of a rule a recurrent semantic contrast between senses, that is to say, a contrast which holds between senses associated with at least two different lexical forms.
On this basis, the unit and type readings of jacket in I like this jacket belong to the same lexeme, because the same contrast recurs with skirt ,dress ,coat ,hat , etc.
(We shall not concern ourselves here with the exact formulation of the regularity: we shall merely note the evidence of its presence.)
Similarly, the two lexical units represented by brilliant in John is brilliant and This is a brilliant book are to be assigned to the same lexeme, the evidence being the recurrence of the relation with confused ,angry ,bitter , etc.
A parallel situation exists with sad in John is sad and This is a sad poem ; this relationship, too, is recurrent (cf. light-hearted ), but is different from that observed in the case of brilliant .
A brilliant book is (roughly) the expression of a brilliant person, but a sad poem is rather one which induces sadness in the reader.
Consider, too, the two readings of flatten out which occur in 77 and 78:
77.
The surface of the mixture began to flatten out.
78.
After Kendal, the countryside begins to flatten out.
The same difference of sense recurs in the following:
79.
The soil began to dry up.
80.
Once you leave the Bekaa Valley, the countryside begins to dry up.
Examples such as these can be multiplied indefinitely.
It is perhaps worth noting briefly at this point a special type of recurrent semantic relationship between lexical units sharing a lexical form, which is of particular significance in lexical semantics (it is discussed in greater detail in connection with markedness and neutralisation in chapter 11).
The two senses carried by the lexical form dog in 81a and b, and the two senses of lion in 82a and b, and of heavy in 84a and b stand in a relation of this type:
81a.
Dogs, both male and female, make excellent pets.
b.
Dogs are more aggressive than bitches.
82a.
Lions breed well in captivity.
b.
When fully grown, a lion is bigger than a lioness.
The two senses of long in 83a and b, and of heavy in 84a and b stand in a slightly different relation, but one of the same type:
83a.
How long is it? b.
How long it is! 84a.
How heavy is it? b.
How heavy it is!
The alternative criterion for assigning lexical units to a single lexeme is that their senses should be local senses belonging to the same sense-spectrum.
Thus all the senses of mouth discussed earlier will represent lexical units belonging to a single lexeme.
This criterion is quite strict, and does not allow the grouping together of all senses normally considered to be metaphorically related.
For instance, there is no spectrum connecting the two senses of expire , so their lexical units would not be assigned to the same lexeme.
The same is true of the readings of position that we have examined in connection with ambiguity.
This differs from normal lexicographic practice, which is to group all metaphorically related senses together.
Among the lexical units which go to make up a lexeme it is possible to distinguish some that are more basic, or central, and others that are less so.
It is clear that established units (i.e. those with established senses) are more central than unestablished ones: an ideal dictionary would be expected to define all the established senses within each lexeme.
But even among established units we can distinguish grades of centrality.
Most basic of all are lexical units which become operative in minimal, or neutral, contexts.
These may be termed the primary lexical units of a lexeme — a category that would include, for instance,dog (’ species’),heavy (’weight’),novel (’text’), etc.
Some lexical units, even though established, are selected only in specific restricted contexts, or in contexts where the primary units would lead to abnormality.
This is true of dog (’ male’),heavy (’copious consumption’), etc.
Such units may be termed secondary (the primary/secondary distinction here is not, of course, a strict dichotomy — the accessibility, or ease of activation, of lexical units may be assumed to vary continuously).
There remain the unestablished units, generally indeterminate in number, and varying in the degree of contextual pressure required to activate them.
Probably some degree of oddness is an inescapable penalty for calling an unestablished unit into service; this abnormality may be very slight, as in A large novel fell on my head , or it may be considerable, as in I received a lot of kindness from him — would you like to try a bottle ?:
The principle of recurrent relationships can also serve for the association of grammatically different lexical units.
In such cases, the recurrent relationship must be simultaneously grammatical and semantic if the units  are to be assigned to the same lexeme.
The following are examples of such recurrence:
85a.
John moved the rock /The rock moved.
b.
John turned the key /The key turned.
86a.
Have some apple /Have an apple.
b.
Have some potato /Have a potato.
87a.
Put them in a can /Can them.
b.
Put them in a box /Box them.
Notice, however, that although the following exhibit a syntactic parallel with the cases cited above, the semantic relationship is not maintained, so the lexical units must be assigned to different lexemes:
88.
Get him into a corner /Corner him.
89.
Put his name in a book /Book him.
Again, this is not in accordance with normal lexicographic practice, which is, first, to regard differences of major syntactic category (e.g. noun, verb, adjective) as justifying a separate main entry, irrespective of the presence or absence of recurrent relationships.
In respect of minor syntactic differences (e.g. transitive v .
intransitive verbs; mass v .
count nouns, etc.) dictionary makers are generally somewhat inconsistent.
To summarise: a lexeme is a family of lexical units; a lexical unit is the union of a single sense with a lexical form; a lexical form is an abstraction from a set of word forms (or alternatively — it is a family of word forms) which differ only in respect of inflections.
It is commonplace to describe a lexeme which has a number of senses as polysemous (or as manifesting the property of polysemy ), and a lexical form which realises lexical units belonging to more than one lexeme as homonymous .
These terms, especially polysemous and polysemy , although innocuous if used circumspectly, are not entirely ideal for our purposes, because they carry with them a view of lexical meaning in which there is a tendency to regard the lexeme as the primary semantic unit, and the different lexical units as ‘merely variants’.
Our approach, however, focusses on the individual lexical unit as the primary operational semantic unit, and consigns the lexeme to a secondary position.
4
Introducing lexical relations
4.1 Preliminaries
Beginning with this chapter, and running through to chapter 12, the principal topics of discussion will be various types of semantic relation which hold between lexical units of the kind established in chapter 3.
There may appear to be an element of paradox in the notion of semantic relations between lexical units whose meanings, at least on the strong version of the contextual view, are partially constituted by those very relations.
It is, however, no more paradoxical than speaking of John's arm , when the arm in question is part of the John who is said to possess it (or the chassis of the car , for ).In such cases we have a notion of a whole which is more, at least phenomenologically, than a mere assemblage of parts.
The same is true of the meanings of lexical units: each one consists of an indefinite number of contextual relations but at the same time constitutes a unified whole.
Hence it is not unnatural to speak of a lexical unit standing in a particular semantic relation to other lexical units.
The paradox does not present itself in quite so acute a form if a weaker version of the contextual approach is adopted, which holds merely that the meaning of a lexical unit reveals itself through its contextual relations, without commitment as to what meaning ‘really is’.
Although no meaning relation can be said to be totally without significance, by no means all conceivable relations are of equal general semantic interest.
To be worth singling out for special attention, a semantic relation needs to be at least systematic, in the sense that it recurs in a number of pairs or sets of related lexical units (it will be recalled that the expression lexical unit is used to refer to a lexical form together with a single distinguished sense).
But even recurrent sense relations are of varying general significance.
There are innumerable ‘low level’ semantic relations restricted to specific notional areas.
Take, for example, the relations between the lexical items see (’ have a visual experience’),look at (’pay attention to a static visual stimulus’), and watch (’pay attention to a changing  or potentially changing visual stimulus’).
If we examine the lexical units referring to other modes of perception we find the following correspondences:
Notice that although listen to corresponds to two different lexical units in the visual mode, it is not ambiguous; the word forms taste ,smell and feel , on the other hand, are ambiguous in parallel ways, their senses standing in a relationship parallel to that which holds between hear and listen to .
Looking now at French, we find that for terms referring to the visual mode, the look at :watch contrast is absent, the notional area being covered by a single, univocal item regarder .
In the auditory mode, French closely parallels English, with entendre and écouter .
Corresponding to taste 1  ,smell 1  and feel 1  , French has a single item sentir 1  , which is non-specific with respect to the three perceptual modes; there is, however, a distinct sentir 2  , which corresponds to smell 2  .
For the ‘pay attention’ meaning in the other two sensory modes, French provides distinct lexical items:goûter , corresponding to taste 2  , and toucher , corresponding to feel 2  .
Now the detailed structure of these lexical sets in English and French, although of intense concern to students of English and French, cannot be generalised to other sets; nor can the semantic contrast ‘have an experience in a particular perceptual mode’v .
‘pay attention to a stimulus in that mode’.
At this level of specificity, therefore, these facts are of limited significance for a general study of lexical semantics.
However, the abstract pattern of lexical items in parallel series is of considerable general significance, and is not confined to particular notional areas.
(Lexical configurations of this sort are discussed in chapter 5.)
Or take the semantic relation between dog and cat .
At its most specific, it has a very limited currency: it recurs between canine and feline , and between puppy and kitten — but that is about all.
However, at a more abstract level, the level at which dog :cat ,church :cinema ,oak :ash and tea :coffee can all be said to manifest the same relation, it is of fundamental significance.
Sense relations of the more specific sort are obviously too numerous and too idiosyncratic to form the basis for a general study of lexical semantics.
In this book, therefore, attention is concentrated on relations of the more abstract sort.
A relatively small number of these have come to occupy  focal positions in discussions of lexical semantics (such relations as antonymy, hyponymy and synonymy), and they form correspondingly prominent topics of the present and succeeding chapters.
Sense relations are of two fundamental types: paradigmatic and syntagmatic.
Most of this book is devoted to paradigmatic sense relations (lexical semanticists, in general, have found them a richer vein to mine than relations of the syntagmatic variety).
However, although syntagmatic relations have only one section of a chapter specifically devoted to them, it is in fact impossible adequately to discuss one type without frequent reference, either explicit or implicit, to the other type.
(Abnormality, for instance, is a reflection of a syntagmatic relation.)
The two types of relation each have their own distinctive significance.
Paradigmatic relations, for the most part, reflect the way infinitely and continuously varied experienced reality is apprehended and controlled through being categorised, subcategorised and graded along specific dimensions of variation.
They represent systems of choices a speaker faces when encoding his message.
Syntagmatic aspects of lexical meaning, on the other hand, serve discourse cohesion, adding necessary informational redundancy to the message, at the same time controlling the semantic contribution of individual utterance elements through disambiguation, for instance, or by signalling alternative — e.g. figurative — strategies of interpretation.
The main purpose of the present chapter is to develop some basic concepts that will be used throughout the subsequent discussion of semantic relations.
In sections 4.2–4.7 certain elementary relations between sets are used as a model to generate (i) a basic set of paradigmatic lexical relations and (ii) a set of concepts which can be applied to other relations, yielding clearly defined and systematic variants.
In sections 4.8–4.12 a further set of qualifying concepts is presented which will help to identify in a systematic way a number of near relations of, and approximations to, more basic paradigmatic relations.
Finally, section 4.13 introduces syntagmatic semantic relations, and briefly considers some aspects of syntagmatic-paradigmatic interconnections.
4. 2 Congruence
The four basic relations between classes furnish a model not only for establishing a fundamental group of sense relations, but also for defining a set of systematic variants applicable to virtually all other paradigmatic sense relations.
The basic lexical relations will be referred to collectively as congruence relations , and the variants as congruence variants .
The relations between classes are as follows:
1.
identity: class A and class B have the same members 
2.
inclusion: class B is wholly included in class A 
3.
overlap: class A and class B have members in common but each has members not found in the other 
4.
disjunction: class A and class B have no members in common 
This model can be applied to the definition of a set of lexical relations in two ways.
The first possibility is to adopt a referential viewpoint.
For two lexical items A and B we can ask whether the respective classes of entities they denote are identical, disjunct, overlapping, or whether one includes the other.
This approach is convenient, and we shall often have recourse to it; however, it has disadvantages (even supposing that a fully adequate account can be given of such notions as ‘the class of dogs’).
One difficulty is that the approach is not sufficiently general: many words do not in any straightforward way denote classes of potential referents (consider air ,some ,usually ,however ).
There are also problems with words like unicorn ,roc ,elf and dragon .
One would wish to say that there was  a semantic relation between, say,unicorn and animal , yet the class of animals contains no unicorns.
A better approach to the study of the semantic relations between two lexical items X and Y is to operate directly in terms of meaning, and look at semantic relations between parallel sentences in which X and Y occupy identical structural positions.
The most useful primary lexical relations are established using truth-conditional relations between containing sentences.
In appropriate cases (i.e. with items that denote classes of entities) this method gives results identical to those obtained with referential classes, but has the advantage of greater generality.
Let us now consider the primary lexical relations (i.e. congruence relations) individually and in detail.
4.3 Cognitive synonymy
The lexical relation which parallels identity in the membership of two classes is, of course, synonymy.
As we shall see in chapter 12, there are different degrees of synonymity; the relation defined in terms of truth-conditional relations will be distinguished as cognitive synonymy .
Cognitive synonymy may be defined as follows:
X is a cognitive synonym of Y if (i) X and Y are syntactically identical, and (ii) any grammatical declarative sentence S containing X has equivalent truth-conditions to another sentence S 1 , which is identical to S except that X is replaced by Y.
An example of a pair of cognitive synonyms is fiddle and violin : these are incapable of yielding sentences with different truth-conditions.
For instance,He plays the violin very well entails and is entailed by He plays the fiddle very well .
4.4 Hyponymy
The lexical relation corresponding to the inclusion of one class in another is hyponymy .
Defining hyponymy is less straightforward than defining cognitive synonymy.
For reasons which will become apparent in due course, it is necessary to restrict the type of sentence used in the definition.
Ideally one would like to be able to give a general characterisation of suitable sentence types; unfortunately this is not at present possible.
What we shall do instead is to restrict the definition to one selected sentence type which happens to work, namely, that represented by the schema A is f(X) , where f(X) is an indefinite expression, and represents the minimum syntactic elaboration of a lexical item X for it to function as a complement of the verb to be .
X will be said to be a hyponym of Y (and, by the same token, Y a superordinate of X) if A is f(X) entails but is not entailed by A is f(Y) :
This is a DOG unilaterally entails This is an ANIMAL That is a STALLION That is a HORSE This is a SCARLET flower This is a RED flower He is a man who MURDERED someone He is a man who KILLED someone 
Even with sentences not of the form A is f(X) it is often the case that a sentence containing a hyponym unilaterally entails a parallel sentence which is identical in all respects except that it contains a superordinate in place of the hyponym:
John punched Bill unilaterally entails John hit Bill She wore scarlet shoes unilaterally entails She wore red shoes 
Conversely, unilateral entailment between two sentences differing only in respect of the lexical fillers of a particular syntactic slot is often an indication of a hyponymous relation between the lexical units.
However, the many and varied exceptions to both these general tendencies render it impracticable to frame a more general definition of hyponymy along these lines.
In the following sentences, for instance, the entailment (unilateral in each case) is in the ‘wrong’ direction (i.e. from superordinate to hyponym):
It's not red entails It's not scarlet 
All animals are forbidden entails All dogs are forbidden 
I always avoid the red ones entails I always avoid the scarlet ones 
Without the red ones there will still be too many entails Without the scarlet ones there will still be too many 
If it is red, it will be rejected entails If it is scarlet, it will be rejected 
It is possible to formulate rules for predicting the direction of entailment in such cases.
For instance, if the hyponym and superordinate fall within the scope of a negative, or a universal quantifier (e.g. all ,every ,each ), or if they form part of a conditional clause or other expression of contingency, then the direction of entailment will be reversed.
However, there are complications.
For instance, the three factors mentioned interact with one another , so that if any two are simultaneously applicable, the entailment is in the ‘normal’ direction, i.e. from hyponym to superordinate.
In 1,dogs and animals are within the scope (’ field of action’) both of the negative not and the universal quantifier all ; in 2,scarlet and red are within the scope of not , and form part of a conditional clause; in 3,cars and vehicles are within the scope of all , and are part of a conditional clause:
1.
Not all dogs are dangerous entails Not all animals are dangerous 2.
If it's not scarlet, it will be rejected entails If it's not red it will be rejected 3.
If all cars are forbidden, I shan't go entails If all vehicles are forbidden, I shan't go 
When all three factors apply, entailment is once again reversed:
4.
If not all vehicles are forbidden, I shall go entails If not all cars are forbidden, I shall go 
(Some readers may find this last example difficult to construe.
Think of it this way: if it is the case that an incomplete embargo on vehicles will result in my going, then anything that entails an incomplete embargo on vehicles will result in my going; an incomplete embargo on cars entails an incomplete embargo on vehicles, so an incomplete embargo on cars will result in my going.)
These regularities follow from elementary logical principles.
However, while the logical principles are straightforward, the application to natural language is not quite so straightforward, because the crucial factors — negatives, conditionality, etc. — may not be overtly expressed.
Consider, for instance, the different entailment relations in 5 and 6, and in 7 and 8:
5.
It is important to avoid red socks entails It is important to avoid scarlet socks 6.
It is important to buy red socks does not entail It is important to buy scarlet socks 7.
Flowers are prohibited entails Dandelions are prohibited 8.
Flowers make an acceptable present does not entail Dandelions make an acceptable present 
There are no overt elements in these sentences to explain the differences; presumably, however, 5 and 7 contain implicit universal quantification.
These are not the only problems.
In another class of instances, hyponym and superordinate in parallel positions yield no entailment at all.
For example,It turned scarlet does not entail It turned red , since the referent of it may have been some other shade of red to begin with; nor, obviously, does the reverse entailment hold.
For somewhat different reasons in each case, there is not entailment between I chose the first rose on the list and I chose the first flower on the list , nor between Mary was disappointed to receive a rose and Mary was disappointed to receive a flower (perhaps she was expecting an orchid?).
Entailment can occur between sentences differing only in respect of the lexical fillers of a particular syntactic slot even when the lexical items in question are not related by hyponymy.
This introduces further complications into the task of providing a principled account of the relations between hyponymy and entailment; 9 provides an example:
9.
The boil is on John's elbow entails The boil is on John's arm 
It should be clear by now that the relations between hyponymy and entailment are quite complex; however, the definition of hyponymy adopted earlier bypasses these problems, so we shall pursue them no further.
There are other diagnostic tests for hyponymy which are either discriminatory but insufficiently general, or general but insufficiently discriminatory.
For instance, a hyponym is often cognitively equivalent to a paraphrase in which a superordinate is syntagmatically modified.
The equivalence between queen and female monarch , and kitten and young cat , for instance, establishes queen as a hyponym of monarch , and kitten as a hyponym of cat .
Where such equivalences can be found, they constitute satisfactory proof of hyponymy.
However, by no means all hyponyms stand in a relation of cognitive equivalence with an expression containing a superordinate.
There is, for example, no possible syntagmatic modification of animal which would render it cognitively equivalent to dog (or elephant ,mouse ,crocodile ,…).
Hyponymously related lexical items occur normally, in the appropriate order, in expressions such as the following:
dogs and other animals There's no flower more beautiful than a rose.
He likes all fruit except bananas.
She reads books all day — mostly novels.
Any attempt to frame a definition along these lines, however, would run aground because, although such a definition could be made fairly general, it would not discriminate sharply enough to provide a guarantee of hyponymy:
dogs and other pets snakes and other poisonous creatures There's no weapon as versatile as a knife.
None of the above expressions contain lexical items related by hyponymy according to our definitions:?
A dog is necessarily a pet ,?
A snake is necessarily a poisonous creature ,?
A knife is necessarily a weapon .
It might be thought that it should be possible to characterise hyponymy in terms of contextual normality.
A hyponym, being more specific in sense than its superordinates, might be expected as a result to be more fastidious in respect of its lexical companions; and thus the normal contexts of a hyponym might reasonably be expected to constitute a sub-set of the normal contexts of a superordinate.
By and large, this is true; for example , the lexical clash in?
The cat barked is removed when cat is replaced by the superordinate animal .
But it is not invariably the case, which makes it impracticable to define hyponymy in this way, unless the exceptions to the general tendency can be characterised precisely.
Unfortunately, it is not clear how to characterise those contexts, like the following, in which a hyponym can be more normal than one of its superordinates:
Prime ministers who are women are rare.
? Prime ministers who are human beings are rare.
4.5 Compatibility
The lexical relation which corresponds to overlap between classes will be given the name compatibility .
The defining characteristics of compatibles (lexical items related by compatibility) are two.
The first is that there are no systematic entailments between sentences differing only in respect of compatibles in parallel syntactic positions.
So, for instance, if X and Y are compatibles, then A is f(X) and A is not f(X) are logically independent of A is f(Y) and A is not f(Y) .
This criterion on its own does not guarantee any but the most tenuous relation of sense, since, for instance,harmless is compatible with heavy , and rare with round .
The second defining characteristic of compatibility guarantees a genuine relationship of sense: it is that a pair of compatibles must have a common superordinate.
Compatibles, therefore, have some semantic traits in common, but differ in respect of traits that do not clash.
The relationship is exemplified by dog and pet .
They both fall under the superordinate animal (in the sense of ‘creature’); and It's a dog and It's not a dog have no necessary links with It's a pet and It's not a pet .
Another pair of compatibles is husband and policeman ; both belong to the category  of human males, and Arthur is/is not a husband and Arthur is/is not a policeman are logically independent.
Two varieties of compatibility can be distinguished:strict compatibility and contingent compatibility .
X and Y are strict compatibles if they have at least one shared hyponym or hyponymous expression which is independently characterisable.
Take the case of snake and poisonous creature .
It's a snake entails neither It's a poisonous creature nor It's not a poisonous creature ; likewise,It's a poisonous creature is logically independent of It's a snake .
Snake and poisonous creature are strict compatibles because adder and cobra , for instance, are hyponymous to both; furthermore, these species are independently characterisable — that is , they are not established solely on the basis of venomousness.
(Adders and cobras are not, of course, necessarily venomous, only canonically so, since any individual snake may have had its venom extracted.)
Contingent compatibility is more common.
It is exemplified by dog and pet : every dog is, in principle, a potential pet .
There is no independently characterisable subclass of dogs for which being a pet is a necessary or canonical trait (lap-dogs do not count, because they cannot be distinguished without invoking the characteristic of pet-hood); nor are there distinguishable sub-types of pet which are canonically or necessarily dogs (except, of course, lap-dogs, which do not count here, either, and for parallel reasons).
4.6 Incompatibility
The sense relation which is analogous to the relation between classes with no members in common is incompatibility.
Two lexical items X and Y are incompatibles if a sentence of the form A is f(X) can be found which entails a parallel sentence of the form A is not f(Y) :
It's a cat entails It's not a dog It's a carnation entails It's not a rose John is the one who is walking entails John is not the one who is running John is near the building entails John is not in the building 
There are certain parallels between incompatibility and compatibility.
Like ‘mere’ compatibility, ‘mere’incompatibility is of relatively little interest: the fact that affix and volcano are incompatibles is not specially informative.
However, a special significance attaches to sets of incompatibles (as well as to compatibles) which fall under a single superordinate:
animal :cat ,dog ,lion ,elephant ,aardvark , etc.
Declarative sentences identical except for different incompatible terms in parallel syntactic positions (besides those used in the test) are frequently in a contrary relationship: if I cycled to work is true, then I walked to work is false, but if I cycled to work is false, then I walked to work may be either true or false.
However, the relationship between incompatibility and contrariety in natural sentences, like the relationship between hyponymy and entailment, is by no means straightforward, and the expected contrariety does not always appear.
For instance, the truth of I met Mary today does not entail the falsity of I met Mary yesterday , although yesterday and today are incompatibles.
However, if both are true, they obviously refer to different occasions of meeting Mary — a single occasion of meeting cannot be both yesterday and today.
The contrary relation will therefore show up in a sentential context that specifies, or at least implies, that a single event is being referred to, such as I only met Mary once, and that was today/yesterday or (somewhat less convincingly)It was today/yesterday that I met Mary .
Another example is I bought some apples , which does not stand in a contrary relationship with I bought some pears .
In this case, both sentences can be true without their necessarily referring to separate events: one may purchase apples and pears simultaneously.
Contrariety will only appear here if it is specified that apples (or pears) constituted the whole of the purchase:All I bought were some apples/pears .
Colour terms present a particular problem.
Most speakers would agree, I think, that Mary wore a red dress and Mary wore a blue dress were contraries (assuming, of course, that they refer to the same occasion, and that Mary, as would be normal, wore only one dress at a time); the colour terms refer to the predominant colour of the dress, and there can be only one predominant colour.
But colour terms frequently qualify only part of the object their head noun denotes; furthermore, different colour terms may typically apply to different parts, so that, for instance ,Mary's eyes are blue and Mary's eyes are red are not contraries (N.B. there is no lexical ambiguity in these sentences).
Clearly, to yield contrary sentences, a pair of colour terms must refer to the same area of uniform colour; but it is far from obvious how to devise linguistic contexts which will guarantee this.
Like hyponymy, incompatibility features as a typical syntagmatic relation between constituent lexical items of certain common locutions.
To give one example, items in a coordinated list are typically incompatibles, and gross deviations from this lead to abnormality:
I like mangoes and bananas.
? I like fruit and bananas.
However, and this is another parallel with hyponymy, strict incompatibility is not necessary, so there is no basis for a definition of incompatibility along these lines.
It is perfectly normal, for instance, to say
You meet all kinds of people here — students, bank managers,…
even though Arthur is a student does not entail Arthur is not a bank manager .
4.7 Congruence variants
We have seen how the primary relations of congruence are defined.
The concepts of congruence can also be applied, secondarily, to other lexical relations.
This works as follows.
Suppose some lexical unit X stands in a lexical relation R to another lexical unit Y. (R must be some relation other than one of the primary congruence relations.)
If every occurrence of X stands in the relation R to Y, and every occurrence of Y stands in the relation R (or its converse, if R is asymmetric) to X, then we shall say that X is a congruent R of Y:
If every occurrence of X stands in the relation R to Y, but there are occurrences of Y which do not stand in the relation R to X, then we shall say that X is a hypo-R of Y, and Y a super-R of X:
If some, but not all, occurrences of X stand in the relation R to Y, and some, but not all, occurrences of Y stand in the relation R to X, then we shall say that X and Y are semi-Rs :
Obviously, if no occurrences of X stand in the relation R to Y, then X is not any kind of R of Y, so disjunction has no counterpart among congruence variants.
The following are examples of the three congruence variants:finger is a congruent meronym of hand ;doctor is a hypo-converse of patient , and patient a super-converse of doctor , because, for instance, dentists also have patients;index is a semi-meronym of book, because there are books without indexes, and indexes which are not part of a book.
4.8 Partial relations
In this and the three following sections a number of general concepts will be introduced which are applicable to all, or at least most, paradigmatic lexical relations.
They represent modifications of various sorts of the straightforward relations, which generally render them in some way imperfect, limited, or attenuated.
We shall begin with partial relations .
These are relations which hold between lexical items whose syntactic distributions only partially coincide.
(The patterns of coincidence could, of course, be described in terms of the congruence relations introduced earlier; but no labels will be offered here except that , when congruence is perfect, the relation will be described as ‘full’.)
As an example of a pair of partial synonyms, consider finish and complete (in the usual sense, not the specific legal sense of ‘fulfil all legal requirements’, as in house-buying, etc.).
There are two principal syntactic differences between these two verbs — first,finish can occur without an overt direct object, as in Have you finished ?, whereas complete in the relevant sense requires an overt direct object; second, finish can take a gerund complement, as in I've finished eating , but complete cannot (* I've completed reading ).
There is no evidence that I've finished ,I've finished eating and I've finished my meal involve different senses of finish , so we must say that complete is a cognitive synonym of finish in only a sub-set of the grammatical occurrences of the latter.
It is important for the diagnosis of partial relations that the occurrences in unshared syntactic environments should not be distinct senses.
(This is not always easy to determine.)
Consider the case of hide and conceal .
In the presence of an overt direct object,hide and conceal are cognitive synonyms —John hid the money is equivalent to John concealed the money but hide is not replaceable by conceal in, for instance,Go and hide!
In this case there is a clear and recurrent difference of meaning between transitive and intransitive occurrences of hide , and it is therefore more satisfactory to speak of hide 1  , which is a full cognitive synonym of conceal , and a separate item hide 2  .
A subtle, but fortunately uncommon, problem arises with certain lexical items; it is exemplified by almost and practically .
These two are cognitively synonymous over a wide range of contexts:
10a.
I've almost finished.
b.
I've practically finished.
11a.
We're almost there.
b.
We're practically there.
In some contexts, however, the equivalence does not hold in full:
12a.
I almost killed him.
b.
I practically killed him.
Sentence 12a has two possible readings, which can be roughly glossed (i)‘I did something which caused him almost to die’, and (ii)‘I almost did something which caused him to die.’
Sentence 12b, on the other hand, has only one reading, which corresponds to reading (i) of 12a.
These contexts cannot be characterised syntactically, although they can be characterised semantically: they require the verb to be of the ‘reversible’ type (see chapter 10).
The different interpretations are due to differences in the scope of almost with respect to certain of the semantic traits of kill : notice how the paraphrases match the interpretations simply by moving almost in the sentence so as to alter its scope.
We shall describe differences of this sort as quasi-syntactic .
The question is, though, are almost and practically partial synonyms?
I am inclined to think that they should be included in this category.
4.9 Quasi-relations
It not infrequently happens that an exactly appropriate lexical partner that would complete a paradigmatic relationship is missing, but a lexical item exists, with virtually the required meaning, but of the wrong syntactic category.
I n such cases we say that there is a quasi-relationship .
For instance, there is no superordinate for the nouns knife ,fork and spoon : that , there is no X such that It's a knife ,It's a fork and It's a spoon all entail It's an X .However, we do have the mass noun cutlery , which has the right sort of meaning, as knives, forks and spoons are all cutlery.
We shall therefore say that knife ,fork and spoon are quasi-hyponyms of cutlery , and cutlery is a quasi-superordinate.
Another example concerns the colour adjectives red ,orange ,yellow , etc.
There is no X such that It's red/yellow/green entails It's X .
Coloured will not do, since in most contexts it excludes one or more of the colours in the incompatible set.
Thus a coloured photograph cannot be simply black, white and grey;a coloured pencil excludes black;a coloured sheet of notepaper cannot be white, and so on.
In this case,colour serves as a quasi-superordinate.
4.10 Pseudo-relations
Pseudo-relations occur when lexical items which do not, in fact, stand in a particular relation mimic, as it were, one or more of the contextual characteristics of that relation under special circumstances.
This phenomenon will be illustrated using pseudo-synonymy, although pseudo-relations are not in principle limited to synonymy.
We have already seen that two sentences differing only in respect of cognitive synonyms occupying parallel syntactic positions are in general logically equivalent.
However, logical equivalence between two sentences differing only in respect of lexical items occupying a particular syntactic position does not guarantee that the lexical items in question are cognitive synonyms — they may well be pseudo-synonyms.
The following examples illustrate a range of possibilities:
13a.
Arthur picked a green disc from this box in which all and only the green discs are smooth.
b.
Arthur picked a smooth disc from this box in which all and only the green discs are smooth.
14a.
This triangle has three equal angles.
b.
This triangle has three equal sides.
15a.
We are working for a greater understanding between the parties.
b.
We are working for a better understanding between the parties.
16a.
This horse has just given birth to a foal.
b.
This mare has just given birth to a foal.
The relations represented here vary in their semantic significance.
Obviously the equivalence in 13 is the least interesting: the logical relationship between smooth and green is restricted to the very specific and ad hoc conditions spelt out within the sentence itself.
It tells us nothing concerning the meanings of smooth and green except, perhaps, that they are (merely) compatible.
The relationship in 14 is more substantial, and arises out of eternal and ineluctable properties of triangles.
Nevertheless, in spite of the logical equivalence between the sentences, they state different things, and angle and side retain their distinct semantic identity:This triangle has three equal acute angles ;?
This triangle has three equal acute sides .
In 16, however (and perhaps in 15, too), it is possible to argue not only that the two sentences can be used to make identical statements, but more specifically that horse and mare make effectively the same semantic contribution to their respective sentences.
This is because the additional semantic traits normally carried by mare are already inferable from the rest of the  sentence, and are to that degree superfluous.
It could thus be claimed that mare and horse were effectively synonymous in this context.
In one sense, this is true, but it is misleading.
Horse and mare in 16a and b do not represent a genuine but contextually restricted form of synonymy: their semantic distinctness remains, and can easily be made manifest.
Consider, for example, 17a and b:
17a.
The second largest horse has just given birth to a foal.
b.
The second largest mare has just given birth to a foal.
The contextual mechanism that allegedly converts horse in 16a into a temporary synonym of mare is equally operative in 17a; but in spite of this, 17a and b are not logically equivalent, and their lack of equivalence is entirely due to residual semantic differences between horse and mare .
For reasons of this nature, the sentences in 13–16 will be considered to exemplify only pseudo-synonymy.
4.11 Para-relations
Many common locutions are semantically well-formed only if an appropriate semantic relation holds between certain of their lexical constituents.
The required semantic relations typically resemble the sort of relations that semanticists usually deal with, but are often less stringently defined.
Whereas linguists normally frame definitions of lexical relations in terms of criterial or canonical traits, natural language is very often satisfied with expected traits.
A lexical relation defined in terms of expectation rather than necessity will be called a para-relation .
Two typical para-relations are para-hyponymy and para-incompatibility.
Strictly speaking, these are both varieties of compatibility.
Para-hyponymy is exemplified by dog and pet .
The but -test reveals that the relationship between these two is ‘expected’:
It's a dog, but it's a pet.
(expressive paradox) It's a dog, but it's not a pet.
(normal)
This does not, however, discriminate between para-hyponymy and para-synonymy.
The former can be diagnosed by the above but -test pattern together with a unique order of occurrence of the related lexical items in Xs and other Ys :
dogs and other pets? pets and other dogs
Para-incompatibility is exemplified by student and bank-manager ; it  involves a negative expectation, so the but -test pattern is complementary to that of para-hyponymy:
He's a student, but he's also a bank manager.
(normal) He's a student, but he's not a bank manager.
(redundant)
Para-incompatibles are not normal in Xs and other Ys :
?
Students and other bank managers
Unlike para-hyponyms, however, they are normal in coordinated lists:
The people I hate most are: students, bank managers,…?
I like dogs, pets,…
4.12 Syntagmatic relations of meaning between lexical units
In one sense, every word in a sentence interacts semantically with every other word, and also with words in neighbouring sentences.
But we must distinguish between a type of interaction which is precisely regulated by the syntactic structure of the sentence, and a more diffuse type of interaction, not dependent on syntax, but merely on discourse propinquity.
Consider sentences 18 and 19:
18.
? The Ruritanian ambassador delivered a jolly strong protest concerning the recent violation of his country's sovereignty.
19.
? Johnny, darling, wouldn't you like some additional butter on your toast?
Both of these sentences exemplify lexical dissonance (i.e. a semantic clash, involving two or more lexical items in the same sentence (or discourse)).
In both sentences, one lexical item clashes in respect of register with the prevailing character established by the majority of lexical items in the sentence.
In 18,jolly , being informal, clashes with the formality established by such items as ambassador ,deliver ,concerning ,violation and sovereignty ; in 19 the technical-sounding additional is dissonant with the prevailing informality established by such items as Johnny and darling .
Notice that none of the items with which the dissonant word clashes most sharply have any direct grammatical relation to it.
Furthermore, in neither case is there any clash between the dissonant word and its closest syntactic companion; thus,jolly and strong go perfectly happily together:
20.
Gosh!
This coffee's jolly strong, Samantha!
as do additional and butter :
21.
Additional butter in the diet would probably prove beneficial.
Semantic interactions which involve this sort of meaning are not usually channelled through the syntactic structure, hence there is no syntactic dimension to any lexical dissonance which may arise.
The effect of what may be loosely described as ‘contextual relevance’ is likewise largely independent of grammatical control.
For instance, in 22, A's mention of cheque , by signalling a financial setting, clearly influences our most likely choice of reading for bank in B's utterance:
22.
A: I need to cash a cheque.
B: You'd better make straight for the bank, otherwise you'll be too late.
(It must not be forgotten, of course, that contextual relevance goes beyond the purely linguistic context and embraces the whole context of situation.
The most likely interpretation of bank could well be different if A and B were on a boat in the middle of a river.)
Now contrast the infelicities of 18 and 19 with those of 23 and 24:
23.
? The Ruritanian ambassador delivered a highly strong protest concerning the recent violation of his country's sovereignty.
24.
? Don't use that rancid fish-paste in your sandwiches.
In each of these, the lexical clash occurs between elements locked in an intimate grammatical relationship; in both sentences the clash can be removed by appropriately replacing either of the elements involved:
25a.
The Ruritanian ambassador delivered a highly emotional protest…b.
The Ruritanian ambassador delivered an extremely strong protest…26a.
Don't use that mouldy fish-paste in your sandwiches.
b.
Don't use that rancid butter in your sandwiches.
The significance of the lexical clash thus does not extend beyond the confines of the grammatical construction in which the lexical units occur.
Grammatically controlled interactions follow strict rules.
Consider the following sentence:
27.
Extremely fast cars crash violently.
The grammatical relations between the elements of this sentence can be displayed by means of a labelled tree-diagram:
Figure 4.1
This shows, for instance, that the element most closely related to extremely is fast : these two are co-constituents of the adjective phrase construction.
Extremely has no direct grammatical relations with any other word in the sentence.
However, the whole adjective phrase extremely fast is a co-constituent with cars of the noun phrase extremely fast cars ; and the latter joins the verb phrase crash violently to form the highest construction, the sentence.
The grammatical structure of the sentence is thus a series of nested constructions forming a hierarchy.
The structure shown in fig. 4.1 can be established on the basis of general syntactic criteria.
For instance, one of the signs that extremely and fast are united in a grammatical construction is the fact that the sequence extremely fast can be replaced by a single element, say,old , which has the same relationship to cars as does extremely fast ; furthermore, this substitution causes no grammatical change in the rest of the sentence.
(The process of substituting a single element for a sequence within a constant grammatical frame is known as reduction .)
Similarly,old cars can be reduced to they , and crash violently to disappeared (the sentence as a whole is not reducible).
It is this pattern of syntactic relationships which governs one type of semantic interaction.
Suppose we start with extremely .
This engages directly with fast , its sister constituent, but only indirectly with cars ,crash , or violently .
We can produce a semantic clash by substituting highly for extremely , and restore normality by replacing fast with dangerous .
The normality of Highly dangerous cars crash violently in comparison with?
Highly fast cars crash violently shows that the mis-match in the latter is between highly and fast , not highly and cars , or highly and crash , etc.
Moving now to the next stage of interaction, between extremely fast and cars , we find that extremely and fast do not have the same status.
Extremely enters into no further direct interaction — it exerts its semantic influence henceforth only ‘through’fast ; it is fast that directly interacts with cars .
This is shown by the fact that while it is possible to produce a semantic clash within the noun phrase which can only be resolved by replacing the adjective or the noun (?extremely fast wines ,extremely fast runners ,extremely potent wines ), it is impossible to produce a clash which can only be resolved by replacing either the intensifier or the noun.
The element in a construction which interacts directly with an element or elements outside the construction may be called the semantic head of the construction.
Fast is thus the semantic head of extremely fast .
Arguing along these lines it is not difficult to show that cars is the semantic head of extremely fast cars ; to resolve the clash in?
Extremely fast cars evaporate it is no use changing extremely or fast — we must replace cars or evaporate :Extremely fast cars disintegrate or Extremely fast solvents evaporate .
For similar reasons,crash is the semantic head of crash violently .
The verb is equally the semantic head in a verb-object construction.
For instance, the mis-match in?
The waves repaired the lorry is between waves and repaired : it cannot be resolved by changing lorry , but can be resolved by replacing either wave s or repaired :
The waves overturned the lorry.
John repaired the lorry.
There is thus no direct semantic interaction between the subject and direct object of a sentence — or, to put it another way, there is no combination of subject and object which is inherently dissonant.
It is not possible, using this technique, to discover which is the semantic head in the highest construction in a simple sentence, that is to say, the subject-predicate construction.
This is because grammatical control of semantic interaction does not, in general, extend beyond the sentence.
In syntactic theory, the verb is often taken to be the head of the sentence, but for our purposes, as we shall see, there are reasons for casting the subject in this role.
Semantic co-occurrence restrictions are in principle bi-directional: that is, two constituents of a construction will each exert semantic selective pressure on the set of potential (i.e. grammatically appropriate) fillers of the syntactic slot occupied by the other.
(For instance, in a steep bank there is mutual selection of senses.)
However, grammatically controlled co-occurrence restrictions also have directional properties.
To describe these, it is necessary first to make a distinction between head-modifier constructions and head-complement constructions.
A head-modifier  construction is typically endocentric ; that is to say, the head alone can play a grammatical role in the sentence identical to that of the whole construction:
There are no head-modifier constructions whose modifiers are obligatory in the sense that the construction would be ungrammatical without them; nor are there any head-modifier constructions whose modifiers, if omitted, become latent .
A head-complement construction, on the other hand, is typically not reducible syntactically to the head alone: the complement may be obligatory, like the cat in Arthur stroked the cat ; or, if it is omissible, it may be latent, like the direct object in John is watching .
Grammatically controlled semantic co-occurrence restrictions manifest two different sorts of directional property, and these interact differently in head-modifier and head-complement constructions.
First of all, it is generally possible to specify a selector and a selectee in a construction in which co-occurrence restrictions are operating.
In a head-modifier construction, the modifier is the selector, but in a head-complement construction it is the head which is the selector.
Selectors may generally be identified by the fact that they presuppose one or more semantic traits of their selectees.
So, for instance,pregnant in a pregnant X presupposes that its selectee (in this case, the head of the construction) bears the semantic trait ‘female’.
Likewise, the verb drink in a verb-object construction is the selector since it presupposes that its direct object bears the trait ‘liquid’.
Thus, on their most probable readings,His cousin is pregnant ,His cousin isn't pregnant and Is his cousin pregnant ? will all be taken to contain a reference to a female cousin; and an addressee, on hearing Drink it!,
Did you drink it ? or Arthur drank it will look for the referent of it among liquids.
Selectees, in general, do not presuppose traits of their selectors; in Arthur's (adj.) sister , or Arthur (verb) rum , nothing positive can be stated about the semantic nature of normal fillers of the semantic slots:
Arthur's pregnant/tall/pretty/diabetic sister Arthur drinks/sells/abhors/wastes rum.
The most that can be said is that they must have selectional restrictions which are satisfied by the selectee.
The second directional property involves the relationship between the  head of a construction and any dependent item or items.
Generally speaking, a dependent item is expected to bring to a construction semantic traits not already prefigured in the head; if the dependent item contributes nothing new, the resulting combination is pleonastic.
Under such circumstances we say that the head encapsulates the meaning of the dependent item.
Consider the noun phrase?a male uncle : the trait ‘male’ is encapsulated in uncle ;male contributes nothing new, so the combination is pleonastic.
The pleonasm can be cured by making the dependent item more specific so that it makes a net semantic contribution to the phrase:my patriarchal uncle (notice that adding specificity to the head has no effect:?my male maternal uncle ).
Similarly, in the pleonastic?
Arthur drinks liquids , the trait ‘liquid’ is contained in the verb, and the direct object adds nothing new.
Again, it is the dependent item which must acquire additional traits if pleonasm is to be avoided:Arthur drinks beer (but?
Arthur quaffs liquids ).
The two sorts of directional property described above work in opposite directions in head-modifier constructions, but in parallel in head-complement constructions.
Consider, first, constructions of the head-modifier type.
In these, the modifier is the selector, and hence presupposes certain traits of the head.
But a head is not required to carry traits not presupposed by its dependants, so when the head of a construction exactly duplicates the presupposed traits of a dependent selector (i.e. when the meaning of the head is fully predictable from the dependant), the result is perfectly normal:a pregnant female (animal).
Furthermore, as we have seen, if the head is non-specific with respect to the presupposed traits of the selecting modifier, these traits are, as it were, transferred to the head:my pregnant neighbour/cousin/friend .
In head-complement constructions, on the other hand, the situation is different.
There it is the head which is the selector, and, besides presupposing certain traits, also behaves as if those traits were encapsulated.
The effect is that if the selectee possesses only those traits which are predictable from the selector, then the combination is pleonastic:?
Arthur drinks liquids .
The same is true if the selectee (i.e. the complement) is non-specific with regard to the presupposed traits of the selector:?
Arthur drinks substances .
(If, however, the complement is a definite expression, pleonasm does not arise, and traits presupposed by the head are transferred to it:Arthur drank the substance/it .)
The subject-predicate construction is not precisely equivalent either to a head-modifier construction or to a head-complement construction.
In syntactic theory it is usual to regard the verb as the head, and the subject as dependent; but the purely semantic evidence suggests that the  subject has certain of the characteristics of a head.
The meaning of a (simple) sentence is qualitatively different from that of any of its constituents — it is capable of saying something that can stand on its own as a message.
The sentence does not appear to have a semantic controller; that is to say, there is no evidence of privileged status for either subject or predicate in respect of semantic relations between sentences.
However, the predicate displays at least one of the characteristics of a semantic dependant, and that is that it is expected to bring to the construction semantic traits not encapsulated in the subject; furthermore, in cases of pleonasm, it is the predicate whose specificity must be increased to achieve normality:
?
The speaker is speaking.
The speaker is speaking French.
? The tall speaker is speaking.
Also, the predicate is the selector; it further resembles a modifier in that when its presuppositions are just matched, the result is not pleonastic:
A dog barked.
A set of syntagmatic relations can be based on the results of putting grammatically appropriate lexical units together in a construction (all the lexical units standing in a particular syntagmatic relation to another lexical unit are, of course, specific to particular constructions, or sets of constructions).
If the combination is normal, we shall say that the lexical units involved are philonyms ; if the combination is pleonastic, we shall speak of head and tautonym ; if dissonance results, the lexical units will be labelled xenonyms .
The relations philonymy, tautonymy and xenonymy are connected in a systematic way with paradigmatic relations, and with presuppositions and encapsulations.
The sorts of correlation which exist can be illustrated by considering presuppositions.
Take, first, the presuppositions of the head of a head-complement construction with respect to its complement.
The meaning of a complement exactly matches the presuppositions of its head if the following conditions are satisfied:
(i)
It is a tautonym of the head.
(ii)
All its superordinates are tautonymous.
(iii)
All its compatibles and incompatibles are xenonyms.
(iv)
All its hyponyms are philonyms.
Thus, in the case of drink ,liquid satisfies these conditions: superordinates, such as substance , or fluid (in the scientific sense which includes gases) are tautonyms; incompatibles, such as solids , are xenonyms; and all hyponyms —beer ,water , etc. — are philonyms.
The presuppositions of a modifier cannot be pinpointed in this way, because a head which exactly duplicates them does not yield pleonasm.
In such cases what we need to discover is the most specific head all of whose incompatibles are xenonyms — that is, a head such that , for any hyponym, at least one incompatible can be found which is also a philonym of the modifier.
Consider a pregnant —.
Clearly woman is a philonym, but its meaning does not precisely match the presuppositions of pregnant because it has incompatibles (e.g. ewe ,mare ) which are also philonyms.
Animal is a philonym all of whose incompatibles are xenonyms (e.g. plant ,affix ).
But this does not precisely match the presuppositions of pregnant , either, because it has at least one hyponymous expression —female animal — all of whose incompatibles are xenonyms.
Female animal , on the other hand, comes close to satisfying the criteria.
Syntagmatic and paradigmatic relations of sense can be used to define degrees of dissonance.
Three such grades will be suggested (although it must be borne in mind that the reality is a continuum): these are inappropriateness ,paradox and incongruity .
Inappropriateness is diagnosed by the fact that there exists a cognitive synonym of the selector for which the selectee is a philonym.
Thus,The aspidistra kicked the bucket exemplifies inappropriateness because replacing kick the bucket with its cognitive synonym die removes the dissonance.
Those presuppositions of a selector, which, if not satisfied by the selectee, give rise to inappropriateness, will be termed the collocational restrictions of the selector.
We shall speak of paradox when (a) there is no possibility of resolving dissonance by synonymous substitution, but (b) there exists a (not too remote) superordinate of either xenonym which is a philonym of the other.
So, for instance,a male aunt is dissonant, but a superordinate of aunt , namely,relation , is a philonym of male ; in We fell upwards ,fell may be replaced by its superordinate moved , which is not xenonymous; in A cat barked , replacing cat with animal resolves the dissonance.
It is characteristic of incongruity that there is no superordinate of either xenonym which can restore normality (except, perhaps, at the highest level of generality, such as thing , or entity , for nouns, or do something for verbs).
This is the case with, for instance,a lustful affix (a lustful thing ?).
Those presuppositions of a selector whose non-satisfaction leads to paradox or incongruity will be called its selectional restrictions .
On occasions, the results of combining two lexical units in a construction  are not what would be predicted on the basis of the principles described above.
The most noteworthy cases are those which one would expect to be pleonastic, but are not.
Consider the following examples:
Arthur murmured softly in Bertha's ear.
Arthur rushed quickly to the door.
Arthur ambled slowly across the lawn.
Arthur was shouting loudly.
In each of the above, one would intuitively say that the meaning of the adverb was encapsulated in the meaning of the verb.
This judgement is supported by the paradoxical result of replacing the adverb by its antonym:
?
Arthur murmured loudly in Bertha's ear.
? Arthur rushed slowly to the door.
? Arthur ambled quickly across the lawn.
? Arthur was shouting softly.
It seems that in these cases, instead of pleonasm, there is an intensification of the adverbial notion (cf. very very good ).
Something similar occurs in a bad headache and a terrible catastrophe ; notice, however, that?a bad catastrophe is pleonastic, which suggests that the dependent item must not be weaker than the notion encapsulated in the head.
It appears that this phenomenon requires the encapsulation by a head of a gradable modifying notion.
In another type of instance, we find apparent duplication of traits with no discernible semantic effects.
Consider the case of gnash the teeth and purse the lips .
The predictability of the direct objects of gnash and purse is revealed by the pleonastic nature of
?
What Mary pursed were her lips.
? What Arthur gnashed were his teeth.
Why, then, are purse the lips and gnash the teeth not pleonastic?
The answer may quite simply be that semantically redundant dependent elements may occur without the penalty of abnormality provided they are syntactically obligatory, as are the direct objects of gnash and purse .
Cases like these should be distinguished from a superficially parallel set of cases such as shrug the shoulders and pout the lips .
In a sense, the meaning of the objects is encapsulated in the verb here, too, and so we would expect the expressions to be pleonastic.
But there is a difference: the object in these expressions is omissible.
However, the omission of the object has a subtle semantic consequence.
Shrug and pout in Arthur pouted and  Celia shrugged refer to a gesture used as a conventional signal;Arthur pouted his lips and Celia shrugged her shoulders , however, are non-committal about whether a signal was intended, and indicate merely that a certain movement was performed.
In other words, the precise sense of pout ,shrug (and probably also nod ,stamp ,wave ) depends on whether or not the direct object is present.
That being so, the direct object cannot be said to be totally redundant.
5
Lexical configurations
5.1 Introductory
This chapter deals with the two most formally complex types of lexical configuration, namely, hierarchies and proportional series.
In the case of hierarchies only general formal characteristics are discussed: specific types of hierarchy are treated in some detail in chapter 6 (taxonomic hierarchies), chapter 7 (part-whole hierarchies) and chapter 8 (non-branching hierarchies).
Proportional series are dealt with in more specific detail as they do not appear anywhere else in the book.
Other possible configurations, which will not, however, be discussed here at any length, are doublets (exemplified by pairs of opposites — see chapters 9, 10 and 11), and clusters, which are groupings of lexical items characterised by a lack of structure (some groups of synonyms appear to be of this nature — see chapter 12).
5.2 Hierarchies
A hierarchy, which need not consist of lexical items, is a set of elements related to one another in a characteristic way.
Two structural types of hierarchy may be distinguished: those which branch, and those which, because of the nature of their constitutive relations, are not capable of branching.
The two possibilities are illustrated diagrammatically in figs. 5.1 (a) and 1(b):
Figure 5.1
We must distinguish between hierarchies of the branching type which in particular manifestations happen not to have branches, and hierarchies which cannot branch.
Only the latter may be termed non-branching.
Suppose a botanist working on the taxonomy of the (hypothetical) Peruvian bladder-grass family (Vesicaliaceae) discovered that it contained only one genus,Vesicalia , and that the genus had but one species,V. peruviensis .
The taxonomy of this family would then not have any branches.
But it would not count as a non-branching hierarchy; branching can be regarded as a canonical feature of a taxonomic hierarchy.
Hierarchies are further sub-classified by the relations which structure them; there is thus more than one kind of branching hierarchy, and more than one kind of non-branching hierarchy.
(Within each type, hierarchies may be distinguished by the elements they contain.)
The most fundamental structural relation of any hierarchy — without it there would be no hierarchy at all— is what we shall call the relation of dominance .
This is the ‘vertical’ relation — the one which connects A to B and C, B to D and E, and C to F and G in 1(a), and P to Q, Q to R and R to S in 1(b).
In a well-formed hierarchy, the relation of dominance is constant throughout the structure.
A branching hierarchy requires, in addition, a relation of difference ; this is the ‘horizontal’ relation, which holds, for instance , between B and C, D and E, and F and G in 1(a).
The relation of difference, too, must be constant throughout a well-formed hierarchy.
The minimum requirement for a hierarchy is a set of interrelated elements structured by a suitable relation acting as a relation of dominance.
Two properties are essential for the relation of dominance of a hierarchy.
First, it must be asymmetric ; that is to say, it must have a directional character.
Suppose it is known that a certain element A stands in a relation R to a second element B. If R is an asymmetric relation, then it necessarily follows that B does not stand in the relation R to A (the relation of B to A in that case is the converse of R).
For instance, if A is longer than B, then it follows that B cannot be longer than A; hence,’— is longer than —’ is an asymmetric relation.
A symmetric relation, on the other hand, holds simultaneously in both directions; ‘is similar to —’ is a symmetric relation, so if A is similar to B, then it necessarily follows that B is similar to A. The second indispensable property for the relation of dominance of a hierarchy is the capacity, in principle at least, to form indefinitely long chains of elements.
We shall describe a relation which has this property as catenary .
An example of a non-catenary relation is’— husband of —’(it is also asymmetric): if A is the husband of B, then B cannot, in turn, be the husband of a third person C. Compare  this with the catenary relation’— father of —‘, which generates chains of indefinite length: A is the father of B, who is the father of C, who is the father of D, etc.
The relation of dominance of a hierarchy can equally well be transitive or intransitive .
A relation is said to be transitive if the fact that it holds between two elements A and B, and also between B and some third element C, guarantees that it holds between A and C. The relation’— is longer than —’ is thus transitive, because if A is longer than B, and B is longer than C, we can be sure that A is longer than C. In the case of an intransitive relation, on the other hand, the fact that it held between A and B, and between B and C, would entail that it did not hold between A and C. For instance, if A were the father of B, and B the father of C, then A could not be the father of C; the relation’— father of —’is thus intransitive.
A set of elements interrelated by an asymmetric, catenary relation R is a hierarchy if, and only if, it possesses the following properties:
(i)
There is one and only one element which stands in the relation R to all the other members of the set (if R is transitive), or which stands either in the relation R or some higher power of R to all the other members of the set (if R is intransitive).
(The ‘higher powers’ of an intransitive relation arise when there are chains of elements each related to the next by the relation in question; thus, if A is the father of B, B of C, and C of D, then A stands in the ‘third power’of the relation’— father of —’to D.) It can easily be seen that A in 1(a) and P in 1(b) fulfil this requirement (assuming, of course, that the lines in the diagrams symbolise the relation of dominance).
We can avoid reference to transitivity by saying that there must be one and only one element which stands in some power of R to all the other members of the set.
In this case, ‘some power of R’ must be taken to include the first power of R, i.e. R itself.
The unique initial element in a hierarchy will be called the ‘origin'.
(ii)
If A and B are two elements of the set which both stand in some power of R to a third element of the set C, then either A stands in some power of R to B, or B stands in some power of R to A.
In other words, any three such elements in a hierarchy must be capable of being arranged to form a continuous chain:
This condition is automatically satisfied by any non-branching hierarchy; its particular significance, however, is in respect of branching hierarchies, as it ensures that the branches do not converge.
Consider the structure illustrated in fig. 5.2:
Figure 5.2
It can be seen that B and C both stand in the relation of dominance to E, but neither stands in that relation to the other; hence, the structure is not a hierarchy, according to our definition.
A branching hierarchy requires a relation of dominance with a very particular property, namely, that of being, as we shall say,differentiable .
To be differentiable, a relation must be capable of being directed along mutually exclusive pathways in an indefinite number of successive stages.
by no means all possible relations of dominance are differentiable.
Consider the relation’— larger than —‘.
This can serve as the relation of dominance of a non-branching hierarchy:mountain :hillock :mound .
It cannot, however, act as the relation of dominance of a branching hierarchy, as it is not of the sort which can be successively differentiated.
Suppose we have a set of elements A, B and C, such that A is larger than B and C, the latter pair being of equal sizes.
We can picture their relationships in a way that looks like the beginning of a branching hierarchy:
But suppose we now attempt to extend the hierarchy and add a fourth element D under B. It immediately becomes clear that the apparent branching hierarchical structure is illusory, since not only B, but also C, stand in the relation’— larger than —’ to D:
The relation’— larger than —’ can thus generate only a non-branching hierarchy; in such a hierarchy we would have to say that B and C above jointly occupied the same position.
Consider now the relation’— initiated (into the Eleusinian mysteries)—‘.
Imagine an individual A, who initiated two other persons B and C:
In this case it is possible to add a fourth element D to the hierarchy, such that B, but not C, initiated D:
The relation’— initiated —’ is thus differentiable, and can, provided it is appropriately directed, form the relation of dominance of a branching hierarchy.
An example of a differentiable relation with lexical significance is the relation of dominance of a taxonomic (i.e. classificatory) hierarchy.
The lexical items in a taxonomy may be thought of as corresponding to classes of things in the extra-linguistic world.
Suppose we start off with the class of animals.
This can be divided into a number of sub-classes which have no members in common, such as dogs, horses, elephants, and so on .
Each of these sub-classes can then be further subdivided into sub-sub-classes which likewise have no members in common; for example , the class of dogs into spaniels, alsatians, poodles, and so on .
This process can be repeated, at least in principle, indefinitely, without convergence (i.e. without producing classes that have members in common).
Another differentiable relation with lexical relevance is the relation between an entity and its parts.
For example, the human body divides into the trunk, the head, the arms and the legs; these parts are disjunct in the sense that they do not overlap.
Each part is in principle divisible into smaller disjunct parts, and successive repetition of this process produces a branching hierarchy.
It is perhaps no accident that these two branching hierarchies, which are the only types of any general lexical significance, have relations of dominance which are not merely differentiable, but which in some sense are inherently differentiated.
There cannot be a taxonomy without differentiation  into more than one sub-species: the creation of one sub-division presupposes the existence of at least one other.
The same is true of parts: it is not possible to divide an entity into only one part (although it is possible to divide an entity into parts which are not lexically discriminated — see chapter 7).
Occasional non-branching nodes may be tolerated in a branching hierarchy provided it is one with clearly established levels.
For instance, in the hypothetical case of the Peruvian bladder-grass, there is in reality only one class of plants.
That class qualifies as a species because all the members will breed with other members of the class, but not with plants from outside the class; but there would be no justification for saying that the class also represented a genus and a family, if the larger taxonomy of which it forms part did not exhibit branching at these levels.
Each element of a hierarchy occurs at a particular level.
The notion of level in a hierarchy can be construed in two different ways.
There is first of all what may be termed the technical conception of a hierarchical level.
To determine to which technical level an element belongs, one needs only to count the number of nodes downwards from the origin (each element constitutes a node): the unique first element constitutes level 1, all elements one node removed from the origin constitute level 2, all elements two nodes removed constitute level 3, and so on(in a non-branching hierarchy, there is only one element at each level):
This method of determining levels precludes structures like that shown in fig. 5 3(a):
Figure 5.3
The element E, since there are no nodes intervening between it and A, should technically form part of level 2, as in 5.3(b).
In this sense of level, all hierarchies have determinate levels.
It may well happen, however, that the users of a hierarchy (in the case of a lexical hierarchy the speakers of the language) have positive intuitions concerning which items belong together at a given level; and these intuitions may conflict with the level assignations according to technical criteria.
In other words, structures like that shown in 5.3(a) may on occasions be felt by speakers to be ‘correct’.
For instance, many speakers of English feel that the sub-classification of garden birds into sparrows, robins, thrushes, blackbirds, etc. is comparable not with the division of animals into dogs, cats, sheep, and so on , but with the sub-classification of dogs into spaniels, poodles, alsatians, and the like.
This makes no biological sense, of course, but it has a certain psychological validity, in that the significance to most members of our society of the difference between, say, a thrush and a blackbird is roughly comparable to that between a collie and a spaniel.
If the classification of living creatures is structured in this way, there will inevitably be a conflict with technically determined levels.
Where there are definite intuitions about which elements belong at a given level, we may speak of substantive levels.
In an ideal hierarchy, technical and substantive levels would be congruent; however, in cases of conflict between the two (which is, of course, possible only in the case of a branching hierarchy), primacy should be given to substantive levels.
In this section we have been considering the properties of hierarchies in general.
All the characteristics outlined apply in principle to the hierarchies which fall within the scope of lexical semantics, that is to say, those which are composed of lexical items, and those structuring relations are relations of sense holding between those lexical items.
The various types of lexical hierarchy also, however, have many specific properties, and these form the subject matter of chapters 6, 7 and 8.
5.3 Proportional series
The simplest proportional series consists of a single ‘cell’ which has four elements:
The relations between the elements must be such that from any three of the elements the fourth can be uniquely determined.
The configuration  is thus structured by the following relations of proportionality:
A is to B as C is to D
B is to A as D is to C
A is to C as B is to D
C is to A as D is to B
The quintessential proportionalities are, of course, numerical:
but lexical analogues of these are common.
One example is 
Placing the lexical items in a proportional series in this way is justified by the following recurrences of semantic contrast:
These two equations are equivalent to the following four proportionality statements:
Mare is to stallion as ewe is to ram .
Stallion is to mare as ram is to ewe .
Mare is to ewe as stallion is to ram .
Ewe is to mare as ram is to stallion .
Notice that the following configuration does not constitute a proportional series according to the above definition:
Firstly, none of the contrasts are recurrent:
Second, it is not the case that from any three elements the fourth can be uniquely predicted.
The identity of X can be uniquely determined in 1a and b, but not in c or d:
1a
Apple is to fruit as dog is to X .
b
Apple is to dog as fruit is to X .
c
Fruit is to apple as animal is to X .
d
Fruit is to animal as apple is to X .
In the sense that apple has the same relationship to fruit as dog has to animal (i.e.' — is an immediate taxonym of —' — see chapter 6 for the meaning of taxonym ), that relation is of the sort known as ‘many-to-one’.
A relation is many-to-one if several elements can stand in that relation to some other element, but for each of these there is only one element to which they can stand in that relation.
Such relations occur in hierarchies, but for a proportional series all the structuring relations must be ‘one-to-one’, that is to say, each relation must be such that for any element there is just one other element to which it can stand in that relation, and only the first element can stand in that relation to the second.
There is a more specific one-to-one relation between apple and fruit , but it is not recurrent; that is to say, there is no animal that has a unique position among other animals analogous to the position of apples among different sorts of fruit.
To constitute even a minimum cell of a proportional series, two recurrent one-to-one relations are necessary.
Any basic cell is in principle extendible along one or both of its axes.
A proportional series which can be extended along both axes simultaneously will be called open .
The cell illustrated in fig. 5.4(a), for instance, can be extended as in 5.4(b):
Figure 5.4
Some proportional series, however, can only be extended along one axis at a time; if an attempt is made to extend them along both axes simultaneously, unfillable structure points are created.
Proportional series of  this sort will be termed closed .
Consider the following example:
This can be extended either as in fig. 5.5(a) or as in 5.5(b):
Figure 5.5
but not both together:
We shall assume in the discussion which follows that an ideal, well-formed proportional series is open.
A given lexical form may appear at more than one structure point in a proportional series, but only if it is ambiguous:
As a diagnostic test for ambiguity, the ability to occupy more than one point in a proportional series is more reliable than, for instance, the mere possession of two different opposites.
Both light (dark and heavy ) and patient (doctor and dentist ) can be said to have more than one opposite, but only with the former can we construct a cell:
In the case of patient ,doctor and dentist , the necessary relations of proportionality cannot be found:DOCTOR is to PATIENT as DENTIST is to PATIENT is perhaps a satisfactory proportion, but DOCTOR is to DENTIST as PATIENT is to PATIENT most certainly is not.
The evidence for ambiguity is stronger if the separate occurrence of a lexical form in a proportional series is established in different proportional sets, as in the case of 
The intuitive judgement of the validity of the proportionality is much harder to make when two senses associated with a single word form are directly contrasted, as in horse :stallion ::dog 1  :dog 2  .
A particular axis of a proportional series may be consistent or inconsistent .
Consider the two examples illustrated in fig. 5.6.
Figure 5.6
Series (b) is consistent in a way in which (a) is not.
This is because the relation between mountain and hill is the same as that between hill and hillock , and hillock and mound , with the result that the following proportionality holds:mountain is to hill as lake is to pond .
In fig. 5.6(a), however, the horse :sheep relation is not identical to the sheep :cow relation; therefore, given the following three elements of a proportion:horse :sheep ::lamb :? the fourth element is not uniquely determined.
Consistency of this type in proportional series is somewhat uncommon.
All extended proportional series can be broken down into a number of linear series of cells, as in figs. 5.6 and 5.7, and this is the form in which we shall study them.
The vast majority of series involve two kinds of contrast: one type is found in only a limited number of lexical pairs; the other type recurs much more freely.
For instance, only a handful of lexical pairs manifest the horse :sheep contrast:
Figure 5.7
The mare :stallion contrast, on the other hand, recurs in dozens of pairs.
The relatively restricted contrasts are invariably carried by open set elements; the freely recurring contrasts may be carried by open set items (as in mare :stallion ), but the members of a pair of lexical items manifesting such a contrast frequently share the same open set element (i.e. the root), the contrast being signalled by one or more closed set elements )i.e. affixes):
We shall adopt the convention of representing the relatively recurrent contrasts between horizontally adjacent lexical items in a series (e.g. sheep :lamb above), and the relatively restricted contrasts between vertically adjacent items (e.g. sheep :duck above).
There are two lexical relations specifically associated with proportional series.
But before these can be discussed, another lexical relation must be introduced, which, although it figures prominently in lexical proportional series, is not in principle restricted thereto.
This relation will be called endonymy .
It is based on the notion of semantic encapsulation, and involves the incorporation of the meaning of one lexical item in the meaning of another.
The term whose meaning is included in this way will be called the endonym , and the containing term will be called the exonym .
Some examples of endonymous pairs are as follows (the endonym is given first):animal :horse ,horse :mare ,horse :stable ,hand :finger ,hand :glove ,foot :kick .
Notice that the relationship between superordinate and hyponym, and in certain instances between holonym and meronym, are special cases of endonymy.
The essential defining characteristic of this relation is its capacity to give rise to pleonasm.
The but -test provides a convenient way of illustrating this; all the sentences in 2 are pleonastic;
2a.
It's a horse, but it's an animal.
b.
It's a finger, but it's part of a hand.
c.
It's a glove, but it's for covering the hand.
d.
It's a stable, but it's for horses.
e.
He kicked me, but with his foot.
There may sometimes be problems in deciding which member of a pair is the endonym and which the exonym, although in most cases we can trust our intuitions.
If the terms are hyponymously related, then the superordinate is the automatic choice for endonym; being less specific in sense, it is therefore less complex semantically.
The same is probably true of the holonym in a pair related meronymously.
Take the case of hand and finger .
Although the relationship is canonical in both directions — a canonical finger is a part of a hand, and a canonical hand has fingers- hand is in one sense the less specific and hence less complex term, the term which carries less semantic information.
Very often the question can be decided by the relative adequacy of definitions.
For instance, ‘a building for lodging horses’ is an adequate definition of stable (or at least is on the right lines); but while ‘a stable-dwelling animal’might serve to identify horse , it is not an adequate definition.
(There is, in fact, no adequate definition of ‘natural kind’ terms like horse — see chapter 6 — so if one term of an endonymous pair is a natural kind term, and the other is a nominal kind term, then the natural kind term is automatically the endonym.)
A similar argument applies to glove and hand : ‘an item of clothing designed to cover the hand’ is a satisfactory definition of glove , but ‘the glove-wearing part of the body’is decidedly odd as a definition of hand .