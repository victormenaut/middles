

1
Accountability and Evaluation
Introduction
It has now become commonplace to observe that the 1960s witnessed a rapid increase in educational investment on both sides of the Atlantic.
However, in relation to the theme of this chapter, this development was significant because it created an urgent need to justify the massive input of resources.
Taxpayers, ratepayers, policy makers and administrators all demanded information about the way in which the money they provided was being spent.
Thus, by the 1970s, the age of accountability had arrived and the concept of educational evaluation had acquired a new meaning.
By the early 1980s, the concept of educational evaluation was often so interwoven with the concept of accountability that the two were difficult to distinguish; indeed Nuttall suggests that the distinction may be untenable.
However, Elliott, following Becher, argues that whilst evaluation and accountability are closely inter-related, the relationship is not symmetrical.
Accountability usually presupposes evaluation, but evaluation does not necessarily imply accountability.
This latter view is the one we subscribe to in this book, for although we consider evaluation as a response to, or the process of, accountability, we also consider evaluation in two other contexts, which, unlike Nuttall, we have chosen to distinguish from accountability.
Accountability Pressures
We have already mentioned one of the factors that gave rise to the emergence of accountability as a central issue in education: the need to justify increased spending in the 1960s.
This was, however, only the most obvious of a number of complex social, economic and political pressures, which contributed to a gradual change in the climate that  surrounds most public institutions in the western world.
Equally important, although in many ways distinct, was a perceptible decline in public confidence.
According to Halsey (1979) the 1970s witnessed a widespread ‘rotting of public confidence in public institutions’.
As a consequence we seem to have entered a strongly conservative phase with an  unmistakable emphasis on consumer rights.
Before focusing on the way in which educational accountability has manifested itself in evaluation procedures we want to spend a little time exploring this more general picture.
Our thesis is this: educational accountability is not a localised phenomenon, therefore, what appear to be local responses may have a wider significance than was imagined at their inception.
After all, policy makers rarely start from first principles but borrow and adapt structures and procedures which they see operating effectively elsewhere.
For this reason the American experience has relevance to the United Kingdom, and perhaps vice versa; and developments in law, medicine, the police force and the social services are worthy of the attention of those within education.
It should perhaps come as no surprise that the Assessment of Performance Unit (APU) in England and Wales has some of the characteristics of the National Assessment of Educational Progress (NAEP) in the US; or that new moves in the UK to establish procedures to make incompetent teachers liable to sanctions (reported in the Times Educational Supplement .
27 Nov. 1981) coincided with the publication (on 25 Nov. 1981) of the Scarman Report which recommended the introduction of an independent element in the police complaints procedure.
In two papers outlining some of the causes of public discontent and their impact on education in the United States, Atkin (1979, 1980) provides a useful framework for comparing the situation in the UK (especially England and Wales) with that in the USA.
Educational accountability emerged in the United States earlier than the United Kingdom, where the term did not appear in an official document until the publication of the ‘Green Paper’.
Despite this qualification, the trend on this side of the Atlantic now seems established and many of the features of North American accountability have counterparts here.
In the rest of this section, therefore, we have used Atkin's framework to draw out some of these similarities.
Economic decline and the failure of education to improve industrial performance.
After the economic boom years of the 1960s, industrial expansion has  been arrested, on both sides of the Atlantic.
In large measure this is attributable to the world recession which developed after the oil crisis in 1974, although another contributory factor is associated with the failure of western societies to respond sufficiently quickly to the development of new technologies.
In particular, the lack of investment planning has hindered the shift in the industrial base of western economies.
Anxieties aroused by the economic crisis have rebounded on the education service which, fairly or otherwise, stands accused of not meeting the needs of advanced industrial society.
Although the USA has always tended to look to education to solve its national problems, education in the UK has traditionally been viewed more as a benefit to the individual.
The advent of accountability in the UK has therefore had the effect of bringing closer together the values ascribed to education by both UK and US governments.
Offering an American view of British accountability House (1978) describes a shift from individualist to societal values in the following way:
The major shift in values is from individualist values, the traditional emphasis, to society goals and values, from the individual to the government.
The longstanding consensus on traditional aims has been broken and the pattern of educational governance is at issue.
Education is being pushed more towards being an instrument of national policy, or so it would appear to an outsider.
House is perhaps mistaken in believing that individualist values have always held sway in the UK.
In earlier periods pressures to provide an education service fitted to the needs of the society have been observed.
For instance the Taunton Commission Report, 1868, and the Hadow Report, 1926, were both much influenced by the contemporary view of the needs of the economy.
It is nevertheless true that the creation of the single subject GCE examinations in the 1950s, and the subsequent development of the CSE (Mode III), allowed considerable power to swing to the teachers.
They now had the means to tailor curricula to suit what they perceived to be the abilities and interests of individual children.
The advent of the accountability movement in the UK represents, therefore, something in the nature of another swing of the pendulum: back to a reconsideration of societal needs.
The current UK trend found an early official expression in the Ruskin College Speech of the Labour Prime Minister, James Callaghan.
In this he initiated the Great Debate by exhorting  teachers to ‘satisfy parents and industry that what you are doing meets their requirements and the needs of their children’.
Subsequent government documents, emanating from both the Department of Education and Science (i.e. Secretaries of State and HMI) and the Department of Industry, have pursued the same theme and in 1985 Better Schools contained the following statement:
It is vital that schools should always remember that preparation for working life is one of their principal functions.
The economic stresses of our time and the pressures of international competition make it more necessary than ever before that Britain's work-force should possess the skills and attitudes, and display the understanding, the enterprise and adaptability that the pervasive impact of technological advance will increasingly demand.
This applies to those who will be employed by others and to the many who may expect, for part or all of their working lives, to be self-employed.
The balance within the curriculum and the emphasis in teaching it now need to alter accordingly.
One manifestation of this statement in terms of policy has been the Technical and Vocational Education Initiative (TVEI) funded by the MSC.
Falling standards, falling roles and higher costs.
Criticism of the education service for failing to meet the needs of an advanced industrial economy is undoubtedly linked with a widely held belief that educational standards, generally, are in decline.
In the United States a sharp drop in Scholastic Aptitude Test (SAT) scores (an examination used widely to select students for college admission) has been evinced as ‘proof’ of falling standards.
The ensuing public alarm encouraged the setting up of a national commission (chaired by the former Secretary of Labour, Willard Wirtz) to investigate the reasons for such a sharp decline.
The commission identified a variety of factors including lack of parental support, the influence of television, the increased proportion of eighteen-year-olds taking the SAT, and a decrease in the importance of formal education in determining life-time earnings.
Significantly this list does not include any indication that the quality of educational provision had, itself, declined.
Nevertheless the indictment of schooling remains strong in the public mind and an apparent increase in violence in schools serves only to compound this belief.
In England and Wales there is no convenient, popularly accepted, indicator of the effectiveness of schooling to compare with the SAT.
No single attainment test is administered to all schools, and GCE and CSE examinations were always dogged by problems of comparability.
Notwithstanding that, from 1969 onwards, the authors of a series of Black Papers saw fit to castigate schools for falling standards.
Unfortunately they tended to use polemical fervour as a substitute for evidence.
Indeed what evidence there was at that time, for instance from a number of reading surveys, suggested the maintenance or improvement of attainment, although the single exception provoked more media interest.
With the publication of the Green Paper, the ‘standards’ issue became an official concern.
Once more the suggestion was that educational standards had fallen and that this decline was in some way connected with the introduction of progressive forms of education.
Again the accusation was presented without evidence.
The fact that two years later the HMI Secondary Survey showed that popular fears about falling standards were largely unfounded did conspicuously little to change the prevailing attitude.
According to MacDonald (1978) the standards debate in England was as much stimulated by an idealised ‘distillation from the past’ as any so called‘objective’measures.
He writes: ‘It may be that when we ‘invent’ the past, especially the lived past, we serve our self esteem by creating an idealized image of our experience, holding it in our heads until it yields measures of virtue'.
Certainly, a large section of the British public came to believe that standards had declined, and, as Thomas (1928) observed, ‘if men define situations as real, they are real in their consequences’.
Moreover, as in America, a growing youth movement was attracting media attention and added to the impression that ‘kids can't read, don't know how to behave, and aren't willing to work’.
The finger pointed at education could not easily be pushed aside, particularly at a time when the period of education had been extended and the school population, on both sides of the Atlantic, was beginning to diminish factors which should have favoured significant improvement.
Furthermore the public expected increased ‘productivity’ in return for the substantial increases in salaries achieved in the 1970s by unionised teachers in both the UK and the USA.
To the layman it seemed that a decreasing service was being provided at increasing expense.
As a consequence the recent decline in public spending on services, such as education, has gone virtually unchecked.
The failure of education as an instrument of social reform.
Commenting on the US federal government's increasing involvement in education, Atkin (1980) observed a shift in national priorities during the Kennedy years, which influenced the nature of that involvement.
An earlier preoccupation with the space race and national defence had focused attention on improving the state of science education, in the USA.
In the 1960s this preoccupation gave way to an urgent need to consider domestic problems such as racial disharmony and poverty.
In 1965, Lyndon Johnson, who, according to Atkin, wanted to be remembered as the ‘Education President’, devoted much of his energies to the passage of the Elementary and Secondary Education Act, which appropriated large sums of money for a compensatory education programme.
‘It was a period of considerable optimism in some quarters that the nation's ills could be ameliorated by wise policy, diligent effort, and lots of money’.
The emphasis on individualism that House (1978) observed prevented education in the UK ever being regarded as an agent of social reform to the extent that it was in the United States.
Nevertheless a similar concern was evident in the discussions of ‘positive discrimination’ and the establishment of educational priority areas (EPAs) subsequent to the publication of the Plowden Report in 1967.
Moreover, in the secondary sector, it was hoped that comprehensivisation would be effective in equalising opportunities among different social groups.
Faith in this doctrine of meliorism (that progress is inevitable if sufficient money and resources are provided) soon began to fade.
In the UK it became increasingly apparent that organisational change in schools was not sufficient to guarantee change in established social attitudes.
For instance, some observers suggest that there are few genuine comprehensive schools in this country i.e. schools fully committed to physical, social and curricular integration.
Indeed comprehensivisation is now likely to be reversed by government policy to allow schools to opt out of LEA control.
In the USA disillusionment was even more obvious, especially after Vietnam and Watergate had turned the national mood from optimism to self-criticism.
Furthermore, disagreement over racial desegregation and the policy of bussing revealed a lack of consensus over the social goals that schools were supposed to advance.
Distrust of authority and scepticism concerning competence
According to Atkin (1979) lack of agreement about social purposes is related to an increasing lack of confidence in those in positions of authority or those who claim specialist knowledge.
Nisbet (1979) has pointed out the irony that this new distrust may itself be a product of modern education, since a number of new approaches to teaching and learning encourage children to ‘think for themselves’.
Certainly ‘professionalism’ is beginning to be viewed sceptically and competence is no longer assumed.
On both sides of the Atlantic the decisions of architects, civil engineers, environmental planners, doctors etc. attract public scrutiny and the numbers of government regulating agencies increase.
In the UK the established professions (law and medicine) and some of the semi-professions, such as the police, have traditionally been self-monitoring.
Now, however, they are finding this position increasingly difficult to maintain.
In the 1980 series of Reith Lectures on BBC radio, Ian Kennedy, a Reader in Law, argued that the disciplinary procedures of the medical profession are more concerned with etiquette than competence.
Supporting a notion of consumerism he proposed litigation as a more satisfactory procedure than the existing forms of self-regulation provided by the General Medical Council.
In October 1981, a court case, concerning the death of a Down's Syndrome baby, was brought against a paediatrician by the association ‘Life’.
Although in this instance, the doctor's action was vindicated, the case was illustrative of a greater public willingness to take legal action in circumstances such as these.
In the US this trend has been evident for some time.
In the educational sphere, the minimum competencies legislation passed by at least 38 states has provided a possible vehicle (litigation) for ordinary laymen to demand that certain tasks are fulfilled by the professionals.
In this context, ‘minimum competencies’ legislation refers to the State's requirement that pupils should attain an agreed level of mastery of basic skills and satisfactory performance of functional literacy in order to graduate from high school.
As a way of ascertaining whether minimum levels had been achieved state-wide testing programmes were initiated.
Given that the minimum levels of pupil competence were set by each school district in cognisance of local circumstances, a question was raised concerning whether students who failed to reach the agreed standards could recover damages for their failure to learn, if they were able to demonstrate teacher negligence.
In one famous Californian court case a school leaver sued the State Department of  Education for precisely this reason.
In this instance the case was dismissed but the fact that such action was taken at all was profoundly significant.
Minimum competencies testing has not been a feature of the UK experience, although the government's announcement in 1987 that a national curriculum was to be established, with benchmarks for achievement at ages 7,11 and 14, appeared at first to have similar implications.
At the time of writing, it seems that the intention is not to assess progress in relation to benchmarks through a blanket testing programme but through assessment by teachers akin to that in GCSE and Records of Achievement.
In other words, rather than representing minimum competencies, benchmarks are intended to raise expectations.
What happens in practice remains to be seen!
In some measure, these examples of lack of public confidence in professional skill, expertise and judgement, provide evidence of what Habermas (1974,1975) has called the legitimation crisis of late capitalism'.
According to his analysis distrust of authority and scepticism concerning the competence of specialists is a function of the breakdown of value consensus.
Thus a ‘working’ or ‘practical’agreement can only be achieved through a process of dialogue.
If recent events are anything to go by, one forum for this ‘dialogue’ will be the courts of law.
The application of economic management systems to public services
The final two factors that we wish to consider here seem to have more influence in the USA, although there are signs that they are becoming increasingly important in the UK.
Americans may have little more trust in businessmen than other specialists, but they do believe they have the ability to ‘deliver the goods’.
For this reason the adoption of economic management systems, such ‘management by objectives’ and ‘cost-benefit analysis’, by the public services rapidly found favour.
It was generally believed that this would increase their efficiency in line with private industry.
In the early 1960s this new attitude was clearly demonstrated in the appointment of Robert McNamara, the director of the Ford Motor Company, to the post of Secretary of the Department of Defence.
In Britain this trend has been less marked although the more recent appointment of Sir Derek Rayner, the managing director of Marks and Spencer, as the Conservative government's economic ‘watchdog’, is significant for similar reasons.
The Jarratt Report, based on efficiency studies in a number of universities, and the Green Paper,The Development of Higher Education into the  1990s , provide evidence of a similar trend in higher education.
The latter advocated the establishment of objectives and the monitoring of their achievement through the development of measures of performance.
The growth of single interest groups
If there is any truth in the observation that, in many things, Britain tends to follow one step behind the United States, then we might expect the single interest group to have a real impact in this country in the future.
The beginnings of such a growth are already being recognised in the vastly increased membership of CND, conservation groups, the Women's Movement, and the emergence of professional lobbyists.
In America the increased activity of the single interest group has led to a reduction in the strength of the political party.
The internal wrangles, sometimes over single issues, which are coming to characterise British party politics in the 1980s, may well foreshadow a similar process.
Summary
In his analysis Atkin (1979) points to the ‘fragmentation of community’ as the single most important factor feeding accountability pressures in the USA.
The growth of single interest groups, the loss of confidence in specialists, and anxiety over the apparent failure of education to deliver a variety of ‘goods’, may all be regarded as manifestations of the weakening of common purpose.
Where there is agreement about goals the public assumes that professionals share in that consensus but ‘if consensus is in doubt, there is an accompanying uncertainty about the values and practices that guide professional activity’.
Clearly this phenomenon is not confined to the United States; value pluralism has created something of an educational Tower of Babel in Britain also.
Paradoxically however, the breakdown in value consensus that generated the accountability movement might seem to require a new form of consensus if accountability demands are to be satisfied.
Unless there is some agreement about purposes how can schools and teachers be expected to render account?
How will they know what they are being held accountable for?
These questions, among others, exercised a group of educationists who met at a seminar on accountability sponsored by the SSRC and held at Cambridge (England) in 1977.
While most participants perceived the problem they differed somewhat over the matter of its resolution.
MacDonald (1978) argued  that no genuine consensus is possible; anything so called would represent only the views of the most powerful and reinforce their hegemony.
Becher (1978) denied that a general ideological consensus about educational ends is ‘necessary in theory’; in practice he believed that teachers can, and do, negotiate a working consensus, usually framed in terms of basic minima.
Nisbet (1978) and Kogan (1978) responded to the problem by turning their attention to the procedures which might be employed to meet accountability demands.
Both, in rather different ways, advanced pluralist or multiple solutions which acknowledge multiple values and purposes, although Nisbet admitted that some methods (viz. testing) were likely to pre-empt the field and destroy the balance.
The question of whether it is possible to establish a normative consensus, based on rational discussion undistorted by values, has also been addressed by Habermas (1975, 1979).
He has argued that such a thing is indeed possible and often a potential solution to the legitimation crisis'.
Responses
While the intention of the 1977 Cambridge Accountability Seminar was to clarify the conceptual background to the accountability movement, the participants were swift to recognise its inevitability and admissibility, in one form or another.
Thus they spent much of their time debating the validity of various evaluation procedures as potential responses.
Details of some of these strategies, and others, are discussed fully in Part Two (chapters 4 to 6) but since not all are considered there from an accountability perspective , they need some introduction here.
It is in the development of specific accounting procedures that the US and UK experience has most obviously diverged.
Although any generalisation should be regarded with caution, the dominance of economic input-output models in the United States has encouraged a dependence on the evaluation, or, more accurately, the assessment of outcomes or products of schooling.
Hence the ubiquity of testing, and evaluation schemes which involve the assessment of teacher or student performances.
Atkin (1979) lists the following as employed in some areas of the USA, at some time in the recent past:
1.
Performance contracting the commissioning of private firms to work with teachers in schools to raise achievement levels of children;
2.
Competency-based teacher education — the requiring of teacher education institutions to specify and demonstrate  what each teacher is expected to be able to do as a result of his/her training;
3.
Programme evaluation the routine assessment of the effectiveness of costly new educational programmes.
(This created an ‘evaluation industry’ which sometimes consumed one-fifth to one-third of the total costs associated with particular programmes.)
4.
Zero-based budgeting, cost-benefit analysis, management by objectives — the application of management techniques which demand the assessment of highly operationalised programme goals as a guide to financial allocations;
5.
Educational vouchers a system of enhancing school competitiveness by issuing vouchers to parents to be ‘cashed’ at the school of their choice;
6.
The National Assessment of Educational Progress — an attempt to establish the condition of the nation's overall educational well-being by administering selected tests to carefully chosen ‘light’ samples of the school population.
(Latterly some states, e.g. Florida, have instituted their own ‘blanket’ testing programmes.)
7.
Minimal-competency testing — as mentioned earlier, some 38 states have now introduced laws which require that students should be able to demonstrate that they possess certain basic skills after attendance at public school.
It is significant that all these schemes, with the exception of educational vouchers, involve some form of testing.
In the United Kingdom the attitude to testing has been more ambivalent, although examinations and tests have played an important part in British education for well over a century.
In 1862, Robert Lowe's notorious Revised Code introduced ‘payment by results’ which relied upon a form of minimum competencies testing.
Public examination statistics have regularly been collected although difficulties of establishing comparability over time, and across different examination boards and subjects, have reduced their usefulness for assessing the performance of the education system as a whole.
In the 1970s the Department of Education and Science pinned its hopes on the APU to provide a general measure of the achievement of children at schools and, implicitly, changes in standards over time.
Ten years after the establishment of the APU, hopes for the kind of information it was intended to provide had faded.
Fierce criticism of the mathematical model (the Rasch model) on which the testing programme was founded  1979) encouraged the DES to begin looking elsewhere for a thermometer to take the temperature of the education system; the benchmarks mentioned earlier may be the new thermometer (Chapter 4 considers these criticisms of the APU).
Other schemes of American origin are not without their advocates on this side of the Atlantic.
Recent Secretaries of State for Education have been known to favour educational vouchers as a way of increasing parental choice and allowing the quality of schools to be judged by market forces though they have been unable to find a workable system.
Instead the traditional role of the national and local inspectorate was enhanced; there was more systematic utilisation of public examination results as an indicator of educational well-being; and newer strategies (such as local authority school evaluation and teacher appraisal schemes) are being devised, adapted or extended.
Nisbet (1978) identifies five broadly defined strategies that might be employed as accountability procedures, namely: testing, monitoring of standards by conventional examination, inspection, the development of standardised pupil record systems, and various forms of school self-evaluation (which he calls self-assessment).
Nisbet maintains that these five strategies represent the range of possibilities and that they can each be located on a spectrum, the poles of which can be described as ‘hard’ and ‘soft’.
Testing stands as the ‘hard’ pole because procedures tend to be external, formal, judgemental, product-orientated, and analytic in their method of assessment.
In contrast, forms of self-evaluation can be located towards the ‘soft’ pole because they tend to be internal, informal, descriptive, process-orientated and holistic in their mode of assessment.
Although, as we shall illustrate in Part Two , it is an  over-simplification to assign certain categories of evaluation strategies to specific locations on a hard/soft spectrum, Nisbet's analysis serves to map the field of actual and possible accountability procedures.
The Concept of Accountability
At this point we think it worth using a little space to examine the concept of accountability.
The diversity of responses to accountability pressures suggests that the concept is interpreted differently by different groups according to their different interests.
In other words, it is a social construct.
The East Sussex Accountability Project, which (like the Cambridge Accountability Project and a Scottish study conducted  by researchers at Stirling) was funded subsequent to the 1977 SSRC Seminar at Cambridge, attempted a conceptual analysis.
Three facets of accountability were distinguished:
(1)
answerability to one's clients i.e. pupils and parents (moral accountability).
(2)
responsibility to oneself and one's colleagues (professional accountability).
(3)
accountability in the strict sense to one's employers or political masters ('contractual' accountability).
From this analysis it appears that the term ‘accountability’ is only strictly correct when reference is made to contractual relations with employers.
The sense in which the term is used is formal-legalistic, and implies that accountability is largely one way (i.e. of teachers to employers) and that accountability procedures involve sanctions (e.g. withdrawal of resources and other forms of support).
Much of the public debate has, indeed, been about contractual (strict) accountability.
It is interesting, therefore, that the evidence of the UK accountability projects suggests that teachers operate with a very different model: one that is grounded in concepts of answerability or responsibility.
In this context Elliott has pointed out that the association of answerability, responsibility and accountability with specific audiences (i.e. clients, colleagues and employers, respectively) is problematic.
Thus in describing the perspectives of various groups on school accountability, the East Sussex Accountability Project's alternative classification (moral, professional and contractual accountability) is probably more useful.
Certainly, Elliott finds less conceptual difficulty with this classification, and it has been used extensively elsewhere, in the analysis of various approaches to evaluation.
In Part Two , it will be referred to in a similar way; or instance, insider approaches to evaluation will be discussed as a mode of professional accountability, and inspections and local authority schemes will be examined as responses to contractual accountability demands.
Levels of Accountability
Another problem, and one that was intimated in the previous paragraph, is the question of who is to be considered accountable to whom .
It is usually assumed that teachers and heads are held to account but whether they are accountable to resource providers (ratepayers, taxpayers, policy makers, administrators), customers (pupils, parents, employers), or their professional colleagues, is ill-defined.
In the UK this issue was thrown into bold relief by the Tyndale Affair, which some observers have, mistakenly, assumed to be a cause rather than a symptom of the accountability debate.
The public inquiry, conducted by Robin Auld QC, into the teaching, organisation and management of the William Tyndale Junior School in Islington, North London revealed considerable confusion regarding the various levels of accountability.
Three are commonly identified i.e. national, local and school, and in an attempt to clarify them the following paragraphs examine each in turn.
According to the 1944 Education Act the Secretary of State has a duty to ‘promote the education of the people of England and Wales and the progressive development of institutions devoted to that purpose…’, although effective control was, at the time of the Tyndale dispute, devolved to the LEAs.
Similarly, after a report of the 1968 Parliamentary Select Committee, a greater share of inspection was also left to LEAs: the ‘duty’ of the Minister to cause inspections was officially interpreted as a ‘right’.
Thus during the Tyndale affair the DES tended to keep its collective head below the parapet.
LEAs have a statutory obligation to provide an ‘efficient’ and ‘suitable’education, as far as possible ‘in accord with parental wishes’.
Through its Rules of Management, however, the Inner London Education Authority (ILEA) had, at that time, effectively divested itself of the exercise of its control.
When things went wrong the early warning system was supposed to be the authority's inspectorate.
However this body was experiencing some role ambiguity and since it possessed no formal power to ensure that its professional judgement was heeded, it tended to define its function as advisory rather than inspectorial.
Rule 2(a) of the authority's Rules of Management gave the schools' Managers (now, since the 1980 Education Act, called ‘governors’) responsibility for the ‘oversight of the conduct of the curriculum of the school, in consultation with the headteacher’.
What precisely was  entailed in oversight was not made clear and in practice the control of the school, its aims, policies and methods of teaching was left to the headteacher.
It was not until a junior school staff, which regarded its professional status as inviolable, was confronted by its Managers that the whole taken-for-granted structure of accountability was thrown into question.
The main target for the Auld Report's criticisms was the LEA because it had interpreted its responsibilities in terms largely confined to the provision of resources.
Clearly Auld was of the opinion that the Tyndale incident could have been avoided if the authority had taken a wider view of its role.
In other words, he held the local authority as partly accountable for the situation that developed at the school.
In so doing he emphasised the need for accountability at all levels of the system.
It is always difficult to establish the precise nature of the relationship between events, but it seems significant that the ILEA published its booklet Keeping the School Under Review in the year following the conclusion of the Tyndale inquiry.
Undoubtedly LEAs have reassessed their stance on accountability issues as a result of the Auld Report, but at school level the impact of the national debate seems to have been erratic.
The Cambridge Accountability Project, after two years of investigations in six schools, reported that teachers rarely saw their accountability extending beyond their colleagues and clients (children and parents) to governors and local government officials.
Neither did governing bodies regard their role as primarily concerned with monitoring the curriculum.
The schools chosen for investigation by the Cambridge project team considered themselves to be ‘responsive’ to the interest and concerns of local audiences.
In the generation and communication of information, they also believed themselves to be ‘self-accounting’.
Their concept of accountability however, appears rather different from that of Robin Auld, QC more ‘moral’ or ‘professional’than ‘contractual’.
At  the end of the 1980s the pattern of accountability is changing.
DES proposals for a national curriculum, the growth of categorical funding by the DES and MSC in priority areas specified by central government, the dismantling of the Burnham Committee on teachers' pay, and changes in the control of polytechnics and colleges of higher education are all moves designed to reduce the power of the LEAs and increase central control.
At the same time schools are being placed in the front line of accountability by the  proposal to give headteachers and governors direct control of budgets and the opportunity to opt out of LEA control.
The Conservative government's principal objective is to allow market forces to operate and enable popular schools to expand to their full capacity i.e. to the numbers they were built to accommodate before falling rolls.
Correspondingly, unpopular schools might expect to contract to a point at which they lose their viability.
In this sense the policy represents the essence of consumerism.
At the time of writing, the required changes in legislation are promised in a major new Education Act scheduled for 1988.
Criteria for Accounting Procedures
Few people today would deny the need for some form of accountability in education.
However the seemingly irreconcilable interests (eg. professional versus lay) that are brought into the forum for debate, require that criteria be established for judging the adequacy of accounting procedures in given contexts.
This need for criteria was recognised at the Cambridge seminar in 1977 and three papers specified criteria that schemes would need to satisfy.
For the purposes of comparison these have been summarised in Figure 1.1.
Although Nisbet states a greater number of methodological criteria, the lists in Figure 1.1 show many similarities.
Drawing these together for the purpose of an Open University course, Nuttall compiled a list that was intended to embody ‘the best and clearest features of them all and that is reasonably comprehensive’.
Thus he proposed that an accountability scheme should:
(a)
be fair and perceived as fair by all the parties involved;
(b)
be capable of suggesting appropriate remedies;
(c)
yield an account that is intelligible to its intended audience(s);
(d)
be methodologically sound;
(e)
be economical in its use of resources;
(f)
be an acceptable blend of centralised and delegated control.
There is a problem with all these formulations of criteria, however.
They tend to be regarded as lists against which particular accountability schemes need only to be checked off.
We would argue that    depending on the concept of accountability (moral, professional, contractual) that the procedure seeks to satisfy, and the features of the particular context (sector of education, local pressures etc.), the individual criteria will assume relatively greater or lesser importance.
In some cases they may appear to be in conflict.
For instance we have argued elsewhere that if accountability is interpreted in a professional sense then the question of intelligibility to lay audiences is rarely an issue because the primary audience is teachers' professional colleagues.
Furthermore to insist that a procedure must include a significant element of external control could hinder the implementation of remedies: a criticism which is often regarded as the most important.
(This theme will be returned to in Chapter 5.)
The implication of the above discussion is that the adequacy of any accountability scheme will depend on (1) the particular interpretation being employed in a particular context, and (2) a holistic, or overall, judgement of the extent to which the procedures meet the criteria.
Clearly there is no simple formula for resolving the problems of educational accountability.
Although one group can be encouraged to understand and respond to the interests of another, we need to acknowledge that true consensus is unlikely.
A ‘working’ agreement is the best we can hope for, though probably sufficient none the less.
For this reason then, the criterion of FAIRNESS seems superordinate.
We will draw upon these criteria in Part Two in judging the various strategies of evaluation.
As a final comment it is worth attempting to put the accountability debate in some perspective.
Currently the question of educational accountability appears to be less of an issue than was predicted in the 1970s.
As mentioned earlier the current government (1987) is set to increase consumerism in education by allowing popular schools to take in as many pupils as possible without the requirement on the part of LEAs to balance intake among schools.
It also intends to set up city technical colleges funded by industry in an effort to increase parental choice, and this is seen as a way of reducing the power of the LEAs.
Indeed, their proposals to give budget control to headteachers is explicitly seen as a way of making a direct link to schools not mediated by LEAs.
However, the government has not been so preoccupied with accountability procedures as appeared to be the case in the early 1980s.
It appeared then to favour teacher appraisal, the publication of examination results, and to a lesser extent the evaluation and review of schools (especially through curriculum review).
Now the  publication of examination results has become routine, and has not apparently delivered the goods (we look at this in Chapter 4).
Teacher appraisal did appear to be part of the accountability process, but, as we shall see, this has changed to some extent.
Some kind of assessment of the competence of teachers was seen as a way of weeding out those who were incompetent: a reaction to severe cuts in education (along with the effects of falling rolls), and the need to thin out the teaching force.
(HMI did not find this an important objective of existing appraisal schemes in the mid-1980s.)
Thus it was taken up as part of a larger review of education in general, and teachers' conditions of service in particular .
Better Schools , which made the definitive statement on this general review, discussed teacher appraisal in the context of the management of the teaching force.
This White Paper saw appraisal as providing ‘reliable, comprehensive and up-to-date information necessary for the systematic and effective provision of professional support and development and the deployment of staff to best advantage’.
This approach became part of the negotiations with the teachers' unions, who did not in principle object to appraisal, but wanted to ensure that they obtained good conditions of service and an adequate pay increase before agreeing to it.
The implementation of an appraisal scheme, and pilot studies to develop the details, have been held up by the drawn out teachers' dispute.
Despite the government's interest in appraisal as being both developmental (for the teacher) and directly related to salary and career advancement, early experience of schools in developing schemes was almost entirely based on teacher development.
Both ends can be achieved, but it is more usual for a school to start with a developmental aim, if for no other reason than that it is less threatening.
In fact some appraisal schemes developed from an interest in, and experience of, school self-evaluation.
King rightly points out that a scheme which is intended to weed out poor teachers is not necessarily the best to engender the trust and confidence required to develop the work of teachers.
In addition such a scheme focuses on individuals and not groups of teachers, which, we will argue in Chapter 2, is an important focus for evaluation.
Group development might also encourage peer assessment which a contractual appraisal scheme is not likely to include.
King also wonders whether the impact of teacher appraisal on school improvement will be commensurate with the cost of such schemes.
Until the ‘official’ pilot schemes are instituted we only have the experience of the formative approaches in the UK to guide us on how appraisal is to be conducted.
The existing schemes in the early and mid-1980s were usually based upon an annual interview by a member of the Senior Management Team of a school, or perhaps a head of department.
Occasionally classroom observation of the teacher under review would also be carried out by the senior teacher, and sometimes an observation schedule was used.
In the USA teacher competency tests are also included; these test teacher knowledge.
As we will show in subsequent chapters observation is an important tool in evaluation in general(i.e. outside of the context of teacher appraisal), but it is likely that given the context of contractual obligations and salary enhancement, teacher appraisal will not form part of school evaluation.
The accountability debate was, however, important in that it highlighted a need for systematic evaluation in education.
Teacher interest was aroused and LEAs began to devise various schemes to encourage school self-evaluation, although current changes, and those expected in the Education Act 1988, make the future of these uncertain.
2
Professional Development and Educational Improvement
Introduction
In this book we have chosen to distinguish three contexts in which evaluation procedures operate.
These provide the titles for our first three chapters.
The discussion of concepts of accountability in Chapter 1 suggests, however, that such a separation may not be justified.
If we accept that accountability can be interpreted in a moral and professional, as well as a contractual, sense then it is possible to assume a concept of professional development.
If teachers regard themselves as professionally accountable to themselves and their colleagues then they have accepted a commitment to the maintenance and improvement of their practice.
Thus professional development becomes a condition of professional accountability.
According to this interpretation, at least two of the contexts for evaluation that we have identified become aspects of the same thing.
If a narrower interpretation of accountability is adopted, one more closely associated with contractual accountability, then the case for considering the relationship between evaluation and professional development,as a separate issue , is strengthened.
There seems to be some justification for this since most of the contemporary debate has been concerned with accountability in a ‘strict’ or contractual sense.
Nevertheless it is worth considering whether some implicit model of accountability underlies all forms of evaluation whatever their stated purposes (an issue that was raised at the very beginning of Chapter 1).
In similar vein, it is also possible to argue that some view of how improvement in practice takes place is a necessary prerequisite of any accountability procedure.
After all there is little point in an evaluation revealing educational provision to be unsatisfactory (by anybody's standards) if the question of how the situation may be remedied has not been considered.
One British observer has pointed out how curious it is that assessment of performance procedures has been developed (by the APU) without any reference to procedures for  the improvement of performance.
However, perhaps the strongest support for the concept of professional accountability derives from the argument that this has the best chance of promoting positive change in the practices of individuals and institutions.
This stance is premised on the view that effective change depends on the genuine commitment of those required to implement it, and that commitment can only be achieved if those involved feel that they have control of the process.
In other words teachers and schools will readily seek to improve their practice if they regard it as part of their professional responsibility, whereas they are likely to resist change that is forced on them.
This argument has a psychological (and ideological!) appeal although the empirical evidence to support it is rather thin.
The work of Bennis, Benne and Chin (1969), and other strategy theorists, is relevant here, although in collating the evidence of various strategies of change little attempt has been made to judge their relative effectiveness.
For instance, the major contribution of the research of Bennis et al was to identify and describe three broad categories of strategies for change in social systems:
1.
power-coercive strategies — based on the intervention of those with legal authority to alter conditions (e.g. the government);
2.
empirical-rational strategies — based on the assumption that people are rational beings who will change their ideas or behaviour if the effectiveness of a concept or practice is clearly demonstrated by research;
3.
normative-re-educative strategies — based on the assumption that patterns of action are maintained by the commitment of individuals to socio-cultural norms (the status quo ).
Thus change only occurs when individuals are encouraged to change their normative orientations in attitudes, beliefs, values, knowledge, skills, roles and relationships.
In order for this to happen it is necessary to ‘activate forces within the system to alter the system’.
In relation to curriculum evaluation, this analysis is important because it can assist the identification of assumptions about change which are implicit in various accountability procedures and evaluation strategies.
We shall return to this issue later in this chapter, but before we do we need to take a brief look at the way in which ideas of change have influenced other aspects of education, in particular curriculum  development and innovation.
Our assumption is that if evaluation is directed towards problem solving then it presupposes a need for change, and most of the obstacles associated with other forms of educational innovation are likely to be encountered in the implementation of proposed ‘remedies’.
Ideas Concerning Educational Development and Change.
When considering those things that prevent the successful implementation of curriculum project materials and strategies, Bolam (1975) located most barriers within the ‘user system’.
Thus a school's organisational structure, the role of its head, and the values and attitudes of its teachers come to be regarded as crucial to the survival of any curriculum project.
According to Hoyle (1975) the root of the innovation problem lies in a dilemma: ‘Curriculum innovation requires change in the internal organisation of the school.
Change in the internal organisation of the school is a major innovation’.
Since social systems, in this instance like physical systems, tend towards inertia, the challenge to innovation is bound up with reversing the usual trend.
Hoyle's solution to the problem lies in his concept of the ‘creative school’: a school whose organisational character is sufficiently ‘open’ and flexible to enable changes to its authority structures, its decision-making procedures, its professional relationships, and its pedagogical ‘code’(eg. from ‘traditional’to ‘progressive’).
Hoyle's major assumption is that the school as a social system can be creative.
It is an assumption which is open to the charge of reification since many people would argue that only individuals can be creative.
The OECD Centre for Educational Research and Innovation, for whom Hoyle first wrote his paper, comes to his defence and expounds the relationship between school and the individual in the following way:
It has been argued that it is the individual not the institution who is creative and that the schools can only adopt the ideas of individuals.
Initially new ideas and practices must stem from the imagination and initiatives of individuals and, similarly, innovations developed outside the school will only ‘take’ if they have the commitment and practical support of the individual teacher.
Nevertheless, in practice, innovation must be seen as a function of the quality of the school.
There are two reasons for this.
Firstly, many  innovations are school-wide in their application and cannot be implemented at all unless a number of teachers, perhaps even the entire staff of a school, both agree to, and become committed to, their implementation.
Secondly, because of the integration between different components of the social system of the school, an innovation introduced by a single teacher will often have repercussions in other parts of the system — perhaps because there is a need for additional resources, or for more time, or because it is predicted [sic]upon new pupil roles, or involves a greater degree of integration.
This is not to deny the significance of the creative individual, but his or her efforts at innovation can only be really sustained when they take root in and pervade the school as a whole.
It needs to be acknowledged that Hoyle takes a very wide view of what constitutes a school's ‘organisational character’ or ‘deep structure’.
At one point he rephrases the central dilemma of innovation and in so doing he implies that the most important characteristic of a school's internal organisation is a ‘collaborative professional relationship’ among teachers.
He then argues the case that teacher professionality is both an input and output of the school.
In other words teacher professionality contributes to the creativity of the school, but the school itself can also be an agent of professional development in teachers.
In this context he formulates his now familiar, if still empirically untested, distinction between ‘restricted’ and ‘extended’professionality.
The following is a recent formulation of this distinction:
By restricted professionality I mean a professionality which is intuitive, classroom-focused, and based on experience rather than theory.
The good restricted professional is sensitive to the development of individual pupils, an inventive teacher and a skilful class-manager.
He is unencumbered with theory, is not given to comparing his work with that of others, tends not to perceive his classroom activities in a broader context, and values his classroom autonomy.
The extended professional , on the other hand, is concerned with locating his classroom teaching in a broader educational context, comparing his work with that of other teachers, evaluating his own work systematically, and collaborating with other teachers.
Unlike the restricted professional, he is interested in theory and current educational developments.
Hence he reads educational books and journals, becomes involved in  various professional activities and is concerned to further his own professional development through in-service work.
He sees teaching as a rational activity amenable to improvement on the basis of research and development.
This description of the extended professional takes some account of Stenhouse's criticism of Hoyle's earlier formulation which seemed to emphasise an uncritical acceptance of theory and consequently reduced teacher autonomy.
Some of this criticism still applies but what is perhaps more important is the alternative formulation that Stenhouse offered.
For him the critical characteristic of the extended professional is: ‘a capacity for autonomous professional self-development through systematic self-study, through the study of the work of other teachers and through the testing of ideas by classroom research procedures’.
This proposition forms the basis of Stenhouse's concept of the ‘teacher-as-researcher’: an idea which he developed in the context of the Humanities Curriculum Project (HCP), and which has since influenced approaches to curriculum development and curriculum evaluation (especially teacher self-evaluation).
According to MacDonald and Walker (1976), HCP offered the teacher a dream-image of himself that, far from undermining his existing professional identity, gave him the opportunity to acquire an additional identity.
‘The promise was a future in which through a process of redefinition of the relationship between teacher, taught and knowledge, schools would be transformed into democratic institutions, teachers into research-based master craftsmen of a new professional tradition, and pupils [invariably called ‘students’ by HCP]into reflective scholars'.
MacDonald and Walker point to the fact that HCP acquired the characteristics of an exclusive club in speculating that, ‘Stenhouse invited the teachers to create an alliance with him against the forces of institutional and attitudinal inertia in the school system’.
What Stenhouse was proposing was a humanistic solution to the dilemma posed by Hoyle.
Whereas the problem, as Hoyle saw it, was only amenable at the level of the social system (the creative school), Stenhouse was here proposing systematic change based essentially on individual action.
Stenhouse's proposal was in marked contrast, not only to Hoyle's, but, for different reasons, to the tradition of curriculum development that had developed in the 1960s, both in the UK and the USA.
As was noted in Chapter 1, the 1960s were characterised by educational expulsion on both sides of the Atlantic.
It was a time of large scale educational programmes in the United States and the genesis of centralised curriculum development projects in the United Kingdom.
Like the National Science Foundation in the USA, the Nuffield Foundation sponsored a number of ambitious science education projects in Britain.
Although born mainly out of an attempt by the British government to gain control of the curriculum, the 1960s also saw the establishment of the Schools Council, a quango whose role was to advise the government on curriculum and examinations.
Immediately dominated by the teacher unions, who were committed to the maintenance of teacher autonomy, the Council soon came to view its tasks as increasing the range of choice available to teachers but in no way prescribing what and how they taught.
For this reason it initiated a substantial number of research and development projects from which teachers and schools could make their choice (a cafeteria system).
Most of these early curriculum development projects approximated to the Research Development and Diffusion (R, D & D) model of innovation, which was already familiar in industry and agriculture.
Accordingly the process of curriculum development involved a team of ‘experts’ at the ‘centre’providing the knowledge base for an innovation, then producing an appropriate content and strategy, and finally communicating it effectively to potential users at the periphery.
The criteria for judging the success of an innovation became the extent to which a curriculum package (materials, and/or strategy) was ‘adopted’ by the user group.
‘Users’ were generally regarded as ‘passive’but open to persuasion by rational and empirically supported argument (an ‘empirical-rational’strategy in terms of Bennis, Benne and Chin's categories).
Unfortunately practical reality fell somewhat short of the theoretical ideal.
The strategy which had proved so successful in the sphere of science and technology encountered serious problems when applied to complex social systems.
Stenhouse's notion of the ‘teacher-as-researcher’ grew out of his (and others') disillusionment with the R, D & D model, which began to appear mechanistic and technocratic and unlikely to enjoy the kind of teacher commitment that he saw as necessary for effective change.
In this respect Hoyle shared some of Stenhouse's view (if only implicitly) since his concept of the ‘creative school’ and his concept of the ‘extended professional’imply that innovations are unlikely to be effective unless they take account of the need for organisational support within the school, or teacher commitment to professional development.
Whether one takes the view that the whole school (c.f.
Hoyle) or the individual teacher (c.f.
Stenhouse) holds the key to successful curriculum development, the argument for suggesting that the  ‘periphery’(the schools and teachers), rather than the ‘centre’(government bodies or centralised curriculum development agencies), is the prime focus of change is very persuasive.
The implication is that the R, D and D or centre-periphery model had been wrongly conceived in its application to education, because it was premised on the possibly mistaken view that people are rational beings who will implement ideas that have been demonstrated to be effective.
The experience of the early curriculum projects seemed to demonstrate that it was not sufficient to change knowledge, but necessary also to change the attitudes, values and the taken-for-granted ways of doing things that govern professional activity.
Thus ‘normative-re-educative’ strategies for change came to be regarded as important.
The influence of social networks was also acknowledged, as was the need to solve specific problems in specific contexts.
For all these reasons an alternative to the centralised curriculum development project was sought, and the ideas of Stenhouse, and those like him, came to have considerable influence.
Our response was the growth of school-based curriculum development (SBCD) grounded in ‘situational analysis’ of the unique patterns of internal and external constraints, influences, needs and resources of individual schools.
In the late 1970s this model of curriculum development found favour in the UK.
It also underpinned some of the Schools Council's programmes of work in the period 1980 to 1983, which were more concerned with supporting and developing existing initiatives, taken at the ‘periphery’, than devising new ones from the ‘centre’.
The evolution of theory and practice in curriculum development and innovation has, to a large extent, been paralleled in the area of in-service education and training (INSET).
The reasons for such a development are much the same.
Early forms of INSET were based on courses located outside schools and dealing with generalised INSET issues.
Like centralised curriculum development, ‘courses have come to be increasingly criticised for their failure to deal with needs in a way which offers ready transfer of practice to the individual teacher's classroom or beyond that to the whole school’.
This loss of faith in course-based INSET to influence practice gave rise to growth of school-based INSET : the INSET equivalent of school-based curriculum development.
However INSET which is located entirely within the school and drawing exclusively on its own resources can be criticised for parochialism.
According to Henderson (1979), ‘no school can reasonably be so bold as to suggest that it has nothing to learn from other schools, from professional teacher-trainers or from educational  scholarship and research’.
Thus a third alternative has emerged:school-focused INSET .
This attempts to synthesise the course-based and school-based models but ‘emphasises the direction of INSET towards the immediate and specific needs of one school and its teachers’.
Although there is still little empirical evidence of its effectiveness, Bolam (1980) indicates that this approach is gathering considerable support.
Indeed this trend has been maintained and further developed under Grant Related In-Service Training (GRIST).
The same may also be true of a similar approach to curriculum development, because a number of recent curriculum development projects have attempted to combine the resource advantages of the centralised project with the relevance of school-based development.
The Schools Council Industry Project, now called the School Curriculum and Industry Partnership, could be described as school-focused curriculum development.
Assuming that schools-industry liaison is a good thing and that schools should do more of it, the project team has set out to support the development of ‘local solutions to local problems’, rather than prescribe a particular kind of development.
Similarly, the Teacher — Pupil Interaction and the Quality of Learning (TIQL) Project, directed by John Elliott for Schools Council Programme 2, aimed to encourage the development of teachers as researchers by allowing teachers to define their own problems (within a general framework), to carry out their own research, propose subsequent action, and monitor the consequences of its implementation.
Likewise the Secondary Science Curriculum Review adopted a periphery-centre strategy whereby the products of local or school-based teachers' working groups were evaluated and published by the central project team.
Thus the role of the central team is one of facilitation: the provision of resources, consultancy, practical assistance and co-ordination.
One of the most interesting things about the recent history of curriculum development and in-service education and training is that most strategies owe more to argument than empirical evidence.
It is significant that having conducted a review of the ‘state of the art’ in these areas, and drawn up a list of generalisations about the change process in education, Bolam cautions that generalisations ‘should be regarded as working hypotheses and pointers for future study since their basis in research is weak’.
He also makes the point that what evidence there is may be culture-bound, since most of it comes from the USA and possesses a dominant technological perspective.
In the UK one of the few recent studies of the impact of educational  innovation was undertaken by the Schools' Council's Impact and Take-Up Project.
In order to assess the extent to which the Council's curriculum development had impinged on schools, the researchers chose to investigate the degree of ‘contact’, ‘some use’ and ‘extensive use’of project materials.
Unfortunately these criteria are more problematic than they first appear; among other things they give no indication of what might be a reasonable expectation of success against which percentage ‘contact’ etc. might be judged.
As early as 1974, Shipman suggested that professional development is possibly the only legitimate indicator of the success of an innovation, although it is considerably more difficult to measure than take-up of project materials.
Recent support for Shipman's view comes from Bolam who, on the basis of his review of innovation research, emphasises that educational change is a process, not an event, and that the individuals and social systems involved interact with each other over time and are changed by the change process itself.
At a commonsense level, therefore, the professional development of teachers, individually or collectively as part of the social system of the school, appears crucially important to the improvement of educational provision.
If this is so, it is worth looking at professional development a little more closely.
The Nature of Professional Development
The proposition that professional development assumes a concept of professionalism appears tautological.
However, ‘professionalism’ can be interpreted in a variety of ways, some of which are now regarded as pejorative.
Some writers have pointed out that the notion of professionalism is occasionally used to improve the image, prestige and rewards of teachers with little or no reference to any commitment to improve educational practice.
Without the latter, the former is indefensible.
It is significant, therefore, that Hoyle employs the term ‘professionality’ in preference to ‘professionalism’.
He thereby differentiates procedures designed to improve professional practice from those concerned with enhancing status.
If professional development is understood in terms of increased professionality then clearly it can be associated with the goal of increasing teacher effectiveness .
No one would deny the value of this.
There is another problem however.
This time the difficulty lies not in the term ‘professional’ but in the term ‘development’.
‘Professional development’ seems to imply that we have some developmental theory  concerning the professional growth of teachers, and that it is a ‘natural’process.
This is the assumption that underpins a comparison between teacher development and child development made by Eraut (1977), an extract from which follows:
1.
A teacher doesn't develop a child, but seeks to understand, promote and foster the development which is already taking place.
So we cannot have a strategy for teacher development any more than a teacher can have a strategy for child development.
We can only have strategies for promoting or fostering teacher development.
2.
Teacher development is natural, just as child development is natural.
So perhaps we need to be more concerned with providing the right environment and with removing constraints than with creating ‘master plans’.
3.
Our expectations of teachers have as significant an effect on them as their expectations have on pupils.
The best way to promote teacher development may be to expect it, or at least to be careful that one's actions do not implicitly suggest that one does not expect it.
4.
The child often learns best when an appropriate variety of concrete experiences are reflected upon, talked about and assimilated or accommodated into his growing mind.
Perhaps the reflection upon and discussion of concrete personal experience should play a role of similar importance in teacher development, especially when our language for communicating about educational problems is so obviously deficient.
Surely the fact that teachers are at the ‘formal operational’ stage does not mean that they prefer to discuss at an abstract level!
Might it also be that the common phenomenon of token adoption of an innovation is an example of assimilation without accommodation?
5.
According to Piaget [1929]the child organises his experience through ‘schema’; and according to Kelly [1955]people organise their experience through ‘personal constructs’.
Even though Piaget was concerned with development and Kelly with personality the comparison increases our understanding of both.
It also explains why experience in the classroom is so difficult to communicate.
Teacher development has to build on those constructs which exist, and cannot easily be promoted in any other way.
6.
The child is best motivated when following his own interests.
These are often a combination of personal and peer-group interests; and pursuing them can lead to the development  of a wide range of knowledge and skills.
Likewise, the teacher is most motivated to study educational problems when pursuing his own problem defined in his own language.
This can also lead to the development of a wide range of knowledge and skills, as nearly all educational problems are multi-faceted and one problem inevitably leads on to another.
Eraut's argument is appealing particularly in the light of recent experience of curriculum development, outlined in the previous section.
However Piaget's theory of child development is an empirically grounded description of the structure of cognitive learning.
We would suggest that there is no comparable description of teacher development as such.
(We assume all teachers have reached the stage of ‘formal operations’!)
Elsewhere, Eraut (1978) admits this himself.
In fact, he identifies two theoretical questions to which he seemed to have assumed answers in his earlier paper:(1) Why do teachers change, or fail to change?(2) How do teachers learn?
Here, he also contends that ‘we have no theory of professional learning on the job which seeks to explain how teachers learn from classroom experience, how they learn from colleagues, or how they learn from people and publications outside the school’.
In the absence of a theory (description and explanation) of teacher development, we are left with a number of statements which are essentially normative or prescriptive.
In other words they give an account of what a professional ought to be like, or advocate a particular process for increasing professionality.
It should be stressed that this is also true of other so-called developmental theories.
For instance, Kohlberg's (1964) theory of the development of moral reasoning has been criticised for proposing a hierarchy of stages, supported more by wishful thinking than empirical evidence:
Furthermore, the empirical base of the theory rests on the Kohlberg moral judgement scale.
The status of this scale is curious.
After more than 23 years of use, the reliability of the measure is still undefined, the validity of the measure unknown, and the scoring system still under development.
Finally, and most important, Kohlberg's Stage 5 corresponds to traditional conservative legal philosophy, whereas Stage 6 reflects traditional liberal and radical political reasoning.
The implication is clear: liberals are more advanced  morally than conservatives.
Liberals may appreciate that conclusion, but it has little basis in empirical fact.
Thus Kohlberg's theory seems more a political manifesto than a scientific statement.
Could it be that statements about the professional development of teachers are mostly rhetoric, or at least moral rather than empirical argument?
It seems so.
If, however, we accept the moral argument we still need to find adequate reasons for our belief that professional development is a good thing per se .
Eraut (1977) avoids specifying the content or outcomes of teacher development, having rejected the assumption that a teacher who has developed has necessarily become a better teacher.
Other writers are less hesitant about attempting to describe what a fully developed professional is like.
Hoyle's description of the extended professional is one such formulation.
As we shall see later, a number of school and teacher self-evaluation schemes are prescriptive in that they are premised on a particular view of the competent professional (and/or institution).
This is perhaps particularly true of LEA schemes which are heavily dependent on checklists.
Questions relating to the way teachers perform their tasks can readily be translated into statements about what teachers ought to be doing!
Any prescription of the content or outcomes of teacher development is likely to be controversial because it is formulated from a value-position, but is a specification of process any less contentious?
Eraut (1977) adopts a process viewpoint when he argues that: ‘A teacher who is not developing to any noticeable extent is becoming a worse teacher, because development is natural and to avoid it is to deteriorate’.
Stenhouse's concept of ‘the teacher as researcher’ could be described as a prescription for the process of teacher development, although the process, as he conceives it, is not natural but learned.
Whether natural or learned, we would concur with the importance Eraut attaches to understanding the process of change and the factors that facilitate or constrain it.
As he points out there has been surprisingly little research in this area and what there is derives mostly from the sociology of education under the heading of teacher socialisation.
As the term ‘socialisation’ suggests this research has tended to concentrate on the macro-level, emphasising the influence of the social structure on the individual.
(It has also been more concerned with attitudes and values than teacher knowledge and skills.)
Studies by Dan Lortie (1975), in the United States, and Colin Lacey (1977), in the UK, have  been less determinist than most.
Lacey, for instance, develops a model of socialisation based on a modification of Becker's concept of social strategy.
The idea that teachers can have a strategy emphasises the power of individuals to act in social situations.
This concept of strategy, and the attempt to relate the macro and micro factors that have a bearing on teacher action, constitute the current research interest of a number of educational sociologists.
One major thrust of this recent research trend is towards greater recognition of what Lortie calls a ‘biographical orientation’, which investigates the interaction of personal and structural influences in an individual's career.
In general, sociologists are more interested in advancing ‘knowledge’ than developing strategies to influence ‘practice’.
However some organisational sociologists and humanistic psychologists working in applied fields have long acknowledged the important influence of personal styles and predispositions on professional and organisational effectiveness.
For instance, in the United States, Argyris and Schon (1974) have investigated professional effectiveness at managerial level across a number of professions.
Observing that people's perceptions of reality are often determined by their expectations (they see what they want to see) and that this can contribute to a serious disjunction between ‘espoused theory’ and ‘theory in use’, they proposed strategies for increasing professional effectiveness based on encouraging receptivity to critical feedback.
In the United Kingdom, the Tavistock Institute of Human Relations offers managerial courses on organisational effectiveness and professional development which pay considerable attention to the individual's need for a sense of personal competence.
In the specific context of developing strategies for increasing teacher effectiveness, the importance of this personal dimension has often been neglected, at least in the U.K. Thus teacher education has tended to focus on the needs of children or the needs of the institution, rather than the individual needs and motivations (including career motivations) of teachers.
This is not to deny that the purpose of teaching is the education of children, but to stress the crucial relationship between a teacher's professional development and his or her personal growth.
During his involvement with the Ford Teaching Project, Elliott (1976) observed a link between a teacher's capacity to develop self-monitoring ability and his tolerance of losses in self-esteem.
The source of his personal identity and the nature of financial and status rewards also seemed to affect a teacher's ability to  change his classroom practice.
In a recent article, William Taylor (1980) argues that professional development and personal development are not distinguishable processes but one and the same thing.
For this reason, programmes of teacher education need to recognise and respect individual teachers' responsibility for their own growth.
If they fail in this they are likely to be ineffective and encourage forms of organisation and control that are essentially unprofessional in their character and consequences.
Taylor concludes:
…one of the essential purposes of every kind of organisational provision must be to establish, maintain and enhance the teacher's own commitment to his own education.
Every teacher who makes excessive sacrifices in the time and attention needed for his own personal growth to the demands of the organisation within which he works or to its students is ultimately denying to that organisation and those students the very knowledge, understanding and skill which it is his professional responsibility to offer.
It is easier and less contentious to talk about professional development in terms of structures, frameworks, resources and methods, rather than in relation to desirable forms of personal knowledge and understanding.
Thus the new interest in professional development…runs the risk of stressing form at the expense of substance.
With this the argument comes full circle and we need to ask again: what is more important, the content/outcomes or process of teacher development?
(The importance of the personal factor will be taken up again in Chapter 11.)
Professional Development and Institutional Development.
If, as Taylor argues, professional development is closely bound up with personal growth we must question whether it is feasible to talk of institutional development.
Quite apart from the earlier argument about reification, is it legitimate to assume that the development of the whole school will be achieved by the collective professional development of its teachers?
Or is the organisation more than the sum of its parts?
Some people would argue that it is.
For instance, in the following extract Alun Jones (1980) argues for an in-school approach to in-service  training based on his experience in the Industrial Training Service:
…in-service training is often much less effective than it could be because it is based on an ‘educational model’ i.e. is focussed largely on the individual.
A number of organisations have  benefited from basing their in-service training on an ‘organisational learning model’ i.e. focussing on a more effective balance between organisational needs and individual needs.
At best this achieves virtual elimination of the transfer problem ('I learned a lot of good stuff but we could never apply it here!’) as it demands a clear ‘contract’ being made between any individual and his/her organisation (his ‘managers’or superiors)before any training takes place.
The contract includes agreement not only about what new skills and knowledge need to be learned but also about why they are needed,how they will be applied and what is expected to result from them within the school or office.
The reference here to ‘managers’ or ‘superiors’as representing the organisation is an interesting one because professional development in this context could be interpreted as merely serving the interest of the dominant hegemony.
The model is essentially a conservative one, permitting little radical change of the organisation as a whole (including managers).
The issue, concerning personal versus institutional development, set out in these two very different statements of Taylor and Jones is a fundamental one.
Positions taken in relation to it will usually reflect markedly different perspectives regarding the position of people in organisations.
On the one hand it will be argued that organisations possess characteristics and pose problems that go beyond those of their individual members; on the other hand, some people will take the view that only people, not systems, are capable of change.
In essence this is the same issue as that outlined earlier concerning the creativity of the school.
Of course few people possess sufficient evidence to argue strongly for the extreme poles of the personal/institutional development issue, and it is unlikely that even Stenhouse or Hoyle would have denied that there is a middle ground which acknowledges the interaction of the system and the individual.
Certainly Bolam stresses the dynamic relationship between the two in the process of change.
Whatever the relative merits of encouraging teacher development or the development of the whole school, the ultimate goal  remains the same: the improvement of opportunities for learning among pupils.
In this respect dissatisfied teachers, and schools lacking a sense of common purpose, are unlikely to be able to provide educational experiences of an appropriate quality.
The task of management, therefore, is to provide the kind of structures for career development, in-service education, and curriculum development and review that are likely to enhance the quality of educational provision.
And it is likely these will incorporate a blend of individual and institutional concerns.
Professional Development and Evaluation.
In much the way that curriculum development and in-service education relinquished their dependence on centralised projects and courses and came to be focused on the particular contexts of schools, so also the preoccupation of project evaluation with theoretical models and procedures gave way to a practical need to solve concrete problems of educational practice in schools.
(It is this shift which, as we noted in the Introduction, supplies the chief rationale for this book.)
It is interesting therefore that many leading advocates of school-based evaluation have themselves been involved with large-scale project evaluations at some point in their careers (e g.
Elliott, MacDonald, Shipman and Simons).
Some of these now strongly argue that evaluation which is initiated and conducted by teachers in response to their own perceived needs and interests has a greater capacity to promote professional development, because the role of teachers is extended but their autonomy is preserved.
It becomes the teachers' responsibility to identify and investigate problems connected with their own and their school's practice; to evaluate existing provision in relation to context and to propose, implement and evaluate remedies that are within their resources.
This view of the potential of evaluation to contribute to change in practice implies support for normative-re-educative strategies of change.
As stated earlier these strategies are defined as ‘activating forces within the system to alter the system’, and they involve either improving the problem-solving capabilities of the system, or releasing and fostering growth in the persons who make up the system to be changed.
The promise is that evaluation, particularly self-evaluation, can accomplish these tasks.
According to a number of writers, the crucial condition, governing the effectiveness of evaluation in promoting development, is that  control of the process should rest entirely with those whose practice is to be evaluated.
Simons (1981), for instance, argues that evaluation which is forced on schools by outsiders (a power-coercive strategy) is likely to be half-hearted, distort reality, engender defensiveness and hostility in teachers, and is unlikely to be sustained.
For these reasons it is also unlikely to bring about genuine professional development and change.
(The concept of self -evaluation will be developed further in Chapter 5.)
Simons's argument appeals to common sense but we need to bear in mind an alternative point of view.
Compulsion cannot be dismissed as incapable of bringing about change, after all we compel children to attend school between the ages of five and sixteen and it would be foolish to suggest that no genuine change takes place as a result.
It is surely true that occasionally interest is awakened only after individuals have been coerced into doing something.
Indeed a number of recent centralised initiatives, such as TVEI, seem to be based on this premise, although, as Harland (1985) points out, compliance cannot simply be bought with the allocation of resources.
Teachers, schools and LEAs are quite adept at subverting or transforming the aims of central government.
Nevertheless, in a liberal democracy, normative-re-educative or empirical-rational strategies for change are generally more acceptable than those that are power-coercive.
In summary then, evaluation in the context of professional development and educational improvement refers to the monitoring of practice in order to diagnose problems and develop, implement and evaluate remedies, or to assure oneself that all is well.
It is assumed that the evaluation of particular practices in particular contexts is more relevant to the educational and professional needs of teachers and schools and therefore more likely to result in improvement.
Some strategies for evaluation are built on practical theories concerning the way individual professional development takes place; others relate more closely to a concept of institutional development.
In Part Two we shall examine these in more detail and consider some of the mundane influences which have a bearing on their execution.
3
Curriculum Review
Introduction
Traditionally all schools are involved in routine reviewing of the curriculum, but this may not involve either questioning basic assumptions or considering the whole curriculum of the school.
The timetabling operation, a routine review of the curriculum in secondary schools, does not usually question the weighting and nature of subjects offered, or the pupil grouping.
New courses may be introduced by subject departments and merely ‘fitted into’ the timetable.
Discussions on core and option schemes covering the final two years of compulsory schooling do of course question some curricular assumptions and consider the curriculum as a whole.
Nevertheless the HMI secondary survey expressed some disquiet at the complexity of option schemes and the resulting individual curricula so generated, in addition to their general concern about the extent of the ‘core’(too many pupils were discontinuing study of important subjects well before the end of their schooling).
In a case study of a school's discussions of an option scheme Hurman noted that they were really about the status of various subject departments, and that discussions on the core curriculum ignored what lay beneath the subject label.
For pupils of below average ability it is not so unusual to find discussions of the whole curriculum taking place, perhaps because of their perceived ‘low’ status or because there are no public examination constraints.
Primary schools, while considering the whole curriculum for a single class, assume that ‘the primary school curriculum that a particular child encounters [is]…the sum of his experiences in a number of classes’.
Various commentators, therefore, have expressed concern about the lack of attention to the whole curriculum across the primary school; and the Inspectorate in its primary survey was unhappy with the extent of discussion that took place between schools to establish curriculum continuity.
It would therefore not be too unfair to conclude that many teachers, whether in primary  or secondary schools, are, by tradition, unfamiliar with discussions that involve the whole curriculum of a school.
Naturally there are exceptions, and the opening of new schools and the reorganisation under comprehensivisation schemes or falling rolls, provide the ideal opportunity for whole curriculum discussions.
Although there is never a clean slate on which to start planning, the new start provides the necessity for such planning.
However the examples of planning exercises that come to light are usually the ‘exotic’ ones that so often feature in Open University case studies: Stantonbury Campus; Countesthorpe College; North Westminster Community School!
The general lack of attention to whole curriculum issues has resulted in what Becher and Maclure call fragmentation.
This occurs at the transition between sectors, at the barriers put up by subject boundaries in secondary schools, and at the ability barriers erected by streaming and banding.
Becher and Maclure also lament the reinforcing of subject fragmentation encouraged by the Schools Council, which paid little attention to the whole curriculum; their few attempts giving ‘predictably marshmallow results’.
The House of Commons Committee on Education, Science and Arts (Education, Science and Arts Committee, 1981) was also concerned about the way subject traditions defend their own patch, with the result that pupils receive an offering of a series of unrelated specialisms, and it was anxious to encourage a more holistic consideration of the curriculum.
The concentration on parts rather than the whole, Becher and Maclure claimed, is the result of decentralisation of curriculum responsibility.
They felt that clear national guide-lines would perhaps help.
Certainly the Department of Education and Science and HM Inspectorate think so; indeed, the latter has argued for a common curriculum at secondary level up to sixteen because of the variety of curriculum offerings, the lack of whole curriculum planning, and the need for national decisions in a political democracy to balance the autonomy of the school.
But it would be wrong, at least at the secondary level, to see the fragmentation as somehow the fault of narrow, self-interested teachers.
Not only do they operate under a variety of influences which limit their room for manoeuvre, but public examinations, based on subjects, are a major constraint, recently reinforced by the subject-based GCSE examinations.
In the USA, legislation at both the State and Federal level often similarly defines the parameters within which schools can consider the curriculum.
There has, however, been a change of climate in recent years which has been a result of the pressures for accountability spelt out in Chapter 1.
Teachers appear to be more willing to support the development of a  common core curriculum (Venning, 1979; Wicksteed & Hill, 1979): a change that is mirrored by opinions in the ‘Week by Week’ column of Education (2 Nov. 1979: 11 Jan. 1980) which tries to reflect the current climate.
The Great Debate, which we consider in more detail shortly, was largely responsible for this particular change.
However this debate, and the ensuing documents, have given rise to a legal-formal or contractual accountability model rather than a partnership model for education, according to Lawton.
There is also an increasing concern for the curriculum among teachers in other countries, although they often operate in more centralised education systems and have not been ‘involved’ in the kind of debate that has taken place in England and Wales.
The advent of a national curriculum in this country may change this situation.
This chapter, then, will consider the debate which has led to the change in climate, and the nature of the demands being made on schools and their teachers to review the curriculum.
In particular it will consider the kind of guidance offered to schools on how to review what they are teaching, and also the issues raised by such an exercise.
The Great Debate and its Aftermath
Chapter 1 has already mentioned the impetus given to the debate by Jim Callaghan's Ruskin speech, and discussed some of the factors which led to accountability pressures.
In the context of the debate about the curriculum, economic decline and supposedly falling educational standards were important elements.
However, the evidence upon which basic standards were criticised was far from sound and the level of analysis about, for example, a core curriculum was low.
Nevertheless this speech, and the Yellow Book which formed its brief, helped to initiate the discussion on the common core curriculum.
Lawton (1980) traces the stages of the debate, in which the Ruskin speech was followed by a series of regional conferences with participants invited by the DES.
Two elements on the agenda of the conferences are of particular note:(1) Curriculum 5–16 — the aims and content of a core curriculum;(2) school and working life, i.e. education for awareness and understanding of the technological and industrial society.
These conferences were then followed by a Green Paper which contained a diagnosis of curricular problems in schools, namely, the lack of attention to basic skills and the lack of awareness in schools of the economic needs of the country.
The assumption of failure on basic skills training was subsequently shown to be incorrect when the two surveys by HM Inspectorate were published, but then, as Reid (1978) argues, the DES seemed more interested in proposing solutions than in defining problems.
The Green Paper also argued for a nationally agreed framework for the curriculum and also wanted the local authorities to coordinate the curriculum and its developments.
This latter requirement brought a circular to local authorities requesting information on the curriculum in their schools.
The information collected was subsequently published; three topics are of particular interest.
First, it appeared that there existed few formal and detailed policy statements, within LEAs, to guide schools in curriculum matters, and also that governors had little involvement with the curriculum.
Indeed, only a quarter of the LEAs required heads to submit reports to governors and these only occasionally included curriculum items.
Secondly, when the Department asked about the balance and breadth of the curriculum it found that few authorities encouraged schools to discuss the issues and it was mainly through routine visits of advisers that concern for balance and breadth was promoted.
The elements of the curriculum considered essential by LEAs were varied and some were reluctant to make any statement on this because they felt it the job of schools.
When they did produce statements about the curriculum, about a half used general categories of knowledge, experience and skills (not related to particular subjects), and just over a quarter listed school subjects.
The third topic of interest concerned what LEAs did to help schools promote preparation for working life.
Sixty per cent claimed that this was done through traditional subjects, although few related this to actual school practice.
This initial investigation and the subsequent discussion (which we will come to shortly) obviously had the desired effect because the follow-up urging the development of curriculum policies at local level showed movement on these issues.
DES Circular 8/83 requested information on these efforts and preliminary results reported in Better Schools showed almost a complete reversal of the situation found in the first survey.
Most LEAs reported that they had a curriculum policy or were developing one; they consulted widely including with governing bodies; they now recognised the importance of ‘breadth’ and ‘balance’, and the need for relevance of the school curriculum to the world outside.
On this latter point, however, they did not give details of how this was achieved in schools.
(At the time of writing the full report of the survey has yet to be published.)
These circulars, therefore, provided the DES with the evidence to substantiate its concern for the curriculum and the need to arrive at a national framework, presumably to correct the faults it saw.
At approximately the same time of the first circular data from HMI surveys, and HMI statements on the curriculum (which we shall consider later), were being added to this evidence.
However, before considering the statements on the curriculum eventually produced by the DES let us summarise some of the issues of the ‘debate’.
The centre piece was the desire to create a core curriculum for pupils in schools and to ensure that its content was both ‘balanced’ and had sufficient ‘breadth’(concepts we shall return to later).
Further, the DES was anxious to achieve national agreement on a framework for this curriculum.
In contrast to the earlier stages of the debate, the concern was to make the common curriculum more than the ‘basics’(something not altogether borne out in their subsequent pronouncements).
Another issue, providing a constant theme, was the role of the school in promoting wealth creation.
Although born out of a concern for the economic decline of Britain, such an emphasis provides a sad irony in the 1980s with massive youth unemployment.
Thus the role of the school in promoting economic change was stated, but little debated, and reference was never made to studies which showed the difficulties of such a role.
True to Reid's claim that the debate jumped to solutions, we now find that a major response to economic decline and youth unemployment has been the Youth Training Scheme organised through the Manpower Services Commission of the Department of Employment, in which the school sector plays little part.
Whatever criticisms one may want to make of the quality of the evidence and analysis of the debate, it is hard to deny its effectiveness in changing the climate with regard to the control of the curriculum.
The DES has made the idea of a national framework more widely acceptable, and, as we shall show, is moving towards some kind of national prescription.
It has also encouraged LEAs to exercise their responsibilities for the curriculum and encouraged those outside schools, such as governors and people in industry, to play a more important part in discussions about the curriculum.
Finally, schools have been expected to initiate discussions and reviews of the curriculum a change from the more usual state of affairs with regard to whole curriculum issues (a point we made earlier).
National Frameworks for the Curriculum
We now turn to statements on the curriculum that came out of the debate.
These statements suggested that schools and LEAs should engage in an analysis of the curriculum and they offered possible kinds of analyses, as well as prescriptions for the curriculum itself.
What they proposed, and the reactions to these proposals, are of interest to schools faced with the task of curriculum review.
The first attempt was put forward for consultation:A Framework for the School Curriculum .
It posed questions about the core curriculum, gave an outline of such a core and stressed the need for schools to have written educational aims.
The questions on the core curriculum concerned its nature, i.e. whether it should be a narrow core or cover most of a pupil's curriculum, and the way it should be expressed, i.e. in terms of school subjects or educational objectives.
The core curriculum outlined by the document did in fact use school subjects: English, mathematics, science, religious and physical education, with modern languages being studied by most secondary school pupils.
Other subjects were grouped under the general heading of ‘preparation for adult life’ and included: craft, design and technology; arts, including music and drama; history and geography; moral education; health education and preparation for parenthood and family life; careers education and vocational guidance.
In addition to specifying what the core should contain, the framework laid down the percentage of the timetable to be allocated to some subjects, for example, English and mathematics were each to be allocated ten per cent .
The document argued that a school would be more effective in achieving its aims if they were written down and it suggested six possible aims expressed at a high level of generality, for example: to develop lively enquiring minds…; to acquire the knowledge and skills relevant to adult life and employment in a fast-changing world.
With such general aims it is not surprising that some of the reactions were as scathing as those of Max Morris, a former President of the NUT: ‘As a pot-pourri of platitudes, a compendium of trite banalities…[the Framework ]would be hard to  emulate.
Although many of the reactions were hostile, there was some welcome for the idea of a framework and for the consultation process.
Even Max Morris, despite his comments on the contents of the document, warned against belittling the importance of the debate on the curriculum.
Besides general criticisms about the framework, some specifically focused on the undue emphasis on subjects, the neglect of a consideration of teaching methods, the specification of percentage  time allocations, and the dominance of national needs as a criterion for selecting or determining the curriculum.
One interesting reaction was that in stating, for example, that science should be taught to all pupils in some form or other in the last two years of schooling for 10–20 per cent of the time (in addition to a broad course up to age 13 years), the DES was implicitly committing itself to increased resources, in terms of teachers and facilities.
It may have been such a realisation (along with the generally hostile reaction to the Framework document) that encouraged the DES to be less specific in its second attempt at producing a framework for the curriculum (almost a year after its first attempt).
As before, this new document,The School Curriculum , emphasised preparation for adult life and the economic needs of the country, and repeated the list of aims claiming that they had been widely accepted during consultations.
These aims were to be used as a checklist to test curriculum policies.
Again LEAs were requested to draw up curriculum policies and schools were expected to set out their aims in writing.
Schools were also expected to recognise that the curriculum could be described and analysed in a variety of ways.
Two requirements guided the DES specification: the need for what is taught and how it is taught to reflect the values of society; the need for a broad curriculum (in terms of subjects).
The document then outlined what the Secretaries of State for Education thought should be the curriculum in primary and secondary schools.
The primary school curriculum was to go beyond the basics of English and mathematics, which in any case should be seen in the wider context of other subjects.
Key elements identified included: multicultural aspects of Britain today; an understanding of the world; experience of elementary science work; music; and the personal and social development of pupils.
In addition to these key elements specific mention was made of topic work, science, art and craft and French.
The secondary school curriculum was described in much the same terms as in the previous framework, but time allocations were not specified.
The School Curriculum was distributed to every school in England and Wales, and perhaps for this reason there was a wider span of reactions, some of which seemed more positive.
For example, of five headteachers invited to give reactions in the Times Educational Supplement (10 April 1981), two were very positive, one somewhat neutral, and two hostile.
As before many recognised the importance of the document in initiating debate on the curriculum.
The problems identified by commentators, included those raised in connection with the previous document: the dominance of subjects, the neglect of teaching  methods, and the implied need for increased resources.
To these were added worries about the lack of justification of the proposals, and the fact that the examination system was totally ignored.
A major critique of the document expressed concern about the nature of the analysis, not just in terms of the way the curriculum was described, but in terms of the view of culture that was used to select items for inclusion in the curriculum.
It is the lack of quality of the analysis that provided the thrust of a  swinging attack by a committee of the House of Commons (Education, Science and Arts Committee, 1981), in relation to the limitation of subjects.
Unlike the DES, this Committee took account of some of the literature in the field, including the work of HM Inspectorate, and some academics.
They commended also the parallel work carried out in Scotland by a committee under the chairmanship of Munn, a Rector of a Glasgow high school.
This (Munn) Report was thought by the Committee of the House of Commons to be altogether more sophisticated an analysis, with its recognition of the debatable nature of the fundamental principles underlying a specification of the school curriculum.
Because of the perceived importance of the Munn approach and because it represents a parallel exercise at defining a national framework, we turn to a more detailed examination of it next.
The Munn Report examined the structure of the curriculum in the last two years of compulsory schooling in Scotland, and carried out its work almost at the same time as the Dunning Committee considered the aims, purposes and forms of assessment for the whole ability range.
In fact the Dunning Committee reported first.
Inevitably this committee had to consider the effect of public examinations upon the school curriculum.
This it did in terms of the effect on the whole curriculum, and on individual subjects.
It saw a role for internal assessment (internal to the school) in helping to release the school curriculum from total control by examination syllabuses originating outside of the school.
The Munn Report, therefore, started with an analysis of the present situation, which considered such issues as certificate versus non-certificate courses, the problem of lower ability children being pushed into ‘O’ grade examinations which they were not intended to cater for, the need to prepare pupils for life in a modern industrial society, and the importance of analysing the content, teaching methods, learning milieu, and informal aspects of the curriculum.
It next considered the problem of designing the curriculum, and in particular the competing claims on the curriculum from society, from epistemology (i.e. theories on the  nature of knowledge), and from the psychology of pupils.
These competing claims usually emerged as community-centred, subject-centred and child-centred curricula, but the report argued that these could be reconciled.
It did this by proposing four aims concerning knowledge, skills, affective development and the demands of society.
These aims, it argued, should be used as criteria for determining the scope of the formal curriculum, which could further be expressed in terms of eight modes of activity: linguistic and library study; mathematical studies; scientific study; social studies; creative and aesthetic studies; physical activity; religious studies; morality.
However, these are theoretical constructs which must be translated into an actual curriculum; inevitably this leads to a consideration of curriculum organisation, particularly subject-based versus ‘integrated’ or ‘interdisciplinary’approaches.
The report rejected integrated studies, although it nowhere defined what they are, and the curriculum it arrived at was again reduced to subjects.
It proposed four compulsory subjects: English, mathematics, physical education, and religious and moral education.
In the remaining three compulsory areas, i.e. science, social studies and creative arts, it proposed that pupils should study at least one subject which falls under these headings.
Thus, for example, biology or food science could represent science, and geography or history could represent social studies.
However, the Munn Committee realised that in the area of social studies, in addition to subjects such as history or geography, pupils would have to study units on political, economic, industrial and environmental aspects of life in modern society.
Also for creative arts, a weekly period of music and art would be insufficient; rather, a rotational arrangement should be employed which allowed pupils to spend more time on music, say, for part of two years, with the opportunity for work in art and perhaps drama at other times'.
For each of the areas a recommended number of periods was given.
When considering assessment the Munn Report recommended that all subjects should be examined, with three levels of syllabuses to accommodate different ability groups.
However, they stopped short of recommending a group certificate for the core areas, because this would effectively force their view of the curriculum on local authorities and schools.
The analysis represented by the Munn Report was indeed more sophisticated than that of the DES document; the fact that the former was drawn up by professionals rather than civil servants may have something to do with this.
However, a number of criticisms can still be made.
Most notable is the observation that the reliance on subjects to express the actual curriculum can be seen as a rationalisation of its present form.
Certainly the resulting curriculum looks rather dull compared with the initial considerations which offered the possibility of a refreshing new view.
But even the more sophisticated thinking concerning the competing claims of the curriculum, and the eight modes of activity, have been criticised.
How, the critique goes, can fervently-held views of the curriculum as represented by community-, subject- and child-based approaches be reconciled in a paragraph?
It could well be argued that the committee under-played the ideological differences that exist between such approaches to the curriculum (an issue we shall return to later).
Finally, although the committee went to great lengths to argue the case for and against integration, have they not indeed simply rationalised the status quo ?
A major part of the argument against integration was based on the reaction of teachers rather than any theoretical problems.
Yet, in the context of the core curriculum, a number of well known ‘practitioners’ have argued for the necessity of a fundamental examination of the organisation of the curriculum, suggesting that the only way to achieve a sensible broad core is to integrate subjects.
HM Inspectorate's Reports
The DES documents on the curriculum can be contrasted unfavourably with the HMI equivalents.
The former take little account of the latter although much of the HMI's thinking has become known over the same period i.e. the late 1970s and early 1980s.
As we noted earlier the surveys of both secondary and primary schools provided information on what was happening in schools, although they were restricted (in the case of the secondary survey particularly) to a subject-based analysis of the curriculum.
In the secondary survey the Inspectorate expressed concern for the balance, breadth, complexity (of options) and coherence of the curriculum.
The primary school survey expressed concern for the range of work, i.e. too much emphasis on the basics, and the lack of continuity (a point we have noted already).
These surveys, although not published before the first major statement on the curriculum, must have influenced HMI thinking.
The first document,Curriculum 11–16 , was generally thought to be useful.
In contrast to the later subject-based discussions of the  DES, this document proposed that the curriculum should be composed of eight areas of experience: aesthetic and creative; ethical; linguistic; mathematical; scientific; physical; social and political; spiritual.
No justification was offered for these areas; neither are they identical to the six lines of development adopted by the Assessment of Performance Unit, which also involved HMIs.
Of particular interest are those parts of Curriculum 11–16 that include discussions of ‘school and society’ and ‘schools and preparation for work’.
The former includes a recognition of the conflict in schools between socialisation and the fostering of the autonomy of the individual, as well as the political and social assumptions and values implied in the curriculum.
In particular the HMI discuss the role of schools in a changing society, arguing, for example, that schools have a limited role in social change, and rejecting the ‘curriculum for violent change’.
Their discussion of preparation for work recognises that in the economic conditions of the early 1980s (which were evident in 1977), there is a need to prepare for unemployment.
Later, these ideas on the curriculum moved beyond a public statement of the views of some of the Inspectorate and became the basis of a curriculum appraisal scheme in conjunction with five LEAs.
In reviewing their curricula schools in these LEAs considered three areas: the education of the individual (in terms of subjects and the eight areas of experience); preparation for the world of work; education and society.
In this context there seems to have been some unexplained change of thinking on the part of the Inspectorate because the eight areas of experience (in Curriculum 11–16 ) were seen as a way of considering a common curriculum, presumably satisfying all aspects of the curriculum including ‘education and society’ and ‘working life’.
In the report of the exercise with the LEAs, however, their scope is limited to ‘education and the individual’.
We will look at the details of the exercise in Chapter 8; for the moment it is worth noting that the review centred around an analysis of school subjects in terms of skills, concepts, and attitudes (expressed in terms of aims and objectives), and an analysis of the contribution of subjects to the eight areas of experience.
It is also worth noting that Lawton claims that the HMIs may be pushing a model of curriculum planning (based upon statements of aims and objectives) which is out of date an issue we return to later in the chapter, and in Chapter 8.
This model found full expression in the final document of the exercise, where a specification for an ‘entitlement curriculum’ was given.
It was done in terms of what the specification should include, and a discussion of possible contents.
Four elements of the specification  are of particular importance here: a statement of aims relating to the education of individual pupils, and to the preparation for life after school; a statement of objectives in terms of skills, attitudes, concepts and knowledge; a balanced allocation of time for the eight areas of experience; and methods of teaching and learning which will achieve the objectives.
It went on to give possible aims and objectives for the curriculum, but in the spirit of showing the process of curriculum appraisal that HMI, and the participating LEAs, hope will be attempted by schools.
Coinciding with the time of discussion on the national framework for the curriculum initiated by the DES, the Inspectorate issued a document giving their ‘view of the curriculum’.
This was a more pragmatic statement than Curriculum 11–16 .
Although it recognised that the eight areas of experience were important, the secondary school curriculum was discussed largely in terms of subjects because that is how secondary education is organised.
The areas of experience seemed to be reserved for describing areas such as arts and applied crafts (aesthetic and creative experience), and history, geography, economics, social and environmental studies (social and political education).
Despite the work of the surveys no reference was made to the importance of teaching method.
The latest statement (at the time of writing) from HMI is the culmination of their surveys and the Curriculum  11–16  series.
It employs what are described as ‘two essential and complementary perspectives’ as an overall framework; namely, the areas of learning and experience, and elements of learning.
The areas of learning and experience are those identified earlier, except that they added one more: technological.
They admit that these represent only one, and not original, point of view.
The elements of learning are the skills, attitudes, concepts and knowledge outlined in the last Curriculum 11–16 document.
Only in the case of skills do they actually list what they think are the appropriate elements of learning.
What they are offering through this framework are checklists to aid the development of a curriculum.
In addition they elaborate several desirable characteristics of the curriculum; breadth, balance, relevance, differentiation, progression, and continuity.
Schools Council Statements
At about the same time as The School Curriculum was being prepared by the DES, the now defunct Schools Council was preparing its own document.
Interestingly, despite DES and HMI representation on the Council, no connection existed between the two publications.
The Practical Curriculum (Schools Council, 1981) was not in fact the Schools Council's version of a national framework for the curriculum, rather it was ‘an incitement to critical self-evaluation’ by schools.
It provided no prescriptions for the substantive curriculum, except at the level of general aims, and these only by way of suggestion.
The first major chapter of the document contains a discussion of various types of rationale that teachers could use for thinking about the curriculum.
These include statements of general and specific aims, learning experiences, various forms of knowledge and areas of experience (e.g. the cognitive-based analysis of Hirst and Peters and the HMI areas discussed earlier), skills, and modes of expression (verbal and non-verbal).
In addition values and attitudes are considered since they are apparent in both the formal and hidden curriculum.
Each theme is offered as a suggestion about how schools could start planning the curriculum.
The other chapters consider the mechanics of this planning (e.g. staff specifically responsible for it), as well as ways of monitoring and assessing the resulting curriculum.
In essence, as noted above, it presents guidelines for self-evaluation, and curriculum planning.
Central Directives
All of the documents considered so far have been intended as items for discussion or guidance to schools and local authorities.
Even The School Curriculum , although issued to all schools, had no force of law.
However, the DES, despite its history of neglect of the curriculum, started to move cautiously into this domain.
The information collected from Circular 14/77 encouraged the DES to take further steps.
Thus the 1980 Education Act made it a requirement for all schools to provide public information on the curriculum.
As noted earlier this was extended by Circular 6/81 which urged LEAs to comply with the recommendations in The School Curriculum .
These efforts by the government were given more force through the White Paper Better Schools , which outlined the aims that had been emerging through the previous documents.
It  picked up the principles (as it called them) enunciated by HMI, that is, breadth, balance, relevance, and differentiation.
Although acknowledging that it was possible to analyse the curriculum in a variety of ways, the White Paper suggested that this was best done through subjects, particularly at secondary level.
In fact even their proposals for the primary curriculum were largely described in terms of subjects (e.g. maths, language, science, history, geography, religious education, craft).
Better Schools signalled the government's intention to offer a further statement on the organisation and content of the 5–16 curriculum.
As we go to press the DES are in the process of drawing up details on various subjects; to date these include English, mathematics, and possibly technology.
To follow up the concern in the White Paper for the definition of levels of attainment, the government intend to introduce some kind of benchmark assessment, a point we made earlier, in an effort to improve standards.
In the USA a state defined curriculum, often enshrined in legislation, requires school district authorities to improve and develop the curriculum through a framework.
One such framework, suggested by the California State Education Department (1977), is expected to contain the goals of instruction, an outline of the concepts and processes to be taught, the content objectives, the appropriate teaching strategies and learning activities, and the tests, student self-assessment and teacher evaluation required.
There is obviously little room for the school to be directly involved in curriculum development at any level.
This might well come to be true in secondary schools in England and Wales through the formulation of a national curriculum and the defining of national criteria for GCSE and the so-called benchmarks.
Issues
Having looked at some of the major developments in encouraging teachers, and others, to review the curriculum, we want now to consider the issues raised by such a review.
In particular we shall discuss the nature of the evaluative activity being required, the type of analysis expected, the value issues involved in a review, the process of review suggested, and who is expected to carry it out.
First, the nature of the evaluation.
It is clear that the focus is on what ought to be taught: the intended curriculum .
This being so, the principal concern must be for the worth and value of the planned activities: something that requires an intrinsic evaluation .
This type of  evaluation can be contrasted with empirical evaluations, which most of the later chapters of this book consider, and which require a consideration of the curriculum as experienced by the pupils.
Such a distinction is not accepted by all commentators, as we shall show, but where evaluating the intended curriculum is accepted, there are clearly a variety of ways of analysing it.
We have already noted the criticisms about the use of subjects as an analytic tool, the neglect of teaching methods, and the lack of awareness of other forms of analysis on the part of, for example , the DES.
Indeed the poverty of the DES analysis in The School Curriculum led the Committee of the House of Commons (Education, Science and Arts Committee, 1981) to advise headteachers to rely upon common sense rather than the analysis presented by the DES!
Many would readily accept the limitations of subjects as a basis for analysing the curriculum because, for example, they tend to emphasise cognition while ignoring affective aspects of education.
On the other hand, the HMI's nine areas of experience, although offering an interesting alternative, appear to have a certain arbitrariness about them, especially when one (technological) is added with no explanation as to why.
Halpin (1980), for example, questions their similarity with the APU lines of development which, because they were tentatively suggested, were specifically not intended as a curriculum model.
If there is no particular justification for these categories, and they appear to be somewhat arbitrary, what faith can schools then have in them as a basis for review?
The Munn Report proposed a list similar to that of the HMI, and Darling (1978) criticised it for being similar to those proposed by Hirst and therefore following his view that education is basically about the development of the mind.
Such an approach would minimise affective elements of the curriculum; something the Munn Committee was anxious to avoid.
In a rejoinder to Darling's criticisms, Kirk (1978), a member of the committee, points out the specific references in the report to the weakness of Hirst's approach, and the addition of appeals to the social usefulness of educational activities (something foreign to Hirst who was concerned primarily with intrinsic worth) as evidence of an attempt to look beyond a cognitive based curriculum.
A lot of course depends upon how these various ‘areas’ and ‘modes’are translated into learning activities.
Clarke (1979), having noted that the areas of experience are a good starting point but too generalised, suggests that they be elaborated by specifying for each, the basic skills, specific experiences and factual knowledge involved.
He then goes on to  outline some examples for the primary school curriculum.
Skilbeck, in commenting upon the progress of the national frameworks, suggests that in addition to setting out areas of knowledge, understanding and human activity firmly and clearly, the various kinds of learning experiences and learning situations also need defining.
In making this request he is echoing the kind of analysis employed by the Curriculum Development Centre in Australia, where he was Director.
This approach, whilst employing a similar list of areas of experience to that employed in Curriculum 11–16 and the Munn Report, avoids the criticism of ignoring teaching methods.
Chanan has questioned the basic analysis of national needs employed by the DES, as we have already mentioned; he goes on to propose a curriculum based on personal values.
A person's ability to relate to wider issues means mastering relationships in the immediate community — initially the home, because family life is where personal and public life meet face to face.
Chanan's argument is that with more than twice as many people who are non-working as are involved in manufacturing, their role in reinvigorating the community can, and should, be developed.
Although this argument is not developed into specific proposals for the curriculum, if it were it would lead to a very different form from that of the DES.
It is worth noting that in the USA there is a long tradition of national commissions on the curriculum, as well as a considerable academic literature that has influenced British thinking.
Van Til (1976), in reviewing reports up to the 1970s, concludes that the seven Cardinal Principles of Secondary Education, proposed by the Commission on the Reorganisation of Secondary Education in 1918, still apply.
These principles dealt with health, a command of fundamental processes (e.g. writing), worthy home membership, vocation, civic education, worthy use of leisure, ethical character.
He then traces four traditions on sources of curriculum content, which are similar to the three conflicting claims recognised by the Munn Report, namely: the needs of learners; demands of society and social realities; clarification of values for democratic life; structure of disciplines.
These four traditions have varied in eminence over time and Van Til argues that the claims on the curriculum are no longer based on a single source — a conclusion in line with the Munn Report.
From the interaction of the sources of the curriculum he identifies sixteen ‘centres of experience’, but he provides no rationale or justification for them.
Despite Van Til's apparent confidence in arriving at a model for the curriculum, Cowen (1981) says that currently the USA has no inclusion or exclusion principles for selecting curriculum  content because: there is a lack of curriculum theory; the ‘demands of society’ as a principle has weakened; and the subject disciplines have also passed their time as a selection principle.
For a school seeking guidance the picture is a confusing one; a wide variety of analyses of the curriculum are available but with conflicting claims as to their usefulness.
What is clear is that the DES, and perhaps even the Inspectorate, portray the task of curriculum review in rather too simplistic a fashion.
Chapter 8 cannot claim to clear up the confusing array of approaches but it will offer some guidance, though with the definition of a national curriculum the role for the school in this is unclear.
The next issue is closely related to the value issues involved in curriculum review.
The School Curriculum took the simplistic view, saying that the values of society should be reflected in the curriculum.
As mentioned earlier, the HMIs took an altogether more sophisticated view of the relationship of education to society and to social change, and like the Education, Science and Arts Committee (1981) saw a conflict between transmitting the values of society and preparing young people to change those values.
Of course, transmitting values through the curriculum assumes a degree of consensus, the existence of which is questionable in a pluralist society.
Such a problem is related to the different value positions represented by the three competing claims identified in the Munn Report, i.e. community-based, subject-based and child-based.
It is not that the advocates of these approaches to the curriculum take different views of the nature of society, but that they fundamentally differ regarding the purposes of education.
Skilbeck employs the idea of ideology (a system of beliefs and values of a social group) to describe powerful traditions which create educational theories.
The three educational ideologies he considers, i.e. reconstructionism, classical humanism and progressivism, roughly correspond to the community-centred, subject-centred and child-centred curriculum respectively, although the community-centred curriculum can also be a form of instrumentalism.
The Munn Report claimed that these positions could be reconciled, but Skilbeck says of the three educational ideologies: ‘each is a powerful force in contemporary educational thought and practice…each can be seen as a comprehensive and well-articulated position’.
Given such a statement, perhaps Darling (1978) was correct in questioning the confidence with which the Munn Report claimed that the conflicts between the traditions  could be resolved.
But at least the Munn Committee recognised the problem; something the DES and HMI largely ignored.
What evidence exists, both in Britain and Australia, about the diversity of teachers' values (e.g. Ashton et al , 1975, and Kallenberger, 1981) also makes it uncertain whether the conflicts will be easily resolved.
What is important is the recognition that curricular decision-making is a process of assigning value and particularly of resolving value conflicts — a practical rather than theoretical activity.
If curricular decision-making can be described in this way, then we need to consider whether the processes of review advocated are suitable for such a fundamental task.
The approaches advocated by the DES, HMI and the Scottish Education Department follow a procedure very common in the USA, i.e. starting with a statement of aims and setting out areas, or whatever, that will satisfy these aims.
Walker (1975) showed that when he monitored real curriculum decision-making, albeit in the context of a curriculum project, he found that statements of aims did not dominate.
Again there is a considerable literature on the use of aims and objectives in curriculum planning that casts doubts on its efficacy.
Chapter 1 has already made reference to the dominance of this approach in the USA, and Chapter 8 will consider some of the arguments for and against it.
One of the major arguments against the approach is that it attempts to deal with curriculum problems involving value issues in a procedural way, i.e. by applying a suitable formula or technique.
Drawing on Reid's thinking, Halpin (1980) poses four questions to be asked about the approach to curriculum review advocated by the HMI in Curriculum 11–16 .
Although agreeing that this approach raises value issues (his first question), he thinks it of limited use in generating a range of curriculum alternatives (second question), that it ignores the effects of choosing particular courses of action (third question), and does not facilitate an examination of teacher's common sense beliefs and opinions (fourth question).
Reid (1978) argues that for curriculum problems the process of deliberation is required: a process described empirically by Walker (1975), and which we shall examine further in Chapter 8.
This brings us to our final issue: who should carry out curriculum review?
The assumption usually made is that it should be the teachers in schools who review the curriculum.
With important value issues at stake it is difficult to deny the involvement of others.
Governors of schools are the most frequently mentioned group and Circular 6/81 asked them to encourage schools to carry out a review.
Better Schools indicated the duty the governors would have in  determining the curricular aims and objectives, and subsequent Education Acts have put this into legislation.
Before asking whether others should be involved, however, it is worth asking if teachers are presently involved in curriculum planning.
Keast (1980) states that curriculum planning should be seen as a right by primary school teachers, not just an activity for headteachers.
In contrast, the Munn Report assumed that headteachers would take the broad decisions after consultation.
Thus subject departments and individual teachers are to be involved in forming curriculum policies rather than having rights over such policies.
The international evidence of teacher involvement in curriculum planning indicates little possibility for ordinary teachers.
In Britain, where there has been a tradition of less direct central control, the climate created by the headteachers is likely to be the most important factor in determining teacher involvement.
Even if teachers are involved do they have the requisite skills?
Bridges (1979) certainly doesn't think so because he sees the curriculum as a selection from culture requiring value judgements over which teachers have no monopoly of wisdom.
Mills (1980) argues that both initial and in-service teacher education fails to prepare them for the task.
Skilbeck (1981), in the Australian context, also wonders whether teachers are yet ready for the task, and states that the importance of in-service education and training has not yet been recognised.
Regarding the involvement of others, besides teachers, we are unlikely to have a Swedish style debate in Parliament, despite the fact that the community has a right to it, and that curricular decision-making is a political act.
The Taylor Report recommended a strong role for the governing board in keeping the school's activities under review; a position backed by the Education, Science and Arts Committee (1981) of the House of Commons, and as indicated subsequently incorporated into legislation.
In Britain no systematic evidence exists of the role of governing bodies in reviewing the curriculum.
In Victoria State, in Australia, Schools Councils (a form of governing body) do participate in review activities, and in Chapter 6 we shall see an example of this involvement.
The involvement of others in planning assumes, of course, that the curriculum that is laid down is compulsory, or mostly compulsory.
It is perfectly possible, as Griffen explains, to allow pupil and parent choice, but there is no evidence that his is other than an isolated example.
Conclusion
The idea of curriculum review has been brought into the schools' arena, though whether it will take off as a regular and meaningful exercise seems doubtful.
Certainly the advice for carrying out a review, offered by official sources, is not altogether complete, and, as we have argued, it ignores work already done.
Even more noticeably lacking is the support for such exercises; a point that became clear in the HMI-LEA curriculum appraisal activity, where advisers, for example, were unable to provide the support required.
It remains to be seen whether contracts or staffing plans will take account of the work being required by central directives.
Whatever the problems for a school carrying out a review, there remains an ambiguity about where the locus of curricular control lies.
Even if the DES does not grasp control, will schools be free to determine the curriculum?
LEAs were encouraged to take a larger part in determining policies and ensuring schools follow them, but recent changes mentioned in Chapter 1 casts doubt on their future role.
The predominant constraint is, of course, public examinations.
Although most directly affecting secondary schools, this constraint has a backwash effect on primary schools.
If, as Marland (1981) suggests, schools should develop new integrated subjects they will be faced with the task of getting them approved by the Secondary Examinations Council under the National Criteria for the various conventional subjects.
For schools, there is also the additional constraint of curriculum-led staffing.
While it may help protect the existing curriculum against falling rolls it will also reduce the curricular decision-making capacity of the school.
The question that must be answered is: will the exercise of curriculum review be a hollow one, resulting in schools simply justifying what they currently do, or becoming frustrated by their inability to follow through the consequences of their thinking?
4
Evaluation by Outsiders
Introduction
This chapter will concern itself with two basic approaches to evaluation by outsiders: the measurement of the ‘products’ or ‘outcomes’of schooling, for example, through testing programmes; the independent observation of the processes of schooling by outsiders, for example by inspectors.
For the most part the school has little control over these types of evaluation so we will consider the approaches in outline, concentrating on the issues raised.
The most controversial of outside evaluations involving outcome measurements are testing programmes and public examination results.
Schools can, and do, of course use tests for their own internal purposes — usually for screening children to give remedial teaching.
Indeed Becher et al (1981) in their interviews with teachers in East Sussex found that teachers were likely to use such tests as an ‘occasional independent check on their judgement’ i.e. as an external evaluation of their own assessment of pupils.
Testing, as an evaluation procedure, is more likely to be conducted at a national or at a local education authority level.
At the national level the concern is with the education system as a whole rather than with individual schools.
However, local testing programmes can give information on individual schools.
In Britain public examination results have always been of internal interest to schools, although they have been used as only crude indicators in evaluating a school's performance.
With the passing of the 1980 Education Act in England and Wales these results have to be published.
It is this publication which gives them their force as a form of evaluation of schools, particularly as the intention of this part of the Act was to give parents information upon which to base their choice of school.
Publication of examination results, therefore, qualifies as an outside evaluation because not only is the examination process controlled by outsiders (except in the relatively infrequent Mode III  school based examinations), but outsiders i.e. parents, can also pass judgement on the results.
The use of an outsider to observe what happens in a school has a long history in Britain through the process of formal school inspection.
The idea of inspection started with national inspectors (Her Majesty's Inspectorate), but increasingly local inspectors are being used at local education authority (LEA) level.
As we shall see, inspectors can provide evaluation at all levels of the education system: school, local and national level.
We shall confine our discussion in this chapter to such ‘officials’ as HM Inspectorate, leaving the observation by ‘consultants’, more common in the USA, to Chapter 6 which considers combined strategies of evaluation.
Testing Programmes and Examination Results
According to House (1978) the importance of testing in the USA derives from two forms of educational accountability: at federal level, the requirement of system analysts for quantitative outcomes to measure the most effective educational programmes; at state level, the need for statements of objectives to judge teachers by testing students' performance on those objectives (a scientific managerial approach).
In its crudest form this approach is based on the idea that the outcomes that are tested (or assessed in the case of public examinations) are all important.
Alternatively, the outcomes are assumed to be indicative of the quality of the educational process.
It follows then that if the outcomes are poor, or lower than expected, the teacher is at fault, and should be held accountable.
(Chapter 1 has already mentioned the classic case of California State being held accountable for not ensuring a minimum achievement for an individual student.)
Despite the fact that this may seem too crude a way to proceed this rationale has governed the operation of some testing programmes in the USA, most notoriously, that of Michigan State.
Such programmes are, as Chapter 1 pointed out, based upon a notion of contractual accountability.
Even if you are not prepared to reject this form for professional accountability, as Sockett does, you might feel that simply holding the teacher responsible for the results contravenes natural justice.
Earlier in the same discussion Sockett (1980) argues that you can only hold the teacher accountable ‘for what is within his control’.
Thus the test results must be interpreted in the light of such things as the ability of the students in the school  and the resources available.
As with any accountability procedure it is insufficient just to indicate that a failure has occurred; information must be forthcoming on how to improve educational practice.
In this respect testing has a poor track record, and its lack of impact at national and school level forms the substance of the major criticisms of it as an evaluation procedure.
However, it is fair to say that at local education authority level there is more evidence of its impact on change.
(We shall examine this evidence later.)
The examples of approaches to the measurement of products that we will outline are:
1.
national testing programmes (mentioned already in Chapter l);
2.
local testing programmes — such as those that a state in the USA, or an LEA in the UK, would employ;
3.
the publication of examination results in the UK.
As intimated earlier it is only our intention to outline these here; there are many easily available descriptions and analyses in the literature (to which we refer).
National testing programmes
The National Assessment of Education Progress (NAEP), the national testing programme in the USA, aims to measure change in educational attainments as well as to develop the technology of assessment.
This technology will not only be of use to the programme itself, but can also be made available at state and local levels.
Ten areas are tested, corresponding very much to conventional school subjects: mathematics, science, reading, writing, literature, social studies, music and art.
The schools are chosen as a representative sample, and neither individual students nor schools can be identified.
A matrix sampling approach is used which results in no more than 12 students in a school being tested, and then on only some of the test material.
Each subject area is tested at 4–5 year intervals, rather than annually.
At the time of testing, background information is collected relating to the students and schools: sex; size and type of community; parental education; colour.
During some of the assessments 20 other variables may also be measured.
The format of the tests themselves is mainly confined to pencil and paper exercises, and within these multiple choice questions dominate, although science tests have used a wider range of exercises  including practical work.
The tests are described in objectives-related, that is, designed to test certain objectives.
Items in the tests are not selected on the basis of how well they discriminate among students, i.e. they are not norm-referenced.
Dissemination of the findings of the testing is diverse and includes sending out some 23,000 full reports and many more summaries.
In the UK the Assessment of Performance Unit (APU) fulfils a similar function to NAEP and indeed has similar aims.
However, as Nuttall and Gipps (1982) note, the aim to measure changes over time was not in the original terms of reference although it appeared subsequently in publicity material.
Unlike NAEP, the APU started with a cross-curricular model for the areas to be tested, proposing the six lines of development already mentioned in Chapter 3.
To date mathematics, language and science have completed their initial round of annual surveys.
Modern language surveys took place in 1983–5 and design and technology tests are being developed.
For the measurement of changes of performance over time items were to be analysed using the Rasch model.
This assumes that a test is trying to measure a single dimension of student ability — a trait — and that the difficulty of a test item is independent of both the other items in the test and the groups of students who answer it.
In other words it is assumed that the difficulty of the item will be the same for any individual irrespective of his or her previous learning experiences etc.
It is also assumed that an individual's response to an item will be completely independent of his or her response to any other items in the test.
Conventional item analysis techniques were intended to be used along with those based on the Rasch model.
A light sampling approach is employed with the result that only a few students, in each of a representative sample of schools, are required to complete tests.
Matrix sampling is also used, such that each student only takes a small part of the total battery of tests.
Considerable effort has been expended to reduce the dependence upon written language when this is not the subject matter of the test, for example, in science use is made of oral presentations of questions.
As with NAEP, the science tests exhibit the most imaginative types of questions, although Michael Marland praised those used in the first secondary language survey.
The APU circulates summaries of its annual survey reports to all schools, but the full report which gives the results with little interpretative discussion, circulates less widely.
Local testing programmes.
The essence of these national schemes is that they provide a monitoring of the system as a whole and do not identify individual schools or students.
Local testing schemes, in contrast, can give information on individual schools if they employ ‘blanket testing’ i.e. all children in the local authority are tested.
The state testing programmes in the USA have been described in a survey by the Educational Testing Service (1973), which reported that, although there were plans for many states to test a wide range of curriculum areas (such as human relationships), few had developed the test technology sufficiently actually to carry out testing.
This resulted in a narrow range of areas being tested.
Many of the states have linked the testing programmes to the minimum competency testing mentioned in Chapter 1.
The style of reporting of results varies.
On the one hand Michigan, contrary to the original agreement with teachers, released individual school results to the public without taking into account the individual circumstances of schools.
On the other California puts results in the context of pupil entry ability, a measure of socio-economic conditions of pupils, percentage of bilingual children, and pupil mobility.
Local authority testing in Britain is rarely used for accountability purposes.
Gipps et al (1983), who surveyed LEAs, found that while most LEAs regularly conduct tests of reading there was no evidence to suggest a wide range of tests being administered, reading and maths being the most frequent.
The most common reason for testing was screening for, say, those students who need remedial help.
This means blanket testing, which was carried out by 52 of the 92 LEAs who gave information.
None of the LEAs admitted publishing league tables of the schools' results, and rarely was any punitive action taken in relation to schools that were performing poorly.
Some LEAs in Britain saw an important opportunity in the formation of an item bank, linked to APU tests, upon which they could draw to generate tests.
The Local Education Authorities' and Schools' Item Banking Project (LEASIB), operated by the National Foundation for Educational Research (NFER), offered such an opportunity.
However, it was based upon the Rasch model, which, as we shall see later, has come under substantial criticism.
The aim of providing national norms for any test supplied has been abandoned and no agreement has yet been reached on the use of APU test items by LEAs through the NFER bank.
Publishing examination results.
The requirement to publish examination results is, in Britain, laid down by law and the following information has to be specified:
1.
the policy of the school in entering pupils into the examinations;
2.
the examinations commonly entered for;
3.
the appropriate year group taking the examination;
4.
the number of pupils in the appropriate year group by subject, grade and total number in each year group.
The GCE and CSE examinations were conducted by a variety of Boards and, although subject experts tried to judge some standard of achievement, it was basically a normative assessment i.e. the same percentage pass the examination each year.
This is a fact often overlooked in discussions on standards, as Choppin points out.
Indeed there were problems about comparability of grades ‘in different years, from different boards and in different subjects’.
(With the advent of GCSE examinations assessments were against criteria and grades awarded for the achievement of more or less specified performances.)
The law's requirement for information on entry is an attempt to take account of the variety of policies operated by schools.
Such information is required, for instance, to compare the success rates of two schools, one of which only enters those who are likely to pass, and another which allows anyone to enter.
However, information that the law does not require, and is often not available, is some account of the intake characteristics of the school.
This poses a problem in that a school with high ability pupils would expect ‘good’ results but it may not be a ‘good school’— a problem we look at under ‘Issues’later in this chapter.
In terms of sampling the curriculum, examinations do rather better than most testing programmes.
However, they sample the pupils in a more selective way, because not all pupils take the same kinds of public examinations, and different criteria are used for each kind.
A small percentage of pupils take no public examination and, if examination results are the sole criterion, there is no way of judging whether schools are effective in meeting the particular needs of this group.
Roles
Tests are defined and designed by people who are outsiders in relation to particular schools.
Often consultation with insiders is inadequate.
NAEP went through an initial consultation with teachers and the general public in an effort to arrive at a consensus on the goals of education.
The tests were then developed by experts and submitted to lay people and subject matter experts for reactions.
However, as might be expected, this consultation was far from adequate in the early stages of NAEP's life.
First, the review of objectives only allowed lay people to suggest the omission of objectives that they found inappropriate, and attempts to add to or change objectives met with resistance.
Secondly, the process of arriving at consensual objectives meant that they represented ‘the least-common-denominator’.
Thirdly, in generating assessment exercises from objectives the whole process took much longer than anticipated and initially reviewers were unhappy with the quality of exercises produced by contract ‘item writers’.
The APU fairs even worse with regard to consultation; for example the six lines of development were not the subject of debate when they were initially proposed.
Moreover, the consultative committee, a representative body intended to guide the work of the APU, was often ignored by those running the Unit.
Burstall and Kay note that the positive response to NAEP testing may have been because critics were brought into the organising committee.
However, such committees, at the national level, are unlikely to make individual teachers feel involved.
Gooding (1980) surveyed teacher opinion and found that a majority thought there was insufficient consultation on the design of the tests, although a response rate of fifty per cent for the survey casts some doubt on how widespread this may be.
Teachers in schools being tested are thus powerless, since they have no control over the measures used and are not in a position to dispute the findings (although this depends on how the results are used, and if, for example, they are published).
It is, of course, possible for schools to use tests for their own internal evaluation, and indeed to operate their own testing programme.
Despite their lack of power and control, it is individual teachers in schools who must effect changes to improve education — if that is what the tests show to be necessary.
Burstall and Kay (1978) report that, with regard to the NAEP  programme, the impact on schools is poor.
Local authority testing can have more impact, and in Britain advisers can follow-up any problems and support schools.
Changes designed to improve education can therefore be regarded as having two sources: those initiated by decision makers at local or national level; those initiated by teachers.
We consider the use of test results by decision makers in the next section, and by teachers later when we consider criteria for judging testing as an accountability procedure.
Issues
Testing inevitably raises many issues, but we will consider five main ones: the validity of testing and other product measures; the technical problems; the possibility of curriculum backwash; use of test results to allocate resources; the release or publication of results.
The validity of product measures as the sole form of evaluation can be considered at a number of levels.
First, at the most general level, testing, and other forms of assessment, represent education in a mechanistic way.
Indeed Sockett (1980) goes so far as to call accountability based on prespecified results ‘anti-educational’.
Drawing on Pincoffs (1975) he argues that:
Educational goals…consist in the development of excellences.
Excellences are indeterminate dispositions…
Wittiness, modesty, prudence and love of animals…[are]examples.
These cannot be defined prespecifically in behavioural terms as they would have to be for the tests.
Secondly, the earlier reference to NAEP's consensual goals reveals another problem with goal-setting.
The ‘facile consensual model of defining national educational objectives’ means that deeply felt aims are neglected.
Thirdly, at a less general level, the particular model of the curriculum represented by the battery of tests may, or may not, be thought appropriate.
The ten subject areas of the NAEP programme cover a good deal of the curriculum, but Greenbaum,et al (1977) argue that this was limiting.
The six lines of development of the APU offered a more attractive model, but as Chapter 3 argues, a somewhat arbitrary one.
(For a critique for this model see Pring, 1981.)
The subsequent change in the areas tested raises a question about the validity of the tests as a representation of the  curriculum — a similar problem to that of the NAEP.
Fourthly, at the level of individual test items, a question can be asked about how well they represent the learning that goes on in the classroom.
In defence of the tests employed by the APU, Foxam, in a letter to the Times Educational Supplement (10 October 1980), points out that the teachers whose pupils took the tests thought that the language in the written tests was appropriate.
Holt (1981), in a review of all three of the APU test areas, has criticisms about each.
The independent appraisals of the maths testing (Cambridge Institute of Education, 1985) and the language testing (Thornton, 1986) do not directly comment on the validity of the tests.
Both are generally positive, and Thornton notes that the testing is based upon an intellectually respectable view of language and uses assessment categories which ‘break new ground’.
He also comments favourably on the test situation.
Even if, in general terms , the curriculum model is adequate, and the test items valid, it may not match the particular curriculum experienced by the student who is being tested.
The technical problems of testing have dominated discussions in the British literature on the APU, particularly the problems of the Rasch model.
This model, as indicated earlier, makes three assumptions: that ability is unidimensional (a trait); that item difficulty is independent of the other items in the test; that item difficulty is independent of the student i.e. it does not vary with the different learning experiences of students and hence it does not vary over time.
As the intention was that items for a test were to be selected to fit the model, it was important to be able to test this model.
But to test, for example, the assumption about item difficulty being independent of the student requires assuming that ability is unidimensional; in other words it cannot be tested!
Such tests are necessary because the model is not educationally very plausible (however statistically elegant and convenient it might be).
It seems unlikely that, all other things being equal, two students will find an item equally difficult when one has studied the topic that the item tests and the other has not.
Similarly it is well known that an easy item following a difficult one appears to be more difficult.
Both of these ideas contravene the model, which assumes that item difficulty is invariant under these conditions.
In addition, the model creates some contradictions in use.
First, we would expect over time that, for example, certain words would fall out of use and items related to these would appear relatively more difficult than those which use words still current.
This also contravenes the model, or rather the model does not fit what  common sense tells us.
It certainly cannot, therefore, be used to measure change over time: one of the reasons for its use.
Secondly, the trait assumption allows an item bank to be constructed so that users, such as LEAs, can construct a test appropriate to their circumstances.
An ‘appropriate test’ will mean one which suits the curriculum studied by the pupils in question; but item difficulty does not depend upon what the pupils have studied so the whole idea of an appropriate test is nonsense — according to the Rasch model.
These difficulties led to the abandoning of this model.
Perhaps the most important issue, however, is the possibility of causing curriculum backwash .
That it can occur nobody denies — witness the report of HM Inspectors on secondary education in England, in which they lament the narrowing effect on the curriculum of public examinations.
Burstall and Kay report that in the case of NAEP early opposition from teacher unions was partly based upon fear of a backwash effect and, indeed, it appears to have been a worry for those involved with setting up the APU testing programme.
Critics of the whole APU testing programme, such as Holt (1981) saw it as a threat to teacher autonomy.
Indeed Holt saw it as a mechanism for controlling the curriculum and even went so far as to suggest that the staff of the APU were concerned to promote desirable curriculum development.
Tall argues, more moderately, that the Rasch model, because of its focus on traits, may inhibit new developments in teaching methods.
National systems of testing use light sampling methods and therefore the direct impact on the curriculum is unlikely to be large.
But the selection of areas for testing (ten subjects in USA, and five in Britain) implies that certain elements of the curriculum are more important than others.
In the USA, NAEP's use of conventional school subjects has been seen as a conservative influence, and the reduction to the 3Rs makes the backwash effect even more acute.
The APU would not have been accused of exerting a conservative influence with its cross-curricular model; however, the eventual selection of subjects could have a narrowing effect on the curriculum.
In reviewing the curriculum backwash effect of the APU, Gipps (1982) reported little evidence of it, and a lack of mechanisms to bring it about.
But her latest account of the APU indicates a more positive approach being taken.
First, the APU has put more stress on disseminating survey information which has implications for teaching.
Second, this is linked with teacher training work, for example the use of practical assessment materials.
Third, there is a possibility that the  APU will be used to set attainment targets to raise standards with the result that teachers will teach to them, and inevitably the curriculum will be narrowed.
Fourth, the need to develop grade related criteria for GCSE may give the APU a link with the examination system, if it is involved in their development.
This link may give the APU a more direct backwash effect on the curriculum than the other three mechanisms above.
If the backwash effect is less direct in a national testing programme, local programmes, involving blanket testing of all pupils, have the maximum potential to cause an effect.
Holt (1981) saw the setting up of LEASIB as the biggest threat to schools, allowing the APU to have more direct impact.
As we noted earlier the developments of this work make this unlikely.
The experience in the USA suggests that local testing programmes are usually of poor quality and their effects therefore more undesirable.
Gipps et al (1983) report little concern amongst primary school headteachers about adverse effects, though the programmes themselves lack clarity of purpose and use.
There is, according to them, no general worry in schools about LEA testing.
One of the attractions of a national testing programme is its supposed potential to help decision makers with policy formation, for example with how to allocate resources.
The experience from the USA on the use of NAEP's results is disappointing and led Wirtz and Lapointe (1982), on the basis of all previous evaluations of NAEP, to conclude that: ‘Everybody pretty much agreed that the results of National Assessment have never been very useful in a practical sense’.
Greenbaum et al (1977) put it stronger when they said NAEP was so limited that it has ‘virtually no capacity to provide the federal government, the lay public, or most educational policymakers with results that are directly useful for decision making’.
One of the reasons for failure is the need to measure more background variables, chosen to meet the needs of decision-makers; critics of NAEP think that more effort should be made to find out the needs of such decision-makers.
(This issue is taken up again in Chapter 11.)
On an APU sponsored visit to the USA, Burstall and Kay (1978) drew the following lessons from the USA experience: that the APU should obtain information that is, on the one hand, of use to teachers and on the other to decision-makers; and that the information collected must be related to needs rather than being simply that which is easy to collect.
However, after a number of years of operation, the APU does not appear to have been conspicuous in its success: most of the background measures are of little use, and there are difficulties in  relevant measures.
Kelly argues that the removal of the requirement to aid decision-makers would allay fears.
Another reason for the failure to use results is the lack of interpretation.
Since its inception the NAEP has been faced with the dilemma of deciding whether to report results in a descriptive fashion or to add interpretation.
In a careful analysis of NAEP's attitudes and possibilities for action, Greenbaum et al say that NAEP has a muddled policy and they conclude: ‘its only really feasible potential — conceptually, economically, and politically — is that of description’.
Interpretations depend upon being able to link the background measures (class, size, socio-economic group etc.) to those of performance.
However, Nuttall has shown that this creates considerable problems for the interpretation of results in relation to, for example , class size.
However, in the more recent evaluation of NAEP, which seems preoccupied with the needs of researchers rather than policymakers, Wirtz and Lapointe (1982) maintain that more effort is needed to interpret results and suggest an independent council to carry this out.
The APU has started along this course with the two independent evaluations of their surveys.
Given the closer relationship between local testing programmes and decision-makers, and the use of blanket testing, such programmes have a greater potential for aiding policy formulation.
Evidence from the USA, however, shows that such use is patchy, and only two states appear to have directly used test results.
We have already made the point that in Britain this seems unlikely.
Wood and Gipps (1982) pose an interesting dilemma for decision-makers allocating resources: do they give resources to the schools with poor results, thus penalising the good ones (from which the good schools may learn the best way to get resources), or do they reward the good schools and let the poor ones suffer?
An issue which has also caused controversy involves the release of results of individual schools.
Of course, this applies only to local testing programmes, which employ blanket testing, and to the publication of public examination results.
The notorious case of Michigan shows this issue at its most stark.
Becher et al (1981) point to some of the problems: it is not obvious what the real reasons are for poor results (e.g. poor intake); criticism of a hardworking school operating in bad circumstances undermines morale; and a high scoring school acts as a magnet and deprives other schools of high ability children.
Burstall and Kay (1978) report that estate agents in Michigan utilise test results — a graphic illustration of the last problem noted by Becher and his colleagues.
While the law may require publication, the form this takes can reduce the damage that results cause; in this respect Michigan provides a contrast with California (a point made earlier).
In relation to public examination results in Britain, Gray (1982) has documented the difficulty of interpreting the disputed results of two competing London schools, Highbury Grove and Islington Green, which sparked off considerable press comment and correspondence in early 1981.
(For example, see letters in Times Educational Supplement , 13 February, 1981.)
The major problems included the need to account for the differences in the schools' intakes, deciding which groups of pupils were included in the result statistics (e.g. whether sixth form pupils taking ‘O’ levels were included along with 5th formers), and the problem, for outsiders such as Gray, of getting hold of all the relevant statistics.
Judgement of testing programmes
We will confine our judgement to testing (for the purpose of monitoring) as this approach is primarily concerned with evaluating educational provision, whereas public examinations are concerned primarily with individual pupils and students.
Many of the criteria put forward in Chapter 1 have already been indirectly considered in the discussion so far.
We noted, for example, that control lay outside the school.
National testing programmes are remote from schools, and even local programmes do not involve schools in planning, test choice or construction.
We have also already considered the issue of methodological soundness and revealed doubts about the validity of the tests, at several levels, particularly with regard to the technical problems, and especially those of the Rasch model.
However, there is no doubt that the APU has pioneered new testing methods.
Deciding whether testing programmes are economic in their use of resources is a more difficult problem.
Nuttall and Gipps (1982) estimate that the direct cost of the APU was £800,000 per year, which crudely would mean less than £30 per school.
The annual budget of NAEP was once as much as 7.1 million dollars (about £3.5 million pounds), although by 1982 the figure was down to 3.88 million dollars.
Despite this relatively small cost the Reagan Administration was encouraged to seek further savings and decided to put the whole operation out to private tender (reported in the TES , 28 October, 1982, p.12).
It is, of course, difficult to make any  sense of these figures; in any case, as Nuttall argues, what is important is the kind of results that are obtained for the money spent.
This brings us to a consideration of whether these programmes are capable of suggesting appropriate remedies.
First, considering the issue at the level of teachers in schools, we have already cast some doubt on this in our discussion of ‘Roles’.
But it is possible that the APU's teacher training and dissemination efforts may have some effect.
Regarding the USA state programme, the Educational Testing Service (1973) says that it is unlikely that even local testing can reveal anything startling about how teachers can improve their work.
It concludes that intensive analysis of individual schools and classrooms is required.
Little evidence exists to indicate that tests help teachers; however this sad fact may not surprise many people.
What is more surprising, when considering what advocates of testing have to say on this subject, is the lack of ideas on how such information could ever help schools.
Consider, for example, this notion put forward by Wirtz and Lapointe (1982):
Nothing…diminishes the recognition that the place to improve formal education is in the classroom and that what is done there is a local responsibility.
Yet there is no question about the constructive effect of concentrating national attention on a common problem by reporting the situation in the country at large.
In other words, if the country gets a bee in its bonnet about some failing in schools, teachers will remedy the situation — hardly a sophisticated theory!
But it may be unfair to look for remedies at classroom level from such global data.
Instead, it may be more appropriate to consider national and local educational decision-makers.
Even here, as we have shown earlier, the evidence is overwhelmingly against the usefulness of testing, whether carried out on a national or local basis.
What is worth considering is whether it could be of help if ‘things were improved’.
From our earlier discussion it is evident that opinion is divided amongst those who have tried to evaluate national programmes.
Greenbaum et al (1977) say there is ‘no capacity’ to help decision-makers; Wirtz and Lapointe (1982) implicitly say there is, by recommending a doubling of NAEP's expenditure and its development to investigate ‘causes’of the results reported (something that is very unlikely given the government decision reported earlier).
However, it is this latter point that holds the key to understanding the different views, and, although a full  analysis is beyond the scope of this book, it is worth exploring briefly.
The thrust of the recommendations made by Greenbaum et al (1977) is that NAEP ‘is not a short-term research or decision-making tool’, but that it should become ‘a useful long-term census’.
However, they realise that such an approach may jeopardise funding of the programme.
Wirtz and Lapointe, on the other hand, concentrate on research problems in relation to policy development, recommending that specific studies be carried out in association with the general testing programme (a recommendation also made by Gipps (1982) in relation to the APU).
Such special studies for research purposes , Greenbaum and his colleagues thought, could be done ‘more precisely and less expensively by smaller studies’.
More central to the concerns of this book is the question of whether testing programmes are a suitable procedure for accountability.
Certainly, on the criteria considered above, the answer would be ‘no’.
Wirtz and Lapointe (1982) however maintain that they are, by affirming the importance of NAEP's work in improving educational standards, although they rely more on judging the ‘mood of the times’ than on any careful analysis.
In contrast, after an analysis of the literature on social indicators and the reform of education, Greenbaum et al (l977) conclude not only that can NAEP not help with research hypothesis formation or policy guidelines, but that ‘the  prerequisites of an effective large-scale system of social accounting demonstrates that no such system lies within reach in the field of education’.
They go on to argue that ‘in the short-term the most likely approach to educational change is through enlarging the use of increasingly refined self-knowledge by particular institutions’.
This is a conclusion with which we would agree and indeed it provides a rationale for this book.
That being said, it is  undoubtedly true that more empirical research is required into the effects on teachers of the APU's programmes of teacher training and dissemination.
Inspections
As we shall see later the basic premise underlying an inspection will vary with the circumstances of the inspectors.
In Britain these are in a state of flux although there has been much discussion about the role of the inspector over a long period of time.
Any inspection system, however, has a number of major elements:
1.
an experienced professional, who has some independence from the school, observes the  schools' activities;
2.
various aspects of school life are observed, through an informal visit or a formal team visit;
3.
in a formal visit to an individual school a report is prepared for the education authority and the school;
4.
inspectors are expected to have intimate knowledge and continuing experience of the classroom;
5.
the inspectors' function is not just to pronounce judgement, but also to encourage and develop education
Becher et al put forward the following strengths and weaknesses of visitation (which covers a wider range of activities than inspection) as an accountability procedure:
Strengths
1.
inspection is commonplace and maintains public confidence;
2.
teachers see it as natural justice (comparison with colleagues reduces isolation and gives them a yardstick);
3.
it is more humane than testing — it can put a human face on any judgement, positive or negative;
4.
it allows headteachers to approach awkward staff who have problems and reinforces the existing management structures;
5.
extra resources may come to the school;
6.
it is flexible and individualistic compared with testing;
7.
it has more explanatory power because it involves direct observation and can hence lead to remedies.
Weaknesses
1.
if it is to certify an institution then it can be superficial and impressionistic (i.e. subjective);
2.
it can be susceptible to a headteacher who is good at public relations management.
Her Majesty's Inspectorate
The first example of inspection that we have chosen is the operation of HM Inspectorate in Britain.
These inspectors, although originally instituted to inspect schools receiving grants from Parliament — a function now replaced by the task of reporting to the Secretary of State for Education on the quality of educational provision — have always had the aim of seeking to improve education in the institutions  they visit.
However, their history, from the first appointments in 1839, has been one of constant change and adaptation.
They have always spent considerable time visiting schools; in the nineteenth century there were regular visits, including during the period of payment by results (1862–1898) when the outcome of an inspection, involving assessing the children's performance, determined whether or not the school received funds.
In the period of expansion of the Inspectorate after the Second World War the tasks diversified and regular formal visiting declined; in 1968 the Select Committee on Education and Science recognised this shift.
However, the decline in regular formal inspection did not mean the abandoning of inspection but rather the development of a variety of types suited to particular purposes.
Thomas, a retired HMI, lists four overlapping categories of present day inspections:
1.
informal visits usually by one HMI;
2.
‘reporting’ or ‘full’inspection followed by a written report to the Secretary of State and others;
3.
area team exercises usually on a single issue, sometimes followed by an internal report;
4.
national surveys followed by a public report.
The ‘full inspection’ is the traditional form, but one which is written about in detail least.
Most accounts of the methods of inspection are by retired or practising HMIs, although those on the receiving end do describe the experience.
Thomas notes that the basis of all the types of inspection are similar.
Clearly a full inspection has a degree of formality because of its import and scale; thus it involves a team of inspectors, finite time (of the order of a week), a timetable of observation and discussion for each HMI, and a formal written report.
A full inspection of a primary school will, of course, differ in scale from that of a large secondary school.
Surveys, while using similar methods, require cue in sampling schools (to aid generalisation) and efforts to standardise the data collected.
But at the heart of all the methods, whatever their purpose or form, are two elements: observations of classroom, and discussions with teachers.
Hopkins (1982) sees the main strength of the Inspectorate to lie in an ‘intimate knowledge of the classroom scene’.
This, he feels, can only come about by a return to the basic function of inspection.
What then is the nature of the observations made by HMI?
Thomas outlines the following kinds of observations  and activities of HMI: observation of the exchanges between pupil and teacher, and pupil and pupil; discussion with pupils as a group, or individually; a look at current or past work of pupils; requests to pupils to do some particular piece of written work; discussions with teachers to find out aims and to check observations; examination of schemes of work and pupil records; a look at the quality of resources and how they are used.
This is not intended to be an exhaustive list and throughout the observations the main questions in the HMI's mind are: Is the range of work suitable for the children?
Are the levels of work such that children are managing increasingly complex information and relationships?
Even in the more structured work of surveys HM Inspectors still rely upon informal and holistic methods rather than observation schedules (a topic we shall consider in Part Three in relation to observation methods).
Before 1983 the reports that resulted from full inspections were confidential and sent only to the LEA, the school's governors, and the headteacher.
However, at the time of the inspection any comments made by the inspectors were discussed with any teachers who were implicated, the head, and possibly the governors of the school.
Interestingly, in evidence to the Select Committee in 1968 the Senior Chief Inspector (Scotland) was asked ‘Do you in fact nowadays have any formal inspections in the old sense of written reports?’
He replied, ‘Not written reports.
We gave up the written report quite frankly because we found it a waste of time.
By the time a report reached the authority something was seriously wrong if all its recommendations were not already in operation’.
In a following question the SCI (Scotland) also admitted that in translating recommendations into a written report the point was often lost; the discussions with the school and perhaps the LEA were the major reporting function.
Now all school and college full inspection reports are published as a matter of course.
The Secretary for State for Education cannot withhold permission to publish and this is seen as an important sign of the independence of HMI.
(This independence was illustrated most vividly over the publication of a survey of spending on education.
It revealed a sorry state of affairs in schools which could be attributed to the cuts in educational spending — something that proved embarrassing to the government of the day.
The publication of reports on full inspections of individual schools has become routine and no longer leads to any public debate of the rights and wrongs of such reporting.
The Times Educational Supplement features reports on a  particular page, picking out significant findings (both adverse and positive).
Individual schools did enter into correspondence with the TES over its reporting of the full HMI report, and over the findings themselves.
This at least testifies to the independence of HMI from the schools they inspect.
(This also applies to LEAs who have equally taken issue with HMI reports on their provision of education.)
It seems that the publication of these reports has by and large not proved such a worry to schools.
When the publication of HMI reports on university departments of education was discussed (as part of the approval mechanism for teacher training courses of the Council for the Accreditation of Teachers' Education, CATE) there was initial resistance.
These inspections were at the ‘invitation’ of the university department, but failure to allow an inspection would result in a course not being approved.
Further permission for publication of the report was left to the department to give.
The Universities Council for the Education of Teachers (UCET) debated this before agreeing to publication as a matter of course, though they were under some pressure from the DES, HMI, and, interestingly, from the Vice-Chancellors (individually and collectively through the Committee for Principals and Vice-Chancellors).
It was agreed by both the DES and HMI that, since university teacher training represented excellence, they had nothing to fear, and other institutions could learn from the reports.
One thoughtful article by a headteacher whose school was the subject of an inspection pointed out the need for HMI to be scrupulous in their attention to details of factual accuracy.
Not only can incorrect facts be used by local press to the detriment of the school, but such errors, and their refusal to correct them in published reports, cast doubt on the wisdom of this process.
These published reports and the surveys of particular aspects of education are periodically reviewed to give a judgment on the state of the education system in general.
Naturally this judgement has to be tempered by the unrepresentative nature of the sample of reports that it draws upon.
In the first six months this sample was of 106 reports.
One of these summary reports was used to identify good teachers and good teaching, in the context of the White Paper Teaching Quality and the discussion of teacher appraisal.
LEA Inspection
The second example of inspection is that carried out by local authority inspectors.
In essence the mechanics of inspections can be the same; what differs is the role of such inspectors and their experience of inspection.
The 1944 Education Act gave LEAs the right to inspect schools, indeed, some LEAs inherited inspectorates from the School Boards which preceded them.
But the titles, size of teams and functions of inspectors vary among the local authorities.
Thus some authorities employ a team of inspectors while others use a team of advisers or organisers.
Bolam et al (1978) have published the most recent study of advisers and they found that the least popular task, except among senior advisers, was the evaluation of individual staff.
Further, although half were involved in general inspection few advisers wanted to spend more time on it (again senior staff were the exception).
Bolam and his colleagues recognised, however, that since completing their research in 1975 the climate had changed and may have increased the demand for inspections.
Some advisers, they thought, may turn to inspection to survive in a climate of education expenditure cuts.
At present, the bulk of an LEA adviser's work involves helping teachers in a variety of ways, and, although this requires them to observe teaching, the act of inspection creates some tensions.
Thus the issue of independence occurs again.
This time the inspector is clearly associated with the authority that employs the teacher, and which is responsible directly for the quality of the education in the school.
The most graphic statement of the dual role, though some would call it an overstatement (e.g. Pearce, 1982), is that given by the National Association of Head Teachers (NAHT) in response to a document on the role of the advisory service issued by the Society of Education Officers and the National Association of Inspectors and Educational Advisers:
For example, how can an adviser go into a school and give advice on procedures, and within weeks go in and inspect those same procedures in a censorial sense?
How can a Head Teacher have the confidence to call in an adviser for consultation on a problem in his school when he is conscious that, as a consequence of that consultation, his school may be subjected to intense overtly critical scrutiny within a short space of time?
This conflict of roles has of course its benefits, and in any case formal inspections are unlikely to be the norm.
Local inspectors, like their HMI counterparts, favour informal routine visits.
These will still contain an inspectorial element but will be much less tense.
The benefits for the local inspector are that by their greater number (compared with HMIs — see Pearce, 1982) they can become more familiar with the schools, and by virtue of their advisory role they will have some responsibility for following up any findings of an inspection — whether it be formal or informal.
In addition to this worry about the dual role, some teachers, and headteachers in particular, doubt the skills and experience of advisers.
Whether or not one feels they are equipped to advise headteachers it is difficult to avoid doubting their skills at inspection.
Except in a few cases, formal inspections will not have been frequent enough to build up the kind of collective experience that HMIs have.
This is not to deny that local inspectors are skilled at informal observation, or able to give advice to teachers in particular areas of the curriculum.
Nevertheless, we know even less about the inspection methods of these inspectors than we do of HMIs.
Roles
Inspection by its nature casts teachers and schools in a passive role.
They are evaluated and yet play no part in defining the criteria, determining the methods, or controlling the process.
For this to be acceptable to teachers they have to have confidence in the ability and independence of the inspectors: independence, that is, from the education authorities who are their employers.
On the other hand the public would want inspectors to be independent of the school being inspected.
HMIs fulfil both of these conditions, but this is not so for local authority inspectors.
The HMI insistence on a formal written report for a full inspection also affects this confidence.
Blackie, commenting on the evidence given to the 1968 Select Committee, claimed that those wishing to see reports abolished did not realise that ‘the written report is a safeguard for teachers, and if abolished…would almost inevitably lead to information being passed orally and, in effect, secretly’.
In saying this, however, Blackie ignored the evidence of his colleagues in Scotland who unequivocally denied any protection, adding, ‘If we have a criticism of a teacher or if we feel that a teacher is weak in some respects…the matter would be discussed very frankly with the teacher in the first place’.
Whatever the form of  the advice, the Inspectorate make it clear that the teachers are free to accept or reject it.
For the LEA inspectors confidence is lacking in both senses stated above.
Even the reporting system can lead to worries: despite a written report the inspector can informally report the ‘real story’ to other officers of the authority.
This may seem too unprofessional a view to have of them, but even discounting direct informal reporting, they cannot avoid using this information when, for example, they are involved in appointments and promotions.
As indicated above the teachers and schools have no control over the criteria and methods, nor indeed the report.
However, the DES speculates about the possibility of an ‘agreed record’— a record of discussions between staff and inspectors which should indicate that the different views expressed have been dealt with fairly.
Whether or not this has been implemented is unclear.
At the local authority level Dorset County Council (1980), in a booklet called Looking at Schools , talks of a joint-evaluation, which amounts to an inspection with the school agreeing to the report, but having no control over the process of the inspection.
Hillingdon local authority have adopted a code of practice for ‘in-depth visits’ which lays down, at least in the case of secondary schools, negotiations over what is to be investigated and the plan of the visit.
For all types of schools the headteacher has the right to append comments to the final report (Craddock, 1979).
In a case study by Turner (1987) an account is given of an inspection which was to have built upon a self-evaluation, with the latter acting as an initial ground clearing and the provision of information.
However, the inspectors ignored and even scorned the self-evaluation, seeing only their inspection as important.
Issues
Clearly two major issues concern the independence of the inspectors and their reporting methods; however, we feel that these have been adequately covered in the discussion so far.
One remaining issue worthy of development concerns the quality of the methods of inspection used by the inspectors.
These methods, as we have already indicated, are based upon an informal unstructured approach, although the HMI surveys employ a greater degree of structure.
While it would be wrong to expect inspectors to use observation schedules (on the grounds that they do not allow the inspectors to keep an open mind on what they observe), it is quite reasonable to ask that they be explicit about the evidence collected and its basis.
Thomas  gives a list of headings used in informal visits but these headings are very general e.g. ‘curriculum’, ‘work seen’.
The surveys have provided the most explicit statement of how, and on what basis, data are collected.
Brown, M. (1979) gives a framework for observation of nursery and infant schools, to be used by LEA advisers during visits to schools.
Becher et al cite the following methodological criticisms of inspections: lack of empirical evidence on which they are based: impossibility of getting to know a complex situation quickly; failure to separate value judgements from evidence.
When the HMI methodology is made explicit, as in surveys, then it tends to draw criticisms.
Bennett (1978) in commenting upon the primary survey complained about the lack of explicit theory on which observations were based, and that the theory which emerged, although respectable enough, had little empirical base.
He was also concerned about the reliability of the data: for example, that no measure of agreement was given for observations made when pairs of inspectors were present in the same classroom.
Bennett was also worried about the lack of allowance made for the impact that HMIs have when they visit a school (the term for this is ‘reactivity’, which will be discussed in Part Three ).
Perhaps, Bennett argues, the finding that so little use was made of exploratory methods in teaching was the teachers' reaction to the presence of HMIs.
Nuttall (1980) questioned the secondary survey in a similar vein, saying that HMI should employ the methodological standards of research.
Nuttall concludes that in the end ‘the only criterion for judging the adequacy of the reports’ findings is one's faith in HM Inspectorate'.
Thomas makes a similar point when he says the ‘quality of their [HMI's]work depends on their personal attributes as shaped by experience’.
This implies that both their background and training are important.
Regan (1977) complains about the lack of statistics on their background but says there are still some subject areas where inspectors only have experience of grammar and independent schools.
The evidence given by the HM Inspectorate (Scotland) to the 1968 Select Committee is however complete enough and shows a good spread of backgrounds.
Although for Scotland the main deficiency was only in the lack of HMIs with primary school experience, the Select Committee was concerned about the overall balance in England and Wales.
The DES, however, saw no need to change its recruitment practices.
The comments, referred to earlier, by the NAHT on local inspectors' background experience indicate a more acute  problem.
Likewise, Jarmen, a former adviser, expressed concern about the requirement for subject advisers to take on general advisory functions many of which they were not qualified to carry out.
The Select Committee of 1968 suggested that secondment of HMIs to schools and colleges might be a useful experience.
Although the DES said it was considering this, it pointed out that there was a practical difficulty in the difference in salary scales.
Again Regan (1979) makes the point that there is very little formal training, of any kind, in an inspector's career.
Edmonds (1962) also says that this has been a problem throughout the 150 years of the Inspectorate.
Again LEA inspectors suffer more acutely in this respect, perhaps because of their lack of corporate identity — each LEA's inspectors or advisers are rather isolated from those of other LEAs.
The publication of full inspection reports gives another source from which inferences can be made about the work of HMI, and here we will consider two critiques that have used them.
First, Elliott and Ebbutt consider the criteria used by HMI and question their lack of educative feedback to schools.
This approach, Elliott and Ebbutt argue, stems from HMI's use of prespecified criteria and what appears to be the use of a check-list by them.
The criticism that Elliott and Ebbutt make of this approach is three fold: values underlying judgements are not revealed; the analysis is atomistic and ignores the inter-relationships among features of a school's activities; and areas are inevitably ignored.
The second critique of HMI comes from Gray and Hannon (1986), who argue that HMI judgements of individual schools are made against a ‘national standard’, i.e. comparing one school with another in an absolute sense.
This ignores the particular contexts of individual schools, and the way they differ.
Thus a school in an affluent area is usually praised whereas one in a deprived area will usually only get a ‘satisfactory in the circumstances’ judgement.
These judgements take no account of the intake characteristics of particular schools, though HMI collect and report such data as social class and verbal reasoning scores at intake.
They do not however use this data to temper their judgements, with the result that a school may be praised because of the intake characteristics of the pupils rather than because of anything it has done.
Judgement of Inspections
One of the great claims that inspectors would no doubt make is their fairness to both teachers and the public.
To the teachers they offer a  professional and sympathetic approach to evaluation; to the public they offer the evaluation of an outsider.
However, this is premised upon a notion of their independence.
As we have already argued, at the level of school, and indeed the LEA, HM Inspectorate have that independence.
This is not so for local inspectors, although they would argue that their involvement helps in effecting change.
In addition to independence, both teachers and public, and teachers in particular, will want to be assured of the inspectors' ability so that they can trust the judgements made.
HM Inspectorate seem to command the respect of teachers, although as Becher et al say, ‘Sometimes this respect appears to be based on an assumption that inspectors must (because many teachers rarely if ever see them) be very busy and therefore very able people’.
Again local inspectors do not seem to do so well in engendering trust.
Whether HMIs or local inspectors are involved, the school still has to give over control of the evaluation to outsiders; it may only be willing to do this if teachers are assured of the kind of fairness discussed above.
If, as HM Inspectorate argue, the recommendations they make are not binding upon the LEA then this may represent an acceptable blend of central and local control.
However, in the case of both local and national inspectors, the school is likely to be bound by the LEA's response to recommendations, in which case the school still has no control.
The argument over where control should reside is often based upon the criterion that an evaluation should be capable of suggesting appropriate remedies .
Although inspectors control the evaluation, they argue that they place great importance on discussions with teachers which increase the chance of changes taking place.
HM Inspectorate are not in a position to follow such discussions up with any kind of sustained support.
Local inspectors, on the other hand, can rightly argue that this is their great strength.
From the evidence that is available there seems to be some doubt about whether inspection is methodologically sound (though this is mainly based on what the inspectors fail to say rather than what they do say).
Again a trust in their ability is their main defence.
However, whatever that ability may be, inspectors cannot avoid the criticism that they fail to follow many of the practices that ensure rigour in research.
(Whether or not any evaluator should follow such practices is an issue we shall explore in Part Three .)
Finally, we need to consider whether inspections are an economic approach.
Most commentators, from the 1968 Select Committee onwards, argue that HM Inspectorate should not expand to the extent  that it is able to carry out a full programme of regular inspections (Hopkins, 1982, is an exception).
If it did, Nuttall and McCormick imply that the costs would rise so substantially as to become prohibitive.
On the basis of calculations about what local and national inspectors could manage by way of inspections, Becher et al (1979) go further and conclude that, ‘It therefore becomes hard to see inspection becoming a routine form of accountability without at least doubling the number of inspectors’.
They reach this conclusion as part of an argument for school-based accounting using criteria similar to those we have considered.
On all of their criteria they conclude that a school-based approach is likely to be superior to either one based upon testing or inspection.
It is not possible, however, to come to any conclusion about the usefulness of testing and inspection (outsider evaluations) without considering what is possible for schools to do themselves (Becher et al , 1979, go on to consider the merits of school-based approaches).
The next chapter is just such a consideration, though one that takes as a starting point the professional development of teachers (Chapter 2) rather than the issue of accountability (Chapter 1).
5
Evaluation by Insiders
Introduction
The evaluation strategies outlined in Chapter 4 may satisfy the consumers of education that an independent check is being kept on the work of schools, but, as the judgement we came to indicated, they seem less satisfactory as procedures for assisting improvement in educational practice.
Even if more apparent than real, they carry some threat of sanctions against teachers and schools who fail to perform as expected however unreasonable, given certain contexts, that expectation might be.
They can, therefore, evoke a defensive, sometimes hostile, response from teachers that is anything but conducive to creative effort in the direction of curriculum improvement .
Within the profession the general feeling is that the greater the degree of autonomy that can be given to teachers and schools, the more likely are they to accept responsibility for educational provision and become committed to improving its quality.
This, as we saw in Chapter 1, is the argument for a professional mode of accountability.
It is also the rationale for suggesting that evaluation has an important role in promoting professional development and curriculum improvement (see Chapter 2).
Proposals for Insider Evaluation
If, as has been suggested above, insider evaluation is primarily associated with curriculum improvement, it comes as little surprise that proposals for particular approaches are directly or indirectly related to models of curriculum design and development.
Indeed, evaluation is regarded as an important stage in ‘rational planning’ or ‘objectives’models of curriculum design, which rest on the assumption that education is a means towards ends.
Accordingly, curriculum development involves specifying educational goals and selecting appropriate learning  contexts in which those goals can be pursued.
Thereafter, the task of evaluation is to ascertain whether or not the pre-specified goals (aims and objectives) have been achieved.
It is customarily acknowledged that this model was first developed by Bobbitt (1918, 1924), clarified by Tyler (1949) and refined and elaborated by numerous others (e.g. Taba, 1962, Bloom, 1956, Block, 1971).
The importance of finding ways to measure the achievement of goals encouraged some writers (e.g. Popham, 1967) to emphasise the need to specify aims and objectives in precise behavioural terms.
This argument had a simple logic.
If the achievement of specific goals is to be assessed, then they need to be observable; if they are to be observable they need to be framed in terms of specific student behaviours.
The arguments for and against this approach to curriculum planning and evaluation are well documented elsewhere.
Suffice it here to say that there have emerged other groups of educationists who present alternative views.
Some of these are in fundamental disagreement with the assumption on which the rational-planning or objectives models rest.
In other words they deny that education is necessarily a means to an end, and argue instead that either the content or the processes of teaching and learning can have  intrinsic educational value.
Thus the teaching of certain forms of knowledge has been regarded by some as intrinsically worthwhile; whilst others have regarded certain principles of procedure, such as enquiry-discovery learning, in much the same way.
The critique of the objectives model and the erection of an alternative paradigm was the central theme of an important book by Stenhouse (1975).
In this he pointed out that whilst the objectives model might be appropriate to those parts of education concerned with skills training and instruction (acquisition of information), it was of no help in the area of understanding (induction into thought systems).
He argued that education for understanding can only be regarded as successful to the extent that it makes behavioural outcomes unpredictable .
In this context, therefore, evaluation can only legitimately focus on processes.
(This issue of what to evaluate will be developed further in Chapter 7.)
Stenhouse's argument, however, goes beyond proposing a process model for curriculum development and evaluation.
According to him an emphasis on processes makes such great demands upon the teacher (an insight gained when he was director of the Humanities Curriculum Project) that any proposal for curriculum development should be  regarded as tentative, having the status of an hypothesis to be tested by teachers in their own classrooms.
For this reason he proposed a ‘research model’ that has as its central theme the notion that it is not sufficient that the work of teachers should be studied (either in terms of outcomes or processes), but that they should study it themselves .
This is the concept of the teacher-as-researcher that we introduced in Chapter 2.
In relation to insider evaluation there is evidence in the educational literature that the three approaches to curriculum development outlined here (the objectives model, the process model, and the research model) continue to have an influence on evaluation, at least in the UK (we will come to the USA and Australia later).
In modified form the objectives model is still alive and well.
Many educationists, administrators and teachers, especially those of a technocratic or managerial frame of mind, continue to argue that evaluation must be concerned with establishing educational objectives and then systematically monitoring, often by statistical methods, whether or not they have been achieved.
This, for instance, is the stance taken by Shipman (1979) in the book he entitles In-School Evaluation .
Avoiding the perennial philosophical question concerning what educational ends are most worthwhile, and what constitutes educational quality, he asserts that it is perfectly possible for teachers to agree ‘working objectives’ that can provide the focus for the development of an evaluation technology.
His emphasis on systematisation, objectivity and the utilisation of indicators by which the achievement of objectives might be measured reveals a conformity to the classic, positivistic or behaviourist tradition.
As we pointed out earlier, the kind of model for insider evaluation that Shipman proposes has a long history and there is little evidence that it has been significantly displaced by newer alternatives.
Undoubtedly its appeal rests on a simple logic that those inside and outside schools can readily comprehend; as such its influence should not be underestimated.
The influence of process and research models for curriculum development can also be detected in a number of proposals for insider evaluation.
Among the most detailed derive, not entirely unexpectedly, from people like John Elliott and Helen Simons who at some time have worked with Lawrence Stenhouse.
Elliott's development of the research model will be discussed in Chapter 11 because it is very much concerned with strategies for action.
Here we will confine our attention to an approach to evaluation proposed by Simons (1981).
Although she argues mainly for process evaluation at whole-school level, her account is representative of a growing genre of writing on insider evaluation, which is generally opposed to the objectives approach.
According to Simons, evaluation in schools should possess the following characteristics:
1.
It should aspire to reflect the processes of teaching, learning and schooling in order to educate judgements about the adequacy of educational provision and the quality of experience pupils have.
Simons rejects product-efficiency models which pay attention only to outcomes, since some outcomes are beyond the school's power to influence (see the arguments outlined in Chapter 4).
2.
It should draw on a wide spectrum of information sources: interview data, close description of observed events, documentary evidence, as well as test and examination results.
In other words, evidence of processes and outcomes should be drawn from a broad data base.
3.
It should examine the attitudes, values and assumptions that  underlie the kind of information that comes from various sources.
In Simons's words it ‘goes beyond the information given’ to identify the interests which shape the ‘facts’.
For this reason it is considered important to gather the subjective judgements of participants as well as evidence of a seemingly factual kind.
4.
It should encourage the flow of information in all directions: down the status hierarchy as well as laterally and upwards, as is more usual.
In this sense it intends to foster the idea that the internal organisation of institutions should be open and democratic.
5.
It should develop the kind of informal evaluation that teachers normally engage in, in order to gain some feedback on their practice.
6.
It should focus on internal needs defined by the school and its teachers, not merely what outsiders consider to be important.
This notion is based on the argument that unless teachers perceive issues to be relevant they are unlikely to be committed to their resolution.
In this connection, Simons makes a special point of advocating the consideration of whole-school issues (a theme that we shall develop later).
7.
It should be particularistic and small scale and concerned with the immediate problems of a given institutional context.
It is likely to be less interested in universals and what may, or may not, be the general case.
8.
It should be concerned, therefore, with evaluating educational situations in ways that provide information relevant to decision making and the analysis of policy options.
9.
It should precede curriculum development rather than following after it; in other words, it should be formative rather than summative.
10.
It should be initiated and managed by teachers inside the schools on the assumption that only if schools and teachers retain control of the evaluation process will they be committed to the implementation of any recommendations for action that arise.
11.
It should recognise that evaluation is potentially very threatening to those whose practice is under scrutiny, so procedures need to be devised to protect the most vulnerable.
These procedures are based on ethical principles concerning impartiality, confidentiality, negotiation, collaboration and accountability (which are expanded in Chapter 9).
Again the assumption is that no genuine change will result if the confidence of practitioners is totally undermined.
12.
It should also recognise that there is a need to protect such exercises from public scrutiny for a period so that teachers have time to acquire evaluative skills.
For this reason Simons argues that self-evaluation should be isolated from accountability demands for a time, although she also believes that school self-evaluation could provide the most positive form of accountability procedure in the long term.
Once more her argument rests on the potential of self-evaluation to influence change.
Examples of evaluations by teachers in schools
All that has been said so far has, of course, been at the level of advocacy.
It has concentrated on the proposals of educational writers concerning approaches to inside evaluation that schools and teachers might be encouraged to adopt.
Very little has been said about what actually happens or, at least, there are still few readily available accounts of school evaluations conducted by teachers.
Moreover, those published have never been analysed to see whether they reflect the theory.
In Australia the Teachers as Evaluators Project has collected descriptions of school-level evaluations for inclusion in three bibliographies.
Nevertheless the project team was forced to admit that: ‘Data about teachers and schools which have carried out school-level evaluations are fairly limited, particularly  with respect to follow-up activities’.
Much the same is true of the UK, although a few case-studies of school-based evaluation activities are beginning to appear in the literature.
This apparent lack of evidence cannot, however, be taken to imply that school-based evaluation exists only in the minds of educationists.
After all, if its purpose is professional development and curriculum improvement, there is no reason why schools and teachers should disseminate what they do farther than the bounds of their own school community.
The question of what is going on ‘at ground level’ is  nonetheless interesting and potentially important because schools that have experience in evaluation have much to offer those who are just beginning to establish procedures.
It was for reasons such as these that in June 1981 we used the educational press to invite schools, colleges, and teachers to contact us if they had ‘undertaken self-evaluation, self-assessment, self-monitoring or curriculum review’.
We had some 200 replies, a large number of which were from LEAs and INSET providers who supplied us with policy documents or general literature.
However, we also received a little over fifty responses directly from individual schools and colleges giving details of particular activities.
Concentrating first on this small group we attempted a descriptive analysis of each activity and used these to compile what we called, rather cumbersomely,A First Review and Register of School and College-initiated Self — evaluation Activities, in the United Kingdom (James, 1982).
Since our sample was self-selected it is impossible to say what proportion of the total number of self-evaluation activities it represents, or whether the range of activities is in any way typical.
If in 1981 there were only a little over 50 recognisable activities of this kind, then educationists writing about school-based evaluation may have something to worry about.
One assumes that there were considerably more, although it is interesting that some of those activities reported to us had already been reported elsewhere.
A few short descriptions of the kinds of activities reported to us may serve to illustrate some of their range and variety.
In accordance with the main theme of this book the accounts given here are drawn from the school sector (primary and secondary) and concentrate on activities that were conducted at the level of the whole institution  (although, in practice, the whole of the school may not have become involved).
By way of qualification it should be noted that the descriptions are based mainly on documentary evidence; thus they lack the richness, and perhaps the verisimilitude, of ‘in-depth’ case studies.
Certainly they are incomplete in terms of the kind of information we might have elicited through observation, interview and questionnaire.
Four accounts follow.
Obviously they cannot raise all the issues connected with insider evaluation so other examples are drawn on, but in less detail, in the final ‘Issues’ section of this chapter.
Quintin Kynaston School is an eleven to eighteen mixed comprehensive in North London.
It was formed in 1969 by the amalgamation of two single-sex schools on the same site.
For the first four years of the new school's existence the buildings were used much as they had been prior to amalgamation, but in 1974 organisation was rationalised to provide departmental areas with teaching rooms and adjacent resource bases.
This re-organisation enabled the introduction of mixed-ability teaching in years one to three, in all subjects, and a decision to this effect was taken at a full staff conference in early 1974.
The idea of co-operative course planning grew naturally out of this commitment to mixed ability teaching and in October 1976 a second staff conference embraced the idea that an emphasis should be placed on ‘the learning process in all courses’.
Since 1976 a number of working groups have met to consider ways of promoting effective learning across the curriculum.
They include working groups on social education course development, mixed-ability teaching, language across the curriculum, numeracy across the curriculum, study skills development, multicultural and anti-racist education, and sexual differentiation in schooling.
Their work is co-ordinated and reviewed by a Support for Learning Group (SLG).
Alongside the efforts of these ‘across the curriculum’ working groups there has been a commitment to review the work of courses, departments, and faculties.
Again however the emphasis is on co-operative effort and, at the end of the 1979/80 year, the school set about producing review reports that would ‘collectively reflect the ways in which staff plan and organise children's learning’.
The format for these reports, agreed by the heads of department, invited consideration of course aims, course planning and organisation, co-operative planning and teaching, record-keeping and continuous assessment, finance, staffing, accommodation, timetabling, moderation and evaluation.
In the first instance reports were compiled for each course (e.g. 3rd year music, lower school drama, the pottery courses, CSE Mode I  maths, upper school biology) by course co-ordinators.
These were then collated by the head of department who sometimes added an overview.
Individual department reports were then compiled into faculty reports by the head of faculty who again added his/her own comments.
In most cases heads of faculty picked up general issues that had emerged during the reporting process e.g. public image, relationships between subject departments, staff support (or lack of it) for extra-curricular activities.
The final collation was then made by the headteacher who again added comments on general issues and problems, and established the school's priorities for the next year.
The number of reporting levels involved almost every member of staff in writing one or other of the reports.
According to the headteacher the intention was ‘to give as many staff as possible a sense of responsibility of teaching and learning’, despite the fact that ‘as in all schools we have a hierarchical structure of responsibilities’.
When the final report was produced it was circulated internally amongst staff and presented to the school's governors and the section of the ILEA inspectorate most concerned with the school.
The commitment to whole curriculum planning and review represented in the final report suggested a need to investigate further the implications of whole school curriculum development.
Thus the publication of the review reports was immediately followed by a proposal to mount a major three-year research project.
The essence of the proposal was a request to the ILEA for funds to second one of the school's teaching staff for a period of seven terms, and for support in obtaining an outside consultant, secretarial assistance, and advice from various agencies including the ILEA's Research and Statistics personnel and university researchers.
The aims of the project were to be ‘process-oriented’ in that they were concerned with evaluating the process whereby the school promotes learning across the curriculum, and the extent to which policies (intentions) are ‘part of the actual learning’being experienced by pupils.
They were also ‘development oriented’ in that the findings were to inform action to ‘improve the quality of the curriculum’and ‘to identify priorities for in-service training’.
In terms of research procedure the project was envisaged as having three stages.
In the first stage the Support for Learning Group would identify and publish the criteria to guide classroom observations.
These were intended to cover areas such as language use and the acquisition of study skills.
Technical advice on classroom observation was to be sought from  various advisory bodies, and agreement to the principle and procedures of the research was to be sought from teaching staff at a staff meeting.
Other INSET and resources support was also to be organised at this point.
Observation was to constitute the major part of the second stage of the project.
This was to involve lesson observation, and related discussion with the class teacher; analysis of teaching material, departmental policy documents, and student ‘products’; discussion with course planning teams; monitoring learning outcomes and dialogue with students; involvement with INSET activities and dialogue with outsiders; and commissioning, training, monitoring and debriefing co-observers.
The third stage of the project was to involve reporting and discussion at the end of the observation period, although it was acknowledged that incidental feedback in the context of dialogue with teachers, students and outsiders was inevitable, and that smaller, interim reports to the SLG, as steering group, would be necessary.
In addition to the production of reports, the research would also be expected to collect and disseminate examples of good practice.
In actuality this particular research project got no further than stage one.
It became clear to the teachers that many of the objectives of the research model identified above could be achieved by building up skills of co-observation and self-evaluation within and between teachers.
Further, self-evaluation was found to be most profitably focused in departments and on those structures which brought departments together to develop and evaluate whole-school policies.
The idea of classroom observation encouraged some teachers to observe each other, and one group, for example , began some research on girls' talk.
By 1987 the SLG had been redefined as the Curriculum Review Group (CRG) and during 1984–5 had reviewed the 14–16 Curriculum to make it more accessible to all, and in particular to reduce gender and class disadvantages and increase its coherence.
This resulted in a new curriculum structure, and the CRG is now reviewing the 11–14 curriculum.
The Staff Development Group is exploring the possibility of extending the observation and self-evaluation process to review and sustain these developments.
Sir Frank Markham School is in the unusual position of undergoing expansion.
Situated in Milton Keynes, it first opened its doors in 1979 as a purpose-built comprehensive for boys and girls between the ages of twelve and sixteen.
In 1980, after only one year's work with the ‘entry’ year of pupil intake  (the 12/13 year olds), the seventeen existing staff were asked to submit a written appraisal of their work.
Subsequently each was interviewed by the headteacher.
In the following year, 1980/81, the staff had grown to 53 and two year groups of pupils were now in the school.
The larger school required a more formal review procedure and a number of activities were initiated.
In June 1981 a whole staff conference was convened to consider specific issues such as examinations, the needs of the less able, and the needs and demands of the older pupil.
In addition, two review procedures were instituted: a staff review, under the aegis of the Deputy Head (Staff Development), and a curriculum review, conducted largely by the Deputy Head (Curriculum Development).
The staff review of performance was intended to ‘look carefully at what we do now in order to do things better’.
The exercise based on individual reports, attempted the previous year, had been modified to render the activity less threatening, and to reduce the workload placed on staff.
Therefore, although a copy of suggested questions was issued to all staff individually, only the head of faculty was expected to submit a written report, on the basis of informal discussion with individual faculty members.
Suggested areas for consideration included aspects of the school environment, communication, responsibilities and achievements, priorities and improvements.
These areas were framed in a checklist of questions, which covered issues of both individual and collective concern.
For example:
What is the general appearance of our faculty/my room?
What visual evidence is there of the quality of children's work?
How noisy is the faculty/my room?
How do the children move to and from the faculty and within it?
Can we welcome a visitor at any time without worry?
Or what sort of worry?
Does everyone in the faculty know what is happening about a) syllabus; b) money; c) timetable?
Does the head teacher know what the faculty thinks on major matters?
Who has responsibility for what?
What are my/our priorities for the coming term/year?
How far are my/our teaching aims hindered by: timetable structures; lack of resources; school policies; faculty policies?
Each head of faculty's final report was duplicated and copies were given to each faculty member, the headteacher, and the appropriate deputy head.
The headteacher then discussed each report with the  head of faculty after discussions between the member of each faculty (other than the head of faculty) and the deputy heads.
At first this procedure evoked a strong reaction from faculty heads who perceived the dangers of over-personalised accounts.
Indeed some reports proved to be fairly personal, identifying the practices of individuals, whilst others dealt only with general issues.
In fairness to the senior management team the original staff review guidelines emphasised that information exchange would be two-way: reflecting also any adverse effect of school policy on classroom practice.
Furthermore the deputy heads were expected to discuss their work with the head teacher, and a visit by two members of the LEA's advisory service was intended to provide an opportunity for the head to ‘account’ to his peers.
In the school year 1981/82, the staff review exercise was repeated, but once again with modifications.
This time a decision was taken to place the process at the beginning of the school year.
Although the faculty-based approach was retained, the scope of the activity was limited by stressing a group ‘objectives-setting’ exercise aimed at the forthcoming year.
The intention was to change the tone of the activity from retrospective to forward-looking, thus emphasising its constructive nature and again reducing any threat (especially to senior staff).
During the academic year 1984/5 another system of staff review was introduced as a development of the earlier one.
This was based upon an annual interview of all staff by the senior member of staff responsible for their work (for example a head of faculty).
This was a formal process which focused on staff development by setting goals for the coming year.
Guidance was given on the conduct of the interviews and a list of questions was provided to assist the tasks of reviewing the work of the teacher and setting targets.
The teacher was also given time to prepare for the interview.
At the time when this scheme was introduced it was recognised that schools would be required to have some such arrangement in the future.
As we pointed out in Chapter 1, the school was right in its prediction!
In some senses a review of the work of staff, taken faculty by faculty, inevitably encompasses an element of curriculum review.
However, in the summer term of 1981, the ‘entry-year curriculum’ was taken as a specific focus for evaluation.
In this instance the issue of accountability was a principal and explicit motivation, and the need for a curriculum review was placed in the context of the need to provide information for the headteacher, the school governors, ‘feeder’ schools, and the LEA.
The need to ‘take stock’ after the first year of the  school's existence figured prominently, and recent publications from DES, HMI and the Schools Council regarding the whole curriculum (see Chapter 3) also gave impetus to the activity (although these documents appeared some time after the review had been initiated).
The exercise was divided into three stages.
The first consisted of an analysis of curriculum content and teaching methods conducted by questionnaire.
Perceiving a need for authority and direction if the exercise was to have credibility, the Deputy Head (Curriculum Development) took the lead in proposing sample questions as a ‘cock-shy’ for discussion.
These were then debated by a working party of representatives from each faculty, who transformed them into ‘a palatable form for staff to use’.
The questionnaire which was eventually devised was designed to elicit information concerning:
1.
Faculty/department aims/goals/priorities/intentions expressed in terms of concepts and/or skills.
Teachers were also asked to assess the extent to which these concepts or skills contributed to the HMI eight areas of experience and their degree of relevance to pupils in terms of getting a job; personal development; subject development; leisure, and so forth.
2.
Teaching and learning methods, including the proportion of class-time spent on individualised learning, small group work, or whole class teaching and the nature of homework tasks.
3.
The nature of the results teachers believed they achieved (i.e. reported outcomes).
4.
Methods of evaluation and subsequent action.
5.
The degree to which the work of faculties/departments overlapped, and the extent to which co-operation was desired.
Some guidance was provided to teachers completing the questionnaire in order to familiarise them with the HMI eight areas of experience and to agree meanings of terms such as‘concept’ and ‘skill’.
For some questions, particularly those connected with (1) above, teachers were asked to use a printed schedule and a 5-point rating scale for their answers.
(A short section from the Maths report illustrates its use.)
Apart from the obvious element of subjectivity involved in scoring the contribution of subject teaching to various areas of the pupil's experience, some teachers seemed to have difficulty in identifying concepts.
Whereas the maths syllabus was organised around concepts (e.g. shape, plane, enlargement, volume), the humanities syllabus, for instance, dealt with topics (e.g. health and fitness, history   and archaeology, ancient Greek, local studies) and these also tended to be listed under the ‘concept’ heading.
Nevertheless, once the questionnaire data had been collected and compared the Deputy Head (Curriculum) was able to present a summary report which included sections on: the relative contribution of subject areas to the eight areas of experience; the nature and degree of relevance assigned to subject teaching; a selective summary of the skills taught by various faculties; an account of the way departments justified their teaching methods; an analysis of subject overlap; a description of evaluation procedures; and a department by department judgement of outcomes.
Among the interesting things to emerge from this first study was the way in which teachers equated formal evaluation exclusively with pupil assessment.
They had no systematic means of monitoring the effectiveness of teaching and learning processes.
Stage 2 of the curriculum review went some way, therefore, to provide more verifiable data.
This involved classroom observation, by the deputy head, in the form of a shadow study of one class for the period of a week.
The intention was to gain some insight into ‘the whole curriculum at operational level’.
Observation' gives more details of these).
It is evident that the deputy record lesson format, materials used, pupil activities, teacher involvement and questioning, pupil responses, etc.
(Chapter 8 on ‘Direct Observation’ gives more details of these.)
It is evident that the deputy head soon realised that he had set himself an enormous task, despite the fact that he decided to focus on the work of three ‘target’ pupils.
Nevertheless the exercise resulted in an evaluation report, which, like the report of Stage 1, contributed to the thinking of Stage 3.
Stage 3 was perhaps the most important of the project's three stages.
Questions and issues arising in the course of the earlier work were collected into a discussion document to be considered by various groups of staff including the senior policy-making body, heads of department, faculty and tutor meetings, and appropriate working parties.
Wherever relevant reference was made to The School Curriculum and The Practical Curriculum (Schools Council, 1981) as well as the ‘entry-year evaluation’ study.
The document was divided into sections concerning curriculum content, overlap, teaching methods, relevance, and evaluation.
Each contained a number of recommendations for consideration and future action.
Among these a need for cross-curricular study featured prominently, as did various areas where curricular provision had yet to be developed (e.g. the tutorial programme, a life-skills' curriculum, curriculum provision for the able child).
In addition, although the deputy head was clearly exhausted by the enormity of the task he had set himself, he had found the experience sufficiently valuable to recommend that all teachers should extend their understanding of curriculum evaluation and develop skills in addition to the testing of  pupil outcomes.
Indeed he went so far as to suggest that pupils might be involved in evaluating the curriculum in the future.
His final recommendation, therefore, was that evaluation should become a continuous process in which all faculties and departments should be involved; that it should examine teaching and learning in all year groups; but that it should perhaps be less wide-ranging and more focused than this first effort.
In the year 1981/82 it became clear that the evaluation project had had a number of ‘spin-offs’, for instance:
1.
teachers in ‘feeder’ middle schools were invited to read the study and two schools subsequently redesigned their humanities course to provide continuity with the curriculum at Sir Frank Markham;
2.
working parties on able pupils, social and life skills, and community education had been formed;
3.
a number of faculties had begun to follow up specific issues e.g. integration between science and maths, and art and recreation;
4.
the Deputy Head (Curriculum) worked with the Head of Additional Studies Faculty to produce a framework for a study-skills course which would link with the work of all other departments;
5.
the Humanities Faculty, having been rather disturbed by one or two things that emerged from the study, decided to meet in someone's house the day after the end of the Christmas Term.
There it began a review of its work which continued, at intervals, throughout subsequent terms;
6.
the exercise encouraged greater communication with governors (a number of whom read the whole study), and between the Deputy Head (Curriculum) and more junior staff (who seemed to be more willing to ask for help);
7.
it also helped to take some of the ‘sting’ out of the staff review, and paved the way for further work e.g. the planning of an evaluation of the 12–16 curriculum with respect to areas of experience and skills.
The process begun in 1981 was continued and developed during 1983/4 and 1986.
In 1983 the whole curriculum for pupils aged 12–16 was reviewed through the production of two important documents.
The first was a ‘Curriculum Digest’ which contained a statement for all areas of the curriculum on aims, syllabuses and contributions to the areas of learning and experience identified by HMI.
A Curriculum Co-ordinating Committee (CCC) was responsible for editing this document to represent the work of each area in a standard format.
The digest was circulated to  all staff and to governors together with a questionnaire asking for comments under headings such as: organisation of the curriculum; aims of faculties/subjects; core and options in years 4/5.
The CCC also drew up a questionnaire for teachers in charge of subjects/heads of departments/heads of faculty to be completed in collaboration with other staff.
This second questionnaire covered a wide variety of issues including priorities in the aims, contributions and importance of the school as a community school, group work, special areas of the curriculum (e.g. health education, multicultural education), co-ordination of teaching across subject divisions, employment and in-service training.
These documents were discussed by the whole staff, by governors, and finally by the Senior Management Team, who proposed changes which were again submitted to staff for their views.
This process of collecting and discussing information involved staff at all levels, although faculty representatives on the CCC played a central role.
The changes decided centrally were structural and left changes in curricular content and teaching methods to faculties.
For example, the school day and week were changed to increase the number of periods but reduce the amount of time pupils spent moving around the school between lessons.
New courses which resulted from these changes began in September 1984 and parents were kept informed at all stages.
The shadow study, which formed part of the 1981 review, was repeated in 1986.
The deputy head who carried out the original study was willing to repeat the exhausting exercise, even though he was also responsible for the CCC.
The second shadow study was a true repeat of the first, although some of the schedules were changed.
Thus comparisons could be made which revealed progress in some areas and decline in others.
For example, the incidence of group work appeared to have declined although caution had to be exercised in interpreting results because there were inherent problems in sampling particular weeks for study (see Chapter 8).
At the time of writing, changes proposed as a result of this study had not yet been implemented.
Nevertheless, the whole review programme was testimony to the school's commitment to a continuous self-evaluation policy as integral to its decision-making process.
Priory Roman Catholic Primary School is to be found in Eastwood, Nottingham.
Two infant and three junior classes cater for children from five to eleven although no class contains children with more than two years' difference in their ages.
In January 1981, the whole school embarked on work connected with a single language-based topic.
The motivation for the project was: staff recognition of a need to evaluate whether children made any real progress in their written work between 1st year infants and 4th year juniors; whether too much was expected too soon, and whether it is possible to decide an age when the average child could be expected to be competent in certain skills; whether the language curriculum throughout the school was sufficiently broad in terms of coverage or whether there was unnecessary duplication; whether the most able children were being stretched enough; whether there was any justification for ‘setting’ across classes for certain kinds of work; whether pooling teacher energy and resources on a common topic increased intra-staff awareness and co-operation, and co-operation and interest among children from different classes; and finally, whether whole-school topic work appeared sufficiently worthwhile in terms of children's learning experiences to warrant repetition at some future date.
Described in this way the aims of the project appear to have been ambitious; the teachers believed them to be quite modest.
The initial stimulus for the work was a story:The Shrinking of Treehorn by Florence Parry Heide.
This acted as the literature focus around which seven learning tasks were devised.
They were not all preplanned; some of the later activities developed naturally out of those that came earlier.
However, each task was intended to give children the opportunity to exercise a range of reading, writing and other language skills.
Thus:
TASK 1 asked children to use their imaginations to predict the end of the story, both orally and in writing.
TASK 2 required simple recall in the act of narrating part of the story already told.
TASK 3 focused on sentence construction in the context of formal letter writing.
TASK 4 asked children to draft, revise and redraft a poem with a given theme.
TASK 5 was similar to TASK 4 but lots of class preparation was substituted for the individualised re-drafting process.
TASK 6 required children to write instructions and explanations relating to some game familiar to them.
TASK 7 demanded that they express their personal feelings in relation to the experience of being ignored or bored.
These seven pieces of work were designed to enable across-class comparison and analysis, but over fifty other topic-related activities  involving art work, mathematics, science, music, environmental studies and various kinds of research were also suggested in order to give each class and its teacher a measure of autonomy over the way their work progressed.
Clearly some of this work was beyond the scope of the youngest children, nevertheless the reception class joined in wherever possible and their teacher attended all staff meetings and discussions.
Her comments were considered especially important since, not being quite so involved with the work, they were perhaps more detached.
Each of the main pieces of work was allocated approximately one week in the spring term of 1981.
At weekly evening meetings staff discussed their observations of their own classes and took decisions regarding what seemed to be required in terms of teaching strategy, expectations, or reinforcement.
In some cases these evaluations were formative in relation to the next main piece of work; thus when the task of story narration (TASK 2) did not appear to encourage children to use full stops, and capital letters, teachers suggested that formal and structured letter writing was more likely to help with the structuring of sentences.
Observations on TASK 3 appeared to support this hypothesis.
At the end of the term and the completion of the topic, staff agreed that satisfactory progress seemed to be made from year group to year group in terms of the development of writing skills.
They were confident that it was possible to make general statements about improvements across a year group, despite individual differences.
However they also felt that they had been expecting most children to write in sentences at too early an age.
Apparently all teachers of junior children ‘found sentences the most difficult thing to teach; the most difficult thing for children to learn; the most irritating thing when correcting work; and decided that all hard work on sentences in the past had little effect.’
Brought to the surface in this way, this problem supplied the staff of the school with a common concern to focus on in its future work.
At the time of writing they are still working on this, although they no longer expect an immediate or easy solution.
Amenable to more immediate action was the decision to write into the syllabus certain activities concerning language skills.
Staff agreed that unless this was done it was likely that some areas would inevitably be overlooked.
In this way, as in others, the project directly contributed to the formulation of the school's future language policy.
Unlike the other activities which we describe in this section, there was no outsider initiative, input or audience in relation to the efforts of  this school's staff.
A report of the work was typed by the school secretary but its informal style and the sometimes cryptic references to individual children make it clear that it was intended for internal circulation only.
A slide show of the work of one class was presented to parents but this was a familiar procedure and not regarded as ‘giving an account’ or involving parents in the evaluation of teaching .
The staff might have been helped by an outsider who could question those things that teachers generally take for granted (for instance, by asking what they meant by their habitual use of the term ‘bright children’), or who could suggest an appropriate range of evaluative techniques.
On the other hand, the staff felt that the project would have taken a different form and provoked different responses from teachers if an outsider had been present at meetings.
In particular they felt that they might have tried to cover up their worst failings and made a public show of only their more successful work.
Even without any contribution from outsiders, the teachers at Priory School revealed a considerable capacity to innovate.
They discovered for themselves the value of taking note of the way pupils write of their school experience; and by passing unnamed ‘pupil products’ around the staff group, they devised a way of cross-checking and standardising the assessment criteria that each was using in grading children's work.
Modest and unsophisticated though this activity may appear to the educationist there is little doubt that it issued in some constructive change in the school, not least, one suspects, in the degree of staff cohesion.