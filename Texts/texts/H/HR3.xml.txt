

4
Computers in Cartography
4.1 INTRODUCTION
The end-product of the cartographic procedure is the map.
Most people think of maps as hand-drawn paper-and-ink products, but now the production of maps by computer, either plotted on paper or drawn in the form of images on a graphics screen, is becoming commonplace.
Digital maps are more easily adapted to a user's needs, especially when automated cartography is combined with spatial database management within the context of a Geographical Information System (Chapter 7).
Automated cartography, or digital mapping, is the process of storing, editing and generating maps using a computer.
The production of block diagrams and other representations of spatial data in graphical form is also part of automated cartography.
The effect of computer mapping techniques on traditional cartography has already been considerable.
Digital mapping has been one of the strongest driving forces behind the development of Geographical Information Systems (GIS).
Monmonier (1982, p. 2) believes that ‘the digital computer has had a profound effect on maps, an effect that will equal or surpass the changes in mapping occasioned by the invention of the printing press and the discovery of photography’.
Yoeli (1982) gives a very useful summary of many of the algorithms used in digitial mapping, including FORTRAN program listings.
Significant developments in the use of maps in the coming decades can be predicted with confidence.
Signals from orbiting satellites forming the Global Positioning System (GPS) can be used to pinpoint the location of objects on the surface of the Earth to within a few centimetres; a computer mapping system carried within a car (and receiving the car's position from GPS) could, given suitable software, be capable of displaying a map showing the car's location and suggesting alternative routes, such as the shortest, fastest, most economical or most scenic route.
Cooke (1987) reports that at least part of this scenario is now possible, for Chrysler demonstrated its Chrysler Laser Atlas Satellite System (CLASS), capable of storing 13 000 map images on optical disc, as long ago as the 1984 World's Fair in New Orleans.
Although the traditional concept of the map is changing, paper maps will continue to be widely used, because their use requires low technology (a pair of eyes, or even one eye), they are cheap to produce in large quantities, easy to store, and are well understood by the map-using community, although there is some evidence that many people are unable to relate the pattern on a map to the corresponding real-world features.
The major advantage of automated over manual cartography lies in the computer's ability to store cartographic and associated data and its speed in handling data and calculating results.
The map shown in Figure 4.1 took only a few minutes to produce, and is easily amended and redrawn.
A manually-drawn version of the same map would take many hours to produce.
A manually-produced map cannot be easily changed, whereas a computer-drawn map takes its data from a database (as described in Section 2.4); this database can be readily edited and updated when new information becomes available, or amended when information becomes out of date, and a new map can then be automatically redrawn.
In addition, because a computer-produced map can be redrawn quickly (or viewed on a graphics terminal) the cartographer can experiment with different contour intervals, or levels of shading, and can try different perspectives and projections with ease.
Maps can be generated digitally to suit different needs.
For example, gas, water, and electricity utilities require maps showing the locations and attributes of pipelines or transmission lines, and local authorities need maps showing bus routes and frequencies, locations of street lights, or positions of police stations (to take a few examples).
In the past, such maps have been time-consuming and expensive to make.
Other users of digital maps will include automobile associations, who will keep base maps of their areas in digital form and quickly display a map showing the relative positions of the broken-down car and the nearest mobile service unit.
Because the map coordinates of the locations of the car and the service unit are represented digitally, the shortest or most convenient route between the two points can be worked out automatically.
In this chapter the hardware and software aspects of automated cartography are described.
Examples of the use of two widely-available software packages for automated cartography (SYMAP and GIMMS) are given, using datasets which are listed in the appendices.
These datasets are also available from the author on a 5.25-inch floppy disc in MS-DOS format.
4.2 HARDWARE FOR COMPUTER MAPPING
The equipment (hardware) required for computer mapping can be divided into two kinds: that required to ‘capture’ cartographic data from existing maps and that required to display newly-derived maps.
Capturing data is called digitizing; it is the process of converting information to numerical form.
Digitizing existing maps is essential if the data derived from decades of surveying   (topographic, geological, pedological, and so on) are to be made available to digital cartographic systems.
Figure 4.1 Machine-drawn contour map.
(By courtesy of M. J. McCullagh.)
4.2.1 Hardware for digitizing
Digitizing means the conversion of information from analogue representation to numerical form.
A paper map represents geographical information in analogue fashion, using lines and symbols.
A digital map is essentially a numerical description of these lines and symbols.
The (x, y) coordinates of points.
lines (i.e. sets of points) and areas (defined by sets of intersecting lines), together with numerical descriptions or feature codes describing each point, line or area constitute the cartographic database.
A digital mapping system requires a cartographic database in addition to the software and hardware required for the editing, compilation and production of maps and related products.
A great deal of information already exists in the form of paper maps, and considerable efforts are presently being made to convert this analogue data to computer-compatible form.
Digitizers are machines which perform this task.
A manual digitizer consists of a digitizing table and a pointer.
The electronic hardware associated with the digitizer can determine the position of the pointer on the table whenever a button is pressed.
Each map feature (whether it be a point or a sequence of points defining a line) is digitized placing the pointer at the location whose coordinates are required and pressing a button.
The coordinates are then transmitted to the host computer.
A description of the feature located at that point can also be entered into the host computer using a keyboard.
The point may be a single entity, such as a church or other building on a 1:50 000 map, or it might be one of a string of points describing a linear feature such as a river, a contour line, a road, a railway or a boundary line.
Each map entity (point, line or polygon) has a feature code or description associated with it in the database.
The database itself is structured according to the uses to which the data are to be put (Section 2.4).
More elaborate digitizers can be used in ‘streaming’ rather than‘one-shot’mode.
If the operator is following a linear feature, such as a contour line, the digitizer can be switched to streaming mode and the location of the pointer recorded at some specified time interval, such as every tenth of a second.
The digitized points are therefore relatively far apart on straight, uncomplicated, sections of line but are more closely-spaced whenever a complicated curve is being followed.
Manual digitizing is slow and error-prone.
If the map can be represented in raster format (Chapters 2 and 5) then image-processing operations can be used to enhance the map image so as to bring out linear features more clearly, and automatic line-following algorithms can be employed to generate the numerical coordinates of points along the lines.
Whenever the algorithm cannot decide unambiguously which line to follow (for example, at the intersection of two  roads, or at a railway junction or a river confluence) then the operator is asked to resolve the ambiguity by making a choice.
No algorithm is yet capable of deciding on a feature code for the line being followed, so the operator is also required to add feature codes describing each line (for example as a motorway, a pylon line or a county boundary).
The fineness of the detail that can be seen on the rasterized image depends on (i) the size of the pixels, termed the spatial resolution of the system, and (ii) the number of grey-levels that can be represented by the system.
On a drum-scanning system the map to be digitized is laid on a rotating drum and a sensor is passed across the map; one pass of the sensor generates one line of the raster.
At each of a large number of points along the raster the sensor records the level of grey in its area of view.
These points are called pixels (for picture element).
The grey level is expressed as a number, normally on a 0–255 or 0–1023 scale, so that the resulting raster representation of the map contains sufficient spatial and contrast resolution.
Cheaper rasterizing systems can be built around a conventional remote-sensing image display system such as that described in Chapter 5.
A vidicon TV camera can provide an input to such systems, and the image from the TV camera is stored in a memory bank just as if it had been read from a disc file (as would be the case with a remotely-sensed image (Chapter 5)).
The pixel size of the TV-scanned image is much larger than the pixel size generated by a drum scanner.
TV-scanned images suffer from two problems in addition to those of low spatial resolution (i.e. large pixel size) and relatively low contrast.
The two problems are (i) uneven illumination of the map and (ii) geometrical distortion introduced by the optical system.
Where high-quality digitizing is not justified, for example in cases where a ‘picture’ of a map is required simply as a background, then TV camera input is a cost-effective means of providing such a raster backdrop.
Details of the types of data collected by national mapping agencies are discussed briefly in Chapter 2.
The Ordnance Survey of Great Britain, as the primary mapping agency for England, Scotland and Wales, is engaged in a digitizing programme which wig result in complete digital map coverage of Great Britain by 2005.
The Ordnance Survey distinguishes between basic scale maps (at 1:1250, 1:2500 and 1:10000 scales) and derived scale maps (1:25000, 1:50000, 1:250000 and 1:625000).
Some 1:10000 maps are derived from basic scale 1:1250 and 1:2500 maps.
Digitizing began in 1973 and completion of the digitizing of the 1:1250 basic scale maps is expected by 1993 and of the 1:2500 series by 2005.
This work is accomplished by manually digitizing the field surveyors' Master Survey Drawing (MSD) which consists of the current published map sheet plus amendments noted by the surveyors.
The Chorley Report (1987) notes that it costs around £800 to digitize, check and edit one Master Survey Drawing.
The end product is a standard format magnetic tape which contains (i) coordinates defining points, lines and polygons, and (ii) feature codes for each line, point or polygon.
The feature codes (of which there are 160) indicate  the label to be given to the line, point or polygon such as fence, road, church and so on.
A single digital map currently costs £85.
The Ordnance Survey of Great Britain is now investigating methods of accelerating its digitizing programme.
In particular, rather than using manual digitization of the Master Survey Drawing, which involves a skilled operator following each line and noting the position of each feature with a pointer, as described above, the Ordnance Survey is considering the use of raster-based digitizing techniques.
The US Geological Survey's National Cartographic Information Center is also marketing digital cartographic data under the title of US GeoData.
Digital map data are available for each 7.5- or 15-minute quadrangle in four data files as described in Section 2.4.2.4.
4.2.2 Hardware for map production and display
Digital maps and related products, such as block diagrams, can be displayed either as images on a graphics terminal or in hard-copy form.
The most common form of hard-copy output device is the plotter, but for draft-quality maps and diagrams a standard line-printer or dot-matrix printer can be used.
4.2.2.1 Graphics display terminal
A graphics display terminal is a high-resolution TV set and, like a TV set, it can display either a monochrome or a colour image.
The screen is composed of an array of phosphor dots (red, green and blue-sensitive triplets in the case of a colour display screen) and these dots are arranged in the form of a matrix.
Low-resolution systems such as those associated with standard microcomputer displays have screen resolutions ranging from 320 (horizontal) x 200 (vertical) to 640 x 480 (the IBM CGA and VGA systems).
More advanced systems have screen resolutions of 1024 x 1024 or greater.
Higher screen resolutions mean either that greater detail can be perceived since the phosphor dots are closer together, or that a greater map area can be displayed at a larger scale.
However, increasing the screen resolution means that more data (defining the dot patterns) must be sent to the screen.
Since a TV screen works on the refresh principle, that is, the image on the screen is updated every  second, the data forming the displayed image must be sent from the computer to the screen every  second or the picture will fade.
For a screen resolution of 1024 x 1024 dots and a bi-level image with 0 representing black and 1 representing white the number of bits (Chapter 1) to be transmitted each second is 52428 800.
If the resolution is increased to 2048 x 2048 then the number of bits per second to be transmitted rises to 209 715 200.
These values can be halved if the screen display is refreshed using the interlacing technique which updates each odd-numbered line of the raster every  odd-numbered refresh cycle and updates the even-numbered rasters every even-numbered cycle.
Each raster is thus refreshed every  second if interlacing is used, and this reduces the data transmission requirements to 26 214 400 bits per second (c. 26 MHz) and 104857 600 bits per second (c. 105 MHz) respectively.
TV monitors differ in their data-handling capabilities — a cheap monitor will not be capable of refreshing the screen at the rate required by a high-resolution output device.
Another consideration is that monitors working in interlaced mode produce an image that generally is more prone to flicker than a non-interlaced display of the same screen resolution.
Colour display systems available for personal computers such as the IBM VGA allow the use of up to 16 colours (light and dark versions of the primary colours red, green and blue together with their combinations — yellow, cyan and magenta — plus black and white) at a resolution of 640 x 480, or 256 colours at a reduced screen resolution of 320 x 200.
Because a colour system requires three dots (one for each primary) at each point on the screen, resolution tends not to be as good as a similarly-sized monochrome display.
The number of colours available depends on the number of levels of the three primaries.
If there are only two levels (on and off) available then the number of colours including black and white is 2 3 or 8.
If eight levels of each colour can be shown then the total displayable colours number 2 8 or 256.
Increasing the number of displayable colours or shades of grey requires more memory to store the image.
More details of colour monitors are provided in Section 5.5.
4.2.2.2 Dot-matrix and inkjet printers
Both vector (line) maps and choropleth (area-shaded) maps can be produced on a printer.
The quality of vector maps is substantially lower than that of maps produced on a specialized device such as a high-resolution screen (Section 4.2.2.1) or a pen-plotter (Section 4.2.2.3), but the dot-matrix printer is both cheap and widely-available.
As the name implies, a dot-matrix printer uses patterns of dots printed within a rectangular matrix to generate individual characters.
The Epson RX-80 printer is typical of the cheapest dot matrix printers on the market.
It uses a vertical column of nine dots moving laterally across the page to produce printed characters, each of which is generated as a dot pattern within a matrix measuring six columns by nine rows.
The letter T as printed by an RX-80 is shown in Figure 4.2.
Each dot is produced by firing a pin against an inked ribbon.
In normal character-printing mode a program sends instructions to the printer to print a character string in a form such as PRINT ‘(message)’ and the printer hardware selects the appropriate dot patterns for each of the characters in the character string ‘(message)’.
The dot patterns for all printable characters are stored internally by the printer, the codes corresponding to the normal ASCIl character set described in Chapter 1.
These dot patterns are based on a 9-row  by 5-column matrix on an Epson RX-80 printer; the sixth column is left blank to form a vertical space between characters.
Other, more expensive, printers use a larger matrix; for example, the Mannesman-Tally MT-86 builds its characters in an 8 x 11 grid, while some printers use a 24-dot print head.
Figure 4.2 Letter T in the Epson RX-80 character font.
Five vertical strikes of the print-head are needed to produce a character; each strike uses up to eight of the nine available pins.
The ninth row is used for descenders (such as the tails of the letterd g and y).
A blank column separates adjacent characters.
Choropleth maps are maps which show the distribution of the magnitude of a variable such as population density for each of a set of areal units such as counties or enumeration districts.
The range of values taken on by the variable is divided into a number of classes before the map is drawn.
If such maps are produced by hand or drawn by a pen plotter, the increasing magnitude of the variable is shown by increasing density of line-shading.
Counties with low population density have sparse shading while counties with high population density have dark shading.
If the map area is represented by a matrix of cells, then the shading level in each cell can be approximated by a printable character (the upper and lower case letters A, B, C,…,
Z, the digits 0–9, and symbols such as *, +,.,
and $) or combinations of these letters, digits and symbols.
A dark shading level is produced on a printer by overlaying a combination of characters such as X, *, + and M. An example of a printed choropleth map is shown in Figure 4.9 (pp. 124–6).
MacDougal (1976) treats the topic of line-printer map production in detail.
Program packages such as SYMAP use the principle of overprinting characters to represent different levels of shading on a printer.
SYMAP can be used on line-printers as well as dot-matrix printers; the principle is the same, the only difference being that the line-printer outputs a full line at once rather than one character at a time, as is the case with the dot-matrix printer.
Figure 4.9 shows a map produced on a standard line-printer by the SYMAP package.
The advantages of this kind of map are cheapness and rapidity of production but these advantages have to be offset against the crudity of the printer map relative to the high-quality pen-plotter map.
Nevertheless, many exploratory applications do not require high-quality output and the SYMAP type of produce is adequate.
Whereas a line-printer can output only entire characters, the dot-matrix printer can output individual dots in the 6 by 9 dot matrix mentioned above.
Thus, any desired pattern of dots can be sent to the printer.
The printer is said to be in bit-image mode when this happens, for the code to fire a pin is the digit 1 and the code to leave a blank is the digit 0.
In normal bit-image mode an 80-column printer can be programmed to print 540 dots horizontally across the paper, with the number of dots printed vertically being restricted only by the length of the paper.
The number of dots per inch in the horizontal and vertical directions can be set to 72 to ensure equal vertical and horizontal scales.
The instructions needed to set the printer into bit-image mode are called escape codes because each instruction is preceded by the ASCII code 27 which is generated by the ESC or ESCAPE key on a terminal keyboard.
For example, the code (ESC) A 8 will set the spacing between lines on an Epson-compatible printer to  inch.
In bit-image mode the ninth pin on the print head (Figure 4.2) is not usually used so eight vertical pins plus the gap between the bottom pin on line i and the top pin on line i + 1 will occupy  inch because the spacing between pins is  inch.
Each byte that is printed in bit-image mode can be thought of as an eight-bit binary number with the digit 1 meaning ‘print a dot here’ and the digit 0 meaning ‘do not print a dot here’.
Eight rows of dots are printed at once by a single horizontal move of the print head across the paper.
If the paper is moved upwards by exactly  inch before the next line of eight-bit bytes is printed then there will be no gap between the lines.
Because the dots in the print-head of the dot-matrix printer can be addressed individually, lines and curves made up of single dots can be drawn.
Figure 4.3(a) is an example of a contour plot produced on a dot-matrix printer.
The individual contours are drawn as sets of connected straight-line segments between successive points x1, y1 and x2, y2 that define the digitized contour line.
A second example, of an outline map showing the international boundaries of the continent of Africa, is shown in Figure 4.3(b).
A pen-plotter normally has built-in firmware that will automatically join two points with a straight line; the command is usually JOIN (X1, Y1, X2, Y2).
The user of a dot-matrix printer has to simulate this command by (i) finding the equation of the line joining the two given points x1, y1 and x2, y2,(ii) using this equation to compute the y coordinate corresponding to each x coordinate in the range xmin to xmax, where xmin is the smaller of x1 and x2 and xmax is the larger of x1 and x2.
The equation of a straight line is given by   where x and y are the coordinates of any point on the line, a is the y coordinate of the point where the line cuts the y axis (x=O) and b is the tangent of the angle between the positive x axis and the line, measuring anticlockwise (Figure 4.4).
The terms a and b are called the intercept and slope of the line.
The slope is found from  and the intercept from  Once a and b are known then the value of y corresponding to every integer value x lying between xmin and xmax is calculated from the equation of the line and a dot is printed at the point x, y.
The result is a draft contour map which can be produced quickly and cheaply using a simple BASIC program on a small microcomputer equipped with a dot-addressable matrix printer.
More efficient ways of drawing lines and circles on dot-addressable (raster) devices such as dot-matrix printers and raster graphics screens are considered by Kingslake (1986).
Figure 4.3 (opposite)(a) Contour map produced using dot-graphics functions on a Mannesman-Tally MT86 dot-matrix printer.
(b) Outline map of African countries using dot-graphics functions on a Mannesman-Tally MT86 dot-matrix printer.
Figure 4.4 Graph of the line y = 2.04 + 0.44x.
The first term (2.04) is the point at which the line cuts the vertical axis.
This value is known as the intercept.
The second term is the gradient of the line, given by the tangent of the angle between the x-axis and the line in an anticlockwise direction.
The two points (9.6) and (4.3.8) lie on the line.
Coloured maps can be produced on a dot-matrix printer by using a printer ribbon that is divided into three parts horizontally along the length of the ribbon.
The three parts carry either cyan, magenta and yellow ink or red, green and blue ink.
The print head can move vertically up or down so that a pin can contact any one of the three pads of the printer ribbon.
This type of colour dot-matrix printer is based upon proven and reliable technology; however, the ink on the ribbon can fade if a large map is printed and the result is rather displeasing.
A better colour product can be produced using an inkjet printer.
Inkjet printers can be used in exactly the same way as dot-matrix printers.
A dot-matrix printer generates a dot on the printed page by striking an inked ribbon with a pin (the pin radius being  inch) whereas an inkjet printer produces a dot by firing a droplet of ink onto a specially coated paper, the coating being required in order to prevent the ink from running.
As the print head moves across the paper individual ink droplets are fired at precise intervals.
Characters can be built up as combinations of dots exactly as described above, while contour maps can be drawn by printing individual dots in the same way as a dot-matrix printer in bit-graphics mode.
Some inkjet printers use black ink only but colour inkjet printers are becoming a popular choice for cheap colour hard-copy output from microcomputers, as prices start at around £600.
The colour inkjet printer uses cyan, magenta and yellow inks (the so-called subtractive primary colours) plus black ink.
Red, green and blue (the additive primaries) can be formed by combining cyan, magenta and yellow dots; for example, a magenta dot on a yellow dot gives red because magenta is ‘minus green’ and yellow is ‘minus blue’, so the result is white minus green minus blue, that is , red (Figure 4.5).
A black dot can be produced by printing cyan, yellow and magenta dots on top of each other but, since the result is perceived as a kind of muddy brown, it is better to print a single black dot from the black ink reservoir.
A white dot is produced by printing nothing at all.
A colour inkjet printer can therefore print eight colours (white, black, red, green, blue, cyan, magenta and yellow).
While this is adequate for many purposes, more colours can be generated at the expense of a reduction in the number of unit map cells that can be printed across the width of the paper by the use of a procedure called dithering.
If a 2 x 2 pixel matrix of dots is used to represent a single cell on the map to be printed then up to 125 different colours can be printed.
Each of the three primary colours is printed separately for each 2 x 2 matrix, and five levels of each primary colour can be represented (no dots, one dot,…, all four dots).
Five to the power three is 125, which is the number of colours that can be generated using this procedure.
An example of a set of 2 x 2 matrices showing levels of no dot, one, two, three and four dots is shown in Figure 4.6.
For colour output the dot patterns can be rotated as shown to reduce the number of red + green + blue overprints (which are printed as something approaching black).
Choropleth maps using different colours to represent different levels of the mapped variable can be generated by specifying one of the 125 colours to be used as the area fill colour.
The disadvantage is that the number of horizontal cells is reduced from 760, the number of ink dots that can be printed  across one line, to 380 as two ink dots in the horizontal and vertical directions make one cell.
Figure 4.5 The subtractive primary colours of yellow, cyan and magenta can be mixed to produce the (additive) primaries red, green and blue.
Each subtractive primary can be thought of as taking away a component from white; thus yellow is, ‘minus blue’ and magenta is ‘minus green’so a mixture of yellow and magenta inks will produce white minus blue minus green — in other words, red.
Although an equal mixture of the three subtractive primaries will, in theory, produce black it is normal practice to use a separate black ink.
Useful maps can be produced using standard printer technology.
The line-printer, dot-matrix printer and inkjet printer each has its own advantages and disadvantages, but all can be used to generate maps ranging from draft-quality   maps such as Figures 4.3(a) and (b) to finished choropleth maps (Figure 4.9).
Further details of printer technology can be found in Byte Magazine for September 1987.
Figure 4.6 Dither matrices for red (A), green (B) and blue (C) components of a colour palette for an inkjet printer.
Note that red, green and blue are themselves mixtures of the subtractive primary colours (Figure 4.5).
If all three colours overlap (such as in the fifth matrix) then a black dot is printed from the black ink reservoir.
Dot-matrix or inkjet printers can be used to generate screen dumps or hard copies of the graphics displayed on a colour graphics monitor.
A standard dot-matrix printer can show only two states, black and white, but shades of grey can be used to represent colours if 2 x 2 or 3 x 3 dot matrices are used to display each single screen pixel.
A colour inkjet printer can display eight colours at one dot per screen pixel, though the dithering technique described earlier can be employed to extend the range to 125 colours, though at a lower resolution.
An example of a screen dump of a graphics display was used in Chapter 3 (Figure 3.6).
The example given here demonstrates the potential use of a simple dot-matrix printer, the Epson RX-80, to produce maps illustrating the use of different map projections.
Map projections are needed in order to display the three-dimensional Earth on a two-dimensional piece of paper (or monitor screen).
The transformation from three to two dimensions cannot be achieved without sacrificing one or more of the following properties: area, shape, scale and bearing.
Some projections are described as equal-area because the areas measured from maps drawn using those projections are proportional to the true ground areas they represent.
To maintain equality of area, however, shape is distorted.
Shape cannot be truly represented on a fiat map except over small areas but some map projections, described as orthomorphic, have the properties that (i) lines of latitude and longitude intersect at right angles, and (ii) the scale is the same in all directions at a given point, but the scale may differ from one point on the map to another.
Like shape, scale cannot be correct over the whole map, but some map projections can be constructed so that either the lines of latitude or the lines of longitude, or certain lines of latitude and longitude, have the scale correct.
Finally, preservation of correct bearing may be important, for example if the map is to be used for navigation.
Azimuthal or Zenithal projections can be thought of in terms of the projection of the lines of latitude and longitude on the globe onto a fiat sheet of paper which touches the globe at some point (for example, the north or south pole in the case of Polar Azimuthal projections).
Bearings from the point of contact (one of the poles) between the sheet of paper and the globe will be correct.
The Mercator projection and the Zenithal Equal-area projection are shown in the form of screen dumps in Figure 4.7.
The area shown is Greenland, Baffin Island and Canada/Alaska.
Appendix E contains a listing of the data used.
The Mercator projection is one of the most common map projections in general use.
It was developed in 1569 by Gerhardus Mercator.
Lines of latitude are shown on the Mercator projection as being equal in length to the equator so that the scale along these lines of latitude increases away from the equator; so much   so, in fact, that Greenland appears as large as Canada and Alaska together.
The poles cannot be shown because they lie at infinity.
However, lines of constant bearing plot as straight lines on a Mercator projection and this is one reason for its popularity; the course of a ship, for instance, could be plotted as a series of straight lines on a map drawn on Mercator's projection.
Figure 4.7 (a) Mercator projection map of Canada, Alaska and Greenland produced using screen dump program on a BBC micro and an Epson RX-80 printer.
(b) Zenithal Equal-area map of the same area as (a).
Many people have a mental map of the world which corresponds approximately to the Mercator projection.
They are thus likely to be surprised to find themselves crossing Greenland and Baffin Island if they take a flight from London to Chicago, or passing over Samarkand en route from London to Delhi.
Lines of constant bearing (straight lines on a Mercator projection) do not necessarily show the shortest (great-circle) route.
A great-circle route is an arc of a circle centred upon the centre of the Earth and passing through the start and end point of the journey; the great circle itself can be thought of as a circular section through the Earth and passing through the Earth's centre.
Great circle routes plot as straight lines on some map projections such as the Gnomonic.
In order to draw a map on Mercator's projection the features forming the map must be digitized; that is, the latitude and longitude of a set of points located along coastlines, rivers and other features must be known.
The latitude and longitude for a number of points along the coasts of Greenland, Baffin Island and Canada/Alaska are listed in Appendix E. These latitudes and longitudes must be converted into (x, y) plotting coordinates using the formulae:
R is the length of the radius of the Earth on the scale of the map and latitude and longitude are given in radians. 360° equals 2 radians, and so /4 radians in the equation for y is equal to 45°.
BASIC and some versions of FORTRAN contain built-in functions to convert from degrees to radians.
Figure 4.7(a) shows the data of Appendix E after (i) plotting on a monitor screen using the formulae given above and (ii) dumping the screen to a dot-matrix printer.
Since the scale on Mercator's projection becomes infinite at the north pole, the region beyond 80°N is not shown.
Some computers have a PrtSc key; if you press this key the screen display is copied to the printer.
However, a lot depends on the hardware available — you must have a printer, at least, and IBM PCs and compatibles require a special graphics card before drawings can be produced on the screen.
Special software may also be required for the PrtSc key to work.
Figure 4.7 was produced from a screen display on an Acorn BBC microcomputer.
The screen display on this machine is ‘memory-mapped’, that is, the contents of the screen are kept in the random-access memory of the computer in binary form (Chapter 1).
An assembler-language program reads the screen map and converts each picture element (pixel) to a dot pattern, suitable for printing on an Epson RX-80 printer.
The second example of a map projection shows the same region (Greenland, Baffin Island and Canada/Alaska) as was used for the Mercator example; in the present example the polar case of the Zenithal Equal-area projection is employed.
The lines of longitude are straight lines converging on the north pole while the lines of latitude (on the full map) are shown as circles.
These circles are spaced so that the area between any adjacent pair of circles (representing lines of latitude) is proportional to the corresponding area on the Earth.
The formulae to produce x, y plotting coordinates from latitude and longitude values for this projection are as follows (definitions of r and clong are given first): with latitude and longitude again expressed in radian measure.
The screen dump resulting from the application of these formulae is shown in Figure 4.7(b).
Miller and Reddy (1987) give a number of subroutines in the Pascal language for the production of maps using different map projections, and illustrate their use.
They also describe three digital data sets.
The first is called WORLD.DAT; it contains 6000 points delineating the world's coastlines.
These points were derived from (i) the US Geological Survey's ‘World Outline Map’ at a 1:40 million scale, and (ii) the US Defense Mapping Agency's ‘The World’.
The second and third datasets are at medium and high resolutions; the high-resolution datasets include international boundaries and consist of 95 000 points and the medium-resolution dataset comprises about 15 000 points.
Details of the availability of the datasets and the Pascal programs needed to make use of them are given in Miller and Reddy (1987).
Figure 4.8 shows examples of output from Miller and Reddy's programs, the output being produced on an Epson RX-80 nine-pin dot-matrix printer.
Snyder (1982) is a useful source of information on map projections, with many worked examples showing the mathematical principles underlying the major map projections.
4.2.2.3 Pen plotters
A pen plotter is a device capable of moving a pen across a sheet of paper with high positional accuracy under the control of a computer.
The pen can be either in the down position (when a line will be drawn) or in the up position.
The size of the paper is dependent on the type of plotter used; a drum plotter has a continuous paper feed (like a tractor-feed printer) with the pen position in the x-direction being controlled by the movement of the entire pen assembly at right-angles to the direction of paper movement.
The pen position in the y   direction is controlled by the movement of the drum.
The width of the drum can be 1 metre or greater.
Flatbed plotters use a single sheet of paper, fixed in position, and the pen can move anywhere over the paper area.
Flatbed plotters range in price from a few hundred pounds to several thousand pounds.
Cheaper flatbed plotters, capable of plotting on sheets of A4 or A3 size paper, can be interfaced to personal computers.
The factors that distinguish a cheap from an expensive plotter are size of plotting area, speed of pen movement, accuracy and repeatability of pen positioning and number of pens available.
A description of an xy plotter produced by the Japanese Graftec Corporation is given below.
The Graftec MP3000 x y plotters are typical of the smaller flatbed plotters used with personal computers.
Figure 4.8 Examples of screen dumps of maps produced by Miller and Reddy's (1987) program for map projections.
(a) Sinusoidal projection, and equal-area projection developed in the 16th century.
Distortion near the equator and the central meridian is small, but increases considerably towards the poles and the outer meridians. (b) Hammer projection, developed in the late 19th century by a German professor of sur is also an equal-area projection and looks more realistic than the Sinusoidal.
The screen dumps were produced on an Epson LX-80 printer.
The plotting area used by the Graftec MP3000 can be selected by setting DIP switches on the rear panel.
One of four sizes can be selected-the ISO A3 or A4 sizes (420mmx297mm or 280mm x 216 mm) or the ANSI B or A sizes (432 mm x 280 mm or 280 mm x 216 mm).
The paper is held in position by electrostatic attraction and the plotter can draw with any one of eight pens.
The pens can be fibre-tip, ball-point or ink pens.
Plots can be produced in up to eight colours with a step size of either 0.025mm or 0.1 mm and with a repeatability of 0.1 mm or less.
The choice of step size is made by setting a DIP switch.
Step size is the minimum pen movement that can occur.
The plotter has a set of built-in commands which can be used by a programmer; some examples are:
D (x1, y1, x2, y2)(draw): draws a straight line from x1, y1 to x2, y2.
If more than two sets of x, y coordinates are given then each pair in the sequence will be joined by a straight line.
M (x, y)(move): move the pen in the up position from its current point to the specified point x, y.
W (x, y, r)(circle): draws a circle or circular arc with radius r and centre coordinates x, y.
X (axis): draws x and y axes on a graph.
% (hatching): connects string of specified x, y coordinates defining the outline of a polygon and hatches inside it using specified line spacing and angle.
J (new pen): selects specified pen.
P (print): draws specified characters starting at current x, y position.
These commands can be used to draw maps and graphs by a programmer writing in a high-level language such as FORTRAN or BASIC; the D and M commands  are used to draw line segments, given the x, y coordinates of the start and end of each segment, while the P command is used to add annotation.
The % command is useful if the output map is a choropleth map.
The GIMMS mapping package, discussed in Section 4.3.2, uses commands similar to those listed above to produce high-quality choropleth maps.
Some examples are shown in Figure 4.11.
For some purposes, direct output to photographic film is preferable to paper output.
If the map is to be reproduced, for example, a higher-quality end-product is obtained if the map is output onto film for subsequent printing.
The alternative is to produce a paper map and photograph it.
A device called a film writer is available for direct output.
The commands to draw lines and characters are much the same as those listed above.
In most mainframe mapping packages it is possible to produce the map in what is called device-independent form, so that it can be output to any suitable peripheral such as a plotter, a graphics display terminal or a film writer.
If this facility is available, the map should be displayed on a graphics display terminal and checked for errors before it is sent to the film writer.
The concept of device-independent code is discussed further in Section 4.3.2.
4.3 SOFTWARE FOR COMPUTER MAPPING
4.3.1 Line-printer mapping systems
Some computer centres do not have a plotter mapping package such as GIMMS (Section 4.3.2) available for use.
In other cases the plotter hardware is physically located some distance from the user; for example, the user may be in a different building or even at a subsidiary office in another town.
He or she may be able to communicate with the central computer via a network (Chapter 1) but special products like graph-plotter output have to be sent through the postal system, and are thus not available quickly.
While this delay may not cause difficulties for the production of the final version of a map it is an inefficient way to proceed during the stage of map design.
In yet other cases a high-quality plotter-drawn product may not be required, either because the nature of the task is such that a draft product is sufficient or because the cost of producing the required number of plotter-drawn maps would be prohibitive.
An undergraduate class of 70–100 students could, for example, so dominate the use of a plotter that other staff and students might effectively be excluded from the use of the device.
Hence, even though line-printer mapping systems might at first sight appear to be of little value in comparison with plotter-based systems, there are instances when it is convenient or cost-effective to make use of them.
The SYMAP system is used in this section as an example of a line-printer mapping system; contour and choropleth maps are generated on a line-printer or dot-matrix printer (Section 4.2.2.2).
Its development was begun in 1963 by  H. T. Fisher, working at Northwestern Technological Institute, Evanston, Illinois.
Later development took place at the Laboratory of Computer Graphics, Harvard University.
Its first UK implementation was probably at the University of Edinburgh, Scotland; an early version was brought there in 1967 by Professor J. T. Coppock.
One of the most widely-appreciated uses of SYMAP in the UK was Rosing and Wood (1971) who produced an atlas of Birmingham and the Black Country.
This atlas was one of the first publications to show the value of computer mapping in geography.
SYMAP was made available to the academic community at a nominal charge, thus allowing many research staff and undergraduates the opportunity to become familiar with the concept of computer mapping.
In this section an example of the use of SYMAP to design and produce a choropleth map of the distribution of two variables over 42 countries of the continent of Africa is given.
The two variables are infant mortality per 1000 live births and gross national product per head.
Both variables are listed in Appendix A and the 42 countries are named in Appendix F. The same variables are used in the statistical examples in Chapter 3 and in the example of the use of the GIMMS plotter mapping system (Section 4.3.2).
The examples were produced using the ICL 3900 computer in the Cripps Computing Centre, University of Nottingham.
Readers wishing to run the SYMAP program on their local computer system will need to supply different Job Control instructions unless their computer centre is equipped with an ICL computer running under the VME operating system.
SYMAP was developed at a time when interactive computing was still at an experimental stage.
Programs and data were, at that time, punched onto cards using a keypunch.
Decks of cards, held together (sometimes precariously) by elastic bands were placed in input trays, collected by operators, and fed into the computer through a card-reader.
The card deck, together with the output generated by the job, was returned at a later time.
Hence SYMAP data formats are ‘fixed’ by reference to the position of the data element in terms of the 80 columns of the punched card.
Since positioning of a character on a video terminal screen is rather more difficult than punching a hole in a specified column of a card, and because today's computer users are accustomed to ‘free-format’ input (in which data elements are not defined by their position on an input record but are separated by commas or spaces), the input format demanded by SYMAP may seem inflexible and difficult.
In the present example the data were entered into a file from a terminal using free format, and a program was written to re-format the data according to the requirements of the SYMAP program.
The data used in this example are listed in Appendix G, and are available on an MS-DOS format floppy disc suitable for IBM PCs.
Stage one of a SYMAP run involves the definition of the location coordinates of the spatial units for which the data are measured.
In this example the spatial units are the 42 largest countries of Africa (Appendix F).
The countries may  be referred to as zones or polygons.
SYMAP's coordinate system is based on the row/column reference system normally used with matrices.
The first coordinate value of a pair refers to position down the page from the top, while the second coordinate is the distance across the paper from the left.
The SYMAP coordinate origin is therefore the top left-hand corner of the map area.
Most published maps use a grid system and the Cartesian reference system in which coordinates are specified as x, y pairs.
Care must be taken to ensure that the coordinates defining the line segments which are the zone boundaries are specified in row/column terms.
If the locational data are available in x, y order then, if you are familiar with BASIC or FORTRAN, or some other high-level language, it is relatively easy to write a program to reverse the order of the x, y pairs and to convert the y coordinate so that it measures distance down from the top of the page rather than distance up from the bottom.
Once the zone outline coordinates have been measured and entered into a data file the statistical variable to be mapped is specified.
Secondly, the measurements on the statistical variable to be mapped must be presented in the same order that the zone outlines are listed in the data file.
Thirdly, details of the map format are given.
These three operations — provision of zone outline coordinates, definition of data values for mapping, and specification of map characteristics — are handled by SYMAP through the use of ‘packages’.
Each package performs a specific function, and the data for each package are provided in a specified, fixed format.
The three packages used in this example are called A-CONFORMOLINES, E-VALUES and F-MAP.
A-CONFORMOLINES is used to supply the location coordinates of a set of points defining the position of the boundary of each zone.
Unlike the GIMMS system described in Section 4.3.2, the zones are digitized individually, which implies that common boundaries are digitized twice.
This can lead to problems if the same coordinates are not entered each time.
The zone boundary is considered to consist of a set of straight-line segments the end points of which are required in the A-CONFORMOLINES package.
The first and last points are the same so as to close the zone boundary.
The use of too few coordinate points will result in angular boundaries while the use of too many points is uneconomical as a printer is only capable of resolving position to within one character position.
Countries which have a very small area are not capable of being shown on a large-scale map, so the 42 zones for Africa do not include Djibouti, Swaziland, Lesotho and Mauritius.
The coordinate points defining the zones are entered into the SYMAP data file as shown below (refer also to the commands and data for this example, listed in Appendix E).
The data must be entered in the columns indicated by the horizontal ‘ruler’, and whole numbers must be given with an explicit decimal point (i.e. a whole number such as 12 should be entered as 12.0 or simply 12. but not as 12).
The package is introduced by the A-CONFORMOLINES statement.
The data for each zone begin with the zone identifying number right-justified in columns 1–5 of the first data record for that zone.
Each data record for the zone contains the vertical and horizontal coordinate for a single point; the vertical coordinate is entered in columns 11–20 and the horizontal coordinate in columns 21–30.
The last point is the same as the first, so as to close the outline.
The points must be entered with the highest point first.
The highest point is the one closest to the top of the map.
Where two points are equally high the leftmost one should be chosen.
Once the first point has been identified the remaining points are entered in clockwise order around the zone boundary.
The A-CONFORMOLINES package is terminated by the code 99999 in columns 1–5.
E-VALUES are the data values for the zones to be mapped.
These values are entered in the same order as the zone boundary definitions in the A-CONFORMOLINES package.
The World Data Matrix (Appendix A) contains data for the largest 100 countries of the world and some of the African countries whose borders have been digitized are not included.
The value -1 (minus one) is used to indicate that no data are available for certain countries (specifically: Mauritania, Guinea-Bissau, Liberia, Gabon, Congo, the Central African Republic, Namibia, Togo and Botswana).
The E-VALUES package is introduced by the characters E-VALUES in columns 1–8 of a data record.
The data values for each zone are then given in order in columns 11–20, with one data value per record.
An example is shown in Appendix G. The data are followed by the code 99999 which signals the end of the package.
The F-MAP package allows the user to choose from a number of options, called ‘electives’ in SYMAP language.
There are too many to list here; the  SYMAP documentation, available from your computer centre, provides a full account.
The options used in this example are:
Elective 1: specification of vertical and horizontal physical dimensions of the printed map, in inches (1 inch=2.54cm).
Elective 2: size of the printed map in terms of the map coordinate system.
Elective 3: number of classes into which the data range is to be divided.
Elective 4: minimum value in the data.
This elective can be used to ensure that those data with a value below that specified by elective 4 are mapped.
Zones (countries) with values less than the minimum are allocated the symbol ‘L’ on the printed map.
Elective 5: as elective 4 except that the maximum required value is specified.
Countries with data values greater than this maximum value are allocated the symbol ‘H’ on the printed map.
Elective 6: class interval specification.
If elective 6 is chosen without any parameters then the range of the data (or the restricted range given by one or both electives 4 and 5) is divided into classes such that there are an equal number of countries in each class.
If this elective is not requested then the data range is divided into classes with an equal range.
The number of classes is five unless the user opts to change this value.
Elective 8: normally SYMAP leaves a gap around the boundaries of each country.
If elective 8 is specified then this gap is omitted.
Elective 23: use of this elective will cause SYMAP not to print an invalid data point symbol for countries without data.
Figures 4.9(a) —(c) show the output from a SYMAP run using the commands and data of Appendix G. Figure 4.9(a) uses the default five classes in a map of infant mortality per thousand live births for the African countries included in the World Data Matrix (Appendix A) and named in Appendix F. Data values of — 1 are excluded by the use of elective 4.
The value — 1 is used to flag missing data; the countries concerned are shown on the map by the symbol ‘L’.
The five classes are printed using the following symbolism class 1 (.),
class 2 (+), class 3 (0), class 4 (0 and -superimposed) and class 5 (0, X and M superimposed.
Figure 4.9(b) uses the same data as Figure 4.9(a) but elective 8 has been used to eliminate the blank lines around the country boundaries.
The third map shows the distribution of values of Gross National Product in American dollars for the same countries.
Elective 4 has again been used to map countries for which no data are available.
Elective 5 has also been selected; this elective limits the upper range of the data.
The GNP per head of Libya is far greater than that of any other African country, so elective 5 was used to cause SYMAP to allocate the symbol ‘H’ to Libya on the printed map.
The data between the lower and upper boundaries specified by electives 4 and 5 are mapped so that each class has, as far as possible, an equal number of countries.
These maps should be compared with Figures 4. 11(a) —(c), which are the output  from the plotter mapping package GIMMS, which is described in Section 4.3.2.
Once the A-CONFORMOLINES and E-VALUES data have been prepared it is a simple matter to use different electives in the F-MAP package in order to alter particular settings, such as the number of shading levels, the choice of class interval (equal width, equal number of zones or user-specified), or the type of symbolism used to define the shading pattern.
The cost of running SYMAP is low since standard peripherals are used, so it makes sense to use it as an aid to map design before proceeding to a more elaborate plotter mapping package such as GIMMS.
The major disadvantage of doing so is that the data formats required by the two packages are very different.
In particular the way in which the zone boundaries are digitized is not compatible.
However, a simple data  reformatting program may be available at your computing centre to help you convert data from one format to another.
My own data format convertor takes as input a set of digitized points and allows the user to specify the order in which the x, y coordinates are written to a disc file.
Operations such as‘reverse the order of x and y’ and ‘subtract the y coordinate from ymax’can be given in order to allow the easy conversion of locational (coordinate) data from GIMMS format (Cartesian coordinate format) to SYMAP (row/column format).
The disc file produced by this format convertor program is then edited using a standard text editor.
4.9 (a) SYMAP choropleth map showing distribution of Infant Mortality for 42 African countries (Appendix F).
Blank spaces separate the countries.
Increasing density of shading corresponds to greater rate of infant mortality.
Symbol L indicates no data.
Figure 4.9 (cont.)(c) Distribution of Gross National Product for 42 African countries.
The symbolism is interpreted in the same way as Figure 4.9(a) with the exception that the character H indicates a value beyond the upper limit specified by elective 5.
4.3.2 Plotter packages
GIMMS, developed by Mr. T. C. Waugh of Edinburgh University, Scotland, is used in this section as an example of a widely-used plotter mapping package.
As in the case of the SYMAP examples earlier in this chapter, the facilities  of the Cripps Computer Centre at Nottingham University were used and specific examples of Job Control commands will require modification to suit the requirements of your computer system.
Figure 4.9 (cont.)(b) As Figure 4.9 (a) with boundaries between countries omitted.
The first task in the process of producing a computer-drawn choropleth map using GIMMS is to input the digitized map (Appendix H) as a set of line segments joining nodes (as described in Chapter 2) and to link these segments together to form polygons.
The data in Appendix H were digitized manually using an xy grid with coordinate values in the range 0–1000.
The coordinates of each point were recorded to the nearest 5 units.
Each line segment was defined by  a sequence of points joining two nodes, the nodes being points where two or more segments join.
Next, the xy coordinates of the points making up each line segment were read from the map and recorded manually, together with the identifier of the country to the left and the country to the right in the direction of digitizing (as illustrated in the 2D encoding and USGS DLG examples of data structures in Chapter 2).
The identifier SEA was used if there was no country to the right or left of the line segment.
The full description of a line segment for input to GIMMS is:
identifier of country to the left of the line
identifier of country to the right of the line
xy coordinates of points defining the line
terminator
Figure 4.9 (cont.)(c) Distribution of Gross National Product for 42 African countries.
The symbolism is interpreted in the same way as Figure 4.9(a) with the exception that the character H indicates a value beyond the upper limit specified by elective 5.
The terminator is the backslash character/ (ASCII code 47).
The ‘country left’ and ‘country right’items are the country identification numbers from Appendix F preceded by the letter Z (meaning zone).
The following GIMMS commands were entered into a file called (on the Nottingham University ICL 3900 computer system) PMMLIB.GIMMSAF.
They perform the following procedures:
(i)
input the digitized map data to GIMMS, and
(ii)
generate the linkages between line segments and so identify which line segments bound which countries:
*FILEIN SEGMENT FILEOUT = 10 FILENAME = AFRlCA
TITLE = ‘AFRICAN COUNTRIES GIMMS SEGMENTS’
LIMITS 0,0, 1000, 1000
BEGIN
SEGMENTS
…
GIMMS line segment descriptors as described above and listed in Appendix H…
END
*POLYGON FILEIN = 10 FILEOUT = 11 ALPHA EXCLUDE ZONE = SEA
*STOP
The *FILEIN command tells GIMMS that a data file is being input.
The qualifier SEGMENT indicates that this is a file of line segments.
FILEOUT = 10 means that the line segment file will be stored in a file connnected to unit 10 (unit connections are specified in the Job Control commands, which are described below).
TITLE can be used to add a descriptive comment to help identify the file at a later stage.
LIMITS gives the xy coordinates of the lower left and upper right corners of the map area.
The line segment data are introduced by the words BEGIN and SEGMENTS and are terminated by the word END.
At this stage, when the commands are executed, the line segment data will be stored in a file connected to unit 10.
The *POLYGON command is a GIMMS instruction to fetch the file whose unit number is 10, read from it the line segment data, and link the line segments together to form polygons.
The polygon definitions are written to the file whose unit number is 11.
ALPHA tells GIMMS to store the zones in alphabetic order of their identifiers, so that Z01 comes before Z02, and so on.
This is important because the statistical data to be mapped must be associated with the correct zone.
EXCLUDE ZONE=SEA is used to eliminate from consideration the zone whose identifier is SEA.
This identifier was used whenever the zone to the left or to the right of the line segment being digitized was sea.
SEA can be considered as the identifier of the zone that surrounds the digitized map of Africa.
The GIMMS commands and line segment data described above are stored in a file called PMMLIB.GIMMSAF on the Nottingham University ICL 3900 computer system, as described in the preceding paragraph.
This computer system, like other multi-user mainframes, requires that each job or task be preceded by introductory commands and followed by terminating commands.
In the case of the Nottingham system the Job Control commands needed to define the GIMMS task are:
JOB (NULG.LGPMMGIMMS 1, STA = 3)
ASSIGN-OUTPUT-FILE(PMMLIB.GIMMSPOLY, OPEN-ON = 10)
ASSIGN-OUTPUT-FILE(PMMLIB.GIMMSPOLYl, OPEN-ON = 11)
GIMMS (INPUT = PMMLIB.GIMMSAF)
ENDJOB
The JOB command tells the operating system of the ICL 3900 which individual is running this job (PMM), what his university (NU), faculty (L) and department (G) are, the name of the job (LGPMMGIMMS1) and the priority to be given to the job (3 on a scale 1–5).
The JOB command will differ from one computer to another, as will the next two commands which relate filenames to unit numbers.
The ICL VME operating system command to relate the file PMMLIB.GIMMSPOLY to unit number 10 is ASSIGN-OUTPUT-FILE.
Two output files are created by the two ASSIGN-OUTPUT-FILE commands.
One (on unit 10) will hold the line segment data and the second, opened on unit 11, will contain the polygon definitions.
The polygon definition file will be used in a later program run when the polygons will be associated with statistical values (one of INFMORT or GNP in these examples).
The GIMMS command tells the VME operating system to activate the GIMMS program, using the instructions contained in the file PMMLIB.GIMMSAF.
The Job Control instructions terminate with the ENDJOB command.
The Job Control commands are themselves placed in a file, using a text editor.
I used the filename PMMLIB.GIMMSJOB1 to hold the Job Control  commands.
This file is then sent to batch queue number 3 (because STA=3 was entered on the JOB command line).
Batch queues are described in Chapter 1.
The ICL VME operating system command to enter a file of Job Control commands into a batch queue is SUBMIT-JOB or SBJ for short, so the command SBJ(PMMLIB.GIMMSJOB1) entered on a terminal will ask the VME system to place the commands held in the file PMMLIB.GIMMSJOB1 into the queue number specified on the JOB command line.
Other computer operating systems have a different but synonymous command, for example SUBMIT on a DEC VAX/VMS system.
The jobs in the batch queue are executed when they reach the head of their particular queue, and the output is sent to the system line-printer.
A sample of the printer output from this GIMMS job is reproduced as Figure 4.10.
Each polygon or zone is identified by its zone identifier (Znn in Appendix H) and the number of bounding line segments is given.
The ENVELOPE is the minimum rectangle containing the polygon, and the coordinates following the word ENVELOPE are the lower left and upper right corners of this rectangle.
Finally, the area and the coordinates of the centre of gravity of the zone are output.
Note that the area is not the actual ground area of the zone but is expressed in terms of the units on which the coordinates were measured.
At the end of the output the total area of the polygons and the number of points processed is given.
In this example the total area is 365 825 square units and the number of points processed was 330.
A second file is printed by the VME operating system for all batch jobs.
This file is called the log file.
It records the progress of the job, including error messages, and also holds messages from the system manager (details of system availability, announcements of problems, and so on).
The log file for my GIMMS job tells me that the job reached the head of the batch queue and started to execute at 48 minutes and 56 seconds after 5 o'clock p.m. on Monday, January 4th, 1988 and ended at 49 minutes and 15 seconds past the same hour on that day.
Once the polygon definition file has been created, a second file, containing the statistical data to be mapped onto the polygons, can be generated.
In the present example, this file contains data extracted from the World Data Matrix listed in Appendix A for the countries named in Appendix F. Two variables, infant mortality and Gross National Product, identified as INFMORT and GNP respectively, are used.
Since data for some of the smaller countries are not incorporated in the World Data Matrix the value — 1 (minus one) is used to indicate ‘no data available’.
The GIMMS commands to build the statistical data file are:
*FILEIN DATAFILE ZONES=42 VARS=2
NAMES=INFMOSRT, GNP
(…date for 2 variables on 42 polygons entered in zone order, i.e. the data for the polygons are specified in the order Z01, Z02…
Z42 where Z01, Z02…
Z42 are the polygon codes used in the program to input the line segments defining the polygons.
Where data for a particular zone are not available the code -1 is used.…)
*SAVE DATA TO FILE 12
*STOP
The Job Control commands given below assume that (i) the instructions and data for the statistical data definition are held in a file called PMMLIB.GIMMSTATDAT and (ii) the GIMMS-generated data file will be written to another file called PMMLIB.GIMMSPOLYDAT which will be opened on unit 12.
The ICL VME Job Control commands are:
JOB (NULG.LGPMMGIMMS2, STA = 3)
ASSIGN-OUTPUT-FILE(PMMLIB.GIMMSPOLYDAT, OPEN-ON = 12)
GIMMS (INPUT = PMMLIB.GIMMSTATDAT)
ENDJOB
Figure 4.10 Extract from printout generated by the GIMMS program.
This Job Control file is sent to the batch queue by the SUBMIT-JOB command as described above.
The output from GIMMS consists of a list of the options specified together with informative messages to the effect that a data file with 42 zones and 2 variables has been created and saved to the file opened on unit 12.
On completion of this second GIMMS job we are in a position to begin the final task, that of producing maps based on the digitized map of the 42 countries of Africa, using one or other of the two statistical variables entered into the file PMMLIB.GIMMSPOLYDAT.
The GIMMS commands to produce a choropleth map are listed below.
The numbers in square brackets are NOT part of the GIMMS command.
They are identification numbers that are used in the description below.
PLOTPARM PLOTTER [1]
PLOTPROG [2]
NEWMAP MAPSIZE=25,25 FRAME [3]
GIMMSFILE FILE = 11 [4]
RESTORE DATA FROM FILE 12 [5]
TEXT POSITION=12.5, 24 [6]SIZE=0.5 [7]
ALPHABET=61 [8]
CENTRE ONX [9]
‘Infant mortality mid-1980s’[10]
MAP VARIABLE = INFMORT, TYPE = AREA [11]
END [12]
STOP [13]
The GIMMS command file is stored in a file on the ICL 3900 computer under the name PMMLIB.GIMMSMAP1 and the ICL VME Job Control instructions required to place this command file into batch queue number 3 (STA = 3) are:
JOB (NULG.LGPMMGIMS3, STA = 3)
ASSIGN-DATA-FILE(PMMLIB.GIMMSPOLY1, OPEN-ON = 11)
ASSIGN-DATA-FILE(PMMLIB.GIMMSPOLYDAT, OPEN-ON = 12)
GIMMS (INPUT = PMMLIB.GIMMSMAP1, DIG FILE = PMMLIB.GIMMSDIGFILE1)
This Job Control file tells the VME operating system that two data files are required, one (created by the first GIMMS program) is called PMMLIB.GIMMSPOLY1 and is to be opened on unit 11.
This file holds the polygon (zone) outlines in order Z01 to Z42.
The second data file is the one holding the statistical data for the 42 polygons for the variables InFMORT and GNP.
Its name is PMMLIB.GIMMSPOLYDAT and it is to be opened on unit 12.
The GIMMS statement specifies that the GIMMS commands are to be read from (INPUT =) the file PMMLIB.GIMMSMAP1, which is listed above.
The second instruction on this line of the Job Control file (DIG-FILE =) will be discussed later.
First, however, a description of the instructions contained in the file PMMLIB.GIMMSMAP1 is given.
These instructions are to be executed by the Job Control instructions that are listed immediately above.
The following paragraphs are numbered so as to correspond with the records of the file PMMLIB.GIMMSMAP1.
1.
PLOTPARM PLOTTER indicates that the map is to be output to a pen plotter.
2.
PLOTPROG begins the instructions to plot the map.
The commands labelled 3 to 12 form the PLOTPROG package.
3.
NEWMAP means that this is a new map.
MAPSIZE =25,25 gives the x and y dimensions of the map in centimetres.
If the y-dimension of the map exceeds 29cm the map will be drawn on wide paper and the computer operator will have to change over the paper on the plotter.
Narrow (29 cm) paper is generally used for draft maps to reduce costs.
FRAME causes a rectangle to be drawn around the map.
4.
GIMMSFILE FILE = 11 associates the polygon outline file with the file PMMLIB.GIMMSPOLY1 opened on channel 11 in the Job Control file.
5.
RESTORE DATA FROM FILE 12 reads the statistical data from the file PMMLIB.GIMMSPOLYDAT opened on channel 12 in the Job Control file.
6.
TEXT is used to provide annotation on the map.
POSITION= 12.5,25 gives the x, y coordinates of the text, in centimetres, with reference to the bottom left-hand corner of the map.
In this case, the command CENTRE ONX (number 9 below) is used so the annotation will be centred on a position 12.5 cm along the x-axis.
7.
SIZE=0.5 gives the height of the characters to be used, in centimetres.
8.
ALPHABET = 61 specifies the type of lettering.
A range of character fonts is available in GIMMS; set number 61 (an open alphabet) is used here.
The others are listed in the GIMMS documentation.
9.
CENTRE ONX causes the text to be centred on the x coordinate specified by the POSITION command (number 6 above).
10.
MAP VARIABLE = INFMORT, TYPE = AREA.
This is the command to generate a choropleth map for the variable INFMORT, using the parameters specified above.
The map generated by these commands is not sent directly to the plotter.
Instead, the map is stored in digital form in the file PMMLIB.GIMMSDIGFILE1 which is associated with the sub-command DIG-FILE =in the Job Control command ‘GIMMS’.
The term DIG-FILE means Device Independent Graphics File, which is a digital map held in a disc file.
The term ‘device-independent’ means that the digital map can be drawn on any available graphics output device; at Nottingham a graphics screen or a plotter can be used.
The data contained in the DIG file can be sent to a graphics screen by the command ‘VIEW-DIG-FILE’.
This is the recommended choice for the first viewing of a DIG file, for the display process is much more rapid than if the data are output directly to a plotter.
Also, the map can be regenerated if it is apparent that a mistake has been made in the specifications.
When the user is satisfied that the map meets his or her requirements the contents of the DIG file can be sent to the plotter using the ‘PLOT-DIG-FILE’ command.
Remember that these system commands are specific to the Nottingham University ICL 3900 computer system; you will have to use the equivalent command appropriate to the computer system used at your computer centre.
Figure 4.11(a) shows the result of the procedure described above.
Although the map shows the distribution of the variable INFMORT over the countries of Africa, it is not satisfactory for two reasons.
Firstly, it is not clear that data are unavailable for some of the countries.
Secondly, the class intervals for the five classes used in the choropleth map have been derived simply by dividing the data range into five equal ranges.
A second map (Figure 4. 11(b)) was easily generated to overcome these two problems.
The areas for which data are not available were excluded by specifying that values less than zero should not be  shaded but should be left blank.
This is done by using the subcommand MINIMUM=O as shown below.
The second problem was overcome by specifying TYPE=QUANTILE.
There is a range of such subcommands available in GIMMS; these two were selected to illustrate the way in which changes can easily and quickly be made to a command file if the result of a GIMMS run does not meet the user's requirements.
Further details of the commands available are given in Carruthers (1985).
The additional command needed to specify that areas with a negative data value be excluded and that the class intervals be chosen so as to place an equal number of zones in each class is:
INTERVALS VARIABLE = InFMORT MINIMUM = 0 TYPE = QUANTILE
This command is placed after the *TEXT command and immediately before the *MAP command, that is, between lines [10]and [11]in the command file listed above.
The result is a more suitable map (Figure 4.11(b)) on which it is clear that data are unavailable for some countries.
The five shading symbols are also more equally spread over the map area.
Figure 4.11 (a) GIMMS plotter map of infant mortality for 42 African countries using equal class intervals.
No special provision is made for missing data.
The legend in the lower left corner of the map is called a default option.
This means that the user does not hag to specify that a legend is required, nor is it necessary to give any detailed instructions on the placement of the legend.
However, the default can be overridden either by (i) specifically requesting that no legend be plotted or (ii) giving a complete specification of the required legend.
Many other GIMMS options have default settings which are used if no alternative is specified (or if the option is not specifically included in a command file).
The map for the second variable, GNP, is shown in Figure 4.11(c).
Again, a minimum data value of zero is specified so as to eliminate those countries for which no data are available.
The option TYPE = QUANTILE is also used.
The resulting map can be visually compared with Figure 4.11(b) in order that any similarities in the spatial distributions of infant mortality rate and Gross National Product can be detected.
Figure 4.11 (cont.)(b) Same data as Figure 4.11(a) but with countries without data being left blank.
The classes contain approximately equal numbers of members.
These examples illustrate only some of the potential of the GIMMS package for the presentation of geographical information in map form.
Other mapping systems may well be available at your local computer centre.
Whatever computer mapping system is used, the major advantage of such systems over manual map production quickly becomes apparent, namely, the ease with which maps can be redrafted and revised once the basic polygon data and statistical database have been entered into the computer.
The mechanics of map drawing are  no longer a constraint or a deterrent to the use of maps for the user can, given a suitable package such as GIMMS, modify and refine his or her map or generate a number of maps without difficulty.
Figure 4.11 (cont.)(c) As Figure 4.11(b) using data for Gross National Product.
4.4 SUMMARY
Automated cartography, computer-aided cartography and digital mapping are different names for essentially the same process, the generation of maps and diagrams by computer.
In this chapter, hardware for automated cartography has been described.
The graphics terminal, various types of printer (line-printer, dot-matrix printer and inkjet), plotter (drum, flatbed), and film-writers have been described in terms of their suitability for output of maps and diagrams.
Each is suitable for a particular application, though there is some overlap.
The cheapest and most readily-available output device is the printer.
Dot-matrix printers, such as those used with popular makes of personal computer, and line-printers (which are normally used with larger, usually centralized, computers) can be used to generate cheap, but not particularly accurate, maps and diagrams.
They are most useful in education, because students are able to get a fast turn-round while at the same time learning the principles of operation of a particular software package, and in draft map production, where a cartographer is experimenting with different map designs.
Inkjet printers provide a similar facility but with the added advantage of colour.
The quality of the display produced by a graphics terminal depends upon the horizontal and vertical resolution of the screen, expressed as the number of phosphor dots in the two directions, and on the number of colours that can be simultaneously displayed.
Modern graphics terminals have a screen resolution of 1024 x 1024 or more, and can display eight or more colours on the screen at the same time.
These devices are useful for experimenting with different map designs and for the production of ‘temporary’ maps.
An example of the latter use might be where a sequence of maps showing alternative strategies (such as routes for a motorway) was required for demonstration purposes, for example at a public enquiry.
A graphics display screen could be used to switch rapidly from one map to another; this would have the advantage of economy (in that costly high-quality paper maps would not be needed by each participant) and would be one way of ensuring that everyone was looking at the right map at any particular time.
In-car maps of possible alternative routes are another example of ‘temporary’ maps, which have no permanent value.
Maps shown on a graphics screen can be output to a dot-addressable printer using a screendump program.
High-quality pen-and-ink maps are produced on a graphplotter.
There is a wide range of such plotters available, from the cheapest A3 or A4 paper size plotter designed for use with a personal computer to the highly-accurate large flat-bed plotter.
Where a map is required to be printed (for example in a book  or a report) it can be output to a film-writer which can produce a film negative.
This negative can be used directly in the printing process.
Software is required in order to make the hardware work.
Since a wide range of different software packages is available, two of the more widely-used packages have been chosen to demonstrate the way in which such packages are used.
SYMAP is the best-known line-printer mapping package; it has a large number of users in universities, colleges and research institutions.
SYMAP has the advantage that no specialized hardware is required and is thus useful for introductory teaching at degree level.
Its other uses are in experimenting with different map designs.
GIMMS is a plotter mapping package capable of producing professional-quality output.
The examples of SYMAP and GIMMS in this chapter use the same data-infant mortality rates and Gross National Product for 42 African countries — so the reader can judge the comparative merits of output from the two systems.
There are several reasons why computer mapping is increasing in popularity.
First of all, more spatial data are becoming available in digital or computer-readable form.
The map user can select features of interest from the digital map and display them in a way that is suited to his or her requirements.
Constraints set by different map projections, or by map borders, can be overcome by the computer.
Secondly, computer mapping allows the user to experiment; if the final product is not satisfactory then the labour involved in redrafting the map is negligible in comparison with manual methods.
Thirdly, digital maps can be combined with other kinds of spatial data in a Geographical Information System (Chapter 7).
A computer-drawn map is generally the end-product from such a system, which allows the user to combine map data with other kinds of data about places (economic, demographic, geological and pedological data, for instance) in order to produce cartographic and tabular output to suit a specific purpose.
The use of computers in cartography has had a number of effects; first of all, cartography as a discipline has become more independent of geography.
Whilst there is no denying that cartography in its more advanced forms was never seen as an integral part of geography, it is nevertheless true that as cartography adopted more advanced technology it became more remote from geography, possibly as a result of the relatively lower interest in technology among most geographers.
Secondly, the use of computers has sparked off an interest in the development of new, more clearly-defined methods in cartography while, at the same time, relieving the cartographer from the labour of manual drafting.
More thought and time is given to questions of map design and methods of data manipulation.
These, and other, aspects of the effects of the adoption of computer-assisted methods on cartography are described by Morrison (1980).
Further recommended reading is Peucker (1972) and the Transactions of the Institute of British Geographers Special Issue on Contemporary Cartography (volume 2, number 1, 1977).
4.5 REVIEW QUESTIONS
1.
Define the following:
GPS
analogue map
screen refresh
master survey drawing
interlacing
subtractive primary
screen resolution
choropleth map
orthomorphism
dot graphics
dither matrix
screen dump
map projection
elective
device-independent graphics
2.
What, in your view, are the advantages and disadvantages of computer mapping compared to manual methods?
3.
List the steps you would follow in preparing the input for SYMAP, GIMMS or any other computer mapping package with which you are familiar.
4.
What is meant by ‘hardcopy’?
Give examples of hardcopy devices suited to the production of cartographic products, listing the properties of each device.
5.
State the properties of the Mercator and Zenithal Equal-area map projections.
Which projection would you choose for a map to be used by a yachtsman sailing from Rio de Janeiro to Liverpool?
CHAPTER 5
Remote Sensing
5.1 INTRODUCTION
Remote sensing is the collection of information about the properties of an object without physical contact between the observer and the object being made.
It is an everyday experience; our eyes, ears and noses collect information about distant objects.
On the other hand, our senses of taste and touch do not act remotely.
In environmental remote sensing the properties of interest are those of the Earth's surface and atmosphere, and the data collected by remote sensing programmes are used to infer the nature of the Earth's surface and atmospheric features.
Such properties are of interest to a range of practical applications including mapping and surveying, weather forecasting, agricultural crop yield estimation, forest management and geological exploration.
In some of these applications, remotely-sensed data in the form of air photographs are used.
These photographs are interpreted visually using a variety of instruments.
Over the last three decades digital or numerical images of the Earth's surface and atmosphere have been obtained from imaging instruments carried by satellites.
Satellite-borne instruments are capable of observing large areas of the Earth's surface on a repetitive basis, thus providing large area regional or synoptic coverage over time.
Such data are valuable for detecting and monitoring change, for example in the type and cover of vegetation, and for observing dynamic phenomena such as sediment patterns in estuaries and coastal waters, or the movements of warm and cold fronts in the lower atmosphere.
Some satellites remain stationary relative to the Earth.
The instruments that they carry are thus able to view an entire hemisphere and to return images every 30 minutes.
These satellites are in geostationary orbit and the images that they provide are used primarily in weather forecasting applications.
Figure 5.1 shows an image acquired by the Pretoria (South Africa) receiving station from the European geostationary satellite Meteosat.
Other satellites are in a near-polar orbit which takes them over the Arctic and Antarctic regions.
They circle the Earth repetitively and, as the Earth rotates eastwards below their orbital path, their instruments build up a picture of land and sea-surface conditions and the state of the atmosphere.
The pictures on the evening TV weather forecast come from the US NOAA satellites which orbit at an altitude of around 850 km.
From this altitude their instruments view a swath of the Earth's surface that extends 1500 km to either side of their suborbital tracks, so that a picture of the globe over a 24-hour period is built up.
The Landsat satellites, which are operated by the American Eosat company, have an orbital altitude of 705 km and their sensors have a narrower field of view which covers the area within 92.5 km of their suborbital tracks.
It takes 16 days for Landsat's instruments to build up  a global picture.
However, Landsat's imaging instruments are capable of showing finer detail of surface features than are the instruments onboard the NOAA satellites, and so Landsat images are used in studies of agricultural crops, coastal sediment patterns and other fields in which high resolution is required.
NOAA images are used in weather forecasting which requires frequent global coverage but at lower resolution.
Data from Landsat's instruments are used in this chapter to illustrate geographical applications of remote sensing.
Other satellite remotely-sensed data, such as the NOAA images already mentioned and the images from the French SPOT and the Japanese MOS satellites, can be processed by the methods described and illustrated in this chapter.
Figure 5.1 Remotely-sensed image showing Africa and Europe.
This image was collected by the European geostationary meteorological satellite Meteosat, and acquired by the South African ground receiving station near Pretoria (inset).
Images such as these, which are collected every 30 minutes, are routinely used in weather forecasting and in atmospheric modelling.
5.2 LANDSAT SATELLITES
The first Landsat satellite was launched in 1972.
Two further satellites, Landsats 2 and 3, were launched in 1975 and 1978 respectively.
These were the ‘Mark 1’ Landsats, and all three have now been retired from service.
The first of the ‘Mark 2’ Landsats, numbered 4, was launched in 1982 and the second (Landsat 5) in 1984.
Both Landsats 4 and 5 are still operational in late 1989, though Landsat 4 is operating on reduced power.
Landsats 1–3 and Landsats 4 and 5 have rather different characteristics.
The earlier series will be described first.
Landsats 1–3 were placed in a near-polar orbit at an altitude of 910 km.
The later Landsats, 4 and, are in a lower orbit at 705 km.
Both orbits are described as sun-synchronous because the relationship between the positions of the satellite, the sun and the Earth is maintained as the satellite passes over the illuminated side of the Earth, so that the local sun time on the ground immediately below the satellite is approximately the same, around 9.30 am.
Landsat images of a given area will therefore always be taken at the same local solar time and not at varying times throughout the day, thus maintaining a constant direction of illumination.
This factor is an important one if images of an area taken on different days are to be compared.
Figure 5.2 shows the orbit of Landsats 4 and 5, and it is apparent that the satellites do not pass directly over the north and south poles; the furthest north they reach is 82°N and the furthest south is 82°S.
Every point on the Earth's surface between these two latitudes was imaged at least once every 18 days by Landsats 1–3, and is imaged every 16 days by Landsats 4 and 5.
Some areas are viewed more than once during this 16-day repeat cycle because they lie in an area of overlap between adjacent orbits.
The degree of overlap increases away from the equator.
As Landsats 1–3 moved southwards over the illuminated side of the Earth an instrument called the Multispectral Scanner (MSS) measured the reflectance of the land or water surface along scan lines extending 92.5 km on either side of the sub-satellite track (Figure 5.2).
The width of one scan line is therefore 185 km.
The measurements made by the MSS can be likened to the measurement  of light by a photographer's light-meter.
Each Landsat MSS measurement is proportional to the amount of light reflected from a ground area (called a pixel, for picture element) with a side-length of 79 m.
For technical reasons the values recorded on the ground are for areas measuring 57 m along the scan lines and 79m between scan lines.
The values recorded for each pixel are expressed on a scale of 0–63, giving a requirement of six bits of computer storage per pixel.
On this scale, 0 signifies minimum detectable reflected light and 63 indicates maximum detectable reflected light.
If the reflectance of sunlight from the ground or sea surface as recorded by Landsat's MSS were shown in photographic form then values of 0 would be seen as black and values of 63 as white with intermediate values being represented by shades of grey.
Some Landsat data distribution centres rescale the pixel values onto a 0–127 or 0–255 range.
Figure 5.2 Orbit of Landsat-4 and -5 satellites.
These satellites have a mean orbital height of 705 km and pass over all points between 82°N and 82°S at least once every 16 days.
The equatorial crossing time on the southband (descending) orbit is 0945 local sun time.
The sub-satellite track is he line traced out on the Earth's surface by a point immediately below the satellite.
The sub-satellite traccks for adjacent orbits become closer towards the Poles.
If 2342 scan lines from the MSS are placed together like the rows of a matrix then the distance from the first to the last scan line is just about 185 km.
Each scan line extends 92.5 km to either side of the sub-satellite track.
A Landsat MSS image is therefore made up of 2342 scan lines, giving the image a size of 185 x 185 km on the ground.
Since pixels are recorded at 57 m intervals along  each 185 km-long scan line there are (185 000/57=) 3246 pixels per line.
A full MSS image is made up of 2342 x 3246=7 602 132 pixels.
An idea of the magnitude of this quantity can be obtained if it is compared to the total population of New Jersey (7 344 000) or Ecuador (7 814 000), or if it is realized that 7 602 138 seconds make 90 days and 10 hours.
The volume of data making up a single MSS image places some restrictions on its use.
Since the reflectance values for the area making up a single image are recorded in four wavebands, the total volume of data for a single scene is 30408528 bytes, since each pixel requires one byte of storage.
The first image is a record of the pattern of reflectance of green light and images two to four record, respectively, reflectance patterns in the red and two near-infrared wavebands.
These concepts are explained more fully in Section 5.3.
Note that, for historical reasons, the four bands of the Landsat 1–3 MSS are numbered 4, 5, 6 and 7 rather than 1–4.
Figure 5.3(a) is a Landsat-3 band 7 (near-infrared) image of the Lake Powell/Glen Canyon area of Utah.
The black, low-reflectance, areas are water, and the Colorado River is seen running in a south-westerly direction from Hite Crossing in the north to Glen Canyon in the south-west.
The river has been dammed to form Lake Powell, which extends through the Glen Canyon Recreation Area.
The major left-bank tributary of the Colorado River is the San Juan.
The dark area to the south-east of the Colorado/San Juan confluence is Navajo Mountain, which rises to 10388 feet.
To the north-west of the Colorado River the Kaiparowits Plateau and the Escalante River are prominent.
Figure 5.2(a) is a computer-generated digital image; some of the numbers forming this image (and representing ground reflectance values for individual pixels in the near-infrared waveband of the Landsat MSS) are listed in Figure 5.3(b).
Figure 5.3(c) is a sketch map showing the locations of places mentioned in the text.
Although Landsats 4 and 5 have a lower orbital altitude (705 km) than Landsats 1–3, their orbits cover the same proportion of the Earth's surface — that between 82°N and S latitude.
A MSS instrument like the one carried by Landsats 1–3 and described earlier is carried by the newer Landsats; in addition, they have a more modern scanner called the Thematic Mapper or TM.
Unfortunately the electrical supply on Landsat-4 has partially failed, though the Landsat-5 TM has worked perfectly since launch.
Landsat-4 is still in orbit and its MSS continues to function, but its TM instrument is not fully operational.
TM pixel values are recorded on a 0–255 scale rather than the 0–63 scale of the MSS.
The TM operates on the same principles as the MSS, but it has a ground resolution or pixel size of 30 x 30 m rather than 57 x 79 m, and it records ground reflection in six, not four, wavebands.
A seventh band covers the spectral region in which heat is emitted by the Earth's surface.
The ground resolution in this ‘thermal’ band is 120 m.
The Landsat 4 and 5 MSS bands are numbered 1–4 and the TM bands 1–7.
Figure 5.4 is a near-infrared TM image of an area to the south of the city of Topeka in Kansas.
The runways of the city airport  can be seen on the extreme centre right of the image, while the route of Interstate Highway 135 (Topeka to Wichita) runs diagonally across the area from lower left to top right.
The black patch in the top left corner of the image area is a small reservoir.
Brush-filled creeks (showing as dark streaks) drain the region towards the Wakarusa River in the south-east, and the regular criss-cross pattern of tracks and field boundaries stands out clearly.
Figure 5.3 (a) Landsat-3 band 7 (near-infrared) image of the Lake Powell/Glen Canyon area of Arizona and Utah, United States.
The main features are shown in Figure 5.3(c).
Both MSS and TM images are composed of individual pixels.
It was mentioned earlier that a remotely-sensed image is made up of a number of scan lines and that each scan line contains a large number of pixel values.
Each pixel has an  associated numerical reflectance value measured on an ordinal scale (0–63 for the MSS and 0–255 for the TM).
Because Landsat MSS and TM images are numerical in nature they are called digital images.
They can be processed, manipulated and displayed by computer.
This chapter contains an introduction  to methods of digital image processing applied to Landsat image data.
First of all, however, the physical principles on which remote sensing is based are reviewed.
Figure 5.3 (cont.)(b) Section of Figure 5.3(a) in digital form.
Each number measures the reflectance of a small ground area (a pixel) with dimensions 79 x 57 m.
The reflectance values are expressed on a 0–127 scale.
These digital reflectance values are converted to a viewable image by the computer system shown in Figure 5.10.
Figure 5.3 (cont.)(c) Sketch map of the area covered by the image shown in Figure 5.3(a).
5.3 PHYSICAL BASIS OF REMOTE SENSING
Landsat MSS and TM instruments measure the reflectance of sunlight (or, in the case of the TM thermal infrared band, conventionally numbered 6, the emittance of heat) by the Earth at each of a very large number of pixel locations.
Sunlight and heat are two kinds of electromagnetic energy and remote sensing is concerned with the interaction between electromagnetic energy and Earth surface materials such as vegetable matter, water, soil and rock.
Electromagnetic energy can be thought of as moving in a wave-like pattern at the speed of light.
The crest-to-crest distance between adjacent waves is called the wavelength of the energy (Figure 5.5).
The wavelength is measured in  fractions or multiples of a metre.
Short wavelengths are measured in millionths of a metre (10 -6; m or micrometre, m) or even billionths of a metre (10 -9; m or nanometre, nm).
To give an idea of the magnitude of a nanometre, consider that light travels one foot in one nanosecond (10 -9; s).
Longer wavelengths are measured in hundredths of a metre (centimetre, cm), metres (m) or in thousands of metres (kilometre, km).
This range of wavelengths — from billionths of metres to kilometres — is called the electromagnetic spectrum, or simply the spectrum.
For ease of description it is divided up into groups of wavelengths termed wavebands or spectral bands (Figure 5.6).
Only certain parts of the spectrum are used in remote sensing  because radiation at some wavelengths is absorbed by gases present in the atmosphere, particularly ozone and water vapour.
Figure 5.4 Near-infrared image of the area around Topeka, Kansas, produced from data recorded by the Landsat-4 Thematic Mapper.
Figure 5.5 The wavelength of a symmetric curve is the distance between corresponding points on adjacent waves.
The amplitude of the curve is its maximum height above its average level.
The curve shown has a wavelength of approximately 6.6 m.
The shortest wavelengths are grouped into wavebands called gamma rays, X-rays and ultraviolet (UV) radiation.
Much of the energy at these wavelengths is absorbed by the atmosphere, which means that a remote sensing instrument such as the MSS or TM would, if it operated in one of these bands, be unable to see through the atmosphere and consequently would be unable to obtain any information about the surface of the Earth.
Visible light has a longer wavelength than UV radiation.
It occupies that part of the spectrum between 0.4 and 0.7 m.
The 0.4–0.5 m band is perceived by our eyes as blue light, whereas the 0.5-O.6 m region appears green and the 0.6–0.7 m band is seen as red light.
The diameter of a full stop (period) character in ordinary type is 0.06cm, so a ray of red light would have a wavelength 92000 times smaller than the diameter of a full stop.
Beyond the red end of the visible spectrum is the infrared or IR.
The IR waveband is not homogeneous.
The shod-wave infrared (SWIR) that lies closest to the red end of the visible spectrum behaves like visible light (except that our eyes cannot detect it).
Photographs using SWIR radiation rather than visible light can be taken with an ordinary camera and special film.
IR radiation with wavelengths between 5 and 15 m is sensed as heat and so it is called the thermal infrared region.
The Earth emits heat in the thermal IR band in a waveband centred at 9.6 m.
This heat can be detected above the atmosphere by thermal sensors which form part of Landsat's TM and by thermal imaging instruments carried by meteorological satellites such as NOAA and Meteosat.
Figure 5.6 The electromagnetic spectrum from 0 to 15 m.
The vertical axis shows the proportion of energy transmitted through the Earth's atmosphere.
Regions of high transmitttance are called ‘atmospheric windows’.
These are the regions of the spectrum that are available for remote sensing.
Microwaves have wavelengths much longer than the thermal IR.
They are really very short-wavelength radio waves (0.3 cm-3 m).
Radar (Radio Detection and Ranging) uses the 0.8 cm-1 m waveband.
Electromagnetic energy in this region has two very valuable properties.
It can penetrate fog and cloud, and can also be used at night.
Radar images measure the roughness (rather than the colour or the temperature) of the target surface.
No civilian radar satellite is in orbit at the moment, though the US Seasat produced much valuable imagery during its shod lifetime in 1978.
The European Space Agency and the Canadian Government are both planning to launch radar satellites in the early to mid-1990s.
Figure 5.6 The electromagnetic spectrum from 0 to 15 m.
The vertical axis shows the proportion of energy transmitted through the Earth's atmosphere.
Regions of high transmittance are called ‘atmospheric windows’.
These are the regions of the spectrum that are available for remote sensing.
The portion of the electromagnetic spectrum with wavelengths longer than 3m is used for radio and TV communications.
FM radio uses the shortest wavelengths, while AM stations use the 20 m to 2 km band.
Short-wave radio uses the 20–50 m band, medium wave covers the 190–550 m band while longwave uses the 1000–2000 m region.
Only a part of the electromagnetic spectrum can be used for remote sensing for, as noted earlier, energy in some spectral bands is absorbed or scattered by the atmosphere.
All energy with a wavelength less than 300 nm is absorbed, and there are a number of absorption bands in the IR region between 1.1 and 2.5 m.
Apart from the 3–5 m and 8–14 m bands, infrared energy is absorbed.
The regions of the spectrum that are not affected by absorption are called atmospheric windows (Figure 5.6).
Energy with wavelengths within these window regions is not absorbed but may be subject to a process called scattering which deflects or redirects the energy.
Scattering gets more intense as wavelength diminishes, so blue light in the visible spectrum is scattered more than red light because the wavelength of blue light is less than that of red light.
The blue component of incoming solar radiation is scattered so severely that it appears to our eyes to be coming from the entire sky.
That is why the sky looks blue.
The Moon has no atmosphere, and photographs taken on the Moon's surface show a black sky.
The degree of scattering is affected by the distance traversed through the atmosphere, called the atmospheric path length.
If you have travelled in an aeroplane at 35 000 feet or so then you will have noticed that the sky looks a much darker blue than at sea-level.
This is because there is less scattering of blue light as the atmospheric path length and consequently the degree of scattering of the incoming radiation is reduced.
For the same reason, the sun appears to be whiter and less orange-coloured as the observer's altitude increases; this is because a greater proportion of the sunlight comes directly to the observer's eye.
Figure 5.7 is a schematic representation of the path of electromagnetic energy in the visible spectrum as it travels from the sun to the Earth and back again towards a sensor mounted on an orbiting satellite.
The paths of waves representing energy prone to scattering (that is, the shorter wavelengths) as it travels from sun to Earth are shown.
To the sensor it appears that all the energy has been reflected from point P on the ground whereas, in fact, it has not, because some has been scattered within the atmosphere and has never reached the ground at all.
This component is called the atmospheric path radiance.
Another component has been reflected from points other than P. Only a part of the received signal represents energy reflected from point P. The effects of scattering diminish the usefulness of shorter wavelengths for remote sensing.
5.4 GEOGRAPHICAL SIGNIFICANCE OF LANDSAT MSS AND TM DATA
You may well be wondering about the relevance of this technical detail on orbits, sensors and electromagnetic energy to geography.
However, it is necessary to understand the principles of remote sensing in order to make intelligent and informed use of remotely-sensed data.
Images produced from these data have the following geographically-significant properties:
1.
They provide coverage of the Earth between 82°N and S latitude, providing information about areas to which access on the ground might be difficult or expensive.
2.
The coverage is repetitive (every 18 days for Landsats 1–3, every 16 days for Landsats 4 and 5) so phenomena which change through time can be monitored.
Cloud-cover problems will diminish the number of useful images from the 20–22 per year that are theoretically possible, but even so the monitoring of surface phenomena that change during the year (such as agricultural crops and natural vegetation) or which change over the years (for example the extent of the built-up areas of cities or the extent of forest cover) is possible.
3.
The TM and MSS produce images from a considerable height above the Earth's surface so panoramic distortion (familiar to users of low-altitude aerial photography) is minimal.
The MSS ‘sees’ through an angle of only 11° so the distance from the sensor to the ground at any point on the image is not too variable.
4.
TM and MSS images are multispectral.
The TM produces images in seven spectral bands, the MSS in four.
This makes possible the identification of ground surface features from their spectral characteristics.
5.
The images that the Landsat MSS and TM instruments provide are digital or numerical in nature, and can therefore be processed by computer.
Indeed, without the use of a computer it would not be possible to use much remotely-sensed imagery at all.
Apart from some photographs taken by astronauts using hand-held cameras, and some experimental photographs taken by cameras carried by the Space Shuttle, all remotely-sensed imagery from satellites is digital in nature.
A computer is needed to convert these images from numerical to viewable form, either as a picture on a TV monitor or as a conventional photograph.
Figure 5.7 Part of the short wavelength energy from the sun is scattered at S2 into the field of view of the sensor.
Some energy reaches point P on the Earth's surface and a proportion is reflected into the field of view of the sensor.
Some energy from point Q is also detected by the sensor as if it had originated at P, due to scattering at S1.
Thus, although to the sensor all the captured energy appears to come from point P on the ground, only a proportion actually does so.
The multispectral nature of Landsat TM and MSS data requires further comment.
A green object is perceived as green because it is more reflective in the green region of the visible spectrum than in the blue or red regions.
A plot of the spectral reflectivity curve for a bright green target is shown in Figure 5.8.
Both the TM and MSS operate in spectral regions beyond the visible.
Although our eyes cannot detect variations in reflectance in the near-infrared band it is possible to measure such variations using appropriate instruments.
Figure 5.9(a) shows the spectral reflectance curves for healthy vegetation (solid line) and for diseased vegetation (dashed line) in the 0.4–1.1 m region of the spectrum.
The most noticeable aspect of the reflectance curve (or spectral signature) of vigorous vegetation is the sharp rise in reflectivity at 0.7 m; the green peak (0.5–0.6 m) is relatively minor.
The curve for diseased vegetation shows that the near-infrared is considerably reduced.
Other targets are characterized by specific spectral reflectance properties.
For example, water has a generally low reflectance in the visible spectrum, the proportion of reflected light being related to the presence and amount of suspended sediment and dissolved organic material.
In the near-infrared waveband the reflectivity of water drops almost to zero.
If the spectral reflectance characteristics of the   different land-cover types in the area covered by an image are known, it is possible to identify each pixel in the image in terms of one or other of these classes.
However, the broadness of the MSS bands (Figure 5.8(b)) precludes such precise identification.
It should also be remembered that the spectral reflectance curve of living vegetation will change continuously throughout the growing season.
Figure 5.8 Spectral reflectance curve for a bright green target.
5.5 COMPUTER SYSTEMS FOR LANDSAT DATA
Of all the data types described in this book, Landsat data are the only kind that are interpreted and used in the form of pictures or images.
Any computer system used for Landsat data processing must be capable of displaying images, preferably in colour.
In this section the equipment needed to allow the computer to display colour images on a TV monitor is described.
Landsat TM and MSS data are provided in computer-readable form on magnetic tapes called CCTs (Computer Compatible Tapes).
The data stored on these tapes are read by the computer and placed in a file (or files) on disc (Chapter 1).
After any processing of the kind described later in this chapter the data are transferred to one of three memory banks, each of which contains a number of parallel bit-planes; each plane is capable of storing one bit (0 or 1) at each pixel position (Figure 5.10).
The pixels within each memory bank are arranged in row and column format, and a common arrangement is to have 512 rows (or rasters) of 512 pixels in each of the memory banks.
The three memory banks represent the red, green and blue components of the image seen on the television monitor.
Generally, eight bit-planes make up one memory bank so that a value between 0 and 255 inclusive (00000000 to 11111111 in base 2 notation, described in Chapter 1) can be stored at each pixel position for the three primary colours of red, green and blue.
Figure 5.11 shows how the value stored at one pixel position in a memory bank is mapped to the corresponding position on the TV monitor display.
Since in the example the memory bank is composed of one bit-plane, the resulting image shown on the TV monitor can have one of only two values at each pixel point: the value 0 (meaning ‘black’) and the value 1 (meaning ‘white’).
No intermediate shades of grey are possible.
Figure 2.2 shows the letter I represented in raster format with one   bit per pixel.
Recall, however, that dedicated image processing computers such as that shown in Figure 5.11 have several bit-planes in each of three memory banks.
Eight bit-planes per memory bank allows 256 levels of the associated primary colour to be represented.
Figure 5.9 Opposite (a) Spectral refectance curves for healthy and diseased vegetation.
Note the minor peak at 0.55 m (in the green region of the visible spectrum) and the sharp rise in reflectance at about 0.8 m.
The dips in the reflectance curve for healthy vegetation at 0.4 and 0.6–0.8 m are due to absorption by the growing vegetation to provide energy for the process of photosynthesis. (b) The actual reflectance spectrum of an object (upper diagram) and the spectrum recorded by a broad-band sensor such as Landsat's Multispectral Scanner.
Figure 5.10 Schematic representation of a dedicated image-processing computer system.
Remotely-sensed images are read from magnetic tapes and stored as disc files.
These data are transferred, under the control of a program running on the processor, to an image display sub-system which contains three memory banks.
These memory banks store the red, green and blue componenets respectively of a false-colour composite image.
The digital images held in the memory banks are converted to television signals which are displayed on the monitor.
The operator issues commands via the keyboard associated with the visual display terminal.
The processor box holds the arithmetic and logical unit (ALU) and the random-access memory (RAM).
Figure 5.11 The numbers stored in the memory banks shown in Figure 5.9 represent the intensity of the colour displayed at the equivalent point on the TV monitor screen.
In an operational system the memory is capable of storing a number in the range 0–255 in each cell of the 512 x 512 array.
A value of 255 would result in the corresponding phosphor dot on the screen receiving maximum illumination while it would be at half brightness if the value were 127.
The relationship between the number of shades of a colour (or shades of grey if the image is monochrome) and the number of bit-planes in the memory bank can be illustrated by a simple example.
A single bit-plane can hold only one binary digit in each position.
Two planes can store the binary numbers 00, 01, 10 and 11 (decimal 0, 1, 2, 3) and so could represent black (0) and white (3) with two intermediate shades of grey.
In general, bit-planes can hold 2 different levels of grey (including black and white) at each pixel point.
A group of data planes makes up a memory bank.
Since Landsat TM data are supplied on a 256-level scale it would seem sensible to have a memory bank comprising eight data planes, since 2 8 equals 256.
It is possible to use less than eight data planes and still get good results.
The Landsat MSS image shown in Figure 5.3(a) was photographed from a monitor screen in the Remote Sensing Unit at Nottingham University using six data planes per memory bank (implying 64 levels of colour per memory bank).
There are two ways of generating a colour representation of an image.
One is to allocate a particular colour to a number of contiguous levels in the image so that, for example , the levels 0–32 might be displayed in dark blue, 33–67 in dark green, 68–87 in cyan, and so on .
This method is called density slicing and it was the technique used in the generation of the colour image shown on the front cover of this book.
Density slicing is normally applied when only a single-band image of an area is available.
When multispectral imagery is available, such as from Landsat's MSS or TM, three bands are selected for display.
The data for band 1 are placed in memory bank 1 which provides the red input to the TV monitor display.
Band 2 is stored in memory bank 2 (green) and band 3 in memory bank 3 (blue).
The resulting picture on the monitor is called a false-colour composite image.
It is a composite of three separate bands and is false (rather than natural) colour because the three selected spectral bands do not usually represent reflection in the visible red, green and blue regions of the spectrum.
Thus, a Landsat 1–3 MSS false-colour composite image is generally made up from band 7 (shortwave infrared) displayed as red, band 5 (red) displayed in green and band 4 (green) displayed in blue.
From the earlier discussion of spectral signatures it is easy to understand why vigorous vegetation appears red in this type of display.
Colours other than pure red, green and blue are formed by the combination of the three primary colours.
For instance, the colour yellow is formed by the addition of red and green.
A Landsat MSS pixel that had equal reflectance in bands 7 and 5 and zero reflectance in band 4 would appear as a yellow point on the display if the false-colour compositing method described in the preceding paragraph were used.
The brightness of the yellow would be a function of the  magnitude of the reflectance.
Cyan is formed by the addition of green and blue, while magenta (pink) is the result of combining red and blue.
Virtually any colour can be formed by mixing red, green and blue light in different amounts and with different levels or magnitudes.
Table 5.1 shows some possible combinations.
Note that if there are eight data planes in each memory bank (giving 256 levels per colour) then the number of combinations is 256 3 or 16 777 216.
The human eye cannot distinguish such a large number of colours and no Landsat MSS image would need to use them all.
However, should a particular colour be needed it will be available.
Many image-processing computer systems can perform a number of straightforward operations on the displayed image.
One useful operation is zooming or magnifying a portion of the image so that it fills the screen.
Zooming is carried out by repeating pixel values, so that zooming by a factor of four implies that each pixel value in the memory bank or banks is repeated four times, and each line of the image is also repeated four times.
Figure 5.12 shows a part of the image in Figure 5.3(a) magnified by a factor of 4.
The area shown is the junction of the San Juan and Colorado rivers in Utah.
Note the prominent abandoned meander on the Colorado River north of the confluence.
It can also be seen, though less clearly, on Figure 5.3(a).
The individual pixels of which the image is formed are clearly apparent in Figure 5.12.
The colour seen on a monitor screen is named in the right-most column.
Over 16 million different colours are possible using eight-bit representation for the three additive primary colours since any value in the range 0–255 inclusive can be selected for any of the three memory banks.
Figure 5.12 Zoomed portion of the image shown in Figure 5.3(a).
The confluence of the San Juan and Colorado rivers can be seen in the lower centre-left of the image.
At this magnification (x 4) the individual pixels making up the image become visible.
5.6 IMAGE PROCESSING TECHNIQUES
Methods of displaying and magnifying digital images were discussed in the preceding section.
Since a digital image is simply an array of numbers it can be manipulated by computer; the type of manipulation depends on the aims of the user.
In this section a number of techniques of digital image processing which can be applied to Landsat TM and MSS images are described.
These techniques can be considered to alter in some predetermined fashion the way in which the image is presented to the viewer.
They are described in the following paragraphs under five headings:
1.
enhancement,
2.
geometric correction and registration,
3.
noise suppression and filtering,
4.
classification, and
5.
transformation.
5.6.1 Enhancement operations
Enhancement operations are those which bring out detail in an image, either by improving the contrast or by emphasizing edges.
The latter operation is sometimes called sharpening.
The raw data received from Landsat often use only a portion of the 0–255 range available in an eight-plane memory bank, so that the image appearing on the screen is either too dark or too light.
Enhancement techniques spread the range of pixel values so that they cover the full dynamic range of the image display system.
For instance, a typical Landsat TM band 4 image might have pixel values in the range 25–90.
If this image were displayed using the methods described earlier it would lack very dark values (0–24) as well as medium to bright values (91–255) and would cover only the dark to medium grey range.
The computer could be used to rescale the image pixel values so that the lowest value in the image (25) was interpolated onto the lowest value that the display system could accommodate (0) while the highest value in the raw image (90) was mapped to the maximum value that could be held at a pixel point in the image memory bank (255).
The intermediate values between 25 and 90 would be interpolated onto the 0–255 range of the display device.
This technique is called contrast stretching.
Figure 5.13 is a contrast-stretched Landsat MSS band 7 image of the Leningrad region in the USSR.
The original image lacked any detail yet on Figure 5.13 the port installations and the delta of the Neva River are clearly brought out.
Another method of enhancement is called sharpening.
As the name implies, this operation involves emphasizing the boundary or edge features on the image so that it looks less blurred.
An edge or boundary can be thought of as a point or pixel across which the reflectance value changes considerably.
Figure 5.14 was produced by (a) moving across the image on a pixel-by-pixel basis and computing the difference between a given pixel and its neighbours to the top, bottom, left and right, and (b) subtracting four times this difference from the central pixel value.
The effect is to highlight edges and boundaries such as railway tracks, roads and streets.
It also has the undesirable effect of enhancing the horizontal scan line pattern, particularly over low-reflectance areas such as the water of the Gulf of Finland.
5.6.2 Geometric correction and registration
Geometric correction and registration are necessary if Landsat imagery is to  be used for cartographic purposes, or is being used in conjunction with map data (for example in a Geographical Information System, Chapter 7).
A raw Landsat TM or MSS image does not conform to any standard map projection.
First of all, in the case of the MSS, the pixels are not square.
They each represent an area measuring 79 x 57 m on the ground, giving the image a compressed appearance when it is displayed on a TV monitor.
Secondly, Landsat's orbit does not follow a north-south track.
Thus, the scan lines (which are perpendicular to the satellite heading, or flight direction) do not run in an east-west direction.
At the equator, Landsat's heading is 189° (9° west of south).
The heading increases with latitude until at 82° latitude the satellite is going  varies by up to 30 km and its attitude can change slightly, implying that the pointing direction of the sensor is not always truly vertical.
If image data are to be correlated with map data then these properties of the image data must be removed and the pixel values forming the image must be re-expressed in terms of a map-compatible coordinate system at the required scale.
Figure 5.13 Landsat MSS band 7 (near-infrared) image of Leningrad and the upper Gulf of Finland.
Figure 5.14 Same image as shown in Figure 5.13 after edge-enhancement procedure has been applied.
Although the image is sharper, the enhancement process has brought out a horizontal banding pattern on the image.
The operations needed to carry out this procedure can be divided into two parts.
Firstly, control points are located on map and image.
These points should be easily-recognizable and accurately-measurable points such as runway  intersections at airports, railway or road junctions, isolated buildings, or prominent natural features.
The location coordinates of suitable points on the image can be found accurately if a zoom function is available, and if a cross-wire cursor can be positioned over the point.
Figure 5.15 shows a control point being located on a magnified Landsat MSS image of Lakenheath USAF base in eastern England.
Around 30 or 40 such ground control points (gcp's) are needed for each full 185 x 185 km image.
For each point the map coordinates and the image column and row coordinates are recorded, and from these a mathematical transform is computed.
This transform  is essentially an equation which will convert from image to map coordinates and vice-versa.
Figure 5.15 Point locations on an image can be found using a cross-wire cursor.
In this photograph the cursor has been placed on the runway of Lakenheath air force base in eastern England.
Collection of ground control point coordinates is the first stage in the geometric correction of an image (see text for discussion).
The second stage of the geometric correction procedure involves the relocation of image pixel values to new positions which are required to achieve conformity between map and image.
This procedure is essentially a two-dimensional interpolation, and is known as resampling.
The map coordinates of the required pixel position are converted to image coordinates using the transform computed at stage one, and the pixel value on the raw image that is nearest to the computed image coordinate position is selected, as shown in figure 5.16.
This process is repeated for each required pixel position in the transformed image.
The same procedures (locating ground control points, computing a map-to-image and image-to-map transform, and resampling to generate a corrected output image) can be used to register or overlay two images of the same area taken at different dates.
Registered images are used to assess the degree of change that has occurred during the time-period represented by the two images.
Both geometric correction and image registration involve lengthy and time-consuming operations, taking several hours on a minicomputer.
Because the resampling operation is both repetitive and independent (that is, two or more resampling operations could be carried out simultaneously — one does not rely upon the other) it does not need to be performed sequentially.
Nearly all present-day computers are sequential (serial) machines which perform only one operation at a time.
A parallel computer is described in Section 1.8.3, and it is easy  to appreciate how the use of such a machine could speed up an important operation on digital remotely-sensed images.
Figure 5.16 The geometric correction of a remotely-sensed image involves the computation of equations which allow map coordinates to be converted to image coordinates, and vice-versa.
Given a raw Landsat image (centre) and a map of the area of interest (left) a corrected image, registered to the map, is required.
This registered image is derived by taking the x, y map coordinates of points corresponding to pixel centres on the registered image and locating the point on the raw image.
The pixel value in the raw image closest to the computed point is placed at location x, y in the registered image.
5.6.3 Noise suppression and filtering
Noise suppression and filtering involve the amplification or the removal of some of the components of the image data.
Noise in this context means the unwanted products of the imaging system.
Landsat images are scanned on a line-by-line basis, and this line-scanning process often leads to the production of horizontal striping effects on the resulting image.
These stripes are an example of noise, which can be defined as random or systematic effects superimposed upon the image due to the characteristics of the imaging system and the electronic circuits used in storing, transmitting, recording or copying the image.
The edge-enhanced Leningrad MSS image (figure 5.14) illustrates one way in which a particular component of the image (the boundaries or edges) are amplified.
The method used to achieve this could be called a filtering technique for, by analogy with the process of filtering as used in the chemistry laboratory, a particular part of a mixture (the edges or boundaries) was isolated and then added back to the original image to give Figure 5.14.
Thus, an image can be considered to be a mixture of components, each component representing variation at a particular scale.
It is convenient to distinguish between two scale components of an image.
One is the overall low-frequency background pattern of dark and light, and the other is the rapidly-changing local variation, or the high-frequency component, which is superimposed upon the low-frequency background to produce the observed image.
Pixel value at any point on the image can therefore be considered to consist of
(a)
a contribution from the background or regional pattern, and
(b)
local variability or detail which is superimposed upon this background pattern.
This way of modelling the scale components of an image should be compared with the Trend Surface model described in Section 3.5.3.
Filters can be designed to extract either the background pattern or the pattern of local variation.
These filters are called low-pass and high-pass respectively.
An example of the use of a high-pass filter was given above in respect of Figure 5.14.
A high-pass filter was used to isolate the local (high-frequency) variation which was then added back to the image so that the local component was effectively doubled, thus amplifying or exaggerating its importance.
This operation is termed sharpening.
A low-pass filter does the opposite of sharpening.
It smooths or blurs the image so that local deviations from the overall trend are removed.
The local variation may not represent information at all for, as Figure 5. 14 clearly shows, some high-frequency noise in the form of horizontal scan line patterns may be present on an image, distracting the user and rendering him or her less capable  of recognizing underlying trends.
The effect of removing noise is to clean up the image while the effect of removing local variability is to smooth the boundaries and emphasize the regional pattern present in the image.
Figure 5.17(a) is a Landsat MSS image of a coastal area of eastern England called The Wash.
The tidal range in this estuary is large (7m at spring tides) and large sandbanks are exposed at low tide.
The suspended sediment from rivers discharging into the The Wash shows up in grey, contrasting with the black of the deeper, clearer water further offshore.
On Figure 5.17(a) the effect of horizontal scan line banding is apparent, and local variability reduces the interpretability of the image.
Figure 5.17(b) was produced by replacing each pixel value in Figure 5.17(a) by the average of the  pixel values in a 7 pixel by 5 line box centred on that pixel; this is called a moving average filter.
A greater degree of smoothing could have been produced by increasing the size of the box, but this implies the loss of more detail.
The balance between the intensity of smoothing and loss of detail can only be worked out by trial and error; the effect of the 7 x 5 moving average filter on the visual appearance of Figure 5.17(a) is sufficient to produce a more usable product which reveals the location and shape of the offshore sandbanks and the disposition of the suspended sediment plumes from the rivers discharging into The Wash.
Students of English history might like to note that the contents of  the English treasury were lost in the thirteenth century by King John in the marshy area shown at the bottom left corner of the image.
They have never been recovered.
Figure 5.17 (a) Landsat MSS image of The Wash, eastern England.
A horizontal striping pattern distracts the eye and disguises the pattern of light and dark.
Figure 5.17 (cont.)(b) A moving-average filter removes the striping from Figure 5.17(a) and makes the underlying pattern clear.
The dark area in the top right is deep, clear water.
Sandbanks and coastal marshes are now clear, as are the variations in the sediment load of the estuarine waters.
However, the field patterns over the land area in the upper left of the image are blurred by the smoothing operation.
Figure 5.18 Points W, P and G represent the average reflectance values for samples of water, pine forest and grassland respectively on two channels of a multispectral image.
Points X and Y represent unknown pixels.
Since X is closest to W then it is allocated to class ‘water’.
Similarly, the pixel corresponding to Y is allocated to class ‘pine forest’ since it is closest to point P.
5.6.4 Classification
Classification of the pixels forming a Landsat MSS or TM image means giving each pixel a label to associate it with a land-cover class such as‘wheat’, ‘forest’ or ‘sandy desert’.
The four MSS bands provide four measures of surface reflectance which can be used to characterize different land-cover classes, as noted in Section 5.3.
A classified image can subsequently be geometrically corrected (Section 5.6.2) to produce a thematic map, which can be used alongside other conventional maps showing, for example, soil, geological and climatic boundaries.
In order to classify the pixels it is necessary to know in advance the number and spectral characteristics of the land-cover classes that are present in the area covered by the image.
Some methods of achieving this knowledge automatically are available but they are less reliable than methods based on field-work or the study of air photographs, maps and documentary records for the area concerned.
A simple (yet still surprisingly efficient) method requires that the number of  land-cover classes is known, and that for each class an estimate of the average reflectance in each Landsat MSS or TM band is available.
A simple example using only two bands is used to illustrate the method.
Assume that, in terms of the two bands, the average reflectance of water, pine forest and grassland are respectively (10,5),(20,40) and (50,80).
Figure 5.18 shows these points plotted on a graph.
The point marked X is an unknown pixel which is to be labelled as water, pine forest or grassland.
To do this the distance on the graph from X to each of the three points (water, grassland and pine forest) is calculated using Pythagoras's theorem, and pixel X is allocated to the class for which this distance is the shortest.
In this instance, X is closest to the average value for water (point W) so it is labelled as a water pixel.
Point Y, on the other hand, is closest to P, the average value for pine forest, so it is allocated to that class.
This process is repeated for every pixel in the image so that, when the operation is complete, each pixel is labelled ‘W’, ‘P’ or ‘G’(in practice a numerical label would be used).
This classified image could be displayed by assigning the colour blue to all pixels labelled ‘W’, the colour dark green to all pixels labelled ‘P’ and the colour light green to all pixels labelled ‘G’.
Figure 5.19 shows a classified image of an area of the county of Norfolk in eastern England.
Shades of grey have been used to represent the different land-cover classes.
Black areas are coniferous forest, which grows on the sandy soils of the Breckland, which is an area of glacial outwash material, while the dark grey, mid-grey and light grey regions represent different agricultural crop types.
The mid-grey is permanent grassland while the light areas are intensively-cultivated fields of peas, beans and other cash crops.
The different shades of grey were chosen subjectively and have no intrinsic meaning.
Usually, colours rather than shades of grey would be used.
Classification techniques such as this have been used to produce thematic maps of land-cover types, of rock types in semi-arid and arid regions and of the extent of urban areas.
One point that must be borne in mind is that such maps cannot be produced using Landsat MSS or TM data alone.
Some knowledge of ground conditions is necessary.
There is a growing tendency to use Landsat images as one of many layers of information within a Geographical Information System (Chapter 7).
5.6.5 Image transformations
Transformations of Landsat image data are used in order to combine the information present in the four MSS or seven TM bands in some particular way.
Recall that the spectral reflectance curve of vigorous, healthy vegetation shows a dip in the red region of the visible spectrum and a peak in the short-wave infrared (Figure 5.8(a)) whereas the corresponding curve for water shows a decline from visible green through visible red to a low in the short-wave infrared.
Clouds and fresh snow have high values in all bands.
A straightforward  transformation, combining information in MSS band 7 (short-wave infrared) and MSS band 5 (visible red) is the ratio of the band 7 to the band 5 value, computed for each pixel.
A high ratio value implies that the band 7 value of that the band 5 and band 7 values were equal.
The ratio technique has been used to assess the vigour of growing vegetation not only using Landsat data for small area inventories but also on a global basis using low-resolution data from the NOAA meteorological satellites.
The AVHRR sensor carried by the  NOAA satellites has a visible and a short-wave infrared band, and the National Oceanographic and Atmospheric Administration in Washington, DC produces global vegetation maps on a routine basis using the ratio transform outlined above.
Figure 5.19 Classified image of part of Norfolk, eastern England.
The darkest areas are coniferous forest.
The brightest areas are those of intensive cultivation, and intermediate shades represent grassland and sugar beet.
Normally a classified image would be colour-coded as the eye is not capable of distinguishing more than six or seven levels of grey.
A second widely-used transform is that of principal components.
Principal components are defined in terms of combinations of the pixel values in each of the four MSS or seven TM bands.
These combinations are computed in such a way as to concentrate the maximum amount of information in principal component 1 and the least in principal component 4 (or 7 if TM data are used, for there are as many principal components as there are bands of imagery).
The combinations are of the form  where C is the value of the principal component for a particular pixel, and a, b, c and d are coefficients derived from the correlations between the bands.
The terms MSS4-MSS7 are the values recorded in MSS bands 4 to 7 for the pixel concerned.
Where the spectral bands making up the multispectral TM or MSS image are highly correlated then more of the information contained in the multispectral image will be compressed into principal component 1 than would be the case if the intercorrelations among the bands were low.
The first principal component for a set of four MSS bands generally accounts for 85–90% of the total information in all the bands.
It is usually thought to represent ‘average reflectance’ while principal component 2 (accounting for 5–20% of the total information in all four bands) is normally associated with the visible/near-infrared contrast.
This contrast between high infrared and low red values is indicative of vigorous vegetation growth, hence principal component 2 is often labelled ‘greenness’.
Components 3 and 4 are much less important and are dominated by noise, though this is not to say that the small amount of information they contain is irrelevant.
Figures 5.20(a-d) show the four principal components derived from analysis of a Landsat MSS image of a semi-arid area in Northern Chile.
The variation in reflectance is largely due to differences in rock type and intensity of surface weathering.
The decline in information content from principal component 1 to principal component 4 does not need any verbal description.
Component 4 is dominated by the scan line banding mentioned previously, but some anomalous dark areas may be worthy of investigation.
Component 1, on the other hand, is free from obvious banding and it is possible to pick out several areas that differ in surface reflectance and degree of dissection.
This image would be useful in preparing a reconnaissance geological survey of this inaccessible and inhospitable region.
The technique is, in fact, widely used by geologists who often combine principal components 1 through 3 to form a principal components colour composite image for the study of rock types.
Figure 5.20 (a)—(d) Principal components 1–4 respectively of a Landsat Multispectral scanner (MSS) image of part of Northern Chile.
The first principal component has most information and hence the greatest contrast and least noise.
The pattern of light and dark areas represents variation in rock type and surface weathering in this arid region.
The dark area in the top right of Figure 5.20(a) is seen more clearly as a bright region on Figure 5.20(b).
It is a small lake.
The noise level increases considerably in Figures 5.20(c) and (d), showing that most of the information in the four bands of the MSS image can adequately be represented by two principal components.
5.7 SUMMARY
The techniques of display, enhancement, filtering and transformation of remotely-sensed images that have been described in this chapter represent only a selection of those available.
As experience of Landsat image processing  accumulates so geographers will become more adept at extracting information from such images.
Remotely-sensed images will become an increasingly important source of spatial information, to be used either alone or in combination with other spatial data in the context of a Geographical Information System, as the number and variety of remote sensing satellites is increased.
France, Japan, Canada, India, the USSR and Europe all have active remote sensing programmes, and US dominance of the commercial remote sensing market received its first challenge in 1986 with the launch of the French Satellite Pour l'Observation de la Terre (SPOT-1).
This satellite has a spatial resolution three times that of Landsat's TM and also has the ability to generate oblique, rather than vertical, views.
Stereoscopic images can be produced from such oblique  views, thus improving the information content of the images by allowing terrain elevations to be derived directly from the remotely-sensed images.
SPOT-2 was successfully launched in 1990.
A Japanese remote sensing satellite, designed for marine observations, was launched in February, 1987.
Other satellites, such as the European ERS-1 and the Canadian Radarsat, are scheduled for the period 1990–1995 and will provide radar imagery of the Earth for the monitoring of storms at sea and the tracking of iceberg movement in Arctic waters.
The volume and quality of remotely-sensed data seem set to increase substantially in the years to come, and the manipulation and interpretation of remotely-sensed data will, correspondingly, become a valuable geographical skill.
Figure 5.20 (cont.)(b)
Figure 5.20 (cont.)(c)
Further information on the material covered in this chapter can be found  in Curran (1985) and Harris (1987) at an introductory level.
Mather (1989) gives more details of computer techniques described in this chapter.
Figure 5.20 (cont.)(d)
5.8 REVIEW QUESTIONS
1.
Define the following terms:
Landsat
Multispectral Scanner
scattering
lowpass filter
ground control point
waveband
infrared
atmospheric window
contrast stretch
registration
pixel 
2.
What are the advantages to the geographer of synoptic and repetitive imagery of the Earth's surface from orbital altitudes?
3.
Outline the difficulties that might be encountered when relating Landsat imagery to conventional maps.
What are the main factors producing geometric distortion in Landsat images?
4.
What is meant by the term noise?
What are its effects on the visual interpretation of remotely-sensed images?
What methods can be used to eliminate or reduce noise?
5.
Define the term thematic map, giving examples.
What computer processing methods are used to derive thematic maps from multispectral remotely-sensed images?
What phenomena can be mapped from such imagery?
6.
Use a simple numerical example to show how the ratio between Landsat MSS band 7 (short-wave infrared) and band 5 (red) can distinguish between areas of vigorous vegetation and unvegetated areas.
What practical difficulties might you encounter in deriving a digital ratio image?
(Hint: a computer, like a human being, cannot divide by zero.
Also, a memory bank forming part of an image display system holds whole numbers, not fractions.)
CHAPTER 6
Simulation
6.1 INTRODUCTION
Teaching a trainee pilot to land an aircraft with a failed engine is a hazardous activity.
It is not surprising that airlines don't train their pilots on real aircraft, otherwise they might quickly run out of both pilots and aircraft (as well as instructors).
Consequently, most pilots are trained on flight simulators.
The trainee feels that he or she is flying a real aircraft, and can see the view from the cockpit just as if (s) he were actually approaching the runway at a particular airport.
However, if a ‘crash’ occurs the worst that can be expected is a rebuke from the instructor.
The term simulate is used in this chapter to mean mimic or copy a real event or situation.
The two reasons for using simulation methods in pilot training are to reduce costs and to eliminate hazards.
Simulation of geographical systems is not necessarily motivated by considerations of cost or avoidance of hazard, but more by the desire to experiment on systems that are either too slow-acting relative to the human life-span or which present ethical problems to the would-be experimenter.
In this context a system is defined to be a set of inter-related components together with the relationships between them (Huggett, 1980).
An example of a slow-acting system is a hill-slope.
In terms of a human life-span, the development of a hill-slope takes a very long time, and one could not stay around long enough to test alternative theories of hill-slope development if observation of processes acting on the present landscape produced the only relevant data.
A system that presents ethical problems to the experimenter is the demographic system.
Without the absolute power of an Egyptian Pharaoh one could scarcely test the consequences of an experiment involving the manipulation of people's lives, for example forcing a percentage of the population to emigrate or insisting that each fertile married couple produce exactly two offspring.
Other examples of applications of simulation methods in geography include the prediction of the hydrological behaviour of a river or the travel patterns of consumers in a region where a new shopping centre is to be built.
An introduction to the use of computer simulation models in geography is presented in this chapter.
Study of the examples will show that in order to simulate the behaviour of a system one must in the first instance understand it.
The design and testing of computer simulation models provides a valuable way of testing the consequences of an idea or theory.
The first example uses a simulation model of a simple pattern, that of rivers in a drainage basin.
6.2 RIVER PATTERN SIMULATION
Imagine a drunken man attempting to walk across a large, empty car park.
If matters are simplified for him by assuming that he can move only north, south, east or west, and excluding the possibility that he might collapse on the spot, can you visualize the path he would follow?
It would be totally random, so it could be called a random walk.
Surprising as it might seem, the random walk model is used in science to simulate situations in which there are no dominant, controlling forces.
This implies that the state of the system at successive time-periods, such as the successive positions of the drunken man, are uncorrelated.
If a very simple model is taken, representing stream patterns developing on a uniform surface with little or no slope, then no dominant process would control the direction of stream flow.
The random walk model could then be used to build up a picture of the possible range of river patterns that might develop in such circumstances.
This model is unrealistic, but is used here to demonstrate the principles involved.
The simplest case of a single stream is considered first.
The area of interest is divided into a set of rectangular grid cells; each cell is identified by a pair of row/column coordinates so that, for example , cell (5,2) is the second cell along the fifth row from the bottom of the grid.
The first assumption is that each cell can accommodate only a single reach or segment of a stream, and the stream can therefore move through each cell only once.
The second assumption is that the stream cannot move backwards on itself, that is, reverse its direction or join itself.
In view of the observed behaviour of natural streams, these assumptions are realistic.
The third assumption is that the stream terminates at the edge of the grid.
The simulation begins by the selection of the coordinates of the cell in which the stream has its source, and proceeds by random selection of the direction of flow.
These operations could be performed manually by the use of a dice.
If the maximum number of cells in a row of the grid is 30 and if there are 30 rows, a dice could be thrown six times and the outcomes totalled to get the row coordinate, and six times for the column coordinate using the convention that the six on the dice is interpreted as zero.
In the unlikely event that six successive sixes (zeros) were thrown the result would be counted not as zero but as one, or the dice might be thrown again.
Next, the dice could be used to determine the direction of flow from the source cell.
The outcomes 1, 2, 3 and 4 could be interpreted as north, south, east and west with outcomes 5 and 6 being ignored.
The dice would be recast if the outcome was incompatible with  the assumptions, so that a southerly-flowing segment would be prohibited from turning through 180° and flowing north.
The game ends when the stream reaches the boundary of the grid.
Figure 6.1 shows a possible outcome for an 11 x 14 grid.
No single result of a simulation experiment can be considered meaningful.
Just as a statistical sample (Chapter 5) must be of a certain size before reliable inferences concerning the population can be drawn, so a number of simulations must be run before the average behaviour can be treated as being descriptive of the real system.
However, carrying out a number of simulations by hand is both time-consuming and tedious.
On the other hand, if the simulation is to be carried out by computer a way must be found of getting the computer to generate random sequences of numbers such as would be obtained by throwing a dice a number of times.
A computer is a machine with the attractive property that it does exactly as it is told, yet the outcome of a series of throws of an unbiased dice will produce a random sequence of numbers in which the n + 1th outcome is independent of the nth.
How can a series of fixed instructions cause the computer to come up with a random sequence of results?
The answer is, of course, that it cannot.
However, computer scientists have developed programs which produce numbers that are apparently random.
They are called pseudo-random numbers and most computers have built-in functions which will generate sequences of such numbers.
In the BASIC language this function is called RND.
The possibility of using the computer to generate apparently random sequences of numbers allows the production of computer programs which, in essence, copy the human ability to throw an unbiased dice or toss a coin.
Figure 6.1 Randomly-generated stream pattern.
The stream sources (numbered 1 to 8) are chosen randomly, as is the direction of stream flow.
A computer program to simulate the simple stream-pattern experiment described earlier would follow the same lines as a manual simulation.
The source coordinates of the stream are found by generating two random whole numbers in the range 1–30 and the direction of movement from one cell to the next is found by generating another random number which can take on one of the values 1, 2, 3 or 4.
It is relatively easy to prevent computer-generated streams from altering direction through 180° (the first assumption) simply by comparing the present direction of flow (1, 2, 3 or 4) with the newly-generated random number.
The newly-generated number cannot be a 2 (south) if the current flow direction is 1 (north), nor can it be a 3 (east) if the current direction of flow is 4 (west), and so on.
It is more difficult to prevent the river going round in a loop and joining itself.
If, though, we place a zero in each cell of the grid before the simulation starts we can use the code ‘0’ to mean that the cell is unoccupied.
The presence of a stream segment in a grid cell is indicated by the code ‘1’.
The program could then corporate a rule which prevented a move into a cell containing a non-zero code.
Sometimes the stream will develop to a position in which it cannot move anywhere without violating one of the two rules (no flow reversal and no joining itself).
The program would then run forever.
To escape from such a condition it must first be recognized and then a strategy to move backwards a step at a time until a new route is found must be followed.
For example, in the situation shown at cell (5,7) in Figure 6.2 the stream is moved  back one cell towards the source, without altering any of the 1s and 0s, until the stream can move in a different direction.
Figure 6.2 The stream pattern shown in Figure 6.1 is subject to two constraints: a stream cannot flow backwards, nor can it join itself.
Stream 4 in this diagram violates the second constraint at cell (5,7).
A BASIC program running on a microcomputer can generate a single stream pattern in about one second.
It is relatively easy to extend the program so that several streams are generated.
The only modifications to the logic discussed above are that the code for ‘square occupied’ is no longer 1, but is the actual stream number (1 for the first stream, 2 for the second and so on).
A stream ends either when it reaches the edge of the grid or when it joins another stream.
The multiple-stream model allows the simulations of real stream patterns, using measurements of actual streams as a guide.
The first hypothesis is that, in the absence of any controls (such as slope, lithology or structure), a stream pattern will develop randomly and will be described by the random-walk model.
To test this hypothesis a number of stream patterns are generated using the program described above and a count made of the number of streams with no tributaries (these are called first-order streams), then the number of streams formed by the junction of two first-order streams (these are second-order streams) and so on.
Figure 6.3 shows how streams are ordered.
The geologist A. N. Strahler showed that if the logarithm of the number of streams of each order is plotted against stream order then a straight line will fit the resulting scatter of points.
If a similar plot for a set of randomly-generated stream patterns shows the same result then it can be concluded, that in the absence of geological and topographical controls, stream patterns appear to be generated by random  processes.
A random process is often considered to be the sum of a large number of small, independent processes so this reasoning is acceptable.
Figure 6.3 Strahler's method of stream ordering.
Further hypotheses might be considered; for example, the effect of slope could be incorporated into the model by assigning different probabilities to each of the directions of flow.
A southerly slope could be simulated by ensuring that 50% of the random numbers generated by the computer were interpreted as ‘flow south’ while 20% could be allocated both to ‘flow east’and ‘flow west’with the remaining 10% being ‘flow north’.
Practical tests on this type of simulation model have shown that real stream patterns are similar (in terms of the characteristics incorporated in the model) to those developed by simulation techniques.
The use of simulation allows the observation of many possible stream patterns, far more than could be observed in the real world.
6.3 LEVEL CROSSING SIMULATION
This section is partly based on an example from Guttman (1977, p. 174).
It concerns the development of a simulation model of a railway level crossing which, in the simplified version presented here, assumes a single railway line crossing a road on which traffic moves in one direction only.
An extended version of the model might be used to simulate the effects of the crossing for different road and rail traffic conditions.
In the present version of the model the train timetable is fixed for a 24-hour period, with trains running every x minutes, x being a value specified by the user.
To make the model more realistic it is assumed that the trains do not always arrive on time, and that the frequency distribution of the differences between the actual and timetabled arrivals of the trains follows a normal (Gaussian) distribution with a mean of zero (Chapter 3).
If s is the standard deviation, in seconds, of the differences between actual and scheduled arrival times then 68% of all trains will arrive within s seconds of their scheduled time.
A positive deviation indicates an early arrival and a negative deviation indicates a late arrival.
The signalman controlling the level crossing is instructed to close the gate n seconds before the train actually arrives, and to open it immediately the train has passed.
However, if the next train is due within m seconds of the gate reopening time, the gate remains closed until the next train has gone.
It is assumed that all trains are of equal length and are all moving at the same speed, so that they each take p seconds to pass the crossing.
The mean time between road vehicles is r seconds.
Because there are more short gaps than long gaps between vehicles the Gaussian probability distribution is not used to approximate the distribution of time gaps between vehicles.
Instead an exponential distribution is used, so that the actual arrival time of the next vehicle is x seconds after the previous vehicle, where x is a random variable sampled from an exponential distribution with a mean of r seconds.
Short gaps  are thus more probable than long ones.
Each vehicle takes b seconds to cros the railway tracks.
The model is shown graphically in Figure 6.4 
Figure 6.4 Level-crossing simulation model in graphic form.
The purpose of the simulation is to estimate mean vehicle queue lengths and delays for various vehicle densities and train frequencies.
Variables such as x and b in the preceding description are all specified by the user of the program, so that different situations can be modelled.
In this example the following specification is used: trains run regularly at 15-minute intervals throughout the 24-hour period.
The standard deviation of the differences between actual and scheduled train arrival times is 90 seconds.
The gate closes 30 seconds before the arrival of a train, and remains closed if the next train is due within a further 90 seconds.
Each vehicle takes 5 seconds to travel over the crossing.
The mean time between vehicles and the time taken by the train to cross the road are the factors that are varied; the following mean times between vehicles were used: 70, 35 and 10 seconds.
For each of these values there were two train crossing times: 10 and 30 seconds.
Six simulation runs were thus possible, with two train crossing times for each of the three vehicle separation times.
The results showed that, for a train crossing time of 10 seconds, the mean delay to road vehicles was 0.
14 second (70 seconds between vehicles), 0.23 second (35 seconds between vehicles) and 1.8 seconds (10 seconds between  vehicles) with the maximum queue length over a 24-hour period being 2, 2 and 8 vehicles respectively.
When the train crossing time was increased to 30 seconds the mean delays went up to 0.52, 0.75 and 3.0 seconds for the three vehicle separation times, and the maximum queue lengths became 2, 4 and 10 respectively.
The example shows that the use of this model allows the planner to examine the consequences of changes in the system (for example, a new train timetable, differing train lengths, greater variability in train arrival times, more road traffic) without carrying out experiments on the real world which, in this case, would be possible but would also be very expensive and inconvenient to road and rail users.
The conclusions reached by the planner would not necessarily be valid simply because a computer simulation model had been used.
One vital step missed out in the description above is the calibration stage.
The planner should take the model and, using real observations, assess the extent to which the output from the model matches real-world observations.
If the fit is not good then the parameters of the model are adjusted until a good match between real and simulated observations is found.
This calibration stage is essential for the planner would otherwise simply be testing his own preconceptions.
It would not be difficult to extend the rather simple model described above.
For instance, it is not realistic to expect that trains will run regularly at fixed intervals throughout the day and night, nor is it true that the mean time between vehicles is the same over a 24-hour period.
Additional programming would be needed to permit (a) the real train timetable to be entered and used by the program and (b) changes in the mean time between vehicles to take place at hourly or half-hourly intervals throughout the day to allow a closer representation of reality.
However, the simple model outlined above shows the stages of
specification of the properties of and relationships between the components of the model,
calibration of the model, and
validation of the inputs to the model in order to assess the effects of such changes on the behaviour of the model.
6.4 MARKOV CHAIN MODELS
The random-walk model described in Section 6.2 is based on the assumption that each possible state of the system (the stream flow direction in the example in Section 6.2) is equally probable.
In some geographical systems this is not the case, and the next state of the system is related to its present state.
This feature is called the Markov property and a sequence of observations possessing this property is called a Markov chain.
The state of the weather on a particular day could be taken as an example.
The weather might be described as ‘wet’ or ‘dry’(W or D) and, in a humid temperate climate such as Britain experiences, it might seem that state W is more common than state D. The reverse may apply in a semi-arid area such as Arizona or Nevada.
The occurrence of wet and dry days is thus not random — there is a persistence effect such that a wet day is more likely to be followed by another wet day than by a dry day, and vice-versa.
This is due to the duration and movement patterns of the weather systems (depressions and anticyclones).
If the state of the weather over a long sequence of days were observed, and record W or D for each, one could work out how often
a W is followed by another W,
a W is followed by a D,
a D is followed by a W, and
a D is followed by another D.
These four counts are transformed into estimates of probability by dividing each by the total number of observations.
If there were 1 000 observations altogether, and 500 represented state 1 in the list above (W followed by W) then the probability of a wet day following a wet day would be estimated as 0.5.
The four estimated probability values are conventionally represented as shown in Table 6.1.
In this table, p(l) is the probability that if it is raining today (time t) it will be raining tomorrow (time t + 1), while p(2) is the probability that if it is raining today it will be dry tomorrow.
Probabilities p(3) and p(4) estimate, respectively, the likelihood of (i) dry today, wet tomorrow and (ii) dry both today and tomorrow.
Another example of a Markov chain is the movement pattern of a business executive who visits four cities each week.
The order in which the visits occur is determined by the executive.
The travel pattern might be influenced by such factors as convenience, minimizing travel time and the nature of the business (for example, the businessman might wish to visit suppliers, manufacturers and retail outlets, in that order).
If the four cities are labelled a, b, c and d then, in order to estimate the probability that the businessman will travel from a to b on successive days (or c to a, or any other combination, including staying consecutive days in the same place) then some observations of his past travel pattern are needed.
These observations are converted to probabilities just as the weather data were converted to probabilities in the first example.
The table    of transition probabilities for the travel example would be laid out as shown in Table 6.2.
Transition probabilities p(1) to p(4) in Table 6.2 are calculated by counting the number of times the business executive stayed in city a and subsequently (i) stayed the next day in city a,(ii) moved to city b,(iii) moved to city c,(iv) moved to city d.
If the counts were 7, 2, 3 and 9 then we first find the sum of the counts (21) and divide each individual count by the sum of the counts to give p(1) = 0.33, p(2) = 0.09, p(3) = 0.14 and p(4) = 0.43.
The sum of these probabilities should be 1.0, meaning that the executive must do one of the four things mentioned.
In fact the sum is 0.99, the error being due to rounding to two decimal places.
From the four calculated probabilities it can be deduced that if the executive is currently in city a then the chance that he or she will (i) stay in city a is 33%,(ii) move to city b is 9%,(iii) move to city c is 14% or (iv) move to city d is 43%.
Probabilities p(5) to p(16) are found in a similar way.
Matrices of transition probabilities such as those given in the earlier examples are useful in that they summarize the behaviour over time of the system under study.
Transitions or changes which have a notably high or low probability can be identified, as reasons for their prominence sought.
Secondly, through the use of techniques of Markov chain analysis, the equilibrium state of the system can be established.
The equilibrium state describes the proportion of time the system spends in each state in the long term.
Thirdly, the table of transition probabilities can be used as the basis for simulation, for many different realizations of a process (travelling between four cities, or daily rainfall patterns) can lead to the same set of transition probabilities.
Each of these realizations is equally likely.
Such simulations, based on observed system behaviour, can tell us how things might have been if we are looking at unrepeatable, past, events or how the system might behave in the future, if the transition probabilities remain unaltered.
Thus, we might look at lithological changes through the geological column.
Changes in the state of the system, in this case changes from one rock type (for example, shale) to another (for example , grit) could be examined and counted in bore-holes and outcrops.
The Markov chain model might then be used to draw inferences about the lithological system from these sample observations.
To illustrate the points made above some data obtained from a study of the occurrence of clear and foggy days in the area of Los Angeles, California, carried out by Gong-Yuh Lin (1981), are used as an example.
From the data obtain at a number of air-monitoring stations, Lin produced a table of counts in the form shown in Table 6.3.
When the actual counts were converted to transition probabilities the results shown in Table 6.4 were obtained.
Table 6.4 shows that on about 75% of occasions the state of the atmosphere (foggy or clear) remained the same from one day to the next, and a change from one state to another occurred on about 25% of occasions.
The table can be used to estimate the average proportion of days which, in the long term and if these probabilities are representative, will be foggy or clear.
These proportions are found by the technique of powering the table of probabilities.
By powering is meant raising to the power of; thus, the single (scalar) quantity two can be raised to the power of three to give the answer eight.
A matrix is not a simple scalar quantity like 2 or 8 and a special technique is needed to carry out the operation of raising a matrix to the power n.
First of all, note that (in scalar arithmetic) we can find x to the power of y by a series of steps: first, multiply x by x to give x 2.
Next, multiply x by x 2 to give x 3 , and so on until x has been raised to the power y (xy).
The probability matrix is raised to successively higher powers in much the same way.
To raise a matrix to the power of two, the layout shown in Table 6.5 is used.
The matrix P with elements p, is multiplied by the matrix Q with elements q i to give the results matrix R with elements r i .
Each element of the results matrix is obtained by multiplying the elements of a row of matrix P by the corresponding column elements of matrix Q and adding the results.
In this case,
If this procedure is applied to the transition probability matrix given earlier then the result shown in Table 6.6 is obtained.
The elements of R (are calculated as explained earlier; the result is r i =0.65, r 2 =0.35, r 3 =0.37 and r 4 =0.63.
Matrix R is the transition probability matrix raised to the power two.
In order to raise the transition probability matrix to the power three the layout of Table 6.7 is used to get S. S is equivalent to P 3 , for R (=P 2 ) is multiplied by P to give 
The values in the first column of P 3 (0.58 and 0.44) are closer together than the corresponding values in the matrix P 2 (0.65 and 0.37) and much closer than the values in column one of matrix P (0.77 and 0.24).
The same is true of the second column — the two elements making up that column are getting closer together in value as P is raised to successively higher powers.
Eventually the two values in column one become effectively equal as do the two values in column two.
In this example, convergence occurs when the two values in column one   both become equal to 0.51 and the two values in column two become equal to 0.49.
This result is interpreted to mean that, in the long run, the system (atmospheric state) will be in state one (foggy) 51% of the time and in state two (clear) 49% of the time.
Because the calculations involved in powering matrices are repetitive they are ideal for the computer and so Markov chain analysis is normally performed with the aid of a computer program.
Many different patterns of foggy and clear days could produce the same numerical values for the transition probabilities in the example.
It is sometimes interesting to use the transition probability matrix to generate synthetic sequences of foggy and clear days; these sequences show patterns that might be expected to occur in the future (since there are an infinite number of alternative futures but only one present and one past).
Study of these alternative future sequences might show a particular tendency, with one type of pattern being more prevalent (and hence more likely) than others.
The steps involved in generating a synthetic sequence are:
1.
Decide arbitrarily whether the initial state of the system is F (foggy) or C (clear).
2.
Generate a pseudo-random number pr (Section 6.2) in the range 0.0–1.0.
If the present state is F then if pr is less than 0.77 then the state remains F or else the state becomes C. If the present state is C then if pr is less than 0.24 then the state becomes F or else the state remains C. The values 0.77 and 0.24 are obtained from the transition probability matrix shown in Table 6.4.
3.
Repeat step 2 until the desired number of realizations of the system has been attained.
Here are four synthetic sequences generated from the foggy/clear days transition probability matrix given above:
FFCCCCFCFFFFFFFFFFCFCCFFFFFFFFFF
FFCCFFFFFCFFFFFFFFCCCCCCCCFCFFCC
CCFFCFCCCCCCCCCCCCFFFFFCFCFCFFFF
CCCCCCFFFCCFCFFFFFFFFFCCCFFFCCFF
It is apparent from these sequences that the persistence of a particular state (F or C) is considerable; if one day is foggy then the next day is more likely to be foggy than clear, and vice-versa.
This is what the transition probability matrix tells us.
The length of the synthetic sequence should be long enough for a pattern to emerge; the length of the four sequences given above is not sufficient for reliable conclusions to be drawn.
For example, study of the third sequence might lead us to believe that foggy days are relatively rare occurrences at Upland, whereas the powered transition probability matrix gave a result of 51 % foggy days and 49% clear days.
The example shows how a system which can be in one of two states can be simulated, and how the results of these simulations can be used to gain some understanding of system behaviour and of the controls which influence this behaviour.
Real systems are rarely so simple; their behaviour can normally be described only in terms of many variables.
In the final sections of this chapter, examples of more complex systems are used, and consideration is given to the role of computer simulation techniques in understanding and predicting their behaviour.
6.5 POPULATION FORECASTING
The advent of the computer has made possible the development of complex simulations of situations in human and regional geography.
The great speed with which the computer carries out calculations means that experiments can be carried out quickly and cheaply.
The availability of on-line facilities and displays allows the inspection of results as a simulation proceeds through time and gives the operator the opportunity to make decisions about progress at regular intervals.
Perhaps the most important consideration in making any simulation that uses a computer program is to know exactly what steps and calculations are needed or, in other words, how a particular system works.
It is therefore necessary to know how the component variables of the system interact with each other.
Often the construction of a simple flowchart or systems diagram can help in this phase of comprehension.
In order to illustrate the procedure and problems of designing a simulation an example of changes in a human population will be taken.
The simplest way in which these changes may be projected through time is to take the total population at a given instant and to alter it year by year (or by some other period of time) according to a chosen assumption about future growth or decline.
For example, in a particular year a given region has x million inhabitants and the population is expected to increase at a rate of 2% per year.
To anticipate future populations, given such a rate of increase, a compound interest-type calculation is an obvious possibility.
It is often useful in the study of population to distinguish between males and females and also between different age-groups.
If forecasts of future population at 10-year intervals are needed, then the population can be divided into nine age-groups each representing a 10-year age-group or cohort (0–9 years, 10–19 years, and so on, to 80 plus).
More refined subdivisions of population by age are by five-year or even one-year age-groups.
The simulation proceeds by computing, for each age-group and for males and females separately, the number of deaths.
In any real-world population the death rate changes from one age-group to another while, for a given age-group, the male and female death rates are also different.
The number of deaths  computed for each age-group is subtracted from the population in that age-group before the number of births is computed.
The number of births depends on the number of females of child-bearing age, and the ratio of male to female births may be (and is normally) rather greater than 1: 1.
The number of births for males and females separately is added to the population of age-group 1 (0–9 years in the example above).
When an age-group limit is reached (every 10 years in the case of 10-year age-groups, or every five years in the case of five-year age-groups) then the population structure is updated by moving every age-group forward by one group.
The members of the last age-group are assumed to have a mortality rate of 100%.
A flow-chart of the model described in this paragraph is shown in Figure 6.5.
The results of a simulation based upon the model described above are shown in Figure 6.6.
Figure 6.6(a) shows the population structure of Peru in 1983 in the form of a population pyramid in which each of the rows represents a 10-year age-group with the lowest row representing the youngest age-group.
The symbols M and F stand for males and females.
If the simulation is run using estimated early-1980s fertility and mortality rates the population in 2003 would be as shown in Figure 6.6(b).
If, however, fertility rates fall for the four child-bearing age-groups (10–19, 20–29, 30–39 and 40–49) from the estimated early 1980s figures of 0.4, 2, 2 and 0.4 children per woman respectively to 0.25, 1.8, 1.4 and 0.3 children per woman then the population structure in 2003 would be shown in Figure 6.6(c).
The effects of different fertility and mortality rates can be assessed quickly, and our understanding of population growth can thereby be enhanced.
The model described above is relatively simple.
It does, however, represent a basic structure which can be extended and refined by, for example, subdividing the population into urban and rural components or considering the interactions between populations of several regions.
The effects of migration can also be allowed for, with appropriate assumptions made about numbers or proportions of population in the different age-groups and the two sexes moving between regions.
By now our model is beginning to get fairly complex.
A danger of including too much in a simulation is that the results get very extensive and perhaps difficult to comprehend.
The basic population simulation outlined above is adequate as a starting-point.
When applied to forecasts of present population it can reveal interesting possible futures or help to confirm more precisely suppositions already made.
If the recent pattern of population change observed in many developing countries were to continue without modification then, in a few decades, there would be some impossibly large populations.
On the other hand, without the use of a simulation model it is difficult to visualize the effect that changes in fertility or in mortality are likely to have on trends over the next few decades.
It is possible also to study the effects of drastic changes in existing fertility and mortality rates.
For example, planners in China do not seem aware of the cohort structure their population might have in decades to come if the drastic reductions in fertility    introduced in the 1970s are maintained for 20 or 30 years.
It is also possible to get data for past populations of countries, and to make alternative projections towards the present day, thus comparing what did happen with what might have happened.
In this way a greater insight into the ways in which population size and structure change may be gained.
Figure 6.5 Flow-chart of the population projetion model.
Figure 6.6 (a) Population pyramid for Peru, 1983. (b) Simulated population of Peru in 2003 assuming present mortality and fertility rates.
The model (Figure 6.5) assumes a closed system without migration.
(c) Alternative population structure for Peru in 2003.
The same mortality rates are used as in Figure 6.6(b) but fertility rates are reduced (see p. 191).
Other possibilities include the combination of changes in population (human or animal) with other elements and influences.
A situation that is basic and very widespread is the rural community in the developing world, represented by the largely self-sufficient village which is strongly affected by local environmental conditions.
The following ingredients might be combined into a simulation:
Human population, susceptible to the kinds of changes already outlined above.
Natural resources and environment: water, soil, possibly vegetation, climate (reflected in the growing season with hot-cold, wet-dry combinations from year to year).
Products from natural resources: crops (different crops preferring different physical conditions), pasture, livestock (as food, materials or work animals), firewood, clay for brick-making.
Needs of the human population: water, food, firewood, clothing, shelter, plus health, educational and transport facilities as well as luxuries.
Interactions between the community itself and places outside: in- or out-migration of population, the exchange of products, flow of information.
Such a model is of interest to geographers since it deals with man-environment relationships.
Already, though, such a study of a community involving, perhaps, only a few thousand people brings in many elements, variables and causal links.
How, then, was it possible to make a rather similar model for the whole world?
It must be appreciated that, although the population of the world is about a million times larger than the population of a large village, the model needed to make a reasonable study of some major world trends and problems is not necessarily much larger or more complex than the village model.
Indeed, while the village is an open system, influenced by many external forces, the planet Earth, as far as the human population is concerned, is a closed system apart from the fairly constant and essential energy supply from the sun.
The power of the computer was indeed appreciated and used in the late 1960s to make a model of the world system.
J. W. Forrester (1971) coordinated work on such a model and gives details of the methods and findings of his work.
Several basic elements were considered individually: population, non-renewable natural resources, cultivated land and agricultural capital, industrial capital, service capital and pollution.
Each element itself involves several aspects.
Assumed links between different elements (such as depletion of non-renewable natural resources through industrial growth, increased pollution resulting from increased industrial activity) were made in the model.
One version, described by  Forrester (1971, p. 20) as ‘a complete diagram of the world model, interrelating the five variables — population, natural resources, capital investment, capital investment in agriculture fraction, and pollution’ can be represented in a systems diagram with 43 separate elements and various links (Figure 6.7).
The Forrester model gained world-wide publicity when it was described in the book Limits to Growth by D. H. Meadows and his co-authors (1972).
The world model described above represents a landmark in the study of global problems.
Whatever the shortcomings of the assumptions made about cause and effect in the relationship between man and the environment (and man with man) the model shows how the use of a computer to carry out the vast number of calculations necessary to realize the model can allow the consideration of a very complex situation on lines not previously possible.
The world model of the early 1970s set people thinking — either to criticize its inadequacies or to suggest improvements.
The frightening prospects described in the Limits to Growth model may have driven geographers of the 1970s to turn to the problems of smaller areas.
The computer offers many possibilities to the geographer who does not aspire to the world model.
Some possible areas of application are:
the search for raw materials,
the location of economic activity,
the structure of transport networks,
the minimization of transportation costs,
selection of crop combinations, and
war games.
While programs already exist for many of these topics it is sometimes more satisfying if one has sufficient ability in computer programming to modify existing simulations or create alternative programs.
6.6 HYDROLOGICAL SYSTEMS
Section 6.5 closed with a description of the simulation of a large, complex system, namely, the world viewed as an integrated and interrelated set of elements such as population, resources, land, capital and pollution.
In this section the problem of modelling another complex, but spatially less extensive, system comprising the drainage basin of a river is considered.
The river basin is a well-defined spatial unit that is of great interest to hydrologists, geomorphologists and geographers.
Geographical interest in river basins stems largely from the fact that a large proportion of the world's population lives close to rivers, which act as sources of water supply for human consumption and for agricultural and industrial use.
Rivers also provide a means of disposing of waste, and act as a transport medium.
Rivers also flood, and such floods are sometimes very costly in terms of loss of life and destruction of property.
For example, the flood on the Hwang-Ho river in China in 1887 resulted in an estimated 900 000 deaths while in recent years India has suffered annual average losses of more than 700 people, 40 000 cattle and $90m in property damage.
Figure 6.7 Diagram of World Model interrelating population, natural resources, capital investment, capital-invested-in-agriculture fraction and pollution.
(Figure 2–1, J. W. Forrester, 1971, reproduced by permission).
A considerable amount of time and money has been spent in pursuing the study of river basin dynamics.
In part, these studies have been designed to improve scientific knowledge of river systems and in part to improve the ability of hydrologists to forecast how changes in land use, for example through increasing urbanization, will affect river levels (though the two are not necessarily distinct — improved scientific knowledge generally leads to improved accuracy in forecasting).
Past efforts have largely been concentrated on the study of experimental catchments but most studies are limited to analyses of effects on a single component of the hydrologic cycle, such as the effect of urbanization on flood peaks, or are relevant only for a particular geographical setting.
Consequently, the information from such studies has a restricted value.
The hydrological cycle model is well known (Figure 6.8).
The basic processes such as runoff, evaporation, precipitation and streamflow operate in a similar fashion, though in different proportions, in all drainage-basins.
A computer simulation based upon the hydrological should be able to allow many aspects of river basin behaviour to be considered simultaneously and also enable the simulation of the hydrological response of different basins.
This is  done by calibrating the model for a particular drainage-basin, that is, adjusting the model parameters until the output from the model closely matches records of the hydrological behaviour of the drainage-basin.
These parameters are then used in the model to predict the behaviour of the basin.
Figure 6.8 The components and processes of the hydrological cycle.
A number of numerical models of drainage-basin hydrology have been devised.
Among these are the US Department of Agriculture USDAHL model (Holtan and Lopez, 1970), the Tennessee Valley Authority Daily Streamflow Model (Betson, 1976) and the Stanford Watershed Model, which was the forerunner of the Hydrocomp Simulation Program (HSP), produced by Hydrocomp Inc., Palo Alto, California.
HSP is the most powerful of the available computer simulation models.
It was developed by N. H. Crawford and R. K. Linsley of Stanford University during the 1960s and has been continuously revised and updated.
It can accommodate simulations of drainage-basins ranging in size from a few hectares to 40 000 square kilometres.
Like other models, its use requires an understanding of the system being modelled, and so a brief description of the land phase of the hydrological cycle is considered next.
Figure 6.8 is a diagrammatic representation of the hydrological cycle.
Rain, snow and hail (collectively known as precipitation) fall on the Earth's surface.
A proportion is intercepted by the leaves and stems of plants, and some is evaporated back into the atmosphere.
Of the water which remains, part sinks or infiltrates into the ground and the remainder flows over the ground surface.
Some water collects in depressions on the surface; these depressions vary in size from the minute to lakes covering hundreds of square miles.
Water flowing over the ground surface as overland flow cuts channels, and these channels combine to form a stream network.
Of the water which infiltrates into the soil, some is taken up by vegetation and is transpired and the rest either flows down-slope through the soil as interflow or throughflow until it reaches a stream channel, or sinks through the soil to become part of the groundwater.
Groundwater flows down-slope towards the river channel, but the rate of groundwater flow is less than the rate of throughflow or of overland flow.
During dry weather, streamflow is maintained by the combination of throughflow and groundwater flow.
The actual rates of operation of the processes of precipitation, interception, evaporation, transpiration, overland flow, throughflow and groundwater flow depend upon climatic, vegetative, pedological, topographic and geological conditions peculiar to each drainage basin.
Figure 6.9 shows another view of the hydrological cycle.
This kind of diagram is a flow-chart or systems model.
It is much more useful to the author and users of the simulation model than the pictorial representation of Figure 6.8 for it shows the inputs, outputs and storages involved in the system.
The computer program must be able to take data relating to local conditions (slope, soil type and depth, amount and nature of vegetation cover, and so on) and output a streamflow record.
The information about local conditions is essential if   questions such as‘if x inches of rain falls in y hours on a given drainage-basin, how will channel flow respond?’ for the rates of operation of the different processes will depend on these local conditions.
For example, the rates of infiltration and throughflow will depend on slope, soil type, vegetation cover, depth of soil and other factors while the volumes of water stored as depression storage will depend upon surface topography.
The simulation model will also require data concerning the initial state of the system, that is, the amounts of water present in the various stores (shown in Figure 6.9).
Figure 6.9 Flow diagram representing a model of the interrelationships between the processes and components of the hydrological cycle.
Stage one of the use of a hydrological simulation model involves the provision of initial information about the drainage-basin.
Such information is obtained from maps and from hydrological and meteorological records.
Stage two is termed calibration.
It involves the testing of the performance of the simulation model using known events.
Given an initial set of conditions the model is run in order to see how closely the real and simulated events correspond.
Various parameters of the mathematical model, which represents the relationships between system components, are modified until real-world and simulation model behaviour agree as closely as possible.
Once this stage has been completed successfully then stage three is implemented.
At this stage the model is used to predict future events, using simulated sequences of precipitation that bear a close statistical resemblance to real sequences.
The statistical resemblance is measured by comparing mean values and ranges of actual and simulated sequences, as well as looking at the distribution of runs of wet or dry days.
The results from the model can be used to answer questions relating to the long-term behaviour of the river basin.
For example, given a suitable calibrated river basin simulation program a sequence of 100 or 200 years of daily observation can be generated and estimates made of the flow level that is exceeded on average once every 10, 50 or 100 years.
These levels are called the 10-year flood, the 50-year flood and the 100-year flood, respectively, and they are used by engineers and planners in the design of structures such as bridges and dams.
Another use of the simulation model might be to assess the effect of increasing the urban area lying within a river basin.
Precipitation is conducted to the nearest water course much more quickly in an urban area than it is in a natural drainage basin, so the building of a new town or the extension of an existing town can have a considerable effect on the rate at which the water level of a river rises after a storm.
The rate of increase of river flow will be greater in the urbanized basin than it would be if the basin were still covered by natural vegetation.
In both these examples it is clear that a major advantage of the simulation model is that answers can be more reliably obtained to questions such as‘how high should 1 build this bridge?’ or ‘what would be the hydrological effect of building another 2000 houses in Edwalton?’than if the engineer or planner were to rely solely upon rules of thumb or ‘common sense’.
Another example of the use of simulation models is in the estimation of the yield of a drainage-basin.
Rivers, together with groundwater reserves, supply much of the water used for domestic, industrial and agricultural purposes.
Overuse can lead to pollution, declining groundwater levels and, eventually, to trouble of one sort or another; internecine feuds were reported in southern Spain in the summer of 1983 when river levels were at an all-time low.
For the sensible management of water resources, good estimates of the total amount of water available, on average, per year together with a measure of the variability in supply from year to year if supply and demand are to be kept in balance.
Such estimates can be made readily if a basin simulation model is used.
6.7 SUMMARY
Simulation is the representation of a system in terms of another medium or at another scale.
A simulation model could be, for instance, a physical model such as a wave-tank model of a beach.
Digital or computer simulation uses the medium of mathematics to represent a system and its behaviour.
Mathematical expressions are used to represent real-world relationships.
The advantages of computer simulation are:
speed of execution — 100 years in the life of a watershed can be simulated in a few seconds of computer time, and
flexibility, which implies that the computer simulation model can be altered easily to take account of changes in circumstances or to allow modelling of a different system.
Experiments using the simulation model are thus made possible; an example given earlier showed how a planner could modify a river-basin simulation model to allow for the expansion of an urban area.
Such flexibility is not possible with a physical model.
Computer simulation models which incorporate random effects have been described in this chapter.
This kind of model is termed a stochastic model, and examples include random-walk models of stream patterns and river-basin simulation models which use randomly-generated rainfall sequences.
Other simulation models, such as population projection models, are usually deterministic.
A random element is incorporated into stochastic models to summarize or act in place of a number of small, independent processes.
No matter whether the stochastic or a deterministic form is used, the successful use of the model will depend on two factors, which are
the degree of understanding of the operation of the system that we possess, and,
the quality of the data used to calibrate the model.
The first factor helps to explain why simulations of physical systems are often more successful than simulations of social, demographic or economic systems, for physical systems are generally easier to isolate, identify and characterize.
In addition, human systems may well respond or adapt to the predictions of a model, which become, in effect, self-fulfilling prophecies.
If the Treasury economic simulation model predicts 15% inflation in 18 months' time then people's behaviour may well be influenced by the expectation that the model is correct in its predictions, no matter how good or objective the data on which the simulation was based.
6.8 REVIEW QUESTIONS
1.
Define:
random walk
population cohort
hydrological system
deterministic model
random number
closed system
calibration of model
Markov chain
open system
stochastic model
2.
Describe the types of simulation model generally used by geographers.
In what way do they differ?
3.
Summarize the factors which make simulation models necessary to and useful in geographical studies.
4.
Outline the problems met with in designing a model to simulate changes in the size and structure of a human population.
CHAPTER 7
Geographical Information Systems
7.1 INTRODUCTION
A widely-accepted model of the relationships between the Earth's atmosphere, land and oceans and their component pads is that of an open system made up of interrelated subsystems (Chapter 6; Chorley and Haggett, 1969).
The boundaries between these subsystems, such as the hydrological and the atmospheric subsystems, are not sharp or clear.
Furthermore, our perceptions of the behaviour of these subsystems depend strongly on the scale at which they are observed.
Subsystems can, for ease of human understanding, be labelled as physical (such as geology, hydrology, climate, soils, vegetation and fauna), economic (trade, transport, industry), political (organization, population size and distribution) and so on.
Much of geography over the last 40 years has been concerned with analysing these subsystems by breaking down each subsystem into ever smaller component parts and studying these parts, and their interrelationships, at an increasing level of detail.
On the other hand, decisions about real-world problems involve the integration or synthesis of these various subsystems, and the appreciation of interactions between them.
Perhaps the most topical example concerns the relationship between global-scale systems of vegetation, climate, oceans and human activity which are thought to influence, or at least accelerate, processes of global environmental change.
In a more localized example, a county planning department would need to consider a wide range of environmental, economic, political, social and spatial factors when deciding on a site for a public service utility such as a thermal electricity generating station.
A distinction can therefore be made between approaches to the study and application of geography that involve the analysis of systems on the one hand and the synthesis of facts and knowledge concerning sets of systems and related to particular places on the other.
These approaches have traditionally been termed systematic and regional geography.
Earlier chapters of this book have been concerned with the analysis and display of geographical data.
This final chapter looks at ways of putting it all together.
Readers will therefore find it helpful if this chapter is read last.
Computer systems for the integrated handling of geographical or spatial data are called Geographical Information Systems or GIS for short.
The most commonly-used device used by geographers to integrate data relating to the physical, social, economic and political characteristics of an area is the map.
A map is both a repository of facts and a tool for drawing inferences.
The first of these properties is readily appreciated by looking at an atlas.
Questions such as‘what is the name of the river on which New Orleans stands?’ or ‘what is the height of Ben Nevis?’can be answered by referring to the appropriate page of the atlas.
The second property, that of allowing inferences to be made, requires a map showing two or more features of an area, such as the distribution of tree species and height above sea-level.
The human eye and brain can produce generalizations such as‘in this particular area, pine trees grow only at heights greater than 90 metres above sea-level’.
This type of generalization requires the comparison of maps showing the two spatial patterns of elevation of the terrain above sea-level and the distribution of pine trees over that same terrain.
It is evident from this discussion that a map contains two distinct types of information.
One type refers to the geographical location (both absolute and relative) of spatial entities (the points, lines and polygons considered earlier in Chapter 2) and the other data type refers to the properties or attributes of such spatial entities, for example the height of a point such as a hill top, the width of a road (line) or the area of a State (polygon) Table 7.1).
In drawing the inference above, concerning the relationship between the occurrence of pine trees and height above sea-level, we used (i) the location of individual points and (ii) the two properties of those points, the first being a continuous variable (height above sea-level) and the second a binary or presence-absence variable (pine trees/no pine trees).
Queries that can be answered by a map can refer to either or both types of data.
One type of query refers solely to the absolute or relative locational properties of the spatial entities.
Some examples are:
Given a network of lines representing highways, what is the shortest route between any two points in the network?
How many of a set of points at which rainfall is measured lie within 50 km of Cambridge (relative location) or in the rectangle defined by the lines of latitude 55°N and 58°N and the lines of longitude 1°W and 3°W (absolute location)!
Show the region lying within 5 km of the M1 motorway.
Other queries may relate to specific attributes of the spatial entities, or to combinations of these attributes, to the exclusion of any locational property.
Examples of this kind of query include: How many states of the United States have a population greater than two million people?
What percentage of the area of New Jersey is classified as urban?
What is the population density (persons per square kilometre) of Alaska?
The third kind of request relates both the locational properties of spatial entities and their attributes: for example, pick out those regions of type X which have among their neighbours at least one region of type Y. List those states of the USA which have more than 1000 kilometres of Interstate highway.
Find all towns in the state of Texas that have a population of more than 10 000 and are more than 50 kilometres from a railway.
These types of questions cannot be answered easily by looking at a conventional map.
First of all, no map can show all the attributes that may conceivably be required by a user.
Two or more maps would be needed if the detail shown is not to get too great to be displayed or absorbed by the user.
Thus, in order to answer a particular query maps showing geology, soils, transportation, elevation, slope, drainage lines, vegetation types, populations of towns and planning designations may be required.
If the area of interest is not trivially small then it would not be possible to show all this information on a single map.
We would thus have to resort to the use of overlays, with one overlay per attribute.
If each overlay were drawn on transparent paper then a light table could be used to allow the viewer to look simultaneously at the spatial distribution of each attribute and to pick out by eye the areas of interest.
The second reason why conventional maps are unsuitable for the answering of the types of queries mentioned above is that the human eye and brain cannot take in the amounts of information that would be present in the overlays and in the accompanying tables of figures and statistics.
The volume of information that would have to be absorbed is simply too great.
If the cartographic and tabular data could be stored in computer-readable form, then the speed of the computer could be used to select areas with the required characteristics, derive composite maps, and perform other operations that would be impossibly time-consuming if carried out by hand.
A Geographical Information System provides just such capabilities.
A GIS can be represented as a means of producing digital overlays of spatially-referenced information, together with the means of entering, recovering, processing and displaying information present in these overlays (Figure 7. 1).
It has been estimated that over 100 GIS are in use in the United States.
This number is expected to grow to 4000 over the next five years.
Several private-sector companies have specialized in the production of GIS; among the best known are Arc-Info (ESRI, USA), Intergraph (Intergraph, USA), Informap (Synoptics, USA), 1 2 S (International Imaging Systems, USA), SPANS (Tydac Technology Ltd, Canada), Sicad (Siemens, Germany), METROPOLIS (LaserScan Ltd., UK) and System 9 (Prime Computers, USA and Wild Heerbrugg, Switzerland).
(These products are mentioned for information only; such mention should not necessarily bc taken as a recommendation.)
Geographical Information Systems that can run on a personal computer are now becoming available; examples are SPANS and PC-ARC/INFO.
All of these systems have several characteristics in common, namely data entry and editing, data manipulation, data display and modelling.
These features are considered in turn in the following sections.
Figure 7.1 Conceptual structure of a geographical information system: maps of various features are converted to a common scale and projection so as to allow the identification of regions that satisfy particular requirements.
7.2 DATA ENTRY AND EDITING
The data stored and manipulated within a GIS are of two specific kinds.
The first is cartographic and defines the relative or absolute location of spatial entities (points, lines and polygons) in the area of interest.
The second kind of data consists of the attributes or properties of the spatial entities shown on the maps.
Cartographic data consist of digitized maps, that is, maps which have been converted to numerical form by the process of digitizing, which was described in Chapter 4.
Each feature of a conventional topographic or thematic map is stored separately in a cartographic database, which consists of a number of files.
Files were described in Chapter 1.
Each file holds, in digitized form, point, line and polygon information defining, for example, a road network, a set of soil boundaries, river lines, or sites of historic importance.
The list given above is just a selection; an operational cartographic database would hold many more features.
Table 7.2 lists the cartographic data files held by the State of Maryland GIS (the Maryland   Automated Geographic Information System).
The importance of the file-structured database lies in the fact that the contents of the individual files can be abstracted and combined to serve a particular need.
The way the database is structured (Chapter 2) will, however, determine the types of question that the information system can be asked.
(Source: MAGI: Maryland Automated Geographic Information System, Maryland Department of State Planning, Publication 81–13, revised April 1981, Baltimore, Maryland.
Reproduced by permission.)
In Chapter 4 a brief account of the process of map digitization was given.
The manual procedure involves following lines (such as contour lines or election district boundary lines) with a pen or stylus.
An intelligent controller can track the position of the pen and record its location either at a fixed rate (such as 16 times per second) or whenever the operator presses a button.
More expensive systems use laser beams to follow lines.
A third kind of digitizer is becoming more popular.
This is the scanning digitizer which uses an advanced type of TV camera to convert the map to raster or cell format (Chapter 5).
This is the pixel format in which remotely-sensed images are stored.
The raster-coded image, in its simplest form, has the value ‘1’ wherever the cell lies over a line and the value ‘O’otherwise.
Scanning has to be followed by computer processing to join up, follow and extract the lines in vector format for storage in a cartographic database.
Figure 7.2 shows  the distinction between raster and vector representation, and further discussion can be found in Chapter 2.
The choice of method of digitizing depends more often than not on the level of funding available.
Manual digitizing is slow but is relatively accurate and cheap.
Laser scanning is fast and expensive.
Raster scanning/vectorization is also fast, and involves almost no user intervention.
However, the cost is high (but falling) and the quality of the final product is sometimes not up to the standard of high-class manually digitized material.
Figure 7.2 Raster and vector representation of locational data.
The vector data in the upper figure are stored as a string of (x, y) coordinates.
The correspondence between the vector and raster representations depends upon the fineness of the raster grid (lower figure).
An increasing amount of cartographic data is becoming available in digital form.
In the United States the US Geological Survey already provides digital elevation models (DEMs) and digital line graphs (DLGs).
The latter were described in Chapter 2.
A DEM is a grid of terrain elevations which can be converted to vector (contour line) form.
Digital maps of slope and aspect can be derived from a DEM if a suitable computer program is available.
The Ordnance Survey of Great Britain is also providing a limited amount of digital map data and DEMs.
Processed remotely-sensed images are another source of machine-readable cartographic data.
A classified Landsat TM image (Chapter 5) can be used to derive boundaries of spatial classes such as cropland, woodland and water, and remote sensing provide a means of keeping the data concerning land-surface cover that are stored in a GIS up to date.
It is likely that the availability of digital cartographic data will increase as demand from users of GIS becomes greater.
Editing of cartographic data files is necessary because of errors or deficiencies in input or in the results of data processing.
Gross errors can be detected by displaying the digitized map and scrutinizing it.
Such errors should be amenable to correction without the need to redigitize all or part of the map.
A deficiency of some manually-digitized data is due to the inclusion of more points than are needed to define the position of a line to a given level of accuracy.
For example, the number of points needed to define a straight line is two.
Points other than the end points of the straight line are redundant and can be removed without compromising the accuracy of the representation and with the benefit that storage space will be reduced (Figure 7.3).
If the x, y coordinates of each point are stored in four-byte units then eight bytes will be saved for each excess point removed.
The process of checking for unnecessary points on a digitized line should be capable of being performed within the GIS.
Another type of error that a GIS should be able to detect and correct is closure error in a digitized polygon, which is shown in Figure 7.4.
The closure error is usually treated by assuming that it is equally distributed over the polygon nodes whilst ensuring that neighbouring polygons are also corrected for any changes in point location.
The last kind of editing function that will be considered here relates to the result of processing of cartographic data files.
The overlay of two sets of polygons representing (for example) soil and geological boundaries respectively may result in discrepancies in the form of small ‘sliver’ polygons  (Figure 7.5).
Such slivers may be an accurate representation of the true situation but it is more likely that they are the result of inaccurate digitization, imprecise surveying, or the use of maps of considerably different scale.
A GIS should be able to identify and remove slivers, and correct the resulting map appropriately.
However, error resulting from map generalization cannot be removed automatically.
Figure 7.3 Editing of input data.
Elimination of the points shown by open circles does not compromise the accuracy to which the line can be represented on a digital plotter, yet computer storage and processing times are reduced.
The number of points needed to represent the line will depend upon the scale of the map; there is no universally-valid number.
Attribute data relate to the properties of the points, lines and polygons that are stored in the cartographic database.
The attribute data are held in a separate database.
Each attribute or set of related attributes is stored in its own file.
One such file might hold demographic attributes for the individual counties of a given state; these attributes would include total population and population  broken down by age and sex while a second attribute file would store the mortality (death) and morbidity (sickness) rates for the same counties.
These attribute files can be envisaged as tables.
The rows of each table refer to the spatial entities, whether they be lines, points or polygons, while the columns refer to the variables that are measured on these spatial entities (Figure 7.6).
Attribute data is most often obtained in computer-readable form direct from agencies whose function it is to collect and distribute such data.
The best-known example is the census of population.
Other sources of attribute data are published maps (such as maps of soils and geology) and publications associated with such maps.
Figure 7.4 Closure error in polygon digitizing.
Points A and B should be the same, but operator or system errors have resulted in a discrepancy.
The error can spread over the polygon by altering the positions of the boundary points appropriately.
However, it must be remembered that these points also lie on the boundaries of adjacent polygons.
Figure 7.5 Silver polygon formed by inconsistent digitizing of the boundary between polygons A and B. Use of a data structure requiring that lines be digitized once only is preferred; compare the data structures used by SYMAP and GIMMS in the examples in Chapter 4.
SYMAP requires separate digitization of each polygon, whereas GIMMS requires separate digitization of each line.
The polygons are then assembled from a description of their boundaries.
Chapter 2 contains a discussion of alternative data structures for spatial data.
Figure 7.6 Example of table holding attribute data for a set of areas.
The table is stored as a disc file, with each row of the table being held as a record (see Chapter 1).
Sets of related files are managed and organized by a Data Base Management System (DBMS).
The problems associated with data collection, input and editing should not be underestimated.
Indeed, it is possible to speculate that the progress of GIS is not being held up by lack of technology or of suitable software but by the cost of acquiring the data necessary for the functioning of the GIS.
Typically, the cost of acquiring, checking, editing, and converting data may be of the order of the system hardware and software costs while the time required to assemble and check the cartographic and attribute databases may be of the order of several years.
The need for data is not restricted to this start-up period, for new data are being generated continuously as roads and towns are built, and as the population changes both in size and constitution (due to births, deaths and disease) and spatial location (due to migration).
Perhaps the greatest mistake in the application of GIS has been to allow the glamour of the technology to distract attention from the more mundane, yet vital, aspects of data acquisition and verification.
7.3 DATA MANIPULATION
The major attraction of a fully-fledged GIS is that it gives access to large volumes of cartographic and attribute data which can be manipulated according to the needs of the user and the flexibility of the system software.
An overview of the manipulative functions offered by a GIS for both cartographic and attribute databases is given in this section.
Cartographic data manipulation operations include
transformation of data from one map projection or scale to another,
joining of adjacent maps,
polygon extraction,
polygon overlay and selection,
buffer generation,
network analysis, and
redistricting.
These functions are considered in turn.
Transformation from one map projection to another will be necessary where two or more maps to be overlaid are drawn on different projections or on different scales.
Snyder (1982, Appendix B) lists 20 map projections used by the US Geological Survey, and individual states make use of their own projections and grids.
The same is true of the individual countries making up the European Community.
It is also not uncommon to find that the projection used to map a particular phenomenon is altered from time to time.
Hence, the ability of a GIS to transform map data quickly from one map projection to another is essential if multi-source and multi-temporal data are used.
The topic of map projections is covered briefly in Chapter 4, while the conversion of satellite imagery to a cartographic coordinate system is considered in Chapter 5.
Thematic maps from satellite imagery represent an important source of data, particularly in third-world countries.
Captain Edward Aloysius Murphy is alleged to have said in 1949 that if a way exists to do a job wrongly, one day someone will do it that way.
This observation is applicable to GIS in a modified form.
A spatial area of interest to a geographer will, if possible, lie in the corners of four adjacent map sheets, thus increasing the cost of acquiring maps and maximizing the inconvenience involved in using the maps.
A fully-operational GIS should be able to extract an area of interest, given the coordinates of two opposite corners of a rectangular region containing the area, irrespective of the number of map sheets that the region occupies.
The map sections should be joined together without the seams being visible.
It may be the case that adjacent maps use different projections or scales.
This can happen if a map series is being updated; for example the Ordnance Survey of Great Britain changed its standard scale from I: 63360 (one inch to a mile) to 1: 50 000 (one centimetre to 500 metres) during the 1970s.
A GIS should be capable of handling this problem.
An area of interest is not necessarily rectangular; a GIS must be able to handle the general case in which the area of interest is polygonal.
Examples are counties, states, islands, lakes or geological regions.
If we wish to study Lake Tahoe from the point of view of hydrology, fauna and water quality we may find it necessary to extract from maps of these features the polygonal area defining the extent of the lake.
The separate polygons showing the hydrological, biological and water quality parameters of Lake Tahoe should be capable of being overlaid.
In some cases the overlay will not be completely accurate as the different maps may have been produced at different times by different teams of surveyors.
Indeed, the outline of the lake may have altered in the times between the individual surveys.
The result will be the generation of sliver polygons along the boundary of the lake.
A GIS is capable of identifying such slivers and allowing the user the choice of leaving them as they are or of replacing them with an average boundary position.
If the spatial feature of interest is linear (such as a boundary, river, a railway or a pipeline) then the user of a GIS may wish to generate buffer zones on either side of the linear feature.
These buffer zones could define regions of ecological interest (such as habitats defined by distance from a forest edge) or environmental (noise levels as a function of distance from a highway, aircraft flight path, or railway).
Given the location of the linear feature the GIS is able to define the boundaries of the buffer zone and extract those geographical features of the zone that are required by a user.
A set of linear features forms a network.
Examples are river and road networks.
If the road network of an area is taken as an example one could envisage it as a set of nodes (representing junctions) and links (the section of road between two junctions).
The nodes (junctions) may have attributes if they represent geographical entities such as towns and cities, and the links have the  attributes of distance, traffic capacity, average speed sustainable by a car.
Questions that are often asked about networks of this type are: what is the fastest route from A to B?
Is it possible to travel through the network visiting each of a specified set of nodes only once?
What is the most efficient way of travelling from A through B and C to D?
If such questions can be answered by a GIS then considerable sums of money could be saved by companies involved in distribution and sales.
A branch of mathematics called network analysis has developed to provide the answers to the type of problem just cited, and network analysis algorithms are incorporated into comprehensive Geographical Information Systems as well as being available for stand-alone PCs.
The final example of a cartographic operation that can be carried out by a GIS is redistricting.
This term refers to the generation of a set of boundaries to define regions or areas which have a particular property or set of properties.
Thus, electoral districts in the United States must have, as far as is possible, an equal number of voters, since all men (and women) are considered by the US Constitution as having been created equal.
If the census data and the voters' register are available for each block in a particular city then electoral boundaries can be defined on the basis of equal voting populations per electoral district, and maps of these districts can be drawn.
The UK practice is rather more subjective and takes into account socio-economic factors as well as absolute numbers of voters.
However, constituency boundaries are changed from time to time.
While perhaps improving the democratic process this redistricting procedure does mean that comparisons between electoral districts over time is difficult, since the boundaries of the units are not constant from one decade to the next.
The manipulation of tables of data such as the census data used in the example in the preceding paragraph is a problem not unique to geography.
The rows of the table could refer to any set of objects (such as the cars produced by Rover) and the columns to the properties of these objects (for example the parts required in the manufacture of the cars).
Questions such as‘how many pads are unique to a single model?’ could be asked.
Most large commercial corporations and government agencies have assembled sets of tables of this kind.
They are called databases.
Computer manufacturers and software developers have invested large amounts in building computer programs to handle queries addressed to these databases.
The computer programs are generally highly complex but are becoming more and more user-friendly as psychologists and computer scientists develop easier-to-use human-computer interfaces or ‘front-ends’ using the concepts of artificial intelligence.
Database Management Systems (DBMS) form a growing proportion of business in the software world.
Several kinds of DBMS are in use, and the interested reader should refer to an introduction to database management systems for a guide to the different types.
The review by Date (1986) is recommended.
The easiest type of DBMS to understand and use is the Relational Database Management System or RDBMS, which was mentioned earlier in this chapter.
A RDBMS uses the concept of the table (with the traditional row-column layout) as its basic structural entity.
Each table is stored as a file on the disc system of the computer (see Chapter 1) and tables can be searched for occurrences of events like ‘all spatial entities having attributes A and B but not C’.
There are thus two types of query that are answered by a GIS.
One relates to the absolute and relative locational properties of the spatial entities themselves (the points, lines and polygons) while the second refers to the attributes or properties of the spatial entities.
Of course, the user of a GIS would not be concerned exclusively with relative or absolute location to the exclusion of the attributes of the spatial entities, nor would he or she be interested solely in the non-spatial characteristics (the attributes) of the spatial entities.
However, in each particular phase of an enquiry, the primary concern would be one or the other of these two types of query.
In order to be able to handle these queries the GIS has two database systems.
One handles spatial queries, which refer to absolute locations or to spatial relationships (such as adjacency or contiguity).
The latter type of relationship is sometimes called topological.
The second DBMS handles queries concerning the attribute set.
For example, the ARC/INFO GIS produced by ESRI uses its own ARC spatial database system and a third-party relational database management system called INFO.
The two are interfaced together so that queries that are primarily spatial can also access the attribute data, and vice-versa.
7.4 DISPLAY OF DATA AND RESULTS
The techniques for displaying spatial data have been reviewed in previous chapters.
These techniques can be divided into two kinds: those which produce a permanent paper or photographic (human-readable) output and those which generate a temporary display on a television monitor screen.
Most large-scale GIS use the television monitor display in an interactive fashion, so that users can manipulate the scale, colouring and annotation of an output map until they are satisfied.
At this point the map can be sent to a hardcopy device such as a graphplotter, an electrostatic printer, an inkjet or matrix printer (in descending order of quality and cost).
These devices were described in Chapter 4.
Temporary screen displays are generated on a high-resolution monochrome or (preferably) colour monitor with at least 640 phosphor dots in the horizontal direction and 400 dots in the vertical direction.
The number of dots on the screen (in this case 640 by 400) defines the resolution of the screen.
Higher resolution costs more money but if the resolution is too low then straight lines look jagged and circles become regular polygons.
Some computer systems use raster graphics which generally have a lower resolution than the more expensive vector graphics.
The distinction between vector and raster systems was made in Chapter 4.
Not all of the output from a GIS is in the form of maps.
Provision must also be made for the output (in hardcopy form) of tables and graphs.
Ideally a software interface will exist to connect the cartographic, tabular and graphical output from a GIS and the report-generation capabilities of a high-quality word-processor, thus allowing the results provided by the GIS to be incorporated directly into a document.
7.5 MODELLING
The world is not static.
If it were, planning would be a very boring occupation.
As it is, the greatest rewards accrue to those who, like Arthur C. Clarke, are most successful in forecasting events.
Not all of us can aspire to this level but we can ask questions such as‘what would be the effect of building a motorway between towns A and B?’
Could we forecast the effect of the new road on traffic flows or on the price of adjacent land suitable for commercial or residential development?
If we live in a free society we cannot carry out experiments on the real world so it would not be possible to go ahead and build the road just to see what would happen.
Simulation techniques have been developed to allow scientists and planners to build working models of the systems which they are studying.
Experiments can be carried out on these models rather than on the world represented by such models.
The examples in Chapter 6 showed how these simulation models could be used in geography.
To be used successfully a simulation model must adequately represent the system under study and there must be sufficient relevant data available to allow for the calibration or tuning of the model.
It should be apparent from the earlier sections of this chapter that a GIS provides both a database of spatial and attribute data and the software tools needed to manipulate and transform those data.
A flexible GIS will also allow the user to experiment by building models of alternative future realities, such as the road development mentioned earlier, and to evaluate the outcome of such developments.
As the volume of digital data becomes larger, and the pressures on the environment increase, so the use of a GIS to evaluate alternative planning strategies will become more cost-effective.
7.6 EXAMPLES OF GIS APPLICATIONS
7.6.1 Land use and environment
One way of understanding the world is to see it in terms of the relationships within and between a set of interrelated systems, as described in the opening paragraph of this chapter.
This approach is becoming more widely accepted; for example, the following statement appears in the Report of the US Committee on Earth Sciences (1989, p. 4): ‘environmental changes are the result of complex  interplays among a number of natural and human-related systems.
For example, changes in the Earth's climate involve not only winds and clouds in the atmosphere, but also the interactive effect of the biosphere, ocean currents, human influences on atmospheric chemistry, the Earth's orbital characteristics, the reflective properties of the planet, and the distribution of water between atmosphere, hydrosphere and cryosphere’.
The development of a GIS capable of storing and manipulating the volumes of data required for a global research programme is still some way off, but smaller GIS have been used to attempt to provide at least a beginning.
One such is an experimental GIS which has been developed for the CORINE (Coordinated Information on the European Environment) programme of the European Community.
This program was begun in 1985 to harmonize the collection of data on the state of the environment in the European Community in order to improve environmental policy formulation and implementation (Wyatt, Briggs and Mounsey, 1988).
Before an integrated environmental database could be established, it was necessary firstly to define standards for recording environmental information, secondly to develop modelling procedures to give predictive capabilities, and thirdly to specify appropriate hardware and software.
Since the programme lasted only four years (1985–1989) and had a modest budget a limited number of priority areas was selected as follows:
ecological sites of major importance for nature conservation;
acid deposition, especially in relation to atmospheric emissions and potential damage to ecological sites and the soil;
resources and problems of the Mediterranean region, including land use, land quality, water resources, problems of coastal regions and seismic risks.
In order to provide sufficient information on the three principal themes, data on around 200 individual environmental variables are in process of collection and recording.
In addition to this attribute database a cartographic database is also being developed.
In this cartographic database will be digital maps of coastlines, hydrography, slope, aspect, settlements, and administrative boundaries.
In all, these maps correspond to 10–12 overlays.
At a 1: 1 000 000 scale each overlay consists of 200 Mb of data, a figure that is expected to increase to 500 Mb when the digitization programme is completed in 1989.
A further 25 Mb of data at a 1: 3 000 000 scale will also be stored.
The experimental GIS is mounted on a DEC VAX 11/750 running ARC/INFO software at Birkbeck College, University of London.
A second workstation, running the Siemens SICAD software, is installed in the CORINE office in Brussels, and a third system, used for collecting land-cover data from remotely-sensed data for the territory of Portugal, is based on an I 2 S image processor.
The CORINE GIS is still under development, and problems of data checking and verification will occupy a considerable amount of time before the GIS will be capable of producing reliable information.
It is, however, in regular use by  the Environment and other Directorates of the European Community and other collaborating national and international agencies.
As it is one of the first international environmental GIS, the CORINE experience will be valuable in stimulating other, similar, projects and in providing experience on which other projects can draw.
A second international programme that is worthy of mention is the United Nations Environment Programme (UNEP), which was established in 1983 to coordinate global environmental management.
One of the first environmental hazards to be studied was that of desertification.
Key variables that were considered to affect the rate of desertification were soil status, vulnerability of land to desertification, and human and animal population pressures.
Maps showing the distribution of these variables at a scale were digitized and desertification models developed by the United Nations Food and Agriculture Organization (FAO) were used within the GIS to produce hazard maps and summary tables.
A second stage of the UNEP project was to start the Global Resource Information Database (GRID).
The African continent was selected for the pilot project, and in 1987 a national environmental database for Uganda was established, using existing data and information derived from remotely-sensed images.
This database was used in modelling crop suitability and erosion potential.
Beginning in early 1988 a second phase was begun, and remotely-sensed data were selected as the source for databases on global forest resources and land degradation (Aronoff, 1989; Mooneyhan, 1987).
7.6.2 Social, economic and demographic
The South East Regional Research Laboratory (SERRL) of the UK Economic and Social Research Council (ESRC) is based at Birkbeck College and the London School of Economics, both colleges of the University of London.
The most important aspect of the work of SERRL to date is centred on the building and maintenance of an integrated settlement and infrastructure database for South East England (Shepherd and Conway, 1988).
The term integrated reflects the fact that the information in the database is referenced by its geographical location, so that maps of any part of the region can quickly be accessed.
This is not the only advantage offered by an integrated spatial database for, given appropriate GIS software and hardware that are jointly capable of providing the kind of operations described in the earlier part of this chapter, geographical referencing opens up the possibility of combining cartographic and attribute data in logical ways, such as in determining those areas which possess characteristic A and (or/not) characteristic B.
The database holds 12 layers of cartographic layers, digitized from Ordnance Survey 1: 50 000 map sheets.
The main layers are:
settlement;
transport networks, including roads, surface and underground railways, and some utility distribution networks;
administrative boundaries (wards, districts, counties, and electoral constituencies);
planning areas (green belts, areas of outstanding natural beauty, development corporations, and sites of special scientific interest).
In addition, quantitative information from the 1971 and 1981 censuses and from other sources describing networks, areas and other infrastructure items such as air terminals, ports, bridges and tunnels is stored.
Over 250 Mb of storage are required for the database, which is accessed by an ARC/INFO geographical information system running on a DEC VAX 11/750 computer.
‘The separate elements of the database add up to the essential spatial framework, in a co-ordinated and computerized format, for carrying out academic, commercial and policy-oriented studies in one of Europe's fastest growing regions’(Shepherd and Conway, 1988, p. 14).
Some examples of the use to which the SERRL database has been put are: the examination of the accessibility of small and medium-sized towns to the motorway and trunk road network in promoting population growth, the analysis of the hinterlands of each of the 900 stations on British Railways' South Eastern Region, and updating the urban/rural boundary lines using remotely-sensed data.
The population growth study took into account both accessibility and the impact of planning policies, including constraints such as green belts.
The GIS gave rapid and easy access to the data in a number of different ways, it provided analytical tools for the production of statistical tables, and it allowed the output of maps and specific factors, such as the overlay of the road network onto the green belt layer, showing areas of high and low accessibility, thus permitting the evaluation of population growth potential relative to accessibility and planning constraints.
The second study used the transport layer of the database to identify the locations of 900 stations on the British Railways network.
Circles of radius one, two, five and ten kilometres were drawn around each station and the census enumeration district data were used to produce maps and tables showing population numbers, structure and characteristics around each of the stations' catchment areas.
Remotely-sensed data from the French SPOT satellite (Chapter 5) are being used in the third study to augment the cartographic data layers.
Remotely-sensed data are acquired at regular time intervals, and thematic information such as land use can be obtained from such data using the techniques of classification described in Section 5.6.4.
The urban-rural boundary can be monitored effectively and the cartographic database updated regularly using this combination of data and image processing.
7.6.3 Planning
A particular east-coast state of the United States, which has several large population centres, requires an assessment of potential sites for new major public facilities, in particular coal-fired electricity generating stations.
The criteria governing the location of such facilities include:
(i) Environmental
Cooling water shall cause minimum disturbance to the aquatic ecosystems of rivers and estuaries;
sulphur-bearing smoke shall not pass over urban areas;
the chosen site must not interfere with or reduce the value of scenic and recreation areas, nor must the habitats of rare or otherwise important plant and animal species be disturbed;
If possible the buildings and other structures associated with the facility should not be visually intrusive.
(ii) Economic
The generating station must be close enough to major population centres to ensure a sufficient labour supply;
transmission distance from the generating station to population centres must be as low as possible consistent with other criteria;
it should not be built on high-grade agricultural land;
transportation costs for fuel and other raw materials should be minimized.
A site near to a railway is preferred.
(iii) Engineering
The selected site should be flat and require a minimum of earth-moving and levelling;
the probability of flooding must be less than a specified level;
foundation material must be of sufficient strength to support the structures to be erected;
the probability of strong winds and tornadoes must be below a specified level;
access to the site must not involve special difficulties such as steep gradients on approach roads;
the site must be accessible during the winter months.
This list of requirements is not exhaustive and it is more than likely that the executive committee in charge of the planning process would change its mind at least once during the selection procedure as enquiries proceeded.
To attempt a solution to the problem of finding a set of possible locations for the electricity generating plant using manual methods would be extremely time-consuming and very costly.
It would involve the use of models of rivers and estuaries in order to predict the pathways taken by pollutants, the modelling  of smoke diffusion in the atmosphere, the comparison of many types of map (soils, recreational facilities, areas of scenic or historical value, plant and animal habitat, slopes, meteorological hazards, and river flow probabilities), and the analysis of demographic and economic data.
If it were possible to store all the different types of primary data in computer-readable form then it would become feasible to use the speed of the computer to carry out the required searches, comparisons, overlays and numerical modelling.
It would then be possible to use computer mapping procedures (Chapter 4) to display the results of these computations either in the form of hard-copy output or as a picture on a graphics terminal.
7.7 SUMMARY
The synthesis of geographical facts relating to the locational properties of spatial entities and their associated attributes is a necessary counterbalance to analytical studies carried out in physical and human geography.
A rough distinction can be made between, on the one hand, the systematic branches of geography (economic, social, political and demographic) which are concerned with the detailed study of subsystems at increasing levels of complexity and, on the other hand, the application of geography to real-world problems.
These applications require the assembling of data and concepts from the different systematic branches of geography to produce an integrated picture of the demographic, social, environmental and economic aspects of a particular area.
In the past these synthesizing studies have been difficult to perform due to the lack of a technology which allows the storing, retrieval, analysis, manipulation and display of large volumes of data relating to areal units and their properties.
This technology is now at the stage of commercial development, and the product is a GIS.
A GIS stores both cartographic data (showing topography or individual themes such as soils or geology) and attribute data associated with the spatial entities (points, lines and polygons) that are represented on the maps.
The locational or spatial aspects of geographical problems are handled by a spatial database management system while queries relating to the attribute data generally use a relational database management system.
The two database management systems are closely integrated to allow the solution of questions which have both a locational and a non-spatial content.
In addition, the cartographic data can be manipulated in a variety of ways including projection transformation, scale change, mosaicing of adjacent map sheets, polygon extraction, overlay of maps showing different themes and the delineation of buffer zones.
The cartographic data must exist in digital format before they can be used within a GIS; although the amount of digital map data is growing larger a considerable amount of manual digitizing is needed in practice to provide the database necessary for a successful GIS.
Display of results is achieved in one of two forms: hardcopy  (such as a plotter-drawn map) or as a display on a television monitor screen.
Most often the monitor display is used interactively as the user experiments with and manipulates the output map in order to achieve a close fit to his or her requirements, and only then is output obtained in hardcopy form.
The technology for commercial GIS is now available.
Two factors are holding back the development of GIS applications.
One, as we have noted several times in this chapter, is the availability of spatial data in computer-readable format.
The second is the lack of personnel who are trained in geography (so as to understand the problems of spatial analysis) and who have the necessary skills to understand and appreciate the uses of computers in solving those problems.
The second of these two factors is likely to be the more important constraint in the long run, for even at the end of the 1980s it is rare to find a graduate in geography who is first of all aware of the wide-ranging scope of the subject and secondly is familiar with the operations capable of being performed by a modern computer system.
One particular difficulty that will cause increasing problems for the GIS user is that of data quality.
It is now possible for a GIS to incorporate databases from many sources, while in the near future developments in networks will mean that remote access to databases at institutions other than the users' own will become possible.
Many GIS users assume, perhaps subconsciously, that data quality and reliability must be high because the technology used to manipulate them is sophisticated.
This is not a wise conclusion; very few data sources — of either locational or attribute data — give any guide to the reliability of the product.
Gross errors may be present, but are fortunately rare.
What is more insidious is the lack of guidance on the levels of accuracy to be expected or, where aggregate data are supplied (for example, the sum or average of the values at a number of points over an area) statements about the variability of these values within the area are exceptional.
The question of data quality is one which will attract considerably more attention in the future, once technological developments have been absorbed.
A second difficulty is that data requiring specialist knowledge are becoming available to non-specialists.
Incorrect or misleading conclusions may be drawn by naive users of, for example, medical data.
Tables of mortality and morbidity values for spatial areas are apparently simple to interpret; however, unless such data are adjusted for the age-structure of the populations of those areas, any conclusions drawn will remain questionable.
Further reading on this new and growing subject can be found in Aronoff (1989) and Burrough (1986).
7.8 REVIEW QUESTIONS
1.
Explain the difference between the analysis and synthesis as applied to the study and uses of geography.
Into which category would you place (a) economic geography and (b) a geographical information system?
2.
What is meant by the following terms:
spatial entity
RDBMS
sliver polygon
mosaicing
redistricting
attribute
buffer
map projection
shortest-route problem (network)
database
digitizer
transformation
3.
How far do you agree with the statement that the development of GIS applications will be held up by (i) lack of digital cartographic data and (ii) lack of skilled personnel?
Give reasons to support your argument.
4.
Give three examples of display devices used by a GIS.
Comment on their applicability to particular problems of your choice.
5.
Are there any problems and pitfalls connected with data sources facing the user of a GIS?
Give examples.
How should such problems be tackled?