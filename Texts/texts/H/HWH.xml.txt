

9
INCOME (RE) DISTRIBUTION
9–1 INTRODUCTION
The achievement of economic equity is a stated policy objective in many countries.
Assessing the impact of government policies on the income distribution is important not only because the intention of some policies is deliberately to alter it, but also because efficiency-directed policies will invariably have some impact on the distribution of income and wealth.
This essentially empirical question is very difficult to answer as it raises a whole host of conceptual, theoretical and practical difficulties that are only partially resolvable.
Evaluating the desirability of any change in the income distribution involves ‘the’ great unresolved question in economics, i.e., How are income distributions to be compared and ranked?
9–2 OVERVIEW OF INCOME DISTRIBUTION
Economic inequality is a subject that has thrived in the 1970s and 1980s.
It is convenient to write as if the appropriate unit of analysis is the individual as opposed to, say, families or households.
Households may contain more than one family; for example, there may be a lodger.
Additionally, there are the questions of how resources are shared within these units and how to weigh, say children as opposed to adults.
Abstracting from these difficult matters, an attractive approach to inequality would be to look at the lifetime purchasing power broadly defined over goods and services enjoyed by individuals, appropriately discounted to give a common basis for comparison.
Unfortunately, such longitudinal individual data are only currently being built up.
In their absence, attention has been directed towards establishing changes in the distribution of income and wealth that can be attributed to government policy.
Table 9–1 sketches a picture of income and wealth distribution.
In part(1) of the top panel all forms of factor prices are listed, their precise values being determined by the supply and demand of the factors in question.
This vector of prices, multiplied by individual ownership of factors (here collected under human, physical and financial capital), gives rise to the distribution of income.
The fortunate individuals who turn out to be at the top end of the income distribution usually own physical and financial capital as well as their own labour, or human capital.
The middle panel of the table attempts to distinguish the distribution of income from the    distribution of wealth.
The basic distinction is that income is a flow and therefore is measured per unit of time, whereas wealth is a stock and is measured at a point in time.
In the presence of perfect capital markets and suitably inclusive definitions, wealth would simply be the discounted present value of all future income streams (i.e. including those that might not easily be measured in money terms).
As capital markets are not perfect, definitions vary from researcher to researcher and some things are better measured as a stock rather than a flow, so that documented wealth distributions are not simply the present value of all future income streams.
The arguments listed under ‘Dynamic aspects’ indicate how having a favourable position in the current income or wealth distribution makes it likely that you will also have a favourable position in a future income or wealth distribution (inter- and intra-generationally).
Current possession of human, physical and financial capital tends to reinforce itself in successive periods, although not completely so.
Having sketched the sources of income and wealth inequality, there is the far from simple matter of how to present the data or, more precisely, what unit of analysis to use.
Since money income is the magnitude that underlies the day-to-day standard of living and, depending on the definition, the variable that will (to some extent) reflect wealth, most studies concentrate on this figure.
As the different factors are viewed as performing different tasks in the production process, one way to present data would be in terms of so-called functional shares, that is the share of income going to land, labour and capital.
If the concern is income inequality, this sort of approach is not very helpful as it tells you nothing about the numbers that have to ‘share’ each proportion of income.
Such an approach makes most sense in a world in which individuals enjoy income from only one source, which in turn was more likely to be the case in earlier historical times.
While suggesting that this approach is weak for ‘inequality’ purposes, the basic framework that is employed in general equilibrium tax analysis, and indeed in much of international trade theory, is cast in terms of the earnings of the different factors (see chapter 13).
There is also a sizeable literature on explaining the size distribution of income which concerns itself with the specific shape this takes (positively skewed (right-hand tail) and leptokurtic (hump-shaped) or leptokurtic lognormal), both over different time periods and in different countries.
(See Fig. 9–1 for an illustration.)
The unit of analysis for these approximately lognormal distributions is usually individuals or families.
This type of work, associated in the UK with Lydall (1968), offers three main types of explanation for the characteristic shape.
Stochastic theories look to the statistics of the situation and ask what type of statistical processes will generate the observed result.
If, for example, you take a group of people and give randomly selected individuals within the group increases in income that are a proportion of their existing absolute income size over a succession of periods, a lognormal distribution will result.
Such approaches, however sophisticated, generally contain no economic explanation of the characteristic shape.
The ‘Chicago’ human capital approach (e.g. Becker 1971; also see Mincer 1980) perhaps goes overboard the other way, seeing observed inequality as simply the reflection of current investments in human capital and returns to past investments.
So observed income in period  is a reflection of a base earning from an individual's raw uneducated ability or talent  and past investments  times their rates of return  minus any current investment (which usually is in the form of forgone earnings).
Hence 
Here the characteristic distribution shape comes from the multiplicative  and  interaction, which arises even if and  are normally distributed in themselves.
Like nearly all the human capital literature, the Chicago approach assumes there is a powerful element of choice.
Given basic ability, equality of opportunity to borrow at the market rate of interest to invest in your human capital so as to secure a future return makes observed income inequality a matter of individual choice.
However, on the demand side, the influences (whatever their relative strengths) of genetic inheritance and other environmental variables will make individual demands for human capital differ.
On the supply side, it is noted in Table 9–1 that high initial income and wealth offer better access to information and financial markets, making the rate of interest different for different groups of individuals in society.
Such considerations make the ‘voluntary—don't have to worry about income inequality’ view look somewhat forced.
The approach does, however, emphasize the importance of time periods.
The longer the period, the more the influences of your current position are ironed out, so that students who look (and maybe are!) poor currently over their lifetime will generally look, and be, well off; i.e. cross-section inequality is greater than time-series inequality.
The third approach, which is now more widely adopted, is more eclectic, recognizing both the impacts of human capital (education, training) on individual marginal products (and hence earnings) and other factors, such as individual cognitive ability and personality differences.
Such a ‘multi-factor’ approach1 (Lydall, 1968) brings inequality policy back into play by recognizing that the unequal and the poor have not simply chosen their lot, but it does retain the emphasis on education and training dominant in the human capital approach.
Other divisions of income, apart from its overall size distribution, suggest themselves as relevant for certain issues; so for example economic growth is associated with changes in shares of income generated in different sectors of the economy (manufacturing, agriculture, etc.); labour market analysis might suggest the relative fates of different economic groups (professional versus manual, architects versus roadsweepers, etc.); regional economists, especially in the current context of the EC, by definition have an interest in regional differences in incomes.
All these breakdowns of data are often presented and have a role to play in the analysis of certain questions.
However, when considering income inequality, it is the income distribution among  individuals that has emerged as most useful.
Presentation of the data as a frequency distribution, however, is not very useful for this inequality issue, and other measures have proved more popular.
9–3 POPULAR MEASURES OF INEQUALITY AND POVERTY
There is a very large and sophisticated literature on the various measures that could be used to summarize economic inequality and make comparisons over time within one country and between countries (see Sen 1973 and Jenkins 1991).
The most commonly used measures are quantile shares and Lorenz curves (and associated Gini coefficients).
These basic concepts are illustrated in Table 9–2, and in Figs. 9–1 and 9–2.
The data given are taken from Jenkins (1990).
The quantile shares data are self-explanatory.
A weakness of this kind of presentation is that concentrating on how the shares in one part of the distribution compare ignores changes that might be taking place in other parts of the distribution.
The Lorenz curve (based on information on incomes ranked in ascending order of size) shows the proportion of income held by each percentage or proportion of the population.
Because of the ranking procedure, shares of income run from 0 to 100 per cent as all income must be held by the total of the income-holding units.
The curve sags below the line of complete equality (the 45° line) because incomes are not distributed equally.
The proportion of recipients is greater than the proportion of income they hold except at the ‘anchor points’ on the axes.
The Gini coefficient is measured by the ratio of the area from the ‘sag’ to the 45° line to the area under the 45° line.
Figure 9–2 includes the extreme values the coefficient can take and makes it clear that, the closer to unity is the value, the more unequal the income distribution is.
The Gini coefficients in Table 9–2 suggest increasing inequality between 1975/6 and 1981/2 and constant inequality between 1981/2 and 1984/5.
In addition, the table gives the coefficient of variation for the income distribution, which is a measure of the spread of the distribution relative to the mean of the distribution (i.e. the standard deviation of the distribution divided by its mean).
These coefficients suggest increased inequality over the whole period.
It has already been noted in chapter 1 how efficiency and equity principles are inextricably linked.
The existence of a public sector that did not have significant intended distributional     consequences would be one that involves universal marginal benefit taxation for each good or service provided in the public sector.
Note that an attempt to introduce universal marginal benefit taxation implies the acceptance of the status quo.
That is, there is reason to accept the outcome of market processes and avoid interference with them.
Such views are discussed further below.
While this, with a suitable amount of information, might be the objective of public sector provision, it has, in fact, not been the case.
Most taxation is driven by the ‘ability to pay’ principle (which in itself is meant to be equitable rather than redistributive), and much policy, as suggested above, may be explicitly redistributional.
While it is not easy to establish as an empirical matter what the current income-wealth distribution is, even if it could be established, the question of what degree of inequality should be the trigger for government policy remains.
While, so far, economic inequality has been discussed in terms of measured command over market resources, there is a connection to poverty when this command is viewed as inadequate.
There are two broad approaches to inadequacy that can and have been taken.
The statistical approach follows on from the Lorenz curve type information but recognizes that, for example, studying the income share of the bottom 10 per cent does not indicate how they are doing in relation to the mean or median of the distribution.
One way to connect the segments of the distribution is to argue, for example like Fuchs (1965), that a moving poverty line be created if it is accepted that no one should fall below, say, 50 per cent of the mean or median income.
This has the attraction that poverty is a solvable problem, unlike viewing the bottom 10 per cent as perpetually being in poverty.
In addition, the approach offers an absolute but moving standard that facilitates research into the characteristics of the poor and measures to move them over the poverty boundary.
The second broad approach is a ‘poverty budget’ one.
The question posed is, What is the minimum acceptable budget below which anyone would be accepted as poor?
Rowntree saw the minimum acceptable as that sufficient to maintain physical efficiency.
This apparently concrete and absolute approach involved, once the poverty measure was defined, the distinction between those in primary poverty and those in secondary poverty.2 The primary poor could not attain the standard whatever they did, while the secondary poor could if they reallocated their income to a different consumption pattern, i.e. if they eliminated some wasteful expenditures.
It was realized, however, that physical efficiency depends on the tasks individuals have to perform and in itself is not a Yes No variable but rather a continuous one.
This recognition, combined with the notion that life has to be somehow larger than a physical notion, meant that this approach has been broadened.
A minimal extension is to a labour market approach, which concentrates on the market productive role of human capital and asks what personal budget allows for a growing economy.
A wider sociological approach poses the question, What command over goods and services is required for individuals to take part in the mainstream of society in which they are a part?
The wider the conception of poverty, the greater the number of people who are likely to be viewed as poor and the greater the policy problem in alleviating poverty.
However, it is suggested that the definition adopted should imply a ‘plausible’ number in poverty.
Important though this literature is, the main purpose of later sections is to isolate as far as is generally possible the impact of the government budget on the Lorenz curve that would otherwise have obtained, and then to consider proposals that are more closely tied to the poverty literature.
9-3-1 Normative Principles for Redistribution
First, we shall consider the question raised in the introduction regarding the optimal income distribution.
There are a number of distinct approaches to providing the recipe for an optimal distribution of income which take the discussion away from the nuts and bolts of the actual effects of government policies on different income groups.
The brief discussion here introduces six such approaches.
All can be interpreted as being part of a social optimality approach.
Utilitarianism
Bentham is associated with the maxim of the greatest happiness to the greatest number and would subscribe to the view of maximizing the sum of utility from income.
Assume for the moment that utility is not only cardinally measurable but also comparable between individuals.
Under such circumstances, the golden rule to maximize social welfare is to equalize the marginal utility from income and set the pattern of income distribution to conform to this.
The two Christmas-tree-like drawings in Fig. 9–3 illustrate the point.
In part(a) the two depicted individuals have different but diminishing marginal utility of income schedules.3 With  to distribute, the relevant maximizing allocations are  and .
Any other allocation, e.g. an equal one at  and  would be inferior in that the move to  and  would lose  of utility for  but raise it by  for , offering a raised total to the extent of trapezoid 3456 where  =  by construction.
Figure 9–3(b) illustrates the special ease where A and B have identical utility functions or, alternatively, where it is accepted that A and B ought always to be treated as if they had identical utility functions.
In this case the recipe for maximization of social-welfare-like utility is egalitarian; i.e. incomes  =  =  = 
Uncertainty
Lerner (1944) derives the egalitarian recipe in a neat and less restrictive manner.
He sheds the unrealistic assumptions of cardinality of utility and comparability between the individuals and argues that in an uncertain context the expected sum of utilities will be maximized by an equal distribution.
Returning to Fig. 9–3(a) and moving to an equal distribution  and  from  and  the loss of utility has been established as trapezoid 3456.
If however, you had been mistaken about the location of  and  and the assignments had been reversed, the effective starting-points would be  and  and the movement towards equality would involve a loss to  and a gain to  of , yielding a net gain of 83-10-9 as  by construction.
If you are truly uncertain about the marginal utility schedules and attach a 0.5 probability to the gain and the loss, expected utility is maximized by the equal allocation, because half of 839–10 clearly exceeds half of 3456.
Culyer (1980), among others, is critical of this argument because, despite the claim made above, he notes that the argument continues to assume that utilities of the individuals can be summed, which presupposes they can be measured in the same units.
In addition, if the probability differs from 0.5, there comes a point where the higher probability of the smaller loss outweighs the lower probability of the larger gain and unequal distributions are prescribed.
Social welfare function
In the so-called ‘New’ welfare economics, the use of the social welfare function introduced in section 1–5 seemed to ‘solve’the equity problem and economic analysis was centred on efficiency.
The source of a social welfare function remains a lasting difficulty.
To assume it is known is accepted for illustration, but this does not push analysis very far.
The Arrow Impossibility Theorem suggests that it may be futile to attempt to build it up from reasonable democratic assumptions (see chapter 4).
In contrast, some sort of appeal to, say, the authority of the government executive (although in practice often the implicit outcome) looks at odds with the individualistic framework of neoclassical economics.
Against this background, following the implications of different formulations has often proved attractive.
The ‘shapes’ introduced in chapter 1 are consistent with the principles of:
(a)
maximizing total utility (utilitarianism)
(b)
the Rawlsian maximin principle discussed below
(c)
]maximizing the utility of a particular individual
(d)
]
The idea of maximizing the product of individual utilities has been employed by Fair (1971) and has been criticized by Ng (1979).
The ‘Rawlsian’ social welfare function
John Rawls' A Theory of Justice (1971) has been a very influential book.
It justifies the use of a fairly radical social welfare function and in a sense combines and rationalizes elements of all three of the above approaches.
Rawls suggests that the appropriate way to think about the development of a theory of justice is from the so-called original position behind ‘a veil of ignorance’.
The idea is to imagine you have been called to a ‘convention’ to set the rules of the constitution and the social and economic structure of society.
In order to make the procedure ‘fair’, you are imagined to: know little except the most general facts about human society; be ignorant of your own eventual position and role in society; be unaware of your own endowments; be ignorant of where your own best interests will in fact lie, and be ignorant also of the state of development of the society in which you will find yourself.
In effect, you are devising the rules for a game of cards (life) in which your particular hand and the game you will eventually play, for some unknown rewards and probabilities, remains unknown.
The point is that you do not in this ‘original position’ know how to be biased and hence have to be fair: justice in this context would have to be ‘blind’.
Because in Rawls's view we are equal moral beings capable of a sense of justice in this fair starting-point, the rules advocated and accepted would be ‘justice as fairness’.
What of the rules that would be derived?
Two are proposed:
1.
All individuals have the right to the most extensive basic liberty compatible with a similar liberty for others.
2.
Deviations from social and economic equality are justified, provided they do not conflict with rule 1 (‘equal liberty’) and provided
(a)
they are to the advantage of the least well off; i.e. changes that improve the position of the least well off are to be recommended (this is the so-called maximin rule, maximizing the position of the minimum welfare individual), and
(b)
they are attached to positions open to all equal opportunity conditions.
Much more could be and has been written about this ‘difference principle’(2a) and its strengths and weaknesses, but enough has been said to, at least, give the flavour of the notion.
The ideas of justifying equality, of uncertainty as a major feature and of consensual individual decision-making are links to the elements in this section.
A further link can be forged to the discussion of inequality measurement above via the Atkinson (1970) inequality index (AI), which can be related to the isoelastic function discussed in chapter 1 (see also Stratmann 1990).
If individual utility of income functions are given the isoelastic form  then the associated marginal utility of income is  
If a utilitarian social welfare rule of summing individual's utility is adopted, then social welfare  can be written 
That is, the aggregate level of welfare in society is given by a welfare function whose arguments are the cardinal utility of income functions.
Given the above,
Now introduce the concept of equally distributed equivalent level of income  as the per capita amount of the smallest total income which if equally distributed offers the same level of welfare as the original distribution, so that 
Then the Atkinson index is , which becomes in the isoelastic case   
Distributional attitudes to inequality are contained in the parameter .
In Fig. 9–4 the two-person (A and B) case is illustrated.
When  there is indifference about the distribution of income (parallel straight lines with a 45° angle to the x and y axes); means that concern is only with the income of the poorest income unit (the Rawlsian case).
For any initial income distribution, say at point 1, the line 45° to the x and y axis shows all income allocations attainable from point 1, the initial distribution.
The 45° ray from the origin represents.
equal (average) income for A and B. (For 1 the relevant equal income point is 2.)
With an  value of unity, point 1 is on  and 2 is on : this represents the difference (gain) in social welfare available by distribution to equality at 2 from 1.
Given the definition above, point 3 is the equally distributed equivalent of point .
This makes 
The meaning of the index can be seen if a specific value for the index (which runs from 0 to 1) is considered.
With , if only 60 per cent of total current income were equally distributed it would be socially valued as equivalent.
Rearranging (9–6) yields  and confirms this.
As point 3 in Fig. 9–4 approaches point 2 the index tends to 0, signalling equality of incomes.
If 3 approaches the origin the index tends to 1, signalling complete inequality.
(For  the index would be zero/02 and for , the Rawlsian case, 42/02.)
The effect of this index is to reduce all the argument about the appropriate shape of the social welfare function to a question of the size of .
While this does not make  knowable, it facilitates discussion of the efficiency-equity trade-off below.
Interdependent utility functions
The above implicitly has individuals gaining utility from their own incomes.
There is however a considerable literature recognizing that your utility will be affected positively or negatively by the utility achieved by others around you.
Other individuals' utility in effect becomes an externality to you, and if Pareto-relevant this would suggest that you would willingly agree to some redistribution.
In Fig. 9–5 B will find himself with income  and if we assume that A for whatever reason is altruistic towards B, then there exists a demand by A for, income for , which is normally marginally irrelevant.
If however B falls on hard times, and is prevented from earning  say, ill health caused unemployment- and his income falls to  then the externality becomes marginally relevant.
As illustrated, the externality is Pareto-relevant over the range  and suggests a welfare-increasing transfer for A and B of that sum.
Concern for others is one way you can gain from giving.
Like mercy, it is twice blessed, offering a welfare gain to A of 123 and a gain to B of .
The effect of this type of ‘everybody gains’ argument is, as noted in note 4 in chapter 1, to provide positive sections to the utility possibility frontier as illustrated by  in Fig. 9–6.
This only ‘narrows’ the efficient area of the frontier to the negatively sloped section between points 1 and 2.
Mishan (1972) notes that a unique result obtains in the unlikely situation of a case like  where 3 represents an optimal distribution of income.
Note that the construction assumes that B is altruistic towards A as well as vice versa.
The fact that this explanation can be formulated in an externality/utility possibility frontier context makes clear that the effect of interdependent utility functions is to make equity an ‘efficiency’ matter.
Equity as non-envy
The ‘utility functions’ described by equation (9–2) allow the social valuation of the welfare of individuals to be calculated independently of the utility (income) levels of others.
This ‘separability’ is a weakness if an interdependent view of income distribution is deemed crucial (see Sen 1973).
Putting yourself in the position of others is the core idea of fairness or equity, being seen as the absence of envy.
The familiar Edgeworth-Bowley trading box can be used to illustrate the argument.
In Fig. 9–7(a) point 1 is the centre of the box and, unless individuals have identical preference maps, cannot be on the contract curve.
Suppose the contract curve is the continuous curved line between  and  and point 2 an efficient allocation of X and Y between A and B along it.
Now the question is, Does A (B) regard her (his) consumption bundle as attractive as that of B (A)?
To find the response, the mirror allocation can be located at point 3 by striking a line from 2 through 1 and extending it for a distance equal to 21; i.e. 31 = 12.
As illustrated, B-but not A can attain a higher indifference curve at 3 than at 2, and therefore B is seen as being envious of A, and therefore point 2 is efficient but unfair in B's terms.
One allocation that would   be both efficient and equitable in this sense would be an initial endowment at 1 where both A and B have the same X and Y. Since they face the same budget constraint, each can have what the other has so that any trades away from equal allocation to the contract curve must meet the reverse allocation test illustrated as part (b) of the figure.
A movement to point 2 raises both A's and B's utility, whereas the reverse assignment at 3 lowers both's utility-they are not envious of each other.
The presence of malice or envy is one spur to redistribution and is a theme taken up by those offering the more positive accounts of redistribution (see below).
Before considering these, however, it is worth briefly considering Rein and Miller's (1974) question as to what people mean if they are in favour of income redistribution.
Possible interpretations offered include the following.
1.
The avoidance of ‘income and wealth crystallization’ would tend to attack the feedback advantages that high-income high-wealth households enjoy (noted in Fig. 9–1) with respect to education, health care and the like so that multiple deprivations are avoided.
In this context the authors note that ‘equalizing’ income differentials (higher income to compensate for the lower attractiveness of some jobs) are normally swamped by ‘accentuating’differentials (such as status and recognition following high income).
2.
A ‘social minimum’ of income and in-kind provision for all should be achieved.
3.
‘One-hundred percentism’ refers to horizontal equity , whereby quality and level of work effort alone should determine income, and discrimination on the basis of sex, race, social background should be avoided so that all have access to the better posts.
4.
‘Lowering the ceiling’ involves reducing the concentration of income at the top by the use and enforcement of tax laws.
5.
‘Income shares’ refers to influencing the share of National Income so that various quantiles in the distribution, e.g. the bottom 20 per cent, must have at least (say) 10 per cent of the income.
6.
' Stratum mobility' is concerned with the narrowing of income differentials among occupational groups.
In particular, some feel that occupational groups should enjoy similar proportional increases in income which preserve existing differentials, while others, pushing for greater equality, want similar absolute increases which have the effect of narrowing differentials.
7.
‘Equalization of lifetime income profiles’ concerns inequalities in lifetime income growth and involves developing career income profiles that rise with age.
Everyone should have a ‘proper’ job.
8.
‘Economic inclusion’ involves the notion that income inequalities that exclude individuals from the mainstream of society are to be avoided.
This corresponds to the type of poverty line advocated by Fuchs (1965).
9.
‘International yardsticks’ means that each country must attain as equal a distribution as that achieved by all other countries at the same development stage.
While not exhaustive, these examples indicate how many interpretations can be given to the goal of income redistribution (and may help readers ‘spot’ their own attitudes!)
9-3-2 Positive Accounts of Redistribution
Positive accounts of redistribution focus on explaining what, if any, actual redistribution takes place.
Whereas the above section was described as being part of the social optimality tradition, this section has elements firmly rooted in the public choice tradition.
(The first subsection is the main exception.)
Interdependent utility functions
The analysis of the previous section offered one mechanism whereby individuals would voluntarily redistribute income either in kind or in cash (see Hochman and Rodgers 1969), the cases being those of the specifically and the generally interdependent utility function respectively.
The former interdependence is tied to specific goods, e.g. health care and education, whereas the latter relates to general purchasing power.
The argument presented is in terms of the ‘haves’ being concerned for the ‘have-nots’.
With many ‘haves’ with similar motivations, a free rider problem emerges to dampen unilateral action.
However, in the presence of coercive taxation to solve that problem, the argument suggests that individual net gains from the public sector-the fiscal residual-should vary inversely with original income positions.
There is no requirement, however, for altruism to be the argument causing the interdependence.
Redistribution can stem from malice and envy.
Brennan (1973a) employs a diagram such as Fig. 9–8 to demonstrate this point.
For individual A, her own income  is a good but the other person's income  is a bad, reflecting the presence of malice towards B. (Envy is increasing marginal disutility of the other person's income.)
The shape of B's indifference map reflects the same malicious feelings.
With initial allocations of income at point 1 on  for B and  for A, there are clearly gains from trade to be had from the lowering of both incomes as long as adjustment is contained within the usual rugby ball shape.
The locus of points between 2 and 3 define the relevant portion of the contract or, more aptly in this case (Boulding's terminology), the conflict curve.
An outcome such as 4 raises A's utility to  and B's to  Intuitively, what is happening is that A's loss of utility from the reduction of her own income is being more than compensated for by the knowledge that B's income is also falling.
But how is the income reduction to be achieved?
With many A's and B's, the free rider problem arises.
Individuals will attempt to allow others to reduce their incomes, gaining in utility from that knowledge, while not lowering their own incomes.
Additionally, the process could get out of hand.
Not all income reductions raise utility.
If the cuts become too deep, both A and B can be made worse off, say at 5.
These two points suggest the power of government to solve the free rider problem and to   referee the process to keep losses in bounds.
Brennan now introduces a third actor (or set of actors) C, whose income level  is a neutral good as long as or  i.e. they are unconcerned about those with less than half their income.
Government redistribution of income from A and B towards C, within limits, raises the utility in this society of some well-off but malicious and envious individuals!
Majority voting
The use of majority voting as the explanation of redistribution has been suggested by Downs (1957) and Meltzer and Richard (1981).
The straightforward Downs approach relies on the shape that income distributions typically take.
With some very large incomes in the extended tail of the distribution and many small increases in the ‘meaty’ body of the distribution, the median voter's income is less than that of the mean voter (see Fig. 9–1).
A vote-maximizing political party therefore has an incentive to propose redistribution from the richer segment to the poorer majority.
The crude implication, not borne out, is that the poorer 50% + 1 gain from the activities of government: This however tends not to be the case in empirical studies.
Tullock (1971), like Disraeli, notes that the top and bottom of the income distribution may have interests in common and that it is the middle (or median) individual, or more loosely groups, who wield the power.
After all, the median voter rule suggests that it is the way in which the middle two voters in the income distribution vote that determines the outcome of a rich or poor majority.
While siding with the poor is more rewarding because the poor represent less attractive pickings than the rich, they may be able to ‘bargain' on the terms on which their support is obtained.
Indeed, if the prudent poor are a minority in the majority coalition, then it is possible to see a reason why the middle and lower-middle income ranges appear to come out well in redistributive studies.
Le Grand (1982) is one author who documents this view of the effects of UK public expenditure.
Income insurance
Buchanan and Tullock (1965) develop an argument about redistribution based on the idea of income uncertainty and possibilities for insurance.
A reinterpretation of Fig. 9–3(a) illustrates the heart of the argument.
Given diminishing marginal utility of income, more income in one period cannot compensate for lower income in another period.
Suppose  is individual A's average income but  obtains in a good period and  in a bad period.
Individual total utility can be raised if  can be removed in good times, leaving  and added to  to achieve  also in bad times.
The utility lost in good times  is clearly less than that gained in bad times  i.e. individuals can gain from ensuring an average income in all periods provided the transaction costs of the policy do not fully swamp the potential gain.
Private insurance policies against earning a low income per se are hard to find, because once you paid the premium the moral hazard problem central to Baumol's case for a public enterprise (see chapter 5) would then loom very large indeed.
Individually engineered low incomes would be the order of the day for all those insured, and the insurance company would not be able to cover the loss.
While some types of income insurance schemes do exist e.g. pensions-the government, for example stepping in to provide unemployment benefit financed from taxation of the employed, may be a superior provision mechanism.
While such intervention is not without a moral hazard problem, it may still remain the best solution for those seeking income insurance; in other words the government can handle the moral hazard problem better than the market can.
Buying protection
Brennan (1973b) picks up on the idea that revolution mechanism is a strong possibility in a society with large income disparities.
If society is divided between a small, wealthy  and politically powerful minority and a majority of poor, politically weak members, the minority have the problem of creating policies to foster stability.
The decision to revolt is discussed in chapter 15 and turns on the evaluation of costs (punishment for failure, injury risk, loss of property, etc.) versus the gains of raised income or wealth.
The rich and any poor (risk-averse) non-participants cannot expect to gain from any revolution and will be happy to see potential revolutionaries bought off.
Here Brennan suggests that revolutionaries will be low-income and risk-loving.
Now clearly, one option is to raise the income level of this group in a flat-rate way.
However, given their risk-loving nature, greater protection is purchased by a low probability of a large prize rather than a high probability of a modest prize; i.e. a society characterized by a few ‘glittering prizes’ awarded on the basis of equality of opportunity recommends itself.
A policy example consistent with this perspective is a public sector education system based on equality of opportunity with the winners being the academically able irrespective of their income or other background characteristics.
Such policies offer the rich some protection as they weaken the resolve of potential revolutionaries.
If there are seeds of truth in the theories outlined in this sub-section, actual redistribution taking place in the public sector will reflect altruistic, malicious, vote-maximizing, insurance- and protection-seeking behaviour.
If all or a variety of these motives are present, some redistribution of income or in-kind government provision is expected within limits, although its pattern is likely to be complex.
The limits to redistribution captured in these motives are reserved for section 9–6.
It is the measurement and pattern of redistribution achieved by the government budget that are the concerns of the next two sections.
9–4 REDISTRIBUTIVE IMPACT OF THE BUDGET
The redistributive impact of the government budget involves numerous problems, which are illustrated below in the form of a convenient list provided by O'Higgins (1980) and Ruggles (1991).
The ‘counterfactual’ problem
Studies of the impact of the government budget necessarily presuppose what would have been the case in the absence of such a budget.
This is the so-called counterfactual problem (common in historical studies) of being able to observe the world of X happening and assessing the impact of X only by trying to suppose what would have happened if X had not happened.
In the present context, this amounts to having a market economy outcome and imagining what would happen if there were a mixed economy or, alternatively, imagining taking government activity out of a mixed economy to produce a market- or government-free economy.
In the UK the most familiar redistributive budget study is that carried out by the Central Statistical Office and published as Economic Trends .
The CSO perspective is one that involves producing a market scenario to compare with the observed mixed economy that exists.
For some, this fundamental weakness of the created counterfactual makes the whole exercise untenable; for others (see Peacock 1974) it is a question of plausibility; i.e. what you think would have been the case must be plausible.
For example, in the absence of state pensions you have to assume that there is some form of post-employment support (presumably private pension schemes), and not that people will have zero income when they retire.
Whatever view is adopted, the fact remains that such studies are undertaken and, if for no other reason, some understanding of their possibilities and limitations is desirable.
Extent of coverage
There is the question of what degree of incompleteness is optimal.
Having, say, opted for different income groups as the unit of analysis, a calculation along the following  lines can be performed for each group :
Over all groups, the original and post-budget incomes will be the same if there is an economic budget of fixed value to be divided.
This corresponds more to economic arithmetic than to economic analysis, and more sophisticated approaches look to evaluation by reference to the tools developed in chapter 6 on cost-benefit analysis.
This tension between economic arithmetic and the prescriptions of economic theory shows up in the discussion that follows.
Before moving on, the problem of the counterfactual can be highlighted further.
Post-budget income minus real (exhaustive) benefits and transfers plus taxation gives original income.
This makes sense at what might be termed an economic arithmetic level, but is flawed at the behavioural level.
Virtually all of economics concerns individuals responding in a utility-maximizing way to different economic signals.
Changing any of the benefits and any of the taxes will almost certainly generate some behavioural response which will have to be guesstimated if the true original income is to be deduced.
Original income calculated by arithmetic is not the original income that would be observed without government intervention.
Even if it were possible to model accurately the supply and demand responses to changes in taxes and transfer or benefit provisions of all kinds, it would remain a GNP or market calculation.
Affording no weight to extra market considerations, whether good or bad, means that individual or income group economic welfare is being identified with command over market goods or services alone.
(Such a criticism can be levelled at most of the discussion of this chapter: see Scitovsky 1986.)
Returning to the question of coverage, this is always less than complete, with more taxes than benefits being allocated to the identified income groups.
The asymmetry arises because of the different nature of the benefits provided and taxes levied.
Dealing with the benefit side first, it is clear from chapters 3, 4 and 5 that goods and services vary in their ‘economic’ characteristics and this leads to their different treatment.
In the CSO exercise the majority of public expenditure is ignored because goods or services offering non-rival (or indivisible) benefits are viewed as not conferring benefits on individual households as such.
In addition, goods or services that provide benefits to both households and the business sector (but in unknown proportions) are ignored.
Even where the benefits can be viewed as almost exclusively attributable to households (e.g. parks), lack of data on patronage leads to them being disregarded.
Capital as opposed to current expenditures also raises difficulties because, although the opportunity cost of investment goods is felt now, the benefits will typically arise in the future.
One view is that they should be allocated in discounted present value form to individuals who gain from them.
However, if these individuals are in a future generation, the problem arises of who gains.
Peacock (1974) suggests that the appropriate view is that the current generation is choosing to sacrifice current consumption to internalize its concern for future generations and therefore can be legitimately viewed as gaining from capital expenditure the fruits of which they may not actually sample.
As with many aspects of any redistributive exercise, sensitivity calculations are an acceptable if not always convincing way forward.
The ‘balanced budget’ issue
It was noted above that there is often a disparity between benefits and taxes covered; that is, an unbalanced budget is allocated which creates a distortion in  measured net benefits.
The word ‘balanced’ suggests that it would be attractive to equalize allocations on the sides of the budget at either 100 per cent or some other percentage.
Ideally, all benefit taxes should be included, but if this is not possible then Peacock and Shannon (1968) advocated equal allocations of both.
For example, a social welfare budget might be created in that the taxes conceived of as paying for programmes could be allocated in line with the volume of social welfare benefits provided.
The drawback with equal partial allocation is that it presents a rather arbitrary account of events.
Suppose direct taxes and cash transfers are allocated and then cash transfers are increased.
Depending on how these increases are financed, different income groups will be affected.
A very different picture can be drawn depending on the part of the budget in question.
If the ‘slice’ considered is unaffected by, say, decreased road expenditures or health expenditures and/or the increased indirect taxes required to increase the transfers paid out, then the cash transfers misleadingly appear as a ‘free lunch’.
In general, less than complete allocations of taxes and benefits, whether matched in size or not, pose problems.
(For a distributive study that allocated all taxes and public expenditures in the UK, see O'Higgins and Ruggles 1981.)
The incidence and valuation of expenditures
Chapter 6 on cost-benefit analysis raises the question of the appropriate valuation of costs and benefits, whereas chapter 3 raises the question of different types of goods.
Both are relevant under this heading, which concerns itself with the benefit side of the government budget.
The exclusion of non-rival expenditures and/or expenditures whose beneficiaries are uncertain by the CSO has already been noted.
However, there are other possibilities.
For such expenditures, their tax cost can be used as their valuation and can be allocated on a variety of possible bases-per capita, in proportion to household income, rateable value, etc., and where possible actual use of the service by different households.
Of course, this is a long way away from the appropriate measures of consumer surplus, and for economic theorists at least looks all too arbitrary.
A good example involves a contribution by Aaron and McGuire (1970).
For non-rival goods especially it is tempting to allocate their costs (= benefits) on a per capita basis, but Aaron and McGuire show that this is equivalent to assuming that all individuals have the same marginal utility of income.
This can be demonstrated as follows.
The individual demand for good G is given by  or 
In a two-person economy (A and B), efficient provision involves summation of their marginal benefits, so that 
Assuming that each individual has the same utility of income function and ability to gain from the public good, then with different incomes they will have different  but the same marginal utility from the (equally shared) public good.
If  is the efficient quantity of public good provided, then this indicates  where  is simply the budget expenditure on G. Here the marginal utilities of the public good are the same but the marginal utilities of income are different.
In short, for it to be appropriate to allocate  equally between A and B, should equal .
When this is not the case, benefit allocations are in inverse proportion to A's and B's .
That is, a lower  justifies, on the specified assumptions, a higher share of the expenditure allocated to the provision of G.
The incidence and valuation of taxes
Chapter 7 rehearses the arguments about the direct and indirect (welfare cost) burden of a tax and raises questions of incidence.
Both of these issues have a prominent part to play in assessing the impact of taxes on different groups.
Except for the cases of perfectly inelastic demand or supply curves, the imposition of taxation will involve an excess burden which will typically (like the incidence itself) be felt in some proportion by consumers and producers alike.
Any accurate allocation involves the knowledge of the supply and demand elasticities that drive the welfare cost calculation formulas (see chapter 7).
Prest (1968) notes that studies can at least be consistent, so that situations where all income tax is allocated to labour (plausible if Fig. 9–9(a) applies) and all indirect taxation borne by consumers (plausible if Fig. 9–9(b) applies) should be avoided because they involve contradictory pictures of the supply side of the economy.
Again, the general way forward is sensitivity analysis.
All the above suggest that income redistribution studies have to be treated with caution and any critical assumptions revealed by sensitivity analysis should be made clear.
Table 9–2 gives the inequality information calculated by Jenkins (1990) from CSO ‘Blue Book’ estimates of the distribution of income.
The fact that the overlap of tax payments and transfers in cash and/or kind leaves as much as half the households in a broadly unchanged position has drawn criticism (see Burton 1985).
Considerable tax compliance and administrative costs are an aspect of the costs of this ineffective ‘fiscal churning’.
Furthermore, it is argued by some commentators that, if an attempt were made to trace the redistributive consequences of other types of government policy, e.g. subsidies that are part of industrial policy, then an already very fuzzy picture would become totally confused.
In short, the criticism is that we do not really know the redistributive impact of government.
The third criticism Burton makes refers to the ‘traps’ created by the interaction of the tax payment transfer receipt system.
This consequence is central to the next section.
9–5 FISCAL MEASURES AND THE ‘LESS WELL OFF'
For a government having to establish a guide to the existing extent of economic inequality and some principles as to when inequality shades to poverty and becomes a policy problem, there is the question of what policy instrument to use.
Referring back to Table 9–1, the bottom panel provides some examples of policies collected under three headings: those affecting factor market outcomes directly, those altering the ownership of capital, and those attacking the income distribution directly.
The issues discussed in this chapter relate mainly to the second and third   options and in particular to proposals to replace a large ‘proportion of them with some type of negative income tax system broadly defined.
(For a wider appreciation of the issues related to the UK social security system, see Dilnot and Walker 1989.)
Overlaps in the tax payment transfer receipt system have been a focal point for much discussion in the 1980s with various sorts of ‘traps’ identified.
The major ones are illustrated in Fig. 9–10, which is amended from Atkinson, Flemming and Kay (1983).
represents the ‘strong’ unemployment trap where individuals are financially better off out of rather than in work.
This is usually expressed in terms of their having replacement ratios of over 100 per cent.
The replacement ratio measures income in and out of work so that it measures net-of-tax earnings minus work-related expenses as compared with out-of-work transfer payments contingent upon the status of being unemployed.
Despite much popular misconception, there are relatively few individuals or families that find themselves in this position.
, the ‘weak’ unemployment trap, may be typical of many low-paid workers who face high but less than 100 per cent replacement ratios.
It must be noted that no value is being given to the disutility of work in itself.
Such a valuation would be controversial; some would want   the value of ‘leisure’ included while others would regard being deprived of work, in a society where people are expected to work, as a cost to the individual.
It is this latter consideration that helps explain why many people with high replacement ratios plus the possibility for ‘leisure’ remain in work rather than opting for unemployment.
represents the ‘weak’ poverty trap, where over a wide range of earned income the effect of explicit taxation plus implicit taxation via the loss of means-tested benefits means that disposable income remains largely unaffected.
is the strong poverty trap, where over a range of earned income disposable income actually falls as earned income rises.
This is because the explicit tax rate and the means-tested benefit withdrawal rate exceeds unity.
One suggestion for avoiding this is to have the explicit tax rate apply only to net-of-transfer income earnings, so that if the benefit withdrawal rate  is 60 per cent and the explicit tax rate 30 per cent the ‘total’ tax paid on an additional £1 of earned income would be at a rate , which is a sum comprising 60p less means-tested benefit, and 30 per cent of 40p = 12p explicit tax, i.e. 72p.
Only if the benefit withdrawal rate exceeded 100 per cent would the individual actually be worse off under such a proposal.
But as Collard (1985) points out, this would create a threshold trap around point .
If the government were to raise the tax threshold, by say £100 (a common policy to try and help the ‘low-paid’), this would be worth £30 to a person to the right of point  facing the explicit tax rate above.
However, to someone facing the weak poverty trap, and again with the illustrative numbers above, this is worth only 30 per cent of £40, i.e. £12, because the explicit tax rate applies only to the net-of-transfer income; i.e. .
The simple message is that traps are easy to create even when the object is to ameliorate  the effects of one that already exists.
As might be expected, high replacement ratios figure in the discussion of unemployment (chapter 10).
The existence of such traps provides a convenient introduction to the case underlying negative income tax and similar proposals.
9-5-1 Negative Income Tax Type Schemes
To avoid the type of problems introduced above, among others, many commentators who accept at least some redistribution as a relevant policy objective advocate some form of automatic tax-transfer system as the only adjunct to an otherwise ‘minimum state’ guaranteeing law and order and little else.
There is a wide variety of possible schemes, ordered below by their varying degrees of generosity to the less well off.
Variations on a tax-transfer theme are presented below, where 
Figure 9–11 illustrates the relationship between earned and disposable income described by these schemes up to the break-even point, where .
The vital issue about these schemes concerns the balance between helping the less well off and the marginal tax rate facing the better off.
They are all tax-transfer schemes: the taxes must cover the transfers.
The illustrative figures contained within Meade (1978) suggest that negative income tax proposals are less ‘demanding’ where guaranteed income is not all that generous.
Only if this is the case does the tax rate in the system not climb sharply.
However, stronger incentives at all levels of the income structure is a theme in many public policy statements of the 1980s.
So for example, if the poverty line  is 40 per cent of average income and 15 per cent of income is required to cover the provision of public sector goods and services, the implied tax rate on earned income for a social dividend at the poverty line is 55 per cent so that individuals would receive 45p of an additional £1 earned!
While it is possible to soften this blow by having different tax rates below and above the poverty line, or by having a social dividend that is smaller for those in than those out of work (the two-tier case), once the simplicity and universality of the system is lost, so are most of its advantages.
(Dilnot, Kay and Morris (1984) offer a different perspective.)
More recently, Atkinson (1989) has calculated the rate of tax to finance two proposed social dividend/tax credit schemes, and he suggests a range of 47.5–51.3 per cent but warns that it is a difficult figure to calculate.
Despite this caveat, the arithmetic of social-dividend-type schemes does not look attractive.
Concerning the choice between contingent benefits (those based on a particular status, e.g. being unemployed, a single parent, disabled) that are associated with typical welfare state provision and the apparently simple income-related means-tested benefits, there is a general point to be made.
Contingent benefits have the advantage of picking out groups in society that are in greater  need of income and/or in-kind support than other groups.
Supporters of this perspective are usually labelled as being ‘back to Beveridge’.
Supporters of a more means-tested approach are also much more likely to favour some type of negative income tax scheme and argue that within each contingent class there are some who need help and some who do not, so that the rich in ‘needy-contingent’ categories gain at the expense of the poor in less needy-contingent categories, e.g. the low-paid workers.
However, to choose either route is to lose information on either means or status that is helpful to targeting support where it is most required.
This is a complex area that is quick to raise controversy and reveal underlying divisions of perspective on the willingness to redistribute income.
(Recall the different views outlined in section 9-3-1.)
For example, H. Parker concludes the introduction of her book on the integration of the tax and benefit system in the UK as follows:
the real issue concerns human relationships and human values.
Do we want to live in a society in which making money is all that matters, or are there other objectives that we hold more dear.
(Parker 1989, p. 7)
For her, at least, this is a much bigger issue than the technicalities introduced above.
9-5-2 Cash Transfers versus Price Subsidies and In-kind Transfers
One of the standard questions of public finance theory is why redistribution is made to recipients via price subsidies and in-kind transfers rather than through cash transfers.
It will become clear that this debate is a mirror-image of the excess burden argument already discussed with respect to taxation.
Here there is an excess burden associated with price subsidies or in-kind transfers which would be absent in the case of a cash transfer.
In Fig. 9–12(a) a cash transfer is compared with a price subsidy the objective of which is to make the recipient as well off as possible.
The initial price ratio between good X and Y (a composite of all other goods) is shown by the budget line 12.
The consumer maximizes welfare at point 6.
The government wishes to assist the consumer of product X by reducing its price.
A price subsidy causes the budget line to change to 13.
The new equilibrium is at point 7 and the consumer is at a higher level of welfare (as can be seen by the tangency point to the higher indifference curve ).
However, if the government had transferred the cash (sufficient to subsidize good X at point 7), the consumer would face the budget line 45.
The new welfare maximum would be at point 8.
The government, at no additional cost to the Exchequer, would have had a greater impact on the individual's welfare.
With a cash transfer the recipient of government assistance would attain a welfare level as shown by .
In this way the price subsidy scheme is a less efficient instrument for redistribution.
It creates an ‘excess burden’(as shown by the difference between  and ), and this can be estimated (see Laidler 1969).
The cash transfer does not distort prices and appears a more efficient redistributive instrument.
In Fig. 9–12(b) the consumer is again initially at point 6 on budget line 12.
An in-kind transfer of good X enables her to consume a quantity 17 of good X at no cost.
The shape of the budget line changes to 175; after point 7 the individual can consume more of good X, but to do so she must give up some quantity of good Y. In the example shown the new welfare maximum for the individual is on the corner point, 7.
The individual would not choose to consume any more of the good than that quantity that is received ‘free of charge’ from the government.
Once again, if the individual is offered the cash equivalent the new budget line is 45.
With the cash equivalent of the in-kind subsidy, the consumer can select any combination of Y and X. This makes possible a new equilibrium at point 8.
Again, the cash transfer leaves    the individual less constrained, and the welfare maximum with the cash transfer (point 8) greater than that achieved with the in-kind transfer (point 7).
While these forms of subsidy are not exhaustive, a consistent message appears to be that a cash transfer is the most efficient way of increasing the welfare of the recipient (i.e., for any given transfer, welfare of the recipient may increase to a greater extent).
Of course, price subsidies are used for many other purposes; for example , in chapter 3 it was noted that they might be used to tackle the problem of an externality.
However, in so far as their purpose is purely redistributive, it seems difficult to provide a rationale for price subsidies or in-kind transfers rather than cash transfers, and yet these latter forms of assistance are extremely important components of public expenditure (see, e.g. Brennan and Pincus 1983).
One attempt to explain the choice of price subsidies and in-kind transfers is to assume a ‘goods-specific’ externality.
In this case concern rests not only with the recipient but also with the donor (who pays the taxes to finance the subsidy).
By a ‘goods-specific’ externality, the important argument in the donor's utility function is not simply the utility of the recipient but also the quantity of a good (e.g. health care or education) consumed by the recipient.
The purpose of the subsidy is to increase the recipient's consumption of good X. While the cash transfer appears efficient at increasing the recipient's welfare, it is not the best instrument to stimulate consumption of a particular good.
In Fig. 9–12(a) the line ICC is the income consumption curve.
It maps a locus of equilibrium welfare maximum points for the consumer as income increases.
For the recipient to increase as much of X as shown at point 7, it would be necessary for income to be increased to point 9 on the income consumption curve.
That is, the budget line 45 would need to be pushed to the right until it passed through point 9.
Obviously this would impose a significant strain on the Exchequer.
The cost transfer necessary would be far greater than the cost of the price subsidy.
The price subsidy creates a ‘substitution’ effect as well as an ‘income effect’, and this substitution effect also encourages consumption of good X. If the objective is to promote the consumption of good X, it is clear that the price subsidy is the more ‘efficient’fiscal instrument.
This general conclusion is repeated in Fig. 9–12(b).
Here the in-kind transfer encourages consumption of good X at a cheaper cost to the Exchequer than would a cash transfer; for a cash transfer to stimulate consumption of X by as much, it would be necessary to give the individual sufficient cash that the budget line would be pushed out to point 9 on the income consumption curve.
How convincing is the goods-specific externality argument as a rationale for government redistributive policy?
Rosenthal (1983) draws together a number of criticisms of the argument which can be listed as follows.
1.
For price subsidy schemes to perfectly internalize the goods-specific externality, a great deal of information would be required, of a nature that would be difficult to measure (Browning 1975).
2.
Following Lancaster's theory of demand (1966), goods may possess attributes which donors regard as important for donees; e.g., food contains the characteristic nutrition.
However, a subsidy on all food may be counterproductive if different types of processed food contain nutrition to a greater or lesser extent.
Some foods may be light on ‘nutrition’ because they are ‘time-saving’in preparation.
If food is subsidized, then ‘convenience foods’ may be promoted with perverse results (see, e.g. Johnson 1978).
The difficulties of applying the goods-specific externality are in this way compounded.
3.
In-kind subsidies are sometimes extremely difficult to police.
Certainly vouchers may be provided to consumers to enable them to consume goods at no charge.
But there is always the possibility that a black market may develop in the vouchers, as with food stamps in the USA.
When the policy and administrative costs of checking this are considered, the advantages of in-kind transfer over cash transfer are reduced.
Tullock (1970) refers to such black market trading as a ‘crime without a victim’, as those who engage in exchange reap gains from trade.
The question of exclusion of non-eligibles from in-kind transfer has been taken up by Toumanoff (1986).
With respect to Fig. 9–12(b) he argues that, if the indifference curves shown related to ineligibles, then the utility gain from attempting to consume this good would be less than the utility gain from falsely claiming a cash transfer.
Suppose that eligible recipients have lower incomes: then it is arguable that with the transfer they would not be at the corner solution.
That is to say, they would wish to (and would choose to) consume all the in-kind transfer.
In this case, for eligible recipients there is no disadvantage in in-kind transfer.
But ineligible recipients, with higher incomes, are affected by the kink in the budget line: the attractiveness of the in-kind transfer is less for them, and so the incentives to consume it illegally (and the costs of policing such activity) are reduced.
Toumanoff explains that, for the ‘hot meal and shelter form of in-kind transfer’(p. 445), the in-kind transfer may be more efficient than hitherto considered.
When considering commodities that are ‘inferior’(in terms of quantity demanded as income rises), the in-kind transfer may be a more rational choice of instrument, allowing for the possibility that ‘ineligible’ individuals may attempt to make false claims on government assistance.
4.
Because in-kind transfers appear overly paternalistic, ‘liberal’ economists would shy away from such interference and constraints on the decisions of recipients.
(For an examination of the liberal position, see Rowley and Peacock 1975.)
Such arguments as these suggest that price subsidies and in-kind transfers do not possess quite the overwhelming advantage for the stimulation of consumption of goods that appeared to be evident above.
Moreover, readers by now will not be surprised to learn that political considerations (rather than goods-specific externalities) have been picked out in order to explain the selection of other forms of subsidies than cash transfers (Browning 1975).
Pressure groups in industries that produce selected goods (like good X) have a reason to push for such selective subsidy because it implies a higher demand for their output.
Bureaus may require larger budgets and a greater number of staff if they are intermediaries in the provision of in-kind transfers.
At the end of the day, the public choice school may offer a more convincing explanation for the choice of redistributive instrument.
9–6 CRITICISMS OF AND LIMITS TO REDISTRIBUTION
Theories of normative income redistribution set a desirable standard or target, whereas the more positive theories are an attempt to predict something about the nature of redistribution in the empirical world which may or may not be consistent with one or more or any of the views of desirability.
The question posed here is what sets the limits to actual and advocated redistribution.
9-6-1 The Philosophy of Equity
The normative literature reviewed above is the product of a relatively small number of economists (and sociologists) thinking about the notion of an ideal income distribution.
It is their value judgement that is largely being presented.
The bias in the contributions is towards quite strong views of equity if not egalitarianism, but different income inequality ideologies exist.
While not wishing to set up any cast-iron categorization, Rein and Miller (1974) do establish a loose typology of income inequality ideologies which they view as ‘overly smooth’(p. 181) but none the less instructive.
The suggestions they make build in the views described in section 9-3-1, as follows:
‘Equality of opportunity’ involves their possibilities 1–3 (see section 9-3-1) and is seen as a market-orientated approach.
‘Lessened inequalities’(possibilities 1–6) is a type of social democratic perspective of retaining the market but reducing the income inequalities it generates in good measure.
‘Normative egalitarianism’ involves possibilities 1–8 and may entail the establishment of a socialist society.
‘Practising egalitarianism’ involves equal incomes for all except for allowances for differences in need.
Although Rein and Miller describe themselves as ‘normative egalitarians’, any of the above positions may not be close to the view of the majority of economists or, more importantly, of the public at large.
As the authors themselves comment, ' a dominating concern for redistribution does not exist' (p. 182).
The marginal productivity theory of the demand for a factor, which indicates that each factor will be rewarded in line with the value of the marginal contribution of that factor at the margin, may go some way as the basis for an explanation.
For many it may be thought that what the market gives you is both fair and rightly yours.
Closer inspection tends to undermine this position, which is obviously a comfortable one for the well paid.
The influence of the technology you work with, the number and quality of co-operating factors and the product price are all relevant to the theory.
However, these are not attributes of an individual as such, which for fairness might be viewed as a necessary condition.
The quality of the factor labour itself is perhaps the only variable that is both relevant and an individual attribute.
Hence the Chicago human capital school comes closest to diffusing economic inequality as an issue.
Uncertainty features in two of the accounts of seeking an optimal income distribution, but the fact is that decisions about redistributions are made by those who know they are either winners or losers in life's lottery and the unbiased perspective that Rawls is seeking is absent.
If feelings of altruism and concern are not as widespread as some would like to think, then the push towards more equality is likely to be a weak one.
In short, one limit to redistribution is that the haves are simply not very concerned about the have-nots.
Tullock (1971) neatly resolves the apparent paradox of there being much rhetoric about redistribution but very little actual redistribution between income groups.
He employs the notion of ‘cognitive dissonance’, met above in chapter 5, and argues that individuals, e.g. many academics, have to have dissonance between their espousal of equity and their lack of any direct action to alter it.
A somewhat superficial way out is to vote for a political party that ascribes to redistribution but does not, when in office, actually take any radical redistributive activities (the past performance of the UK Labour Party, for example, may fit this bill) -that way, you get to salve your conscience and keep your money!
9-6-2 The Politics of Equity
The voting-oriented positive approaches to redistribution, given the comments above, may seem on stronger ground in explaining policy in that they largely rely on a narrow self-interest motive to make them tick.
What prevents the less-well-off majority from really soaking the better-off minority?
One explanation is that a one-person one-vote democratic mechanism does not  correspond to equal political weight.
High-income and wealthy groups have more political influence than lower-income ones.
A number of arguments have been presented in the literature to account for this.
Parliaments typically contain a section of people drawn disproportionately from the better-off sections of the community.
They share a natural empathy with the concerns of that class which, as we have noted, may not be redistribution towards the less well off.
Information is vital to politics and the well off are better placed to acquire and use it.
They typically have more education which reinforces this tendency.
The wealthy and high-income groups can afford to be part of pressure groups favouring their position and to make donations to political parties to ‘buy’ influence, broadly speaking.
The rich have greater incentive to oppose redistributive policies in that they have much more to lose, and there are arguments that suggest that risk-averse individuals are keener to defend against a loss than to secure a gain (see Jones and Cullis 1986).
Reinforcing this differential political power of the rich is the argument above that many poor people may feel they have no reason or right to be part of a redistributive society.
Working-class conservatism and Conservatism is a well known phenomenon.
While personal philosophy may be one basis for this observation, the economic limits to distribution that are introduced next provide another.
9-6-3 The Economics of Equity
One major reason why many individuals may shy away from a very redistributive budget or a generous negative income tax scheme is that they fear that attempts to share the economic cake (GNP) more evenly will reduce its size because of disincentive effects.
They may believe that a smaller share of a larger cake is absolutely bigger than a larger share of a smaller cake.
Disincentive effects are to many minds the limit to extensive redistributive equity.
Even if people stay in the same rank order, the argument runs that the only way to make ‘have-nots’ into ‘haves’is via economic growth, to which high taxation and transfers are seen as inimical.
A second line of argument is to see the picture painted so far as too static.
It may well be that the overall shape of income distributions is roughly constant, but that is not to say there is not much movement within it intra-and intergenerationally.
Concerning disincentives, the predicted effects of a negative income tax provide an example.
High income tax rates above the break-even point of any tax transfer scheme make leisure relatively cheap (the substitution effect) but simultaneously reduce income for buying goods including leisure (the income effect).
If the income effect is large for those in high income tax brackets, it may not be implausible to suppose that the overall adverse work consequences are not all that large.
Critics, however, argue that you have to measure the impact on the recipients of transfers as well.
The negative income tax case illustrated as Fig. 9–13 shows an initial equilibrium at 1 on 10, where the individual is assumed simply to face the wage rate implied by the slope of .
The introduction of the scheme guarantees  irrespective of actual earnings, so  becomes the origin of the budget constraint.
All earned income is taxed at a rate  so that the slope of the budget constraint is reduced along , where  is the break-even point at which earned and disposable income are identical along the poverty line  by construction.
Given the illustrations, the negative income tax moves the individual equilibrium to 2, involving a slightly higher income and less work, more leisure and a higher level of utility 11 as opposed to 10.
The dashed line can be used to decompose this price effect into an income effect 13 (reducing work effort) and the substitution effect of the lowered compensation for each hour of work, 32 (also   reducing work effort).
Some variation in predictions can be obtained by a different location of the indifference map so that,a priori , the strength of effects cannot be settled.
In the event, empirical work in general(as noted above) does not appear to confirm the presence of large disincentive effects, although for negative income tax (NIT), experiments in the USA undertaken in the 1970s did produce significant negative-work-hours responses of the order of 7 per cent reduction for males, 25 per cent for wives and 15 per cent for female heads of households (see Robins and West 1980).
While such estimates are always open to dispute of all kinds, it should be noted that the experiments involved a scheme more like a social dividend, with the income guarantee being set near or at , and the marginal tax rate was a high one at 50 per cent.
Such figures generally exceed what advocates of a negative income tax have in mind.
Turning to movements within the income distribution, mean-variance analysis has been used to illustrate that  progressive income taxation will tend to lower the amount of risk-taking it is optimal for a utility-maximizing individual to undertake.
The argument runs on to suggest that movements within distributions are significant (e.g. Gallaway 1966) and that any mechanism, like progressive as opposed to proportional taxation, that impedes the process needs to be considered in this light.
As always, there is also contradictory evidence and indeed theory.
While the above arguments are a reflection of ‘budget constraints’, there is also the question of the preference map used in determining equilibrium work-leisure choices.
Okun (1975) notes that high taxation of the rich may be interpreted as an adverse ethical judgement on economic success, altering attitudes (preferences) to it and its attractiveness as a goal.
Similarly, at the other end of the spectrum, it is possible that transfer receipts may alter attitudes such that being a ‘contributor’ to the economic process ceases to be viewed as being part of society.
Other causal connections can be argued about; for example, tax transfers may decrease envy, facilitate participation in the mainstream of society and/or foster a sense of unity.
While the mainstream  of economic analysis is on the whole silent about preference formation (see Lewis and Cullis 1988), these connections between economic policies and preferences are important.
The thrust of the above arguments is the suggestion that there is, or is widely believed to be, a trade-off between efficiency and equity whose precise form is unknown.
This trade-off needs to be confronted by those advocating redistribution.
One side of the coin is the extent of disincentive effects, while the other side, discussed here, is the willingness to accept these in order to gain from equity.
(These types of calculation arise in project appraisal in developing countries introduced in chapter 6, where the question is the intra-temporal equity one of weighing income/consumption gains for individuals at different points in the income distribution.)
The Atkinson index introduced above is fruitful in facilitating the comparison of the marginal social utility gain to, say, a poor person (P) from additional income with that of a rich person (R).
The point effectively being made is that, if making a poor person better off by £1 via a redistributive transfer reduces the income of the rich person by more than £1 (because of, say, the necessary administrative costs of the transfer and/or the disincentive effects to earn in the market-place), how much more than the £1 gain to the poor is an acceptable ‘price’?
It is convenient to think of a valuation ratio of poor to rich,, which reflects their relative marginal social utilities of income whose form comes from equation (9–3) so that Jenkins (1989) and the Overseas Development Administration (1988) provide some convenient calculations for a rich person whose income is four times that of a poor person.
These are reproduced with minor modification as Table 9–3.
‘Leaky bucket’ calculations
Of course, this does not resolve the issue of inequality, but it does provide a mechanism through which individuals can focus their view of an acceptable ‘trade-off’ between redistribution (equity) and efficiency.Okun (1975) characterized this sort of trade-off as a ‘leaky bucket’, which lost some of its contents (disincentive effects and administration costs) when used to carry income from the rich to the poor.
In particular, he frames the question in terms of carrying income from the top 5 per cent of US families in 1974 (average income $45 000   per annum ) to the bottom 20 per cent (average income $28 000).
A $4000 annual tax on a rich family raises poor families' income by only $1000 each because of their large numbers, but how much beyond that $1000 would you accept as a tolerable loss?
For illustration, Okun suggests that Milton Friedman would accept no leakage, characterizing him as an efficiency-maximizer, while the Rawlsian answer is a 99(0.9) per cent loss, as Rawls is an equality-maximizer.
Okun feels that the price set by Rawls on equality is too high but in this context he would be prepared to accept a 60 per cent leak Okun (1975, p. 94).
He further suggests that the chosen acceptable ‘leakage’ on any particular issue should be the outcome of a collective ‘democratic’choice, which, of course, raises the voting issues discussed in chapter 4.
9–7 SUMMARY
This chapter has considered a very large topic not just within public sector/finance economics, but within economics per se .
As such it is difficult to do more than introduce some issues and concentrate only on the subset of issues that have figured most prominently in the public finance sub-discipline.
By way of summary, we contrast some recurring themes in this area of economics.
What types of study are the way forward?
It is the ‘all'-inclusive macro-redistributive studies that capture most interest in general, but these are the studies that are beset by the most problems at all levels.
The more micro-based studies, which focus on a particular expenditure programme or transfer policy, often offer a more  tractable research problem, but these are inevitably open to the criticism that they are very partial in nature, giving no real insight into whether government intervention is narrowing or widening the extent of overall economic inequality (assuming we can agree how to measure it!).
Second, in redistributive studies there is a wide gulf between the appropriate cordon bleu (theoretical) recipe and what the empirical short-order cook is forced to do in practice if any sort of meal is to be forthcoming within a reasonable time period.
Data limitations serve to accentuate this gap between theory and practice.
In line with this disjuncture, a persistent suggestion in all sorts of studies is to conduct sensitivity analyses to isolate those elements in any assessment that has a significant impact.
However, this has its limitations.
If, on the one hand, the outcome is insensitive to variation-say, in a valuation-the question arises as to what the study is sensitive to.
If on the other hand it is very sensitive to valuation variation, it is difficult to know which valuation is more representative.
(Widely varying information may not be very helpful.)
After all, if you do not know an appropriate valuation, there may be something arbitrary about knowing what a ‘plausible range’ for a valuation is.
If it is accepted that what motivates interest in redistributive impacts is a desire to be ‘fair’, then the studies that are carried out using current measures of economic status may often by misleading.
To extend an analogy offered by Jenkins (1987), the snapshot/'stills' outside the cinema may not offer a very good guide to the nature of the whole movie.
If it is the impact of government intervention over a lifetime or series of lifetimes that matters, then existing work on the snapshot distribution, however sophisticated, may have little of relevance to offer.
What may look highly redistributive in a ‘still’ may be no such thing across a series of time periods.
Regarding the desirable extent of redistribution, there is little consensus.
Normative theories tend to be fairly egalitarian, whereas positive theories are generally more pessimistic about redistributive prospects.
Finally, it was suggested that widespread philosophical, political and economic beliefs serve to make the relative small amount of measured redistribution that appears to take place the order not only for today but for tomorrow as well.
FISCAL ASPECTS OF MACROECONOMIC THEORIES
10–1 INTRODUCTION
In traditional public finance texts, a considerable proportion of chapters are devoted to fiscal policy in a macro context.
This can be justified by the fact that Keynesianism was the accepted dominant macro-intellectual tradition and that in this tradition a key role, if not the key role, is the manipulation of fiscal policy weapons to achieve economy-wide targets.
In the 1960s, 1970s and 1980s many macroeconomists have seen different lights on the road to an economic Damascus.
Each has attracted his or her share of supporters who could also see the light once it was pointed out to them.
Some theories have enjoyed more academic success than success in terms of policy adoption, while others have been very influential at the policy level but not within the circles of academic economists.
Given that there has been no consensus at the academic level about the superior way to model the macroeconomy, the best way forward, with regard to the role of fiscal variables in the macro world, is to review their significance in the context of different schools of thought.
It can be noted that the ‘Keynesian’ perspective has links with the social optimality approach to public finance as it incorporates market (economy) failure and hence a role for government.
The other perspectives of ‘monetarism’—‘new classical’ and ‘supply side'-have found more favour with the public choice school with its University of Chicago connections.
In this way, the contrast of view that is a theme of the microeconomics chapters is sustained in this macroeconomics one.
10–2 THE KEYNESIAN REAL SIDE APPROACH
While there has been an academic ‘industry’ built around what Keynes really meant in his writing, a one-sentence summary might go as follows.
A market economy that registers only effective demands made upon it may find or tend towards an ‘equilibrium’ that does not coincide with full employment, and hence the manipulation of aggregate demand (especially via the more potent fiscal weapons) can produce a preferred path for the economy.
Equilibrium occurs when the aggregate planned demand from all sectors of the economy matches the output level of the economy, so that all plans are fulfilled.
Alternatively, equilibrium occurs where planned injections into the circular flow of income equal planned withdrawals.1 In the basic Keynesian model the different sectors are viewed as undertaking different activities that are dependent on different main variables.
Variables in themselves are divided between those determined inside the model (endogenous) and those given outside the model (exogenous).
In an open economy, the textbook model is usually   
Such an approach will be familiar to anyone who has ever done a course in macroeconomics.
The model has the following properties:
1.
The more elements are related to , the more complicated is the income multiplier formula.
2.
The more leakages dependent on , the lower the value of the income multiplier.
3.
The more injections dependent on , the higher the value of the income multiplier.
The specific form and impact of the tax-government expenditure multipliers are more central to the current context.
Having considered quite a complicated multiplier appropriate for an open economy, it is still worth while considering the ‘standard’ fiscal multipliers, usual in public finance texts.
The simplest models are for ‘closed’ economies with no tax equation; in short, only consumption is endogenous.
In such circumstances, the multiplier effect on equilibrium  of a fiscal policy of changing  is given by 
Introducing autonomous taxes, would leave the multiplier for a change in  unaffected, however, because the consumption function would now be  
The multiplier for a change in taxation becomes 
The balanced budget multiplier states that ‘increasing both  and  by the same amount raises income by .
This is because 
With the complication of an open economy, this appealing result is lost.
Using the tax function introduced above, the multiplier for a change in government expenditure becomes  and for a change in autonomous taxation it is 
A more likely alternative would have been to change the tax rate , which raises disposable income by , initially inducing expenditure rises determined by the multiplier applied to that term; i.e. so that 
The structure of any model of the type described above can be captured in the general formulation  where  is all the autonomous elements and  collects together all the coefficients on  in the specified model; i.e., in the case presented above.
To elaborate the analysis further and make it richer, it is conventional to replace the exogenous investment function with  where  is the rate of interest and  a coefficient indicating the extent to which a higher rate of interest will reduce the planned level of investment in the economy.
Adding this to the general  formulation in (10–29) yields 
It is this basic equation that is presented in the familiar Keynesian cross-diagram in Fig. 10-l(a).
It is drawn based on a value for the interest rate of .
It is now possible to trace the influence of a change in a nominal monetary variable, the rate of interest, in this model.
A rise in the rate of interest from  to  will reduce the level of investment by , and the effect of this on the level of equilibrium income will depend on the size of the multiplier,.
In Fig. 10–1 this yields a decrease in the equilibrium value of income from  to .
Part (b) of the figure plots the relationship between the level of income or output on the x axis and the rate of interest on the y axis.
This relationship is the so-called  curve, 2 which shows combinations of the rate of interest and income that are all equilibrium combinations in that the level of planned aggregate demand equals the level of output.
Higher rates of interest choke off investment demand (and indeed any other interest-sensitive variable that might have been introduced in the model) so that aggregate demand and output fall, imparting a negative slope to this curve.
(Returning to the original investment equation, it can be seen that this is tantamount to having , in which case the  curve would be vertical under point 1 at .
Changes in the rate of interest would have no influence.)
The relationship plotted as the  curve is easily derived as follows.
From this final expression it is clear that the concepts discussed above influence both the intercept and the slope of the  curve.
A change in autonomous spending  affects the intercept, while the multiplier  affects the slope.
10–3 THE MONETARY APPROACH
In the above section, the Keynesian approach resulted in an  curve that gave a locus of equilibrium combinations of the nominal rate of interest and the real output level, in that the demand and supply of real output of goods and services were matched everywhere along the  curve.
The monetary approach affords primacy not to goods and services as such, but rather to the demand and supply of money (real balances).
Equilibrium in the monetary approach requires that the demand and supply of money be equated.
The approach can be illustrated with reference to a demand-for-money function that has two arguments.
The rate of interest represents the opportunity cost of preferring liquidity by holding cash.
Other things equal, the higher the rate of interest, the more individuals can be   expected to economize on cash holdings.
The second argument involves the transactions demand for holding cash balances instead of interest-bearing assets.
It positively relates the demand for money to the level of income.
These statements can be summarized as  where  is the demand for real money balances, and  are as above and  and  are the coefficients describing the sensitivity of the demand for money to the level of income and the rate of interest respectively.
The curves labelled  in Fig. 10–2(a) illustrates this demand function for two income levels  and , where .
If we assume that the monetary authorities set the size of the nominal money supply  and that for the moment the price level is fixed at , then the supply of real cash balances  can also be illustrated in the figure.
The point labelled  (and its associated rate of interest,), represents equilibrium when  equals  (similarly for , and ).
Given that the diagram involves both the rate of interest and the level of real income, this information can be translated to part (b) to give the positively sloped  curve showing a locus of equilibrium points in the money market.
For a given real money supply, the higher the level of income, the higher the rate of interest must be to allow the transactions demand for money to be met.
Putting both  and  curves on the same diagram in Fig. 10–3 allows the selection of a point like  where there is simultaneously equilibrium in the market for real cash balances-the money market- and the market for output-the product market.
The ‘arithmetic’ of this is that, for money market equilibrium, demand and supply of real cash balances must be equated so that 
The equations that define the  and  curves are important because they explain how fiscal policy might affect the level of output in an economy.
Since autonomous expenditure helps determine the position (intercept) of the  curve (equation 10–35), it is clear that an increase in government spending will shift the  curve to the right.
In Fig. 10–3 the  curve shifts to  and both the level of output  and the rate of interest  increase from , to  and , to  respectively.
But how effective will fiscal policy be in changing the level of output?
Here the slopes of  and  are extremely important.
If the  curve is steep the implication is that an increase in government spending increases income, which increases the transactions demand for money, which increases interest rates, which chokes off private investment.
In Fig. 10–3 the increase in output is not as great as it would have been if this interest rate effect had not occurred (in which case the rise in output would be , to , rather than, to ).
This effect of interest rate ‘crowds out’ the expansionary impact of increased government spending.
Of course, if government spending were financed by an increase in the money supply, the  curve would also shift to the right  to  and the interest rate increase might be avoided as the economy would move from  to  rather than from  to .
In the UK, in recent years the funding of government spending by increasing the money supply has been seen as detrimental, while funding it by borrowing has also been seen as objectionable because of the choking off of private investment.
The reduction of the public sector borrowing requirement (PSBR) in the UK has been a target, and this indicates a desire to curb the role of government spending.
Nigel Lawson, the longest-serving Chancellor of the Exchequer in the post-1979 Conservative government, is quoted as saying: ‘Too high a PSBR requires either that the government borrow heavily from the  banks-which adds directly to the money supply, or failing this, that it borrows from individuals and institutions, but at ever increasing rates of interest, which place an unacceptable squeeze on the private sector’(in Cairncross and Keeley 1981, p. 96).
The impact of fiscal policy on interest rates and on crowding out private investment has, then, to some extent been a consideration of policy-makers.3 More generally, however, the  model and the equations defining the slopes of the functions point to those variables that will be important in explaining the impact of fiscal policy on the level of output.
Changes in the price level, however, have been central to the macroeconomics of the 1960s, 1970s and 1980s.
Inflation analysis divides many macroeconomists, but for the moment the question is how it can be introduced to  analysis.
The simplest method is to relax the assumption of a fixed price level used to locate the real money supply in Fig. 10–2(a).
If  rises to , then,ceteris paribus , the real money supply contracts and has the illustrated effect (Fig. 10–4(a)) of shifting  to the left, hence .
If the price level change has no other impacts on the variables introduced above, then the  curve will intersect the stationary  curve at a higher rate of interest and a lower level of income.
That is, a higher price level is consistent with a lower real income level.)
This relationship between the economy-wide price level and the level of output yields the aggregate demand curve  in Fig. 10–4(b).
This derivation can be made more complex and realistic if the price level affects other variables.
There are a number of plausible arguments.
The most obvious perhaps are via consumption.
If the consumption plans of individuals are related to real wealth as well as to disposable income, then changes in the price level that alter the real value of assets (which are denominated in nominal terms) will affect aggregate demand.
Similarly, an unanticipated price rise will lower the value of real debt of debtors and the value of real credit of creditors.
This redistribution from creditors to debtors may well affect overall consumption plans in the economy.
However, we shall proceed with a rather more simple approach,
A point to note is that both the  and  curves are necessary to give the aggregate demand curve for the economy.
This is an indication that  analysis is demand-side analysis; but what of the supply side?
The aggregate supply curve and its shape allow the introduction of different views of where the macroeconomy can settle and of the significance of economic policy in general and fiscal policy in particular.
10–4 THE AGGREGATE SUPPLY APPROACH
Figure 10–5 has four panels.
In part(a) the demand and supply of labour for the economy is depicted.
The real wage rate is on the y axis and the quantity of labour is on the x axis.
The demand for labour is its marginal product (derived from the aggregate production function in part(b)).
The supply curve represents the outcome of the income-leisure choices of individuals who are utility-maximizing.
At the equilibrium point  the real wage is  and  is the quantity of labour employed generating , of real output.
The 45° line in part(c) projects this level of output to part (d), where the level of output at the price level  can be plotted.
With different price levels it is possible to derive the level of output that will obtain and hence an aggregate supply curve is derived.
If the price level rises to  (falls to ) when the nominal wage remains constant, the real wage falls (rises).
If on the other hand all prices, including wages, rise or fall together, the nominal wage will rise to  (fall to ), leaving the real wage unchanged and equilibrium in the labour market (and the level of output) completely unaffected-a completely inelastic aggregate supply curve .
The Keynesian tradition in particular does not view  and  as moving completely in sympathy.
Wages are seen as flexible upwards but ‘sticky’ downwards, so that rises in  cannot decrease the real wage rate but falls in  can increase it (illustrated in Fig. 10–5 as ).
Downwardly sticky wages gives a J shape to the  curve, labelled , with the curve beginning at the existing price level .
A further combination is possible if wages are ‘sticky’ upwards (for whatever reason) and price level  lowers the real wage rate.
The double-'sticky' case yields the positively sloped  curve throughout its length, labelled  in the figure.
It is hoped that sections 10-2-10-4 have provided sufficient analytical tools to be able to appreciate the differences in perspectives contained in the major schools of thought discussed below.
10–5 MACRO THEORIES, POLICIES AND POLITICAL INCENTIVES
Once the public choice perspective is introduced, a relevant question becomes, What is in each theory for the political actors?
They are not neutral with respect to what is seen to be the current orthodoxy.
Some theories help their own positions while others do not.
Taking each in turn, their basic tenets and relative political attractions can be highlighted.
At the risk of oversimplification, 4 only four ‘schools of thought’ are discussed: the Keynesians, the monetarists, the ‘new classicals’and the supply-siders.
Their typical profiles are summarized in Table 10–1.
10-5-1 The Keynesian Tradition
The Keynesian tradition, at least in its popular form, is the inspiration of section 10–2.
It is short-run aggregate demand-driven analysis which suggests that there is no reason to suppose that the equilibrium level of output consistent with total planned spending will be consistent with full employment in the labour market.
Deflationary and inflationary gaps can be closed by discretionary monetary and/or fiscal policy.
With the ability to learn from past policy mistakes, Keynesians often argue ‘fine-tuning’ of the economy to avoid the misery of unemployment and inflation, with more benefits (and hence weight) being given to the relief of unemployment.
The emphasis in this tradition is very much on the limitations of the market mechanism.
Disequilibrium is seen as the order of the day, with markets on the real side (goods and services, labour) being slow to adjust.
If prices are moving only slowly towards their equilibrium values, then they are currently ‘too high’ or ‘too low’, and in either case too few transactions will take place.
If prices are ‘too high’, demand is choked off, and if ‘too low’, supply is choked off.
The short side of the market is said to dominate.
Given this view of market allocation, there is no incentive to ‘respect’ the market and intervention is fully justified.
The market for labour may be a convenient way to separate the schools of thought.
Referring back to the aggregate supply curve derivation in Fig. 10–5, it is  that is usually attributed to the Keynesians.
Nominal wages that will not fall allowing situations where the real wage gets too high to clear the market.
With no inherent mechanism to correct this disequilibrium outcome, the economy can stay on the lower curve of the J with considerable unemployment; i.e. with the real wage W1/PO the economy might stick at  on  in part(d) with  unemployed in part (a).
Increasing aggregate demand along  with expansionary fiscal policy-lower taxes, raised government expenditures on transfers and goods and services-looks attractive as it moves the economy towards full employment at .
(Recall IS, and, other things equal, will move to the right in Fig. 10–4.)
The implied price level rise from  to  is sufficient to depress the real wage to the equilibrium value in part(a).
10-5-2 Monetarism
Monetarism is identified and associated with the work of Nobel Laureate Milton Friedman.
Recalling the money demand function enables a simplified account of his position.
If the demand for real balances function  is rewritten in the following specific form where  is nominal money demand and  the price level  then, taking natural logs and introducing a time subscript,
Changes in the log of variables can be used to measure the percentage change of that variable.
Now the equivalent equation for period  is 
Differencing the equations yields  
With the emphasis being placed on long-run equilibrium, percentage changes in the rate of interest can be expected to be zero (is a proxy for the return on a wide range of assets) and the  is the rate of change of output governed by real influences such as factor supplies and their productivities.
For equilibrium, where  is the rate of change of the nominal money supply set by the monetary authorities.
Substituting, or 
This is the familiar result that the rate of change of prices, i.e. the inflation rate, is the difference between the rate of growth of the money supply and the rate of growth of the demand for money for transaction purposes.
(is the natural or equilibrium rate of growth of output and  the income elasticity of demand for nominal cash balances.)
In the long run, if the rate of growth of the money supply set by the authorities outstrips that warranted by the ‘natural’ rate of growth of the economy, the result is inflation; hence the call for a ‘monetary rule’.
In this respect inflation is not only everywhere a monetary phenomenon, but is also the responsibility of government.
This is a chord that finds sympathy in the public choice school.
According to Friedman, it is the unwillingness of governments to tax-finance their activities that induces them to cover the gap between expenditures and taxes with money supply increases.
Turning to the labour market comparison suggested above, Friedman allows for rates of growth in the short run to deviate from the natural rate.
This introduces the famous expectations-augmented Phillip's curve, which can be related to Fig. 10–5 and is employed below.
If unions or individuals bargain for, and receive, wages on the basis of an expected rate of inflation that does not occur, then real wages will be higher or lower than expected over the period of the bargain.
If real wages are lower, then in the short run employment will rise to  and output to  i.e. output rises above its equilibrium level because people are ‘fooled’ into thinking they are working for real wage  when they are actually working for real wage .
If, in contrast, the inflation rate is lower than expected, then the real wage can be viewed as rising to  and employment will fall to  and output to .
The aggregate supply curve traced out by these short-run deviations from the equilibrium real wage is  and has a positive slope.
10-5-3 The ‘New Classicals'
The ‘new classicals’ macro theory is historically fairly recent, having come into vogue in the late 1970s and 1980s.
In the monetarist world, a positively sloped short-run Phillips curve existed because mistakes over real wages could arise and therefore temporary deviations from equilibrium existed.
In the long run the Phillips curve is vertical because consistent expectations and outturns are established so that the equilibrium real wage and the natural rate of output obtain.
For the ‘new classicals’ there are no systematic mistakes, and the long-run equilibrium position is always established except for random errors.
This powerful and eyecatching result is obtained by postulating a world in which:
1.
all prices, including wages, are perfectly flexible upwards and downwards;
2.
economic agents suffer no systematic misperceptions, money illusions, etc., so it is the unforeseen and unexpected that have influence on the economy;
3.
economic agents simultaneously employ an economic model of the economy and use all available information, the expected marginal benefits of which equal or exceed its marginal cost, to make predictions about economic outcomes.
In this ‘rational expectations’ type of world (see Sheffrin 1983) everyone can rapidly appreciate both the consequences of economic policy and the fact that the underlying equilibrium values for real variables will be unaltered by policy.
Once again, returning to part (a) in Fig. 10–5, there will be no deviations from the equilibrium value of the real wage rate: any price changes will be appropriately compensated for by wage changes and  individuals will be employed producing  level of output, irrespective of the price level.
The aggregate supply curve  is vertical in the short run as well as in the long run, so the ‘natural’ rate of employment (and hence unemployment) and output are always achieved as long as changes can be foreseen and are expected.
The incomplete, sluggish and/or mistaken adjustments to changing economic signals that can be found in the Keynesian and monetarist short-run situations are removed from the new classical world by economic agents' incentives and their ability to use full information to adjust to any new configuration of nominal variables as rapidly as possible.
Any attempt, for example, to engineer a rate of unemployment except that associated with the natural rate of output  will be thwarted.
If the government increases the money supply to increase the price level to engineer a fall in the real wage, actors can be expected to be fully aware of this and hence to adjust the nominal wage so that no real purchase on the economy can be obtained.
As noted above, there can be exceptions to the vertical aggregate supply curve when changes are unanticipated.
With stable macro policies of either a monetary or a fiscal kind, rational expectations on behalf of economic agents mean that such agents fully appreciate the signals that trigger government policy and the prescriptions that follow, internalizing this into their behaviour.
Apart from making random forecasting errors, the only way to affect real variables is to continually surprise people by deliberately fostering ‘unstable’ macro policies; but this is counterproductive.
With the inability of stable monetary and/or fiscal policy to alter the real course of the economy, it is the determinants of the ‘natural rates’ that are the source of concern, and this is where the supply-siders would say they come in: by highlighting the way existing government policy provisions affect utility-maximizing choices, they concern themselves with the location of the various functions involved.
10-5-4 Supply-Side Economics
Supply-side economics is probably the perspective that had least credibility academically but most credibility politically.
After all, by conforming with the prejudices of many voters, it must offer something close to a ‘dream’ economic platform for the politicians.
The recipe of supply-side economics can be illustrated by reference to Fig. 10–6.
Suppose the wage rate for the economy is : then at the individual level in Fig. 10–6(a) the equilibrium income leisure choice is at point 1.
This is associated at the macro level with an overall income level  and, given a zero tax rate (in our example, for simplicity, the tax rate  is a proportional one so that average and marginal tax rates coincide), the level of recorded income will be close to if not identical with it at .
With the introduction of higher tax rates  and , the effect is to move the equilibrium income leisure choice to points 2, 3 and 4 respectively.
Initially, the income effect of the taxes makes the individual ‘buy’ less of all normal goods including leisure.
Work-hours increase and the actual level of income rises.
At some point, however, the substitution effect associated with taxes makes the opportunity cost of leisure less.
More leisure hours are taken.
The relative strengths of the income and substitution effects dictate the outcome.
The tax rate where actual income is maximized is  in part(b) of the figure.
With higher marginal tax rates the incentive to evade and not declare income increases, so that the discrepancy between actual and recorded income widens as  increases.
The lower tax rate  is the tax rate at which recorded income is maximized.
Tax revenue is the product of the tax rate and recorded income, and this generates the Laffer curve, in Fig. 10–6(c).
The Laffer curve  in the same part of the diagram relates to actual income.
Note that the products  and  are not maximized where  and  are maximized, because over a range a bigger share of a smaller income will represent a higher total tax revenue than a smaller share of a larger income.
Laffer argued that with a high tax rate, say  a move to a lower one, say , would raise actual income, recorded income and tax revenue.
Getting the government ‘off the backs of the people’ by offsetting the incentives to leisure and evasion would offer something for everyone.
The government would have more to spend, at the same time as real output would have risen offsetting unemployment.
If the rise in real output takes place against a background of a tight money or explicit ‘monetarist’ policy, there will be downward pressure on the inflation rate and an already attractive package is further enhanced.
While the logical steps in the argument are acceptable, there are a number of difficulties.
Not least among these is that you have to be beyond the peak of the Laffer curve to begin with.
The account of Buchanan and Lee (1982), relying on the distinction between short-run and long-run Laffer curves in this respect, is crucial (see chapter 17).
In terms of Fig. 10–5, ‘supply-side’ macroeconomics can be viewed as shifting the aggregate supply curve to the right.
The evidence of labour supply responses to tax cuts is that they are undramatic (see chapter 12).
If they are to occur, it is likely to be in the long run when economic actors can adjust to the new situation.
In the short run it is generally argued that tax cuts will simply stimulate aggregate demand and, with aggregate supply largely unaffected, will be inflationary.
Such a consideration raises the prospect of having to run a surplus budget at the same time as cutting taxes.
The difference between the short run and the long run is important for the political business cycle models which are now seen as a more central feature of a public choice perspective.
The focus here is not so much on which macro ‘school of thought’ is ideologically attractive, but rather on what macro actions will capture the voters.
In this sense the literature discussed next is about the political process and macroeconomics rather than macroeconomics per se .
10–6 POLITICAL BUSINESS CYCLES
The presence or absence of political business cycles is an area of contention in the realm of macroeconomic policy.
The basic idea is a simple one and follows in the Downsian vote-maximizing tradition, suggesting that those in office, conscious of election dates, manipulate the economy to achieve political popularity.
The cost of such actions is that individual welfare is lowered by such manipulation.
Broadly speaking, expansionary monetary and fiscal policies before an election will lower rates of interest and levels of unemployment while raising national income.
After an election, this policy has to be reversed to avoid the likely inflationary consequences.
Many models built around this basic theme are surveyed by Alt and Chrystal (1983).
They build up a taxonomy that relies on whether the preferences of the electorate are seen as fixed or varying and whether government capability is seen as strategic or responsive.
Responsive government seeks to follow the preferences of its supporters, whereas strategic government action seeks to vote-maximize irrespective of the party's own supporters' preferences.
Fixed and variable voter preferences are self-explanatory labels.
Here we make no attempt to survey as many models as in the Alt and Chrystal taxonomy, but seek rather to highlight some examples.
(For an alternative taxonomy see Alesina 1988.)
The first model considered is one of the best articulated ones and assumes fixed preferences and strategic government.
It is the model developed by Nordhaus (1975) and it adopted the then current views of the shape of the Phillips curves.
In particular, there is a long-run Phillips curve  (‘e' for ‘early’) that is negatively sloped.
The basic picture is represented by Fig. 10–7(a), where a family of short-run Phillips curves  are also illustrated.
The hypothetical numbers attached to short-run curves indicate that the point on a short-run Phillips curve that   is on a long-run Phillips curve is where expected and actual inflation rate coincide.
To the left of  inflation is greater than expected or anticipated, and vice versa to the right.
To bring this picture into line with the earlier part of this chapter, a vertical  has been added labelled  (c for current as opposed to e for the early version).
Part (b) of the figure represents the iso-vote curves and indicates combinations of two ‘bads’, namely inflation and unemployment, that yield equal votes from the electorate where the labels indicate more votes as you move towards the origin.
Putting the iso-vote ‘preferences’ on the Phillips curve constraints yields the ‘equilibrium’path of the model (see Figure 10–8).
Attempts to trade on the location of the short-run Phillips curves means the equilibria that governments try to engineer   are successively found at 1, 2 and 3, assuming that  incorporates the initially expected inflation rate.
The trade-off possibilities worsen because to the left of  people's expectations about inflation are falsified with the actual rate exceeding the expected rate.
Trade union bargaining and other attempts to ‘catch up’ with reality serve only to raise inflation (and unemployment) until point 3 is achieved and expected and actual inflation rates coincide.
The reverse pattern would obtain to the right of  and a move from a point such as 4 to point 3 can be anticipated.
The highest long-run sustainable popularity is achieved where the  is tangential to the iso-vote curve  at point 5.
The burden of Nordhaus's model is to suggest that a democratic economy will exhibit an inflationary bias with the gains from exploiting a ‘fooled’ electorate being a higher rate of inflation at point 3 than at point 5.
(Note that this also involves a lower rate of unemployment than the long-run equilibrium would suggest.)
Of course, the possibility of lower unemployment at point 3 in Fig. 10–8(b) is precluded as the natural rate  will obtain.
The long-run sustainable position that maximizes votes is now a ‘corner solution’ at point 5', where the natural rate is combined with zero inflation.
However, short-run political considerations suggest that point 3 will be the outcome.
Among the criticisms levelled at the Nordhaus model is the assumption it contains that voters are systematically ‘fooled’: they do not appear to learn that costly post-election recession follows beneficial pre-election boom.
As noted above, one of the most influential schools of macro thought in recent years is that associated with rational expectations, which involves actors internalizing all available information in a model to anticipate now the consequences of, say, increasing the money supply.
If accepted, then the short-run Phillips curves disappear and there is only the vertical location on the long-run one to argue about.
Such an outcome seems to cut the ground from under the Nordhaus model, with point 5' in Fig. 10–8(b) being the equilibrium outcome.
The point of this criticism, however, has been dulled somewhat by models offering somewhat similar predictions that replace myopic voters with voters who have less information than those who shape policy (e.g. Rogoff and Sibert 1988).
Another model allows for partisan effects to occur even in the presence of rational expectations.
In a US setting, Republicans are associated with keeping inflation in check at a greater cost in terms of unemployment than the Democrats will accept; to put it, perhaps, too strongly, one is the party of unemployment and the other the party of inflation.
Before an election, voters uncertain of the outcome are viewed as assigning probabilities to the result, allowing wage-setters to negotiate on the basis of the average expected post-election monetary growth rate-the average being a weighted one with the weights the assigned probabilities of each party's success.
On this basis, if the Republicans win the monetary growth rate will be lower than ‘averaged for’ and a recession will occur.
The reverse will apply if the Democrats win.
Sheffrin (1989) considers empirical evidence relating to this proposition and finds it lacking.
One of his main pieces of evidence is the failure of the ‘announcement’ effect of the result on the stock exchange to be strongly supportive with the theory.
(The stock market should, for example, internalize a Republican success with instantaneously lowered prices, reflecting the expected depressed profit streams because of the result; see also chapter 5.)
Frey (1978; also see Frey and Schneider 1978) manages to combine both responsive and strategic government with fixed voter preferences in his several contributions to this area.
The main novel feature exploited is a two-level test of political business cycles with a popularity function and a policy function.
The first function connects economic conditions-unemployment, inflation and the rate of economic growth-to the incumbent's party political popularity and hence his or her chances of winning the next election.
It is the policy function that embodies the strategic and responsive government positions.
If popularity is low then economic variables are manipulated to ‘correct’ the picture, whereas with comfortable popularity the government will follow its supporters' and its own ideology, i.e. will be responsive.
In this sense, the Frey model is more utility-maximizing than vote-maximizing as such.
Popularity in the polls is wanted so that the ideological programme can be followed.
This is consistent both with politicians being larger than people who simply wish to be in office whatever they have to do, and with parties having a central number of supporters who share an ideology.
Before mentioning some of the evidence and the criticisms, it is worth noting that, as with macroeconomics in general being lent micro underpinnings, so macro-political business cycles  have a microeconomic aspect.
Ekelund and Tollison (1986) and Lewin (1988) note that the Austrian school (associated in particular with Hayek) see the macro consequences as being the result of microeconomic-motivated actions and some macro actions finding their impact at the micro level; for example, industrial, regional and other policies often adopt subsidies to maintain an output and employment target (see chapter 5) in a particular industry.
However, repeating the process for other industries eventually leads to the running of deficit budgets.
The point is that the deficits are the result of specific policies directed at specific groups of workers.
An example of the macro-to-micro arguments is that politically inspired monetary relaxations and contractions serve to alter the nominal rate of interest, giving the wrong investment signals.
If losses are made by investors acting misguidedly, this results in macro output and employment reductions.
Again, the point is the micro connections through ‘wrong’ relative prices having macro consequences.
Most authors of political business cycle models subject their models to econometric or other forms of testing.
The results tend to be very mixed.
Alt and Chrystal comment that
It is curious that the literature on political business cycles is widely invoked, even though there is little evidence for the existence of such cycles.
(Alt and Chrystal, 1983, p. 103) whereas Schneider and Frey comment:
Summarizing the results of this part, we clearly see that governments in representative democracies undertake those fiscal policies which are popular for a majority of voters when they feel that their re-election is in danger.
(Schneider and Frey 1988, p. 262)
A number of criticisms have been levelled at the political business cycle literature in general.
Some relate to queries concerning economic theory, others to the nature of the actors involved in political processes.
Regarding economic management, one tenet of monetarism is that the effects of money supply changes involve both long and variable lags, so that it assumes too much expertise on behalf of politicians to imagine they can time expansive monetary policy to their advantage.
In this respect politicians apparently have knowledge of the economy that economists do not.
Elsewhere contradictions between models and economic theory can be noted.
Alt and Chrystal (1983) discuss a model presented by Hibbs (1977) which involves party members/supporters with fixed preferences occasionally ‘disciplining’ a wayward government of their own persuasion by failing to vote for it.
With changes of government over time reflecting different views about inflation and unemployment, a cross-section Phillips curve with different countries as the observations is postulated.
Left-wing incumbents are expected to adopt high-inflation, low-unemployment positions and right-wing governments the reverse.
One problem with this is that, up until the break-up of the Bretton Woods system in the early 1970s, the postwar period was characterized by a world of fixed exchange rates, which suggests that rates of inflation should converge, as opposed to being different under different regimes, if fixed parities are to be maintained.
Laidler (1987) notes the constraining impact that a fixed exchange rate regime will have on politicians:
Increased government borrowing tends, under such a monetary policy regime, to lead to increased domestic credit expansion and hence ensures that current account difficulties quickly become overall balance of payments problems.
So long therefore as the central country of the Bretton Woods system pursued responsible policies, fiscal deficits in a peripheral country such as the United Kingdom generated balance of payments problems for that country, and any government seriously committed to maintaining a fixed exchange rate on the US dollar found its freedom to run such deficits severely curtailed by the commitment.
(Laidler 1987, p. 345)(One argument for the UK fully joining the European Monetary System is that in order to maintain our par the UK would have to have the same (low) inflation rate as West Germany.)
It has already been noted that most models have a view of politicians as people who follow overly narrow self-interested behaviour to the detriment of interests of the electorate and presumably their own long-run reputations.
A similar point can be made with respect to voters who, despite what some economists might like to think, will have views beyond the fate of major economic indicators and will be concerned about the conduct of foreign and domestic policy at large.
Kelman (1988) in particular takes this kind of line, pointing out that those most opposed to the Vietnam war were those who had no chance of actually going there and being in danger.
Ideology is apparently a better predictor of attitudes of American voters to the introduction of a national health insurance programme than the personal benefits that individuals can expect to receive.
In general, Kelman points out that voting surveys, despite the predictions of many of the political business cycle models, suggest no significant connection between personal fortune and voting behaviour.
Those who tend to vote against an incumbent government are not those who have become unemployed: rather, they are those who see the government as a weak and incompetent one.
All this is not to suggest that political advantage has not had and does not have any effect on the conduct of macro policy, but rather that the evidence and theory presented is consistent with its having a small rather than dominating impact.
As with any relatively recent field of investigation, this conclusion needs to be viewed as interim rather than final.
10–7 UNEMPLOYMENT
As a crude approximation, the 1930s saw unemployment as a dominant issue, while the 1950s and early 1960s saw the operation of the Keynesian consensus with full (or some say over-full) employment.
Inflation as a problem dominated the late 1960s and 1970s, whereas the 1980s seem to have been characterized by both inflation and unemployment.
It was noted that the Hibbs contribution suggested that right-wing governments tended to see inflation as more of a problem than unemployment.
A straightforward explanation for this is that inflation affects all voters whereas unemployment tends to be heavily concentrated on (as far as the UK is concerned) areas not noted for extensive Conservative support.
Of course theories that suggest the economy will gravitate to the natural rate of output and unemployment to some extent sanction concentration on inflation as ‘the’ policy issue.
(Note that it is possible in such models to alter the natural rate, but only by altering the structure of the labour market.)
In this respect the concentration of the Nordhaus model on inflationary bias is appropriate to its context.
However, the purpose of this section is to focus on unemployment, its measurement and some explanations of its ominous presence.
The account is not exhaustive but is outlined with a view to drawing out alternative perspectives.
Measuring unemployment, like measuring the size of the public sector, at first seems an obvious exercise, but in fact is far from being so.
While there has been a world recession to contend with on top of the problems the UK would otherwise have faced since 1979, public choice theorists would not be surprised that the Conservative government has sought to minimize the level of reported unemployment.
By February 1986 the government had announced fifteen separate changes to the way the unemployment figures were calculated and presented.
By the same token, the public school choice would not be surprised to find that the Labour Party opposition regarded the official unemployment figures as underestimates The arguments that divided them are illustrated in Table 10–2, which reproduces in a slightly amended form a table that appeared in The Sunday Times (6 November 1983).
While not wishing to examine the pros   and cons in detail, enough is presented to establish that the much vaunted ‘facts’ of any situation are seldom that.
Furthermore, whatever reducing arguments are accepted, nearly all commentators acknowledge that Britain did have an unemployment problem of some considerable dimensions in the 1980s (which was heavily age- and geographically concentrated).
How is this accounted for?
We offer some forms of explanation, the first two of which are Keynesian in orientation (see Blinder 1988) while the third is based on a public choice approach.
10-7-1 Real Wage Stickiness
There are an increasing number of theories about why the market-clearing real wage is not attained.
In terms of Fig. 10–5, if  is established, how is it that the number of workers recorded as unemployed is measured between points 2 and 4 rather than the real wage falling so that labour market equilibrium is established at  Trade union power is an obvious explanation and is explored further in the context of coalitions below.
A less strongly related argument is that contained in a version of the ‘insider-outsider’ accounts of unemployment (see Linbeck and Snower 1986).
Here, even in the absence of unions, those currently in employment have power.
The realization that it is a very costly option for a firm to try and lay off all employees and replace them allows ‘insiders’ to bargain for a continuing employment relationship and to achieve a greater than labour-market-clearing wage.
Employers know that ‘insiders’ will not co-operate with any undercutting ‘outsiders’if they employ them, while on the other side of the market would-be undercutting outsiders can expect to be ‘harassed’by insiders if they are successful in gaining employment.
Linbeck and Snower (1990) respond to Fehr's (1990) comment on their work by explaining why firms will not replace all insiders with undercutting outsiders.
Their explanation relies on the ‘turnover costs’ that would be involved: the fact that insiders are more productive because they have had more on-the-job training; that such training may well come from insiders who on being sacked will not be there to supply it; that  harassment via picket lines, the ‘angry silence’, etc., can be employed even by displaced insiders, that the unpopular act of replacing a whole work-force is likely to cost the firm in terms of lost' good-will ‘.
If this argument is accepted, then insider-outsider theory still has some purchase despite Fehr's objections.
10-7-2 ‘Efficiency’ Wage Theories
Efficiency wage theories tie back with the rationale of the firm as a form of productive organization.
The Alchian-Demsetz (1972) approach suggests that team production outproduces isolated individual production, providing a necessary but not sufficient condition for firm formation.
The trouble with firms is that ‘team’ production gains are bought at the cost of opportunities to ‘shirk’.
An employer might respond to this by offering his workers higher wages to foster effort so that they will fear losing their jobs because the alternative jobs are less well paid (see Greenwald and Stiglitz 1987).
However, if this is a rational response for one employer, it is likely to be a rational response for all of them, so that all firms will pay more.
The consequence of this is that the real wage level exceeds the equilibrium one so that there is, simultaneously, high real wages and unemployment.
The main implications are (a) that the fear of unemployment, not of a lower paid job, becomes the ‘disciplining’ mechanism, and (b) that there is some ‘pay-off’to above-equilibrium real wages in the form of reduced shirking and increased output.
The latter point suggests some output loss to reducing unemployment.
10-7-3 Public Choice and ‘Coalitions'
Colander and Olson (1984) claim that too little attention has been devoted to the role of rent-seeking (distributional gain-seeking coalitions) in the macroeconomics of both the Keynesian and new classical varieties.
In their view, the effects of employees’ coalitions keeping wages artificially ‘high’or of employers' coalitions keeping them artificially ‘low’needs to be fully analysed.
As noted elsewhere in this book, such group action requires small numbers or the use of selective incentives to avoid the free rider problem.
The authors argue that most coalitions related to ‘sellers’, so that it is greater-than-market-clearing wages that are the concern, resulting, as far as the labour market is concerned, in excess supply (unemployment) rather than excess demand (vacancies).
In Fig. 10–9 the area  represents the coalition gain from a higher-than-equilibrium wage .
The coalition reduces employment to  from .
In a wider context a quantity of labour  will be forced into the sectors of the economy where there is less rigidity.
However, if the rent-seeking coalitions are extensive, this may well reduce wages elsewhere to the point where reservation wages are not met and unemployment and/or underemployment is commonplace.
The return to being on the inside of the charmed circle entails potential employees extending their search and queuing to join the successful rent-seekers; i.e. search unemployment is raised.
Colander and Olson contend that the effect of coalition power is to reduce the speed and quality of adjustment to changing economic circumstances.
The time and trouble costs of getting an agreement rise once you move from individual private decisions to group ones.
Regarding quality, the incentive for group members to be well informed is less than for private individuals because of the opportunity to try and free-ride on the information of others.
Incomplete information guides the outcome.
Slowly adjusting, ill informed rent-seekers can, to some extent, be traded upon by vote-seeking politicians who want a growing economy with falling unemployment.
Expanding aggregate demand to raise prices will unexpectedly lower real wages, pushing employment away from 1 and towards 3 in Fig. 10–9 while simultaneously increasing output.
While empirical evidence relating unemployment levels to the unionization level in the USA provides some support for the analysis, the major point the authors offer is that the explicit or implicit adoption of price-taking competitive behaviour in macro modelling is misleading.
10–8 SUMMARY
In this chapter thumbnail sketches of the major ‘schools’ of macro thought have been presented.
By definition the nuances of each have been ignored.
This sacrifice was made in order to bring out their relevance for government intervention, especially of a fiscal form, and the public choice perspective.
Keynesianism, with its blessing for both policy intervention and unbalanced budgets, is a bete noir of the public choice economists (see Buchanan and Wagner 1977).
A perspective of well working markets (therefore the need for minimal government intervention) and a balanced budget make the competing schools of thought more attractive to this group.
It was argued that supply-side economics offered most to the politicians, whereas theories of political business cycles suggest an ‘incentive’ but perhaps little real ability to manipulate the economy to secure re-election.
As for unemployment, arguments about the statistics cannot mask the realization that the UK has a considerable unemployment in the 1980s.
The public choice approach suggested that coalitions and rent-seeking were central to understanding this.
Interestingly, Blinder (1988) connects the success of the new classicals over the Keynesians in the 1970s with: the need to be both different and technical to succeed as a (US) academic economist; Keynesian lack of microeconomic underpinnings; and the rise of a right-wing ideology in the USA.
In this respect, the ‘trick’ was to make macroeconomics look like neoclassical microeconomics.
Blinder argues that the resurgence of Keynesian economics is based on the reverse process of making microeconomics look more like (Keynesian) macroeconomics.
This resurgence involves pervasive monopoly, externality and other ‘market’ failure arguments which connects the ‘social optimality’approach to public finance with modern Keynesianism.
LOCAL GOVERNMENT
11–1 INTRODUCTION
In this chapter we focus on some fundamental questions pertaining to the fiscal activities of local authorities.
In particular, two related questions are, How large should local authorities be? and What gains, if any, are derived from fiscal decision-making at a local level?
Traditionally, public finance theory has approached these issues using the assumption that government is motivated by the pursuit of the ‘public interest’.
Such analysis is typically removed from any historical context and the theory is inevitably limited as a description of the formation of an actual local authority or particular federal state.
It ignores specific historical and political constraints to discuss a broader welfare-maximizing Paretian framework.
In this way the theory may sometimes strike readers as a little naive.
Even so, it provides a model for researchers who are interested in local government reform.
The intention again is to illustrate the difference between the traditional theory of public finance and the public choice approach.
The literature on the impact of intergovernmental grants is particularly useful for this purpose.
The public choice school once more offers explanations for economic phenomena that cannot be easily explained by traditional public finance theory.
It is left to readers to assess whether such explanations appear reasonable or contrived.
11–2 THE WELFARE GAINS FROM MULTIPLE FISCAL UNITS: THE DECENTRALIZATION THEOREM
The welfare gains from decentralization are often considered by reference to those deadweight losses that result from centralization (Oates 1972).
Assume that the population of a particular nation-state is divided into two distinct localities.
A local public good is to be provided in each locality and the cost is to be shared equally by residents.
In Fig. 11–1 we illustrate the demand for the local public good of two ‘representative’ individuals, one from each locality.
represents the demand of individuals in locality  and  represents the demand of individuals in .
The marginal costs of providing this particular public good  are assumed to be constant.
The price each individual is asked to pay is shown as  in the diagram.
(This would be each individual's share of the marginal costs .)
In this diagram, if a centralized regime provided a single uniform level of the good, the level of output provided could be shown as a compromise between the demands of the individuals in each locality, i.e. a level of .
Such a quantity is lower than the amount that would be demanded by the representative individual  but more than would be demanded by the representative individual .
Inevitably, welfare losses are experienced by each of these two individuals.
The losses are shown as triangles 123 and 145.
Triangle 123 indicates the loss that arises because individual A does not consume as much as she would choose if there were no need to compromise.
She would gladly pay  for the additional units  but these would cost only  to be made available.
Triangle 145 indicates the welfare losses that are experienced by individual B because he is consuming more than he would otherwise choose.
He pays  for the additional units  but he values them at only .
If each area could provide itself with just the quantity of the good that it requires, these deadweight losses could be avoided.
Decentralization permits each locality to provide itself with the quantity of the good it prefers.
This illustrates the ‘decentralization theorem’, which is described by Oates as follows:
For a public good-the consumption of which is defined over geographic subsets of the total population and for which the costs of providing each level of output of the good in each jurisdiction are the same for the central government or the respective local government — it will always be more efficient or at least as efficient for local government to provide the Pareto-efficient levels of output for their respective jurisdictions than for central government to provide any specified and uniform level of output across all jurisdictions.
(Oates 1972, p. 35)
There are, however, a number of points to add.
1.
As Oates (1979a) notes, in Fig. 11–1, if  and  were close, then  would provide a close approximation.
It is evident that the greater the difference in tastes and preferences, the greater the welfare losses.
Welfare losses from centralized provision increase with heterogeneity .
2.
As in other cases, the deadweight welfare loss depends on the price elasticity of demand .
The more inelastic the demand curves (the steeper the demand curves at points 5 and 3 in Fig.  11–1), the larger will be the area of the shaded triangles.
The sizes of the triangles are the key to the losses from centralization.
In an attempt to estimate these welfare losses, Bradford and Oates (1974) estimated a multiplicative demand function (for local school expenditures).
They used this to estimate the loss in consumer surplus that would rise from adherence to a hypothetical uniform level of expenditure.
(This was an expenditure level equal to the existing average level.)
3.
In the above analysis, if there are economies of scale in the production of the good, this will influence the optimum size of the locality.
Other things equal, there will be a greater case for taking advantage of the lower average costs of larger communities.
4.
The above efficient gains from decentralization arise as government deals with its allocative functions.
By contrast, there is more widespread agreement that the macroeconomic stabilization function will be better performed by central government than by local governments.
Because of the openness of small local economies, the government expenditure multiplier will be low and fiscal policy will have less impact for stabilization purposes (see chapter 10).
In this case the effect of local fiscal expansion, for example, will fall on the ‘imports’ from other local economies.
The fiscal multiplier in the expansionary locality will then be reduced.
Any particular local government may be forced to incur an extremely large budget deficit in order to have an expansionary effect on the local economy.
5.
Similarly, a local economy may not prove effective for the operation of redistribution policy .
When individuals are mobile between local authorities, a local economy seeking to impose a higher tax on its upper-income residents would simply create an incentive for such residents to move to another locale.
If individuals are less mobile internationally, a central government is more able to effect redistribution policies.
The rich tend to want to be away from the poor, but the poor want to be in the same jurisdiction as the rich.
11–3 THE OPTIMUM SIZE OF LOCAL AUTHORITIES: AN APPLICATION OF THE THEORY OF CLUBS
In chapter 4 an analysis of consumption-sharing arrangements was based on Buchanan's (1965) theory of clubs.
Here, following Musgrave and Musgrave (1989), our objective is to show how this theory can be applied to the question of the optimum size of local authorities.
By ‘optimum’ we mean efficient, and by size we refer to the number of residents and the total expenditure on local public goods.
In order to discuss the analysis of Musgrave and Musgrave, it is helpful to set it in a four-quadrant diagram, similar to that used by Sandler and Tschirhart (1980).
The question of how many individuals  should be resident in a local authority is considered in quadrant II of Fig. 11–2.
The costs per capita of providing a particular local public good (e.g. street lighting, fire service, education) depend on the number of residents who share the total cost.
The curve  illustrates costs per capita; as more people live in the locality, there is a reduction in the share that each resident pays of the total cost  incurred by providing some service level of the good in question.
If we assume that the total cost is constant, then curve  will be a rectangular hyperbola.
It is an average cost curve for citizens for a constant level of output.
However, by comparison, the curve  shows the marginal savings in per capita cost as the number of residents increases.
The curve measures the amount by which  falls as the population of the locality increases.
It shows the fall in average costs as numbers increase by one additional individual.
If  is the total cost of providing the good, then the change in   per capita costs of providing the good is 
This is the marginal cost savings experienced as a consequence of increasing the number in the locality.
Increasing the number of residents reduces the costs of a fixed level of the public good.
On the other hand, as more individuals settle in the locality, costs of crowding will be experienced  by the residents.
The public good in question is not a pure public good (see chapter 4) but one whereby congestion costs are experienced as capacity levels are reached.
The  curves indicate the per capita crowding cost for individuals.
Such costs increase as the population size increases.
By analogy, shows the marginal per capita crowding costs , i.e. the amount by which crowding costs increase as the population increases.
In interpreting the curves  and , it is possible to think of curve  as a marginal benefit curve (i.e. reduction in costs) associated with increases in the population and of curve  as a marginal cost curve associated with an increase in the population.
In this context it should be clear that the optimal number of residents in the locality is .
(The population size should be increased to the point at which the marginal gains to residents are made equal to the marginal costs to club residents as a result of increasing the number in the locality; i.e. the property rights are vested with existing club members.)
However, it will be obvious that this solution is not independent of the total size of the service provided.
For example, suppose that the level of output of the good increased.
The total cost may as a consequence increase.
The  curve would be shifted upward to .
It is possible also that the increased expenditure might alleviate the crowding cost associated with a greater number of people, and in this case the  curve would shift to the right, thereby increasing the optimal number of individuals for the community.
In the diagram we illustrate the shift in both  and  functions to  and  respectively.
It is evident then that the optimal number of residents increases to .
The important point is that the optimal number of residents for a local authority can be determined only when the ‘appropriate’ quantity of the local public good is determined.
In quadrant  is an individual's demand schedule for the good in question.
For simplicity it is assumed that tastes and income are identical between residents, and therefore, once again, this is a ‘representative individual’ for the locality.
is the per capita marginal cost curve.
It shows how costs increase for each resident as the quantity of the local public good increases.
On face value, the question of what output of the good to produce appears quite easy to resolve.
The solution would appear to be .
Yet it has already been argued that the marginal costs of the good will be a function of the number of people in the community, and therefore , relate to different numbers (e.g. 100, 200, 300 residents in the community).
It is obvious then that, until the question of the optimal number of individuals in the community is resolved, it is impossible to determine how much of the good should be provided.
In so far as both these questions have to be solved simultaneously, it is important to utilize the other quadrants in Fig. 11–2.
A 45 degree line is used in quadrant III to transpose quantities from the horizontal axis on to the vertical axis.
In quadrant IV information derived from quadrants I and II are collated.
The line Nopt plots the optimal number of residents for any given quantity of the public good.
(This is derived from quadrant II.)
The line  plots the optimal quantity of the good for any number resident in the neighbourhood.
(This is derived from quadrant I, via quadrant III.)
The intersection of the two curves indicates the simultaneous solution to the two problems.
Moving back from quadrant IV through quandrant III to quadrant I, we see that this implies that  should be produced.
Tracing upwards from quadrant IV to quadrant II, the optimal number is .
The model as discussed may appear rather simplistic, and there are qualifications that might be made.
1.
Musgrave and Musgrave (1989) note that technical economies of scale may be experienced in the provision of increased quantities of a local public good.
Above it is assumed that the marginal costs of increasing output are themselves increasing.
2.
Not all benefits of a locally provided public good are experienced by the locality that  provides it.
For example, some portion of the benefits may spill over to residents in another locality.
Topham (1983) argues that this may not affect the optimal number of residents in the locality but would influence the optimal provision of the good.
3.
The above analysis has been undertaken on the assumption that individuals have similar tastes and similar incomes; i.e. we have used the assumption of a ‘representative’ individual.
Since individuals have different tastes, it may be that the efficient solution is for individuals of similar taste to group together.
However, with multiple groupings, some of the advantages of cost-sharing may be lost.
The question of how groupings occur will be considered in the next section.
4.
If individuals of similar income were grouped together, the outcome might be unstable.
If the taxes that individuals pay for a local public good were higher as a consequence of higher income, the poor might enjoy a greater quantity of a local public good if they were resident in a high-income area.
There may well be a tendency for zoning on the part of high-income groups in order to exclude the poor.
5.
The optimal size of the local authority depends on the kind of public good under consideration.
It will be evident to the reader that it is the element of congestion that occurs in a local public good which determines that the size of the locality should be restricted.
If the good were a pure public good then there would be no limit to the size of the locality.
If there were no congestion costs the optimal size of a locality would be infinite.
However, a given locality may be responsible for the provision of more than one local public good, and local public goods will differ according to their capacity limits and the congestion costs thereby created.
It may be impractical to have local authorities of different sizes for each and every local public good that any locality may provide.
11–4 THE TIEBOUT HYPOTHESIS: ‘VOTING WITH YOUR FEET’
Following a discussion of the optimal size of clubs, it is appropriate to consider how individuals take up club membership, i.e. how they choose a local authority in which to reside.
Tiebout (1956) argued that individuals select the local community whose provision of local public goods and tax prices best satisfies their preferences.
Tiebout's analysis was framed as a direct response to Samuelson's (1954) conclusion that individuals would not reveal their preferences for public goods.
Tiebout, however, argued that in a local community context individuals would reveal their preferences, by moving to the locality that best reflected their tastes and offered the preferred tax-benefit mix (if mobility was relatively costless).
As Hughes has observed,
we may assume that households will move so as, in effect, to subscribe to the clubs (local governments) whose policies most closely match their own preferences.
This is equivalent to the competitive processes of matching consumer preferences and cost conditions in a market with many buyers and sellers and it is possible to show that under appropriate conditions similar efficiency properties will characterise the ultimate equilibrium of the distribution of households across local authorities.
(Hughes 1987, p. 5)
Samuelson (1954) noted the problem for the provision of public goods by large groups, i.e. the problem of preference revelation.
The Tiebout hypothesis appears to mitigate this, in so far as individuals reveal their preferences by ‘voting with their feet’.
For example, those who like expenditure on libraries and the arts can reside with others of the same persuasion.
Those with a preference for other forms of fiscal expenditure will join their respective local ‘club’ elsewhere.
If each local community offered a different menu of public goods expenditures, then each  individual could be thought to select the local community that provided a level of output corresponding to his or her preferences.
It should be clear, with respect to the decentralization theorem, that the Tiebout effect increases the welfare gains from decentralization:
household mobility means that differences in local preferences and in the policies of local government may reinforce each other…
. In other words household mobility shifts the trade-off between local autonomy and national standard decisively in favour of local autonomy because it increases the homogeneity of such preferences between local jurisdictions.
(Hughes 1987, p. 5)
In this way the ‘Tiebout hypothesis’ is obviously of considerable theoretical importance.
It stands as a qualification to the problems of public good provision.
But, in practice, how likely is it to act as an equilibrating mechanism?
To answer this question it is possible to refer to at least two areas of discussion.
First, there is the restrictiveness of the assumptions that underly the Tiebout mechanism.
On the basis of analysis by Tresch (1981), Hughes (1987), Musgrave and Musgrave (1989) and Boadway (1979), attention can be drawn to the assumptions required to make mobility efficient.
Second, there is empirical work which looks for evidence that fiscal considerations play any part at all in the decision of individuals to reside in a particular locality.
11-4-1 The Tiebout Mechanism: Underlying Assumptions
The following list of assumptions, which is by no means exhaustive, adds a note of scepticism to the claim that individuals can easily locate in the local communities that reflect their preferences.
Full knowledge of all the communities' characteristics
It is assumed that the individual has complete information of the local taxes and expenditures.
Costless mobility
The mechanism functions only if fiscal considerations play a decisive role in location choice.
Of course, other factors, such as job opportunities, friendship and family ties, typically play their part.
It has been alleged that the assumption that only fiscal considerations are important ‘makes the voting by feet hypothesis somewhat unrealistic, except in a setting where people work in the inner city and may choose among the suburbs for residence’(Musgrave and Musgrave 1989, p. 453).
Costless mobility implies that there are no work problems, i.e. that households can move without having to obtain alternative jobs or without having to worry about transport costs to their place of work.
Housing considerations are also important.
In the UK, for example, there is evidence that the local authority council house system has reduced mobility over long distances for those who seek housing in this sector (Hughes and McCormick 1981).
Externalities
The movement of a household from one locality to another may cause externalities in the form of added congestion.
For a welfare-maximizing equilibrium, the Tiebout mechanism must create a situation whereby it is impossible for any individual to increase utility as a result of changing communities.
However, when there are externalities even costless mobility may not be sufficient to attain this result.
As individuals migrate, externalities are experienced by those already resident in the community.
This literature (see for example, Buchanan and Wagner 1970, Buchanan and Goetz 1972, Flatters, Henderson and Mieszkowski 1974) has been discussed by Boadway (1979).
Assume  that individuals migrate between districts until the benefit they drive from being resident in one locality is equal to the benefit they derive from being in another.
If total benefit (utility) derived from being in locality  is denoted by  and total benefit from being in  is , then equilibrium occurs where 
But will this prove a welfare maximum?
When an individual moves to a region, she may add congestion costs to already crowded facilities.
If  represents marginal congestion costs of adding one more person to region , then a welfare maximum requires that 
Because the individual moving into a local community is not concerned with the congestion costs that this implies for existing residents, her decision to move will be determined by the difference between  and  and there will be no incentive to move at a point when  is equal to .
Equilibrium occurs when equation (11–2) rather than(11–3) is satisfied.
(Note that now the property right is with the entrant, who is able to join any club she wishes.)
One variant of this argument which Boadway (1979) discusses relates to the impact of migration on tax costs.
The share of local taxes (which has already been taken into account in  is relevant for other existing members of the locality.
As noted in our discussion of the optimum size of clubs, the arrival of an additional individual reduces the taxes that existing residents have to pay to finance a given level of expenditure.
As a result, the benefit of one more resident in  (to the new and existing residents) is  where  is the tax paid by the marginal immigrant.
Ignoring problems of congestion, it is argued that a welfare optimum requires 
Free migration will result in an optimum only if  that is, if the total tax bill for a marginal individual is the same in the two regions.
A priori , there is no reason to expect that the tax bill per person will be the same in both regions.
However, Topham (1983) raises a question-mark over this criticism.
If there were a divergence in tax bills, then, other things equal, there would be a preference to reside in the locality where the tax bill is lower.
If one area were to turn out to be a tax haven, property and house prices would rise (capitalizing the favourable tax bill) in this area, so reducing its .
Economies of scale
When there are diverse preferences for public goods, the number of local communities required to produce an equilibrium would be extremely large.
This might imply many small communities, thereby missing out on possible gains that would arise from the existence of economies of scale in the production of local output.
Benefit spillover
In the analysis above, the assumption was that all of the benefits were experienced by those residents in the locality (i.e. in the club).
Benefits provided by one locality may spill over into another jurisdiction.
The two localities may ‘internalize’ this spillover by a process of direct bargaining.
Alternatively, there may be a role for a central government.
(This is discussed later in this chapter.)
Either way, there will be a modification to the analysis outlined above.
Non-static preferences
If preferences for local public services change during the life-cycle, there are added strains for the Tiebout mechanism.
At certain ages individuals have a priority for  educational facilities for children: later they will be more concerned with facilities for pensioners.
The implication is that either households move as circumstances change, or local communities consist of individual households whose needs change simultaneously.
11-4-2 The Tiebout Hypothesis: Empirical Tests
The improbability of all the above assumptions obtaining casts doubt on the Tiebout proposition.
So how can we test whether fiscal conditions play any role in the decision to reside in a local community?
There are at least two approaches.
One looks at the relationship between fiscal conditions and house prices, the other looks at fiscal preferences and residence.
1.
Oates (1969) focused on education expenditures per pupil and used this as a measure of the quality of public services in 53 northern New Jersey municipalities.
If property is fixed, then, as people move into an area that has a superior set of public services, they will drive up property prices in that area.
Oates found that property values were negatively correlated to the tax rate.
He also found that school expenditures per pupil and property values were positively related, i.e. that additional fiscal spending attracted an inflow to the locality.
These results support the hypothesis that individuals are willing to pay more in order to live in communities that provide high-quality services.
However, this test has attracted criticism — see for example Edel and Sclar (1974) and Hamilton (1976).
Studies by Aaronson and Schwartz (1973) and Aaronson (1974) indicate that, in both the USA and UK, the mix of public goods and tax rates has an effect on how population is distributed among governmental units (see chapter 5).
2.
Gramlich and Rubinfeld (1982) examined responses to survey questions.
If the Tiebout mechanism is relevant, then there should be some effect of the costs of moving on the pattern of preferences; that is, when there are many localities it is easy for individuals to move to the one they most prefer, and hence there should be a greater homogeneity of preferences within those localities.
They confirmed there was substantially greater homogeneity of demand within suburbs located near many other communities.
By contrast, where there were few other communities exit was less easy and there was more heterogeneity.
11–5 THE SOURCES OF LOCAL GOVERNMENT REVENUE: LOCAL DOMESTIC RATES versus THE POLL TAX
While the ‘decentralization theorem’, the theory of clubs and the Tiebout hypothesis focus on the gains to be had from leaving decision-making in the hands of the local authority, central government exerts an important influence on local authorities when limiting their choice of local taxation.
In this section attention turns to the question of which source of finance is preferable for a local authority.
With many tax options available for local authorities, it is impossible to consider all possibilities thoroughly within this chapter.
However, as an illustration of the significance of the different approaches to public finance, we consider the recent debate in the UK about whether or not a poll tax (‘community charge’) should replace a system of domestic rates.
The aim is to illustrate the emphasis in the debate on public choice considerations.
In a broader political economy model, this question would be tackled with respect to a large number of criteria.
Sandford (1984) suggests a set of ‘criteria for local taxes’ as follows.
1.
The tax base should be widely and fairly evenly dispersed.
2.
It should be economical to administer.
3.
There should be localized incidence of the tax.
4.
The tax should raise high and reliable yields.
5.
It should have an equitable impact.
6.
The tax should be  perceptible .
7.
It should promote local accountability.
This set of criteria is really very broad but it could be even broader.
Through their impact on property prices, local taxes can have important implications for mobility of labour.
Muellbauer (1987, p. 9), therefore, considers local tax reform ‘from the point of view of the UK economy's supply side, in particular of a less inflationary, better functioning labour market base…‘.
Central government in the UK has of late tended to place greater emphasis on the criteria of local tax perceptibility and accountability.
Indeed, this may be an example of popular expression of those worries that arise from the criticism that is engendered by the public choice approach.
Public choice analysis would suggest that local government expenditure may be in danger of ‘excessive growth’ if tax perceptibility and accountability are not characteristics of the tax system (see chapter 14).
In the UK, the Conservative government has introduced a reform of local taxation which replaced domestic rates with the so-called ‘community charge’ or ‘poll tax’.
Domestic rates are a tax on the rateable value of real estate (land and buildings).
They are payable by the occupiers of the property, and the rateable value is assessed on the annual letting value of the property.
By contrast, the community charge is a poll tax levied on all individuals aged 18 or over.
The switch was planned to occur in Scotland in 1989 and in England and Wales in 1990.
While the debate surrounding this reform has been extensive, there is reason to argue that ‘Most of the debate has been about controlling local authority expenditure, about voters, about redistribution among households and about administrative issues’(Muellbauer 1987, p. 7).
While not exclusive, public choice considerations stand proud in this list.
In this section our intention is to look briefly at the nature of debate surrounding this local tax reform.
We acknowledge that there are well-known problems with the domestic rate system in the UK, but leave it to readers to discern whether the emphasis on constraining local authority growth warrants this change of taxation.
The intention is to indicate the degree of ambiguity and the general lack of information that can characterize debate on tax reform.
This, of course, creates considerable leeway for the input of influence which stems from the basic approach to taxation that individuals take.
While it is difficult to argue convincingly that one system of taxation is superior to another, strong positions are still taken according to ideological commitment.
11-5-1 Criticisms of Domestic Rate System
Among the most quoted (though controversial) criticisms of domestic rates are the following.
Regressive between tax-payers
Reflecting the importance of housing in the household budget, domestic rates fell most heavily on the low-income groups.
Sandford (1984) quotes the Report of the [Allen]Committee of Inquiry into the Impact of Rates on Households.
It shows that in England and Wales the lowest income groups paid 8.1 per cent of household income in rates, whereas the highest income group paid under 2 per cent.
Distortion of business investment
The rate of tax (the ‘poundage’) differs; it is higher where the property values are lower and where the needs for local expenditure are greater.
High rates may be a locational disincentive for both businesses and households.
Arbitrary assessment/administrative costs
Because rateable valuations are expensive to undertake, they are done infrequently and irregularly.
The result is that the valuations can be outdated and appear arbitrary.
Revaluations are costly though other costs of administration are relatively low.
Tax awareness
Muellbauer (1987, p. 11) argues that ‘Dominating the recent debate…is a fourth set of objections against domestic rates.
This is that of ‘no representation without taxation’…
' In the UK rates do not provide a close link between those who vote for expenditure increases and those who pay the costs of local services.
Only about one-third of potential voters pay full domestic rates.
Rates are paid by the head of the household, and some households receive rate rebates.
Rates and the benefits of local services
Rates do not relate to the costs of providing services to different residents.
This is obviously linked to the issue of cost awareness.
Even between those who pay the tax, the link is weak.
For example, a family of four occupying a semi-detached house may consume more local services than the single occupier next door, but would still pay the same rates.
There is no relation between the services consumed and the costs of them to individuals, and the central government appears to wish to introduce a benefit-related tax for local authorities.
11-5-2 Criticisms of the Poll Tax
While the objections to rates are well known, it is difficult to be very confident that a switch to a poll tax will adequately redress these problems.
Regressive tax
The community charge will operate as a poll tax and will be paid irrespective of income.
Obviously the tax will be regressive.
As Kay and King (1986) stress, ‘what matters from the point of view of social and economic policy is not the progressive or regressive impact of every individual element of the tax system but the impact of that system as a whole’(p. 150).
The same qualification applies to domestic rates.
Administrative costs
To avoid the full regressive impact of the poll tax, it is possible to introduce rebates for old-age pensioners, low-income individuals, single-parent families, the disabled, etc.
It should be clear, however, that the more that the tax is tailored to the characteristics of the taxpayers, the greater the administrative costs will be.
It is possible that, while we lose the administrative costs incurred by property valuation, we could easily replace them with the valuations of the poll tax for many different households.
Tax awareness
While the above arguments suggest that the link between payment of the domestic rates and services received will lead to greater expenditure, it should be noted that domestic rates are one of the more obvious and most easily perceived of all taxes.
Kay and King (1986, p. 150) note that ‘Domestic rates occasion much criticism.
Often this criticism is less than coherent, and it sometimes seems that a principal reason for the volume of protest is simply that rates are an unusually transparent tax; there are few other cases where individuals are personally and directly responsible for making payments’.
Tax transparency should be a feature  that serves to resist ‘excessive’ local government growth.
 In the USA this experience has been evident in the sense that, when there are movements to restrain the growth of state spending.
For example, Proposition 13, which sought to curtail local government expenditure, can be related to antipathy towards property taxation.
(For a fuller account, see the review of literature in Cillis and Jones 1987.)
The poll tax and the benefits of local services
The government in the UK has made much of the case that a poll tax relates to the benefit principle of taxation.
On face value, this argument appears justified.
However, when the recipients of local government services are identified, there is reason to question this argument.
A study by Bramley, Le Grand and Low (1989) analyses evidence on usage of services carried out by ‘a major and representative’ local authority.
Only about 10 per cent of expenditure went on services that were clearly pro poor and about 20 per cent were biased toward those services (e.g. education, roads, leisure services) that favoured the better off.
They estimated that, overall, it could be said that the better off use services costing 45–70 per cent more than those used by the least well off.
By comparison with the current rating system, the poll tax incidence deviated even more systematically from service usage.
The poll tax did not prove to be a good benefit-related tax.
The authors of the report conclude: ‘the Government is mistaken in its assertions about the use of local services…the retention of the rating system is a more attractive option if indeed a benefit tax is what is being sought’(p. 28).
A recent comparison of the pros and cons of the poll tax concludes:
The argument between domestic rates and the community charge (CC) is finely balanced…
They share many defects.
Neither is fair, in the sense of being related to income, and thus ability to pay.
They are both regressive taxes, in that they fall in relation to income as income rises, except where the complex rebate system helps lower incomes.
Neither is buoyant as a source of revenue, without unpopular increases in poundage or amounts.
Neither has much relation to local services used by the taxpayer.
Neither achieves greater accountability of local authorities to the voters, in spite of claims made for the CC…
(Johnson 1990)
What then is the purpose of reform?
Commentators instead emphasize that the poll tax is ultimately concerned with reducing local government revenue.
Sandford (1990) presents a humorous discussion how replacing the poll tax by a local sales tax on salt might perform this better.
Local governments with high tax rates would be forced to reduce the rate of tax on salt to that pertaining in lower-rate localities, or else lose revenue by seeing their residents travel to purchase salt elsewhere.
Perhaps the real purpose is then a response to fears of a Leviathan in local government.
The discussion here as to the relative merits of domestic rates and the poll tax has been introductory.
(See Morrissey, Cullis and Jones 1990 for further analysis.)
At this juncture the aim is simply to note that, in this debate, public choice arguments concerning tax awareness and the growth of local government have been important.
Muellbauer (1987) questions the tax awareness argument.
He notes that the ‘argument against rates rests on the shaky premise that, in local elections, individuals vote as individuals and are little influenced by the costs and benefits to the household of a policy change by the local authority’(p. 11).
However, in the absence of clear evidence and when the fiscal debate is difficult to resolve, it is possible that those who begin with a public choice framework may be led to quite different reform proposals from those who approach the issue from a more traditional framework.
As Mitchell (1988, p. 50) notes, ‘At bottom the gap between public choice and conventional political science reflects a conflict of values and beliefs — in other words, ideology.’
This same conflict also plays its part in the distinction between public choice analysis and traditional public finance.
Before drawing this discussion to a close, it is worth noting briefly that there are, of course, other tax alternatives for a local authority.
(For further discussion see Foster et al.1980.)
They might, for example, raise revenue by a local sales tax or a local income tax.
In the UK local income taxes were recommended by the Layfield Committee (1976), to operate alongside domestic rates.
Local income taxes might be thought capable of performing better against the criterion of equity, but it was argued that they would be difficult to administer in the UK, for the reasons outlined by Kay and King (1986).
However, the public choice approach, in terms of explaining policy developments, may have a more clear-cut analytical impact again when it comes to analysing the acceptability of this tax.
As George Jones, a member of the Layfield Committee, noted,
A study of the Layfield Committee…provides an intriguing irony.
Although set up in 1974 in response to outcries about huge increases in domestic rates, it never came near to recommending their abolition or even their substantial replacement with another tax.
Indeed, it proposed that they be retained and further, than in addition to this unpopular tax there should be a new unpopular tax local income tax — a prospect of little attraction to most politicians.
(Quoted in Sandford 1984, p. 262)
The likely unpopularity of the local income tax may explain resistance to this tax.
In the case of the poll tax, unpopularity has led to its withdrawal having induced a change in premiership.
11–6 INTERGOVERNMENTAL GRANTS
The traditional public finance approach to intergovernmental grants (or grants-in-aid) which flow from central (or federal) government to local (or state) authorities has been concerned with the question of what form the grant should take.
Central government can use grants to change both the distribution of income and the pattern of spending between local authorities.
In order to know how to structure the grant, it is necessary to predict the response of the local authority to different kinds of grant.
In this way, the impact of alternative forms of grant on local fiscal decisions becomes an important consideration when choosing the ‘appropriate’ form of grant to use.
The results of some empirical studies suggest that the theoretical predictions that emerge from traditional public finance are, in this respect, at odds with experience.
The public choice school again has the opportunity to explain this inconsistency.
A public choice appraisal indicates that the whole question of central-local budgetary arrangements can assume considerable importance in explaining the growth of the public sector in general.
11-6-1 The Effect on Local Authority Spending
Intergovernmental grants are used for a number of efficiency and/or equity purposes.
Topham (1983) notes that in the USA state grants finance about a third of local public expenditure, while in the UK grants-in-aid account for about half the revenue of local authorities.
In this section some basic microeconomic theory is applied in order to analyse the likely response of local authorities to the receipt of different types of grants.
Intergovernmental grants may be conditional or unconditional.
Conditional grants are dependent (in some way) on the behaviour of the recipient local authority; for example, central government may require that the grant be spent on some particular expenditure programme (health, education, transport).
Conditional grants can come in the form of matching or non-matching grants.
In the case of matching grants the central government agrees to match a  certain proportion of the expenditures of the local authority; for example, central government may pay x per cent of the total cost of providing a service at the local level.
Moreover, grants may be open or closed: there may or may not be an upper limit beyond which the central government will not go.
In traditional public finance, the form in which the grant is made will influence the expenditure of local authorities.
In keeping with this, the analysis utilizes the assumption that a local authority maximizes a utility function, in exactly the same way as would an individual in neoclassical microeconomic theory.
The relevant indifference curve may be considered to be that of a ‘representative voter’.
As Rubinfeld (1987) notes, this is all right if everyone in the community is identical, but it causes an obvious problem if there is heterogeneity.
(Alternatively, therefore, the indifference curve has sometimes been taken to reflect the preferences of the median voter inasmuch as there are circumstances in which, when the majority voting rule applies, the decision from the local community will be that of the median voter.)
In the following analysis an initial budget line (12 in Fig. 11–3) represents a constraint prior to any grant assistance from a federal government.
It limits the consumption possibilities between one good X (provided by the local authority) and all other goods Y. The local authority (‘representative' individual) seeks to maximize utility.
The impact of the grant is then captured by changes in the position and/or slope of the budget line.
Wilde (1968) exemplifies the approach on which the following analysis is based.
Unconditional, non-matching closed grants
In Fig. 11–3 the line 12 illustrates the trade-off faced by a ‘representative’ individual prior to grant assistance.
With no grant aid, the local authority prefers (at point E o ) to pay taxes of 15 and provide OX° of the publicly provided good.
If the   authority receives a fixed sum 31, then it is able to purchase more of the publicly provided good.
The budget line moves out to the right and the individual elects to purchase more of X if the publicly provided good is a normal good.
ICC is the income consumption curve, and it is clear that the total provision of the good will increase as the local authority receives the grant.
(The new equilibrium point is E 1 .)
In the locality, the welfare of individuals is increased (a shift from 10 to 11).
More of the local publicly provided good is consumed, but not all of the grant is used to increase consumption of this good (i.e. consumption of Y also increases — distance 57).
Conditional, non-matching closed grant
In Fig. 11–4 it is possible to consider the impact of a conditional, non-matching grant.
In this case the total of the amount received by the local authority must be spent on the provision of good X. In the case shown, the budget line now looks like 154 and the conditional constraint forces the local authority to a corner solution 5.
The local authority would have moved from E o to E 1 had the grant not had any conditions binding.
It is evident that, by comparison with an unconditional grant, it is on a lower level of welfare (shown by indifference curve I 1 ) as a result of spending more than it would otherwise choose to spend on good X.  
Matching open-ended grant
In this example, for every pound spent by the central government, a specified sum must be spent by the recipient authority.
This means that the grant operates like a price subsidy for good X and the budget line for the local authority changes slope from 12 to 13 in Fig. 11–5.
As a consequence, the local authority shifts from the initial equilibrium E o to E 1 .
There is a movement along the price consumption curve (PCC) to a point where OX 1 of the good is demanded.
The matching open-ended grant (price subsidy) will always lead the authority to consume more of the good than an unconditional non-matching grant (lump-sum subsidy).
In Fig. 11–5 a comparison is made of the two grants.
To enable the authority to consume (if it should choose) OX 1 (the equilibrium with the matching open-ended grant), the central government must offer an unconditional non-matching grant of 14.
In this case the new equilibrium point would be E 2 .
With an unconditional non-matching grant the impact is simply that of an ‘income effect’(a shift along the income consumption curve ICC).
In the case of the matching open-ended grant the effect is that of a price reduction, which incorporates both a substitution effect and an income effect; hence the shift along the price consumption path PCC.
It may be noted that in this diagram, to be sure that there is an increase of the consumption of the good X by a similar amount (i.e. to OX 1 ), the grant must be much greater (i.e. equal to 16).
Matching closed-ended grant
With a closed-ended matching grant the budget line will be kinked.
In Fig. 11–6, assume initially that the conditions of the matching grant are such as to reduce the price of good X; i.e. the grantor will match at a rate of 23 to O2.
The budget line changes from 12 to 13.
However, now assume that there is an upper limit on this grant of 25 (in units of X).
In this case the relevant budget line becomes 165, as the most that will be forthcoming from the central government is 25 (in units of X).
The grant will now have the same effect as a non-distorting conditional non-matching grant of amount 25 (in units of X) and the individual will choose to move from E o to E 1 along the income consumption curve ICC.
By comparison, if the upper limit for spending were 28 (in units of X), then the matching rate is relevant.
The budget line is now 178, and the individual will choose to move along the price consumption curve to point E 2 .
Clearly, everything depends on the way in which the grant is closed.
(For other examples, see King 1984.)
The above examples of intergovernmental grants are by no means exhaustive, but enough has been said to indicate that, when the form of grant aid is specified, the nature of the amendment of the budget line for local authorities is specified.
One point that is obvious is that a matching grant is generally more successful than a non-matching grant in stimulating local expenditure on a particular good or service.
With this analysis in mind, it is now useful to consider alternative forms of grants in the context of the objectives that underlie the use of intergovernmental grants.
It is already clear that, for example, if the objective of the central government is to encourage local authority spending in some service, a matching grant will be preferred to a lump-sum grant, even though the lump-sum may increase the welfare of the local authority residents by more than a matching grant.
This is just one example of the interrelationship between the form of grant and the objective of the central authority.
11-6-2 The Case for Intergovernmental Grants
In this section the objective is to consider the rationale for intergovernmental grants and the particular form they should take.
Interjurisdictional spillovers
It has already been noted that there may be external benefits for neighbouring localities as a result of any one jurisdiction's expenditures.
The fact that the spillovers are external benefits implies that the local authority responsible for such activity takes no account of it in its decision-making.
If region R undertakes programmes that create spillovers for region S, then, following Boadway and Wildasin (1984), the optimal decision is to set the provision of that good at the quantity where  where 
However, if the local authority does not include the spillover benefits in its decision-making calculations, it will provide only to the point where 
In such circumstances a subsidy granted at the per-unit rate of  would lead the authority to the optimal point.
The marginal cost of expansion to R would then be set equal to  and the authority would increase its provision of this good.
Matching grants are better in this context because, in altering the price, they stimulate a greater provision of the good at a lower cost to the grant donor.
The fact that the donor is better off, because the recipient demands more of the good, makes a grant that changes prices better than one that simply changes income for the donee.
Promoting a merit good
Central government may, on merit good grounds, think it appropriate that a local authority provide more of a particular service.
From the analysis above, it would be reasonable to recommend the use of open matching specific grants for each individual service that it wanted expanded.
However, it might use closed lump-sum grants if there were simply some relatively high level of consumption which it felt was ‘desirable and adequate’.
General grants would be appropriate only if the grantor felt that all local services were merit goods.
Revenue sharing
Local authorities in aggregate may suffer a fiscal imbalance inasmuch as they are unable to finance all those expenditure programmes that are considered desirable.
Central government may encourage local governments to raise more tax revenue by introducing new taxes, levying charges or borrowing.
However, one alternative way in which central government may play a role is to collect the tax revenue on behalf of local governments and then simply to turn the revenue over to them.
If the central government plays a role purely in terms of revenue raising, then an unconditional grant would seem the most appropriate instrument from the point of view of benefiting the recipient local authority.
Equalization
While there may be no fiscal imbalance in aggregate, some authorities may be unable to finance programmes that other authorities find easy to handle.
In this case the objective is to close the fiscal gap between revenue sources and expenditure responsibilities between different authorities.
The reason could be based on considerations of either equity or efficiency.
Horizontal equity
When there is no mobility of labour across jurisdictions, it is possible that two identical individuals residing in two different jurisdictions may obtain different net fiscal benefits.
Buchanan refers to fiscal equity being attained when there is horizontal equity across different states:
Individuals of a given level residing in a high income state will obtain a larger net benefit from the state fiscal activities than will a similar person residing in a different state.
This source of horizontal inequity can be removed by a set of interstate transfers that equalize the fiscal residua across states.
(Buchanan 1950, p. 588)
Whether central government chooses to remove this is, however, dependent on value judgements and a decision to attain horizontal equity (Grewal, Buchanan and Matthews 1980).
Efficiency
With labour mobility, inefficiency can arise from fiscal spending in different localities.
To attain efficiency, it would be expected that factors of production would be allocated so that their marginal products would be equal.
Here, following Boadway and Wildasin (1984), it is possible to illustrate how different fiscal residua create inefficiency when labour is mobile.
Assume that R is a high-income locality and S is a low-income locality.
In Fig. 11–7 the wage rates for labour in the two localities are shown on the vertical axis.
The marginal value product of labour in the two locations is illustrated by M r and M s , respectively.
The total supply of labour is shown by the distance on the horizontal axis; if initially there is an efficient allocation of resources, then O r L o labour is in locality R and O s L o is in locality S. At this point the marginal products of labour are identical at point 1 in the two localities (assuming that wages are set equal to marginal value product).
Now suppose that in locality R revenue can be raised from resource taxes t r (e.g. taxes on land) and that this is available to be shared by the resident population l r In S (now the ‘poor’ state) there is no such revenue.
In the figure  is the wage rate (the ‘social’ wage, i.e.   inclusive of the marginal value product and the fiscal residuum) and there is migration from R to S to the extent of L o L 1 , leading to an output loss measured by triangle 123.
Unless there is any redress to this distortion, the marginal products of labour will not be equal.
While the higher wage rate compensates the marginal worker for the lack of amenities in S, there is an equilibrium where the marginal products of labour are no longer equal.
In this way output is lower than it would otherwise be and there is an ‘efficiency’ cost in terms of this output loss.
Sufficient has been said to suggest that there may be good reason to utilize intergovernmental grants and that, in order to choose the appropriate grant, it is necessary to consider both the objective and the likely response of the local authority to the grant.
However, while the theoretical analyses yield precise predictions, these have not always been found in empirical analysis.
While there is some evidence that matching grants are more stimulative than unconditional grants, the prediction that unconditional grants have the same effects as a lump-sum increase in income is not confirmed.
Once again, the door is open for public choice explanations as to the impact of grants on decision-makers in local authorities.
11–7 PUBLIC CHOICE AND INTERGOVERNMENTAL GRANTS: THE ‘FLYPAPER EFFECT'
In the analysis outlined above, it should not matter whether a central government cuts taxes or gives lump-sum grants to local authorities.
In either case, public spending should increase by the income elasticity of demand.
With reference to the previous discussion of an unconditional, non-matching grant, it was illustrated that the effect on local spending is just the same as that which arises as a result of an increase in income.
If central government cuts taxes, so that the income of a representative individual increased by the same amount, the increase in local spending should be identical.
(Again, the effect would be illustrated by a parallel shift of the budget line and by the movement along the income consumption curve.)
A review of empirical work by Gramlich (1977) indicates that this is not the case in the USA.
Lump-sum grants from a central government stimulate greater local authority spending than would occur as a result of an equivalent cut in taxes by a central government.
Whereas a $100 increase in the net income of individuals leads to an increase in a recipient authority's spending by $5-$10, a lump-sum grant raises spending by $40-$100.
Gramlich and Galper (1973) estimated that in the USA an additional $1 of unconditional aid to state and local governments induced, on average, a $0·43 increase in spending.
This phenomenon has been referred to as the ‘flypaper effect’, so named because money will stick in the sector that it hits — grants to the local public economy will be spent in the local public economy.
In order to explain the ‘flypaper effect’, it is again possible to examine public choice theory.
The traditional model assumes harmony between the interests of voters and their representatives in the political process.
The public choice approach, however, disputes this assumption.
In particular, the role of bureaucrats and the impact of fiscal illusion has been considered.
However, such arguments are not the only ones made to explain the ‘flypaper effect’.
Following King (1984) we contrast some alternatives.
11-7-1 The Role of Bureaucracy
The Niskanen model
King (1984) applies Niskanen's (1968) model to yield one explanation of the ‘flypaper effect’.
In Fig. 11–8 the bureau is assumed to be maximizing the size of its budget and   producing an output of Oq b .
This is the output that satisfies the constraint that total cost does not exceed the total benefit derived by consumer-voters.
In other words, the area under the marginal cost curve MC up to Oq b is just equal to the area under the demand curve, and therefore P o 12 equals triangle 234.
(For an elaboration of Niskanen's analysis see chapter 14.)
Here the bureau under consideration is the agency working for the local authority.
It is relatively straightforward to consider the impact of any form of central government grant.
Assume, for example, that the local authority receives a lump-sum specific grant.
This reduces the initial cost of the service from central government.
In Fig. 11–8 the result is that the marginal cost curve is shifted to the right (i.e. MC shifts to MC').
If the bureau observes the requirement that the total budget be equal to the total benefit derived from the good, the new equilibrium output is Oq b ' (where area P 1 15 = area 567).
There is an increase in output.
The budget for the bureau rises by more than the grant.
Additional output is  and, as total benefit increases by , this permits an increase of the budget (from local sources) by the same amount.
If this theory is to explain the ‘flypaper effect’, it must be demonstrated that a rise in citizen's incomes would raise the bureau's budget by less.
How will an increase in income affect Fig. 11–8?
A rise in incomes will change the demand that citizens register for the good.
The D curve will move to the right, as long as the good is a normal good.
This means that the budget of the bureau will rise.
However, it is extremely unlikely that the increase in the budget will equal the value of the grant: for it to do so would suggest that the recipient would spend everything on this good.
It is very unlikely that this change in income could lead to a greater budget than that which emerges when there is a lump-sum grant from the central government.
The Romer-Rosenthal model
Romer and Rosenthal (1980) have presented an alternative model of the operation of bureaux.
This is referred to as the ‘setter model’.
In this model bureaucrats   in local authorities propose a level of agency funding which is put before the electorate in a referendum.
If a majority of voters accept the proposal, it is enacted; if not, the local expenditure is set at a legally specified reversion level.
Examples of such reversion levels are evident in some states of the USA (e.g. Colorado, Oregon, Michigan).
Romer and Rosenthal assume that the reversion level is exogenous.
Should the budget proposed by the local bureau be rejected, expenditure will revert to a specified level which is known to the voter.
One objective of the analysis is to show that this institutional arrangement will cause local authority spending to differ from the usual predictions of the traditional model.
In Fig. 11–9 are illustrated the preferences of the median voter over a private good and the local public good.
Each voter pays a tax price for the good and this is implicit in the slope of the budget line 12.
It is clear that the most preferred position for the median voter is X*.
If the reversion level were set at , it should be evident that the median voter would vote for any level of the output between  and an output just below  (e.g. ) in preference to .
Any such level of output will put the median voter on a higher indifference curve than would the reversion level .
Given this choice two situations are possible:
1.
If the reversion level is , the median voter may vote for an output of almost .
This is a higher output than would be preferred if the only constraint were that shown by the budget line 12 (i.e. output X*).
2.
If  is greater than X*, the bureau will propose a level of spending that is the reversion level.
This, again, would mean that output is greater than preferred by the median voter when this institutional constraint does not apply.
Assume case 2, i.e. that the level of expenditure most preferred by the median voter (X*) is less than the reversion level.
In Fig. 11–9 assume that the reversion level is .
If the incomes of voters increase, this will shift the budget line in the figure to 34.
The most preferred expenditure level of the median voter increases to  (assuming the local publicly provided goods are normal).
The equilibrium allocation for the median voter shifts from point E° on indifference curve I 1 to E 1 on I 2 .
However, if the institutional arrangement described by  Romer and Rosenthal applies, the individual does not freely choose to move from E° to E 1 .
If the median voter's most preferred point  remains less than the reversion level, the level of spending remains unchanged at the reversion level .
The bureau still enacts the legally specified reversion level, which is still greater than the median voter's most preferred choice.
In this case, there is no increase in spending as a result of an increase in the level of income of the median voter.
In contrast to this, if the local authority receives a lump-sum grant, equivalent in size to the increase in income, this will have an effect on the local authority's spending on X. The bureau takes full account of the grant to increase the reversion level of output by exactly the size of the grant, e.g. to  in Fig. 11–9.
Just as the setter is legally obligated to spend fully at the reversion level (should his proposal fail), so he is obliged to spend the whole of the grant in addition to the reversion level of spending (an assumption consistent with the institutional arrangements of some states in the USA).
Thus, if the median voter's preferred point X *1 is less than the reversion level, a lump-sum grant will put the new equilibrium level of public spending at a new higher reversion level.
(The increase is equal to the full amount of the grant.)
This particular case vividly illustrates the possibility of a ‘flypaper’ effect.
With an increase in income there is no increase in local provision of the good, but when the increase comes via a lump-sum grant there is a full increase in spending.
Of course, this particular case depends on the assumption that the reversion level exceeds (and continues to exceed) the most preferred level.
Romer and Rosenthal (1980) consider alternative relationships between these levels of spending.
For our purposes, however, enough has been said to describe how the institutional setting can cause expenditure patterns of local authorities to deviate in the direction indicated by empirical work of Gramlich.
11-7-2 Fiscal Illusion
Oates's model
Another means of explaining the ‘flypaper’ effect depends on the assumption of fiscal illusion.
Voters are given only part of the story when making their decisions.
They make their decisions on the basis of two pieces of information: the level of output Q and the associated tax liability T. This means that they may have an idea of the average tax price Q/T of such services.
In Fig. 11–10 the D curve is the demand curve of the median voter for the locally provided good.
The tax price to the median voter is P m .
Without any grant from central government, the preferred position is output  (i.e. where marginal benefit for the median voter is equal to marginal cost to the median voter of providing the good).
On receipt of the lump-sum grant, the authority could pass it on, as an income increase, to voters.
In this case the D curve moves to the right, to D 1 , and the quantity demanded is Oq 1 .
The effect is similar to a change in income and depends upon the income elasticity of demand.
By contrast, the authority, on receipt of the lump-sum grant, could simply offer to produce the good at a lower ‘subsidized’ price P s .
For example, in Fig. 11–10, the new tax price for the good may be thought to look like the curve B (instead of MC).
Now the impact on spending depends on the price elasticity of demand.
Demand becomes Oq 2 .
Whether or not a ‘flypaper’ effect is prevalent depends on the relative size of the price and the income elasticities of demand.
Oates (1979b) considers the relative size of these elasticities as indicated by empirical work (see Bergstrom and Goodman 1973).
He calculates that the marginal increase in public expenditure for a rise in incomes is 0·1, while the marginal increase in public expenditure for an increase in intergovernmental grants is 0·4.
This is quite close to the empirical results that suggest a ‘flypaper’ effect.
11-7-3 Adaptation of the ‘Traditional’ Model
King's model
King (1984) continues with the assumption that decisions reflect the demand of the median voter and makes no allowance for governmental failure.
However, he assumes that, when the median voter votes, she will not accept proposals that imply that the local tax rate leaves the poorest citizens in the locality with a net private income below some specified level.
In Fig. 11–11 the median voter is constrained to vote for an output combination along 18 of the budget line 12 because otherwise the local authority would set tax rates that left the poorest citizens with a minimum income level lower than that regarded as acceptable; i.e. they would set a tax greater than 19.
The initial equilibrium chosen along this range is E o .
In the diagram 12 is the budget line prior to receipt of a grant.
A lump-sum specific grant would change the budget line to 145.
If the voter were unconstrained by concern for the poorest individual she would move   to E 1 .
(She may feel no such constraint because spending all the grant does not increase taxes in the locality.)
A cut in taxes that raised residents' incomes by the same amount as the lump-sum grant would be expected to produce the same amount as the lump-sum grant.
If there were such an identical cut in taxes, the relevant budget line for the median voter would be 65.
Unperturbed about the taxes of others, the individual would prefer to be at E 1 .
However, if the additional constraint is binding, the median voter would no longer be able to choose E 1 .
For example, assume that, as a part of the cut in tax introduced by central government, the poorest citizens in this locality enjoyed no benefit (possibly because their incomes were previously too low for them to be required to pay the central government tax).
The median voter, concerned about the welfare of the poorest in her locality, would not want local authority spending to increase if this increased the tax on the poorest members of the locality.
Therefore, in Fig. 11–11 the total tax raised from each individual could not exceed 6–10 (equal to 19): the median voter is constrained, by concern for the poor, to keep taxes payment at 6–10.
On the new budget line, 65, the best position to be chosen now is point 7 (vertically above 8).
In these circumstances the same output of OX 1 is provided after the central government has provided a cut in taxes which affects the median voter.
The result is that there is no increase in provision of the good when there is a cut in taxes, even though when the lump-sum grant applies there was an increase in provision.
Once again, the ‘flypaper’ effect is evident.
This is an extreme example.
If we assume, instead, that the poorest in the locality benefits (though not fully) from the cuts in central tax, a higher output will be chosen as a result of the  cut in taxes, though this will be less than output OX 2 , the output that would be chosen if an equivalent lump-sum grant had been received.
Of course, the analysis is sensitive to the impact of the central government tax cuts: if these were actually targeted on the poor, they might reduce the initial constraint on local taxation to which the median voter adheres.
Has public choice theory satisfactorily explained the flypaper effect?
The above example may appear something of a curioso, but it illustrates another example of the distinction between what we have referred to as the ‘traditional’ approach and the public choice approach to public finance.
With so many explanations, readers may be forgiven for thinking that, in theory, ‘anything goes’.
We would simply note that, for those instances where empirical evidence clashes with traditional public finance, there may be explanations other than governmental failure.
The ‘social optimality’ approach can be refined to deal with the problem without necessarily resorting to the conclusion that ‘self-interest’on the part of politicians and bureaucrats is proven.
Of course, in this particular case it is questionable whether voters in local authorities are as concerned with the plight of the poor as is suggested in King's approach.
Even so, King argues that his theory has the advantage of also explaining why a lump-sum grant has less of an impact on local spending than does an equal value-matching grant — another result evident in empirical work.
11–8 DECENTRALIZATION AND THE GROWTH OF THE PUBLIC SECTOR
One of the arguments that comprise the ‘Leviathan’ school of the ‘over-expanded’public sector relates to the extent of decentralization.
Brennan and Buchanan (1980) argue that, where there are competing political jurisdictions, ‘exit’ possibilities will act as an effective constraining mechanism; i.e. public expenditures should vary with the extent of fiscal decentralization.
Oates (1985), among others, offers some counter-arguments and finds the empirical evidence lacking both at the international level and in the state-local sectors in the USA.
This material will be discussed alongside other related material in chapter 17.
Although the ‘Leviathan’ school see centralized government as constrained, another line of argument would draw attention to the potential expansionary impact of central government.
Weingast, Shepsle and Johnsen (1981) explore the implications of projects, programmes and grants that concentrate their benefits on specific geographical constituencies but are financed through general taxation.
This is what is understood in their paper by a ‘distributive policy’ It is an ‘over-expansion’scenario with political costs and benefits dominating economic ones.
The total economic costs (TC e ) of a project are divided into
C 1 = real resource expenditures on the project in the constituency in which the project is located
C 2 = real resource expenditures outside the project constituency
C 3 = non-expenditure real resource costs located in the project constituency, e.g. non-pecuniary externalities such as environmental pollution
The total benefit of the project in a given locality, TB e , is the sum of the present value of the economic benefits of the project.
This is enough information to identify the efficient benchmark project size as OE in Fig. 11–12, where the difference between TB e and TC e is maximized.
The expenditure costs T of the project  are assumed to be allocated over n districts so that and the tax bill for the ith district is  where .
With these data, the analysis of the selection of a project size can proceed.
The authors isolate three processes or mechanisms.
1.
The politicization of expenditures involves the recognition that C 1 expenditures result in local pecuniary gains for factor owners as increased demand raises factor prices so that large C 1 -type costs of the project are transferred to the benefit side of the equation.
In order to analyse and isolate the impact of local districts in the analysis, the authors initially assume one district, j, so that all real resource expenditures  take place in j and t j = 1.
The object then becomes to maximize the difference between  and  (which is the maximum difference between TB e and C 3 that occurs at project size OP in Fig. 11–12).
2.
The districting mechanism allows the expenditure costs of the project to be diffused, so that .
The relevant difference to maximize for those legislators who see maximizing their district's private benefits as a way to seek re-election is between  and , which occurs at project size ON in the diagram.
The requirement for ON to exceed OP is that the rate of growth of C 1 (local real resource expenditures) with respect to‘size’ exceeds the rate of growth of the local tax bill as size increases.
This is not a very demanding condition.
If, for example, there are 20 districts, it means that C 1 can grow at just a shade over one-twentieth the rate of growth of total expenditures and the condition for ON to exceed OP will be met.
3.
The taxation mechanism has already been introduced.
However, it is worth noting that, as long as taxes in each locality are a declining function of the number of districts, as for example with equal shares, the optimum size of project for each locality increases with the number of  districts, other things equal.
That is, t j T will tend to fall in Fig. 11–12 and point N will tend to migrate to the right.
In some ways this is the ‘tyranny of the majority’ argument (met in chapter 4) described in a different way.
However, the authors have a more concrete institutional context for their analysis, noting that the US Congress is characterized by universalism and reciprocity when this type of distributive project arises.
Universalism tends to guarantee all districts a project and reciprocity allows the recognition that different districts will have different project priorities.
In such a setting, the ‘log-rolling’ process is easily established.
This type of argument presents a link between local government districts (or areas), central government representation and central government expenditure.
It apparently adds a ‘twist’ to the public choice argument that local Leviathans are in chains with many competing districts.
It suggests that the cost is an over-expanded higher level of representative government.
Decreasing local government spending autonomy, in circumstances where there is a close connection in j between tax costs and benefits, will tend to replace OP-sized local projects with ON-sized centrally provided and generally financed ones.
11–9 SUMMARY
As noted in the introduction to this chapter, the theory of fiscal federalism, which tries to explain the rationale for, and the optimum size of, local government, can appear rather removed from the historical and political accidents that have helped to shape the pattern and prerogatives of state and local government.
Yet for the purposes of future reform, it is important that policy be anchored to some identifiable and acceptable theoretical basis.
That the theory of local public goods, together with the analysis of clubs and the Tiebout mechanism, are less than perfect explanations of local government responsibility does not mean that these concepts should have no part to play in shaping future policy.
Of course, in and of themselves, they are unlikely to do justice to all the complexities that influence policy change.
Yet there are ways in which other more practical considerations can be brought into consideration.
Helm and Smith (1987), for example, introduce an administrative rationale for local government.
They argue that ‘…the local/central government relationship with respect to administration is…an example of the general principal/agent problem — how to provide necessarily decentralised (to maximize information) agents with incentives to pursue the central government principal's objectives’(p. ix).
In keeping with the literature on fiscal federalism, local preferences are more readily apparent to local government; however, more than this, local government provides a more suitable hierarchical pattern for administration.
Instead of central boards to oversee services, such as education, fire protection, etc., it may be better to have a decentralized pattern.
One of the administrative advantages is that central government can ameliorate the monopoly of information which may be possessed by such agents.
By creating ‘yardsticks’, central government may find the task of monitoring quality of service more manageable (e.g., ‘if more dustbins are emptied per kilometre for a lower cost in Scotland than Gateshead, central government has useful information for appraisal’: Helm and Smith 1987, p. x).
Local government, then, is better informed and easier to monitor than are national bureaucracies established to provide particular services.
That they are able to raise revenue is a ‘safety valve’ to correct decisions by a less perfectly informed central government.
Administrative considerations, which look for the best assignment of tasks within a hierarchical structure, can in this way augment other considerations outlined above.
The result is that tasks such as redistribution, which in the fiscal federalism literature are seen as a prerogative of central  government, may (given the imperfections of the Tiebout mechanism and the informational requirements of administration) be shown to be better pursued at a lower level of government when broader considerations are taken into account.
While such considerations as those outlined by Helm and Smith may amend the prescriptions of basic fiscal federalism theory, it is a matter of concern when some of the staple prescriptions are flaunted.
In the UK, since 1979, central government has tightened control over local authority spending.
There have been changes in the block grant from central government; rate-capping; the abolition of the Greater London Council; the forced introduction of greater tendering; and changes in local authority finance.
Moreover, in the 1986 Green Paper it is stated that ‘The main task of central government is to establish national policies and priorities for defence, foreign affairs and the economy as well as for public services — such as education — which are provided locally, but where there is a national interest in standards.’
To set national standards and seek to restrain local expenditure are not policy prescriptions that easily emerge from fiscal federalism.
While such theory may indicate that local voters should be made aware of costs, the case for differences in spending patterns and in standards of services is rooted in the reduction in welfare losses indicated by the decentralization theorem.
Also, in the context of Helm and Smith's (1987) case for local government, ‘The notion that central government can make judgements about local ‘overspending’ sits very uneasily with the rationale for decentralising redistributive functions to local governments in the first place' (p. xix).
CHAPTER TWELVE
CENTRAL GOVERNMENT
12–1 INTRODUCTION
The source of finance used to cover the expenditure activities was traditionally the very heart of public finance.
The expenditure side has now become much more fully developed but the analysis of the sources of finance, especially taxation, remains very important.
Despite the urging of Wicksell and the modern public choice theorists, in practice the two sectors of the budget are essentially treated separately so that very few expenditure proposals come forward with a specific financial source specified.
In the UK, the institutional mechanics are broadly that a government's intended expenditure plans for the coming four years are drawn up in the autumn of each year, with the upcoming year being the dominant period for consideration.
The process, especially under the expenditure-cutting plans of the Conservative government, is a hard bargaining one between the heads of the various government departments and the Treasury.
Once the spending plans are established, the necessary finance is sought, essentially through taxation.
12–2 THE BASIC CONCEPTS
Given the element of independence in the taxation and expenditure sides of the budget, a focus on revenue raising as such is a sensible pursuit, and this motivated the majority of earlier work in public finance.
There are two basic principles to inform the way such taxes should be levied.
These are the benefit principle and the ‘ability to pay’ principle, which have been discussed elsewhere (see chapters 1 and 3).
Although some elements of taxation are based on benefit considerations, the bulk of taxation is designed to conform to ‘ability to pay’, the interpretation of which is no easy matter.
The fundamental choice of tax base is between two flow measures: income and consumption (expenditure), and a single stock measure, wealth.
Income is usually defined in terms of the amount of money an individual can spend over a period while leaving his or her net wealth position unaltered.
This is the so-called accretion concept of income.
If an individual earns   £20 000 per year and makes a £5 000 capital gain over the same period, then her income is £25 000.
However, this makes it all too simple.
Table 12–1 documents a fuller way to appreciate the notion of income.
It is clearly the elements in panel (a) that are most easily documented and are typically subject to the tax system.
If sources of income are not all taxed at equal rates, there is obviously an incentive to convert income into the untaxed form.
So, for example, high marginal tax rates encourage fringe benefits in ‘remuneration packages’ and the growth of the ‘cash’economy.
Panel (d) would be part of ‘imputed’ income in a full study of someone's economic position.
In developing countries with widespread subsistence farming, it does, by definition, come closer to total income.
However, with economic specialization and trade, both intra- and internationally, the existence of market prices and recorded transactions makes the process of taxation much easier.
(See the discussion of ‘tax handles’ in chapter 14.)
The equivalent of income-based taxes on the expenditure side is the personal expenditure tax, which places a tax on the difference between income receipts during the financial year and savings in the year, i.e. a tax on that part of the income that is consumed.
Kay and King (1983) have been consistent supporters of this approach to taxation.
The idea is that tax, payable annually in arrears, would be based on taxable expenditure, which is the difference between net receipts during the year and net savings over the same period.
It is often viewed as attractive because the base is that which individuals consume (or their revenue from the economic system) rather than a reflection of what they contribute, i.e. income.
It relates to actual consumption rather than possible consumption, and for many the equity of this method of taxation may well be greater than that achieved through income tax.
Personal expenditure tax was tried in Sri Lanka but was abandoned mainly because of administrative difficulties.
It requires that each taxpayer's spendable receipts (i.e. income) be calculated from which savings and investment are deducted, so that consumption is measured as a residual.
Hence an expenditure tax is a tax on the difference between net income (gross income minus the costs of securing that income) and the change in net worth (net change in the value of liabilities minus the net change in the value of assets).
Whether, in operation, such a tax would have lower administrative costs than a personal income tax depends on the details of the tax.
Such a tax is often claimed to encourage saving but the argument can cut both ways.
The taxing of consumption does make current saving more attractive.
However, if the scheme is viewed as one that does not tax interest on savings, then more consumption in the future can be financed from a given volume of savings and those seeking a target future consumption can meet it with a lower level of current savings.
Given the limited experience with actual personal expenditure taxation, empirical evidence is lacking.
A general point to be kept in mind throughout this chapter is that any tax reform involves the costs of transition from one scheme to another.
Changes falsify individual expectations and  inevitably create windfall gains and losses and other undesigned consequences which are likely to affect equity adversely.
The design and administration of transitional rules in themselves suggest high short-run costs that may well outweigh discounted long-run benefits.
In principle, there is no significant difference between income (a flow) and wealth (a stock) since the value of an individual's wealth is simply the discounted present value of the individual's net income stream, i.e. the stock value of the flow.
If income is part of ‘ability to pay’, then it would seem clear that wealth is also.
The difference between these tax bases arises at the practical level in that some things are more easily measured as a stock than as a flow, for example the value of a painting.
As a consequence, individuals (and many measures) tend not to think of wealth and income as two sides of the same coin, but rather as different segments of that coin.
As with all taxation bases, there are the usual coarse and fine questions of definition.
Americans especially distinguish between ‘realty’(land, housing, property type wealth) and ‘personalty’, the latter being subdivided further into tangibles (physical-type personal wealth, e.g. cars) and intangibles (financial-asset-type wealth, e.g. share certificates).
In practice, it is those elements of economic worth that are most easily measured (because of their marketable nature as an asset value, which is easily detectable) that attract taxation.
These types of tax take the form of annual wealth taxes, gift taxes and inheritance taxes.
Taxation of sales is also common, in the form of specific (so much per physical unit of measurement) or ad valorem(percentage of money valuation) taxes on goods and services.
Taxation of income, personal expenditure and wealth are usually viewed as direct taxation, whereas taxes on the sale of goods and services are seen as indirect taxation.
(For some fairly recent comparative material, see Pechman 1987.)
But what does this distinction mean?
Atkinson (1977) provides an account of traditional and modern themes in the debate, central to early public finance, between the use of direct and indirect taxation.
At the outset he reviews a number of definitions, the main two economic ones being to associate taxes with ‘shifting’ and with ‘tailor-making’.
In the first, direct taxes are seen as being paid by those on whom the formal incidence sits, e.g. income tax, whereas indirect taxes are those that are shifted so that the formal or statutory and actual or effective incidence diverges.
The second, ‘tailor-making’, definition relies on whether the tax is sensitive to the particular (economic) characteristics of the taxpayer, so in this definition sales taxes of varying rates on different goods and services would be indirect, i.e. independent of who is the buyer or seller.
Atkinson himself favours this second approach and contrasts it with direct taxation (a tax on total income or expenditure with varying marginal rates) by considering what he calls ‘transitional’ taxes.
The background to the tax-mix debate is seen as having two major schools of thought:
1.
the targets-instruments approach, with the instrument of direct taxation being suitable to equity and indirect taxation to efficiency: while tailor-making is the link in the case of equity, visibility is the apparent link for the efficiency (disincentives) assignment;
2.
the superiority of direct taxation on both the equity and efficiency scores.
Neither view comes out unscathed, and the conditions under which each holds more water is explored in chapter 16.
12–3 TAX THEORY AND TAX PRACTICE
Although theory and practice are meant to go together in most accounts of economic endeavour, one area where there seems to be an alarming gap is between tax theory and tax practice.
At  one extreme there is the abstract tax theorist who analyses with great sophistication the introduction of subtle variations on ‘(1-t)’ into his or her equations, while at the other there are those applying the percentage of an academic's book purchase price that is tax-deductible.
Tax administrators often see tax theory as a luxury to be indulged in in any odd moment they might have to look up from their files, while tax theorists tend to see the administration and practical aspects of taxation as an easily coped with minor irritant, or deviation, from their ‘grand design’.
(See the Ricketts (1981) critique of optimal tax theory discussed in chapter 16.)
Most would find Adam Smith's canons or basic principles of taxation attractive.
These are:
1.
Equity
Individuals ought to contribute ‘as nearly as possible in proportion to their respective abilities’(Smith 1776, p. 310).
2.
Certainty
Tax liabilities should not be arbitrary or uncertain (visibility and compliance cost considerations).
3.
Convenience
The manner and timing of tax payments should be convenient to the taxpayer.
(Here the question of compliance costs also arises.)
4.
Economy or efficiency
The excess burdens (or welfare costs) of taxation should be minimized.
(Included under this heading are the administrative, collection and psychic compliance costs of taxation.)
(For further discussion see Sandford, Godwin and Hardwick 1989.)
Putting the principles above into an analytical and practical context is difficult, not least because they may well conflict with each other.
In the UK the Inland Revenue Department and the Customs and Excise Department administer income tax and expenditure-type taxes respectively.
The major Inland Revenue tax is personal income taxation whose yield is a quarter of total revenue raised.
The other main ‘income’ taxes are: national insurance contributions (NIC); corporation tax (a tax on the gross profits of companies); petroleum tax (comprising three levies on UK gas and oil production); capital gains tax (a tax on the gain from the sale of certain assets); and a gifts tax (in the form of the capital transfer tax which applies to transfers between individuals).
The relative importance of these revenue sources can be seen in Fig. 12–1.
Where the Customs and Excise Department is concerned, the valued added tax (VAT) compulsory in all EC countries, vies with excise duties as the most significant revenue source.
VAT is a general sales tax which applies to the value added at each stage in the production chain with its formal incidence being on consumers, as the tax is included in the sales price at each ‘intermediate’ stage.
Excise duties are taxes on specific home-produced or imported goods, with ‘cigarettes, booze and petrol’ being the usual suspects to be rounded up on each Budget day.
The income sources and expenditure patterns of the government sector are reported in official statistics (see Fig. 12–1) but are not widely appreciated.
In an area where the costs of being well informed are high compared with the benefits, this is not surprising.
However, it does mean that misconceptions are common.
Tracing out the efficiency and equity consequences of different tax tools forms a large part of the purpose of this text.
Here the actual taxes employed are briefly reviewed and their efficiency and equity aspects commented on in the light of the earlier, more abstract analysis.
Since rates were discussed in chapter 11, the areas for discussion here are personal income tax, national insurance contributions, excise taxes, VAT, corporation tax and capital taxation.
12-3-1 Personal Income Taxation
The effects of personal income taxation are usually viewed in relation to the aggregate supply of hours of market work and the associated welfare costs.
The presence of income tax at high marginal rates should also induce movements into untaxed areas: jobs with high non-monetary returns/attributes, fringe benefits as opposed to recorded cash payments, and work in the ‘black economy’(see chapter 8).
One of the most heavily researched areas in economics is the response of labour supply (hours) to income taxation.
An outline of the basic approach can be found in Killingsworth (1983).
The object is to establish the change in hours supply to the labour market  ta; H as a result of a change in wages δW, which, other things equal, generates an income effect (y) and a substitution effect (s), as follows (assuming that the only tax is the introduction of a proportional one on labour income and it is this that is causing the change in W:
Now the term  ta; W can be expressed as the change in income δY divided by hours worked H, so that substituting  for δW in the final term of (12–1) and multiplying all terms by W/H yields  
And multiplying the top and bottom of the final terms by Y yields  
The effect of the income tax system on the budget constraint that individuals face depends on the precise nature of the tax system.
Progressive tax systems usually involve higher marginal tax rates for higher earnings.
This, combined with a level of non-taxable income  would generate a budget constraint like 123 in Fig. 12–2(a).
In fact, for the UK the tax structure achieves progressivity (a marginal tax rate greater than the average tax rate) by having tax allowances and a wide band of income over which the marginal tax rate is a constant.
There is a second, higher, constant marginal tax rate for those who earn more than, say, Y h in Fig. 12–2(b).
This replaces the curvilinear constraint with one that has several flats.
More realistic accounts of the budget constraint allow for a level of unearned income Y u and the presence of an overtime premium on the basic wage rate when the standard work week  is exceeded.
(In the diagram this occurs after the individual involved is liable to tax.)
The effect of these is to produce a constraint like that in part(c) of the figure.
Hausman (1985) notes how the Slutsky equation discussed above needs to be modified in the presence of a tax system that is more complicated than the proportional one assumed in equation (12–1).
The presence of  non-linearities create so-called virtual incomes like those illustrated as Y 1 and Y 2 in Fig. 12–2(c).
They are established by the extension of any of the budget segments backwards to the right-side vertical axis.
Such ‘linearization’ establishes an ‘as if’budget constraint for an individual.
An individual finding a tangency on the segment 12 of the  ‘kinked’ budget constraint would choose the same number of hours of work if she faced the linear budget constraint Y 1 125.
Changes in tax rates generate income and substitution effects by altering the slope of the segments.
However, in the non-proportional tax rate case, the virtual income is also altered (except for the first segment), generating a further income effect which will serve to alter labour supply.
Under a system of progressive income taxation, there are few a priori sustainable generalizations about the labour supply consequences of taxation.
While this reinforces the empirical nature of the question, there is a further empirically relevant problem raised by nonlinear budget constraints.
If the tax-transfer system creates a budget constraint that is nonlinear and non-convex, then it is possible for more than one tangency with an indifference curve to arise, and indeed for the same indifference curve to have two tangency points, and small changes in the budget constraint can cause the chosen number of hours to jump from one segment of the constraint to another (e.g.points 6 and 7 in Fig. 12–2(c)).
The consequences of changes in the budget constraint for hours of work again become generally unpredictable a priori.
In the case of two tangencies for the same indifference curve illustrated by 10 in the figure, a ‘gap’ is created in labour supply as there is no wage at which the individual will choose the number of hours associated with the ‘kink’point 2.
Hausman (1985) explains how specifying a utility function and searching the segments econometrically for the tangency offering highest utility provides an empirical answer to the problems posed by nonlinearity.
Analysis of how individuals respond to a change in tax allowances and/or tax rates is now a much more complex affair.
(For further discussion of these constraints and other issues see Brown 1981.)
Empirical work on labour supply can be briefly explored here.
Atkinson and Stiglitz (1980) provide a survey of the various approaches and methods employed.
Surveys of attitudes have been popular with some researchers.
Basically, individuals are asked what their responses to higher taxes on earnings are.
However, such surveys, even if couched in sophisticated designs, have the weaknesses of all surveys: they are ‘hypothetical’ and do not correspond to actual behaviour.
Respondents may act ‘strategically’ or tell the interviewer what they think he or she wants to hear.
Results are often open to many interpretations and extension to a reliable  quantitative answer is difficult.
Experimental work, as in the various American negative income tax experiments, is also open to many of these criticisms.
Those under study are aware they are part of a short-run experiment and therefore are less likely to act ‘naturally’ and signal their long-run responses.
In addition, experimental design in any area of research is always open to criticisms concerning sample size, composition and interpretation of the results.
Neuberg (1989) is an author who has recently considered this type of work in detail.
As with the quest for compensating variations in cost-benefit analysis, economists are happier with data on observed behaviour.
The evidence, whether in the form of a time series or a cross-section of individuals, industries or regions, comes not from taxation directly but from hours of work supplied at different wages net of tax — which, of course, is not quite the question at hand.
People may act differently in response to changes in taxation than to variations in earnings per se.
The use of large datasets and sophisticated econometric techniques is impressive but invariably proceeds only in the face of technical difficulties that weaken confidence in the results.
One type of regression equation that has been employed to give empirical content to the question of taxation and labour supply is  where 
The estimates of a 1 and a 2 are a source of the substitution and income derivatives in equation (12–1), which, when combined with the mean values for H, W and Yin the sample, can give the three elasticities in (12–3).
Typically, the value of the uncompensated wage elasticity for males is small and negative, i.e. a mildly backward-bending aggregate labour supply curve.
The equivalent value for women suggests a positively sloped aggregate labour supply curve.
This overall effect is the product of the income elasticity which is usually negative, confirming that leisure is a normal good (as income rises more leisure is ‘bought’ and fewer hours of work supplied) and a positive substitution elasticity.
The results of this type of work have always been less dramatic than people are comfortable with.
There seems to be a feeling that labour supply ought to be very sensitive to taxation so that the disincentive effects of income taxation are large.
The evidence does not appear to confirm this, especially in the case of full-time male workers.
It must be noted, however, that the supply of labour is a multi-dimensional concept, so that the effect of taxation on labour supply may show up as: less effort while at work, emigration, longer holidays, shorter working lives, different occupational choices and associated human capital acquisition, etc.
These other possible connections to income taxation require separate investigation for a fuller picture to be painted.
Having said this, there are reasons to suppose that labour supply would not be as responsive to tax changes as is, perhaps, expected.
First, individuals do not work only for pecuniary rewards.
Job satisfaction or the prestige associated with a particular occupation may be important in their decision-making, and these factors are typically ignored.
Second, individuals rarely have the control over their work-hours that is typically assumed in the theoretical literature.
Hours of work are set for certain occupations (e.g. 40 hours a week) and overtime may or may not  be an option.
For professional workers like solicitors and accountants, there may be greater discretion, but typically the individual's work/leisure choice may be far more constrained.
Third, the assumption is that individuals are fully aware of tax rates.
Empirical work has long cast doubt on this (see e.g. Brown 1968).
Again, solicitors and accountants may have greater awareness of tax rates, but this is less likely for the man in the street.
In Brown's 1968 survey only 3 per cent of workers knew the standard rate of tax and only 6 per cent of managers were able to estimate their marginal rate of tax.
While Brown's survey indicated that people overestimated the amount of tax paid, a more recent survey by Lewis (1978) confirmed the misperceptions but indicated a general underestimation.
Both studies cast doubt on individuals' awareness of tax changes and therefore suggest a low labour response.
Despite the evidence, the Conservative government in the 1980s has been determined to lower income taxation to offset its disincentive effects.
It is possible as a matter of deduction to gain some insight into the likely consequences of cuts in the basic rates of tax.
Ulph (1987) points out that those who earn close to the tax threshold will enjoy little or no income effect from the tax cut so that the substitution effect should dominate, causing them to work more hours.
In contrast, those at the top end of the earnings distribution will enjoy a substantial change in their after-tax income so that the income effect will be large, causing the high-income earners (the dynamic entrepreneurs?) to work less.
Ulph emphasizes the need to consider different groups in the labour force separately e.g. those who work at the tax threshold (mainly part-time married women) and the currently unemployed — so that their particular incentives can be analysed.
To date, the evidence that changes in marginal rates have very significant effects on the labour market decisions of individuals has yet to be established.
Finally, it is worth considering the incidence of personal income taxation.
As noted elsewhere, it is the relevant supply and demand elasticities that matter.
In Fig. 12–3 the demand for labour in the absence and presence of a proportional income tax is depicted as D and D T respectively.
Two labour supply curves are depicted, one perfectly inelastic (S LI ), the other with a positive slope (S LE ), reflecting that in aggregate the substitution effect of an increasing wage   rate dominates the income effect and more hours are supplied.
In the case where the inelastic curve S LI applies, the initial market wage W O and supply of hours L 1 obtain but the net of tax wage becomes W T and the whole of the tax paid (distance 12) is paid by the factor labour.
With some elasticity in the labour supply curve S LE the effect of the tax is to reduce employment to OL E so that the market wage rises to OW M and the net-of-tax wage received by workers becomes OW E .
In this case only part of the tax paid in total (distance 34) is paid by the workers (W O W E ): the remainder of the tax (W O W M ) finds its incidence on consumers in the form of higher labour input costs.
If, as generally seems to be accepted, the supply of labour (especially for male heads of households) is overall fairly inelastic, it is safe to assume in redistributive studies that personal income taxes stay where they are put and that forward shifting is fairly insignificant.
12-3-2 National Insurance Contributions
National insurance contributions (NICs) represent some 18 per cent of total tax revenue in the UK.
Their tax base is employment incomes.
The most significant tax reform in the UK 1989 budget involved changes in the way that the employee share of NICs is levied (the employer's share is unchanged), and it is interesting to compare the old and the reformed system.
In Table 12–2 we can see that the rate up to the lower limit was cut to 2 per cent from 5, 7 or 9 per cent, depending on what employees' pay level was.
The ‘Employee gain' column illustrates how much this ‘helps’ payers.
Compared with the old system, increases in the marginal tax rate (MTR) are seen to occur for the £75-£115 weekly pay band with the average tax rate (ATR) falling, indicating that both substitution and income effects should pull in this range towards less work.
However, for those not currently working the attraction of paid employment is enhanced.
The nature of the old system also illustrates the way ‘notches’ or ‘traps’are introduced into the pay system in that as an employee moved from, say, £74 to £75 a week, NICs went from 2 to 7 per cent of all income.
(£43 and £115 were obviously the other notches.)
12-3-3 Excise Taxes
Revenue from excise duties on home-produced goods and services and imports comes mainly from three sources: tobacco, alcoholic drinks and hydrocarbon oil (predominantly petrol and diesel oil).
In the UK, tobacco, for example, is taxed as a specific duty per unit of quantity and an ad valorem element based on the recommended retail price of 21 per cent .
In 1986 this accounted for nearly 12 per cent of revenue raised by expenditure taxes and 4 per cent of total government revenue (see Godfrey and Maynard 1988).
At one level an attractive feature of goods subject to excise taxes is that they are relatively price-inelastic in demand, so that it is possible to raise taxation appreciably and increase revenue, because with only a modest effect on the level of consumption there is a small excess burden.
At another level, however, this inelasticity feature is unattractive, because on a merit good, and some ‘externality’ arguments, the objective of government policy should be to reduce consumption, and owing to the price inelasticity tax rises will not have a very significant impact on the level of consumption.
Given the price inelasticity argument, changes in duties in the annual budget are probably best seen as motivated by revenue-raising considerations.
12-3-4 Value Added Tax
Value added tax is important in the UK because of its EC membership.
It is a general sales tax covering a very wide range of goods and, as its name suggests, is a tax on the value added at each production stage (the difference between the value of sales and purchased inputs).
The difference between formal and actual incidence is important and is emphasized by the ‘shifting’ definition of an indirect tax.
The bread sale example in Table 12–3 has four production stages, each ‘adding’ £200 in value and facing a 15 per cent tax rate.
Until a sale is made to a non-registered person, all VAT paid is redeemable by the next registered trader in the chain.
(Note the incentive to be registered for VAT.)
At each stage the gross (output) tax due (OT) is included in the price as the inputs (intermediate outputs) are passed on.
Tax paid at an earlier stage is deducted to produce the net tax due at each stage.
Registered VAT payers have to present a three-monthly return (not synchronized between stages) on which all output tax and input tax is declared for the period and the net tax paid.
That is, the baker declares £90 worth of output tax, and with £60 deductible input tax pays £30 net.
(This has been recovered by him in the price to the retailer of £690.)
At   first sight all the tax is paid by the final purchaser.
However, the simple analysis of chapter 7 dealing with excise taxes suggests that this can be the case only if demand is completely inelastic or supply is completely elastic.
In the other cases, part of the tax is felt by the producers or suppliers in the form of the lower prices that would have obtained if VAT did not apply.
12-3-5 Corporation Tax
Taxation of income earned from corporations is not a simple issue.
There are two broad views about the object of the exercise (see Musgrave and Musgrave 1989).
On the so-called integrationist view, corporation tax is a device to include corporation income within the personal income tax base.
The second, absolutist, view is that it is an additional ‘absolute’ tax on corporate income independent of the operation of the personal income tax system.
If the integrationist position is accepted, then the one-time perennial exam question of whether ‘corporation taxation’ is double taxation is brought to the fore.
If all profits from corporations were distributed to shareholders, then on the integrationist view all that is required is a mechanism by which individuals can pay their tax on this income source at their personal marginal rate.
The absolutist view is that this would not be a sufficient appreciation of the matter and that corporations have a separate liability to tax.
While not denying that only individuals can ultimately feel the burden of taxation, absolutists feel that the corporation is a legal entity, an economic organism in and of itself.
In this respect any shifting of corporation tax would counter this argument to tax corporations per se.
The general line of argument developed by Musgrave and Musgrave (1989) is that, while there may be a case for a separate tax policy in relation to corporations, it is not evident that the type of corporation tax system enacted fits the bill.
All businesses, not just incorporated ones, gain from the public-good and quasi-public-good provisions of the public sector, especially the legal framework in which limited liability is enjoyed.
While this is a benefit, it is difficult to establish the cost of securing it, and it is not obvious what the appropriate tax base for each public-good or quasi-public-good gain should be.
In the absence of perfect competition, tax policy may be justified in influencing industrial structure, and microeconomic theory describes the impact of different types of taxes on monopoly firms' decisions.
Again, however, a specific objective needs to be established and a suitable tax instrument selected.
Alongside concerns about the benefits enjoyed from public sector provision and the structure of industry, there is also the desire to influence the pattern of expenditure in the economy.
Levels of investment are important to economic growth, and it is often considered a ‘good thing’ to stimulate growth by inducing a higher level of investment.
The use of investment tax credits, so that firms can offset some of the cost of capital equipment against corporation tax liability, is one instrument that could be assigned to this target.
Corporation tax systems fall into different categories.
Under the ‘classical’ system company profits are taxed and then any dividends paid out are taxed as unearned income by the recipients at their marginal tax rate.
This is the double taxation case (in comparison with income from non-incorporated businesses) and tends to encourage profit retention rather than dividend payment.
The imputation system in the limit corresponds to integrationist views and offsets the double taxation effect by imputing corporation tax paid to dividend recipients as an offset to their personal liability to tax from that source.
Such imputation can be complete or partial.
The partial imputation shades into the split rate system, which treats distributed income in a more favourable tax manner than income retained by the corporation.
The incidence and welfare costs of corporation tax have been discussed in chapter 7 in a general equilibrium context.
12-3-6 Capital Taxation
There are two main UK taxes under this heading: capital gains tax and capital transfer tax.
Capital gains tax is levied on the difference between the selling price and the buying price of an asset.
There are a number of exemptions, including a sole or main residence, a private car and life insurance policies.
Capital losses can be offset against capital gains tax liability, and there is a tax-free element before capital gains tax is levied at the individual's personal marginal tax rate.
One of the purposes of capital gains taxes is to prevent individuals from avoiding tax by converting their income into a capital gain: individual choices could be distorted and people might, for example, seek assets like oil paintings as opposed to bonds.
The return of the former when realized on sale represents a capital gain, and if untaxed would be much more attractive than interest payments which would be taxed as part of income.
Variations in the ability to convert income to a capital gain, plus the fact that such gains are more significant in higher than lower income brackets, means that any favourable treatment they might receive would be inequitable.
Capital transfer tax (since the 1986 Budget inheritance tax) has undergone a number of changes.
Originally it covered all gifts, but since 1986 it is restricted to gifts on death or those made within seven years of death.
Again, there is a tax-free element, and there are exemptions which include transfers between husbands and wives and gifts to charities.
James, Lewis and Allison (1987) document the growth of concessions related to capital transfer tax and conclude that, like its predecessor estate duty, it is ‘a voluntary tax paid only by those who dislike[d] their relatives even more than they disliked paying tax’(p. 45)
12-3-7 Taxation in Aggregate
So far the discussion has considered the separate elements in the UK tax system in isolation, but a common query concerns the burden of the tax system as a whole, say as between countries or across income ranges.
There is no easy way to answer this type of question.
With regard to the first part of the question, ‘league tables’ of the most taxed countries is a common response.
Table 12–4 reproduces some recent relevant data for a number of countries.
For the sample of countries chosen, it is clear that the UK is not the most heavily taxed overall.
However, despite political rhetoric, it is impossible to draw any ‘robust’ normative conclusions from such estimates (see Cullis and Jones 1987).
With respect to the effects of the overall tax system at each income level, Dilnot, Kay and Morris (1984) provide an insight.
To put their approach crudely, they attempt to summarize the tax system in a complicated version of the following equation: where 
This is more than a summary of the descriptions of each tax introduced above: rather, an economic picture captured by econometric estimation.
The authors introduce a methodology for describing a whole tax system that is useful here as a summary device.
The essentially degressive structure of UK personal income taxation (tax allowances plus a single marginal tax rate) allows it to be represented as  where 
Next, income-related deductions are introduced.
These comprise mainly mortgage interest, pension fund contributions and life insurance premiums and are captured in the form of  where M is mortgage interest payment.
Equation (12–1) becomes  so that and  so that the effect of mortgage interest deductions is to alter the effective marginal tax rate to  and raise the value of the tax credit by bM 1 .
(Other deductions are treated similarly: see Table 12–5.)
The favourable treatment of mortgages, pensions and life insurance in the UK tax system has not gone without comment.
Kay and King (1983) note that, because of the advantages associated with these assets, they dominate net personal savings in the UK.
The authors describe them as ‘civil servant’ assets rather than‘entrepreneurial’ones, because they suit those with settled plans who do not wish to move geographically or occupationally.
Additionally, because of their contractual nature, they have elements of ‘forced’ savings about them in times when individuals may need greater flexibility.
With regard to expenditure taxes, Dilnot, Kay and Morris use a linear Engel curve for the ith commodity () as follows: where  Introducing t i as the tax per unit on i, aggregate tax T becomes 
In words, the effective marginal tax rate is raised by t i x i and the tax credit is reduced by t i Z i .
The NICs discussed above are introduced at a rate n 2 and gross employee  remuneration Y r is given by 
Equation (12–11) becomes 
All the adjustments made are summarized in Table 12–5.
To recap the method, direct taxes have a legal framework facilitating the assessment of the overall effective marginal tax rates.
However, marginal income tax rates would be overestimated if income-related deductions were ignored.
Here the assumption is that mortgage and other  deductible payments, including (half) of life insurance premia, are ‘caused’ by high incomes.
As for indirect taxation, estimated Engel curves relate the expenditure of groups of households on taxed goods to total expenditure.
The application of the structure of the indirect tax system to the estimated consumption patterns in each group enables the integration of the indirect with the direct tax system.
The third and final step is the inclusion of payroll-based taxes.
The results suggest that in 1981, for a married couple with two children (wife not in paid work) in the basic band for income tax and below the national insurance ceiling, the overall marginal tax rate on gross employee remuneration (GER) was 53 per cent.
For other groups the authors note that the overall marginal tax rate was at an historically high level in excess of 60 per cent.
Such calculations clearly lend credibility to the claim of Mrs Thatcher in the early Conservative ‘era’ that the population was ‘over'-taxed.
The pros and cons of this are discussed elsewhere; the main purpose here is to offer an insight into how a whole complex tax system can be summarized by condensation into a ‘tax credit’ and a single ‘marginal rate’.
12-3-8 Debt Finance
If taxation finance is not available to cover public expenditure, governments must resort to debt finance or increases in the money supply to finance their activities.
The money supply eventuality has been considered in chapter 10.
Here a perennial topic in traditional public finance — the burden of the national debt — is considered.
The debate has many of the elements that divide commentators on government activity.
If the government sells bonds to the public to finance its activity, who bears the burden?
(For the moment we shall assume that the public's payments for the bonds come from their expenditure on consumption goods.)
Consider two periods, ‘now’ and the ‘future’, and two views, the ‘real resource’view and the ‘utility-based’view.
On the ‘real resource’ view a public sector project uses up real resources now and hence the opportunity cost is incurred now in the form of reduced private sector consumption; in the future, debt interest payments must be paid and the bonds redeemed if they are not perpetual ones.
However, such service and repayment responsibilities are transfer payments between the general taxpayer and the debt-holders, which, as long as they are internally held, will alter who gets command of goods and services but not their volume in aggregate.
This argument firmly places the burden of the public debt in the ‘now’ rather than the ‘future’period.
In contrast, the utility-based argument associated with Buchanan (1958) does not quarrel with when the resources are used but rather points to the fact that debt-holders have voluntarily taken up the debt and are being compensated for decreased present consumption by the enhanced future consumption that interest and repayment will allow, and hence are not made worse off.
However, in the future the utility of the then general taxpayers is lowered because they are coerced, by paying the tax, to transfer it to the bond-holders who are simply having their ‘contract’ fulfilled.
On this basis, the utility reduction has been felt not when the real resources are used buy in the future when interest payment and repayments are made, i.e. there has been forward shifting in time.
Browning and Browning (1983) offer a reconciliation that relies on individuals making what Lewis (1982) calls the ‘fiscal connection’ between debt issue now and future general tax payments.
If the future tax is anticipated, it is effectively' capitalized' into individual wealth now, so that individuals feel the burden now although the actual payments  will take place in the future.
This is the Ricardo ‘equivalence theorem’, which suggests the equivalence of taxes and loans as revenue-raising instruments.
This view has been explored by Barro (1974).
West (1975) develops a taxonomy designed to separate out the different strands in the ‘great public debt debate’.
There are several elements in the taxonomy.
For example, the word ‘burden’ has notions of subjective (opportunity — utility-based) cost and objective (outlay — commodity-based) costs.
Individual and aggregate (national) burdens are separated, as are gross and net-of-benefit burdens.
The final main distinction is between flow payments of costs and their capitalization into current net worth.
West, in a sense, sides with the real resource school as defined above but establishes his position ironically with Buchanan's (1969) subjective notion of costs.
The relevant concept is seen to be that choice, influencing cost, which is borne exclusively by the decision-maker, cannot be shifted to others and is dated at the moment of the decision.
Hence public debt, irrespective of whether it is domestic or foreign owned, involves a cost-influencing choice: at the time the decision is made ‘forgone opportunities are experienced’(p. 182), but this has ‘no connection with the fact that resources are used up in the initial period’(p. 182).
The validity of the lower inherited capital stock argument (which relies on bond purchases reducing current saving and hence investment) is also called into question.
Here West argues that informed individuals subject to taxation are free to reduce their private saving as opposed to consumption or, indeed, to reduce their consumption if the debt alternative is employed.
His general point is that the debt burden debate is resolved when each of its aspects is placed in its appropriate ‘cost’ category.
Perhaps, like all good debates, this one relies on confusion, with participants writing about different aspects, for its sustenance.
12–4 TAX REFORM
Tax reform is a subject that cuts across general disciplines and can have a number of motives.
Approaches can be divided between
(1)
those following an implicit social optimality approach, looking at the pros and cons of a reform from the viewpoint of all affected individuals rather than reflecting sectional interests,
(2)
those looking to political philosophy, and
(3)
those, for example in the public choice tradition, who are sceptical of reform proposals, regarding them as an attempt at ‘rent seeking’(Buchanan 1987, Tullock 1988)
.
The following three examples correspond to these views.
12-4-1 Annual Wealth Tax
As an example of the first approach, the case of an annual wealth tax discussed in Sandford, Willis and Ironside (1975) can be considered.
The volume they produced contains sections on economic perspectives, case studies from other countries and a series of nine chapters centring on the precise details and pitfalls of a possible wealth tax for the UK.
(For these authors, wealth is the value of the stock of physical and financial assets held by an individual, company, association or institution less liabilities.)
Table 12–6 provides a useful framework to structure the discussion.
Column (1) deals with the objectives of a wealth tax and can be summarized as follows from the related paragraphs in their work.
1.
Efficiency is discussed in relation to the wealth tax replacing some income tax or a projected increase in income taxes.
Such a tax is seen as having lower disincentive effects than an income tax because it relates to past effort; i.e. there is no disincentive effect to work for additional income that is to be consumed.
Second, the imposition of a wealth tax creates an incentive for wealth holders to seek money returns on their wealth (otherwise the tax generates   a tax liability and no money income to meet it) and indeed to maximize them; for example, investment in valuable picture collections looks relatively unattractive.
(High progressive rates would deter savings and investment, so low proportional or weakly progressive rates are advocated.)
2.
Horizontal equity is met more nearly by a wealth tax than by a higher income tax rate on unearned income (income from property) or than on income from work.
This is because the wealth base recognizes the additional economic power and hence taxable capacity offered by wealth ownership, even if no money income is derived, as for example with the ownership of jewels, or where an identical money income is secured from two very different capital values.
The money income-less wealth holder is not in the same position as the money income-less street dweller.
Again, a low wealth tax rate is suggested as a supplement to income tax.
3.
Inequality reduction is treated at two levels.
The first views a wealth tax as in paragraphs 1 or 2, as a way of capturing income, with the object under this heading being to reduce the feedback effect of large wealth holders enjoying higher incomes and therefore adding to their wealth by saving.
This suggests the ‘substitutive’ wealth tax, which can be paid from income leaving wealth intact as opposed to the ‘additive’wealth tax, which necessarily involves the sale of assets and corresponds to a strong aim of reducing wealth inequality.
The views correspond to relative versus absolute wealth reduction and the implied rates can be seen from Table 12–6 and guessed easily.
4.
Administrative control refers to the data that are gained by the presence of a wealth tax, enabling the cross-checking of statistics and facilitating good tax administration and reduced evasion.
The discussion in the original work is obviously much fuller than this, but here the interest is in the approach.
Possible criteria are outlined and the implications of the criteria for thresholds, rates, ceilings and the tax type are presented.
While the authors have a view, readers are given the options and the relevant costs and benefits.
The authors are broadly following the ‘textbook’ approach to economic policy — setting up the ‘facts of the situation’, laying out the alternatives and predicting or assessing their likely consequences.
Before considering another approach, it is interesting to note that the objectives broadly correspond to Sandmo's (1976) introductory discussion of what might be meant by an optimal tax with the efficiency (excess burdens) approach being identified with the economist, the equity considerations with the ‘man in the street’ and the ‘control’point with the tax administrator's viewpoint.
In this way the eclectic nature of the approach is clear.
12-4-2 Family Taxation
This section is based on an article by Wilkinson (1982), which is very useful as it exposes the underlying ideologies/philosophies or interests that are at stake in this kind of reform.
In particular, the author isolates three perspectives: conservative, radical and moderate.
It is assumed that income taxation of the family unit should correspond to principles of ‘ability to pay’, i.e. horizontal equity and the minimization of ‘excess burdens’.
Essentially, in the UK the schedule of non-zero tax bands is the same for most individuals so that progression (a marginal tax rate that exceeds the average tax rate) is achieved by the exempt income band.
Traditionally, the tax system was constructed on the basis of a family with one ‘breadwinner’ and with the husband assumed to be that ‘winner’.
It offered married men a tax allowance of some one-and-a-half times the single person's allowance to which working wives were entitled.
By the 1980s the increased labour force participation by women, combined with the desire for equity of married man and women, provided the spur to reform.
This suggested two elements of concern in the existing system.
First, the ‘aggregation’ principle meant that on marriage the husband and wife were treated as a single tax unit, with any income earned by the wife being added to that of the husband for tax purposes.
For most couples this made little difference in terms of tax actually paid, but, as feminists were quick to point out, it treated the wife as a dependant and not a separate entity.
Relatedly, it afforded the wife no financial privacy (except by couples opting to be taxed as two single persons, which ‘paid’ financially only if the loss of the husband's allowance could be compensated for by a lower amount of income subject to a tax band higher than the basic rate).
Second, the rationale of the married man's (husband's) allowance looked doubtful.
Working wives had a single person's allowance in their own right and, while ‘non-working’ wives had no money income, it was felt that the imputed income from non-market home production needed to be part of the picture.
The existence of economies of scale in family life (bulk buying, spreading fixed costs, etc.) means that, although two cannot live as cheaply as one (it seems to us at least), cohabitation means that a given per capita standard can be maintained for two at less than double the expenditure for one.
If anything, these considerations suggest that the ‘allowance’ was in the wrong direction.
The 1980 Green Paper, The Taxation of Husband and Wife, had as a central proposal the scrapping of the married man's allowance to be replaced by a single person's allowance each for husband and wife.
However, for a non-working partner this allowance could be partially or wholly transferable to the working partner; i.e. there was transferability of tax allowances.
Against this background, Wilkinson explores the positions noted above.
Conservatives would like to preserve traditional family roles so that women are discouraged from market-based work.
Whole or partial transferability encourages this, favouring in tax terms one-earner couples over two-earner couples.
However, having a wife and protecting the traditional family are not quite the same thing, and the system is really an indiscriminate subsidy to all married men.
If the object is to encourage mothers to stay at home, the use of child benefits would have been a superior policy.
Furthermore, if the problem is seen to be women taking men's jobs, making them unemployed, the problem is one of macroeconomic policy, and is not to be solved by effectively concentrating it in a disguised fashion among non-working wives.
Moderates tend to favour single allowances that are non-transferable with a cash benefit payable for dependent children.
(Note that tax allowances offer least to low-income individuals who may not be liable to tax and most to those paying the highest marginal tax rates.)
This approach tends to have a neutral effect on a decision about whether to be part of home or market production, avoiding women's role being institutionalized as dependants.
Radicals fully recognize the point of the common phrase, ‘can afford to have a wife and children at home’.
Against this background of a wife who was willing to work on the market, the choice to work at home must involve a higher (or at least as high a) level of utility.
That is, there is an imputed income that might be proxied by the market wage required to buy in the domestic work of the wife or, more appropriately, the necessary compensating variation (the minimum sum acceptable to compensate for the loss of the services of a non-(market) working wife).
Radicals would end the married man's allowance, would tax ‘imputed’ income and would recycle the increased tax revenue as child benefits.
Although this seems equitable, it is claimed that imputed income is not an everyday concept so that the tax of income that is not a money flow would be politically unpopular as it would have to be paid from the working partner's income.
Of the three broad proposals considered, this would encourage women to work on the market.
Political feasibility was adduced as one of the pluses of the moderate scheme of family tax reform.
In April 1990 reforms came into operation which addressed the first but not the second elements of concern outlined above.
The element of sexism in the tax system has been corrected to the extent that the income of the wife is now taxed independently so that her income is no longer viewed as belonging to her husband.
However, there remain horizontal inequities in that married couples are entitled to the ‘married couple's allowance’(equal to 0.6 of a single person's allowance (SA)), offering them tax gains compared with unmarried couples.
Furthermore, two-earner couples enjoy greater allowances (2.6SA) than single-earner couples (1.6SA), a provision that dates from the Second World War when there was a policy to encourage married women to work.
In a context in which the majority of married women now work and the reason for a single-earner couple is often related to having children, this looks inequitable to the extent that those with more responsibilities are less favourably treated (see Johnson and Stark 1990).
Leaving the tax details aside, the importance of this example of tax reform approach is the clear way in which choices of tax system reflect the personal (political) philosophy that is held implicitly or explicitly by individuals.