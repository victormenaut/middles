

Research practice, theory, methods and data
Chapter 1 offered some introductory remarks on the nature of social research and the role of theory, methods and data in the research process.
It is now time to flesh these remarks out a little more and begin to orient the discussion toward some of the themes we shall be discussing in succeeding chapters.
We shall also take the opportunity to make some ground-clearing observations of a rather wider methodological import in order to provide an appropriate context for much of what follows.
THE POINT OF RESEARCH
We want to begin by posing the question: what is the point of research?
We ask this not as a government minister might, faced with the seemingly interminable demands of research scientists for more and more funds, but to try to see what relationship research bears to knowledge.
In Umberto Eco's novel, The Name of the Rose, the story of the conflict between a theological and a rational-scientific explanation of a series of murders in a monastery in the fourteenth century, Father Jorge, the self-appointed censor of heretical literature, preached that knowledge is not something to be furthered, only refined.
Such a view could not be sustained today.
The advent of scientific thinking has institutionalised the idea that knowledge has to progress and can do so only through research.
None the less, the question we have posed is an important one even if it has no ready answer; important because it directs our attention to the ways in which disciplines acquire, develop and, not to be forgotten, discard knowledge.
We remarked in Chapter 1 that research is about "finding things out" , and there are many activities consistent with this description.
Looking up a reference in a library on some topic, a firm doing market research for a new product, an opinion poll prior to an election, physicists building particle colliders to find an elusive sub-atomic particle, the search for a cure for AIDs, and many, many more would all qualify as research in this sense.
 "Finding things out" is not an  inappropriate rendering of what research is about.
However, as it stands this is far too simple.
It says little about the "why" of "finding things out" .
Of course, one kind of answer to the why has to do with the particularities of each and every research project.
More generally, the "why's" have to do with providing answers to problems or questions: what has been written about this topic?
What are the likely market trends?
Which party is likely to win the election?
Does the Z particle exist?
And so on.
Of course, any piece of research will involve more than one question.
But our main point is that the problems that research is designed to solve, throw light upon or shape up, do not stand alone but are part of a wider context.
Even so-called "fact-finding" research is rarely, if ever, just that but is normally part of a wider enterprise into which the "facts" discovered in the research are fitted.
In the course of ordinary life many of the kinds of activities that could fairly be described as research are an aid to practical decisions and conclusions, answer practical problems.
But even when practical concerns are uppermost there is still a framework, a wider context, into which the research and the questions to which it is directed have to fit.
In science, and we include the social sciences in this despite the arguments both about the nature of science and whether or not the social sciences can be counted as such, an important, indeed essential, element of the context of research problems is theory.
As we pointed out in Chapter 1, the importance of theories in the pursuit of and in the constitution of "facts" is hard to underestimate.
Having said this, however, the notion of theory is a troublesome one.
In sociology, for example, it embraces the broad perspectives or approaches, such as Marxism, symbolic interactionism, structuralism, to mention but a few, to more specific explanations of, say, social mobility or suicide, to the highly particularistic hypotheses specific to a research project.
Some theories are more formal than others.
Some have a much more general scope than others.
Some are little more than loose collections of concepts, while others try to achieve a higher level of integration among their concepts.
Some, and one can use Goffman's "dramaturgical approach" as an example, constitute methodological metaphors, and yet others are simply empirical generalisations.
There is, to put it briefly, a plethora of offerings to which the term theory has been applied in sociology.
Not only are there different kinds of theories but also there are different priorities awarded to theories vis-à-vis methods.
Sometimes theories are all important and drive the research and the use of data.
In some extreme cases, theorising obliterates any need for empirical method.
Thus, much of sociological theorising consists of commentaries upon commentaries on other theories rather than trying to bring data systematically to bear upon theoretical problems.
Sometimes the methodological apparatus dictates or shapes the theorising.
For example, the experimental style  of psychology is very often treated as a precondition of effective theorising.
Similarly, some ways in which the survey is regarded define the scope of social science for its exponents.
A basic starting point for us is, then, that concepts and theories give meaning to potentially observable things and events, and in this sociology is like other sciences.
These potentially observable things may, with or without the help of more precise concepts and ideas, be used to construct data.
Data is valuable because, in conjunction with theories it illustrates, discovers and explains.
All this will be elaborated more fully in the course of this chapter.
However, before proceeding, it is important to note the way in which diverse and sometimes contradictory theories — together with their associated methods — find a place in a broader entity.
This is the academic discipline which is the intellectual concept of both theories and methods.
There are a number of implications to be drawn from this observation which have relevance for the context of data.
The ordinary world as known to common sense is full of things, events, people and happenings; full of, for brief illustration, tables, chairs, friends, enemies, measles, drugs, books, cats, dogs, Golden Virginia, deceit, honesty, teachers, poor essay marks, good luck, all the infinitude of things that we, in our ordinary experience know about, talk about, ignore, are aware of, are not aware of, and so forth.
However, a discipline's interest in this world, and any discipline will do as an example here, is not like the interest that any of us show in that world as a world in which we have to do, and know about, the quite ordinary and mundane things that we do.
As everyday creatures our interest in the ordinary world is very much a practical rather than a theoretic one.
We have no need to theorise about bus timetables in order to catch a bus into town.
We have no need to theorise about this world as a condition for acting in it.
There is much in the ordinary world that we do, and have to do in order to act within it, take for granted.
Disciplines can choose to doubt matters that we in our everyday lives take for granted.
For one thing, a discipline's interest in the ordinary world is highly selective.
No discipline is, or could be, interested in everything about the common-sense world but in those things, those aspects, those properties, those attributes, conceived in terms of its conceptual apparatus and its theories.
A discipline, if you like, abstracts and selects from the totality of the world those features that are its own special province.
The human sciences differ on how human behaviour should be conceived.
Economists, for example, often work with theories which stipulate that human economic behaviour is motivated by rationality, more or less conceived as the maximisation of means to ends.
Psychologists tend to focus on behaviour as the expression of certain psychological propensities while sociologists tend to see human behaviour as shaped in its course by the social context of human life.
Such pithy pronouncements on what a discipline is about  can be only of heuristic guidance.
They cannot tell us in any detail what kinds of investigations might be prompted by such conceptions, or how they may be carried out, what concepts and theories are relevant, and so on.
Even within disciplines there are differences as to how, in sociology for example, the "social" itself should be conceptualised.
Some propose that social behaviour is caused by external social forces while others, such as the symbolic interactionists or the ethnomethodologists, want to see social behaviour as actions mutually created and sustained by parties to social arrangements.
Such differences (and we have sketched them only very briefly here), are entirely right and proper within and between disciplines which are alive with debate and curiosity about the aspects of the world they have as this domain of inquiry.
In important respects, this is the point.
The domain assumptions of a discipline provide a context for research but are themselves relatively unresponsive to the conclusions of the research.
To put it simply, the economist's assumptions about the maximising propensities of human beings are precisely that, namely assumptions; they are a place to start.
Economists know that real flesh and blood human beings are not like that at all; sometimes they are, but sometimes human beings do things which are manifestly not in their best economic interests.
Part of being selective is that it is also necessary to simplify the world in order to try to see more clearly just what a discipline can say about aspects of the world.
Differences between disciplines are not, of course, hard and fast even though , at times, they can become crucial.
Disciplines, or more accurately, theories belonging to disciplines, constitute their phenomena as selected aspects of the totality of the world.
Some years ago a number of philosophers of science and some scientists had the vision of a unified science in which all the separate disciplines would be integrated within a set of all-embracing, mutually coherent theories.
Such a dream, if it is realisable at all, is certainly one for the far future.
There are, it is true, many points of contact between disciplines, for example, between biology and chemistry, physics and medicine, psychology and sociology, but these are local rather than overall points of contact.
Many current points of contact are likely to change as our knowledge changes, as our ideas develop and change.
Disciplines take a special interest in the world as shaped and reflected in the theories they produce; theories which constitute their respective phenomena of interest.
Physics abstracts and selects those properties in the world that it is interested in not billiard balls, tables, chairs, but objects in motion, angles of momentum, and so on.
Thus, though one might for some purposes characterise the human sciences as concerned with human behaviour in all its fullness this is to misrepresent what turn out to be very different ways of looking at or being interested in the world of human beings.
Economists make very different specifications about the  nature of human behaviour than do sociologists or psychologists.
The economist's rationale for selectivity is human economic life and other features of human life are subordinated to this.
Though typically economists look at the way in which human beings create and distribute goods and services, often with an eye on issues to do with efficiency according to some rational criteria, this does not prevent them using economic theories to examine, for example, educational provision, the supply of blood donors, voting choice, to name but a few.
The point is that they examine such areas with very different specifications in mind to, say, the sociologist, the historian or the political scientist.
This is not to imply that they are exceeding their disciplinary mandate in examining topics which might be said to belong to some other discipline; simply that their interests in doing so are different.
Indeed, one might say, though a little misleadingly, that it is not so much the substantive topics which distinguish disciplines, but their theoretical interests.
Accordingly, the differences of disciplinary interests mean that one needs to be very careful about the kinds of problems that are being addressed.
Sociological problems are not those of economics, or of political science, or of psychology.
However, there are one or two qualifications which must be made at this point with respect to the human sciences.
The first is that there is a widespread notion that a full explanation and understanding of human behaviour needs the contribution of all the various disciplines.
Institutionally this is reflected in the growing fields of educational research, management sciences, organisation studies and communication studies where the contributions from relevant human science disciplines are directed to understanding one area of human life.
There is no doubt that this kind of focus is likely to become more common and likely to make major changes in the contributory disciplines themselves.
A second qualification, and really one to stress a point made earlier, is that no discipline is a static enterprise but is continually shifting and changing in both its knowledge and its interests.
A final qualification is that the issues we are pointing to here are thoroughly debatable.
What we are stressing is that the disciplinary context is important to understanding what kind of contribution is on offer, and this includes understanding the special limited concern a discipline has toward the world, and is an essential consideration in evaluating its research and the data it produces.
We shall have more to say on such matters throughout the chapters to follow.
We have stressed the importance of theories in constituting the phenomena of a discipline and also recognised that within disciplines there are right and proper arguments about just what these phenomena might be.
No more so than in sociology.
To some this might seem puzzling: surely a discipline knows what it is about, what aspects of the world it is interested in?
Why are there arguments about this?
Sociologists are interested in human society, so what is the problem?
The problem is that saying this, or offering any simple definition for other than heuristic purposes, is the beginning not the end of inquiry.
Durkheim and Weber, two immensely influential figures, spent a great deal of time not merely defining sociology's subject matter, but arguing for and demonstrating what the consequences of each of their different conceptions might amount to as a disciplined inquiry.
In significant respects both differed on what a study of human society might look like, and both made strenuous and hard-won efforts to carry through their respective conceptions through argument and research into the phenomena they tried to identify as sociology's subject matter.
Clearly, what a study of society might look like is closely, one might say intimately, related to not only the phenomena but also the data relevant to those phenomena.
For Durkheim, the phenomena of sociology were "social facts" , those products of human collectivities that displayed "thing-like" qualities of externality, constraint and generality.
For him, though rather ambiguously, the subjective perceptions of social actors were subsidiary to "social facts" which were the reality with which sociology dealt as its special province.
Subjective meanings, however, for Weber were the very constituent of actions that made them social and, hence, the subject matter of sociology.
So, although "finding things out" is not an inaccurate rendering of what research is directed toward, often this is finding out whether a particular conception of the discipline, in sociological terms a perspective or an approach, can be deployed in research inquiry rather than trying to find out whether a particular theory is true or false.
Much of sociological research is, we might say following Garfinkel, trying to "find the animal in the foliage" or, to extend the implication of the metaphor, trying to see if an idea can be made to say something of sociological interest.
Fielding, for example, describes his research strategy for studying the National Front as follows: to understand why NF members believe what they do, and to examine the link between their ideology and their actions…
The ideology's appeal was seen in terms of its ability to solve problems of the individual's experience.
Commitment to a particular ideology was seen as a rational choice originating in the individual's assessment of the situation…
Political deviance was the rational, constructive activity of those with a claim to political self-awareness.
This is a statement not of something that the research is going to conclude, is going to find out, but a statement of how the inquiry is to be directed, what it is going to investigate, look at, examine, and so on.
This does not mean that its findings will be biased because of this; it is simply setting out the parameters and the objectives of the research and the kinds of ideas that will inform it.
Similarly, and to refer to a figure mentioned earlier, Goffman's "dramaturgical approach" is not a theory of social behaviour but a metaphor, a way of seeing, pointing up, features of the system of interpersonal communication in public places.
The data he used, which were highly variable including field observations, quotations from etiquette books and extracts from novels, illustrate rather than prove or disprove hypotheses.
So, much of the context of research has to do with trying to see if a particular approach, a particular theoretical conception can be made to yield matters of sociological interest.
Finding this out is not a matter of one or two studies but can take many years.
Approaches and perspectives are more or less fruitful in encouraging promising lines in inquiry, rather than being true or false or responsive to empirical test.
They constitute agendas for research rather than a collection of findings and substantiated theories of social life.
And this makes a difference to the role of data.
Thus, Goffman's material is intended to illustrate, illuminate, try out and display his perspective.
In other cases, evidence has to be weighed and balanced, whereas in so much of quantitative research the aim is explicitly to test hypotheses.
So one of the purposes of research is to find things out by seeing if the world can be investigated using a particular set of assumptions, a particular perspective or a particular approach, trying to see if they yield promising and interesting findings, answer problems that preoccupy researchers, and so on.
Looking at this as one of the points of research avoids some of the narrowness of the kind of conception that has tended to dominate thinking about social research, namely that it is about testing theoretical explanations of the facts.
This emphasis is misleading in a number of ways.
For one, much of scientific activity is not concerned with explanation as normally understood but with, "just finding out how things are" , "how things work" , "what things look like" .
Much of biology and botany, for example, is concerned with taxonomy or classification rather than with explanation.
Although to be effective taxonomy needs to be informed by theoretical and research requirements, it is not explanatory in the sense that theories are expected to be.
Much of science is concerned with describing things rather than with explanation.
Although there is perhaps a sense in which both taxonomy and description are related to explanatory purposes, this is not in any straightforward or enlightening fashion.
Thus, in social science much research activity is directed at simply describing how things work, how conversations are organised, how slaughtermen do their work, how managers manage, what police-officers do on the beat, and so on; activities which are not especially motivated by explanation as the point of inquiry.
This is not to say that at some point such studies may not eventually facilitate or enter into explanations of a traditional theoretical kind, but this is not their point.
Further, and although this will not be our major preoccupation, "finding out" new theories, new perspectives and new approaches, looking to see how well they work and what problems  they can deal with, is as much part of research as "finding out" new facts.
A new theoretical formulation or a new analogy can be immensely important in furthering knowledge; certainly just as much as can finding out a new fact.
Indeed, one could say that the latter without the former is more use to the game of Trivial Pursuit than it is to science.
Darwin's great innovation, for example, was not so much in finding out new flora and fauna during his voyage in the Beagle, but in thinking about them in a new and interesting fashion; one of major consequence for our understanding of the nature of life on this planet and driving much of biological research explicating and developing the programme that Darwin's theory initiated.
Similarly, a great many of the data Marx used in his theory of capitalist society were taken from "fact-finding" Royal Commissions established during the nineteenth century.
There is one additional point we want to make about research which has to do with its collective and temporal character.
By these we do not just mean that lots of people do research and take time over it.
It is to stress than no piece of research, no matter how expensive or extensive, stands alone but becomes part of a corpus that is argued over, debated, used, criticised, ignored, reviewed, assessed, discarded, used as the basis for further research, and more.
There is a strong sense in which the audience for research is other researchers.
The significance of any research can never be merely an internal matter but is very much one determined by the response and judgements of fellow researchers and a fact of research life.
THE ROLE OF PHILOSOPHY IN SOCIAL RESEARCH
Perhaps one of the more puzzling contexts of social research is philosophy.
Earlier we spoke of the selective interests that disciplines take in the world.
For most this is a consequence of them being, or aspiring to be, objective sciences incorporating, well or badly, the scientific method.
Physics is interested only in those abstracted features of the world which its theories specify: one way of describing what physics does is "go beneath" how the world appears to us to uncover the "real" physical principles and processes which produce the ordered universe.
In hindsight it is, in some respects, a pity that the social sciences, and sociology in particular, have taken physics as the exemplar of science; the science that it is the aspiration of all sciences, including the newer ones, to emulate.
It is a pity not because sociology cannot become like physics or, indeed, become a science — it is far too early for us to decide about either of these and related questions — but because sociology looked outside itself in order to discover the appropriate model of science to follow and, as it happened, it looked toward philosophical versions of science rather than to the practices of  the sciences themselves.
In one sense this was a reasonable step to take.
If physics is to be taken as the acme of scientific knowledge, then it would make sense to try to emulate the methods that physics uses to gain its knowledge, and where else could one go for this by way of a shortcut but to philosophy, the discipline that has been endlessly preoccupied with the foundations of human knowledge.
If there is a scientific method, then philosophy is likely to be the place to find it set out.
Unfortunately, philosophy has proved to be a poor guide in this respect.
Not because of any failure on its part, but because of its own nature as an argument subject.
Philosophy's business is with argument, and its theses, assuming that this is its endeavour (which is arguable), generate yet more argument, such that issues are never finally settled, and this is just as true for its ideas about the scientific method.
None the less, given that sociology did award philosophy a juridical role in determining how sociology should conduct its business, the effect has been to make social research methods extremely sensitive to judgements about whether or not they conform to the appropriate methodological criteria.
Methodological criteria, in fact, derived from philosophical versions of the so-called scientific method.
For our part, we wish to step back from philosophical issues, not because they are totally irrelevant but because we believe that it is not necessary, from a sociological research point of view, to take them up.
The problems of social research are themselves difficult enough and ought to be approached in the spirit of treating them as sociological and methodological problems rather than philosophical problems.
Nevertheless, some general, if brief, discussion of some of the more directly relevant philosophical issues may help clarify matters.
It is possible to distinguish, albeit rather grossly, between two contrasting philosophical positions regarding the relationship between theory and data.
Both agree that it is theories which do the job of explanation, but disagree on precisely how it achieves this and, as a result, on the nature of theory itself.
The first view we can call the "empiricist" , and derives from a philosophical tradition which reaches back as far as Aristotle and runs through more historically recent figures such as Bacon, Locke, Hume, J.S. Mill, and, in the twentieth century, the logical positivists and, latterly, the neo-realists.
The second view owes more to the rationalist philosophical tradition usually associated with continental philosophers such as Descartes, Kant, Leibnitz and, much more recently, structuralist philosophers.
Briefly, the difference between these traditions is not their objective of seeking the basis of human knowledge, but the place where they saw it located.
The "empiricist" view sought the foundation of human knowledge in indubitable experience of the external world.
The task of science was to formulate procedures whereby this external world could be described, measured, and otherwise charted with certitude.
Pride of  place in this endeavour was given to systematic and properly grounded empirical investigation.
What is important, for our immediate purposes, about this view is its stress on publicly verifiable, observable sensory data, systematically collected and collated, as the route to knowledge.
The theoretical task, and in a significant sense secondary to the activity of producing "facts" , was to link observations together within some causal scheme.
J.S. Mill, for example, proposed certain "canons" , or principles, by which causal relations could be determined.
One of these was the "method of agreement" which stated that if two or more instances of a phenomenon have only one element in common, then this is the cause (or the effect) of the phenomenon in question.
Similarly, his principle of "concomitant variation" proposed that whatever phenomenon varies whenever another phenomenon varies, is either the cause or the effect of that phenomenon — a principle more familiarly known as correlation.
By using these and other principles, which are embodied in the logic of experimental design, causal patterns could be determined empirically and theories built upon these.
For immediate purposes what is important about this and similar procedures is that the theoretical generalisation is induced from systematically gathered data.
Theory is subsequent to the collection of data or facts about the world, even when the data are being used to test theoretically derived hypotheses.
We shall see in later chapters how this conception shaped many of the uses of the social survey, to mention but one example.
Such researchers saw their task as collecting facts about a population.
For them, the survey embodied the scientific method because it sought to make basic observations of the phenomena of interest and out of this formulate generalisations.
Such surveys routinely now make use of various inductive statistics to secure the generalisation from sample to population.
To some extent, though less so than with survey researchers, the same spirit informed the early exponents of participant observation.
They argued, and some still do, that in order to grasp fully how social situations are created and sustained by social actors, social investigators need to immerse themselves in the social world under study.
Only then could theoretical speculation take place.
Although they differed markedly in the kinds of data it was thought necessary to collect, they held to a similar conception of the relationship between theory and data.
However, the conception we have just been briefly outlining came up against a number of philosophical difficulties.
One of the more crucial ones concerned the empirical interpretation of scientific generalisations and theory.
Laws in science, so it was argued, were of the logical form "All As are Bs" ,(for example all swans are white) yet it is impossible to investigate empirically all As.
Empirical investigation always deals with a sample of a phenomenon, never a fully enumerated population.
Even natural scientists experiment upon  particular elements, chemical compounds, organisms, or whatever; never with all the instances of these that have, do, and will exist.
We cannot examine all water to see if, when an electric current is passed through it, at one electrode hydrogen is given off, at another oxygen.
We cannot examine all gas to see if Boyle's law, to the effect that volume is proportionate to temperature, operates universally.
Accordingly, it appeared that all law-like generalisations were always derived inductively whereby the instances investigated stood as proxy for some total population.
Unfortunately, this inductive procedure could not, logically, underpin universal and determinate laws since no finite number of events can ever guarantee the truth of a universal statement.
It was this kind of objection which led to the influential doctrine of falsification and the conception of the hypothetico-deductive model of explanation which is sketched below.
The second of the views we have noted derives from a claim that the route to indubitable knowledge is not through empirical experience of the external world, but through logical, that is rational, principles which are beyond doubt.
Whereas, for the empiricists the criteria of knowledge were to be found in the practices of empirical science, for the rationalists the appropriate models were those of logic and mathematics.
Here the logical principle is deduction.
On this view, theories are deductive systems of thought in which "facts" are deduced from higher order principles, much like geometricians effect a proof by showing how the conclusion logically follows from one or two general premises or postulates.
Theories, on this view, are of much greater importance than on the empiricist tradition.
The orthodox account of scientific practice represents a marriage between the two traditions just outlined.
The empiricist account of theories as empirical generalisations has largely been discredited, but not the stress laid upon systematic methods of investigation.
The principle of deduction is incorporated by seeing empirical investigation as primarily a procedure for testing theories through hypotheses deduced from the theory itself.
This model, known as the "hypothetico-deductive model" , uses the general statements of the theory as premises in a deductive argument, along with statements describing the conditions under which the test is carried out, a testable conclusion, or prediction, can be deduced and compared with empirical evidence.
If the conclusion and the evidence do not match then the theory is falsified; if they do match, then this is some evidential support for the theory and its explanation.
Subsequent research will then be devoted to determining its range of applicability and subjecting it to still further tests.
We shall see something of this in connection with developments in survey design.
More recently, developments both in the sociology and history of science and in the philosophy of science have begun to question this orthodox model.
They point out that in the history of science it is  clear that social and political factors play a great part in determining which theories are held on to and which are rejected; certainly they play at least as great a part as the degree to which a theory is seen as having evidential support.
This is also consistent with some of the claims of the newer philosophies of science which recognise that theories are under-determined by the nature of the world.
That is, it is possible to hold as true a number of theories about the world, it being impossible to choose between them on strictly evidential grounds.
Moreover, we can have no theory-independent way of describing the world.
It is theories which tell us what the world is like and we cannot make the recourse that empiricist accounts of theory wish to do, to check our theories against a world conceived independently of theories.
Such philosophical arguments can go on endlessly as is the nature of philosophy.
Despite many protestations to the contrary, its arguments fail to offer solutions to the problems of empirical research.
Because of the status philosophy has been awarded in sociology, the conception of the scientific method derived from philosophical ruminations has proved inhibiting to social research in a number of ways.
For one, the hypothetico-deductive method has too often been accorded paragon status as the form which all social research should seek to adopt.
Anything less than this is a measure of the extent to which the research falls short of scientific standards.
But (as we said before in another connection) even much of natural scientific activity does not conform to this model, is not so much concerned with explanation but with taxonomy, for example, or with finding out how things work, looking for things, and so on .
It is not that testing rigorously formulated theories from deduced hypotheses is never done, only that it is not the standard of scientificity.
It is even less so in the social sciences where there is a dearth of sufficiently well-worked-out theories to test in this way.
But testing is not the only point of theories.
Given philosophy's interest in the foundations of human knowledge it is not surprising that it should spend a considerable amount of its concern with science, the form of human knowledge which has achieved so much.
Philosophy has its own way of being interested in the world, its own problems to solve by its own lights, and these are not those of empirical sociology.
Philosophical guidance can never resolve the particular problems of social research.
THE PLACE OF METHODS
It is now time to review the place of methods in sociology.
Methodological approaches in social science emerge, develop and, sometimes, fade away.
In this respect, two factors are important to note.
First, an approach within a discipline emerges in a particular  social context marked, among other things, by influential social groups and authoritative doctrines.
Both of these will invariably influence the character of research.
Second, an approach is developed by a social group.
The perceptions a research community develops will be influenced by a whole set of factors, none more potent than the ideas and practices that have been used previously, as well as those which are seen to yield further advances in understanding.
There is an important social dimension necessary to the understanding of both the development of, in this case, methods and methodological thinking, and the kinds of presuppositions on which they are based.
There is one curious feature of sociology that is worth mentioning, namely that methods these days are largely seen as a distinctive branch of the discipline.
This is reflected both in teaching and in the fact that, by and large, textbooks are written separately to deal with methods.
This state of affairs is, if not unique, certainly unusual among disciplines.
It would be strange, for example, to see separate courses on methods for natural scientists.
Natural scientists are normally expected to acquire the skills and aptitudes necessary for research through learning the subject itself.
Research, theory and method are virtually inseparable activities within the natural sciences.
Much the same is true of history, literary criticism, law, accountancy, for further examples.
There are, no doubt, many reasons, historical and intellectual, for this distinctive disjointedness between methods and what is regarded as the substance of sociology itself.
One consequence, however, is a prevalence of the view that sees methods as more or less atheoretical tools.
Research methods are to be treated as a collection of tools designed and thereby suited for particular jobs.
Research is simply a matter of defining one's problem and selecting the appropriate tool or method for that problem.
This implies, of course, that each method has only a limited potentiality and, to this extent, particular methods can be used only for certain kinds of research objectives.
There is more than just an element of truth in this conception.
Our quarrel is with the notion that underpins it, namely that methods are atheoretical which makes it seem that the choice of a research method is governed by technical criteria.
While it is often the case that methods are treated as if they were tools in a tool box ready and waiting to be used for their appropriate task, it is vitally important that any aspiring methodologist does not take this too seriously but tries, instead, to understand the presumptions which underpin methods.
What we want to emphasise is the theoretical context of method and how this is integral to sociological investigation, not simply as a technique but as something which has profound significance for the possibility of sociology itself.
After all, since much of social research requires a direct encounter with the everyday social world, the act of research can be immensely revealing about the nature of social life.
Though here we do not intend this as anything more than a thought-provoking remark we shall see, in connection with the interview method particularly, how much of the technical apparatus of methods requires conceptions about the nature of social encounters.
One upshot of the tool box view is that it invites us to use data generically with little regard for the theoretical auspices of the method.
This sits easily with the view summarised earlier that there are "facts" in the world, recorded in various ways, and the task of research is to gather the appropriate ones in light of the resources and circumstances affecting the particular research project.
It matters little whether the "facts" have been produced by questionnaires, found by searching through records, or are the result of a period of participant observation.
There may be problems of a technical nature, but these are of little substantive consequence for sociological theory which is capable of being sustained, or not, by data culled from a variety of sources using a variety of methods.
However, some research methods, along with the data produced by them, are approach- or theory-specific in that they developed within, or have come to represent, a particular theoretical tradition or perspective.
Participant observation, for example, although it developed more or less outside of any strong theoretical tradition but simply as a way of getting research of a particularly descriptive kind done, in sociology has come to be closely associated with the symbolic interactionist tradition.
By contrast, the social survey was developed as a more generic method.
Although the line between the theory-specific and the more generic surveys is a difficult one to draw, it is important as a reminder of the very important point that methods do have theoretical implications of a profound kind, even if these are not always easy to determine.
We have come a long way in this preliminary discussion without saying anything about what actually counts as data in the social sciences.
It has to be admitted that there are problems with trying to state what data are without appearing to stipulate their character in advance.
Just as different theoretical schools within each of the social sciences, as well as the disciplines themselves, have various views about the nature of human behaviour, how it is conceptualised and conceived, the way in which this should be investigated, then they will also have different ideas about what sorts of things are to count as data.
Some would even say that the very term "data" limits the possible options in this respect by implying that there are special kinds or orders of phenomena which qualify as data.
Behaviourists, for example, want only to treat of overt behaviour as the data for psychological research and this is as much a theoretical specification of what, for them, is to count as data as experience and meaning are for non-behaviourists.
Durkheim sought to establish the scientific  credentials of sociology by arguing that it should be concerned only with its own special order of "social facts" ; that is, those events and processes which possessed the qualities of externality, constraint and generality.
Examples of such "social facts" included language, law, custom, economic and political organisation, and so on.
In both of these examples, and there are others, only certain phenomena could qualify as data.
In the human sciences data can encompass narrowly conceived bodily movements, complex packages of statements about motives and attitudes, quantitative descriptions of whole aggregates of people, including whole societies, and highly detailed qualitative descriptions of the life of a group or community.
That these, and other materials, are taken as data in research projects is determined not only, or even mainly, by the subject matter of the research, but also by the theoretical presuppositions informing the study.
In the end, of course, what is to count as data is whatever materials are grist to the researcher's mill; whatever it is that he or she wants to work with.
The historian Lawrence Stone, for example, in an extensive study of the transformation of the family and marriage in England from 1500 to 1800 made use of personal documents, diaries, autobiographies, memoirs, domestic correspondence, handbooks, newspapers, reports of foreign visitors, imaginative literature, art, housing plans, modes of address between husbands and wives, folk customs, legal documents, and demographic statistics.
Although this is both extensive and varied by the standards of most of the human sciences, though perhaps not of history, what it illustrates is the difficulty of specifying what is to count as data beyond saying that it is whatever material that researchers need to work with in order to pursue their inquiries.
None the less, it is necessary to point out that there have been a number of attempts to develop what might be called, "theories of data" , that is to specify what can count as suitable data for scientific disciplines: some of these we shall be looking at in this book.
One such influential doctrine of this order which, though now discredited in its strong form, still influences methodological thinking is the notion of "operational definitions" .
This, in brief, stated that the meaning of a concept is whatever can define that concept in terms of  "operations" , or measures, of observable features of the world.
Thus the definition of IQ, under this doctrine, would be whatever an IQ test measures.
A more extended example can be provided by the notion of alienation.
One tradition argues that this concept refers to a "state of mind" , one that expresses withdrawal from or disenchantment with the life that one leads.
Less broadly than this, it can be used to refer to a disenchantment from more specific areas of a person's life, such as his/her work, or from politics, or from religion, and so on.
In which case a researcher's task is to translate this rather abstract and vague  notion into some operational form.
On this rendering of alienation as a state of mind the most usual form of this would be as an attitude scale consisting of a series of statements judged to express alienative feelings, and to which subjects have to respond in terms of their agreement or disagreement.
An example of such a statement might be, "For me life simply has no meaning" , or, "Even when I am enjoying myself I often feel that I don't belong" .
A scale of this kind would normally consist of a number of such statements.
But the point is that the scale constitutes an "operational measure" for the theoretical concept of alienation.
It effects a translation between the theoretical language and the empirical world by, in this case, constructing a putatively quantitative description of a concept in the language of social research.
However we do not want to engage in the quantitative issue for the moment, but stay with the relationship between the theoretical concept and its operational definition.
Theoretical concepts are, by their nature, much wider in their meaning than operational definitions.
To refer back to the above example, the statements selected could not exhaust all the possible statements that could have been used.
Further, researchers have to take practicalities into account.
It may be, for example, that an attitude scale, for whatever reason, could not be used as an "operational measure" .
An observational study of a production line, say, although it might want to talk a great deal about the alienative effects of such work, could not make use of an attitude scale in the way that a questionnaire study might.
In this case, then, what is the relationship between one measure and any others than might be used?
The answer to this is as much a theoretical matter as it is a methodological one.
The doctrine of operationalism took a particularly extreme view on this issue by stipulating that the meaning of a concept consisted in the operations required to measure it.
Thus, strictly interpreted, the meaning of the concept "alienation" is the attitude scale used to measure it.
Of course, the implication of this is that a different measure is also a different concept.
This is hardly a satisfactory conclusion and not one seriously intended by the doctrine itself.
Instead, the orthodox presumption is that the same concept can be measured in different ways using different indices.
Different indices represent the ingenuity with which the theoretical constructs can be made to produce satisfactory elaborations that result in different indices and, equally important, the extent to which different indices can, plausibly, be said to measure the same concept.
As we shall see in Chapter 3, this conception of measurement, although originally proposed as an account of scientific measurement in general, bears only a superficial relationship to much of measurement in science which is an activity much more integral to substantive theories than it is in most social research.
What we referred to as "theories of data" , though originally concerned with the mathematical structure of quantitative data in the social and the cognitive sciences, is a notion that can be usefully extended to encompass the relationship between theory and data more generally.
It would, of course, under this wider conception also include "instrumental presuppositions" as well as the more abstracted philosophical discussions already mentioned.
What the notion is intended to emphasise are those issues to do with the how and the why of sociology's empirical reference.
We take it that the point of theories, and from this the point of research, is to offer adequate accounts of the empirical world as conceived as the domain of the discipline to which the theory belongs.
There are a number of philosophical accounts of how, in science, this is achieved.
Its more practical aspects have to do with what we referred to in Chapter 1 as the "inferential structure of data" : that is, how to effect a connection between the empirical materials, whatever their character, and our theoretical knowledge.
The chapters which follow will deal in more detail with the various theories of data involved in the use of social research methods: there are a variety of these, often connected to the same method, just as there are a variety of perspectives in sociology.
There is no one solution to sociology's empirical reference, no clear idea as to whether there ever could be, no one canonical method for all sociological research, and no one conception of data: data are whatever a researcher can make useful for meeting his/her research objectives, aims or problems, which is not to say that just any old thing will do.
Material has to be made into data and this involves a structure of inference that directs the material to research problems.
One common division in social research that needs to be addressed is that between allegedly different kinds of inferential structure encapsulated in the dichotomy between qualitative and quantitative social research.
QUALITATIVE VERSUS QUANTITATIVE RESEARCH
This is another of those methodological issues which can quickly rise to the point at which it becomes a major issue of principle, and usually a matter of philosophical principle at that.
Thus, the issue can be joined as human beings are not like the objects of physical science and therefore cannot be quantified, that human action is concerned with meaning, reasons, intentions and understandings and this, therefore, is an interpretative matter rather than a phenomenon subject to causal explanation, that qualitative studies are not really scientific, and so on.
The upshot is that it looks as if major and fundamental matters are at stake about the very nature of sociology itself and that, accordingly, a choice has to be made, and made soon.
Further, it is a debate which displays all the symptoms of degeneration in argument that sociology is too often heir to, namely thinking about issues in dualistic terms; that, in this case, the choice is between two sides, the quantitative and the qualitative and that one cannot have both.
This not only serves to give the issues all the appearance of being fundamental and crucial, but also conceals the fact that matters are not so simple as to be accurately captured by such a dualistic portrayal.
Thus, we have a collection of antimonies which pretend to describe the two sets of methods: hard versus soft, explanatory versus exploratory, objective versus subjective, causal versus interpretative, generalising versus particularising, rigorous versus unrigorous, and so on.
Such labels, of course, not only represent an attitude toward particular styles of social research, differences in theories and philosophies, but also point to significant methodological issues.
However, it is important that the latter are seen as methodological issues to be faced rather than as postures to be taken in advance of looking closely at them.
Though we shall have much more to say on the issues that allegedly divide quantitative and qualitative methods in later chapters, the kind of choice just alluded to is neither urgent nor necessary.
It is the nature of the research problem that should dictate the appropriate research method; sometimes quantification is required, sometimes not.
There is no intrinsic virtue to either style of method.
What we are being asked to choose between are promissory notes, not achievements.
There is a great deal wrong with quantitative methods just as there is a great deal wrong with qualitative ones.
Both kinds are, as it were, in much the same boat.
Both have much to do to achieve the aspirations they set themselves: we cannot choose between them in terms of which of them is going to take social research forward.
We simply do not know.
This is not to say that a preference for one style or the other is inappropriate; it is to recognise that both are still in their infancy and neither one markedly superior to the other in all respects.
Of course, none of this is intended to imply that there are no important differences between the two styles of social research, for clearly there are.
But the structures of inference involved are not so easily captured by the dualistic thinking spoken of earlier.
For example, there is a considerable amount of interpretative work involved in quantification to secure the link between the raw data material and the number systems employed.
Further, many qualitative-type studies would make claims to generality and rigour.
Similarly, questionnaire designers are keenly sensitive to questions about meaning as a prerequisite for framing their questions appropriately, constructing attitude scales, as well as interpreting the results.
They may not, it is true, hold to the conception of meaning which, for example, many interactionists would, but this is, again, a matter for serious analysis and argument rather than sloganeering and  posturing.
It is not, accordingly, that there are no debates or issues here; on the contrary.
But what their character is not is adequately portrayed by the gross distinction between quantitative versus qualitative.
One has only to think of the variety of positions that can be taken with respect to qualitative and quantitative research.
Durkheim, as an ardent positivist, urged and pioneered a way of thinking sociologically that lent quantitative data to the testing of theoretically derived hypotheses.
Weber, in stressing the meaningful and subjective character of social action, emphasised the importance of interpretative understanding as a method for securing causally adequate explanations of social phenomena.
Some symbolic interactionists inveighed against the "quantomania" of variable analysis and argued in favour of a more interpretative approach to the study of social life which, for some, was more scientific than variable analysis.
More recently, there have been critiques from ethnomethodology concerning the categorising procedures of variable analysis which, they argue, owe more to the needs of quantification as proposed by variable analysis than to the properties of social activities themselves.
Yet, this is not an argument against quantification per se, only against its premature use in advance of knowing what the mathematical properties of the phenomena of social life might be.
The issues are complex, varied, resistant to easy resolution and, of course, immensely important: far too important to be encapsulated in a simple dichotomy between quantitative versus qualitative research.
THE SOCIAL SOURCES OF DATA
A further reason why such dichotomies as are embodied in the quantitative–qualitative distinction should not be allowed to dominate our thinking is that they tend to obscure the sheer and sometimes bewildering variety of materials that can qualify as data.
The example of Stone's materials cited earlier is an exemplary case of this in one study, but as a feature of social research more generally it is not excessively so.
Sociologists have made use of, and again only for brief example, fragments of conversations, records of various kinds, photographs, letters, paintings, attitude scales, film and video, not to mention the materials produced by the more orthodox of research methods such as the questionnaire and the interview.
However, in light of what has been said earlier, it should not be thought that data materials, to call them that, are always restricted to one study, or that the study which originally produced them is their only home.
Attention to the instrumental theories underpinning data should point toward the fact that materials are often open to varying interpretations; another way of expressing the idea that theories are under-determined by data.
By this we do not mean to imply that any  old interpretation will do because, clearly, there are standards involved in any inference from the data materials to the theory, be this a substantive sociological theory or what we have referred to as an instrumental theory.
An example of this process is the secondary analysis of data.
We have already remarked that data collection is increasingly prevalent in all kinds of organisation, much of it intended to monitor the performance of the organisation itself.
In this respect the various branches of the state are important, economic statistics being simply the most well known.
Further, given the cost of large-scale social research, it is tempting to tap these rich resources of data, often for purposes other than those originally intended.
The use of official statistics, for example, has a long history in many of the social sciences.
Once again there are different ways in which such data are used, but all share the object of analysing the data anew, using them for different purposes than originally intended.
A prevalent use involves showing that the conclusions originally drawn are unwarranted, even incorrect.
However, a rather more theoretically informed use of secondary data is exemplified in the work of, again, Durkheim who made use of official statistics in his study of suicides in Europe, particularly France, to demonstrate the validity of his theories of the social causation of suicidal behaviour; an objective for which the original statistics were not intended.
Whether or not Durkheim was justified in using such data as he did has proved to be an enduring and important debate ever since the study was published.
What Durkheim did was transform or recontextualise the official statistics, which he well knew were less than satisfactory in many respects, produced by officials for administrative purposes, and relate them to his theoretical concerns.
Others have challenged the assumptions and interpretations offered by Durkheim and, in so doing, made important elaborations in sociological theory; elaborations which have profound methodological consequences.
(See Table 2.1.)
For our purposes what is important here is the way in which the data materials were transformed by deploying a different theoretical perspective.
With reference to the official statistics, Durkheim did this first of all by regarding the rates compiled by officials in the pursuance of their routine duties as not so much a simple factual registration of certain types of death, but as indicators of a "suicidogenic" current caused by various states of society itself.
Much later in the debate, and in time, the same "raw data" were transformed yet again, this time seen as the negotiated outcomes of actors"methods, particularly the police and coroners, for making sense of and constructing their courses of action which are only imperfectly, if at all, reflected in the figures.
This, once again, illustrates how data are intimately responsive for their sense and their meaning to the theoretical context in which they are placed.
To refer to a method we shall be discussing more fully in Chapter 3, we can see much the same sort of development with respect to the survey.
Used originally to discover demographic facts about a population, this was later widened into seeking from respondents facts of other sorts, such as marital status, housing conditions, levels of education, leisure use, and even attitudinal materials.
Thus, the accounts offered by respondents of their experience, their conditions of life, etc. were taken as indicative of a fairly static fabric called the "social structure" .
The theory, if such it can be called, which underwrote this use of the survey, was a "naive empiricist structuralism" according to which social structural facts about a society were susceptible to factual observation and description using the survey method.
Finding out the "facts" characteristic of a people who constitute the population of some society, usually a nation, is seen as the essence of social scientific investigation.
Significantly, the use of interviews and questionnaires in mass surveys depended upon the notion that the responses offered by respondents about their conditions and experiences were almost as good as the direct observation of the respondents and their lives; a far greater coverage of the population could be achieved than by using observational methods.
This is, perhaps, the closest that social science has come to pure "empiricism" or, as it is sometimes referred to, "vulgar fact gathering" .
Yet, it is important to note that theoretical interpretation, even if unacknowledged, was involved.
For example, taking the answer given by a respondent to a question as equivalent to direct observation of the event to which it refers, was an assumption upon which the method rested.
It is an assumption which amounts to an instrumental theory about the relationship of types of questions to  types of answers and both of these to the context in which answers are elicited.
It also commits the user to more typical theoretical questions to do with the nature of the social structure, its facticity, and so on: many of these instrumental and other theoretical conceptions have proved less than durable.
Certainly, more modern uses of the survey method have disregarded some of the rather naive methodological assumptions of the early surveys.
In the 1940s and 1950s, especially in the United States, data produced by the survey were differently deployed.
It was argued that social acts were essentially motivated behaviour and could be properly understood and explained only in terms of these underlying dispositions.
So, data generated from surveys were used to infer the "latent structure" of respondent attitudes and motivations.
Rather than seeing responses to questions as simple indicators of factual properties, these theorists saw them as data from which it was possible to make inferences about the dispositional and motivational character of social actors' behaviours.
These, in their turn, were seen as indispensable for the explanation of actual behaviour.
In a very real sense, although answers to questions are being elicited in both approaches, the data that result are fundamentally different.
Not only do the questions differ, the one asking about "factual" information, the other about attitude or belief, but also the answers are used in different ways.
For the early empiricists the answers taken in conjunction with other facts about the social structure add up to a description of a particular society.
For the latent structure analysts, however, the answers index deeper motivational and disposition characteristics of social actors and, when appropriately processed, reveal a respondent's psychosocial orientation which can then be used to explain social conduct and behaviour.
The kind of theory invoked by latent structure analysis was basically socio-psychological and cultural.
The argument was that different components of personality are built up in particular individuals as a consequence of cultural conditioning.
Hence, the aim of the analysis of attitudes was to reveal the hidden patterns typically sedimented in particular social and cultural contexts.
Having a distinctive view about the origin of personality, as well as the structures they might find, these survey users were not nearly so preoccupied with representative samples, but rather with analyses showing intercorrelations between sets of attitudes and other social behaviour.
The importance of these examples is not simply to reinforce the general point that data materials, whatever else they may consist in, have to be "read" through, in terms of, a theoretical framework to exist as data, but that the theoretical significance of such materials can change.
Often, too often perhaps, the impression is conveyed that data are separate from the purposes for which they have been gathered, that  data can exist, as it were, on their own.
Data are always contextualised even though very often the context is vague, indeterminate and, as these examples illustrate, open to change.
The inferences that may be placed in data materials can and do change as theoretical frameworks change and shift.
Not in a haphazard or whimsical fashion, but as knowledge itself changes.
It could be said that from the point of view of social research, the world only exists as data and data can exist only through the interpretations placed on materials gathered from the world.
In which case, how is it that theories are tested by data?
If, as we have been suggesting, the nature of data has much to do with the theoretical presuppositions which underlie their production, how can it be said that theories are tested by means of exposure to data?
Theory looks to be testing theory.
Moreover, if we examine social scientific practice at all closely we can often see how substantially the same data can be used to support or discredit very different, sometimes contrary, theories: the generic use of data and methods should not make this too surprising an observation.
Indeed, social science theories are under-determined by facts.
There are a number of reasons for this, many of them constituting significant areas of debate within social science methodology.
One has to do with the fact that many theories in social science are not so much theories susceptible to straightforward empirical confirmation or refutation, but are more like points of view.
Marxism, functionalism, symbolic interactionism, marginalist theory in economics, and so on, would be examples of this.
Such theories, or perspectives, are really agendas for research programmes.
It is not that such agendas are unresponsive to data but they are not responsive by way of direct testing.
Their main role is providing ideas and means by which the world can be investigated sociologically; in Lakato's words, they represent a discipline's "research programmes" .
Another reason has to do with the relative imprecision with which those theories that, arguably, are more susceptible to direct testing are couched.
Very often they do not, unlike many natural scientific theories, suggest direct ways of measuring the concepts employed, and, because of this, it is difficult to determine what the limits of a theory might be.
A third reason has to do with the non-experimental character of most social research.
This means that it becomes difficult, some would say impossible, to specify the ceteris paribus conditions of a theory.
Newton's law of falling bodies postulates a uniform rate of fall for all bodies in a vacuum other things being equal; a condition which enables the theory to assume a very precise quantitative expression to the theory itself.
So, the paradox noted earlier is a paradox only if we adopt a particular and constrained view of what theories in social science are about, what role they play in the process of acquiring knowledge.
As things currently stand, and there are no  compelling reasons to think that matters will suddenly change, there are few theories which could meet the standard of being directly testable, though there are more subsidiary theories within larger frameworks which do gain, or lose, plausibility in light of empirical evidence.
An example of this might be the "embourgeoisement theory" which enjoyed widespread currency a few years ago in sociology, and which argued that the "working class" , in Britain, were becoming more like the "middle class" in their aspirations, consumption patterns and political views.
But it is important to note that there was no one study which established or refuted the theory.
What studies did contribute to was its amendment, its clarification, its reinterpretation, its revision, its incorporation and almost replacement by other perspectives, in light of accumulating evidence from a wide range of studies.
And this kind of process, one might add, is not untypical of the career of theories in natural science.
Sudden death is rarely the fate of a theory; a slow ageing to redundancy is the more usual end.
CONCLUSION
The foregoing discussion has tried to make and illustrate the point that research methods cannot stand in isolation from the theoretical and conceptual issues which constitute the social sciences.
While problems of method have their technical aspects — such as how many people should be interviewed?
How long shall a group be observed?
What is an acceptable chi-square value?, and so on— little of this will cast very much light on the crucial issues of method, namely what shall we study?
What we study follows from theoretical or more broadly, disciplinary concerns rather than technical matters.
We hope to show that methods are not, and cannot be, selected according to the qualities of the data they yield alone.
The richness of the data sought by participant observation methods, for example, and the "objective" and representative data sought by the survey are not, by themselves, virtues.
The point is that they are deliberately sought because some reasoned theoretical considerations are felt to require them.
Of course, such considerations may turn out to be erroneous; but the choice is, or ought to be, a reasoned one.
So far we have been raising rather large issues in an abstracted and certainly general fashion which, it is to be hoped, will become clearer as they are filled out in what follows by way of the discussion of specific methods of data collection.
Finally in this chapter we want to return to the source of all social science data, and the ultimate object of social scientific investigation, namely the members of society.
Social science is concerned to understand, explain if you will, the social origins, context and consequences of what the members of society do, the relationships they form, what they believe in, think  about, pray to, fight about, collaborate on, discover, create, build, buy and sell, produce, and so on.
Although the various social sciences take different interests in such matters and differ also on how such an understanding of them can be achieved, they do at least share this common source of data; that is, what the members of society have produced, and are producing, in the way of artifacts, social groups, institutions, documents of various kinds, systems of conflict and co-operation, records, and so on .
Very generally we can categorise what this source produces by way of data into the following elements: first, what people do, their acts and behaviours; second, the thoughts, beliefs, aspirations, values and motives that people hold; third, their speech, either verbal or written, which accompanies both of the above.
With respect to all of these elements there are widely different interpretations both as to their nature and as to the relation between them; all of which have profound methodological consequences.
However, conventionally, which is not to say correctly, modes of social scientific explanation tend to see these elements as analytically separate orders of phenomena and, accordingly, data.
On this view, one of the more important problems of methods is to relate these various elements together through some inferential apparatus in systematic ways.
Thus, the interview is often used to inquire into the beliefs and values of a particular social group on the supposition that these are crucial to the explanation of the behaviour of the members of the group.
This could arise, for example, in researching into the voting behaviour of, say, white-collar workers, or the differential rates of absenteeism among workers within a particular plant.
The beliefs are seen as influencing, at least in significant part, the behaviour in which the members of the group engage and which distinguishes them from other groups who hold different beliefs.
The methodological problem arises because beliefs, attitudes, values and other so-called subjective states cannot be directly inspected.
They have to be inferred usually from some form of verbal behaviour, such as responses to attitude scales, or to questionnaire items.
In turn this leads on to the problems to do with the extent to which, and the conditions under which, respondents accurately report their beliefs, attitudes and, ultimately, to the extensive and impressive technology of interview and attitude measurement.
Some of these issues we shall deal with more fully in Chapter 5 on the interview.
The point we want to make for immediate purposes has to do with the way in which methodological problems arise from particular conceptions of the "order of things" .
In other conceptions, for example, problems of the kind just reviewed do not arise.
It is argued that the distinctions noted earlier are by no means clear and that behaviour cannot be identified in isolation from speech and so-called "internal mental states" .
Such elements are not, logically speaking, analytically independent.
There is a further theme to do with the collective nature of social life.
All the social sciences are predicated on the notion that individuals are not isolated like so many Robinson Crusoes — who, in any case, was already a social creature by the time he was shipwrecked on the island — but are related to others in complex ways.
Human beings form economic relations of many kinds with one another, involve themselves in political relationships or religious ones, live within many kinds of groups, and so on .
As Durkheim and others have tried to demonstrate, these relationships seem to have an independent existence over and above the individuals who compose them.
Individuals live and die, but economic, political and religious systems, for example, show durabilities that go beyond the lifespan of any one individual.
The methodological problem arises, it is argued, because all we can observe and gather data from are individuals.
Only individuals can fill out questionnaires, be interviewed, respond to attitude scales, be observed, and so on, and yet, very often, these are used as evidence for, or descriptions of, the supra-individual phenomena to which we have just referred.
Accordingly, some theoretical and methodological grounding for this transformation needs to be provided.
As we shall see in Chapter 4, it is the absence of this grounding that opens some methods to the charge of excessive individualism.
There are many problems here and we cannot hope to deal with all of them adequately, not simply because of limitations of space but, more importantly, because many of them are, as yet, problems to which there are no satisfactory answers, no clear solutions or, very often, many possible solutions but no clearly superior one.
What we hope to have shown so far, if only in a general way, is the vital link between theory and method which is so essential to a fuller understanding of methods of data collection.
Chapter 3 begins a discussion of one inferential structure that is predominant in social research, namely variable analysis and its approach to data, measurement and theory building.
This is important since it informs much of the discussion of substantive methods which, these days, are associated with this mode of social research, namely the survey and the interview.
Variable analysis and social measurement
What we intend to do in this chapter is discuss the inferential structure that forms the backbone of many of the methods of data collection currently in use.
Although, and it is important to stress this, most of these methods arose and developed from a diverse range of sources and traditions, their contemporary unity was a rather later achievement, as that collection of ideas we can refer to as variable analysis.
Broadly expressed, variable analysis is the disposition to see and describe social life as a collection of variables which, potentially, can be quantified and the relationships between them also measured and described in quantitative terms.
These days it is not unreasonable to present variable analysis as a relatively coherent approach to social research, some would say the approach, which embraces not only the technical matters to do with data collection and analysis but also, importantly, a way of thinking about theoretical and empirical problems.
Some go so far, though this is an excessive claim, as to argue that variable analysis is the embodiment of the scientific method, while more, if less fulsomely, do make strong claims for it as the epitome of objective, rigorous empirical social research against which all others are to be judged.
While we do not wish to go even this far, there is no doubt that it represents a powerfully persuasive tradition of social research.
It is often equated with the explanatory social survey (as we shall see in Chapter 4) and although this may well be its prime expression, the logic and the impulse of variable analysis is somewhat wider than this being devoted to securing a more general basis for quantification in social research.
A separate section in this chapter is devoted to the topic of measurement itself.
The key figure in the initiation and development of variable analysis was Paul F. Lazarsfeld, who worked at Columbia University from the 1930s to the 1950s and who, with colleagues such as Stouffer, Thurstone, Rosenberg and Guttman, pioneered what was to become the orthodox mode of social research.
Their work had a considerable impact on both the thinking and the practice of social research, including some of the highly mathematised branches of social research.
Indeed, as far as the latter are concerned a direct line  of descent can be traced from the work of Lazarsfeld and his colleagues to the modern mathematical and statistical modelling of social data.
Many of the techniques that came to be associated with variable analysis, the survey, cross-tabulation, indicators, covariation, to mention but a few, were not all invented by Lazarsfeld and his co-workers, though a number were, but begged, borrowed and stolen, from a variety of other fields and brought together as a distinctive and integrated way of constituting a theoretically informed and theoretically consequential empirical social research approach.
Of course, what became this major achievement did not happen overnight.
Rather, it evolved in fits and starts as its various components were deployed in a variety of areas producing what quickly became classic studies and the base line for a growing corpus of social research findings.
Here, it seemed, was a method capable of testing theoretically generated hypotheses by expressing the hypothesised relationship between two or more factors quantitatively and, so it was assumed, objectively.
These days, of course, the relatively primitive Lazarsfeldian methods have grown into the full mathematical eloquence of causal modelling, factor and cluster analysis, and more, encouraged by the power of the modern computer to handle larger and larger data sets and their mathematical analysis.
However, Lazarsfeld, though primarily a methodologist, was no mere technician.
He had briefly been involved with the Logical Positivists of the Vienna Circle and developed a strong leaning toward the importance of systematic empirical observation as the cornerstone of the scientific method, and a corresponding dislike of abstracted theorising and metaphysical speculation.
Despite his European background he developed a detached, almost apolitical style of social research.
For him, and ultimately consequential as one of the prime presuppositions of variable analysis, science does not deal with "things-in-themselves" but with their manifested properties or attributes.
It is the attributes or properties of some phenomenon that are exhibited, revealed, discovered and which are measured; never the "thing-in-itself" .
Science does not deal with its objects of study in their full concreteness.
Science's empirical connection to the world is an abstracted, or selective, one dealing with the properties, attributes or qualities of phenomena rather than with the phenomena themselves.
We do not, for a simple example, examine heat directly but through, for instance, the property it has of causing certain metals to expand at uniform rates: a property which enables us to construct mercury thermometers which are capable, within reasonably precise limits, of measuring heat.
In which case, and on this conception, a great deal of scientific activity, including its laws and theories, is concerned to measure and, through this, examine the observable properties of phenomena.
Again for example, the property of heat to expand metal at uniform rates is a great advance on the common sense distinction  between "hot" and "cold" .
We can now speak of quantities of heat and use this to develop better and better theories and laws of thermodynamics.
Developing better and more precise measurement of the properties of phenomena is the key to the progress of scientific knowledge.
But this process is two way: it is also better theories which allow us to develop more precise measurement.
In this respect the human sciences should be no different.
Where they do differ is that they know a great deal less about the properties of social and psychological phenomena than do the natural sciences about the properties of the natural world.
There were, and still are of course, immense difficulties in the way of quantifying human phenomena, some of which we shall touch on later.
None the less, since antiquity there have been many efforts to describe features of the world, including the social, in quantitative terms, efforts which began to assume an even greater urgency and consequentiality with the rise of the modern nation state and its requirements for an accurate accounting of its resources.
The modern census is but one expression of this movement, as well as the development and vastly increased scope of economic statistics and other methods of social accounting.
But none of these efforts, important as they were, amounted to a mathematised science in which theoretical relationships could be expressed mathematically or, less ambitiously, subjected to stricter testing through measurement.
Nevertheless, a start needed to be made somewhere to build a cumulative and objective body of knowledge of the relationships between the properties of social phenomena as a prelude to the formulation of substantial theoretical laws.
They did this by emphasising the development of measurement scales by which data could be systematically organised and available for various forms of mathematical manipulation.
What was at stake was not merely organising data in this way, but this was an inferential structure that could be used to accumulate knowledge systematically and, little by little, develop laws of social life.
It was to building this basis that Lazarsfeld and his colleagues devoted much of their energies.
Up to the 1930s the bulk of quantitative social research had been largely demographic in character.
Although Durkheim had made use of official statistics and standardised arithmetic procedures, such as averages and percentages, for theoretical purposes, the connections he made between the data and his theoretical conclusions were largely impressionistic if, from his point of view, effective enough.
It was due to scholars such as Lazarsfeld in providing a logic of social research which encouraged the making of the connection between research problems in biology, particularly eugenics, which had stimulated the development of inductive statistics, and those of social research.
This led to the incorporation of statistical techniques of inference into empirical social science.
None the less, it had to be faced that most, if not all, social science theories, with the possible exception of those of economics, left a great deal to be desired if quantification on the natural science model was to be achieved.
Most theories were little more or less than an integrated set of concepts or too impossibly abstract to have much direct relevance for social research.
The only route to more empirically grounded theories, according to what became the Lazarsfeldian programme of social research, was to develop suitably confirmed empirical generalisations across a range of studies and problem areas, and this would require the effective translation of concepts into empirical indicators; translate, that is, concepts into the publicly observable.
To achieve this Lazarsfeld borrowed a notion from mathematics and logic, that of the variable, and used it to create a way of thinking about social science in both its theoretical and empirical aspects.
THE IDEA OF THE VARIABLE
Thinking of social organisation and processes in terms of variables is now commonplace.
It is a common strategy, for example, to think of analysing or decomposing a construct into a number of dimensions or variables.
A well-known example is Merton's suggestion that there are degrees of conformity to cultural goals, differences in the willingness of groups to innovate, and so on.
The device of constructing typologies to distinguish and, then, compare and contrast phenomena, as well as efforts to measure such differences through organising relevant data, is a predominant feature of sociological thinking and research.
Typologies such as traditionalism, rationalism, affectivity, industrialism, and many, many more, all reflect what is now known as variable analytic thinking.
So common is this way of thinking in social research that it is difficult to recapture its radical and innovative character.
It is a way of thinking that is predominant in social research and to a considerable extent in social theory, too.
For many, one of its important features is that, as a method, it is theoretically unspecific.
It belongs to no particular approach but is a means of linking theory with empirical analysis to the betterment of theory.
The basic requirement of the approach is to think about concepts as empirical variables which can be measured through indices.
This enables the data to be searched for patterns so placing theories within the constraints of empirical evidence.
Indeed, it is through data collection and searching for patterns in those data that theory is elaborated.
Lazarsfeld's contribution to the development of variable analysis was pivotal both as thinker and as teacher.
His idea was that social phenomena can and should be measured in a way similar to the way physical properties, such as size, weight and temperature, are  measured.
He recognised that the metrication of these properties had to be constructed, that measuring devices, or units of measurement, had to be devised, and so it should be for social and psychological phenomena.
On the Lazarsfeldian conception, people, or any unit for that matter, can be treated as objects displaying properties such as age, gender, social class, status, intelligence, attitudes or beliefs.
But the trick was to think of these properties as mappable; that is, capable of being thought of as dimensions in space.
To this end he used a metaphor drawn from mathematics, the variable, to create "devices by which we can characterize the objects of empirical social investigation" .
The idea of a variable is simple enough.
A variable, as opposed to a constant, is anything, any attribute, that can vary in value; that is, take at least two values.
Such values can be 0 or 1, where 0 might indicate the absence of some property, and 1 its presence.
Thus, if a researcher was interested in the property of home ownership, 1 might indicate a "home owner" and 0 a "non-owner" .
This is a very minimal level of quantification, if quantification at all, but at least we can add the frequency with which these values occur within some collection of persons.
We could describe the distribution of the property among some population.
If, in addition, we had a similar frequency count of another property, say level of income, and looked at their mutual distribution, their covariation in a word, we can see how strongly the two properties, the two variables, are related.
Of course, other concepts, other properties and attributes, could make more significant use of the properties of number systems other than their ability to classify.
 "Power" , for example, is an ordinal attribute in which we might want to talk about individuals having "more" or "less" power than others and to reflect this in using the power of numbers to reflect "more" or "less" of some attribute in the same way that a higher number score on a test signifies a greater ability to do the test than a lower number.
The point is that by thinking of concepts as variables we also begin to think of suitable ways of reflecting their character by numbers.
In significant respects, Lazarsfeld's proposals were both bold and radical.
The route to quantification, he urged, could be secured through the notion of the variable; a format that could be applied not simply to properties which were self-evidently quantitative, such as money, but also to qualitative materials.
By simply recording the presence or the absence of some property a level of quantification could be attained; certainly sufficient to allow for the examination of the joint frequency and occurrence of a property with others.
One could go further and try to rank order properties, such as "power" and "status" , which would give a yet higher level of measurement.
But the idea of the variable was only part of the revolution.
What Lazarsfeld was after was a way of searching for patterns in data, patterns exhibited between variables, and patterns that, if confirmed  regularly across studies, could stand as statements of empirical relationships between phenomena.
Thus, we could begin to provide statements of the form "The greater the X, the greater the Y" , "A's are associated with B's" , "Q is inversely related to P" , and so on: statements which would be supported by, and indeed describe, quantitative relationships.
To see this we need to look more closely at the essentially simple idea, taken from mathematics, of the property space.
A property space is simply a conceptually bounded area defined by one or more properties.
Location in this space can be indicated by means of coordinates, a technique familiar to map-making, graphs, gunnery, navigation, and more.
In a two-dimensional space, for example as on this printed page, every point can be fixed, and fixed uniquely, by two numbers derived from the scales measuring of the length and the breadth of the page.
However, the dimensions on which we can locate units, such as people, in some property space can be of different kinds and certainly of more than two dimensions.
We can use continuous variables, such as psychological test scores, qualitative variables, such as occupational type, or dichotomous variables such as voter/non-voter, male/female.
Thus, if we take a unit and an attribute of that unit, say a person and home ownership, the property space is defined by two values: being a home owner and not being a home owner.
These are the values the property can take and can be, as before, denoted as 1 and 0 respectively.
If, for the same unit, we take another property, say trade union membership, then, similarly, this property space is defined as trade union member — not trade union member.
Therefore, each unit can be classified in terms of these properties and can take one of four combined values: home owner/trade unionist; home owner/not trade unionist; not home owner/trade unionist; not home owner/not trade unionist.
Each unit, that is, is uniquely described in terms of these properties by one, and only one, of the above categories.
If we display the property space formed by these attributes with each attribute constituting an axis, then we arrive at Figure 3.1.
Figure 3.1 shows the joint variation of the two properties we have been talking about, and, of course, the possible values which any unit can take.
Each unit in some population can be allocated uniquely to one of the cells so giving, providing that we count the number of units  in each cell, the frequency with which combinations of the relevant properties occur.
In social research this is the basic structure of the cross-tabulation or contingency table.
As Lazarsfeld urged, cross- tabulation is the "automatic" research procedure employed in social research when faced with a relationship between two or more variables.
In actual social research such tables are generally more complex than the one illustrated here, often involving "higher" levels of measurement than the simple dichotomous attributes in the example.
None the less, they are based on this simple inferential structure which is the core of variable analysis.
The point of the structure is to find patterns of relationship among variables; patterns which can, hopefully, become established empirical generalisations and, ultimately, strongly established theoretical laws.
However, it is important to stress that this latter ambition is not one that Lazarsfeld, for one, felt could be quickly fulfilled.
Variable analysis is very much a beginning by presenting theory with reasonably well-confirmed empirical relationships upon which to work.
It offered, too, a way of testing hypotheses and theoretical predictions by providing a method for detecting whether patterns hypothesised by some theory were, in fact, supportive.
But, prior to any of the deployment of the inferential structure is the crucial issue of what properties, what variables to examine and how to reflect their character in measurement.
For the Lazarsfeldian programme this is a matter, though not a simple one, of selecting and refining indices.
VARIABLES, PROPERTIES AND INDICES
Of course, aspects of social life have been measured for almost as long as history.
Duncan reminds us of the antiquity of the propensity to quantify the doings of people in various ways.
There has long been the counting of people as one of the first activities of states (as we shall see in Chapter 4).
There are voting, taxation, efforts to measure and record social rank, attempts to fix standards for weights and measures, and above all, money.
Money is one of the more fascinating of social inventions which depends on counting as a capacity to express, in a word, measure, the social value of individuals, labour and commodities in society.
The measurement of length, area, distance, weight, and such like, was achieved long ago as an integral part of day-to-day practical activities, and later to be refined within the context of modern science.
It was within the latter context, that Lazarsfeld and his colleagues sought to apply a generic conception of measurement to social phenomena as a means of effecting the link between theorical concepts and the empirical world.
Lazarsfeld recognised that social science theories, currently and for the foreseeable future, could simply not match up to those on offer in the natural sciences.
There were no adequate generalisations to build on, let alone laws, and certainly few, if any, solidly confirmed hypotheses.
It was not so much a case of social science theories being senseless, misguided or absurd, but more to do with their serious lack of evidential support.
What they had by way of this was largely impressionistic, qualitative and suggestive rather than confirmatory.
This did not make such theories false, but it did prevent them being seriously developed as scientific theories.
The only way forward was to develop the tools of empirical research, measurement scales to facilitate the description, aggregation and comparison of data; to provide good, solidly based findings on the lines just sketched.
For Lazarsfeld, the research process began with a problem and a "vague image" of some relevant concepts and their interrelationships.
It was this "vague image" which had to be translated into a form which could be explored, even tested, empirically using the pattern-searching techniques of variable analysis.
And this meant translating the concepts into empirical indicators.
Take a common sociological concept, that of social class.
This is a concept which belongs to a number of well-known sociological theories, including those of Marx, Weber and many commentators since.
What we have are a number of ideas of what social class is as a phenomenon, sometimes overlapping, sometimes divergent.
Marx, for one example, regarded class in capitalist society as a collection of persons who have in common a particular relationship to the means of production, namely, that of ownership or non-ownership.
The bourgeoisie class own the means of production, the proletariat do not.
Weber, on the other hand, while agreeing that class had much to do with a person's economic position within a social organisation of capital and labour, departed from this dualistic conception.
For him a class was about life chances and included dimensions other than the ownership and non-ownership of the means of production.
This alone could not take into account the much finer distinctions that it is necessary to look at when determining social class.
Weber also gave more emphasis to status as a factor which, in some circumstances, could override the effects of class on social behaviour and ideas, often to the point of diminishing them entirely.
What we have here is a range of differences and similarities concerning a concept, and putative phenomena connected with it, that both scholars, and many more since, have argued and disputed over.
But on the Lazarsfeldian view theoretical debate without systematically provided empirical evidence is essentially sterile not to say unscientific.
It is, like most of the concepts in social science, a contested, relatively vague one that can only be made less vague, of greater theoretical relevance through systematic empirical  exploration.
The task is to generate indicators of the concepts in order to see better just what empirical relationships the phenomena pointed to by the concept of class might be.
Thus, it is reasonable to argue, instead of trying to determine what class is by theoretical disputation, let us recognise that what we have here is a concept which probably indicates something significant about social behaviour, but precisely what that is is not clear.
It has something to do with a person's occupation, the control and autonomy a person has, the amount of training required in order to do a particular job, the way occupation shapes life chances, income, style of life, the kind of social activities engaged in, the prestige a particular occupation attracts from others, and may be more.
So, one reason why "class" is a "vague" and contested concept is because it is multi-faceted and, as a result, it is not always clear just what possible dimension, attribute or property is being used.
Such problems, on the Lazarsfeldian view, can be sorted and clarified empirically only by, in this case, formulating indicators for each of the possible dimensions of the concept.
Indeed, on the Lazarsfeldian conception we do not need to know what class really is.
All we require is a collection of reasonable indicators which represent, to some degree which may be unknown, the concept of class.
It is the behaviour of the indicators which enables us to unravel the conceptual and definitional ambiguities.
This process of elaborating a concept and moving toward empirical indicators is the crucial step in variable analysis.
It is nothing less than the invocation of a two-language model of social scientific inquiry: that of theory and that of research; that of concepts and that of variables.
Theoretical ideas are connected to the world by a translation into an empirical language more closely attuned to the observable world.
The language of theory would be built using the terms and semantics of the language of observation.
In a word or two, it is an empiricist strategy of theory construction and testing.
Of course, the choice of indicators is not a straightforward business even though , these days, there are available a number of fairly standard ones, such as occupation as an indicator of social class.
In fact, any concept is likely to generate a number of indicators with no very clear idea, in advance of empirical inquiry, what they "stand for" .
What Lazarsfeld proposed was essentially a trial-and-error process of winnowing out the poor, if promising, indicators of a concept in favour of ones which proved effective across studies.
Finding patterns of association among indicators will enable us to determine which among them are the most significant.
It is important to recognise that the research itself, and its setting, inflicts its own contingencies on the choice of indicators: research using interviews will have to use indicators that are largely constructed out of respondents' answers to questionnaire items whereas observational studies, and Lazarsfeld did not preclude them from  variable analysis in principle, would have to use others.
Similarly, depending on the setting, some concepts would require different indicators entirely.
It is not proposed that in every case a single indicator will suffice for a concept on every occasion, and it is not suggested that in every case an indicator will fully represent the concept it is to "stand for" .
The relationship between an indicator and the property of the underlying phenomenon it represents is a probabilistic one, though the parameters of the relationship are unknown since the phenomenon itself can never be directly inspected.
It is made visible only through its indicators.
However, this is no reason for despair since it is by examining and measuring the relationship between indicators that researchers can begin to get a better idea of what are good and what are poor indicators.
If a number of studies are able to show that occupational type shows consistently stronger correlations with other variables, say voting choice, style of life, level of education or values, this is evidence that the variable occupation is a reasonably effective indicator of the important dimensions embodied in the concept of social class.
It is some evidence, that is, that the concept of social class points to a real phenomenon with stable properties as reflected in the empirical relationships among the various indicators.
Matters do not, of course, end there.
Science is importantly a cumulative endeavour fuelled by a trial-and-error process of refining theories so moving toward theories of greater scope and explanatory power.
Of course, it may turn out that what these empirical relationships show is that some or all of the original theories were wrong or, at least , insufficiently precise.
But this eventuality is exactly what variable analysis is intended to show.
Effective theory building is from discovered empirical patterns or relationships.
Armchair theorising may be a useful preliminary, a source of what may turn out to be interesting ideas, but for science to begin it must be secured to empirical results and its theories determined by them.
The connection between the world and the indices is effected by means of the interrelationships between indices and the strength and durability they display, if they do, from study to study.
Indicators are, on this conception, what social research works with and they indicate something, however well or badly, if they show detectable patterns of association with each other.
As it happened, Lazarsfeld and his colleagues recognised that it was, and still is, difficult to develop indicators for many concepts used in social science.
However, asking people to express attitudes was a relatively straightforward way of producing a large number of indicators on almost any subject that was of interest.
Attitudes could be elicited aplenty and could, contra the views of many of the early survey researchers who thought them unlikely material for social research in being basically subjective opinions, provide valuable data  if suitably measured.
The key to this was developing attitude scales, many of them named after the researchers who devised them.
One consequence of this for social research (as opposed to psychology) was to make it very dependent on the survey as a means of data collection.
As we shall see in Chapter 4, one of the first results of these ideas was to transform the social survey.
THE LOGIC OF PATTERN SEARCHING
The inferential structure of the pattern searching method of variable analysis made use of the idea of the property space and the covariation of property attributes.
It also made more than passing obeisance to the logic of the experiment which, for many and wrongly, was taken as the sine qua non of the scientific method.
The great advances in producing the laws of physical science had come about through the application of a method, one which systematically simplified the messiness of the appearances of the world, to produce the pristine laws of natural science.
The experiment was regarded as the embodiment of that method.
Essentially, the classic experimental design involves controlling all factors extraneous to the hypothesis of interest in order that this can be tested.
It was realised that the ability to experiment in the human sciences was extremely limited for a number of practical and ethical reasons.
Apart from branches of psychology, laboratory experiments in which factors were manipulated in order to achieve the necessary control were clearly impracticable when dealing with, say, the effects of educational attainment on voting choice.
None the less, variable analysis was seen to offer a surrogate way of using the logic of experimental design engineered from the idea of the property space.
Imagine that we are interested in the effect of a new managerial style on output.
In variable analysis the managerial style would be called the "independent variable" , or causal factor, and the output, or the effect, the "dependent variable" .
The simplest way would be to introduce the style and then see whether or not output increased or decreased or, even, stayed where it was.
However, we know that there are potentially many factors other than managerial style, which could affect output: a more satisfied work-force, a better trained and more experienced work-force, increased pay for higher productivity, more investment in up-to-date machinery, greater morale among the work-force, and so on.
Accordingly, to be sure that changes in managerial style have the effect found we need to take into account the actual or potential effects of all these other factors on the dependent variable, output.
In the classic experimental design a control group would be used which was as alike in all respects to the experimental group (the latter being, in this example, the workers who experienced the new managerial style), save in this one respect; only  the experimental group is subjected to the independent variable.
In which case, if all the other factors have been adequately controlled, any difference in output has to be attributable to the independent variable since it is the only difference between the two groups.
In practice, of course, it is extremely difficult to establish such a design effectively.
Normally a control group and an experimental group are constituted deliberately by matching subjects on relevant characteristics and then randomly allocating one of each matched pair to the control or the experimental group respectively.
In this example, such an endeavour could prove practically very difficult, as it is in most social situations.
Moreoever, even if one were to do this the fact of setting up the control and the experimental groups could well introduce a note of artificiality into the experiment.
None the less, for variable analysis such problems are by no means the end of the matter since the logic exemplified in the experiment can, it is argued, be replicated, at least sufficiently, by multivariate analytic procedures involving statistical controls.
In multivariate procedures the controls are deployed as potential intervening variables.
Such methods will be dealt with more fully in Chapter 4 on social surveys where the Lazarsfeldian conception became most firmly entrenched.
With hindsight, it is difficult to see quite the radical innovation variable analysis proved to be in social research.
Its advent was auspicious in that following the Second World War the strenuous efforts of many social scientists, especially in the United States, to secure a more acceptable place for social science, which itself contributed to many of the techniques which became part of variable analysis, was served by a way of thinking which seemed to offer a way of emulating some of the crucial features of the scientific method.
Sociologists, social psychologists, anthropologists and economists began to use and develop variable analysis in a series of what became classic studies.
Lazarsfeld's own contribution lay in the study of voting choice and the studies on the effects of the mass media and, during the Second World War, collaborating on studies of Nazi propaganda and race relations, among others.
These had a major impact in Britain and elsewhere and form the beginning of subsequent studies.
Statistical analysis also developed apace making use of statistical theories which had their origins earlier in the century in the work of Pearson especially.
Variable analysis welcomed, indeed required, an un- ashamed borrowing of regression and correlational statistics and, later, building these into causal models in which the weight of the effects of various variables could be determined.
Of course, none of these developments took place overnight, but their growth to some maturity had much to do with the promise variable analysis held out that this was the route toward the scientific respectability of social research methods.
Lazarsfeld's ingenious, if  ultimately flawed, step toward the basis of quantification in social research, provided, for some at least, a realistic hope that social research, through measurement and hypothesis testing, could begin to develop serious empirically based theories.
It was not without its critics, of course.
Symbolic interactionists were trenchant in their attack on variable analysis largely because of its failure to provide a sense of the processual and negotiated character of social life.
For those, talk of variables smacked too much of talk of causes with no place for the human being as agent.
(This particular criticism we shall deal with later, especially in Chapter 6.)
For now we wish to go into some detail on one of the major planks of variable analysis, namely measurement.
MEASUREMENT AND VARIABLE ANALYSIS
The history of social measurement is a long and fascinating one, certainly too considerable to do justice to here.
Our more immediate concern in this section is with measurement as understood within variable analysis.
Variable analysis stipulates that the phenomena of social research be reflected in objective, observable indicators which "stand for" the phenomenon.
No direct inspection of phenomena is possible; they can be investigated only through their indicators.
The problem here is an obvious one and has already been alluded to, namely how do we know how good an indicator is if we cannot compare the phenomenon with the indicator?
The answer is that we cannot know or, rather, that there is no simple solution to this problem.
All we have is a process of trial and error which, essentially, consists in seeing how well a particular indicator correlates with other indicators of the same concept and with other indicators of concepts presumed to be related in some causal connection.
This process of refinement within and across studies will, it is argued, slowly build up our confidence that the indicators which work are measuring something, some phenomenon, that our concepts point to.
This is never once and for all, but slowly and more or less surely.
The refinement of concepts and the steady march of trial and error depends upon not only thinking up good indicators for our concepts, but also on measuring them appropriately.
Measurement is, in many ways, the point of variable analysis and is its inferential backbone.
Measurement, and the reason why Lazarsfeld was so insistent on developing a social research format that permitted even a modest level of quantification, is one of the procedures that facilitates the mathematisation of theory, a feature which is the hallmark of the most advanced of the natural sciences, such as physics.
A standard model of the progress of science sees it as a move from classificatory knowledge to knowledge which is more quantitative in character and able to express its laws in precise mathematical form.
Quantification  provides greater descriptive flexibility and subtlety than simple classification.
Instead of "warm" and "cold" , temperature scales allow for much finer distinctions.
Relative ordering is possible; we can say that 70°F is warmer than 60°F.
Greater descriptive flexibility makes for a greater flexibility in the formulation of laws.
An increase in the temperature of a column of mercury accompanied by a proprotionate increase in the height of the column would be impossible to state precisely using classificatory concepts.
Measurement opens up the possibility of using mathematics in which to state general laws and theories such as the relation between the height of the column of mercury and its temperature.
So, the advantages of rendering properties measurable, as contrasted with simple classifications, are manifested in both the descriptive and explanatory functions of science — if it can be achieved.
For our purposes, measurement can be characterised as the assignment of numbers to some property in such a way as to effect a one-to-one correspondence between the character of the numbers and the characteristics of the property being measured.
For brevity, and without going into the axioms of the mathematics of number, the main features of numbers we need to note are order, distance and origin.
Numbers are serially ordered (1,2,3,4…n) as are the differences between numbers so that, for example , the distance between any pair of numbers is greater than, equal to, or less than the difference between any other pair of numbers.
The distance between 0 and 5 is equal to that between 5 and 10.
The number series also has a unique origin indicated by the number 0.
Accordingly, if it is possible to establish the necessary correspondence between these characteristics and the property of concern, then relationships between the numbers should reflect the relation between objects with respect to the property being measured.
We could, to suggest an example, determine whether A has more, or less, or equal power, status, intelligence, or whatever, to B, assuming, that is, that we have suitable measures for these properties.
If we can satisfy the stringent requirements of the number system then we have established a scale of measurement.
However, mapping the characteristics of the number system on to some property is not to be had for the wishing.
One has only to think of the time it took and what was necessary to develop the now largely taken-for-granted temperature scales; an effort involving not only technological developments, but also developments in physics, thermodynamics, mathematics, and more.
That the social sciences are a long way from devising scales which even approximate to the temperature scale is not to be wondered at.
Nevertheless, this does not mean that measurement in the social sciences is impossible since, as Lazarsfeld endeavoured to establish, even lower levels of measurement offer a beginning.
The founder of the theory of scales which is commonly used as the  basis for social measurement is the psychologist S.S. Stevens, whose ideas began to crystallise in the 1940s in response to a challenge issued, in 1932, by physicists and psychologists of the British Association for the Advancement of Science to "assess the possibility of"  "quantitative estimates of sensory events" ".
Stevens identified four types of measurement scales: nominal, ordinal, interval and ratio scales.
The first of these, nominal scales, which some would argue do not involve measurement in any strict sense of this term, are classificatory schemes and are fundamental to any level of measurement.
In classifying the aim is to sort objects by their selected properties into homogeneous categories.
Placing individuals in the categories "male" or "female" , "working class" or "middle class" are cases in point, though nominal scales need not be restricted to dichotomies.
As long as the categories are exhaustive and mutually exclusive, the minimal conditions for the application of some counting or statistical procedure are met.
Thus, if we have placed people into the various categories "male" or "female" we can count the frequency of the cases in each.
Formally nominal scales have the properties of symmetry and transitivity.
Symmetry means that a relation holding between A and B also holds between B and A, and transitivity that if A=B and B=C, then A=C.
Taken together these properties mean that if A is in the same class, or category, as B, B is in the same category as A, and that if A and B are in the same category, and B and C, then A and C are in the same class.
These, complicated and ponderous though they may seem, are the basic rules of classification.
What they are not, of course, are rules for the assignment of some number system.
Although numerical values may be arbitrarily assigned to various categories, the standard arithmetic operations of addition, subtraction, multiplication and division are not permissible, though the frequency of cases within categories can be calculated.
But, and to repeat the point, in assigning cases to a category one is not measuring the property except in some very truncated sense of the term.
Ordinal scales are used where it is possible to order cases in respect of the degree to which they exhibit a certain property or quality, even though it may not be possible to state precisely how much of that property they have.
Socio-economic status is one such property where we can classify individuals as having "more" or "less" status but not be able to say how much more or how much less status one person has with respect to another.
Formally, ordinal scales are asymmetrical in that if A is greater than B, B cannot be greater than A. Transitivity still holds in that if A is greater than B, and B is greater than C, then A is greater than C. It is these properties which enable us to order cases along a continuum.
But it is important to note that since nothing can be said about the magnitudes of the differences between the various elements along the continuum, none of the standard arithmetic operations can legitimately be used.
It is with interval and ratio scales that we reach a level of measurement which allows us to use the standard arithmetic operations.
Not only can cases be ranked but also we know the distances between the rankings.
What this requires is an agreed upon standard of measurement such that we can say that we have a unit of measurement and can give a precise quantitative expression to distances between the various points.
Further, if it is also possible to locate an absolute zero point, scores can be compared by taking their ratios to assert, for example, that one score is twice as high as another.
Also, we can transform one scale into another.
Another property, concatenation, arises when we can add measures together: a feature which attaches only to ratio scales.
The amount of money is a good example.
This type of scale has a non-arbitrary zero point of "no money" , and we can add figures for the amount of money with respect to a particular unit be it a person, a country or a firm.
Thus, we can add the joint income of husband and wife to obtain a total for that unit, whatever we choose to call it, whereas we cannot sensibly add their separate statuses to achieve a joint status for both of them unless we know a great deal more about how status is a distributive phenomenon and what its properties are.
Ratio scales, to remind ourselves, contain all the properties of ordinal and interval scales with the additional one that they can be transformed one into another.
The best known of such a transformation is probably that for turning Celsius temperature into Fahrenheit where F=32+9/70C, or, for another example, a conversion formula for turning imperial weights into metric ones.
These requirements represent an attempt mainly by social and psychological researchers to formalise the conditions for measurement in the social sciences, and one that has been remarkably successful judging by the extent to which such scale types are taken as the standard fare for methods training.
There is a recognition in the notion of scale types that any effort to measure human attributes, be they psychological traits, attitudes or social properties, is unlikely to attain the standards of measurement typical of the natural sciences; indeed, they are seldom used in their most developed form.
Basically, devising a scale involves three stages.
The first is to generate a large number of test items designed to indicate the supposed social or attitudinal attribute.
In a scale of authoritarianism (an example we shall look at in Chapter 4), a large number of items designed to produce responses that might be judged more or less "authoritarian" are devised.
These are tested in a number of ways to cull out those that seem less than clear or ambiguous, then they have to be scaled.
The Thurstone procedure involves judges ranking the test items on a scale from "most authoritarian" to "least authoritarian" to establish which items are most indicative of different degrees of authoritarian sentiment.
Finally, the test items selected are weighted accordingly and used in research contexts to discriminate groups of different degrees of authoritarianism  and search for any correlates which might explain such differences.
The vast majority of social research employs ordinal data or, more rarely, the interval scale: even in such cases it is doubtful whether even the most developed of such scales actually satisfy the requirements.
For example, even with the widely used psychological scales, such as those for measuring intelligence or extroversion, we cannot be sure that an IQ of 145 points is really greater than one of 144.
As psychologists will readily admit, such scales are unreliable at the extremes because the cases they measure are so rare that the scales cannot be adequately calibrated.
However, even the best of these efforts, and they are perhaps in their fully fledged forms used more in psychology than in social research, do not reach up to the standards of measurement used in science or, less ambitiously, the higher levels of measurement represented by interval and ratio scales.
None the less, for the inferential structure of variable analysis some level of quantification is required.
This is precisely what the apparatus is designed to achieve.
The very idea of the variable draws upon an analogy with the highly abstract structure of mathematics in which variables and constants are objects in a mathematical domain operated upon by the appropriate rules for manipulation.
To apply a mathematical system, as in measurement, objects in the target domain (for brevity we can call this the social world) must be mapped on to objects, that is numbers, in the mathematical domain.
If the mapping is successful then manipulation of the mathematics is equivalent to manipulation of the objects in the target domain.
This is, for illustration, exactly what is done in a voting system.
Each vote is weighted 1 and by adding, that is manipulating the numbers according to the rules of arithmetic, the result of the election is determined.
But in a scientific context matters become far less straightforward than this example suggests.
In physics and other mathematised disciplines, there is an established homology of structure between the mathematics and the relevant substantive domain.
This connection is normally secured theoretically and depends upon well- established law-like relationships which are not only expressed mathematically but also indicate measurement units, as in the case of the thermometer.
Indeed, in such disciplines, measures are strictly derived from the mathematical theory; measurement being akin to engineering where the measurement devices, be they atomic clocks, watches, thermometers, lasers, electronic counters, dials, etc. are engineered instantiations of well-established theories.
Thus, and again for example, the measure of velocity v=d/t can be instantiated in a number of ways, in car speedometers, lasers bounced off the moon, radar, inertial navigation, astrolabes, etc. and can be expressed in various kinds of ratio scales translatable one into the other, such as feet per second, miles per hour, metres per second, and so on .
As Duncan illustrates in a brief discussion of the development of temperature  scales, it is not merely that in science measurement becomes more precise and reliable in the move to a new type of scale, say a shift from the nominal categories "hot" and "cold" to degrees of heat to the Fahrenheit, Celsius and, lastly, the Kelvin scale, but that the theoretical basis also shifts.
It required much experimentation to determine the properties of air, mercury, alcohol and other thermometric substances, as well as devising methods for constructing and calibrating instruments.
The story of temperature measurement has to do with the experimental determination of the quantitative laws of expansion as well as a greater theoretical understanding of heat and thermo- dynamics.
Kelvin's scale of temperature, the only true ratio scale of temperature since it has a non-arbitrary zero point, is not simply a mathematically more powerful scale or one that is invariably more useful, as far as the latter is concerned quite the contrary, but it is one that "incorporates a profound understanding of how a certain class of phenomenon works" .
As Pawson remarks more generally, The very objective of measurement is to incorporate and embody within an instrument principles derived from theoretical science.
Instrumentation is a branch of engineering, and engineering is nothing other than application of the laws, theories, hypotheses and principles of theoretical physics.
Another feature of measurement in science worth noting is that although there are thousands of measuring instruments in daily use, the number of dimensions measured is actually quite small.
In the human sciences, of course, again with the possible exception of economics, there is no system of units or standards for them equivalent, for example , to the quantities of mass, length and time.
Instead, what we have are literally thousands of measures in educational testing, social surveys, attitude research or statistical analysis, with little or no idea as to how any of them could conceivably be reduced to a few dimensions or compared with agreed-upon standards.
However, given the lack of such well-established theories in the human sciences, variable analysis proposed to achieve the homology between the mathematical and its substantive domains by working through the methodological stipulation that social and human properties be described in variable analytic terms and the measurement scales just discussed.
It should be no surprise that both variable analysis as a mode of sociological thinking and the use of scaling in research have been criticised.
Some have expressed doubt that Stevens' scale types add up to a theory of measurement or, if they do, whether this approach is a useful one for social research as it currently stands.
As Duncan rather carpingly points out, age is a ratio scale but it is hard to see any analysis of age as a variable which exploits this fact.
In other words, it is a moot point as to whether the effort to develop interval and ratio scale measures is really worth it, especially since it underplays the  importance of counting and categorisation as perfectly respectable procedures which are possibly more beneficial in the long run.
Arguably more of a problem is the inadequate theoretical base upon which to devise measures even approximating to the standards of natural science.
Effective measurement requires detailed knowledge of the properties of phenomena which are to be reflected or mapped on to some mathematical system.
Without this social research runs the risk of imposing on its subject matter properties derived from mathematics for other purposes.
However, it is not unreasonable to argue that trying to meet the measurement standards of natural science is to inflict a crippling over-ambition on social research.
If theory and measurement do go hand in hand, there is no alternative but a patient and directed effort to improve both.
This is the burden of Blalock's views, one of the doyens of causal modelling and quantitative social research.
For him, the only way to bridge the gap between theory and data is by the development of "auxiliary measurement theories" which can better specify appropriate measures and their levels and, through this, contribute to theory development.
Others are less sanguine than Blalock, arguing that if quantification in social research is to proceed, there are some very fundamental problems to resolve first, not least describing accurately and effectively the properties of social phenomena.
A number of the latter arguments will be addressed in subsequent chapters, but the thrust of the critique has to do with the categorisation procedures employed in data gathering in order to meet the requirements of variable analysis measurement and their relationship to the properties of ordinary language and of social phenomena themselves.
A UBIQUITOUS LANGUAGE OF SOCIAL RESEARCH?
To repeat, these days it is hard to recapture the innovative and radical character of variable analysis since it is now so much the orthodox conception of what social research consists in.
Its innovativeness did not so much lie in the originality of the separate ingredients but in the recipe itself.
Most of the ingredients were taken from other fields and disciplines, but the achievement was to meld these into a way of thinking, both theoretically and methodologically, so that one, the latter, could provide a route for a more effective formulation of the other, namely, theory.
As one textbook advises: "It is necessary to translate your ideas into the language of variables before you can carry out or evaluate research.
The experienced sociologist develops the habit of routinely translating the English he reads and hears into variables."
Variable analysis is an inferential structure, a form of methodological reasoning, that has come to dominate social research.
One important feature of variable analysis, and for many its primary virtue, is that, as a method, it is theoretically neutral.
It is the prisoner of no particular approach but is a ubiquitous way of thinking, capable of dealing with and being deployed in respect of the widest range of approaches.
It is a format for thinking theoretically-in- research-terms.
Its approach of quantification even allowed for dealing with qualitative properties and variables.
The basic requirement of the approach is that concepts be translated into empirical indices.
Its pattern-searching strategy resolves many theoretical issues by placing them within the constraint of empirical evidence.
So, the elaboration of a theory is through not only the kind of conceptual elaboration spoken of earlier, but also elaborating the indicators through pattern searching.
Variable analysis is the closest that social research has come to a generic method of social investigation.
There is a metaphysics of ontological realism underlying the conception of variable analysis, if only to the extent that it makes sense to talk of indices only if it is assumed that they "stand for" something.
Lazarsfeld's proposal is not to try to resolve methodological problems philosophically but to see what follows by way of research practice if we recognise that we can never investigate phenomena directly.
If we have only indicators what his methodological reasoning suggests is that we look for patterns among indicators which might suggest that we have found something of substance and significance.
Social surveys
Most of us living in industrialised countries are familiar with social surveys of one type or another.
Few of us would be surprised to find an interviewer on our doorstep asking us to give a few moments of our time "to answer one or two questions" on our voting habits, which TV programmes we watch or which washing powder we use.
Some of us may have taken part in an academic survey; most of us will have taken part in the census.
Week by week we read of the latest opinion polls on this or that.
Accordingly, while most of us may not be au fait with the technicalities of surveys, we are likely to have an intuitive grasp of what surveys are about; they are concerned with finding out how many people, within a defined social-cum-geographical area, hold particular views or opinions about things, events or individuals, do particular activities; possess particular qualities; and so on.
In this chapter we shall be considering some ideas which inform the design and purpose of social surveys; we shall also say something about their origins and their applications.
As the above introductory remarks suggest, the experience most people have of social surveys is through the interview.
For the sake of convenience this will be left for Chapter 5 though it is essential to remember that the data collected through social surveys are almost exclusively obtained by means of this method.
We shall consider four types of surveys.
The first we call the "factual survey" , which aims at collecting facts about the conditions of populations.
This was the first kind of social survey to be seriously used in the United Kingdom, a fact which was a consequence of a combination of historical and political factors.
What the approach bequeathed is procedures for surveying large numbers of people at minimum cost, and a series of guides for eliciting "factual" information from respondents in an interview.
This may be contrasted with the second type, the "attitude survey" , which aims at producing an accurate picture of people's attitudes as a guide to their likely behaviour.
This type of survey was first developed seriously in the United States, and its importance can similarly be traced to economic and social factors peculiar to that country at a particular stage in its history.
Among the inheritance of this type of survey are procedures known as the quota sample and the attitude questionnaire.
The main aim of both these types of surveys was to effect, as accurately as possible, a description  of the social structure or, in the case of the attitude survey, the current state of public opinion.
This meant that issues to do with the representativeness of the sample drawn and interviewed were paramount since the objective was to gain an accurate estimate from the sample of the likely population characteristics.
By contrast, the third and fourth types were more concerned with explanation and theory testing than with description.
The "social psychological survey" , for example, used survey designs and questionnaires to investigate the distribution of personality via various kinds of attitude measurement techniques.
The "explanatory survey" , as its name implies, is concerned to gain information from respondents in order to test some theoretical explanation and represents the full-blown expression of variable analysis in the survey tradition.
In an important sense the factual survey and the attitude survey were designed to achieve practical objectives rather than serve disinterested theoretically inspired research.
The interests which stimulated their innovation and guided their development and use were primarily those of political administration rather than the strictly academic.
Throughout the nineteenth century in most industrialised nations there had been a growing need for governments to obtain reliable knowledge about the state of their societies.
In Britain, the first census of modern times was begun in 1801 and a series of government reports resulted in various inquiries into the state of the nation.
In general, many of these inquiries were motivated by the need for what we would now regard as manpower planning, especially to do with the defence of the realms concerned.
Governments, throughout Europe especially, found themselves, sometimes reluctantly as in Britain, sometimes with more enthusiasm as in Prussia, assuming an increasingly managerial role in economic life as the basis of political and military power.
For this information about the "state of the nation" became vital.
However, such social research was not only governmentally inspired.
Booth and Rowntree, in the late nineteenth century, carried out the first major surveys of income and consumption in London and York respectively, which laid the foundations for a style of social research which was, in the coming years, to play a major role in the formation of policy and social welfare legislation in the United Kingdom.
Booth's survey also had an influence on a similar movement in the United States, though its roots go back to the middle of the nineteenth century when a number of small surveys on the "dangerous classes" were undertaken.
As in Britain, the early social survey belonged much more to a reform impulse than to an effort to develop an explicitly social science methodology.
One major presupposition of these early surveys was that it was preferable to study the whole population of a society in order to ensure the reliability and accuracy of the data collected.
Though Booth and Rowntree were wealthy industrialists, it was principally considerations  of cost which led them to limit their study to the particular areas they did.
If it had been possible to study the whole country cheaply and in sufficient detail they would have done so.
So, one key feature of these early surveys was the assumption that the greater the absolute size of the population studied and the closer this approximated to the total population of the country, the better.
The higher the proportion of this population which could be contacted the better.
It was developments in sampling theory from statistics which weakened the force of both these assumptions, and quite early on in Britain.
Sampling theory showed that reliable estimates of population characteristics could be arrived at using appropriately constructed samples.
Though the whole population remained the focus of interest, sampling techniques enabled it to be studied economically.
But, none the less, the aim to study the whole population determined the scope and the character of both these types of early surveys and, in so doing, encouraged the search for new ways of doing so cheaply through innovations in the applications of statistical theory to the selection of samples.
THE EARLY "FACTUAL" SOCIAL SURVEYS
Given the interests of the early social surveyors in investigating whole populations we must include among the forerunners the censuses of pre-modern times.
The two best-known ones are the one undertaken by Augustus Caesar, which allegedly affected the birth of Jesus, and the Domesday Survey compiled at the instigation of William I. Both of these were attempts by an occupying power to extend its control over the population and, no doubt, record the spoils of victory.
Data in each of these cases were sought by the central administration of the dominating power for taxation purposes, among other considerations, so that money and tribute could be more effectively extracted, and the rewards to loyal service allocated.
It was this legacy of coercive intent along with centuries of suspicion toward central administration which, perhaps, encouraged resistance to attempts to introduce a census in Britain until the beginning of the nineteenth century.
By the time the first censuses were undertaken in Britain, much had changed in the structure of society as well as in the nature of the state itself.
By 1801, not only had the conflicts between monarch and nobility over the extraction and use of rents and taxes, and the respective rights and duties of each, largely been resolved and in the process made irrelevant, but also the industrial revolution was well under way, establishing the basis for the growing political ascendancy of the industrial classes over both monarchy and aristocracy.
The character of the state had changed decisively from the coercive apparatus of monarchical power to the increasingly bureaucratic (but determinedly laissez-faire) administration of the first capitalist nation.
Indeed, the categories used in the censuses display many of the concerns of the governments of the day.
In the first census of the nineteenth century, many of the concepts developed by the classical economists Smith, Ricardo and Malthus influenced the categories used.
Since then the assumptions underpinning, and the meanings attributed to, census data have changed a good deal.
Nowadays, the census does not seek information about the numbers of people obtaining support from different factors of production, but has extended its range into a whole gamut of policy-related matters such as housing, education, income as well as occupation, and, very recently, ethnic status.
The census has been for many years now an important instrument, among a range of such instruments, in the administration of the welfare state.
This particular development of the census, along with other official data and information-gathering techniques as an integral part of the welfare state, is a comparatively recent development in Britain.
Much of the early social survey work was concerned with establishing the case for the need for nation-wide welfare provision along the lines now embodied in the modern welfare state.
Also, the census was slow to be influenced by the techniques of survey method, both in the use of sampling designs and in the search for more appropriate data.
A biographer has said of A.L.
Bowley, the man who above all others took up the mantle of Booth and Rowntree in the early part of this century, that"it was unfortunately not the custom in Bowley's day for the British Government to call outside experts.
Undoubtedly British official statistics would have advanced more rapidly, particularly in the use of sampling techniques, if Bowley had had more to do with them."
Britain was comparatively slow in acquiring a welfare state by comparison with some other societies, notably Germany, and it is in the context of this struggle to achieve a more adequate provision of social welfare that the early uses of social surveys in Britain must be understood.
The process of industrialisation not only began later in Germany than in Britain, but also Germany achieved spectacular economic success in a relatively short period of time.
In the space of two decades Germany rapidly overtook Britain in industrial output.
By the early years of the twentieth century, well before the outbreak of the First World War, Germany was increasingly challenging Britain's dominance as the world's leading industrial and imperial power.
That Germany had also provided a comprehensive state insurance for sickness, accident, disability and unemployment for its people from an early date was thought by some to be implicated in that country's economic success.
Also, the inability of Britain to sustain its economic growth from about 1870 onwards was partly explained by inadequate state welfare protection for its citizens.
About this time a particularly long and deep depression hit the British economy, giving further  impetus to the need to reappraise social and economic policy.
British liberal political thought, hitherto contenting itself with a more or less straightforward advocacy of laissez-faire non-interventionist policies, began to transform itself into what has been called "social liberalism" .
This, along with parallel doctrines such as Fabian Socialism, provided important ingredients to the intellectual context in which the pioneering social survey work was undertaken in Britain.
Social liberals, like Booth and Rowntree, and Fabians, like Sydney and Beatrice Webb, may have differed in their views on the extent and the permanence of the provision of state welfare that they advocated, but shared an interest in what they saw as the factual demonstration of the extent of poverty which existed in what was still regarded as the major industrial and political power.
They also advocated the use of social survey methods of research to show, accurately and in considerable detail, the actual extent and character of existing social conditions in a way that would be difficult to challenge.
While it would be going too far to claim that social surveys such as these by themselves induced major political change, it would be dangerous to ignore their significant contribution.
In the circumstances in which they were used they powerfully augmented other forces of change by providing data on the state of society at a period when so little was known.
This can be illustrated by the early surveys of Booth and Rowntree.
At the time the prevailing view of poverty was that it was primarily due to personal inadequacy, especially laziness and moral turpitude; a convenient view for the orthodox political doctrines of the time which held that government intervention in either the state or the economy or society was invidious, and, what is more, likely to make matters worse by restricting liberty, constraining the rights of property and, in any event, useless.
Governments could do little to turn immorality into morality, or bad characters into good.
But the scale of the poverty revealed by the Booth and Rowntree surveys shocked late Victorian sensibilities.
Both surveys showed that for many people poverty was a way of life even when they were in gainful employment.
This struck at the root of the idea that nobody need be poor if they conscientiously engaged in economic activity.
Poverty was merely the lot of the indigent.
As a result, there came an increased acceptance of the view that persistent, and unacceptable, inequality and want might be built into the economic system unless the state made key interventions along the lines of the German model.
The shift towards a greater acceptance of this point of view marks the emergence of social from laissez-faire liberalism, a shift assisted in no small measure by the early poverty surveys.
If liberalism was a spent political force in Britain by 1930, the kind of social survey to which it helped give rise was not.
Sampling techniques were refined throughout the early decades of the twentieth century by Bowley, Hilton, and others.
Such methods were  increasingly copied and applied within the official investigations of the state itself, and became an important element in its maintenance and extension.
As Moser comments: "By the middle of the 1930s surveys were beginning to assume importance in the field of town planning and reconstruction" .
By 1941 social surveys on the lines pioneered by Booth, Rowntree and Bowley were fully incorporated as instruments of the welfare state, impelled further by the imperatives of planning for war.
The Government Social Survey was created in the same year as an adjunct to the Central Statistical Office, more recently combined into the Office of Population Censuses and Surveys.
The survey has changed from being an instrument devoted to demonstrating the need for a welfare state into a central feature of its maintenance and administration.
As Moser revealingly wrote of the Government Social Survey: "the survey exists to collect data required for administration, not for party politics" .
While the ability of the factual social survey to provide large-scale pictures of prevailing social conditions within a community is important, it is less frequently used these days.
To the extent that social research more generally has retained an interest in social reform this has been redirected in various ways.
Increasingly, private pressure groups commission private survey organisations to focus on particular subgroups or issues and, as a result, deal with matters that go beyond material deprivation.
Where such studies make use of the survey, they tend to be smaller in scale and more analytic in scope using directed samples.
CONTRIBUTION OF THE EARLY SURVEYS: PROBABILITY SAMPLING
In Britain the social and intellectual origins of the early surveys gave them a particular emphasis summarisable as generality and factuality.
That is, the aim of describing the state of the society by gathering hard facts about the conditions of life from as many people as possible; hard facts to do with income, expenditure, consumption or living conditions.
Little interest was evinced in gathering material to do with how people felt about their conditions, or their hopes and fears for the future.
Facts were to do with the material conditions of life described as precisely as possible and counted as accurately as possible.
In terms of the impulse for social reform which motivated many of these surveys, such facts were intended to be difficult to rebut by erstwhile opponents of reform.
Although in terms of later social science methodologies such an approach might seem naive, it did leave an important legacy for social research and survey data collection, namely sampling.
The desire to  survey the social conditions of the largest possible population proved difficult and costly, so methods were sought to reduce the costs of such surveys without, at the same time, sacrificing accuracy.
Sampling was a means to achieve this objective.
Sampling techniques were adopted from statisticians working in the fields of biology and botany.
The statistical theories involved were designed to allow generalisations about a population on the basis of a sample of that population, within known margins of error.
Thus a precise estimate of the average height of adult males in this country can be made on the basis of a representative sample of the total population of adult males.
The problem is that without measuring the heights, and their frequency, of all adult males we will not know what a representative sample would be.
While we can say that the average figure is likely to fall between 1 and 3 metres, since we do not know how many are 1.6 metres, 1.7 metres or 2 metres tall, we cannot calculate the average.
What we can do, however, is take a sufficient number of adult males chosen randomly and use this as the basis of the calculation of the average, and take this as an estimate for the average of the population.
Since the population of adult males in Britain is many million, there are obvious savings to be made using these techniques.
It means that the population value of some characteristic, say, average height of adult males, can be estimated within range of error, from the values found within a suitably drawn sample of that population.
Although this is not the place to enter into a detailed exposition of the mathematics behind sampling theory, there are two questions worth dealing with.
First, how large does a sample have to be for a given population?
Second, how can we be sure that it provides for an accurate and reliable estimate of that population?
As far as the first is concerned, without going into statistical details, generally the larger the population the smaller the sample needs to be.
The ratio of sample to population is normally expressed as a fraction, known as the sampling fraction.
In our example, estimating the average height of adult males in the British population, would require a sampling fraction of about 1/4,000, whereas to estimate the same parameter in a population of 200, a sampling fraction of ¼, or a sample size of 50, would be necessary.
In other words, the sample in the latter case would have to be a greater proportion of the total than the former.
Broadly, the reason for this is that in smaller populations the selection of an extreme value for the sample would have a greater effect on the calculation of any value for that sample if the sample was also small as a ratio of the population.
So, to minimise the chances of this, smaller populations require larger sampling ratios.
However, this is not the only factor involved.
Sample sizes cannot be decided independently of acceptable error since sampling cannot guarantee that it will provide the true population value.
What it does  offer is a way of calculating the probable size of the error in estimating that value.
Probability has a precise meaning here.
It will be possible for a researcher to know, for example, that there is a 99 per cent probability that the sample estimate falls within 3 per cent of the real value of the total population.
Larger samples will increase precision, the less likely they are to vary from the population value, and the more confident we can be that our sample estimate of the population value is within a given range of accuracy.
For any chosen sample size there will be a calculable range of variation within which an estimate of the population value falls, and an associated probability that the estimate will fall within that range.
For any sample size there will be an inverse relationship between these; the smaller the range specified, the lower the probability of accuracy it will be possible to associate with it.
Thus, for example, we may be 99 per cent sure that the true population value is within 3 per cent of the estimate, or 99.9 per cent sure that it falls within 10 per cent of the same estimate, or 95 per cent certain that it falls within 1 per cent of the estimate.
Accordingly there is a choice about the level of accuracy we want to accept.
Confidence limits of 95 per cent and 99 per cent are conventionally used in most statistical calculations in social research, not only in descriptive studies of the kind we are presently discussing, but also in more analytic ones we shall be considering later in the chapter.
In choosing a sample size, therefore, not only do con- siderations of accuracy enter, but also considerations of conventionally accepted limits.
A crucial assumption of the kinds of statistical calculations we have been referring to is that the sample has been randomly drawn from some population.
Randomness, which again is something that has a precise meaning in this context and certainly not equivalent to "take anyone that comes along" , is necessary to ensure that the estimate of the population value is unbiased.
In brief, what this means is that every individual comprising the population of interest should have an equal chance of being selected for the sample.
This is not always easy to operationalise.
Sampling lists, that is, a record which identifies and sets out the population from which a sample is to be drawn, may not always completely enumerate the population from which the sample is to be drawn, the list may follow some peculiar sequence, sections of the population may be difficult to contact or refuse to co-operate, and so on .
Unless care is taken to minimise biases of this kind, careful calculations of precision will be pointless; the estimate of the population value will be wrong.
It is not enough for researchers to assume that if they do not make conscious decisions, try to be scrupulously fair when selecting their samples, that randomness will be assured.
Biases can creep in in extremely subtle ways, and researchers can, quite unconsciously, favour some groups and disfavour others.
The only way to ensure randomness is to make sample selections independent of human judgement.
There are several techniques for this, the most common being to select a sample from a list, called a sampling frame, according to numbers generated by tables of random numbers.
If the researcher is confident that there is no ordering principle at work in the sampling frame, that the list is random in other words, then systematic sampling can be employed by selecting every nth item from the list as required.
As we say, systematic sampling requires care if there is unwanted selectivity in the list.
On occasions simple random sampling procedures as just described do not meet the requirements of the research.
For one thing, especially if the sample is relatively small, unlikely events can skew the sample.
More likely, it might be that we need to ensure that particular subgroups are represented in the sample.
To meet these possibilities, a technique known as stratification is employed: this involves dividing the population into groups or strata and sampling randomly within each.
If the differences between strata are maximised and the variations within them minimised, the benefits from stratification can be considerable.
It is a technique which can also help keep sample size down in the case of a large survey.
Against this one must set the likelihood of increased travel and other costs arising from the greater geographical dispersion of the units in the sample.
To obviate these an alternative to stratification is to concentrate the sample within selected subgroups, or clusters, of the population which makes interviewing more convenient by concentrating respondents together.
This does, however, tend to reduce precision and leave room for biases.
Nevertheless, there may be special reasons why clustering may be a useful technique, such as when an investigator is interested in certain subgroups of the population.
However, neither of these procedures recommended themselves to the early survey researchers, such as Bowley; his procedure was to compromise between administrative convenience and representativeness by using more than one stage of sampling.
He chose a sample of towns for his study as a first stage, then selected smaller districts within these, and so on.
Multi-stage sampling surveys of this kind are most effective when the sampling units are carefully stratified at each stage.
The great achievement of the early survey researchers was to provide and encourage the development of techniques for surveying large populations cheaply and within calculable degrees of accuracy; although to a large degree the emphasis in social science has shifted from descriptive to analytic surveys, the legacies of sampling and survey design remain.
We now turn to a consideration of the early use of social surveys in the United States.
These were scarcely more analytic or explanatory in their approach but were interested in different kinds of data, and, as a  result, developed different techniques for dealing with the problem of representativeness.
EARLY ATTITUDE SURVEYS
In Britain the early surveys were primarily concerned with discovering the material conditions in which the population lived.
They showed little interest in attitudes or opinions which explains their insistence on "factual questions" , precise and exact, in order to claim that the research yielded "hard" data.
In the United States, although a social survey movement not unlike the tradition of Booth, Rowntree and, later, Bowley, was prominent in the early years of the twentieth century, different political traditions, among other things, gave rise to a different use of social surveys.
In this the concern was to measure public opinion as a guide to political action.
In Britain, despite the development of forms of democratic political institutions, the idea of an independent and consequential public opinion had never been a very serious consideration.
By contrast, the political culture of the United States, always more populist in character than the British, took seriously the notion that public opinion was there to be wooed, cajoled, seduced but never ignored.
As Abraham Lincoln is reported to have said,"With public opinion on its side, everything succeeds.
With public opinion against it, nothing succeeds".
It was against expectations and conceptions such as these that two of the early surveys were developed in the United States — the market research survey and the pre-election poll.
The presumption was that whatever people said about their tastes, feelings, beliefs, attitudes or opinions was a reliable guide to how they would behave or how they would act.
So surveys could be used to predict behaviour, for example, how the electorate would vote or whether people would buy a new product.
Or they could be used to design new strategies; useful, for example, to politicians trying to get a policy on the agenda, or a sales manager trying to market a new product.
This kind of survey arose in a political culture very different from that which gave rise to the factual survey.
It was a political culture which emphasised the democratic assumption that opinion was not merely of passing interest but an important guide to understanding how people would react to various policies.
It recognised the power and the autonomy of the public as a force to be reckoned with; predicted but never ignored.
By contrast, the British use of surveys involved finding things out about people in order that representations could be made on their behalf by their "betters" .
In addition, in the United States the view prevailed that it was neither possible nor desirable to attempt to influence social and political behaviour very much.
However, one need not be overly cynical to realise that having a good idea of what masses  of people are likely to do in response to certain policies gives a competitive advantage to politicians and businessmen alike.
The early American public opinion surveys were probably little influenced by British social survey work by contrast to the reformist social surveyors.
Market research surveys were probably the first type of opinion survey to be used and as early as the first decade of the twentieth century.
Abrams explained this in terms of a particular configuration of economic factors affecting the United States at this time.
American firms were among the first to confront a national mass market since the market for consumer goods was huge, the whole of the country being a free trade area for business firms.
For business people the question of what consumers wanted and how their products could be most effectively marketed was a vital one spelling the difference between success and failure.
As a consequence many large firms began to conduct their own market research until, more recently, it has become the specialised trade of advertising agencies and professional market research organisations.
Attempts to survey political opinions came rather later, though they did have not dissimilar aspirations to those of the market surveyors; however, they were rather less well conducted.
Until the Three Mile Island nuclear accident, Harrisburg, Pennsylvania, was notorious only for the earliest perpetration of a "straw poll" attempting to predict the outcome of the 1924 presidential election.
Similar polls conducted by various newspapers became notorious for their frequent and lamentable failures to come even close to accurate predictions of electoral outcomes.
The most famous débâcle was the Literary Digest Poll of 1936.
Despite the success of an earlier poll in 1932 and the distribution of over 10 million questionnaires to respondents selected from telephone directories, the poll failed to predict the election of F.D. Roosevelt.
However, far from discrediting such polls, it encouraged efforts to make them more effective predictors of outcomes and preferences.
One of the more important of these was the quota sample, an attempt to approximate to random sampling methods but in a way that minimised the practical difficulties often involved in selecting and contacting respondents, so offering considerable advantages in cost and convenience.
The other important innovation was the rise of the professional opinion research agency offering its services and expertise in opinion polling.
CONTRIBUTIONS OF THE EARLY ATTITUDE SURVEYS: QUOTA SAMPLING
Instead of seeking a random sample from a population in which each member has a known, calculable and non-zero probability of inclusion, the quota sample proceeds by deliberately selecting a sample which reflects the known composition of the target population.
These days much is known about the socio-economic composition of the population thanks largely to the national census.
It is possible, therefore, to construct a sample so that it has the same distribution of characteristics as the population as a whole or, if necessary, selected portions of it.
By selecting for a sample a definite "quota" which reflects the proportion of different types of people in the target population, which can, of course, be the whole population, we have, prima facie , reason to assume the sample as representative.
The criteria most commonly used to establish how many people we should have in a sample are such characteristics as age, gender, marital status and socio-economic status, although various other criteria may be used as appropriate.
These criteria are called "quota controls" because they are used to limit the number of respondents chosen within predetermined quotas.
Strictly speaking, of course, this kind of sampling does not allow the deployment of statistical analysis in order to make inferences to population values from the sample, since the selection of cases within quota categories is not done according to random sampling procedures.
For this reason, the method has attracted heavy criticism from a number of statisticians and methodologists; however, it can be argued that quota sampling is informed by sociological principles at least.
For one thing it takes into account the fact that people in different social circumstances are likely to have different views and different opinions; the sample is chosen so that the more salient features and differences that are thought to exist are proportionately represented.
To some extent this aim can be achieved by stratifying a random sample appropriately.
But there are often insurmountable practical difficulties in doing this given that, under most random sampling procedures, it is individuals who have to be contacted not types of individuals who satisfy the quota controls as in quota sampling.
Also, it is very difficult to stratify the electoral register (a frequently used sampling list) by social class or by education.
Random sampling, it can be argued, makes rather few concessions to the fact that human populations are not normally socially well-mixed: indeed, they tend to develop distinct homogeneity within subgroups.
Quota sampling, intelligently used, can deal with these difficulties reasonably effectively.
Instead of all the problems of finding or developing an appropriate sampling frame, and of drawing the sample randomly from the list, the quota sample is usually drawn by the interviewer.
The researcher goes out looking for respondents who conform to the quota requirements, either by knocking on doors or by asking people in the street to participate: it must be stressed that the point is not to interview everyone who happens to live on the street or who happens to pass by, but only those who conform to the quota controls and in the  proportions specified.
Selecting respondents in the High Street on a Monday would include an excessive proportion of women of child-bearing age unless the quotas are strictly adhered to.
Working the High Street on the day in question, an interviewer will probably fill the quota of married women 20–35, and possibly men and women over 65, but will most likely have to look elsewhere for men and women of other ages, marital status and socio-economic grouping.
The contact procedure is usually to begin with a number of preliminary questions to ensure that the people contacted do fulfil the quota requirements.
If they do not then the interview is politely broken off.
There are, of course, great temptations for an interviewer to classify respondents into categories where they are most needed rather than where they really belong, especially when the job is nearly complete and respondents from particular categories seem rare or, perhaps understandably, at the end of a long day in the rain and the cold.
None the less, when properly used, the quota sample can avoid the kind of gross errors made by attitude surveys in the past.
On this point it seems that the Literary Digest Poll and others committed two errors.
First, non-response was high and it is now known that, as a category, non-respondents are often very different in a number of relevant respects from those who do respond.
Second, the telephone lists actually used for the sample were unrepresentative of the electorate.
Owning a telephone, for example, implies a certain minimum of income and life-style, and using telephone owners as the sampling list would seriously over-represent the better off and, presumably, the more politically conservative sections of the electorate.
In view of the comparatively greater possibilities of error, it is perhaps surprising that the early polls came as close as they did in predicting electoral outcomes.
After all, the Literary Digest Poll for the 1932 election came within a tiny margin of the actual result.
This heightened expectations for the accuracy of the prediction for the election of 1936.
Looked at against the background of the difficulties in the way of achieving a representative sample, the close result of 1932 was a fantastic stroke of luck; and errors of 4 per cent or so, as produced in 1936, are only to be expected.
However, as quota sampling methods became more widely used much greater levels of accuracy were routinely achieved.
On the basis of relatively small samples, only a few thousand in each of selected states, it proved possible to make accurate predictions of the electoral outcomes.
This is quite an achievement in view of the size and the regional diversity of a country such as the United States.
In 1948, three of the main polls wrongly predicted the outcome of the election of that year.
Truman won (taking 49.5 per cent of the votes cast) against Dewey (45.1 of the votes).
The Gallup Poll predicted 49.5 per cent for Dewey and 44.5 per cent for Truman.
Although as a prediction of the electoral result  this was incorrect, the estimates were only a few per cent out.
For purposes other than electoral forecasting such close estimates would be regarded as highly commendable.
Since the interwar period, when quota sampling was first developed in the United States, it has been refined to a high art by commercial research organisations in many countries.
Its chief merits are its cheapness and convenience.
Such samples can be interviewed very quickly at a fraction of the cost of full-scale randomly chosen samples.
Thus, for certain purposes, such as market surveys and pre-election opinion polls, they are probably not to be improved upon.
In the 1980s there have been attempts to develop random sampling procedures as quick and as cheap as quotas.
However, there is little evidence to suggest that these give better estimates of opinions which are any more accurate for these purposes than those yielded by carefully chosen quota samples.
Indeed, for some purposes its cheapness and speed make quota sampling a procedure which could be more extensively used in some academic research where a general indication of the attitudes extant in a specified population is required.
Moreover, it is possible to incorporate elements of randomness into quota sampling by rejecting numbers of possible respondents according to a random sequence.
We have described two uses of the survey method which originated outside academic circles.
Moreover, by today's standards they both adopted rather naive assumptions regarding the nature of and the relationship between behaviour, ideas and respondent reports of these.
For the early British researchers, surveys were a means of obtaining from large numbers of people reports on their conditions of life, while for the American surveyors, more interest was expressed in attitudes and opinions which predispose people to behave in certain ways.
Today, and at least in academic circles though not solely these, both of these uses have been developed by a greater use of social scientific theory and by more advanced statistical techniques.
In both these developments it was largely scholars in the United States who took the lead.
There social science and social research had become an established and thriving part of the academic community from the beginning of this century.
The requirement of a PhD for an academic post marked the early professionalisation of social science.
By contrast, social science in Britain, with the possible exception of economics, was largely unrecognised and underfinanced having little or no foothold in the elite establishments of higher education.
In those institutions where the social sciences, especially sociology, were taught, principally the London School of Economics (LSE), it was a theoretical tradition rather than a social research one which was encouraged.
This theoretical tradition was that of social liberalism developing the evolutionary and organicist elements of this approach  into elaborate bodies of theoretical ideas.
As a result, there is an unbroken strand of social liberal philosophy from Hobhouse, Professor of Sociology at the LSE from 1903 to 1929, through Ginsberg (1929–54), down to Marshall in the immediate post-war period.
The outlook of these men, particularly Ginsberg and Hobhouse, was evolutionary and comparative, scarcely connecting with the strictly factual investigations of Bowley, Boyd, Orr and Caradog-Jones.
In Britain, it was mainly left to social anthropology among the social sciences to sustain a theoretical development based on empirical research.
The contrast with the United States could not be sharper.
In that country three great universities (Chicago, Columbia and Harvard) had pioneered the development of sociology.
Sociology had a major presence, though of variable quality and intellectual traditions, throughout the university sector before the Second World War.
Peel, reviewing the development of the social sciences, suggests that "sociology was made a reasonably unified subject by the Americans who welded together very diverse streams" , which, by the 1940s, "was being synthesised into a mainstream of theory to which most ongoing research was related" .
It is certainly true that the most active social science departments gave rise to the approach to social science which became associated with participant observation, the more extensive use of the survey method as a means to examine attitudes and personality and, last but not least, the modern sociological use of the survey as a tool for the development of theory as in variable analysis.
The divide between theory and empirical data had long been a recurrent and problematic one for the social sciences, not least within sociology.
Indeed, arguments about the relationship constituted much of the core debate as is evidenced by the attention given to it by classical figures such as Weber and Durkheim.
However, it is fair to say that despite these distinctive efforts, and one reason why such people are now regarded as classical contributors, for most within the early social survey tradition the divide seemed unbridgeable or irrelevant.
Indeed, in the early quarter of the twentieth century in the United States, interest in social survey research was far stronger among academics and activists in social welfare and social policy than it was among sociologists.
For them, theory consisted of broad speculation which seemed to need little in the way of systematic data collection, while for empirical research on social life, such theories seemed to be of little relevance.
Certainly, the British survey researchers saw little or no need for theories; hard facts were what was important and so with the early opinion researchers in the United States.
So despite the widespread acceptance of social science in the United States by the early years of the twentieth century, it is possible to produce a sizeable list of American sociologists, all eminent figures in the history of the discipline, who seldom undertook on their own account, systematic data collection of any kind.
In the main they relied  upon their own convictions and inspirations and on secondary sources of various kinds.
Such a list would include Sumner, MacIver, Giddings, Small, Sorokin and Cooley.
They were eclectic in the data they sought and, by some standards, relatively unsystematic in their use of the data.
None the less, important foundations were being laid in the period immediately following the First World War.
The University of Chicago, under Park and Burgess, had begun to move sociology toward becoming an empirical social science.
Though this period of Chicago's history is normally associated with the more ethnographic, qualitative tradition of social research, both Park and Burgess were aware of the work of the social survey movement both in the United States and in Britain.
Though the social survey method was not extensively used in Chicago-inspired studies, and there was some scepticism about what it could achieve for sociology compared to field research, with the appointment of Ogburn in 1927, a statistically trained sociologist, the pace of the development of quantitative methods quickened.
Martindale charts the intellectual history of American sociology from the interwar period to post-Second World War as a movement from the dominance of social behaviourism as a perspective to that of functionalism.
He suggests that shifts in the social and political climate in the United States may have had something to do with this change: the very dates of the steep rise of interest in functionalism among sociological theorists also suggests that it may have some ideological import.
It rose after 1940, and with particular speed after the Second World War.
Moreover, its ranks have been increasingly swelled by deserters from social behaviourism — an evidently liberal position.
The rise of sociological functionalism thus coincides with the return of the Republican Party to power, the return to religion, the rise of McCarthyism, and other typical manifestations of a postwar conservative reaction.
Whether or not post-war social science was more conservative than its predecessors it is difficult to say: the character of social science is strongly influenced by its social, political and economic context.
There are additional factors important in this case, however.
In the United States during the period we are discussing there were powerful moves for the professionalisation of sociology and social science.
The main manifestations of this were the insistence on education to doctorate level for recruits to the discipline, and the development of theoretical and methodological orthodoxies in teaching and in research.
The orthodoxies which eventually established themselves were function- alism and, in methods, the survey.
Prior to the culmination of these changes in the institutionalisation of American social science, the various branches of social behaviourism were well represented in the major American  universities.
As is to be expected, there were differences of viewpoint, sometimes major, both within and between institutions.
Indeed, only by holding to a very diffuse and very general understanding of social theory is it possible to see many of these views and their exponents as representatives of the same general theoretical approach.
This diffuseness was paralleled by a marked degree of confusion over the appropriate research methods to use in empirical studies.
Indeed, in what is perhaps a more healthy attitude to such matters, a diversity of methods and investigative postures was the order of the day.
The social survey was, in fact, only a minor player in the research game.
Symbolic interactionism, as it became known, was perhaps the most vigorous of the variants of social behaviourism having a firm foundation at the University of Chicago.
Although this branch years later became closely associated with participant observation, during this period researchers in the Chicago School made use of a variety of methods in their research, including observation and, to a degree, survey type methods.
Perhaps one can gauge the relatively carefree attitude to data and their analysis from a seminal study from the period in question, The Polish Peasant in Europe and America by Thomas and Znanieki.
The bulk of the data used for this study were documentary in origin: letters from Polish peasants to relatives living in the United States, the archives of Polish newspapers, and the records and periodicals of Polish émigré organisations.
Also included was the autobiography of a young Pole, running to some 300 pages in length.
This material forms the basis of an account of the social changes in rural Poland, the attempts on the part of emigrating peasants to retain elements of their cultural identity, and their eventual imperfect integration into American society.
There is no attempt at any systematic statistical analysis of the documents, either of their numbers or their content; there is also no attempt to supplement this material with interviews, though from the text it is clear that both authors talked to many Poles in the course of their investigations.
However, the point to notice is how the data seemed ideal for the investigation as conceived: intimate life-histories are central to the project.
An equally celebrated study in its day, and one deserving more attention even today, was that undertaken by Robert and Helen Lynd working from Columbia in 1924–5.
This was a study of life in Muncie, Indiana, and typified by an eclecticism of data sources.
They undertook the extensive analysis of various documents, compiled statistics of their own, made use of officially provided statistics and other materials, such as records, participated in community events and organisations, interviewed various members of the community in depth as well as administering a standardised questionnaire to various sets of people.
Although the survey does make an appearance it is very much an adjunct to other methods of data collection.
It was by no means the <pb n=82 most important of the social research methods used; participation in the social life of the community and the consideration of documentary material is given far greater prominence.
However (as we indicated in Chapter 3), between the mid-1920s and the mid-1950s in the United States there was the marked and dramatic shift towards the dominance of survey methods in social research.
A study of the kind of research, published in the official journal of the American Sociological Association for the years 1962 to 1969, showed that 90 per cent of the articles and research notes presented data taken from social surveys using questionnaires.
A small number of studies did make use of observational methods, but a high proportion of these also included supplementary interview data "to bolster their conclusions" .
Brown and Gilmartin also report that"Other anthropological techniques were completely ignored.
Life histories and personal documents were seldom gathered".
Associated with this rise to prominence of the social survey method were new modes of theorising about social action and social organisation.
As Turner and Turner note, the "history of social thought" as a subdivision of the discipline dropped out of view as the "relentless propagandizing for the scientific method" and the identification of science with metrication gathered pace.
Survey research became the paradigmatical method of sociology.
For one thing, the business of developing theory that was responsive to empirical investigation became a much more serious business as did the whole enterprise of methodology as a specific and distinctive branch of sociology and social research.
Parsons's efforts to build a general theory of action, though criticised in some quarters, did at least provide an ambition for social research as something it could and ought to contribute to.
As part of this a rather different kind of social survey emerged and with it new kinds of data.
THE SOCIAL PSYCHOLOGICAL SURVEY
During the 1930s the interest in public opinion polling germinated a more academically oriented interest in attitudes, in part as an attempt to resolve some of the problems arising from electoral prediction.
At this time, and throughout the 1940s and 1950s, a series of attempts were made to take the problems of attitude measurement, and the related issue of the relationship between attitudes and behaviour, very seriously indeed.
And, given its tradition, one of the problems to which this effort was first directed was toward the understanding of voting behaviour and the prediction of election results.
In the United States, what we now recognise as social psychology has always been a rich vein of thought.
Not only have Americans made seminal contributions to the origins of this discipline, but also many American sociologists, and social researchers more generally, have been imbued with an interest in small-group phenomena and in personality and attitudes.
Scholars such as Giddings, Cooley, Mead, Thomas and Znanieki are often considered as contributors to some of the basic ideas of social psychology as well as to sociology.
Scholars in this field had for some time been engaged in a debate over the importance of acquired and inherited personality traits in behaviour.
Attitude research was the property of no school in this respect and constituted a set of problems to which all might contribute.
At this time, too, the vigorous and largely indigenous current of thought and research in social psychology in the United States was given a powerful boost by the influx of expatriate German scholars, liberal democrats most of them, fleeing from the Nazi regime.
Lazarsfeld and Adorno are, perhaps, the best known of these (as we suggested in Chapter 3) as major figures in the development and application of scaling methods in social research.
The work of these men, which was primarily pioneering, though concerned with social surveys as a method, also contributed to American social psychology by suggesting new theories of personality and personality formation inspired by a very different European tradition of thought.
Also in the 1930s and 1940s, as has been argued in the last chapter, such scholars as Lazarsfeld, Thurstone, Likert, Stouffer and Guttman had begun to develop a quite different approach to attitudes than had previously been considered.
Instead of taking attitudes as relatively straightforward guides to behaviour and expressed as opinions, they sought to measure attitudes more as dispositional and rooted deeper in the personality.
They reasoned that an attitude held by an individual is a unique value on a continuum of possibilities or scale, rather than something which is simply present or absent.
Hence, instead of asking a voter whether or not s/he intends to vote Republican, they would ask a battery of questions bearing on many aspects of policy.
In itself this was not so radical a departure from polling methods, and soon Gallup and other agencies began to adopt the same methods.
But the procedures involved were more than attempts to improve the sensitivity of attitude measures; they also involved no little reformulation of the theory of attitudes.
It was assumed that what was being measured was a property of the personality.
Here we have, in fact, a developed form of the variable analysis discussed in the last chapter.
Scholars were seeking to measure attitudes at a high level, and to infer from this different accounts or models of the personality by reference to which behaviour could be explained.
This logic is common to many scaling procedures currently in use, and, of course, incorporates what later became known as the logic of variable analysis in reasoning from observable indicators to some theoretically defined construct.
The study which pushed the techniques discussed here furthest in the direction of theorising about personality on the basis of attitude  survey data was the celebrated work of Adorno and his colleagues reported in The Authoritarian Personality.
In this study several discrete attitude scales were used: the so-called Anti-Semitism, Ethnocentricity, Political Conservatism, and Fascism scales.
The scales were devised using a method originally devised by the American social psychologist, Rensis Likert.
The questionnaire for the survey began with a few brief factual questions about personal details, and a second, more important part of the schedule contained batteries of questions aimed at measuring an individual's standing on the scales mentioned earlier.
For the authors of this study there was a clear expectation that individuals would commonly produce patterned responses which could be ascribed to a particular personality type.
The type they were most interested in was exemplified by persons scoring highly on each of the scales, which they called the "Authoritarian Personality" .
Such personalities were seen as objectifying within the personality a particular sort of social and political ideology, which was the product of determinable social processes.
CHIEF LEGACIES OF SOCIAL PSYCHOLOGICAL SURVEYS
These developments in social psychology and social research made available a whole series of highly sophisticated techniques for measuring attitudes and other social properties.
Though attitude surveys were never widely used in Britain, none the less, the achievements of these researchers have inevitably influenced the work of modern survey analysts in the design and the analysis of questionnaires.
The social psychological survey embodied the practical use of scaling techniques by which the attitudes of respondents were held to exemplify positions on basic dimensions and, in this respect, has profoundly affected the way in which social researchers think about the constitution of "things" that constitute the social world.
Not only was it the structure of attitudes which concerned these scholars, but also they were interested in the dynamics of attitudinal change.
Attitudes can change, can be changed, can be responsive to many kinds of stimuli, such as election campaigns, advertising, interactions with others, and so on, and sometimes such changes are crucial to understanding and predicting the outcome of events.
Elections, for example, are not decided by those electors whose support for particular parties is relatively fixed, but by those relatively uncommitted individuals whose attitudes and voting choices may not set until nearer polling day.
Presumably on many issues, and in many situations, attitudes in everyday life do change, and may change quickly.
Recognising this problem led scholars in the area to make the first serious use of what are called longitudinal studies.
The surveys we have discussed so far in this chapter have all  involved taking a single cross-section sample of a particular population.
But, given an interest in attitude change, a survey taken at a single point in time is not very useful, for no matter how carefully chosen, one sample will fail to capture changes.
Administering, as part of a cross-sectional survey, a series of attitude questions to a sample of respondents, we will not be able to determine which of them are expressing fairly firm attitudes from those responding out of some whim or other, or who have changed, or who simply want to please the interviewer or get rid of him.
Moreover, in a volatile period, such as the run-up to an election, all kinds of events may predispose some people to change their minds and their attitudes, and it may well be important to chart this movement in order to decide if it is systematic, persistent or spasmodic.
In an effort to meet these kinds of problems, Lazarsfeld and his colleagues devised the "panel study" .
In this type of survey a sample of people is recruited to a panel and their attitudes are surveyed at different times.
This has the merit of allowing researchers to identify changes in attitudes among a population in a more reliable way than random sampling where variations might simply be due to variations between samples.
Provided that the panel is selected on a random basis in the first place, we can be sure that the changes identified are real changes in the group and, within a given limit of reliability, in the population as well.
A major problem to guard against is the effect of the research itself.
Repeatedly interviewing the same people can sensitise them to the research, and this may have unknown effects on their responses.
They might, for example, become more interested in the topics the attitudes concern than they might otherwise, or, conversely, become bored.
Another factor is sample mortality.
During the normal course of events people move, die, drop out of sight or get involved in other things, and such events are likely to affect the panel subjects.
To obviate these effects sometimes a series of control samples are randomly selected and interviewed alongside the panel sample to check on the likely consequences of these effects, if any.
Panel studies are an example of longitudinal studies which are not, of course, confined to attitude research.
In the form of "cohort studies" , that is, following single age groups through successive periods, they have proved extremely useful in medical, environmental, educational and policy-related research.
They are also costly which is, perhaps, the major reason why they tend to be little used when compared with the cross-sectional, single survey.
THE EXPLANATORY SURVEY
In Chapter 3 we outlined the logic of the experiment underlying the inferential structure known as variable analysis which achieved its full flowering in connection with the final type of survey we wish to  discuss, the explanatory survey.
In a way all the survey types we have been discussing have been concerned with explanation, at least in the wide sense of this term.
Even the "factual" survey provokes, at some point, the requirement to explain why the facts are as they are.
What we have in mind here, however, are uses of the survey method which are explicitly designed to test particular theories or explanations.
As such, it involves using the survey as a method which, through its design, allows for the testing of theoretically derived hypotheses: this was partly consequent upon the development of statistical methodology.
Just as an earlier generation of social survey researchers in Britain had made use of developments in statistics, so did the post-war generation of social scientists in the United States, though building on work done prior to this period.
The eventual outcome of these innovations was the emergence of the social survey as the dominant method of social research using principles derived, and extended, from experimental designs in biology and botany, and in psychology.
For many years biologists and botanists had been concerned with developing methods for eliminating extraneous variables in their research in order that the factor in which they were primarily interested could be more effectively gauged as to its effects.
For example, in evaluating the yield of a particular hybrid plant, they had to be certain that all the factors which, taken collectively, and variably, affect growth, such as climatic conditions, fertility of the soil, moisture, disease resistance, and so on , were adequately controlled so that the yield of the hybrid could be stringently compared with that of the non-hybrid.
In this way observed differences in yields, or whatever property was under investigation, could be accounted for.
The techniques which emerged to deal with this kind of problem owed much to the pioneering work of R.A. Fisher, and others, and involved elaborations of the classic form of experimental design.
In Chapter 3 we reviewed some of the main principles of experimental design in which a control group is used to assess the relationship between some causal factor and its presumed effect.
In trying to determine the effect of, say, a new teaching style on academic attainment, factors extraneous to this relationship but which might have a bearing on attainment, need to be excluded or controlled in some fashion in order to assess the effect of teaching style.
In this case a control group would be selected which matches as closely as possible, member for member, the characteristics of the people constituting the experimental group.
The presumed causal factor, normally referred to as the "independent variable" , is withheld from the control group and administered only to the experimental group.
So, in our example, it would be the experimental group which was exposed to the new teaching style.
Since the two groups are as alike in all respects except that one of them, the experimental group, has received  the supposedly causal treatment, the new teaching style, then any differences in academic attainment between the two groups must be due either to chance or to the causal factor.
There are a whole set of statistical techniques for assessing the probability that the observed differences between the two groups could have resulted from chance.
Such statistical tests yield statements of probability about the likelihood of a particular result having occurred by chance.
This is what is meant when it is reported that a result, according to a particular test, is significant at, say, the 0.001 level.
That is, the probability is 1 in 1000 for the result to have occurred by chance.
Because this is a low probability the researcher could feel justified in accepting the result of the experiment as, at least, probably demonstrating a causal connection.
Of course, one major problem is ensuring that the experimental and the control groups are as alike as possible in all relevant respects.
Accordingly, the researcher needs to know a great deal about likely extraneous factors so that they can be controlled.
In the example here it might plausibly be supposed that the age of the pupils might well influence attainment or otherwise modify the effect of the causal factor.
In which case it would be verging on the absurd to have one group composed of 8 year olds and the other of 16 year olds.
In this case, the researcher has the choice of restricting the samples to one age-group, or increasing the sample size to include wider age ranges.
But assuming that matches can be achieved on all the known likely factors, there may well be others that could affect the main relationship of interest that are not known about.
Accordingly, in allocating each of the matched subjects to either the control or to the experimental group, and to ensure that there is no surreptitious influence determining this allocation, the researcher randomly allocates one of each matched pair of subjects to one or the other group.
In this way the effects on any unwanted and unknown factors are randomised and should exert no untoward effect on the outcome of the experiment.
Matching and randomisation are the two key principles here.
The logic instantiated in this research design has been used to effect in some branches of psychology and medicine as a method for testing causal explanations.
It is also a design adopted by some survey researchers, though in a truncated form.
The degree of control of human populations required by the design, especially in the random allocation of subjects to experimental and to control groups, and subjecting one but not the other to the causal treatment in the field, is practically impossible.
This is quite apart from any moral objections that might arise.
So, only approximations to the classical model can be achieved.
In place of the random allocation of respondents to the control and experimental groups, survey analysts have to be content with random samples from different groups which occur "naturally" in the population.
In place of the controlled administration of a "treatment" , survey  analysts have to ensure that individuals with different experiences or attitudes or characteristics are represented in the sample by stratification, or similar, procedures.
Neither practice has the rigour of the design of the classical experiment.
In fact, much of the use of the logic of experimental design in survey work takes place at the data analysis stage through elaborations of the cross-tabulation technique (described in Chapter 3).
Although this use of the survey seemed to offer to social scientists a more scientific way of approximating closely to a natural scientific model of research, incorporating measurement and quantification, hypothesis-testing, generalisability and theory relevance, it has not been without its problems and controversies.
One such concerned the validity of the statistical tests upon which much of the power of the method seemed to depend.
Another, more prolonged and more significant, concerned the very foundations of variable analysis, and by implication the explanatory survey, namely its empiricist inspiration.
The first of these, the statistical test controversy, arose in the 1950s when a group of American scholars vigorously attacked the use of such tests, pointing out the difficulty of surveys meeting the strict mathematical requirements demanded by the statistical theory, especially those to do with randomness.
The random selection of units was vital.
Unless this condition was met inferences about relationships within the sample could not be statistically secured.
The standard defence against this charge was to concede the statistical point but, none the less, argue that such measures were valuable indicators of possibly significant or interesting relationships in the data.
Both sides, however, agreed that the use of statistical tests without a well-thought-out theory was little more than useless.
In other words, statistical testing should not be used as a substitute for theoretical ideas by simply dredging the data for any statistically significant relationships that happen to be present.
It is the theoretical significance that is important.
In fact, the statistical significance test controversy was the precursor of concerns that turned out to be rather more fundamental to variable analysis; concerns that were not voiced by such as Becker and other Symbolic Interactionists who wanted no truck with a sociology derived from variable analysis (and whose criticisms we shall review later in this chapter), but by advocates of variable analytic and survey approaches.
In brief, such doubts centred around the use of experimental designs in this context and, related to this, the nature of the knowledge such an empiricist research strategy was capable of producing.
We raised the matter of theory in connection with the explanatory survey: the testing of theory was the point of such a research tool and the rationale behind the inferential structure of variable analysis.
The testing of theories or, more accurately, hypotheses derived from  theories, was to be done using principles of experimental design and statistical testing.
Unfortunately, in a number of respects explanatory surveys failed to match up to the strict requirements of the logic required.
The normal practice of surveyors is to select groups of interest and sample within these using an appropriate list giving full coverage of the population to be sampled.
It is at the analysis stage that the logic of the experiment is deployed: in an important sense, this is too late a stage.
The classic experiment requires both a control and an experimental group to which subjects are randomly allocated.
In this respect, and prior to the experimental treatment, the two groups are as alike, in all relevant respects, as they can be.
However, in field conditions nothing like this is ever attempted.
Instead, random samples, simple or stratified, are taken for the survey.
Then, when the data have been collected, the respondents are grouped into homogeneous categories according to their scores for selected variables.
Thus, occupational type might be used, and for ease of exposition, the categories manual/non-manual.
Clearly, although respondents so grouped will have this property in common, they will undoubtedly also vary on lots of other factors, such as level of education, income, attitudes and beliefs, number of siblings, ethnicity, age, gender, and many more.
These, or at least the more salient ones, the analyst will try to control by partitioning, that is dividing each of the original occupational categories into, subgroups with other possibly salient characteristics in common.
In this way, it is proposed, the effect of occupation on, say, political affiliation, can be explored by holding constant marital status, level of education, etc.
However, it is necessary to note that there is a limit to the number of variables that can be held constant in this way.
These may be practical limits, but are real enough.
The main ones are as follows.
First, a survey can ask only about a limited range of matters.
Kinsey, in his pioneering studies of human sexual behaviour in the late 1940s, may have made use of eight-hour interviews, but in the vast majority of surveys these are out of the question.
The point is that data analysts can control only for those factors on which they have data.
This is true of the experiment but, by the random allocation of subjects to the control and the experimental groups, any effects of the unknown factors are randomised.
This cannot be assumed so easily in variable analysis.
Second, statistical partitioning requires expected cell frequencies of, roughly, between ten and twenty cases otherwise tests of significance and measures of association become unstable and unreliable.
This constraint means that even with large samples of, say, 1,000 respondents, controlling for three or four factors at once means the analyst is likely to run out of cases very soon.
Third, using the example of occupational categories again, even assuming that a researcher has selected the sample randomly, only later dividing the  group with respect to the property of occupational type, this is hardly the randomisation required by experimental design.
To repeat, in this randomisation is intended to neutralise the effects of all confounding factors, while in the case of the survey this is not so.
The random selection of cases is an approximation to experimental randomisation if it can be assumed that the population from which the sample is drawn is homogeneous: a reasonable assumption when dealing with a population of seeds, plants, germs, etc.
It is less reasonable, we suggest, when dealing with the social properties of human beings.
Moreover, it is one of the founding presuppositions of sociology, one might say of social science more generally, that individuals are related to each other rather than isolated.
They are members of groups, associations, cultures and subcultures, families, neighbourhoods, work groups, organisations, and have many other affiliations.
It simply cannot be assumed that samples selected for their distinctiveness on one variable will vary randomly on others.
The sociologist makes the opposite assumption.
There are a number of complex issues bound up with this particular matter, ontological and epistemological, practical as well as theoretical.
Sampling individuals for, say, opinion polling prior to an election is a reasonable procedure since the act of voting is an individual one.
The outcome of the election is, at least in simple majority systems, a direct arithmetic consequence of the individual votes cast.
From this point of view, the factors which influence an individual's voting choice are less relevant: what matters is the choice and its distribution.
But the objectives of an explanatory survey are not likely to be so straightforward, and it may be that sampling individuals, though convenient, does not sample the phenomenon of interest.
Sampling theory is aimed at providing a mathematical justification for inferences to some population value on the basis of knowledge of a subset, or sample, of that population.
In this regard, achieving a representative sample is the objective.
It is this requirement which requires a listing of the population members, or units, from which the sample may be drawn using a random procedure.
Accordingly, if one wishes to produce a sample to estimate the prevalence of certain characteristics in the population of the United Kingdom, in principle one has to be able to list that population.
In cases such as this substitutes to this ideal are used, such as electoral registers, lists of households, etc., with the proviso that such lists, while convenient, may not include, for any number of reasons, all the units that belong to the population of the United Kingdom.
Given that we can adequately define who to include as belonging to the category "the population of the United Kingdom" , and providing that we have convenient lists which do not seriously under-represent significant subgroups, then reasonable estimations of population values can be made from the sample.
However, such a procedure is not always suitable for explanatory research since, in this case, the aim is to achieve sufficient cases for analysis rather than a representative sample of some population.
Indeed, in many such cases, it is not at all clear what the parameters of the population, of which the sample is a subset, actually are.
 "Deferential conservatives" , "militant labourites" , "alienated workers" , "authoritarian personalities" , are types that are a sample of some population, but we could not list that population in advance.
In most cases of explanatory surveys it is perhaps less appropriate to speak of samples at all in the strict sense.
What explanatory surveys require are cases which possess characteristics relevant to the problem of the research.
Thus, selecting cases needs to be done on the basis of theoretically informed criteria rather than those to do with representativeness.
This may require targetting particular, and known, subgroups of the general population in order to obtain sufficient cases, or respondents that will contain sufficient cases.
There is an additional point worth noting here.
The social survey makes use of the interview and/or the questionnaire, a method of data collection obviously designed to be administered to individuals.
As a result, the sampling units are ultimately, even if stratification or a similar strategy is used, individuals.
It is the responses they provide which constitute the data recorded and analysed.
It is individuals who, in one capacity or another, appear on lists used by surveyors to select as their samples.
However, it is this which is a possible disjunction between the instrumental presuppositions of the survey and various theoretical conceptions of the phenomena that are the subject of social research.
It is a crucial postulate underpinning all the social sciences that individuals are related through associations of various kinds.
In short, it is not so much the isolated individual, or even a large number of isolated individuals, that is the focus of interest, but individuals- in-relation-to-other-individuals.
In this respect, then, it can be argued that the survey is too individualistic, not only in the sense that only individuals can respond to questionnaires, but also in that every individual is assumed to have as much importance as every other.
As Galtung puts it, in surveys every individual is "made to appear in the sample as a society of one person to be compared with other societies of one person" .
The only way in which such a procedure might be excused is if the societies from which the samples were drawn were homogeneous — an assumption which is hard to sustain.
Although individuals may be grouped on the basis of various variable scores, this is almost always without regard for their position within the social structure.
In other words, and as Lieberson stresses, there are selectivity processes at work in almost all social settings that vitiate, in the end, the idea of random sampling.
There are, of course, ways of attempting to counteract this excessive individualism of the survey.
For one, the sampling procedure  could be designed so that individuals are selected according to their position within the social structure or social group.
Such purposive sampling could sample individuals along with other individuals with whom they are significantly related, such as members of their family, stated friends, work-mates, or whatever is appropriate.
This is in fact the implicit approach of some observational methods as we shall see in Chapter 6.
Another method is to collect information on structural and other contextual properties and to use these as a basis for sampling.
In any event, surveying becomes a much more complicated business and much more difficult to execute satisfactorily.
Purposive sampling, for example, could not be effectively done in advance of interviewing, since significant others could only be guessed at without the informant furnishing more detailed information.
Galtung suggests that the individualistic survey method may well yield results that reflect conditions prevailing in one type of society only, that is societies which rate highly both on individual mobility, geographic, horizontal as well as vertical mobility, and on inner- directedness.
Thus, the traditional survey based on random samples from populations of individuals and the effort to account for what they do in terms of an interaction between attitudes, personality and general background structural factors, implies that we have an adequate understanding of the relative importance of social position, personality and the relationship between the two.
Galtung goes on to suggest that social science needs a much richer conception of what constitutes the social unit, bearing in mind that these may well need to change from society to society.
The counterpart of the survey is the election.
The democratic principle is one person one vote, as is the principle of statistical analysis.
Thus a democratic bias is introduced which may be inappropriate where individuals do not count equally.
CONCLUSION
There can be little doubt that the survey since its modern inception has had a major impact on social research, and any history of social research has to award it a salient place.
It is probably the method most associated with the idea of social research constituting the source of much if not most of social science data.
What is also of interest here, and this relates to a point Galtung makes, are the historical and social conditions which make the survey, like any method of social research for that matter, possible as instruments of data collection.
This is not only to do with the intellectual innovations that led to the idea of the first factual surveys through to the social psychological and, finally, to the explanatory surveys incorporating variable analysis, but also to do with what is indicated about the nature of society and social life.
Surveys, we might say though all too briefly, depend upon mores that  allow individuals to be interviewed about their private lives, their feelings, attitudes or beliefs, without feeling unduly threatened, intimidated or insulted.
The survey requires, too, an institutionalisation of the individual as an autonomous member of civil society with rights and obligations and a conception of the same individual as a distinctive agent in the social process.
The individual is the provider of material and data, is sought after for this purpose, is the bearer of social forces and is the agent of society itself.
Indeed, one could hazard a further, and more general, observation that the possibility of social research itself is an indicator of the character of society; to paraphrase Lieberson, social conditions not only determine the data of interest but also shape the availability of those data.
Celebrating the importance of the survey in the history and contemporary milieux of social research is one thing; but this importance does not place it beyond criticism as a method of social research.
As we indicated in the discussion of sampling, the survey method, especially the explanatory survey, has been subjected to severe criticism and from social researchers whose own careers have been forged within the tradition of variable analysis.
Lieberson in a powerful and detailed critique of experimental thinking in social research, after all one of the cornerstones of variable analysis, argues that although most data in social research are non-experimental in origin, they are "treated as if they were truly experimental data…sliced, chopped, beaten, molded, baked, and finally artificially coloured until the researcher is able to serve us proudly with a plateful of mock experiment" .
As should be clear, this is precisely the objective of variable analysis and the explanatory survey, that is to emulate the experimental method in the collection and analysis of non-experimental data.
Lieberson goes on, "we are still totally oriented to the experimental model" .
Researchers without very much thought, continually try to manipulate non-experimental data so as to approximate as closely as possible to the kind of experiment held to epitomise natural science.
But to do so, he maintains, they are obliged to make impossible assumptions that "generate analyses that are completely off the mark" .
Although the details of Lieberson's argument are often statistical, formal, carefully wrought and complicated, the burden of his complaint is that controlling in most social research ignores, or fails to deal with adequately, selectivity in the controlled variable.
This is a not dissimilar point to the one we made earlier concerning sampling individuals from a social world which is relationally organised.
To put it briefly: in social science one is dealing with situations in which people, ignoring their birth, have not been randomly assigned to their respective social universes.
The social world is an organised world.
In which case, the absence of random assignment, to use Lieberson's rendering of the problem, presents special difficulties if "there is  reason to believe that the subjects thereby placed in each condition differ in other ways that themselves have a bearing on the outcome of interest to the researcher" .
For example, suppose a researcher wishes to determine the influence of military service on later civilian earnings.
Simply comparing the incomes of those experiencing military service with those who did not will not do.
There are good reasons to think that military service is not a random event, irrespective of whether there is a draft system in operation or simply voluntary service.
Social processes operate, "selectivity" in Lieberson's terms, such that volunteers, draftees or those never serving, will differ from one another on factors that will have a bearing on life chances, hence income, later on.
It cannot be assumed, as can reasonably in many experiments in natural science, that units are identical.
Selectivity affects variables or attributes that influence the outcome or the dependent variable: the problem is, if using the experimental mock-up, to separate out this initial selectivity from the impact of the institution, in this case, the military.
Matters are made worse if different selectivity processes are operating for each subgroup.
Thus, to continue with the example, different processes, or the same processes with different magnitudes, may well operate between volunteers, draftees and those with no military experience.
Such unmeasured selectivity processes are operating in most social research.
The reason why Lieberson is doubtful about the control variable approach is the selectivity processes are probably operating within the control variables themselves and involve factors which affect the dependent variable but in unmeasured ways.
In a series of examples, Lieberson goes on to demonstrate that under a variety of conditions, unmeasured selectivity can produce wrong answers and identify wrong patterns.
That is, the assumption that by controlling a researcher can move closer to the truth, or is at worst a benign procedure, cannot be sustained.
Another set of problems that has serious implications for the social survey involves issues to do with data analysis rather more than collection but, none the less, does have a bearing in getting us to understand the limits of the survey and of variable analysis.
Most social surveys are cross-sectional, for obvious reasons of cost, even though the topic of the research may well be social processes of various kinds, such as attitudinal change, changes in life-style and life chances.
Many of the techniques, and importantly the theories, used to analyse such data make assumptions about the nature of such processes, particularly that they are symmetrical and reversible.
Suffice it to say that the cross-sectional survey is not well attuned to handling processes, but this is a much more serious matter if one abandons the assumptions of symmetry and reversibility.
In examining, for example, the influence of X on Y, it has to be considered whether shifts to a given value of X from either direction have the same consequences for  Y. Does it matter, that is , whether X has increased or decreased to reach its present level, or whether the relationship is asymmetrical in that different values of X do not have a uniform effect on Y?
Further, a great deal depends upon whether processes are reversible or irreversible.
A reversible process would be one in which changes in X cause an increase in Y and a reversal in X produces a decline in Y. An example of this would be the move toward a more punitive style of management in a factory (X) which increased absenteeism (Y) which declined when a move is made to a more indulgent management style.
An example of an irreversible process would be Weber's essay on the influence of Protestantism on the development of capitalism.
Once the attitudes toward the acquisition of material goods and worldly signs of success had been acquired, then any decline in religious beliefs would leave the attitudinal changes unaffected.
The point that Lieberson is making is one concerning multivariate analysis but also has lessons for the cross-sectional survey.
First, theory needs to be explicit about whether it is dealing with symmetrical or asymmetrical, reversible or irreversible relationships.
Second, whatever is determined about this, it is crucial to determining whether or not the data produced by the cross-sectional survey can provide accurate estimates of the relationship of interest.
This Lieberson doubts.
We have spent some space reviewing Lieberson's arguments because he provokes an important critical reaction which is necessary to uproot the widespread belief that the survey is the answer to social research's dreams.
The early proponents of the explanatory survey felt that they could, through the logic of variable analysis, closely approximate to the experimental model using non-experimental data and, through the patient accumulation of findings discover law-like relationships about the nature and processes of social life.
This hope it begins to appear, admittedly with hindsight, looks to be one that must remain unfulfilled using current methods.
For one thing, the Lazarsfeldian method is empiricist, that is concerned to discover empirical regularities or patterns among phenomena.
While not denying that this has an important role to play in any science, it is not clear that it is the method responsible for the discovery of natural laws.
To quote Lieberson once again: imagine an inquiry, using the logic of social research, into why objects fall.
The strategy would be to find that different objects fall at different rates and, likely as not, determine that two variables were mainly responsible — size and the shape of each object.
Both of these would account for most of the variations in the different rates of fall.
It would not, in other words, discover gravity.
The strategy could not make, nor sustain if it could, the ceteris paribus conditions such as the idea of a perfect vacuum in which objects fall at a constant rate of acceleration whatever their size and shape.
In "real" conditions where friction, for example, can affect the  rate of fall, we would have a parallel situation to that of the social scientist.
This does not, of course, have any bearing upon whether or not there are such laws of social life to discover or imply that the survey method ought to be abandoned.
Certainly there are many who would concur with at least the gist of Lieberson's, and others', criticisms but argue that more effort should be directed at improving methods of data collection and analysis to meet these kinds of objections.
There are others,(we shall meet some of them later) who would argue that this urge to emulate the natural sciences in this way is premature.
In any event, the idea that Lazarsfeld had discovered a ubiquitous method of social research has to fall by the wayside.
Interviewing
Interviews are encounters between a researcher and a respondent in which an individual is asked a series of questions relevant to the subject of the research.
The respondent's answers constitute the raw material to be analysed at a later point in time.
Usually a questionnaire, sometimes referred to as an interview schedule, is used in the interview and contains the questions that the interviewer puts to the respondent.
Questionnaires are sometimes used without an interviewer, the respondent completing the questionnaire without any assistance other than the guidance provided by the written instructions on the questionnaire itself.
Questionnaires depend on the use of some verbal stimuli — normally a question, but sometimes a statement expressing an attitude or an opinion — designed to elicit a verbal response which is recorded and subsequently analysed along with other responses from other interviewees.
Interviews are normally, though not exclusively, used in surveys.
Respondents are selected according to some sampling procedure to be representative of some group, collectivity, attribute or process.
For example, a researcher interested in the factors responsible for differing rates of absence from work may well interview groups of workers randomly selected from lists of employees in large factories and small ones, factories which have high or low overall rates of absence, or factories which involve different kinds of production processes.
Any one, or a combination of these, may be chosen as the basis for choosing the work-places from which a sample can be selected.
Similarly, a researcher interested in the determinants of voting choice might select respondents to interview from an electoral register.
Each of the sample members would then be interviewed and the results cross-tabulated to see what differences, if any, there are in the replies from each of the sample collections.
However, interviewing is not the exclusive preserve of survey research.
It is not unusual, for example, to find participant observers using interviews.
In such cases the interview is used to collect illustrative material to complement other material and findings.
In such cases the issue of representativeness is of less concern than in the sample survey.
Yet the interview, especially of the formal and standardised type in which questionnaires are used, is more commonly  used in connection with survey research, which means that standardised interviews using questionnaires are the most frequently used social research technique.
There must be few people in modern industrial societies who have not taken part in an interview for a social survey for the purposes of market research, public opinion polling or academic research (see Chapter 4).
Of all the methods available to the contemporary social researcher, the interview, in conjunction with the sample survey, is the one most typically associated with social research itself.
For some, social research and the sample survey are the same: most reports of academic research published in the field of sociology make use of the interview as a means of data collection.
There are, of course, some obvious practical benefits in the use of interviews and questionnaires in surveys; the main one being that they are an economical way of obtaining data related to the behaviour and attitudes of large and sometimes scattered populations.
There is now a considerable body of lore and detailed research on the interview method devoted to understanding the dynamics of interviewing and how, in practical terms, its effectiveness as a data-gathering instrument can be improved.
Some of this we shall be looking at in this chapter.
As with survey techniques, interviewing practices have also evolved.
Indeed parallel with developments in the methodology of the survey, there has been a similar effort to make the interview a much more standardised, methodical and effective instrument of social inquiry.
Much of this, if not all, has been within the tradition of variable analysis discussed in Chapter 3; that is, making the interview serve the requirements of objective and quantifiable data in the variable analytic format.
The early surveys sought factual information about people and tended to ask straightforward questions to elicit this information.
They specialised in questions which, to quote Bowley, "required an answer of 'yes' or 'no' or a simple number or something equally definite and precise" .
Contemporary surveys also make use of such questions, especially to do with face-sheet information about a respondent, such as age, marital status, and so on, but usually in conjunction with other types.
The social psychological survey also left a legacy in the attitudinal questions which are very often contained in questionnaires.
With the explanatory survey and the refinement of variable analysis as a way of thinking about social research, the interview and the questionnaire have become most important instruments in achieving the dream of a quantitative social science: it is this which has also modified the character and the rationale of interviewing and questionnaire design.
A great deal of valuable work has been carried out on the interview itself.
In the past, the interview tended to be regarded as simply a means of collecting factual information from respondents and, by itself, of little interest.
Today, however, there is a much greater realisation that the quality of the data is important to their precision and quantification and, in this regard, it is important to be able to assess the validity and the reliability of those data by understanding the nature of the collection instrument itself, the biases that it is heir to, and the kinds of instrumental corruptions that can affect the quality of the material it provides.
In order to understand better the data produced, it is necessary to understand better how and in what ways the instruments that produce those data work.
In this chapter we shall, first, consider the rationale of the interview as offered in contemporary social research.
Second, we shall look at the types of interviews and the way in which they commonly feature in social research.
Third, we shall address some of the problems associated with interviewing and the use of questionnaires in the context of variable analysis.
Fourth, we shall also look more fully at some of the implications of the recognition that the interview is a social process as much as it is a research technique; implications which are, potentially, far reaching.
THE RATIONALE OF INTERVIEWING
The foundations of interviewing lie in the mundane observation that individuals can report on what they feel, are, have, tell others about their lives, disclose what their hopes and fears are, offer their opinions, state what they believe in, say what they did last week, how much they spend on food, who they see regularly, and so on; in short , they can impart masses of information about themselves.
The point of the interview is to make full and systematic use of this to gather data for research purposes.
In its way, this unremarkable fact about human beings has, in the hands of skilled researchers, created a remarkable instrument of social research.
Using as data what respondents say about themselves offers the social researcher access to a vast storehouse of information.
Researchers are not constrained to what they can observe or experience directly, but are able to cover as many facets of as many people as resources allow.
Nor are researchers limited to studying small numbers of people, as is the case with participant observation, but can, in principle, investigate many thousands.
After all, the census questionnaire is intended to cover the entire population of the country.
Researchers are not limited to studying only members of their own society but can interview people in other societies including people who may be illiterate and therefore leave no written record of their activities.
Using verbal reports offered by respondents, the investigator has access to an almost infinite variety of information that would be impossible to gather by any other means.
When reports are analysed using the various methods of statistical  treatments available, they can be used to describe fundamental features of society, its nature and changes.
We can now begin to see a little more clearly some of the instrumental presuppositions on which interviewing depends.
For one, the method is predicated on a claim that answers offered by a respondent to questions proffered by an interviewer are indicators of whatever aspects of the respondent's social life and being that are the subject of investigation.
That is, to put it at its most basic, the respondent is at least an adequate reporter of his or her attitudes, beliefs and other subjective states, his or her relationship with others, past, present and intended behaviour, and about objective features of the respondent's life.
This presupposition may seem an uncontentious one but it is far from that.
TYPES OF INTERVIEW
The most common criterion for classifying interviews is in terms of their degree of standardisation; that is, according to the extent to which the interviewer is allowed to vary both the content and the order of the questions asked.
At one extreme is the structured interview in which interviewers use a schedule to which they must strictly adhere for all respondents.
The same questions and the order in which they appear on the schedule would be administered, in a survey, to all respondents by all interviewers in the same way: this is to standardise stimuli.
That is, in an effort to ensure that any variations in replies respondents provide are not artifacts of variations in the way in which the questions were asked, each respondent should be given the same questions in the same serial order.
Thus, if an interviewer were to ask some questions of a respondent in one way and to another in another way, the researcher could not be sure what effect this variation in the administration of the questions had on the responses received.
A question asked early in the interview may affect answers to subsequent questions, and if this order were to be altered it becomes difficult to detect the effect this might have on the replies.
Of course, it is necessary to assume that the questions, however they are phrased, are understood in the same way by all respondents whatever differences they may have in other respects, such as level of education or gender.
Unless all respondents share a single interpretation of a question their answers cannot be compared.
(This is a point to which we shall return.)
However, there is a place in social research, and a very important one, for the type of interview which stands at the other extreme to the structured one, namely the non-standardised interview.
In this type interviewers work from a list indicating, often in some detail, the kinds of topics to be covered in the interview.
Interviewers are free to ask <pb n=104 questions in whatever way they think appropriate and natural, and in whatever order is felt to be most effective in the circumstances.
Both interviewer and respondent are allowed much greater leeway in asking and answering questions than is the case with the structured interview.
Such an interview almost amounts to a conversation.
Flexibility is the keynote and is a feature often recommended in pilot studies preliminary to a full-scale study.
It is also particularly useful where highly sensitive and subtle matters need to be covered, and where long and detailed responses are required to understand the matters the respondent is reporting on.
In a pilot study it allows researchers to test out various lines of questioning, different ways of phrasing questions, gauge the tenor of likely replies, and so on.
The focused interview is closely related to the non-standardised or unstructured interview, and differs mainly in the extent to which the direction of the interview is controlled by the interviewer.
Between the two extremes of standardised and non-standardised interviews is the large category of semi-structured interviews.
As their name suggests they combine, or attempt to do so, the advantages of both of the two polar types.
The interviewer is normally required to ask specific questions but is free to probe beyond them if necessary.
The relative weight of standardised and non-standardised items can vary from research to research.
The most common arrangement is to use the standardised format for "face-sheet" information, such as age, sex, marital status, educational experience and other relevant data of a demographic character.
The less standardised section is used to elicit information more varied and qualitative in character.
Each type of interview is designed with a particular research task in mind.
The non-standardised type is most suitably used in exploratory studies where little of any systematic nature is known about the topic.
In studies such as these the researcher might interview a small group of people in a fairly free-ranging manner with the intention of gaining useful guidance for the construction of more systematic and standardised interview schedules.
The researcher will be looking for indications of the salience of topics, the extent to which questions are understood by different classes of respondents, the likely range of replies to given questions, and so on.
These pilot studies are often of immense value in the design of more systematic and more extensive social surveys.
There is a limit to which the non-standardised interview can be used with larger samples.
It is extremely costly in time and money since such interviewing can easily take two hours or more, and the data produced are not easy to code and analyse.
In fact, pilot studies using the non-standardised format are a useful guide to the coding categories a researcher might use in a larger survey.
Accordingly, where large samples are necessary, the structured or semi-structured format provides a number of advantages.
They are less costly in time  and effort to administer, more straightforward to code and process, and can be used by interviewers not fully conversant with all the fine details of the research.
Further, the quantitative form in which the results of standardised interviews can be cast makes it especially important for the testing of hypotheses.
QUESTION AND QUESTIONNAIRE CONSTRUCTION
In designing questions and questionnaire schedules for use in standardised or semi-standardised interviews, the first question that needs to be addressed concerns the objective of the study.
What information is the questionnaire intended to elicit from the respondent?
Whatever theoretical ideas inform the research will have to be translated into questions, or statements, which can be administered to a relevant respondent.
One obvious constraint here is that the questions must be cast in a form understandable to the vast majority of respondents.
There would be little point, for example, in asking about "social integration" or "anomie" .
Concepts such as these will have to be translated into readily understandable questions, the answers to which can serve as indices of the more abstract and theoretical concepts.
There is an art to the design of questions and questionnaires.
Apart from the content of the questions decisions will have to be made on the form of the question-and-answer unit.
Basically there are two choices here, between "open-ended" and "closed" or "fixed-alternative" questions.
The "fixed-alternative" question provides respondents with a selection of answers, "yes" or "no" or "don't know" being the simplest, from which they have to make the choice which best reflects their answer to the question.
In some cases such multiple choice items form attitude scales in which each alternative is given a numerical weighting so that a set of such items can be cumulated to give the respondent an overall score on the scale.
For example, a questionnaire designed to investigate attitudes towards work may provide respondents with a list of statements indicating a point of view to which they have to express a level of agreement or disagreement (see Figure 5.1).
Depending on the particular dimension being measured, the degree of agreement may be given a higher weighting and that of disagreement a lower one.
A scale like this will normally consist of a series of such statements tapping the same attitudinal dimension.
The cumulated score over all statements constituting a particular scale provides the researcher with a quantitative means of describing respondents in terms of their scores which can then be correlated with other variables of interest to the research.
The "open-ended" item allows respondents the freedom to provide an answer in whatever form they choose.
For example, "What do you think about Mr Gorbachev?" or "Who do you think is going to win the next election?" 
Unlike "fixed-alternative" questions, the coding categories of "open-ended" items have to be decided after the interviewing stage of research is complete in order to see the range and kind of answers produced by the question.
It also takes longer to ask "open-ended" questions and to record the responses.
However, sometimes the richness of the responses makes this a price well worth paying.
It is not unusual for questionnaires to contain a mixture of both types of questions.
In the main, "open-ended" questions are best used, conventional wisdom argues, in exploratory surveys when a researcher needs to elicit the respondent's frame of reference without undue constraint by the format of the question.
They do also help to achieve and sustain rapport and stimulate the respondent's thinking.
The wording of the question is as important as the form.
A question should be free of ambiguity, precise and clear; each question should express a single idea.
Asking a question such as "Should Britain spend more on defence or on education?" and requiring a single response one way or the other does not cover those cases where a person might feel that more should be spent on both, or, for that matter, less on both.
The question begs other questions and is potentially leading and confusing.
Loaded questions should also be avoided, although in statements comprising attitudes scales such "loading" is often deliberately intended to express a strong point of view with which the respondent can concur or not.
Questions should also be as short as possible, be easily understood, and avoid esoteric language.
They should be specific about events and topics: instead of asking, "How often have you been off work?" , ask, "How many times in the past two months have you been off work?" 
In this way a standardised frame is provided for all respondents alike making comparisons easier and more sensible.
In phrasing questions it is as well to remember to protect the self-esteem of the subject by avoiding subtle hints as to what is an appropriate or desirable answer.
Also, it is necessary to avoid giving the impression that the respondent's answers are in any way exceptional no matter how hair-raising.
In the case of "fixed-alternative" questions, the alternatives provided should be exhaustive covering all possible ranges of response including "don't know" or "no answer" , and be mutually exclusive.
The order of questions is another matter which needs careful attention: initial questions may predispose answers to later ones.
A technique known as "funnelling" in which more general questions are followed by more specific ones amplifying the general ones can be useful in guiding the interviewer through the schedule and encouraging the respondent to give fuller answers.
Using this mode of question organisation, a respondent and an interviewer can often be guided through subsets of questions.
For example, questions of relevance only to married women can be prefaced by a general question about marital status followed by an instruction for those who have answered in a particular way to move to the relevant subset.
Sequencing questions can play a helpful role in easing the respondent into the interview.
Uncontroversial and fairly routine questions — not always easy to spot — should normally come at the beginning, leaving personal and more intimate ones for later.
By then the interviewer and respondent will, hopefully, have established sufficient rapport.
Closing the interview can be eased by using less challenging questions.
One final point as far as the design of questionnaires is concerned.
An interview can last anything from fifteen minutes to a few hours, though normally one hour is considered long, so it is essential to maintain the informant's interest and attention for the duration.
This means that the designer must avoid long unbroken sequences of questions demanding little thought or deliberation from respondents, otherwise they are likely to grow bored and inattentive and provide ill-considered answers to get the interview over with.
This can be especially serious in the case of attitude scales where respondents by simply offering the same answer to the series of items produce a "response set" so distorting the score.
The judicious use of "open-ended" questions can go some way to mitigating these effects by making the questionnaire more varied and interesting.
But the designer must not go too far in the other direction by filling the schedule with deeply sensitive and thought-provoking questions so that the respondent is exhausted after a short period.
Many of these difficulties can be anticipated and corrected by testing the questionnaire in field conditions prior to the full-scale study.