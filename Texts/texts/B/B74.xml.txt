

Remedial lessons for physics
It's official — physics in a bad way.
That is, if you exclude from ‘physics’ the glamour areas of astronomy and particle physics, leaving the substantial but hard-to define area that includes our knowledge of solids, liquids and gasses, interactions between atoms and electrons, magnetism, instruments and techniques.
The word is that morale is at a low ebb among university researchers in ‘mainstream physics’.
The reason is largely that younger researchers are unwilling or unable to embark on a career in this kind of research.
Those who are brave enough to hope for one of the few lectureships around tend to go for the astronomy or nuclear physics.
Elsewhere there is a preponderance of older lecturers who have heavy teaching loads, a discouraging success rate for grant applications, and a shortage of people actually to carry out the research, so physics departments have to be very determined indeed to maintain a thriving research programme.
Not all of them are.
Yet the physicists maintain, this type of research underlies new developments both in technology, and other sciences.
Such all-embracing inventions as the transistor, X-rays and nuclear magnetic resonance spectroscopy all come into this category.
And if such research is neglected, no-one will stumble over the next brilliant idea.
Against this background with the general shortage of funds for science, all researchers are being forced to justify their demands in terms of‘packages’— research arranged around well-defined themes.
Physicists seem to be finding this particularly difficult.
First, physics itself is dealt with in a disparate way.
Particle physics and astronomy each have their own source of funds; so does engineering.
A given physics department may have money from all three of these, as well as the general physics pool.
Also, say the physicists, the nature of physics itself makes it difficult to compartmentalise.
And they are reluctant to make the categories so tight that really original work cannot break through.
Despite the difficulties there are now eight or nine themes that define the programme of the physics committee of the science and Engineering Research Council.
They include the development of new lasers, magnetism in metals, electronic properties of organic conductors, and such like, with particular emphasis on working in collaboration with industry where relevant.
It is now up to the mainstream physicists to show that they can organise themselves to the point where they can justify their basic funds, and the extra money that has now been set aside for them (This Week, 3 February, p 287).
Then they could talk about bringing all the funds for physics under one umbrella.
The debate in physics has highlighted other issues that will not be so simply resolved.
The first is the number of big machines in basic science that the SERC is trying to build on a tight budget.
As a result equipment is late coming on stream — a blow to the morale of the users.
And when it comes there is not enough cash to make the best use of it.
An added irritant is that the SERC employs permanently people who would not even get jobs in universities now.
The result is that they fail to do the jobs they take on, witness the case of an operating system for the PERQ computer (This Week, 20 January, p 144).
Meanwhile the SERC will not employ people in universities: it will give them short-term contracts only.
Will the Department of Education and science inquiry into where research council money goes grasp this nettle in its report, due in April?
That would throw up some even more interesting questions — and might eventually drive research money back into the universities where, at least for the most part it belongs.
That sinking feeling
THE COMPUTERS on board HMS Sheffield functioned effectively prior to and during the attack; allegations that the Exocet missile was mistakenly identified as friendly are without foundation.
So said defence minister Peter Blaker last week in response to a question from Tam Dalyell.
Despite this official denial,New Scientist stands by its report that the Abbey Hill electronic support measures (ESM) equipment aboard the destroyer identified the missile that sank it as friendly (This Week, 10 February, p 353).
After the sinking of HMS Sheffield, the Ministry of Defence asked MEL (which makes the Abbey Hill equipment) to come up with a modification to ensure that it rapidly alerted crews to further Exocet attacks.
Until the Sheffield incident, the MoD had abided by an agreement with Exocet's French manufacturers that the British would not open up the missile's guidance section.
After the attack on Sheffield, MoD technicians got out their screwdrivers.
The Royal Navy rapidly came up with a countermeasure once it had discovered exactly what circuits Exocet used to foil attempts to head it off.
As the Fleet Air Arm's quarterly magazine says, ‘A more unusual task was the manufacture of Exocet decoys.’
The Royal Navy formed a special squadron, No 815, to carry these decoys on Lynx helicopters aboard the aircraft carriers in the South Atlantic.
Although the Royal Navy was slow to appreciate the danger posed by Exocet in the Falklands conflict, it soon made amends.
Just as the sinking of the Israeli destroyer Eilat by Egypt's Russian-made styx missiles in 1967 spawned the new breed of anti-ship missiles such as Exocet, the destruction of HMS Sheffield is already causing a radical rethink by the world's naval planners.
As the only country with first-hand experience of modern missile warfare at sea Britain will benefit from its hard learned lesson.
If the United states Navy had operated Sheffield, Congress would have openly debated the affair and heads would have rolled.
Is the British MoD really  serving anybody's best interests by refusing to come clean?
THIS WEEK
Britain plans new nuclear dumps
A PLAN to dump thousands of trainloads of radioactive waste from Britain's nuclear power stations in three new burial grounds — one of them 300 m underground — will be announced soon.
It is part of a move to clear a growing backlog of radioactive waste, some of which has been in store for 25 years.
The dumps could cost £100 million to build at today's prices.
They will be run by private firms under contract to Britain's new nuclear waste authority, NIREX.
Peter Curd, a spokesman for NIREX said this week that the body will apply for planning permission for the dumps ‘within the next few months’.
Details of the main part of the plan, to dispose of 100 000 drums containing 45000 cu.m of waste with ‘intermediate’ levels of radioactivity in two dumps, are revealed in a new technical report from the UK Atomic Energy Authority.
The third dump will deal with the huge amounts of low level waste that are currently handled at the Drigg tip in Cumbria.
Ministers may decide to extend the dumps to take the masses of rubble that will be produced when Britain's first generation of Magnox power stations are demolished in the 1990s.
And they may have to be adapted to receive radioactive medical and industrial waste that is currently dumped in the Atlantic each year.
Britain is under pressure to end this dumping following the vote at last week's London Dumping Convention for a moratorium on all sea disposal of radioactive waste (see right).
The dumps will be big enough to take waste produced up to the year 2000.
But they will begin life by taking the 20 years' accumulation of magnesium oxide cladding from around uranium fuel rods used in the Magnox reactors.
The cladding is cut from the rods before the fuel is reprocessed at British Nuclear Fuel's Sellafield (formerly Windscale) works.
The cladding is in store in ponds at Sellafield.
It was once intended to dump this and most of the rest of the waste now earmarked for the new dumps at sea.
But government policy changed after the Royal Commission on
Environmental Pollution reported in 1976 that ‘there are very strong grounds for doubting whether dumping on this scale will be acceptable’.
Scientists at the UKAEA have decided that it would be too expensive to reprocess these ‘intermediate’ wastes to make them safer before dumping.
The dumps will not, however, take the highly radioactive waste produced when the fuel rods themselves are reprocessed to reclaim uranium and plutonium.
(This waste will stay at Windscale until a final decision is taken on what to do with it.)
There will be three dumping grounds: o A labyrinth of concrete-lined tunnels 300 m below ground will take the majority of the nuclear waste — 67 000 drums — that contains large amounts of plutonium-239 and-240 and americium-241.
The isotopes give off long-lasting alpha radiation and the waste will remain dangerous for 3000 years or more.
One idea is to build this dump under the sea-bed, 0.5 km off-shore.
It would be reached by a railway tunnel from the beach and sealed in with concrete when full (see diagram).
o An ‘engineered trench’ 30 m deep will take 34000 drums of intermediate wastes with low levels of alpha radiation.
o A shallow trench, similar to the Drigg site, will take the low-level waste which will be covered with 1m of topsoil and left to decay.
There are plenty of possible sites for these dumps.
The problem will be to find one without any geological ‘boobytraps’, such as heavy faulting, without generating a political furore.
The row that followed the announcement of a programme of drilling to find a suitable site for burying high-level waste — and resulted in the programme being called off two years ago — has led NIREX to abandon any hope of drilling to find the best geological formation for the  intermediate waste.
Instead, a desk study will have to suffice.
The final decision on where to apply for planning permission to build is certain to be taken on political grounds.
NIREX will opt for the place where they are least likely to meet opposition.
This political dimension may make the massive civil engineering work even more hazardous.
The design study notes: ‘Unfortunately, with only limited geological information available and in the absence of normal site-investigation data, it is prudent to consider construction in what may prove to be adverse as well as favourable conditions,’
Rocks that should prove suitable for taking the highly-active waste are mudstones and sandstones in coastal areas, where the sand is saturated with salt-water, says the study.
Suitable sandstones are found along the Lancashire and Cumbrian coasts; either side of the Severn estuary; in Lyme Bay, Dorset; in north-east Scotland and the Orkneys; in Devon and in parts of north-east England and south Wales.
Suitable hard argillaceous rocks — mudstones and shales — are found in Wales, Devon, the Lake District and the southern uplands of Scotland, says the report.
For these rocks there is no need for a coastal site.
A third idea, to put waste in existing man-made caverns in chalk or limestone, is still being assessed.
Such caverns are available in Kent, Wiltshire, Cleveland, Humberside and Lincolnshire, The UKAEA's report proposes that special trains with 10–12 wagons, each loaded with flasks containing drums of waste will travel on public railways between the Sellafield reprocessing plant and the waste dumps, which could be up to 400 km away.
It envisages 595 train journeys each year — more than 800 journeys in all.
British Rail's technical centre in Derby is already at work designing wagons for the trains.
Before beginning its travels all the waste will be mixed with bitumen or concrete and sealed in 0.5 cu.m drums.
The report says that the waste may start being moved from Sellafield in 1988.
But, even if work on the deep-disposal site gets under way this year, there is ‘virtually no possibility of having the repository available before 1997.’
So the plan is for the waste with the high-alpha content to be put in an interim store.
The store will cost more than £20 million.
The store will be quite separate from that planned by the Central Electricity Generating Board to house spent nuclear fuel before it is reprocessed.
But, in both cases, the need for and expense of the stores arises from the nuclear industry's failure to plan ahead for getting rid of its waste.
The report admits to several outstanding questions about the long-term safety of the deep-disposal dumps.
The absence of data from boreholes on particular sites means that ‘the long-term radiological consequences arising from activity transport by circulating groundwater have not been assessed’.
And it says: ‘A more comprehensive investigation’ is needed to find out whether concrete can contain the radioactivity for 3000 years while the radioactivity decays.
Windscale report angers nuclear industry
THE publication last week of the National Radiological Protection Board's assessment that some 260 people may have caught cancer of the thyroid as a result of a fire at the Windscale plutonium pile in 1957 has been greeted with anger by the British nuclear industry.
The report undermines the industry's often-repeated assertion that nobody has been killed by the British nuclear programme.
More than that, it threatens the industry's preferred method of assessing risk and calls into question the adequacy of the emergency measures that would be adopted after an accident.
At the time of the fire, British Nuclear Fuels Ltd, which runs Windscale, used its own estimates of the doses of iodine-131, the most dangerous radio-isotope released during the fire, on individuals to claim that nobody was at risk.
The NRPB, however, has now attacked the problem from the other end, by assessing the radiation dose on the British population and extrapolating from that 260 cases of thyroid cancer and 13 deaths were likely.
The BNFL method assumes some kind of ‘safe’ level; the NRPB's does not.
BNFL this week dismissed NRPB's approach as ‘theoretical.’
At the time of the fire, government health officials poured the milk from cows grazing across 500 sq.km of Cumbrian land into the sea.
This was said to be ‘erring wildly on the cautious side.’
In fact, the NRPB concludes, the ban on milk distribution only cut the total collective dose of iodine-131 to the population by 12 per cent.
Most of the rest of the iodine reached the population via milk, produced all over the country, that was not banned.
‘The most exposed group,’ says the report ‘were young children drinking milk produced in the northern counties.’
Since the cancers may take several decades to appear, some of those children may still be at risk.
The NRPB now intends to begin an epidemiological investigation across Britain to see if it can spot any increase in the incidence of thyroid cancer in areas under the night path of the radiation cloud that spread south-east from Windscale 25 years ago.
The report notes that’ the introduction of counter-measures following a nuclear accident’are still ‘based on the reduction of individual risk’, rather than on any assessment of the overall impact on the population as a whole.
There may now be pressure for this to change.
Bad omens for Sizewell's timekeeping
IT TOOK an average of 106 months to build the six nuclear power stations that were completed in the US last year.
This is 16 months longer than the Central Electricity Generating Board budgets for in its statement of case for the Sizewell pressurised-water reactor.
And 32 months longer than the board hopes to take.
The US Atomic Industrial Forum — an industry lobby group — says that nuclear power should move into second place, behind coal, as a producer of electricity in 1983.
In 1982 electricity utilities cancelled 18 nuclear power stations, some of them well advanced in construction.
The president of the AIF, Carl Walske, says: ‘The challenge of the industry and the [Nuclear Regulatory Commission]is to squeeze construction time down to six years as a rule, rather than the exception.’
The CEGB says that it should be possible to build a PWR in Britain in six years, but it uses a period of 7 years in its calculations of the economics of Sizewell B.
There are cases in the US where the construction time is less than 90 months.
The AIF expects it to take 68 months to complete st Lucie 2 in Florida, which is due to be commissioned this year.
And the first of three units at Palo Verde in Arizona could cross the finish line in about 87 months.
Both power stations are, like Sizewell, PWRs.
But the nuclear parts were designed by Combustion Engineering.
Britain in deep water over sea-dumping
Catherine Caufield
Britain suffered a a double setback at last week's meeting of the London Dumping Convention.
On Thursday delegates approved a resolution calling for a two-year ban on dumping radioactive wastes in the sea.
And the following day Britain lost its battle to impose the burden of scientific proof on those who oppose radioactive dumping.
The two-year moratorium is not binding, and Britain, which is responsible for 90 per cent of all  radioactive waste dumped at sea, has already said that it will not comply with the ban.
The moratorium was a compromise, suggested by Spain, off whose coast Britain dumps its waste.
Originally two Pacific island countries Kiribati and Nauru, who fear Japan's plans to dispose of radioactive waste near their shores, tabled a binding amendment adding radioactive waste to the convention's  annex of banned substances.
The Nordic countries suggested instead a phase-out of such dumping by 1990.
But delegates decided to opt for a scientific review of all amendments to the  annex .
They voted by 19 to 6 in favour of a two year moratorium, during which time a scientific committee will ‘review the scientific and technical considerations relevant to the proposed amendments’.
The committee's findings will be presented in 1985.
Last week's meeting left the crucial question of burden of proof open — a fact which may have shifted the odds in favour of the would-be banners.
Britain would have liked the scientific committee to be asked to present clear evidence that radioactive dumping is damaging before it could recommend a ban.
The nations who oppose dumping want proof that it is not harmful.
Now the delegates' meeting in 1985 will be free to make up its own mind.
The chances are that Britain will have to find a new place to dump waste by the end of the decade.
o Britain will dump 50 per cent more radioactive waste this year than last.
The wastes include leftovers from the reprocessing of spent fuel from nuclear power plants, from isotope production and from work at research establishments.
The waste, to be dumped in July, will contain twice as much alpha radioactivity (mostly plutonium) and three times as much beta/gamma activity as was dumped last summer.
British plastic — heart operation fails
SURGEONS at Harefield Hospital near London have secretly taken the first step toward implanting Britain's first artificial heart.
A team under Magdy Yacoub, the heart transplant pioneer, last Thursday attempted to connect a 61-year-old London man to the pumping section of an American cardiac-support machine.
The attempt failed, and the man died in surgery.
The team did not issue a statement and staff were told not to talk about the operation.
Only one person has survived an operation to implant an artificial heart.
He is Barney Clark, a dentist from salt Lake City, Utah.
Clark has been living with a Jarvik 7 implant, connected to a separate air compressor, since 2 December last year.
Clark's implant, which replaces the two ventricles — bottom pumping chambers — is made of polyurethane and aluminium.
It weighs 300 grams, 20 grams more than a large man's heart.
Compressed air oscillates the ventricles, circulating blood around the body.
The operation at Harefield last week was not an attempt to replace the entire heart.
The patient had come to the hospital for tests, and suffered a massive heart attack.
Magdy Yacoub was summoned, and decided the only way to save the man would be to boost his heart with part of a cardiac support system that Yacoub borrowed at an international congress last October.
A spokesman for the hospital described the device as a ‘sophisticated pacemaker’ similar to the Utah device.
Yacoub connected the device, but the man died in the early hours of
Thursday morning.
The staff at the hospital were keeping silent this week.
The reply of one surgeon when asked whether the operation had taken place was ‘I think not’.
Harefield Hospital has carried out 48 heart transplant operations.
Twenty three of the patients are still alive.
Candidates for transplants normally need careful selection — which was obviously impossible in the emergency that preceded last operation.
‘It was a fifty-fifty chance of saving someone on the verge of death,’ one source close to the surgeons said.
The surgeons in Utah who carried out the first artificial heart operation are still waiting to see how their patient manages before carrying out any more operations.
They will also need approval from the US government's Food and Drug Administration before the implant can be used regularly.
No such hurdle exists in Britain.
A spokesman for the Department of Health and social security said a decision to implant an artificial heart would be up to the doctor ‘like any other replacement operation’.
The University of Utah said that Barney Clark was ‘fine, in fair condition’ when New Scientist went to press.
Eradicating liver cancer
DOCTORS are claiming a ‘landmark in preventive medicine’.
They believe that one of the most common cancers, liver cancer, could be largely prevented by a vaccine.
Specialists from 16 countries said after meeting this month in Geneva that ‘for the first time, unique opportunities exist to prevent a frequent cancer by vaccination’.
Liver cancer is one of the 10 most common cancers in the world and also one of the most deadly.
It is particularly prevalent in developing countries where it claims 250000 victims each year.
Few of them survive.
 Professor Arie J. Zuckerman of the London School of Hygiene and Tropical Medicine, who co-chaired the Geneva meeting, said he believed that a newly-developed vaccine could prevent 80 per cent of liver cancers and that 200 000 lives a year might be saved ‘at a conservative estimate’.
‘This is an exciting advance’ said Zuckermann ‘a landmark in preventive medicine’.
Most people who get liver cancer are afflicted with the hepatitis B virus.
New studies, carried out in several countries, have shown that immunisation can prevent infection with the hepatitis B virus.
 Professor Zuckerman said that field tests, using the new vaccine, are now to be done in West Africa, Burma and China.
Celltech tries direct selling
BRITAIN'S biotechnology company, Celltech, is making a pitch at a £2000 million market to pull itself into the black.
The company's latest annual report, published this week, says the company is well-placed to attack the business of making, promoting and selling diagnostic kits for hospitals.
It has set up a new division to do the job — its first venture into direct selling.
Celltech made a loss of £1.9 million last year, much of which went on setting up new research projects.
Japan takes X-ray lead
THIS WEEK Japan launched a new X-ray satellite, ASTRO-B.
It will study individual X-ray sources in more detail than its predecessor, the five-year-old Hacucho.
These two are the only X-ray satellites now working, although some Western astronomers doubt that the Japanese can continue to control both with their small team.
The Japanese satellites currently represents half the world's astronomy satellites — the other two being IRAS (see p. 507) and the International Ultraviolet Explorer.
The great TMI show
THERE IS a new attraction on the tourist circuit in the US — the nuclear power station at Three Mile Island.
So many groups want to visit the plant, which was stricken by a now notorious accident to its reactor in 1979 that its owner, General Public Utilities, has a waiting list.
Meanwhile GPU wants other electricity companies to contribute to the cost of cleaning up the site.
It says that other owner of PWRs are learning a lot about reactor safety as the clean-up continues.
But so far only the West Germans have shown any inclination to chip in.
Top of their shopping list is a robot that can climb stairs The restoration team wants to send a robot down into the basement of the reactor, which is flooded with contaminated water.
Open house for high-tech?
BRITAIN'S new environment minister, Tom King, this week gets the chance to choose whether a piece of derelict land at London's Elephant and Castle should be used for housing or high-technology industry.
The idea of an ‘urban science park’ comes from the director of the Polytechnic of the South Bank, John Beishon.
It would be an extension of his buildings.
He already has the backing of £4.5 million from the Prudential insurance company.
But the land is zoned for housing and Southwark has a long waiting list.
With local councils deadlocked, King must decide.
Inter-City gets the six-degree bends
BRITISH Rail are to develop an electric version of the 200 km/h high-speed train (HST), which runs its Inter-City 125 services.
Officially the electric HST is still intended as a stopgap for the much-delayed advanced passenger train.
But in practice this is not so much another nail in the coffin of the advanced passenger train, more shovelling the earth on top.
In a reversal of policy, British Rail has also accepted that conventional trains can take bends faster.
British Rail's standards for the maximum speed that trains could round bends were based on tests done on a branch line in North Wales with a tank engine in 1949.
After these tests the railway engineers laid down a maximum sideways acceleration equivalent to tilting the track by 4½ degrees.
Following recent tests with a 176 km/h train, however, the engineers have agree that the speed through bends can be increased to 6 degrees of track tilt — or ‘cant deficiency’, in the railways' jargon.
Trains with a maximum speed of 176 km/h (compared with the present maximum of 160 km/h will take bends faster and will run from London to Liverpool and Manchester next year.
The following year British Rail's London Midland region hopes to run electric HSTs, but these are now the subject of a row between the region and engineers at BR's headquarters.
The headquarters' engineers want to develop an electric version of the HST, which will involve considerable redesign and could take several years to complete.
The London Midland region, however which has to run the trains, wants them in service as quickly as possible.
It would dearly like (as one railway manufacturer has proposed) to rip the diesel engines out of an existing HST and replace them with electric engines, and then use this train for tests.
Meanwhile, back in the sidings at Derby the APT is still being modified, after its last run before Christmas when some bolts worked loose on its bogies.
BR says it hopes to start test runs from London to Glasgow again ‘soon’.
Mick Hamer
Tell-tale antibody that marks diabetics
A BREAKTHROUGH may be at hand in combating one of the most perplexing diseases of adolescence, juvenile diabetes.
American doctors may soon be able to spot potential victims before the symptoms develop.
Juvenile diabetes is an ailment that strikes its victims before or during adolescence, destroying their bodies' abilities to produce insulin, the hormone that enables the body to use and store sugar.
About one in every 350 American children suffer the disease, which appears to run in families.
Doctors put the life expectancy of sufferers at about 40 years — even if they have daily injections of insulin.
Until recently, researchers have thought that juvenile diabetes developed suddenly.
Now it seems that the disease builds over a period of years.
Last week, a group from Boston's Joslin diabetes centre announced that it had devised a blood test that can identify children most at risk.
If the test proves successful, it may enable physicians to start therapy for the condition before the diabetes causes irreparable damage.
The test, which at present can only be carried out in half a dozen laboratories around the world, seeks to identify an abnormal antibody in the blood of likely sufferers.
The antibody was first identified through studies of one pair of identical twins and another of identical triplets.
One of the triplets developed diabetes at the age of 13 while another was diagnosed as a juvenile diabetic at 21.
The third triplet followed suit seventeen years later.
Of the twins, one contracted the condition when 12 years old while the other developed it 36 years later.
Both of the patients who were diagnosed late in life had the abnormal antibodies in their blood for several years before the condition became obvious.
Exactly how the antibodies are involved in the development of diabetes remains uncertain.
According to Dr George Eisenbarth, who headed the Joslin team, a simpler version of the test may be developed within the next year, ‘We and other labs are most certainly working on it, to predict who's at the most risk of developing diabetes,’ he declared.
Because juvenile diabetes runs in families, the brothers and sisters of victims are likely candidates for the testing.
Eisenbarth's group has already identified two youngsters with the antibodies, and is monitoring them to see if their production of insulin starts to fall.
Once that happens, it may be possible to delay or halt the development of the condition with drugs designed to suppress the body's immune system.
‘In the future, we hope to try a number of relatively simple manoeuvres to see if we can slow that destructive process to prevent diabetes,’ says Eisenbarth.
However, in an accompanying leader in the Journal of the American Medical Association , Dr Also Rossini of the University of Massachusetts Medical school cautions that little is known about the safety of immunosuppression for human diabetics.
Antibodies beat off rejection of blood cells
DOCTORS are claiming a new success for monoclonal antibodies in fighting the rejection of transplants by the human body.
Last week a team from Boston's children's hospital announced that they had, for the first time, used the treatment to halt a ‘graft-versus-host’ attack that was actually in progress.
‘We were able to stop what was clearly a fatal reaction,’ announced Dr Fred Rosen.
The patient was Bryan Ahlers, an eight day-old boy from New York, who was born with severe physical problems.
During an effort to overcome one of those problems — a heart defect — surgeons gave the boy a blood transfusion.
Almost immediately he developed a lobster-red rash, the first sign of what is known as graft-versus host disease.
Physicians found that Bryan had been born without a properly-working thymus gland.
This left him defenceless against the foreign white blood cells in the transfused blood.
The cells immediately attacked his organs.
The doctors made monoclonal antibodies against the attacking white cells in the transfused blood and Bryan's parents agreed to try the treatment in a desperate attempt to save him.
Two days after the reaction began, the child received the antibody treatment.
It worked and halted the attack.
A group of physicians at Harvard University has pioneered the use of monoclonal antibodies to combat graft-versus-host disease, a condition in which specific cells in the body turn on other body tissues.
The treatment was first tested in patients who received transplants of bone marrow.
In two-thirds of such patients, white blood cells known as T-Lymphocytes that are produced by the marrow attack their fresh surroundings.
The monoclonal antibodies work by combating the T-Lymphocytes and other threatening cells.
They have apparently prevented the graft-versus-host reaction from starting up in a number of patients who have received bone-marrow transplants.
Fall-out from Vietnam war continues
THE US state department is being accused of trying to sabotage a recent conference in Vietnam that was called to discuss the long-term effects of the spraying of defoliants on the country's forests by American planes during the Vietnam War.
Delegates returning from the conference, held in Ho Chi Minh City at the end of January, says American officials tried to persuade them not to go.
Two United Nations bodies were persuaded.
They were the UN Development Programme and the Economic and Social Commission for Asia and the Pacific — both of which were billed to appear but did not show up.
But other UN agencies did appear.
State department officials seem to have been concerned that the conference would deflect attention from their own campaign to expose the alleged use of mycotoxins by Vietnam in Laos and Kampuchea.
Don Coleman, a state department official at the US embassy in Bangkok, said the department had ‘tried to point out that there was a potential for [the conference]being used as political propaganda.’
Caleman added that every time the United States accuses the Soviet Union or Vietnam of using mycotoxins in south-east Asia the standard reply is to ‘remind people about the US use of herbicides in Vietnam.’
But one UNESCO official, claimed: ‘There was no finesse about the state department's actions whatsoever.’
The message was quite blunt: ‘Do not go.’
The withdrawal of delegates from the UN from the conference is of more than symbolic importance.
Vietnam wants UN help to rebuild its forests, 10 per cent of which were obliterated by spraying during the war.
The US dropped 90 000 tonnes of herbicides — including Agent Orange, which was contaminated with dioxin — onto Vietnam's forests and fields between 1962 and 1971.
Delegates to the conference were taken on field trips to see the devastation.
They were duly impressed.
But they have been left in little doubt that Washington would be displeased if they decided to help Vietnam's programme to grow its forests anew.
Infrared astronomers are over the Moon
A FORTNIGHT after starting its pioneering survey of the sky, the Infrared Astronomical Satellite (IRAS) is turning in high-quality data in such profusion that astronomers are having difficulty keeping up.
The American-Dutch-British satellite has already shown that it will fulfil its task of locating infrared sources, for follow-up by conventional infrared telescopes and by future infrared observatories in space.
In addition the infrared detectors have proved to be much more stable than anyone had dared to predict.
So the astronomers can rely on measurements taken months apart to compare conditions in different infrared sources.
And as a bonus, IRAS should be able to send back information for at least nine months, instead of the seven expected at launch.
IRAS has so far been one of the most trouble-free scientific satellites; even its orbit is within 20 m of the planned 900 km high path.
The only problem occurred a few days after launch, when one of the sun sensors produced occasional false readings and shut down the satellite.
But ground engineers reprogrammed IRAS to work around the fault well before the survey began.
Other anticipated problems, like contamination of the mirror by dust around the spacecraft just did not happen.
Fred Gillett of the American science team says that despite the sun's heat falling on IRAS, the satellite's insulation is working so well that there is ‘less heat going into the system than is radiated by the tip of my little finger’.
The detectors can work only as long as the system is cooled, and the low boil-off rate of the helium coolant on board means the mission will last at least 300 days.
The survey will take about six months to complete.
So the extra time means more opportunity to use the Dutch Additional Experiment (DAX), a set of detectors designed to investigate individual sources in more detail.
The satellite makes 14 orbits per day, and at present IRAS surveys the sky for nine orbits and uses DAX for five.
The four IRAS survey detectors pick up infrared sources at wavelengths of 10, 20,
60, and 100 micrometres.
This means it can ‘see’ cool clouds of dust and gas, with the longest wavelength detecting the coldest.
On its first survey orbits, IRAS scanned our nearest galaxy, the Large Magellanic Cloud.
One minute of observation away from the Earth's atmosphere revealed more than has ever been known before about that well-studied galaxy's infrared emission.
The detailed maps show dozens of dust clouds — the most intense being around the great Tarantula Nebula, where thousands of stars are currently being born.
The maps confirm theoreticians' ideas on the birth of stars from interstellar clouds.
The cold clouds seen at 100 micrometres are large and diffuse, evidently just beginning to condense under their own gravity.
At successively' shorter wavelengths, IRAS sees clouds that have broken up into smaller and warmer cloudlets — as theory predicts — and the sources shining at 10 micrometres have probably completed the process and have just become stars, shining by their interior nuclear reactions.
The IRAS survey is finding many such areas of star formation in our own Milky Way galaxy too.
IRAS will scan the Milky Way for the first two or three months, concluding with passes over the centre of the galaxy — a strong infrared source hidden from optical astronomers by dust.
Then it will fill in the rest of the sky.
So far the survey has picked up 20 galaxies; it should eventually find several thousand.
The total number of sources in the IRAS catalogue — mainly clouds in our Galaxy — will probably run to two hundred thousand.
And the detectors' stability means that they can even measure radiation from the faint cloud of dust around the sun which produces the zodiacal light.
The results are being processed at the Jet Propulsion Laboratory, California.
Nigel Henbest
Crumbling uranium shuts radio-therapy units
FOUR OF Britain's newest cobalt radiotherapy units, used to treat cancer patients, are temporarily out of action.
Scientific ignorance is apparently to blame.
Uranium shutters, that shield the cobalt radioactive source until the patient is in position, were found to be crumbling.
The manufacturer, TEM Instruments of Crawley, has recalled the machines, which are worth more than £1 million each.
The company fears that uranium dust sealed inside the machine could jam the mechanism that controls the shutters.
So far uranium dust has been detected in only one machine — the Oxford unit at Churchill Hospital.
TEM is now checking machines at Shrewsbury, Cambridge and Glasgow.
The Royal Shrewsbury Hospital's cobalt unit opened only last September after a massive public fund-raising drive.
TEM declines to estimate the cost of the entire operation, which will be borne by the company, but say it is ‘not cheap.’
The trouble springs from a recent change in the composition of the ‘depleted uranium’ shields.
For 20 years the company has used a uranium-molybdenum alloy.
But about five years ago it shifted ‘on expert advice’, to a denser uranium titanium mixture.
But this new alloy is being oxidised — and flaking off — much faster than the old alloy; the chemistry of the mixtures is still poorly understood.
‘We were given the wrong advice in the first place,’ says Jeremy Myles of TEM.
He blames a hospital physician in Britain who acted as a consultant, and the American suppliers, Nuclear Metals Incorporated of Concord, Massachusetts.
Nuclear Metals says, however, that the behaviour of the alloys is ‘controversial…we are not 100 per cent convinced that it is the titanium alloy itself which is at fault — it may be the environment,’ Don King of Nuclear Metals told New Scientist .
Some British hospitals are older and more humid,’ he suggests.
Some TEM units may also direct more heat from the radioactive cobalt source onto the shields, speeding oxidation.
‘We are doing our best to replace them with good units,’ King says.
Meanwhile TEM has sent the shutters to Fulmer Research Institute in  B hamshire where they have been cleaned and sprayed with epoxy paint.
‘The paint will discourage further oxidation,’ John Hutchings of Fulmer told New Scientist 
TEM recently sent out a circular to the many hospitals with their machines, asking them to look out for uranium dust.
Some older machines will have had their original shutters replaced with the newer alloy.
But the problem seems rare.
‘We have had a TEM machine since 1970, and we have never found any radiation on the uranium diaphragm,’ says Dr Trevor Godden of Brinol Royal Infirmary.
Hospitals routinely check for radiation on the shutters by doing a ‘wipe test.’
Gail Vines
Reveille for sunrise — science links with Japan
EUROPE's research supremo, Commissioner Etienne Davignon, has returned from a trip to Tokyo determined to build on a new understanding over trade in high-technology goods to increase collaboration between Japan and Europe on costly research projects.
Top of his shopping list is an infusion of yens to speed nuclear research in fusion, fast-breeder reactors and reactor safety.
So far the Europe-Japan connection has been the weakest link in the triangle of cooperation between Europe, the US and Japan.
If the present discussions on trade in televisions, cars.
hi-fi, video tape recorders and an assortment of other goods succeed, then the way will be open for more scientific cooperation.
That's the word from officials close to Davignon, who has the European brief for energy and research as well as industry.
More sceptical types at the European Commission shake their heads.
‘The Japanese bow low to the knees and say yes, but so far we've seen no results,’ said one.
Talks have been going on for some time on a range of scientific matters including fusion, nuclear safety and the environment.
On energy, consultations have been taking place on generation, conservation and solar energy.
‘Real collaboration only happens when people working on the same scale want to share the results of their work or are willing to put money in a pool for an expensive project’ said another official.
One such expensive project is fusion.
Europe's large fusion installation at Culham, Oxfordshire — the joint European torus known as JET — is likely to begin operation in the next few weeks.
Community partners will soon need to start work on a new machine that will build on its results and bring commercial fusion a step nearer.
After JET, Europe is planning NET, the next European torus.
But it is not clear whether this machine will be built by Europe alone or whether the cost will be shared with others.
Sharing with the Japanese and the Americans would make sense.
(The other member of the fusion club, the Soviet Union, seems to be ruled out of the project).
Nuclear safety is another area ripe for cooperation.
But the track record is not very good.
The Japanese were interested in buying into the Super-sara nuclear safety experiment at one time.
But they later backed off.
Collaboration is emphasised in a report prepared at the request of Europe's heads of government, who met at the Versailles economic summit last year.
A working group on technology, growth and employment will shortly report that, because fast reactor research is extremely expensive, there is a particular need for international collaboration in the field.
Britain is actively seeking partners to share the cost of a commercial demonstration nuclear reactor.
But the American government is distinctly cool towards its own Clinch River fast-reactor project.
‘No one is doing much work here except France, whose super-Phenix should come on line next year.’
said one expert.
Meanwhile, Germany and Italy are moving ahead slowly.
‘Some useful international work might be done on closing the fuel cycle’ he added.
Europe's experience of collaboration with Japan has not been easy.
Caution is still the watchword.
US watchdog attacks anti-satellite weapon
Mark Hewish
THE General Accounting Office of the US says that America's planned missile to shoot down Soviet satellites is too complicated and would cost tens of billions of dollars.
The Russians themselves have developed a ‘killer’ satellite that explodes as it passes a target spacecraft.
The US Air Force, however, favours a different approach, using small missiles fired from conventional fighter aircraft.
The Vought Corporation is developing an ASAT (anti-satellite) missile for the USAF to carry on F-15 fighters.
The aircraft would launch its ASATs at a height of about 15 000 m.
The missiles would climb out of the atmosphere, using a two stage rocket motor, and home in on the heat emitted from a target satellite.
ASAT carries no explosive warhead and relies on ramming the enemy spacecraft.
Although the air force put a price tag of only $3600 million on the project the General Accounting office says the true cost is likely to be tens of billions of dollars.
The office wants Congress to order the Pentagon to investigate other methods such as lasers fired from the ground or installed in satellites.
At last, the hand — held European anti — tank missile BRITAIN, France and West Germany have decided to work together on a family of new missiles that will destroy, tanks.
They will replace a hotchpotch of weapons that these countries have in the past developed for their own use or bought from abroad.
The new missiles will be much more effective than their predecessors against the latest Russian tanks, and worldwide sales are estimated to be worth thousands of millions of pounds.
On 16 February the three countries signed a ‘memorandum of understanding’ authorising a further 2½ years of work on detailed design.
Aerospatiale in France will be in charge of developing a small missile that an individual soldier can carry and use to attack tanks up to 2 km away.
British Aerospace at Stevenage will be responsible for a larger weapon, with twice the range, to fit on armoured vehicles.
 Messerschmitt -Bolkow-Blohm in Germany will look after the development of a version of this missile to arm helicopters.
The medium-range missile will replace the Franco-German Milan weapon, which Britain has also bought, from the early 1990s.
The long-range type will succeed the British swingfire and the Franco-German Hot from the mid-1990s.
The launcher for the medium-range version will incorporate a projector that produces a beam of infrared radiation.
The operator will keep this beam aimed at the target while the missile, which has sensitive detectors at its back end, will steer down the centre of the beam.
It may then penetrate the side of a tank or fly over the top.
In the latter case, a downward-pointing warhead fires a stream of molten metal at several thousand kilometres an hour to punch a hole in the tank's vulnerable upper surfaces where the armour is comparatively thin.
The longer-range missile will be of the
‘fire and forget’ type.
Before launching the weapon, the operator in his armoured vehicle or helicopter locks the missile's nose-mounted seeker on to the infra-red radiation emitted from the target.
He then fires the weapon, which automatically steers itself toward the target and dives on to its vulnerable upper parts.
The three governments have agreed that the missile projects will include the free transfer of all appropriate technology amongst the participating companies.
All three countries will thus benefit in the areas where their defence technologies are now weak.
As well as improving NATO's defences against Russian tanks, the new missiles look set to become moneyspinners for the three participating countries.
Sales of the present Milan missile have already exceeded a quarter of a million rounds at a cost of several thousand pounds each.
Why Sizewell's crucial test will side-step inquiry
SIZEWELL public inquiry will not have a chance to consider what everybody agrees is the most crucial safety issue affecting the design for the proposed pressurised-water reactor.
An experiment to test whether, in an accident, the core of the PWR might overheat and cause a melt-down will not be ready to start until next year, and will not be complete until long after the inquiry ends.
The experiment will investigate the danger of the cladding round the fuel rods ‘ballooning’ and blocking the flow of cooling water.
It is to be run by the UK Atomic Energy Authority at the request of the Nuclear Installations Inspectorate, the government's safety watchdog.
The NII says that the work will be ‘crucial to the understanding of the safety implications of ballooning.’
Last week witnesses for the Central Electricity Generating Board claimed at the inquiry that work around the world had already shown that the ballooning phenomenon is not as critical as once feared.
Last autumn the CEGB's chairman, Sir Walter Marshall, said that ‘my reputation and the economics of the PWR are now most at risk from fuel-clad ballooning.’
The NII evidently agrees.
The experimental rig that will be built at the UKAEA's Harwell base is, ironically, called ACHILLES, The NII agrees that recent work in Canada, West Germany and the United States has gone some way to showing the likely scale of the ballooning effect.
But it is not prepared to accept that the mathematical models developed to explain the phenomenon are sufficiently proven.
Further validation is needed, says the NII, before it will accept CEGB assurances that only a limited number of rods will experience significant ballooning.
Those that do, claims the board's researchers at its Berkley Nuclear  Laboratories , will rupture before producing a blockage of the coolant channel sufficiently severe to impair coolability.
Ballooning was one of the five crucial issues identified by the NII last year in its initial comments on the board's Pre-Construction Safety Report (RSR).
Links between nuclear power and the incidence of cancer was not a matter of specific concern in that review.
But it remains to be seen whether that will prove a significant omission.
The CEGB's chief medical adviser, Dr John Bonnell, was due to give evidence this week.
Last week the third death of a Sizewell A worker from  leukemia was reported.
It was followed by the National Radiological Protection Board's revised estimates of cancer deaths resulting from the Windscale fire in 1957.
The latest Sizewell A worker to die from leukaemia entered radiation areas only infrequently during his 18 years at the existing Magnox plant.
His total dose was 109 millirems — well below the recommended level set by the International Commission on Radiological Protection.
Dr Bonner told New Scientist that this third cancer death at Sizewell was difficult to explain.
Socialists line drug companies' pockets
DRUG COMPANIES in France will be allowed to raise prices by £57 million a year as part of a government bid to boost research, jobs and exports.
But the French government which will pick up most of the tab through increased social security costs is giving the handout only to companies which toe the state policy on drugs.
Nineteen companies have so far agreed to sign contracts with the government agreeing to fixed objectives.
They will raise R&D in the industry by £36 million a year, provide 1200 more jobs and improve the balance of payments by £35 million, it is claimed.
The companies have undertaken to make capital investments of £95 million in 1983 and to limit their spending on advertising and publicity to 16 per cent of their turnover.
In return they will be allowed to raise prices by several per cent more than competitors who have not signed the government convention.
Only three non-French companies have agreed to the new deal — Dow Chemical, Upjohn and Riker.
Most of the multinationals have steered clear of commitments so far.
Medical technology is one of France's priority sectors for industrial development.
But this is the first major announcement of aid for the drug industry, apart from £9 million for biotechnology research last month.
Pulp mills and power plants threaten Malaysia's forests
Catherine Caufield
PRESSURE from Malaysia's environmentalists has saved one of the country's national parks from obliteration for a hydro-electricity scheme.
But now they face a battle to save another from being stripped of trees for a paper and pulp mill.
The Malaysian government this month announced that it has dropped a scheme to flood the country's oldest and largest national park, Taman Negara by damming the Tembeling river.
The scheme would have flooded 250 sq.km, and displaced 2500 people as well as hundreds of elephants and tigers.
But the Sabah state cabinet is standing by its decision to strip the Klias peninsula national park of its protected status.
The Klias park was established by the state government in 1978 to protect its mangrove forests and habitats for estuarine crocodiles and the proboscis monkey.
The state cabinet overturned the park's protected status so that a paper and pulp mill, a joint venture of the Malaysian conglomerate and the Indian firm Birlas, could be built there.
A 200 000 acre forest site just outside the park boundaries will be cleared and replanted with softwoods to supply the mill.
‘The felling will be an ecological disaster,’ says Gurmit Singh, the leader of the Malaysian environmental protection society.
‘It will destroy the habitat of thousands of birds and animals, and the erosion will have a detrimental effect on water quality and riverine life.’
The group claims that fibre and chemical effluent discharged into coastal waters from the mill will damage the neighbouring Bay of Brunei and its fisheries.
Sea-bed geology goes up the mountains
By drilling into the mountains on Cyprus geologists are hoping to learn more about the sea bed.
The highest rocks on the island, it  seems , once lay deep beneath the sea
Sean McCutcheon
EARLY ONE EVENING last spring in the Troodos mountains of Cyprus a peasant was climbing up a winding road, driving a donkey laden with goat fodder.
As he passed our party he saluted with polite astonishment.
Some of the group were hammering at the rocks through which the road cut.
Pacing and gesticulating, the others were debating whether or not the flat patch by the road could be widened to accommodate a drill rig by blasting the cliff.
The peasant was witnessing members of an informal group of earth scientists known as the International Crustal Research Drilling Group (ICRDG) during the early stages of an intriguing and seemingly paradoxical research venture: probing into a mountain range to learn a good deal about the ocean floor.
One member of the ICRDG is Ian Gass, a geologist who now teaches at the Open University.
During the 1950s, when he was a member of the Cyprus Geological Survey, Gass mapped the Troodos massif and worried about its origin.
It was, he decided in the end, an ophiolite.
Ophiolite comes from ophis , Greek for ‘snake’, and it originally signified rocks, such as mottled-green serpentinite, that resemble snakeskin.
It implied nothing about how such rocks were formed.
‘The 19th century geologists’, according to Gass, ‘would draw a line around anything green and dirty, call it an ophiolite, and walk away.’
Early this century, however, the meaning of the word was broadened to include the other rocks, such as‘pillow’ lavas, commonly found with serpentinite, although until recently there was no generally accepted explanation for this association of rocks.
After a detailed study of the Troodos massif, Gass became convinced that all the 3000 square kilometres was a fragment of ocean floor that by some monumental feat of earth moving had been stranded on Cyprus.
He co-authored a paper in which he identified these mountains, which cover a quarter of the island, as an ophiolite, using the word in its modern sense.
Ophiolites, geologists now believe, are land-bound fragments of oceanic crust.
Several hundred have been identified, and many are being studied for the evidence they can yield on how the oceans form.
How do the oceans form?
The first version of the currently accepted answer to this question was developed in 1960 by Harry Hess of Princeton University.
Hess commanded a troop ship during the Second World War and the vessel's echo sounder had traced out curious mountains on the floor of the Pacific.
Speculations on their origins, in what he called ‘an essay in geopoetry’, led Hess to outline the concept of sea-floor spreading, the gist of which is as follows.
At ridges in the mid-oceans molten rock rises from the mantle below the crust and spreads out on either side to form new ocean floor.
The new oceanic crust welds to the edges of two plates (huge pieces of crust that move slowly over the mantle beneath).
This new oceanic crust migrates from its place of birth, eventually plunging to destruction back down in the mantle, when the oceanic plate collides with a continental plate.
When new and still unorthodox, Hess's concept fired the imaginations of a number of the earth scientists who were later to get together on Cyprus.
Fred Vine was one of these.
In 1963 Vine had just graduated in geophysics from Cambridge.
With Drummond Matthews, his supervisor, he showed that sea-floor spreading combined with periodic reversals in the direction of the Earth's magnetic field could neatly account for the striking pattern of magnetism on the flanks of mid-ocean ridges.
This work, in time, helped move geological opinion from scepticism to belief in sea-floor spreading and in the overall concept of plate tectonics.
One reason for resistance to the new paradigm was the sheer impossibility of convincing geologists in the traditional way: by convening on an outcrop and hammering out the evidence.
Though they cover more than 70 per cent of the Earth's surface, the rocks of the sea floor are virtually inaccessible.
Between geologist and geology there lies a daunting barrier: the deep and rolling ocean.
Jim Hall, a founder of the ICRDG and one of its driving forces, was doing geology on land in his native Britain and in Africa, when he was, like Vine, ‘bitten by the bug of the ocean floor’.
In 1971 he moved to Canada, to Dalhousie University, and that same year sailed out of Halifax on board the research ship Hudson for his first field trip to study marine geology.
He gathered rocks, but found a dredge such as the Hudson's to be a crude sampling tool.
There was no way to pinpoint where on the sea bed the dredged rocks had come from, nor any way to penetrate into the ocean's basement.
For good data, Hall decided, he would have to drill.
Hall's office at Dalhousie is decorated with souvenirs of the drilling expeditions he has since helped organise.
With coworkers he probed into the floor of the Atlantic from the margins of San Miguel in the Azores and  Bermuda .
In 1974 he was on board the Glomar Challenger, for Leg 37 of the Deep Sea Drilling Project.
On that cruise the ship's drilling bit, after being lowered through 3 km of water, bored through a thin veneer of sediments and 600 m into the underlying basalts; it had successfully penetrated the ocean crust for the first time.
On the Glomar Challenger, and back on shore, Hall met others who shared his enthusiasm for the ocean floor.
They talked about pooling their resources.
By 1978 they had formed the International Crustal Research Drilling Group and a team of a dozen or so, along with graduate students and drillers, was at work in Iceland.
The island is an ideal location where new ocean crust wells up at active ridges near the surface, rather than deep beneath the ocean.
But this very difference means Icelandic crust is not the same as normal ocean crust.
Early in 1982 the headquarters of the ICRDG moved from Hall's office in Dalhousie University to Cyprus.
When 1 visited Hall and his colleagues there they were beginning their most ambitious project yet.
The team is truly international and includes: Fred Vine from England; Paul Robinson.
director of the Cyprus Project, and Paul Johnson from the US; Hans-Ulrich Schmincke from West Germany; Kent Brooks from Denmark; Ingvar Birgir Fridliefsson from Iceland; and Andreas Panayiotou of the Cyprus Geological Survey and George Constantinou, its director.
The ICRDG is a collective; its members pool their skills and their grants.
But there are difficulties in finding money for research drilling.
In Cyprus the plan was to obtain a total of 5 km of core from separate holes sampling the upper 4 km of the ocean crust.
For this the drilling costs will eventually total an estimated Canadian $1.1 million (nearly £600 000); and most of this has, to date, been raised.
There is. it seems.
a prejudice against research drilling.
The geologists sense that some funding agencies ‘obviously feel that ophiolite work is a waste of time.
They think you can't learn anything about the oceans if you don't get your feet wet.’
From limited evidence, from drill cores, from seismic data, and from what has been learned by field work on ophiolites, earth scientists have put together a composite picture of the layered oceanic crust (Figure I).
At the lowest level are mantle rocks such as serpentinite and harzburgite.
These are the congealed and metamorphosed residue left in the bowels from which magma, or molten rock, has been vomited upwards.
In the middle layer is greenish gabbro, molten rock that never made it to the surface of the crust.
Instead it slowly froze in a magma chamber into a mush of coarse crystals.
The upper layer is of lava.
Where the rising lava froze like playing cards in the fissures of a spreading sea floor are the so-called sheeted dykes, vertical slices of fine-grained lava.
Above, where hot lava erupted from the crust to be chilled by cold sea-water are purple, bulbous pillow lavas.
Drilling brings to light a vertical column of rocks in which history is written, albeit tersely, in the cryptic shorthand of rock sequence, texture, composition.
The sequence above, starting with the lavas, is what geologists would expect to find in a hole piercing 6 km into the ocean crust.
But on Cyprus a single hole is impractical; cost and difficulties mount rapidly with depth, so instead a number of holes (probably five) will be drilled in Cyprus.
Because the Troodos ophiolite has been uplifted and eroded, a slice through successive layers of oceanic crust has been exposed, high and dry on the main hillsides of Cyprus.
Thus the five holes will sample, in overlapping segments, the uppermost 4 km of the ophiolite (see map).
These holes will probe the vertical relations between types of rock whose horizontal relations nature has already revealed in creating the Troodos massif.
At Mount Olympus, the highest point of the massif, mantle rock is visible.
The slopes around are gabbro.
(Gabbro weathers readily, forming the good soil on which grow the grapes that go into the sweet wines of Cyprus.)
In a ring around the gabbro are the sheeted dykes and in the outermost ring, marking the periphery of the massif are the pillow lavas.
In climbing down from Mount Olympus and passing over these concentric circles, you can imagine you are tracing the path of magma rising at the mid ocean ridges, eventually to spew through vents, producing large quantities of mineral ore.
Of all the phenomena submersibles have observed on the ocean's floors, the strangest are probably the black smokers — the hot springs on the East Pacific Rise that spew forth clouds of sulphide minerals (New Scientist .
vol 92, p 7).
To see a black smoke is to see a body of ore actually being formed.
To drill beneath an ore body, as the ICRDG has done in Cyprus, is to study the plumbing of a fossilised black smoker.
As I write, the drilling phase of the Cyprus project is still underway, with four holes completed.
The first, which sampled the upper part of the extrusive lava layer, had to be abandoned at 500 m because of technical problems.
A second and a third hole have been drilled beneath the deposits at Agrokipia.
All the cores obtained have been described in detail, and samples taken for geochemical, paleomagnetic and other laboratory studies.
The fourth hole has reached a depth of 1850 m beginning at the base of the sheeted dykes, so as to sample the gabbro.
Its purpose is to gather sufficient information to answer questions about magma chambers in oceanic crust.
If funding permits, a fifth hole will be drilled to complete the sampling of the upper extrusives.
What can be learned from such research?
Previous work by the ICRDG has shown, for example, that the growth of the ‘sea floor is  discontinuous .
Eruptions on the mid-Atlantic ridge occur sporadically, each major one fed by a distinct magma chamber.
The group also has evidence, from the Azores, of volcanoes rising above the waves only to sink again and again beneath the weight of accumulating lava.
But, says Hall modestly and realistically, ‘Drilling has taught us that the first models we worked with were only the simplest of a large number of possibilities that were consistent with the observations.
The information we are gaining is essential in developing more realistic models.’
The project on Cyprus will shed light on the origin of the Troodos ophiolite, and on the structure of oceanic crust.
By revealing the mechanisms of the formations of ore bodies on the ocean floor.
it may lead to new techniques for the prospecting of minerals.
Curiously though, in Cyprus finding water is the paramount geological task: the growth of agriculture and hotel development added together have helped to drain the aquifers.
The lakes, coloured blue on maps of the island, are dry.
In every river there is a dam, and almost all the considerable revenue from tourism is spent on water projects.
But the shattered gabbro of the Troodos ophiolite may well hold water, and information gained by drilling into it may be of great practical value on this semi-arid island.
But geology, is not done just to be applied.
Even now, when it has in plate tectonics a unifying, fundamental theory, much of it remains an observational science, intuitive to the point of subjectivity.
Doing geology is like playing outdoors with enigmatic jig-saw puzzles: giant puzzles in the two dimensions of the Earth's surface, the third dimension of a drill hole and the fourth dimension of time.
There are always pieces missing; and ample room to use the imagination.
Geological sightseeing in the mountains of Cyprus
IN NICOSIA.
The trees are dusty, the rivers are dry.
Jim Hall and I leave the city on a road flanked by fortified encampments flying UN, Greek and Cypriot flags.
On the hills are similar encampments flying the flag of Turkey.
After some 30 minutes of driving towards the jagged mass of the Troodos Range, we turn and plunge down a steep trail to a river bank.
Here the drill rig, which after numerous delays had only recently arrived from the mining camps of Northern Quebec, was boring downwards at a rate of about 30 m per day.
It had penetrated through the layered chalks on which Troodos sits and had just begun to bring up rock cores from the ophiolite's fringe.
As we watched, the rig foreman hammered on a drill pipe to release a 2 m cylinder of greenish rock with reddish blotches.
‘Beautiful’, said Hall.
‘Just look at that olivine.
Oceanic crust that no one has ever seen before!
We thought all our problems were over when we finally got the rig set up, but now we've got to examine a deluge of fresh rock!’
On another day we drove into the mine at Skouriotissa.
‘Cyprus’ is  synonymous with — copper’, and the island was celebrated in antiquity for its mines.
Here was smelted metal for the spearheads, helmets and chariot fittings of Homer's warriors.
Basing his calculations on the mass of ancient slag heaps dotting the Troodos ophiolite, George Constantinou estimates that 2000 thousand tonnes of copper had been mined by Roman times.
To smelt this ore, the forests of Cyprus must have been cut, burned and regrown 17 times.
At Skouriotissa a bulldozer scoops up ancient slag and dumps it on a new road.
Andreas Panayiotou is offended.
He is conducting a field trip to some of the places where once ‘black smokers’ rose above the floor of a long-vanished ocean, depositing their minerals to form the ore mined  millenia later.
The slag heaps, he feels, are historic relics and to use them as resurfacing material is vandalism.
He speaks about the archaeological finds that have been made in Cyprus's mines — the reed ore baskets, the wooden winches and woven ropes, the skeletons cramped in galleries less than one metre high.
And at the bottom of a deep open pit, up whose ramped sides labour belching trucks, he vividly describes how sea water percolated down through the space above our heads when it was occupied by still-hot lava and how, laden with dissolved sulphide minerals, this heated fluid gushed back to the surface, struck cold sea water and deposited its minerals.
Most of my companions on this field trip to the mines are from the Third World.
The ICRDG has invited earth scientists from the geological surveys of almost all the developing countries to spend eight weeks in Cyprus, living and working alongside its members; during the summer about 20 will come.
As we drive from mine to exhausted mine I chat with some of the first group about doing geology.
In Zimbabwe, Nick Bagelow is mapping 4500 square miles of geologically-frustrating territory’.
— We can walk for days,’ he says, ‘without seeing a rock.
Here the exposure is fantastic,’
Different problems face geologists on expedition in Tierra del Fuego where the field season is only two months long, a quarter of its duration in Zimbabwe.
And when a field party from Cairo camps in the desert, 40 to 50 tents are pitched and water is supplied from a road tanker.
In the Sudan the animal field geologists most fear is the scorpion; in India it is the leech; in Zimbabwe, the rhinoceros.
What beans lurk in the rocky wilds of Cyprus?
I learned the answer when I joined Kent Brooks and Ingvar Fridliefsson for a trip up a river canyon.
The wind was warm.
In the field above a peasant dressed in high boots and baggy pantaloons watched a troop of grazing goats from the shade of an ancient olive tree.
The traditional garb he was wearing, I realised, was snakeproof.
In Nicosia that morning Andreas Panayiotou had warned us about snakes, and in particular, about the squat, dirt-coloured and venomous vipers that congregated at this time of year near water where they hunted birds.
As we climbed up the canyon we made a great clatter with sticks and stones and old tin cans, announcing our presence to the denizens.
Our progress was made noisy, too, by disputation.
Like a surgeon's scalpel the river we were following had cut through the thin skin of soil and sediments to expose the underlying pillow lavas.
With some students, Hans-Ulrich Schmincke had mapped these rocks.
Their interpretation won less than the complete assent of my companions.
‘Rubbish!
These are good pillows here but they've been mapped as intrusives.’
‘Well, it must have been raining miserably when they went through here.’
We came to a spot aromatic with eucalyptus scent, whose rocks had been mapped as a cascade of lava falling from a faulted escarpment.
‘This has nothing to do with lava cascades,’ said one dissenting voice.
‘This is intrusive, see, there's the fault going up there and squirts of lava coming down.’
But then dissent in geology, as in any science, is good.
It shows the subject is alive and well.
A SAFER LIFE FOR THE PEEKING DUCK
A sleeping duck always runs the risk of being caught napping by a fox or cat.
Or does it?
Dennis Lendrem
ANYONE who has watched birds sleeping will have noticed that they frequently open their eyes for a moment, or ‘peek’.
Peeking allows a bird to sleep and watch for predators at the same time.
But how often does a duck need to peek to be fairly sure it won't get caught?
At Folly Bridge on the Thames at Oxford there is a short wooden jetty from which punts can be hired during the summer.
Every morning at about 8 am ducks come out of the Thames to sleep on the jetty.
Adopting special sleep postures (Figure 1), they settle for a snooze in flocks of up to 30 birds.
At about 10 am the owner of the jetty arrives.
Being unpopular with the owner (they foul the jetty), ducks leave promptly on his arrival.
The major predators at Folly Bridge are domestic cats, small boys and the occasional fox.
Should a cat appear, ducks immediately increase their peeking rates to keep an eye on it.
They will roughly double their peeking rates from 10 to 20 peeks per minute following disturbance by a cat.
If the cat gets too close, ducks may peek anything up to 35 times per minute.
Any closer, and they stop peeking altogether and watch the cat closely.
They behave similarly should a man appear carrying anything remotely like a gun (for example, a cricket bat, a length of scaffolding or an umbrella).
One duck usually raises the alarm (a deep quack) and suddenly every eye on the jetty snaps open to follow the man across the bridge until out of sight.
All this happens without a single bird appearing to twitch a muscle.
Predators such as cats can handle only one duck at a time, so if you are a duck it makes sense to sleep in flocks.
If a cat attacks, the chances are it will get someone else and not you.
The bigger the flock, the smaller the chance that you end up as the cat's next victim.
So, as the size of the flock increases individual birds can afford to lower their peeking rates (see Box).
Sure enough, as the size of the flock increases, peeking rates decrease.
Laboratory studies of sleeping doves give similar results.
The larger the flock, the less time individual doves spend peeking and the more time sleeping.
Ducks at the end of the jetty are obviously much safer than those closer to shore.
Not surprisingly ducks sleeping close to the shore have much higher peeking rates than those farther away.
But it is not just distance from the shore that is important — the number of birds between a duck and the shore is important too.
If you have half a dozen birds between you and the shore, a cat is likely to get one of them first.
So, the more ducks between a bird and the shore, the lower its peeking rate.
In the breeding season males peek more often than females.
This sex difference applies to herring gulls in Cumbria and tufted ducks in Gloucestershire as well as to mallards at Folly Bridge.
There are a number of reasons why males might be more vigilant than females, but at the moment the evidence supports three hypotheses.
The first — the male voyeurism or ‘disco-bar’ hypothesis — suggests that males are more vigilant than females and have higher peeking rates because they are on the look-out for promiscuous copulations with females (as well as watching for predators).
If true, we might expect male peeking rates to increase as the number of females in the flock increase.
As expected, peeking rates do increase with the proportion of females in the flock (Figure 2).
A second possibility — the mate-guarding or ‘ chaperone ’ hypothesis — suggests that males are more vigilant than females because they have to guard against promiscuous ‘rape’attempts on their female partners.
If this is true we might expect paired males to be more vigilant than bachelor males.
In a study of mallard and tufted ducks at Washington Wildfowl Park, paired males had significantly higher peeking rates than bachelor males (Figure 3).
So it looks as though mate-guarding too has a part to play in sex differences in the breeding season.
The third hypothesis — the sexual selection or ‘Gary Glitter’ hypothesis — suggests that the brighter, more conspicuous nuptial plumage of the breeding male makes him more attractive to both females and predators.
The brightly-coloured males may be at greater risk than the dowdy females.
Support for this hypothesis comes from an analysis of male peeking rates during the change in plumage which many ducks undergo at the end of the breeding season.
In May and June females leave the males, build a nest and incubate their eggs.
They are in great danger from predators while on the nest, but their dull, cryptic plumage is thought to minimise such predation.
Back at Folly Bridge the males are left in large all-male flocks.
These males stick to their old habits, arriving at Folly Bridge at about 8 am and sleeping for one or two hours.
These males are still in their bright nuptial plumage and as long as they retain it they maintain the high levels of vigilance observed when accompanying their females.
However, during June and July they undergo a transition from their bright nuptial colours to a dull, camouflage ‘eclipse’ plumage in which they resemble the female.
As soon as this happens, male peeking rates plunge to the same levels as female peeking rates (Figure 4).
The implication is that males need maintain high levels of vigilance only when in nuptial plumage.
Once they lose those bright feathers they can afford to relax their vigilance.
These findings raise some important questions.
Rather than maintain high levels of vigilance all the time, birds choose to lower their levels of vigilance when risk is low.
This gives them a little more shut-eye.
Why is eye-closure so important?
Some clues might be found in studies of brain activity in peeking birds.
As in mammals, such studies reveal two main components of brain activity during sleep — active sleep and quiet sleep (Figure 5).
Birds can experience quiet sleep when they are peeking as well as when their eyes are closed.
However, active sleep is confined to periods when they sleep with closed eyes.
So it looks as though the length of time their eyes are closed determines the amount of active sleep in birds.
Thus sleeping in flocks may allow a bird to lower its level of vigilance and increase its active sleep without suffering an increase in the risk of predation.
Why birds should want to increase their active sleep is a mystery.
An answer to that question might give clues to the broader question of the function of sleep.
Flock size and peeking rates?
AS FLOCK SIZE increases the individual risk to any one bird decreases and so each bird can afford to lower its peeking rate.
However, there are other grounds for expecting a reduction in peeking rate with increasing flock size.
Let us assume that a cat stalks a duck until it gets within striking distance.
The cat then breaks cover and makes a final uncovered dash along the length of the jetty.
Let the time taken to make the final dash be T seconds.
The probability that the attack will be spotted is the probability that a flock member peeks before the cat completes its final uncovered dash.
That is the probability of a flock member peeking in the interval T .
If we assume that ducks peek randomly, briefly and independently of each other then the probability of the flock detecting a randomly attacking cat is given by P = 1 — e where n is the flock size.
B the mean peeking rate and T the time taken for the cat to complete its final dash.
This means that as flock size,n .
increases individuals can afford to lower their peeking rates,B , without suffering a fall in the probability of the flock detecting the cat.
Moreover, the farther from shore a duck sleeps the greater the distance a cat must cover in its final uncovered dash.
The greater this distance, the longer the time taken to make the final uncovered dash (T ), and so a duck can afford to lower its peeking rate.
White holes: cosmic energy machines
White holes are the poor relations of black holes, neglected by the mainstream of astrophysics.
A new concept of a cosmic oscillator, however, accords equal roles to both
Jayant Narlikar
BLACK HOLES have occupied the centre stage in astronomy and astrophysics for a decade and a half.
From the ‘mini’, weighing as little as an amoeba or only one hundred-millionth of a kilogram ( kg) to the ‘supermassive’ with a mass one thousand million times that of the Sun, they have been invoked to account for a wide range of cosmic phenomena.
By contrast; their counterparts, white holes, have been neglected.
But some new ideas incorporate both concepts and point the way to a role for white holes that is equally important to that presently accorded to black holes.
What are white holes?
To answer this question we first recall the standard description of the birth of a black hole through the phenomenon of ‘gravitational collapse’.
A star like the Sun can preserve a steady configuration because the thermonuclear reactions in its core generate high temperatures that result in strong outward pressures.
These counteract the tendency for the body to contract under its own gravitational pull.
Self-gravity would shrink the Sun to a point in a mere 29 minutes, if the outward thermonuclear pressures were absent.
But when the nuclear fuel runs out, the star contracts until its matter becomes highly dense.
The contraction is eventually halted when the subatomic particles enter a ‘degenerate’ state in which the space available for each particle hits a lower limit set by quantum mechanics.
The competition for space generates an outward pressure, holding the star in a new equilibrium; the star then becomes a white dwarf or a neutron star, depending on its mass.
The greatest mass a white dwarf can have is 1–44 times the Sun's mass; neutron stars cannot be heavier than about two solar masses.
Any more massive star that exhausts its nuclear fuel will collapse completely under its own gravity.
Supermassive objects — with masses as high as, say, a hundred million times that of the Sun — would collapse even with the resistance provided by thermonuclear reactions; in other words, before the fuel runs out.
An observer watching such a collapse from a nearby star would lose sight of the collapsing object.
When the star reaches a point where its total surface area equals that of a sphere of radius 2 GM/c2 , it disappears and becomes a black hole.
Here,G is the gravitational constant,c the speed of light, and M is the mass of the star, so the crucial radius, called the Schwadschild radius, depends only on the collapsing star's mass; for a star of the Sun's mass the Schwarzschild radius equals about 3 kilometres.
As the object shrinks further, no signals from it can cross the sphere with the Schwarzschild radius, not even light.
This barrier, containing the black hole, is called the event horizon .
Although the observer on another star loses touch with the collapsing object at this stage, the object itself still has a future.
An observer sitting on the star's surface could, in theory, trace the history of the object as it continues to shrink until it reaches the so called space-time singularity, when all its mass is concentrated into a point.
Albert Einstein's theory of general relativity suggests that the singularity marks the end of the future of the object.
An object the size of the Sun would take 29 minutes to collapse to a singularity under its own gravity — at least that would be the time measured by an observer stationed on its surface before he too vanished into zero dimensions.
An interesting feature of the general theory of relativity is that it should not matter whether time is running backward or forward: it is time-symmetric.
In principle, then, there is no reason why a star's collapse could not be reversed.
In the gravitational collapse of a massive star, the outer surface crashes through the event horizon into the space-time singularity (Figure 1a).
In the time-reversed case, the object emerges from the space-time singularity to come out through the horizon and attain an extended form (Figure 1b).
This object is a ‘white hole’.
The argument based on time symmetry applies only to the frame of reference of a person on the surface of the object and moving with it.
To a remote observer at rest relative to the centre of the object, the two pictures of expansion or collapse are manifestly not symmetric.
The most dramatic difference in the two pictures as seen by the remote observer is in the nature of radiation he receives from the object.
Figure la illustrates the situation in the collapsing stage.
Imagine a source at B on the collapsing surface,S , sending light waves radially out to the remote observer at A , who is stationary with respect to the centre of the object.
The wavelength of the light increases as it passes from A to B for two reasons.
First, because the source and observer are moving away from each other the doppler effect causes an increase in wavelength.
Secondly, as first discussed by Einstein, light going from an area of strong gravitational field to a region of weak gravitational field increases in wavelength.
An astronomer can measure this increase in wavelength if he can identify some emission lines in the spectrum of the object.
If the wavelength of a line produced in the observer's laboratory at A is and the  wavelength of the same line observed in the spectrum of the collapsing object is then the fractional increase z= (—) /is called the red shift of the spectral line.
Consider next what happens in the case of a white hole.
The radiation from B to A is again subject to both doppler and gravitational effects (Figure 1b).
However, they no longer act in the same way.
As before, the gravitational effect tends to increase the wavelength, because light is passing from a region of strong gravity near B to a region of weak gravity near A .
Notice, however, that the surface S is now moving towards A and the doppler effect tends to decrease the wavelength, to produce a blue shift .
The net effect at A will now depend on the dynamical details a of white hole's expansion.
Qualitatively the answer is illustrated in Figure 2 where the observed spectral shift is plotted against the time measured from the instant that the first signal from B reached A .
Notice that in the initial stages the doppler effect dominates and there is a strong blue shift.
But when, however, the expansion slows down, the gravitational effect begins to assert itself.
Eventually the blue shift declines to zero and changes over to a red shift.
The epoch of blue shift is usually confined to the time when the object is still inside the event horizon.
To someone familiar only with black holes, this behaviour of a white hole comes as a surprise.
But it is based on a reasonable argument; and the strong blue shift seen in the early stages of explosion justifies the adjective ‘white’.
How would an observer at A see the white hole?
While examining the spectral shift we considered the radial rays from the white hole.
Its overall appearance, however, depends also on non-radial rays.
Moreover, the observer at A forms a picture of the white hole on the basis of all the light rays that reach him at the same time.
Not all of these rays will have left the object when it was of the same size.
Some rays, which took a longer time to travel, left the white hole earlier (when it was smaller) while others, which took less time to travel, would have left the white hole later (when it was bigger).
We also have to take into account the passage of light rays through the highly curved space-time near the expanding object.
In the very early stages the white hole appears to expand at a rate several times the speed of light, as I explain in an article written with R. C. Kapoor in Astrophysics and Space Sciences (vol 53, p 155).
What of the blue shift of light from white holes?
Can we relate this property to any observable features of the Universe?
In 1975, Krishna Apparao and I discussed this point in a simplified model of a white hole (Astrophysics and Space Sciences , vol 35, p 321).
We assumed the white hole to be made of homogeneous dust, that is, matter free of pressure.
That assumption enabled us to calculate explicitly many dynamical effects associated with the white hole.
For example, if the expanding surface S emits monochromatic radiation of fixed intensity, then during the time of the strong blue shift the intensity of the white hole, varies simply in proportion to the cube root of the frequency.
Conversely, given the observed relation between intensity and frequency of radiation from an exploding object, we can determine the spectrum of the emitting surface S .
The exploding nuclei of galaxies such as the Seyfert galaxies (Figure 3) could be candidates for white holes.
Transient X-ray sources in our own Galaxy could be associated with white holes of stellar mass.
Sir Fred Hoyle has argued that ‘extra-supermassive’ white holes on the scale of 10 14 solar masses have ended up as large clusters or superclusters of galaxies.
And, of course, on the largest scale, the Universe itself, expanding from the big bang, may also be looked upon as a white hole erupting from a singularity.
The short period of large blue shift should manifest itself as a burst of high frequency photons (Figure 2).
Could the bursts of gamma rays detected by astronomers over the past decade, and still not accounted for, possibly be white holes?
Our simple model of 1975 showed that a white hole with the mass of a star can explain a galactic gamma-ray burst 10 seconds long.
The ‘softening’ of the spectrum (the steady increase in the relative proportion of lower energy photons) is a stamp of white-hole radiation that is often found in gamma-ray bursts.
The concept of a white hole was mooted in the early 1960s.
Why has it not caught on?
I can think of two reasons.
The first is a matter of taste.
The formation of a black hole is fairly well understood in astrophysical terms.
Its end, that is, the singular future that lies ahead for the collapsing object.
is no doubt peculiar; but, at the same time it is hidden from the external observer by the event horizon.
By contrast the white hole originates in a space-time singularity and the horizon does not prevent us from viewing this strange event.
The physicist tends to be unfavourably disposed toward systems whose beginning he cannot understand, and this attitude accounts for part of the antipathy towards the concept of white holes.
(Strangely enough, this attitude does not manifest itself in cosmology where the singular origin of the Universe is accepted as a matter of fact.)
The second reason is a mathematical one, raised in 1974 by D. M. Eardley (Physical Review Letters , vol 33, p 442).
Eardley discussed the strange topology of space-time near the origin of a white hole and argued that the expanding surface S ‘sees’ an avalanche of incoming matter from the surroundings.
This apparent infall is so fast as to smother the expanding white hole.
Eardley's argument suggests that a white hole would be a highly unstable object and that soon after its formation it would be converted into a black hole as it gathered surrounding matter.
For this reason a white hole cannot serve as a viable energy machine.
A white hole enthusiast may react to the above criticism both positively and negatively.
A negative response would run something as follows.
One could point out that supporters of the concept of massive black holes are also batting on a sticky wicket.
There is as yet no general relativistic demonstration that a collapsing and rotating supermassive object of about 100 million solar masses can survive as a single coherent entity to become a black hole.
Yet many theories based on black holes proceed on the tacit assumption that such objects exist in the Universe.
One could also point out that explosions on a large scale are observed in the Universe, and on empirical grounds these could be considered evidence for white holes.
Nor can the stability argument be regarded as the last word, as we do not know whether general relativity itself will be valid right up to the space-time singularity.
But we can be more constructive than this, using a new idea that unifies the concepts of black hole and white hole.
Let me go back to my earlier discussion of gravitational collapse.
I noted that a star collapses if the internal pressures in the object cannot resist the gravitational contraction.
This argument tacitly assumes that once the collapse begins there is no hope of stopping it at a later stage.
The reason behind this assumption is that the force of gravitational contraction becomes stronger as the collapse proceeds and the gap between its power and the resistance offered by any surviving internal pressures widens with time.
Indeed, general relativity tells us that any agency put in to oppose gravity must have energy.
The energy has an equivalent-mass and so it attracts matter and therefore increases the force of gravity.
For this reason, beyond a certain stage, any remedial measure to counteract gravity becomes self-defeating.
This argument does have a loophole.
Suppose there exists a gravity-opposing agency with negative energy, which grows in strength faster than gravity as the object contracts.
Such an agency generates a repulsive force which eventually becomes so strong as to halt the contraction of the object and to make it ‘bounce’.
Recently Apparao and I explored the possibility of the existence of such bouncing objects (Astrophysics and Space Sciences , vol 81, p 397).
In the early days of general relativity, Einstein himself proposed a repulsive force, the so called l-force.
This force grows in strength as the distribution of matter expands and is not useful in the present context.
Another repulsive force, the so-called C- field that Fred Hoyle and I used in the context of the steady-state cosmology, does however fill the bill admirably.
It modifies the scenario of gravitational collapse in the following way.
A massive object containing a small quantity of C- field begins to collapse when the pressure is no longer adequate to prevent it.
At this stage the C- field is also ineffective in stopping gravitational contraction.
However, as the object shrinks the C- field grows in strength and ultimately succeeds in causing a bounce.
The object thereupon begins to expand, and it will rapidly pick up speed.
As it continues to expand the speed drops and the expansion eventually comes to a halt.
This completes one cycle of oscillation.
This oscillator therefore resembles a black hole during contraction and a white hole during expansion.
The resemblance is not exact, however!
At no stage does the outer surface of the object go inside the event horizon.
This condition is satisfied even though the minimum size of the oscillator is quite small (Figure 4).
The massive oscillator combines most of the virtues of the black hole and the white-hole without their awkward features such as the space-time singularity and the event horizon.
And it provides a useful explanation for the power house that fuels certain cosmic sources.
The purist may, however, still balk at the idea of a negative-energy field, even though to date the C- field is not known to have led to any conceptual difficulty either in classical or quantum physics.
In the last analysis the need for such ideas will be dictated by observations of violent phenomena in the Universe.
MONITOR
A radical way to  tackle malaria
MALARIA parasites living in mouse red blood cells are killed by substances released by specialised cells of the immune system called macrophages.
This seemingly innocuous statement carries with it a completely new strategy for treating the 200 million or so malaria sufferers around the world.
The first drug to be recognised for its antimalarial effects was quinine, which found its way into the British  Pharmacopaea as early as 1677.
Quinine has been overtaken by newer drugs, the three most important being chloroquine, primaquine and pyrimethamine.
The problem with all these drugs is that they have many side effects which are sometimes fatally toxic.
But the biggest drawback is that there are very few places left in the world where the malaria parasites (species of Plasmodium)have not developed resistance to them.
Quinine and chloroquine kill parasites by blocking their ability to synthesise nucleic acids and primaquine and pyrimethamine disrupt the energy metabolism of parasite cells.
Now, Ian Clark from the Australian National University in Canberra, has proposed a completely new strategy for developing novel antimalarials — one that mimics the simplest mechanism the body has for combating infection; so called nonspecific immunity (Infection and Immunity , vol 39, p 1).
In non-specific immunity a class of white blood cells called macrophages kill invading organisms by releasing a gamut of potent substances and toxins.
The ones of interest here are a highly reactive chemical species called free oxygen radicals.
The half lives of these radicals are measured in nanoseconds — they literally destroy the first thing they bump in to.
Macrophages are found mainly in the liver, spleen and lungs, the small blood vessels of which, provide a perfect size for ‘bumping’ into red cells that are infected with malaria parasites.
So could malaria parasites be destroyed by assaulting them with free oxygen radicals?
Clark tested this idea by injecting a drug called alloxan into mice that were previously  inoculated with P. vinckei ,(other strains of Plasmodium have to be used in the mouse model because the human parasites P. vivax, P. ovale.
P .
falciparum and P. malariae do not infect rodents).
Alloxan is a diabetogenic drug that is known to produce free oxygen radicals as it is broken down.
Clark found that the level of parasitaemia dropped dramatically in the mice following alloxan treatment.
To confirm that it was due to free radical production he searched for a less complicated generator of oxygen radicals.
His chemist colleagues suggested he tried a substance called t-butyl hydroperoxide — an ‘off the shelf’ chemical reagent, whose ability to produce free radicals is well known to chemists.
Substituting t-butyl hydroperoxide for alloxan in a similar experiment, Clark found as he had hoped, that parasitaemia again dropped radically.
These experiments were later confirmed by a group at Syntex Research in California (Lancet , 1982, vol ii, p1431).
These results are important for a number of reasons.
After infection, malaria parasites multiply by a factor of eight every 24 hours.
A critical point is then reached after which a patient will either die from the disease, or survive if the parasites are killed and parasitaemia returns to a manageable level.
Until now nobody knew how the parasites were killed, but if Clark's idea is correct, and can be shown to operate in humans, a new generation of anti-malarials could be made which would kill parasites inside the red blood cells by local production of free radicals.
The idea goes some way to explaining why some individuals with red cell mutations are immune to Plasmodium infection.
People with sickle cell anaemia and thalassaemia are known to have red cells with defects in their outer membranes.
The same is true for individuals with a deficiency of the  enzyme glucose-6-phosphate dehydrogenase;(G-6-PD is an important enzyme of the glycolytic or central energy producing pathway).
This membrane defect makes it much easier for toxic substances made by the immune system to enter red cells and kill parasites.
It is unlikely that radicals are responsible for the body's total defence against Plasmodium infection, however, and antibodies are probably involved in fighting the later stages of infection.
As yet involvement of radicals has only been observed in mouse models.
Scientists still do not know whether the parasites in these systems are killed directly by macrophage products or whether the latter destroy the red cell membranes.
Clark's work clearly holds promise of a new class of antimalarials, even though there is much still to be done.
But it is exciting too for another reason.
Though pharmacologists now know how the present antimalarials work, quinine was initially based on a folk remedy and the rest were developed by producing chemicals and testing their effects.
The next generation of anti-malarials may be the first to be developed with specific biochemical knowledge of how the malaria parasite can be attacked and killed once inside the body.
Universe theory is full of holes
THE LARGE-SCALE structure of the Universe resembles a Swiss cheese — a collection of holes with matter (in the form of galaxies) only occupying the flattened walls around the holes.
So say F. Occhionero, P. santangelo and Vittorio, of the University of Rome, who have been inspired to make a new theoretical study of cosmological voids by the observational discovery of large regions of space devoid of galaxies (New Scientist , vol
94, p 355).
In traditional studies of the way inhomogeneities — lumps of matter in the form of clusters of galaxies — form in the expanding Universe, it is assumed that the dominant influence is a mass, or density perturbation.
On such a picture, a region of space which contains more than its fair share of matter ought to pull in still more by gravity, so that a cluster of galaxies forms in the heart of a region of space sucked clean of matter.
But that is exactly the opposite of the new picture.
By considering variations in the velocity of matter (compared with the ‘smooth’ velocity of expansion of an ideal model universe) the Italian team shows that cavities of the kind now observed can arise naturally.
A condensation surrounded by a void is equivalent to a local energy deficit; a void is associated with a local energy surplus (Astronomy and Astrophysics , vol 117, p 365).
The result is a new model of the Universe which resembles a certain brand of chocolate that is full of bubbles.
The size of the holes, and the thickness of the surrounding bubbles of enriched galaxy formation, depend on the details of the perturbations fed in to the idealised model calculations, and this offers hope that better observations of these holes in the Universe may reveal information about the kinds of disturbances that made the big bang of creation develop irregularly.
How to tell gluons from quarks
QUARKS, so the present theories go, are the building blocks of matter, and they are bound together by entities called gluons.
While no experiment has ever identified an individual quark, there was a good deal of excitement in 1979 when physicists working at DESY, the German national accelerator laboratory near Hamburg, found evidence for quarks and gluons being produced together in high-energy collisions between electrons and positrons (antielectrons).
Now, one group working at DESY believes it has found a way to differentiate the effects of the gluon from those of the quarks produced in electron-positron collisions.
When an electron collides with a positron the two particles disappear, or annihilate, to create a high-energy photon.
In some instances the photon quickly materialises as a quark and an antiquark, which turn into showers of observable particles such as protons and pi-mesons.
In collisions at relatively low energies of PETRA (the electron-positron accelerator at DESY) the quark and anti-quark produce two streams of particles that appear back to back in apparatus surrounding the collision point.
At higher energies the detectors reveal not two but three jets of particles, all in the same plane, rather like the Mercedes symbol (New Scientist , vol 87, p 786).
The third jet is evidently created when either the quark or the antiquark radiates a gluon, which in its turn creates another shower of particles.
Gluons are in fact radiated by quarks produced at lower energies.
But it is only when the parent quark and radiated gluon themselves have relatively high energies that the jets from each can be clearly distinguished.
The gluon is a particle akin to the photon of electromagnetism and the W particle of the weak nuclear interactions (New Scientist , 27 January, p 221).
Like these two particles, the gluon transmits a force between other particles: in this case, the strong nuclear force that binds quarks within protons and neutrons.
Several of the groups working on PETRA have detected three-jet ‘events’ in their apparatus, but now one of these groups has worked out how to tell which jets come from the quark and antiquark and which from the gluons.
Members of the group known as JADE, who come from the UK and Japan as well as Germany, have  analysed the way in which momentum and energy are carried away from the collision by particles in the jets (DESY preprint 82–086).
The researchers first order the jets according to the amount of energy in each.
They then look at the average momentum particles carry transverse to the main direction of the jet: a higher transverse momentum means that the jet is more spread out.
The group finds that, for a given jet energy, the transverse momentum is always larger for the jet with lowest energy thin it is for the other two.
The researchers also calculate how events look according to present theories of the strong interaction, and ideas about the conversion of quarks and gluons into observable particles.
They generate — mock events’ according to these assumptions and feed them through the analysis chain.
The mock events turn out to reproduce the data only when the quarks and gluons are made to convert differently into particles, for the comparison with theory shows that the lowest-energy jet is generally associated with the gluon.
This means that gluons for some reason produce jets that are more spread out than the ones that originate from quarks.
The researchers have therefore not only separated out the effects of gluons from those due to quarks, but have also learned something about the still little understood way in which these building blocks turn into conventional particles.
Suicide — proof paracetamol
PARACETAMOL could soon be cured of the stigma of being a ‘dangerous and insidious’ drug.
It was labelled as such by a London coroner recently, after four inquests on suicides were heard in the same court within a week.
But its lethal potential could be eradicated if a new formulation incorporating methionine, a harmless compound used in treating overdose victims, is granted approval by the Committee on safety of Medicines (methionine is an amino acid).
Sterling Winthrop. which markets paracetamol under the trade name Panadol, says that an application for a product licence is imminent.
Around 30 standard paracetamol tablets can kill a healthy adult and even less if the liver has been damaged before through alcohol or drug abuse.
The drug combines with glutathione present in the liver.
But once the glutathione has been used up, paracetamol breaks down to form benzequinone-amine.
This substance is thought to bond to the walls of liver cells and eventually kill them.
Methionine or an alternative drug, N-acetylcysteine, prevents liver damage by boosting the levels of glutathione.
Since this treatment was introduced, the number of fatal overdoses has fallen from a peak of 192 in 1978, to 152 in 1980, the last year for which figures are available.
But even expert attention will not help if the victim doesn't arrive in hospital until hours after the overdose — which is often the case.
Collagen implant lifts scars
BIOTECHNOLOGISTS have come up with a surprising new way of repairing many scars and wrinkles — using purified cow-hide.
A Californian high-technology firm, the Collagen Corporation, has found a way to enzymatically alter bovine collagen, making it virtually indistinguishable from the human variety.
Injections of collagen, the protein in connective tissue, can build up soft depressions in skin  caused by acne, age, injury, or disease.
The collagen implant, known as Zvderm and marketed in the UK by Kirby-Warrick Pharmaceuticals, is a white paste packed in syringes.
The paste contains collagen suspended in a salt solution mixed with a local anaesthetic, lignocaine.
Once injected, the lattice of collagen fibres is gradually invaded by cells and blood vessels and so comes to look and feel like normal skin.
But some people are allergic to even this highly-purified animal collagen, so potential recipients are first given a small test dose.
And the implant is not the answer to all disfiguring scars or wrinkles.
Inflexible or rough-edged blemishes caused by chicken pox or acne and superficial wrinkles around the eyes are not helped by collagen implants and the technique cannot be used to enlarge breasts.
But several sessions in the surgery can improve many scars, birth defects such as cleft lip, and deep frown lines.
So far some 300 patients in the UK have been successfully treated with the collagen implant by plastic surgeons and dermatologists.
Inorganic chemists find new cancer drug
INORGANIC substances are now rarely used to treat diseases, but one platinum compound may prove to be a powerful new anti-cancer drug.
The chemical, codenamed cis- DDP, acts at the very site where cancer begins — the DNA.
The inorganic compound cis- DPP can chemically bond to guanine bases in DNA and so disrupt the replication of DNA in actively dividing cells.
Cis- DDP, short for cis- diamminedichloroplatinum (II) or cis-[Pt (NH3) 2CI2], is a square planar complex.
Discovered in 1844, it was called Peyronne's chloride after its discoverer to distinguish it from another complex with the same formula, known as trans- DDP.
In 1969 researcher discovered that only the cis- DDP isomer killed tumours.
There are good chemical grounds for expecting a difference in the reactivity of the two isomers, because the chlorine atoms of cis- DDP are diagonally opposite NH3 groups in the molecule, whereas in trans- DDP the chlorines are opposite each other.
The chlorine atoms make way for the other atoms when cis- DDP attaches itself to guanine, one of the bases of DNA.
Nuclear magnetic resonance spectroscopy has confirmed that the platinum in cis- DDP bonds to the nitrogen atom in guanine's smaller ring.
When two guanine bases are side by side in the DNA chain, both can attach themselves to the same platinum atom, forming a stable complex.
Jan Reedijk and co-workers at the state University of Leiden in the Netherlands found that cis- DDP could bond to two guanine bases in a small chain of single stranded DNA despite an intervening cyosine base (Journal of the American Chemical Society , vol 104, p 2664).
New research has gone further.
Stephen Lippard and John Caradonna of Columbia University, New York, working with Michael Crait and Mohinder Singh of the Medical Research Council's Molecular Biology Laboratory at Cambridge, have shown that cis- DDP can bond to a double stranded chain of DNA as well (Journal of the American Chemical Society , vol 104, p 5793).
When they reacted the drug with a self complementary two’ stranded, six-base DNA chain, they found that the hydrogen bonding which holds the two strands together cannot compete with the bonding of the platinum complex to adjacent guanine groups (see Figure).
This disruption of the hydrogen bonds which  normally hold the two strands of the DNA molecule together could block the replication of DNA chains during normal cell division.
For it is the hydrogen bonding ability of the existing chain that determines the sequence of bases laid down in a growing chain of genetic material.
Further research will hopefully discover more metal complexes that can bond to the nitrogen or oxygen atoms of other bases in the DNA.
If these drugs can selectively block the hydrogen bonding in the DNA of cancer cells, then replication of the genetic material of such cells will be halted, and proliferation of tumours may be foiled.
Close encounters revive dead quasars
IN TWO separate investigations, astronomers have found evidence that encounters between two galaxies can turn one of them into a quasar.
The interaction rips gas from one galaxy, which falls to the centre of the other to fuel the quasar ‘explosion’, probably a reawakening of activity which the galaxy suffered much earlier.
This could explain why we see some quasars much nearer than we would normally expect to see them.
Gregory Bothun, of the Harvard Smithsonian Center for Astrophysics, and five colleagues from as many different establishments, have been investigating the nature of a relatively nearby (low redshift) quasar dubbed 0351 +026.
This quasar was already known to lie within a galaxy, and improved observations have shown that the ‘host’ galaxy itself is interacting with a small companion galaxy.
The whole system is rich in hydrogen gas.
This observation leads the team to suggest that quasar activity may have been triggered by galaxy-galaxy interactions which have stimulated a flow of material onto the nucleus of the larger galaxy, possibly the site of a black hole (Astronomical Journal , vols 7, p 1621).
The companion galaxy in this system is a very modest dwarf, and the host galaxy itself is similar to the Large Magellanic Cloud, a companion to our own Milky Way Galaxy.
If the redshift of the system had been more than 0.1, still modest for a quasar, neither host nor companion would be visible.
This evidence lends weight to the supposition that most quasars are the active nuclei of normal galaxies — not necessarily giant galaxies — and suggest that any hydrogen-rich system might be triggered into such activity.
Alan Stockton, of the University of Hawaii, has been investigating three quasars with redshifts between 0.07 and 0.26, each of which has a very close companion galaxy (Astrophysical Journal , vol 257, p 33).
These companions lie within 30 000 light years of the quasar — only the Sun's distance from the centre of our Galaxy — and they appear unusually small.
Stockton argues that we are here seeing a pair of galaxies in mutual orbit.
One (presumably the more massive) contains the quasar core, the other is the ‘companion.’
As they reach their distance of closest approach in each orbit, the quasar galaxy rips some of the outer, loosely bound, stars and gas from the companion.
As a result the companion has lost its extended outer regions, and we see it as merely a compact core of stars.
The material that has fallen into the more massive of the two galaxies rekindles the quasar at its core.
These investigations could solve one major problem in quasar research.
The  energy emitted by a quasar can exceed the total output of an ordinary galaxy a hundred times over.
Most astronomers think that the energy comes from a disc of gases surrounding a very massive black hole.
It is easy to ‘feed’ a black hole in the early days of the Universe, when galaxies were first forming out of gas.
When we look out in space (and hence back in time) to a redshift of 2 to 3, we do indeed see a lot of quasars.
They cannot keep up this luminosity for long, however, and they should have burnt out long ago.
But we do detect quasars relatively near in space, and hence at virtually the same age as our own Galaxy (some 15 000 million years).
The new results suggest that these galaxies undergo intermittent outbursts as a companion passes particularly close to them.
It will be intriguing to test whether other nearby quasars have close companions, not distinguishable from the quasar images to be seen on previous photographs.
And do galaxies with unusually compact companions show any sign of past quasar activity? one intriguing clue is that the nearest compact galaxy we know happens to be a companion to the giant radio galaxy M87 — and its orbit must have taken it to within 6000 light years of M87 only 100 million years ago.
Stockton says ‘what we witness today [in M87]may be only a feeble remnant of a blaze kindled 10 6 years ago.’
Technology 
Atomic billiards on the market
FACED with cuts of around 15 per cent in support from the government, Manchester University's Institute of Science and Technology has turned successfully to industry for support.
Its fast technique for assessing samples drilled from beneath the sea for oil companies is a commercial winner, and a go-ahead team under Dr John Bather is having to expand to keep pace with the demand.
Another service to industry, which has Just started up, looks like having a great future.
This is FABMS — fast atom-bombardment mass spectrometry.
Essentially it is atomic billiards; a beam of atoms fired at the surface of anything from glass to an industrial catalyst dislodges ions from the specimen's top one or two atom layers for analysis by mass spectrometry.
The difference is that FABMS for the first time uses a beam of uncharged atoms instead of charged ions for the process.
Ions are fine for probing electrically conducting materials because the charge they carry to the specimen is carried away as fast as it builds up.
But ions cannot probe non-conductors because they build up a charge on the surface, which distorts the analysis.
Atoms open up a much wider range of materials; glasses (the first client for FABMS was Pilkingtons which studied the effects of new metallic coatings), paint pigments, insulators, biological materials, adhesives and industrial catalysts.
Dr John Vickerman, who leads the atom bombardment team, has offered the technique on a part-time basis for the past two years.
But he found it was taking up more and more time: ‘It had to be double or quits,’ he said.
Now, £100 000 from the Department of Industry has enabled him to set up a full-time commercial unit to  analyse samples sent from Europe as well as Britain.
The technique is still being developed; it is now possible to image surface structures on a television screen, using a beam focused to one micrometre to scan the surface.
The focus will eventually be sharpened to make it possible to ‘see’ individual large organic molecules.
The key to FABMS is the technique whereby atoms, having first been stripped of electrons to allow them to accelerate in a magnetic field, subsequently have their electrons replaced by passing through inert gases.
The cost of the service is between £300 and £500 per day, during which the team can work through about eight to 10 specimens.
The Department of Industry will pay for the first three years, but after that expects FABMS to pay for itself.
Probably the single most important area for atom bombardment is in the design of better catalysts for chemical reactors.
Today, this is as much an art as a science, because of the huge differences of scale between small laboratory experiments and conditions in industrial reactors.
Vickerman's unit is just starting to bridge the gap with a new piece of apparatus.
It subjects experimental catalysts to the same conditions they would face in an industrial reactor, then to probing by FABMS.
Less than a second elapses between the two stages.
This facility, the first of its kind in the world and built with the aid of a £100 000 grant from the Science and Engineering Research Council, should allow chemical companies to design catalyst much more rationally — and so help to avoid future disasters like the dioxin explosion in Seveso, Italy.
Save energy and get back to work
BRITAIN could create over 150 000 new jobs by investing in energy conservation.
such a programme would pay for itself within five years, and save fuel worth something like £2800 million a year.
The figures are from a report that the Association for the Conservation of Energy published last week.
The report says the main thrust of the work should be in reducing the amount of energy Britain burns to keep buildings warm.
The government's Building Research Establishment estimates that buildings account for half of Britain's energy consumption.
The report urges measures such as insulating lofts, walls and ceilings, and improving draught proofing and heat controls on a national scale.
Such a programme would create 124 000 jobs immediately, building up to 155 000 over two years.
The jobs would largely be unskilled and semi-skilled and a high proportion would be in inner city areas, where high unemployment bites particularly badly.
The undertaking would cost the government about £10 000 for each job it creates.
But the association points out that the government already spends £12 300 on each job it creates through its regional incentive scheme.
Meanwhile, Britain's government offices are being shown an easy way to cut their energy bills.
According to the Building Research Establishment, the government's Property Services Agency spends about £20 million a year on lighting its buildings.
On 8 March, the establishment will tell architects and administrators how they could cut that cost by as much as 40 per cent.
Measures such as increasing the amount of natural light, and relying more on ‘local’ fittings could do the trick, the establishment believes.
But the most important saving could be made by persuading people to turn off lights when they are not needed — either by time switches or by well-designed panels which allow people to select easily the amount of light they need.
Battery meter
SCIENTISTS from the General Electric Company in New York have come up with a way of measuring how much charge is left in a lead-acid battery.
The device could solve one problem with electric vehicles — the lack of an accurate ‘fuel gauge’.
The device is based around a humidity sensor.
The amount of water vapour in a battery depends on the concentration of sulphuric acid in the solution.
This in turn depends on the state of charge of the battery.
The sensor consists of a piece of solid electrolyte with two gold electrodes on its surface.
A porous polymer membrane bag seals the electrolyte, allowing water vapour, but not the acid solution, to pass.
The prototype reproduces readings with an accuracy of about 10 per cent— on par with most petrol gauges.
One drawback is that it responds only to quick changes in humidity, but the inventors point out this should not be a problem with a fuel gauge.
Tablet timer
AN ENGINEER with an American drug company has invented a high technology aid for people who cannot remember when they last took their medicines.
It is a liquid-crystal time display built into the top of a pill bottle, which indicates the time and date the bottle was last opened.
The inventor, Bart Zoltan, says the device could be made in bulk for under $4 — a good deal cheaper than treating an overdose.
Zoltan's company, Cyanamid, plans to license its pending patents to makers of digital watches.
They are likely to snap it up — unless wearing two watches becomes fashionable, the market for digital timepieces is pretty well saturated.
Slipped disc
THE WORLD'S third incompatible videodisc system, VHD, is to go on sale in Japan on 21 April.
But there is still no firm news of a VHD launch in Europe or the US.
And the plants that Thorn-EMI set up to press the discs will remain in mothballs.
The company behind the system, JVC, plans to have 5000 players and 200 000 discs available from day one.
The player will cost £400 and the discs £15 each.
There will be around 200 titles, mainly films, music, ‘how to’ programmes and a little soft pornography.
If the launch is a success, 12 other Japanese firms will follow with players.
JVC's disc plant near Tokyo can make up to 300 000 discs a month.
Unmanned submarine plumbs new depths
Marine archaeology is heading for new depths with the second and perhaps most spectacular underwater shipwreck foray by a new unmanned submarine.
After an 11-year search, a team of archaeologists, photographers and engineers has found and photographed two American sailing schooners which sunk during the war of 1812 as they sailed Canada's Lake Ontario to repel the English invasion.
The submersible, or remotely-piloted vehicle, is a roughly hamburger-shaped package of lights and cameras, weighing 162.5 kilogrammes, powered by direct current sent through cables from a surface ship.
With five horizontal and vertical fan bladed thrusters, it is capable of turning completely on its axis of moving helicopter-like in any direction to within a few centimetres of where it is directed.
The ‘driver’ watches the vehicle's progress on a colour  television monitor.
The submersible's forte is going where divers cannot.
It proved its mettle in its first dive, an expedition to the Arctic to photograph the wreck of the Breadalbane (New Scientist , vol 89, p 136), 105 metres down.
In its latest expedition, an improved vehicle took thousands of still shots and 23 hours of videotape of the Hamilton and the Scourge, both about 20 metres long and top-heavy with cannon for more fire power.
On 8 August, 1813, a sudden and violent squall sank both ships within minutes of each other.
They took all but eight crew members with them, 100 metres to the bottom of icy Lake Ontario.
The icy coldness at that depth, about 3°C, and the low oxygen level have limited algae growth and preserved the  vessels in almost ‘as good condition as the day they went down’, said Daniel Nelson, the expedition's leader.
Cutlasses can clearly be seen secured over gun ports, with boarding hooks and axes nearby and the bones of sailors scattered in the silt.
A female figurehead still graces the Hamilton's bowsprit, and cannon lie askew along the rails.
According to Nelson, divers could not have reached the wreck without cumbersome diving suits and mixed gas air supplies.
Their movements would have kicked up the fine silt carpet on the bottom of the lake, obscuring vision.
The vessels' hulls are completely intact, and the team hopes to raise them within a few years.
The inventor of the submersible, Chris Nicholson, says the machine is capable now of reaching 600 metres.
Theoretically it could go to any depth — for instance to the bottom of the Atlantic, where the Titanic lies.
Besides the Titanic, Nicholson and his colleagues have their eyes on several suspected Roman, Greek and other ancient wrecks in the Mediterranean.
They plan to try next spring for a suspected ‘major gold wreck in south America’, which they decline to discuss in detail.
But on academic grounds, the North American expeditions are the most valuable.
The Breadalbane and Lake Ontario expeditions have opened a new era in underwater archaeology, Nelson says.
Unlike shallow-water wrecks, which are rotted by marine organisms and turbulence, deep water finds should be well preserved.
Japan's chip-makers head for the good life
TECHNOPOLIS: the word conjure up visions of towering skyscrapers connected by vertiginous walkways with flying machines of all descriptions whizzing about.
But to Japan's Ministry of International Trade and Industry' (MITI) the word has a different meaning.
It is the name of a new strategy for regional development based on technology.
The move has its origins in three phenomena.
Japan's industrial development is grossly imbalanced, with about two-thirds of production squeezed into one-fifth of the land.
Secondly, high technology industries are footloose — products such as microchips are easy to transport, and thrive in a clean environment.
Thirdly, more and more people, particularly the young and well qualified, are opting out of Japan's overcrowded cities for the ‘good life’ outside.
MITI came up with the Technopolis project as a cheap method of developing regional areas by exploiting existing infrastructure, and local initiative.
High technology industries are not tied down by transport costs: one tonne of microchips is worth anything up to 100 000 times a tonne of steel plate, so chips tend to travel by air.
Another consideration is that the government expects high-technology' industries to grow by 10 per cent a year for the next decade.
A typical MITI Technopolis will be near a ‘mother city’ with a population of over 200 000 and an airport.
It will consist of three zones, in a pleasant natural setting.
One zone will contain the core industries, electronics, robotics, biotechnology and so on.
The academic zone will contain laboratories and information processing facilities, and the third zone homes for 50 000 people.
Houses will be solar-powered, with ‘experimental social facilities’ such as cable television.
About 18 of Japan's 47 prefectures are in the running for Technopolis developments.
one likely site is Kumamoto on the southern island of Kyushu.
The area, already known as ‘silicon island’, is Japan's largest producer of microchips.
The communications grant NEC set up there in 1970, and its daily output of two or three tonnes of chips is jetted up to Tokyo every evening.
The first step to getting Technopolis on the road is legislation to channel into the project what few funds the government has for regional development.
MITI wants to offer incentives such as cheap loans and low taxes to firms moving in.
The second stage will involve the finance, education, housing and several other ministries.
MITI had hoped to get the legislation through by next month, but it now looks as if it will have to wait until autumn before the ministries have talked it over.
Although there is no final date for the project's completion, the men from MITI reckon that 1990 should see it ‘almost finished’.
‘The unemployed cannot blame automation’
The Secretary of State for Industry said that robots would create jobs in Britain, when he opened an unmanned factory last November.
He was asked to mike the case that supports his belief
Patrick Jenkin
FEARS that automation will inevitably lead to higher unemployment are not new.
In 1811 the Luddites rioted and destroyed the textile machinery which they saw as a direct threat to their jobs.
Yet employment in the textile industry proceeded to grow during most of the 19th century.
Nor was this an isolated example.
In the same century, the fastest growing industries, in terms of employment, were those based on new technology.
Railway employment rose from 29 000 in 1851 to 320 000 in 1901; in chemicals, employment over the same period trebled; and in metal manufacture employment nearly trebled.
The last century demonstrates clearly that, despite the fears to which new technology gave rise, technology promoted employment.
More recent history repeats the lesson.
Considerable concern was expressed in the 1950s and early 1960s about the impact of automation on jobs.
Nonetheless, employment in the UK reached record levels towards the latter part of the 1960s.
Despite the evident lack of competitiveness of much of the British economy, and the impact of the first oil crisis, total employment showed no overall fall during the 1970s, a decade which witnessed the widespread diffusion of computers.
Even today, Britain has the highest proportion in Europe of people of working age actually in jobs.
It is easy to understand why the fears of technology generated unemployment should enjoy a renaissance during a world recession.
Undoubtedly concern about the impact of robots and other microelectronic-based production equipment has been exacerbated by the depressed world economy and the high levels of unemployment in nearly all the major industrialised countries.
But the facts do not support any causal relationship between automation, higher productivity and unemployment.
It cannot be emphasised too strongly that our unemployment problems do not stem from the installation of such equipment.
In the first place the penetration of robots, numerically controlled machine tools, and other microelectronic-based equipment in British industry is as yet very limited.
By the end of 1982, for example, there were a total of 1152 robots installed in the UK.
Estimates suggest that little more than 5 per cent of the stock of machine tools were numerically controlled.
Quite simply, there is too little equipment installed to account for the levels of unemployment.
Secondly, even when such equipment has been installed it would be wrong to conclude that the overall impact on jobs has been negative.
The countries with the highest level of robots per employee, Japan and Sweden, both have very low rates of unemployment.
Far from high usage of robots being associated with high levels of unemployment, the opposite is true.
This may at first appear paradoxical because robots are often — perhaps most often — thought of as mechanical workpeople, displacing humans.
It is hard to associate that picture with an analysis which shows the use of robots promoting employment.
To understand the true picture, it is necessary to consider how any new technology incorporating high productivity affects jobs.
The installation of a robot, for example, has both a ‘direct’ and a ‘compensating’effect on employment.
The direct effect is the net change in the number of jobs before account is taken of output changes.
It is sometimes, although by no means always, negative.
However, the installation and operation of robots and related equipment improves output, albeit not immediately, and this helps to increase jobs.
How then does output increase?
The primary reason for introducing new technology such as robots is to reduce costs and improve product quality.
Lower costs mean lower prices.
With the improvement in product quality, this results in increased demand for our goods and  services , which in turn generates higher output and employment.
Profits also increase, inducing higher investment and R&D expenditure thus creating jobs.
Finally, investment in robots and other microelectronic-based equipment provides opportunities for domestic producers of such capital goods to increase output and employment.
Some specific examples show how the argument works out in practice; how automation, far from destroying jobs, can create or safeguard employment.
Tallent Engineering at Aycliffe, County Durham, last October began to operate a computer-operated press system linked to a robot welding line.
The system helped the company to win a £5 million a year contract to supply rear suspension arms for the new Ford Sierra.
It not only secured jobs which might otherwise have been lost but also created 80 more.
Without investment in new technology is thought that the work would have gone abroad.
Without the robots the company could not have coped with the Ford contract.
The pressure on the welders would have involved a very high rejection rate — a problem overcome by robot welding.
Flexible manufacturing systems (FMS) provide the economics of mass production to small batch manufacture.
Savings come not so much from savings in manpower as from the reductions in working capital, higher production quality.
better control, and much faster switching from one product to the next thus avoiding the need to carry excess stock.
Normalair-Garrett (NGL) at Crewkerne was among the first companies to introduce flexible manufacturing in the UK.
NGL found that with FMS stock work in progress is now being turned over 24 times a year as opposed to the previous 3.3 times.
It has also cut manufacturing lead times from 17 weeks to two and trebled output per operator.
A more traditional industry gives a similar account: J & J Cash of Coventry has been weaving name tapes on narrow measures of cloth since 1902.
The industry's traditional labour-intensive Jacquard process had by the 1960s begun to threaten Cash's position because of rising prices and inability to respond to peak demands.
A measure of automation based on a computer and a punched-tape system was introduced and this helped cut costs and speed production.
But, more recently it became necessary to introduce an improved system based more fully on microelectronics.
The investment has made Cash strongly competitive, by keeping prices  down and improving turn-round.
Although a few jobs have been lost, the workforce today is nearly 200, whose jobs are now more secure because of automation.
Most recently, consider the direct effect at Telford in Shropshire through the expansion of the robot manufacturing activities of Unimation (Europe).
Nearly 250 new jobs have been created in the company, and as many more in its suppliers.
The important point is that increased use of advanced production technology represents a growth area for supply of the equipment involved.
In robotics, for instance a number of British companies have begun to develop and make robots, so creating jobs directly.
Measuring the wider, compensating effects of automation is, of course, difficult.
However, it is clear from a variety of European studies that improved competitiveness helps jobs.
The Institute of Employment Research at Warwick University recently carried out a number of macroeconomic simulations to discover what would happen if Britain installed sufficient microelectronic technology to improve its rate of productivity growth by 1 per cent relative to its competitors.
The answer was that such a technological acceleration would create more jobs than it displaced.
Similarly both the Rathenau Advisory Group in the Netherlands and the Industrial Institute of Economic and Social Research in Stockholm, carried out simulations which indicated that slow introduction of microelectronic technology would have a worse effect on employment than keeping up with other countries.
It is not automation but the failure to automate that risks jobs.
Although microelectronic production technology can increase the total number of jobs, the occupational structure of employment is likely to change significantly.
In particular.
the demand for engineers, technicians, computer programmers and software experts can be expected to increase sharply.
(The NEDC says that already 16 000 more programmers are needed.)
Fewer machine-tool operators, welders and production fitters are likely to be required.
In particular, the new demand is likely to be for those concerned with software.
Already there is evidence that some firms which have introduced microelectronic production technology have experienced difficulties as a result of a shortage of engineers, technicians and programmers.
What is needed is the right training and retraining and the government therefore makes available a wide range of training schemes and courses.
The overall message is clear.
We must make use of microelectronic technology.
We must be prepared to adapt as some industries and occupations expand and others contract.
Secure employment will come from embracing new technology, not from pretending that it does not exist.
This is the way to build a high wage, high productivity country.
We can then become more competitive, sell more goods and employ more people.
We can also afford the better social services which are the hallmark of a civilised state.
Road casualties solve toad mysteries
Thousands of common toads are killed by traffic, distressing passers by and alarming conservationists.
The overall impact may be insignificant — but studies on the victims are highly illuminating
Paul Gittins
IN THE NEXT few weeks the common toads of Britain (Bufo bufo) will converge upon lakes and ponds intent on reproduction.
As they migrate to their breeding sites, from distances of up to a kilometre and a half, many will be squashed by traffic; sometimes singly, sometimes in pairs with the males already piggybacked on the females, in the characteristic prenuptial position of anurans (tailless amphibians) known as amplexus.
So great is the slaughter that there has been enormous public concern and since 1978 my colleagues and I have studied the effect of road casualties on the toads that breed in the lake at Llandrindod Wells, in mid-Wales.
In passing our studies have helped to clear up some of the outstanding biological problems that underlie the reproductive biology of Bufo bufo , such as why it is that the males so greatly outnumber the females, and why they are smaller.
Our first problem at Llandrindod Wells was to estimate the numbers coming to the lake, so each night during the spring we made hourly circuits of the lake collecting all the toads we encountered.
This was made easier as the lake was completely encircled by a road, with a wide pathway down one side of the lake, and we often collected several hundred in one circuit.
After the final collection of the night, when all the toads had been recorded and marked, we released them at the margin of the lake near the spawn site.
We handled more than 6000 toads in the first year and immediately realised that the population was larger than at first envisaged.
Of course this 6000 includes some individuals that we picked up more than once; but by marking the toads we ensured that we counted each one only once each year, and standard marking and recapture techniques enabled us to estimate the size of the population, and the annual rate of mortality and recruitment of newly matured adults to the breeding population.
Thus we discovered that about 6000 males and 2000 females were breeding in the lake (see Table).
This is the biggest toad population ever recorded but careful studies elsewhere, using similar mark and recapture techniques, will probably reveal others as large or even larger.
Only a few hundred were killed on the road each year (about 4 per cent mortality), which, as the Table shows, is insignificant compared with the overall annual mortality rate of 50–60 per cent.
It is heartening to know that road casualties present no substantial threat to the toads at this particular lake.
Of course we helped to reduce road casualties by removing toads from the road for marking.
At other places people have often sought to reduce casualties by carrying the toads across the road and putting them into the breeding pond, but as often as not the toads they put into the pond were moving out of it rather than in, so the toads have to run the gauntlet of the road a second time.
Also, we observed that males close to the breeding site seem deliberately to sit out on roads, where they have a clear view, and wait to jump on females as they pass.
More than 70 per cent of the females at the lake reach the water with a male already riding piggyback.
Collecting and holding the toads in containers until about 23.00 hours when the traffic dies down, as we did in our study, is a much more effective way of reducing road casualties.
We recommend it to toad rescuers.
Actually, road casualties at the Llandrindod Wells lake did not significantly affect the overall breeding potential, and warning signs have encouraged drivers to slow down.
But why are there three times as many male toads as females coming to breed each season, as all studies of breeding toads have shown?
The imbalance is even more pronounced on any particular night as males stay at the breeding site for the whole season, whereas females mate and leave as quickly as possible.
The work at Llandrindod Wells lake has at last revealed the answer.
We were able to find the age of the toads in a way analogous to that used for ageing trees; by taking thin sections of bone from a toe of the victims of road casualties.
When the sections are stained we can see wide, light-coloured bands representing the summer period of growth, and darker lines representing the winter when there is little or no growth.
Thus it is easy to gauge an individual's age by counting the number of dark resting lines in the bone (see below right).
By this means we showed that males at Llandrindod tend to start breeding a year younger than females.
In detail, about 3000 young males join the adult breeding population each year, and thus make up about half the total of breeding males.
Almost certainly there is an equivalent number of young females in the non-breeding population, but these take a further year to reach maturity.
Given a 50–60 per cent annual mortality, only about 1400 of the immature males survive to join the breeding population; the annual mortality of females is slightly higher than in males, probably because of the physiological stress of producing eggs.
Such a rate of mortality, combined with the earlier sexual maturation of the males, would produce the 3:1 sex ratio found in our population.
Similar calculations for other populations of toads will probably produce the same results, although the actual sex ratio may vary from about 2:1 to 5:1 according to the size of the population and the rates of mortality.
A problem that has bothered biologists, at least since Charles Darwin, is why the males of Bufo bufo toads are smaller than the females (New Scientist , vol 95, p 2214.)
In general, when male animals compete for the attention of females, the biggest males are most likely to be successful; therefore, as Darwin observed, in species where the males compete, they tend to be bigger than females, as in baboons or in most species of seal.
Male common toads do compete for females, and in general, the biggest males (those with the deepest voices) are the most successful.
Yet the males average only about 60 mm in length.
while the females average 75.
Our study helps to resolve the apparent paradox: females take a year longer to reach sexual maturity and so have longer to grow.
The optimal reproductive strategy for a male would appear to be mature as quickly as possible, so as to achieve as many matings as possible.
But for females it is best to be as large as can be achieved so as to be able to produce most eggs.
Indeed, the very small females that occasionally come to the lake do not contain any eggs at all, implying that females must reach a certain minimum size before they can produce eggs.
Finally, the mortality rate is such that although toads can live for 40 years or more in captivity, only about 1 per cent of the population live to be eight years or more in the wild.
The oldest individual we found was eight years.
Although we have answered some questions, our work has presented us with many more.
Perhaps the most interesting is to discover what keeps the size of the population within such narrow bounds from year to year.
Presumably there are factors that control the size, and they depend on the population density.
We are now trying to find out the details of this negative feedback system.
FORUM
Hacking with the hackers
Neil Frude considers the case of the compulsive programmer
ABOUT 15 YEARS ago the computer scientist Joseph Weizenbaum announced that he had discovered a new personality type — the compulsive programmer.
‘People get hooked,’ he wrote, ‘they begin to behave in a way that resembles addiction.
They refuse food, they refuse their girl-friends.’
In their paper, ‘The psychology of robots’, Henry Block and Herbert Ginsburg speak of ‘computerniks — those starry eyed young men who can be found loitering at computer installations at all hours of the day and night.’
But the term that has caught on most widely to describe such zealots is ‘hacker’ and what they do, constantly, is known as ‘hacking’.
The characteristics of hackers have now been described a number of times.
They are fascinated by, addicted to an in love with the thinking machine.
They are fanatical, single-minded and devoted.
They spend hours and hours coaxing the computer to perform extravagant tasks.
They can hardly bear to be out of physical contact with the machine and when they are they carry their printouts around with them.
They prefer to associate with the machine rather than with human beings, although they may make exceptions for fellow hackers.
The conversation then revolves around programs and programming.
There are both advantages and disadvantages to hacking.
First of all, the hacker generally becomes a very proficient programmer, developing particular computer skills through constant practice and problem-solving.
The analogy has been drawn more than once between the hacker and the dedicated musician.
Secondly, the hacker makes a friend of the computer.
There is constant companionship and eventually, when the program is finally debugged, the machine really seems to ‘understand’.
Thirdly, the hackers are preoccupied, they have a vocation, a mission, a hobby which can take on the proportions of a religious quest.
And the quest can be without end, For there are always additional programs which can be written, programs which are more elaborate, more powerful and more refined.
The hacker is not content with a program which merely works, it has to be written in a style which is elegant, to perform its task gracefully.
The hacker has a purpose in his well-structured life, and constantly expanding horizons.
There are the good days when things work out well and the whole world seems sunny, and the bad days when a depressing bug refuses to give up its secrets.
Hackers talking about their preoccupation may have glazed eyes, they can see the true Light at the end of their programming tunnel.
For some, there can be no doubt, operating the system can have a deep existential relevance.
Then there are the negative effects, and it is these which have been stressed in the warnings of computer scientists, university doctors, and in the various confessions of ex-hackers.
Joseph Weizenbaum paints a suitably lurid picture of the victims of this computing monomania:
‘…bright young men of dishevelled appearance, often with sunken glowing eyes…their arms tensed and waiting to fire their fingers, already poised to strike, at the buttons and keys on which their attention seems to be riveted as a gambler's on the rolling dice.
When not so transfixed, they often sit at tables, strewn with computer outputs over which they pore like  possessed students of a cabbalistic text.
They work until they drop, twenty, thirty hours at a time.
Their food, if they arrange it, is brought to them: coffee, Cokes, sandwiches.
If possible they sleep in cots near the computer.’
The first stage in the demise of the hacker is marked by a lack of interest in other subjects.
Programming might have started out as an ancillary task in a student's special subject of physics chemistry or psychology but soon takes over as the dominating interest.
Computing becomes an end in itself as the fledgling hacker gets sucked into the loop between the human and the computer.
The A grade in computing which may result from the obsession is regarded as more than adequate compensation for the dismal Cs in all other subjects.
I have seen students who were initially persuaded rather against their will, to use a computer for solving some statistical problem in psychology become addicted within a very short time.
They lose all interest in the initial problem and prefer, instead, to concentrate on further abstract programming.
Some university departments are so aware of the possibility of the compulsion taking over that they make efforts to prevent their brightest students drowning in a sea of output.
The second stage in the hacker's social downfall involves a disturbance of normal habits.
Meals are taken irregularly, sleep-cycles are disturbed and leisure activities are pushed aside to allow time for more interaction with the machine.
It is not difficult to get carried away with programming and even the casual programmer can easily lose track of time.
The intense involvement which can soon develop makes programming one of those rather rare activities in which time can cease to exist and the passage of hours goes by unnoticed.
Psychologists have called this phenomenon ‘flow’ and have studied some of the conditions under which it occurs.
There is no doubt that now is pleasurable.
Hackers recognise it and enjoy it.
And it helps to disrupt their lives.
The third stage of hackerhood is characterised by profound social withdrawal.
Several writers have suggested that those people who most readily succumb are often rather introverted and  socially inept individuals even before the compulsion takes over.
The computer acts as a substitute for human friends, perhaps, but the infatuation may also bring about the end of existing relationships.
In the final stages the hacker's personality undergoes a fundamental change.
He (or she, although hacking does seem to be a sex-related disorder) becomes de-socialised through lack of human contact.
The world is now seen through a system of concepts in which feedback loops and fast fouriers have taken over from friendship and fun.
We can easily imagine the effects of hacking on family life.
A number of hackers' wives have now joined other grass widows parted from their husbands by golf or similar obsessional activities.
In an article entitled ‘The men who fall for their computers’ Jane McLoughlin  examined this new phenomenon.
One hacker's wife remarked: ‘The whole thing started when he began to work late at the office, and I began to think that there was another woman.
When he came home he was distant and vague, and preoccupied, and in the end I accused him of having a mistress.’
Under such pressure the hacker broke down and confessed: ‘…he began to talk of the pleasure he got out of playing the weirdest experimental games with the computer…
I couldn't compete, not with a machine, for God's sake.’
This wife stood by her afflicted husband and even expressed fears about what might happen if the firm were to remove him from his electronic friend: ‘I know it sounds funny, but I'm afraid that losing that computer may break his heart.’
Jane McLoughlin also met an ex-hacker who, since his self-cure, had been able to look back with some pleasure at his early hacking day's: ‘I'd kick that machine of mine into life, sing a snatch of Yes.
sir ,that's my baby to get her going, and she did whatever I wanted.’
Hackers are not only obsessed with the programming but also often have a deep affection for the machine itself.
They explore one side of their personality and develop one aspect of their skills with a single-mindedness which has obvious disadvantages.
Some regard what they do simply as a form of legitimate adult play, while others take it far more seriously and see themselves as going beyond present human limitations, journeying into a new galaxy of knowledge in a way which they find at least as exciting as the exploration of deep space.
However, the dismal picture which some computer scientists have painted of hackerhood, it should be noted, applies only to extreme cases.
Any powerfully gripping activity will produce, its casualties, and many programmers find their relationship with the machine exciting and satisfying without being completely taken over by it.
They are the social drinkers in the picture, while the hackers are the alcoholics.
The existence of both species illustrates the fact that human-machine relations are by no means free of emotional implications,
Delays down under
THE BEST laid plans…our promise to bring copies of this organ to our readers in the Far East and Antipodes were genuine.
Honest.
We really thought we'd found a quicker way to get copies to our distant subscribers.
We wanted to avoid all the delays that creep in if we hack them by hi-speed Busby post to Dover, put them on board a ponderous  Sealink ferry and eventually consign them to the decidedly risky hands of some unknown foreign postman in the forlorn hope that they-might, with luck and a following wind, reach the Antipodes before the turn of the century.
We decided that it would be easier to send them by air to Singapore, placing them considerably closer to their intended final destination.
It hasn't worked out like that.
We've had various explanations, including the British Post Office telling us that Australia's strike record is as bad as Britain's and that there have been numerous disputes that have delayed the mail to that country.
But perhaps the most intriguing reason for the hold up comes from J. W. Carr in New South Wales.
— Australia post claims that the delay is not of its making,’ says reader Carr, ‘and hints darkly that every package from Singapore raises suspicions in Customs Dept, as a possible vehicle for drug-smuggling, so is shoved into the ‘hold for inspection’bay.’
We couldn't have anticipated that one could we?
Reaumur's road
Martin Sherwood celebrates the 300th  anniversary of a Great French polymath
DURING the second half of the 17th century, science began to be organised.
Part of the reason was a growing belief in the power of scientific thinking to improve trade and commerce.
The major landmark is, perhaps, the foundation of the Royal Society of London in 1660.
Initially, both this and its French counterpart, the Academie des Sciences, were concerned as much with what we could call technology as with science.
The Royal Society seems to have achieved little in this direction in its early years; in Paris, however, the academie fostered someone who worked  diligently at the applications of science.
In Rene Reaumur, the academie had a first-rate technologist, but a man who is now little remembered.
Frequently, the scientific understanding needed for the progress he wanted to make was not available to him and the work he began did not bear fruit until after his death.
Reaumur went to live in Paris at the beginning of the 18th century and his initial contact with the academie came through an interest in mathematics.
He very soon diversified, however, and his subsequent career included investigations in many areas.
One task he undertook was the preparation of a comprehensive account of current technology.
This project had been conceived by the Marquis de Colbert, one of Louis XIV's ministers, soon after the foundation of the academie in 1666, although it was not until 1713 that Reaumur began work on the project.
One area to which this drew Reaumur was iron and steel manufacture.
He conducted a lengthy series of experiments on the conversion of iron into steel, from which he concluded — contrary to conventional wisdom — that steel owed its properties not to its exceptional purity, but to the presence of impurities.
Reaumur was concerned also with trying to make cast iron less brittle.
At the time, iron castings were often unreliable if subjected to stress, as in a gun barrel for example.
Reaumur knew that steel is more brittle than pure iron and connected this with the impurities in it.
He postulated that the brittleness of cast iron resulted from its even greater degree of impurity.
He experimented with materials which, when heated with cast iron, might combine with some of these impurities.
Eventually, he found an ideal substance for improving cast iron's malleability.
Unfortunately, he failed to recognise that it was the same as red iron ore, an abundant and in expensive material, Instead, he thought it was scarce — and consequently expensive — being obtainable only from a particular treatment of iron itself.
Not until long after his death was this process commercialised.
Reaumur also worked extensively on ceramics, again because of the commercial potential.
Shortly before his birth, a porcelain industry had begun to develop in France.
Unlike Chinese porcelain, very popular in Europe at the time, the french porcelain was made from a previously fired glassy mixture, rather than from feldspar and kaolin.
Reaumur received samples of these materials from China but, despite an intensive search, was unable to identify their equivalents in France.
He did, however, manage to show that the structures of the two types of porcelain were different.
Building on his studies, later technologists were able to duplicate the Chinese method and to establish the true porcelain manufacture for which France became justly renowned.
Reaumur was also one of the great naturalists of his time.
Again, utility was not far from his mind.
One of his earliest discoveries in this field was how to make Tyrian purple — an indigo derivative — from certain shellfish, a secret which had been lost since Roman times.
He made numerous studies of insects, believing that this could lead to the production of useful materials and to ways of controlling insect pests.
In one investigation, he even tried to convert pollen into beeswax.
More fundamental were his experiments with hawks, in which he fed them meat contained in small cages.
From the condition of the meat when the cages were regurgitated, he inferred that digestion was a chemical rather than a mechanical process.
Perhaps Reaumur's most significant contribution to the biological sciences, however, was his observation of the regenerative power of certain crustaceans which had lost a limb.
This helped to deal a crippling blow to the preformationist theory, which argued that all parts of a living organism are already formed in miniature in the seed or egg from which it comes.
A corollary of preformationism was a belief in the immutability of species.
Its overthrow was a necessary precursor of, and possibly stimulus to, the theories Charles Darwin was developing a century later.
In the history of science, Reaumur is also remembered for his thermometer.
He tried to improve on the work of the Polish physicist Gabriel Fahrenheit, but did not succeed — largely, it seems, because of the difficulty people found in following his instructions on how to construct his thermometer.
Despite the best tries of metricationists, the name of Fahrenheit is still a household word; that of Reaumur is not.
 Worrying yourself sick
Bernard Dixon on the fun of being a hypochondriac
CORONARY THROMBOSIS, cholecystitis and brucellosis.
I've had all three during the past few months — these and various other unmentionable conditions several of them potentially fatal.
And every one has the same, underlying cause.
It is the sheer variety of its manifestations that makes hypochondria such an interesting complaint.
In my teens, I remember, the usual result (and when I say usual I mean about twice a week) was sudden, fulminating appendicitis.
Every attack was accompanied by the certain knowledge that within a couple of hours I'd be under the knife.
But the pathology failed to develop and the ambulance was never required.
Another recurrent crisis, during university years, was the cerebral accident — a subarachnoid haemorrhage unambiguous enough for me to sit down with pen and I paper and put my affairs in order.
In much more recent years chronic maladies have taken over from acute ones.
There's this feeling that your polymorphonuclear leucocytes have lost their grip, that the brain has gone, or that a slow virus has chosen its moment.
Not that I am unique in experiencing this sort of thing.
I've spotted it in lots of people and suspected it in most others.
And such observations bring out one of the most arresting features of hypochondria: its almost total independence from any real diseases from which the hypochondriac suffers.
Like most people, I have had a handful of serious troubles during my lifetime.
All have been duly diagnosed and dealt with — but all have been quite separate from my varied catalogue of imaginary disasters like adolescent appendicitis and last week's coronary.
I even knew a chap in hospital once who was more concerned about his totally symptomless brain tumour than about the lobar pneumonia from which he was cheerfully recovering.
Now what perplexes me about this universal condition (perhaps the most universal of all) is the scant attention it receives in — the literature’.
Look up such excellent works as J. Rachman and Clare Philips' Psychology and Medicine (Temple Smith) or Richard Totman's Social Causes of Illness (Souvenir) and you will find a total of 14 words between them on the subject.
Even that respected organ The Practitioner , in a recent special issue (1983, col 227, No 1375) devoted to psychiatry and matters of the mind, had just a single word concerning this most widespread, of all medical phenomena.
Psychosomatic medicine may be in vogue.
But the hypochondria which affects the lives of millions still remains to be taken seriously.
Could this be because medics themselves suffer so grievously from the complaint, that they do not wish to talk or write about it?
Perusing my library shelves recently, in a largely fruitless search for scholarly references with which to stiffen this article, I came across some evidence supporting that contention.
It is in David Mechanic's Medical Sociology (Collier Macmillan), one book which does treat hypochondria seriously.
There the dread chondria is equated quite explicitly with something that bothers medical undergraduates.
Ignoring the remainder of the world's population, Mechanic defines hypochondria as a disorder experienced at one time or another by some 70 per cent of apprentice doctors.
Moreover, he concludes, ‘medical students’ disease terminates readily and within a relatively short time’.
I don't believe this — except in the trivial sense that trainee medicos soon conquer anxieties such as waterworks phobia, caused by working on a ward full of ailing kidneys, bladders and prostrates.
Similarly, A-level zoologists quickly overcome the unease they develop over pork on learning about the tapeworm ‘s (Taenia solium)exotic lifestyle.
Real hypochondria encompasses a much wider range of symptomatology, is far more persistent, and is certainly not an occupational disease limited to would-be quacks.
Some real research, I suggest, is needed into a condition which, though frequently rib-tickling in retrospect, causes widespread anguish at the time.
Does it follow a  biorhythmic pattern?
Is it associated with remediable personality traits?
Can it be avoided or modified?
Is it amenable to psychotherapy or gene therapy?
Why are its effects realer than real?
Let us hope the Medical Research Council can rumble a few answers.
Meanwhile, I have just one tip for fellow sufferers.
It came originally from my father, who employed the technique with great relief on many occasions.
Next time you develop an ache, lump, pain, or tenderness in part of your body, see whether you can find the same thing on the other side .
My father learned a lot of anatomy this way, comparing one patella with the other, and fondling his soft tissues in anxious searches for symmetry.
Nine times out of ten, using this tactic, you discover that there's nothing to worry about.
If your right nostril, thumb, rib cage or knee feels the same as the left one, then you can relax, confident that the machine is OK.
The only tricky areas are, of course, anything amiss dead centre — or, of course , anything wrong with the brain.
And now for the poplar casket…
THE WORLD WILDLIFE FUND Switzerland this month secured the cooperation of the country's largest manufacturer of coffins (or as the Americans call them caskets) in a bid to preserve the tropical moist forests of the world.
Rudolf Egli AG, of Beromunster, has announced that it will switch from making coffins of rare West African abachi wood to locally grown poplar.
Half of Switzerland's coffins are made of abachi wood.
A spokesman for the National Association of Funeral Directors in London said that it would be impossible to obtain comparative figures for the UK.
‘People here like their coffins plain and simple and solid oak, if they can,’ she said.
But many coffins are made of imported woods.
The Glasgow Cooperative and Wholesale Society is one of the largest coffin makers in the UK.
Ninety per cent of its solid coffins are made of imported hardwoods, using, in approximately equal proportions, American oak, Brazilian mahogany and Ghana abachi.
But solid coffins represent less than 10 per cent of the Coop's business.
An additional factor is the increasing popularity or cremation.
Fully 65 per cent of all funerals are by cremation, and the crematorium will specify the type of wood for the coffin, depending on the type of furnace and chimney.
‘People think that you don't need wood for a cremation,— the spokesman told New’ Scientist , ‘but you do, because bones are very difficult to burn, as that chap in North London found out.
— WWF UK has no immediate plans to pursue the Swiss initiative with coffin makers here.
Acid rain erodes our credibility
Tam Dalyell believes we should raise the standards, not umbrellas
DECLARE WAR on acid rain!
If Britain were to make such a gesture we should be doing an international service.
And even over a period as long as 15 years we would be paying a lot less (£184 millions) than the £684 millions that will go next year to safeguard the Falkland Islands from the  Argentinians — a matter which many ecologists see as a fight between two bald men over the possession of a comb.
I write with some conviction on acid rain having recently attended a well organised meeting on the subject in the Upper House.
Credit for its success is due to Lord Craigton, chairman of the All-Party Conservation Committee that meets about once a month in the House of Lords.
Craigton invited Dr M. H. Unsworth of the Institute of Terrestrial Ecology (ITE), at the Bush Estate, Penicuik, Midlothian, and Dr Gwynneth Howells of the CEGB, to speak on ‘acid inputs to the natural environment’.
Plenty of people turned up, including Mark Lennox Boyd, one of the influential and able new generation of Conservatives, and MP for ITE Merlewood, the Father of the House, John Parker, who has been campaigning on the environment and forestry since 1935, and a Green troika of David Clark, Opposition spokesman on environment, Peter Hardy, author of a book on badgers, and chairman of the Council of Europe Agricultural Committee, and me.
How many, two years ago, would have supposed that ‘acid rain’ would become a topic of importance?
You would have been forgiven for a knowing smile then, but now acid rain is no laughing matter.
What those little droplets have absorbed after the burning of fossil fuels is of grave concern, not only to the anglers of Scandinavia, but to most Europeans.
The potential sources of acid rain are not only in Britain and the Ruhr, but also in Czechoslovakia and
Poland.
The monster does not recognise national boundaries, nor even the divisions between East and West.
Twenty per cent of all lakes in Sweden are highly acidic.
Six per cent of all lakes in wild Ontario are affected and downwind from Sudbury Smelter 19 lakes have no fish.
Nova Scotia has lost much of its salmon spawning.
Half of the more acid lakes in southern Norway have no fish at all.
We need to be monitoring for more data.
We do not know enough about how often acidic reservoirs occur.
Of course, vegetation and the nature of the soil can make a difference, For example , if acid rain falls on a spruce forest, the rain can become even more acid.
Moreover, acid rain can alter the ecology by dissolving aluminium in the soil.
Acidifying droplets can reduce the growth of trees and crops, at concentrations far lower, than had been suspected up to now.
Circumstantial evidence suggests that many trees have died in areas of Germany where acid rain is most prevalent.
Rain falling through canopies of spruce forests becomes more acid probably because dry deposits on leaves are washed off and because of chemical reaction with the leaves.
It appears that deciduous trees do not acidify in this way.
Whereas agricultural soils are usually maintained close to neutral by adding lime the problem is altogether more serious with forest and moorland soils: extra acid inputs may release aluminium in various chemical forms to the ground water.
The modifications of the quality of acid rain as it passes through soils depends on the soil properties, organic matter, microbial activity and underlying rock.
Most of the rain which reaches rivers and lakes has first passed over vegetation and through soils, so the land use and soil type can influence the acidity of water courses.
At present.
I am told, the subject is not well understood.
Like study of the forest, it may take a generation to quantify the effect on fish stock.
A direct causal relationship may not be easy to establish.
Changes in land use might have to be taken into account.
The relationship between min acidity and surface water acidity will vary from area to area.
Conditions will determine the different degrees of neutralisation: even lakes next to each other can have different acidities.
Ever since the 1920s, the Norwegians have used lime, in some lakes, to produce better fish stocks.
Again, conditions in which calcium is leached from the soil may be beneficial for brown trout.
Persistent acid conditions may inhibit the reproduction of fish.
Deaths of trout and salmon have been connected with acid input to streams in spring and autumn.
In spring melting snow releases pollutants; in autumn rain probably removes the acid accumulated during the summer.
For the most part, the damage is done by soluble aluminium released from soil by acid water.
Professor Fred Last and his colleagues in Edinburgh have also observed effects on other aquatic animal and plant life.
What to do?
Britain has signed the European Convention on the Environment, promising our best efforts to limit and reduce emissions, and to exchange information in collaborative work.
But, in practice, there should be a long term programme of washing coal, extracting the sulphur from carbon, extracting flue gases, and building fluidised beds.
The technology is available, and should certainly be used in any new coal-burning power station.
The acute question is — do we try to introduce such ideas into existing power stations?
Dr Howells and Dr Unsworth said when asked the inevitable MPs' question about the price, that for £500 million spent between now and the end of the century we could reduce toxic emissions, by half, at the cost of increasing the price of electricity by 15 per cent.
One of the attractions of this work is that it would employ a lot of labour.
If we say we cannot afford it, the reply is that we pay out more and more millions of pounds in unemployment benefit.
Science's new friend in the White House
Dan Greenberg reports some scientific glee from Washington
UNDER the improbable aegis of Ronald Reagan, who has never found occasion to say much good or bad about science during his long public career, it may well be that the American scientific community is headed for an economic boom.
The signs are in his new budget, which while characterised as ‘freezing’ domestic spending, actually pumps huge new sums into basic research (New Scientist, 3 February, p 290).
The new money — most cherished of all currency in scientific finance — amounts to some $600 million, thus bringing the grand total to $6600 million.
To this must be appended the usual qualification of ‘Congress willing,’ but, if anything, the current US Congress exceeds Reagan in pro-science fervour.
The one area of basic science that the president passed over in his new budget was biomedical research, for which he recommended a mere token increase of $71 million atop its current annual fund of approximately $4000 million.
Rather than being an act of neglect, this seeming parsimony simply recognise the historical fact of Congress routinely adding money to whatever the president recommends for health research.
What is the origin of this presidential plunge into spending on science?
And how can we account for its appearance now when less than two years ago, Reagan and his government-shrinking colleagues attempted an across-the-board 12-per cent blood-letting on the research and development budget they had inherited from Jimmy Carter?
Part of the answer is that there is a lot of fiscal juggling in the R&D accounts, with a great deal of large-scale engineering and demonstration work of the federal government — especially on matters related to energy — having been scuttled by the Reagan administration as inappropriate for the government.
From the ‘savings,’ as they are referred to, funds have been redeployed to make up for a decade in which growth of support for basic scientific research was, at best, sluggish.
But that still leaves the question why, which becomes all the more nagging in the context of Reagan's ruthless clampdown on other domestic programs.
What does he see in science?
Though neither Reagan nor any of his aides has formulated it in so many words, I think that the failure of standard economic remedies has created a kind of desperation, and, like a jilted lover, the administration is ready to take up with any attractive candidate.
In fact, his state of the union message contained so many references to the wondrous economic powers of ‘high technology,’ that one wondered whether the president was about to promise a ‘white hot technological revolution’.
In any event, that strange sound that has lately been emanating from the American scientific community is a kind of purring.
The president cares, and money is on the way.
In comments following release of the budget, the president of the National Academy of Sciences, Frank Press, who served as presidential science adviser under Jimmy Carter, hailed the budget as ‘very innovative’ and ‘highly  laudable ’.
No reference was made by Press, or, so far at least, by any of our other statesmen of science, to the fact the new Reagan budget consigns 70 per cent of all federal R&D funds to national security.
(The balance between military and civilian shares of federal R&D was 50–50 is recently as four years ago.)
Nor was anything said about the fact that federal support of civilian R&D has been at a ground-losing $14 000 million for the past three years — down by $3000 million since Reagan took office.
It is an odd affinity that is forming between Reagan and the scientific community.
But, nourished by Reagan's money, there it is.
Journey into eternity
FIVE tonnes of silica gel, enough to bury a small car, is on its way from Warrington to Giza in Egypt where it will be used to keep the moisture in the world's oldest surviving ship, the Royal Ship of King Cheops, second king of the 4th dynasty (c2613–2494BC).
Normally the chemical — best known as the little fabric bags found in boxes containing anything important — is used to take moisture out of the air.
The Egyptians want to use the opposite effect: silica gel gives water vapour when gently warmed.
King Cheops's ship lay for 4600 years in a dry rock chamber kept it a stable temperature and humidity by massive limestone blocks above it.
the Egyptians moved the 48 m ship to a purpose-built museum alongside the King's pyramid and put her on display last year.
As the temperature rises in the museum under the hot sun moisture evaporates from the ship's wooden hull.
As it does so the timbers expand.
When the temperature drops at night the water vapour is not reabsorbed by the ship.
The Egyptians will expose the silica gel, which has been donated by Crosfield Chemicals, to humidity before placing it around the ship.
The moisture in the gel will be given off during the day and reabsorbed at night.
In this way the timbers will be protected from repeated desiccation and expansion, potentially a grave danger to such ancient wood.
Silical gel marketed under the brand name ‘Sorbsic’ by Crosfield is pure, synthetic silicon dioxide.
It gains its water-absorbing qualities by virtue of multi faceted internal structure: surface area of one gram is over 800 square metres.
It is also used to produce dried flowers, fitting perhaps, now that it is preserving the flower of the ancient Egyptian fleet.
REVIEW
Does science need a vice squad?
Betrayers of the truth by W. Broad and N. Wade,Simon & Schuster, pp 247, $14.95 
Theodore Roszak
FRAUD, according to William Broad and Nicholas Wade, ‘offers another route to understanding science…
By studying science through its pathology rather than through some preconceived criterion, it is easier to see the process as it is.’
Betrayers of the Truth might have been little more than a scientific rogues' gallery and, as such, an entertaining if disillusioning read.
But the authors have tried to make it more than that.
They have sought to use fraud as an insight into the sociology and methodology of science, an approach that might connect with the more philosophical investigations of Robert Merton, Michael Polanyi, John Ziman and Thomas Kuhn.
I'm not sure they succeed in this more ambitious intention, but it's certainly a commendable effort by the authors.
The examples of scientific ‘betrayal’ which Broad and Wade assemble for inspection range from routine opportunism to bare-faced mendacity.
The study reaches back to find some classical historical instances of cooking and doctoring, fudging and fiddling from Hipparchus to Gregor Mendel.
For the modern period, we have detailed reviews of the most notorious cases: the Piltdown hoax, Paul Kammerer's midwife toad, T. D. Lysenko's ideological biology, Walter Levy's parapsychological fabrications, Elias Alsabti's mass plagiarism (60 papers in all!),
Mark Spector's cancer research falsifications.
The crowning disgrace is, of course, Cyril Burt's scandalous bamboozling of professional psychology with his fabrication of data on IQ and social class that influenced the post-war years.
From such cases, Broad and Wade seek to prove that fraud is a chronic vice of science that radically (perhaps irremediably) compromises its objective methodology.
I hardly approached the book unwilling to hear ill spoken of science; but I came away struck by the rapidity with which most cases of scientific fraud have been exposed and penalised.
True, there are the remarkable exceptions: Burt's quarter century escapade in wholesale duplicity is a real shocker — though it may prove nothing so much as that psychology, or at least intelligence testing, has no claim to scientific respectability.
And Broad and Wade do make clear that the frauds detected in science are opportunism, not some formal process of falsification — an important corrective to the public image of science as a rigorously self-verifying mechanism.
Yet in most of the cases they present, the hoaxer was found out within a few years and promptly punished with significant disgrace.
In comparison to the way in which fraud, obfuscation and inanity have been able to hold out in other fields — from politics and religion to scholarship and law — it is an impressive record.
The reason for this relative success at self-policing is not hard to find.
In science, especially the hard sciences, the culprits are normally up against a robust professional consensus that defines excellence, originality, and the nature of evidence.
They may get away with a trick or two, but only for as long as nobody is watching too closely.
To be sure, from time to time the consensus may weaken in one science or another (— the paradigm shifts’, as we have learned to say) and then, for a period, matters grow more complicated.
Still, few other fields are gifted with even this much purchase upon the elusive ideal of inter-personal truth.
Some areas of culture (and they include the most important) simply have no consensual criterion for telling honest effort from trumped-up, self-serving folly.
Try arguing with one of Andy Warhol's fans, or Aleister Crowley's admirers, or the swami-of-the-month's disciples.
It is like trying to get a firm grip on a plateful of pudding.
Scientists may be more slipshod than they care to admit about replication and falsification; Broad and Wade do a good job of proving that.
But, for as long as any paradigm holds, they do have some court of last resort.
Unhappily, the great questions of moral truth, goodness, and beauty no longer enjoy, even in principle, so accessible a means of validation.
What Broad and Wade do is an excellent job of documenting the countless ways in which careerism has corrupted every field of science.
Science, they argue, is ‘a human process governed by the ordinary human passions of ambition, pride, and greed’.
In every example they offer, it is competitive egoism that has subverted the ideal of objectivity — from instances of brazen cheating to the simple laxity with which papers are refereed, grants awarded, and experiments checked — or left unchecked.
There is no automatic, built-in guarantee of quality control.
As Broad and Wade point out, the rhetoric and  mythos of science cloud these universal frailties and create the comforting image of linear progression toward truth.
Their book reminds us that everything human is all too human.
Whatever nature may objectively be, it is reflected in the flawed mirror of the mind.
Particles of belief
science and the renewal of belief by Russell Stannard,SCM Press, pp 213, £2. 95 
Eric Jenkins
NEW SCIENTIST readers will include some who, like Russell Stannard of the Open University, combine an orthodox Christian faith with the career of a research scientist, in his case that of high energy physics.
Such ‘Christian scientists’ are open to challenge — can they reconcile their faith and their science intellectually?
Or are these two apparently divergent activities kept in quite separate mental compartments?
There will be other readers who may look wistfully at the attractions of religious faith but are restrained by the folklore and fashions of what they suppose to be a current scientific philosophy.
For both categories of readers, as for anyone interested in questions of value, ethics and social responsibility in science, here is a bold book by a scientist who has equipped himself theologically and philosophically.
Science and the Renewal of Belief does not duck the obvious but difficult questions — as an Anglican lay minister, Professor Stannard must often meet them at grass roots.
Biblical interpretation, Adam and Eve, original sin, evolution, miracles, evil, the nature of God, free will, prayer, Galileo and Charles Darwin — here are all these issues in 22 short and attractively written chapters, each one a readable  essay .
The sequence follows first the themes of a theological and scientific view of creation and of the emergence of the human spirit, leading to an examination of the concept of the evidence for the resurrection of Jesus, the ‘touchstone of Christian belief’.
The methodology of scientific research, enlivened by personal experiences, is presented as an unusual starting point for the evangelical and experimental approach to Christian faith —‘an experiment with prayer’.
The second half of the book takes seriously some of the philosophical obstacles to belief.
The failure of the classical arguments for the existence of God, the vogue for scientific reductionism, the Galileo scandal, the problem of evil are all discussed.
Stannard's treatment is not entirely new, rather he is usefully conveying elements of some recent trends in Christian theology which take science very seriously while preserving the realities of faith (one thinks of the writings of Tom Torrance, Stanley Jaki, Arthur Peacocke, the meetings of the UK science and Faith Forum, and of the World Council of Churches's programme on faith and science).
These approaches — startling both to old guard materialists and to some conservative believers — deserve the popularisation that is offered in this book with the accreditation of a working scientist.
Overall, the most interesting examples of Stannard's treatment come out of his own field of physics.
He uses relativity to throw light on time and eternity, and indeterminacy to comment on free will.
This interaction of science and theology is not one-sided.
I read with fascination his speculation that some writings of the 19th century Danish theologian, soren Kierkegaard, about truth and paradox may have influenced the  physicist Niels Bohr 80 years later in his thoughts about the wave particle dualism!
Rocking the energy applecart
Brittle power by Amory and L. Hunter Lovins,Brick House, PP 486, $17.95 
Walt Patterson
AMORY LOVINS upsets applecarts.
That has made him, over the years, distinctly uncomfortable company — at least to those with a large stake in applecarts.
In 1970 he helped to found the British wing of Friends of the Earth; with them he was instrumental in giving a hefty nudge to the rickety barrow of the British nuclear establishment.
In November 1973 Friends of the Earth published his book World Energy Strategies — written before the October 1973 oil shock — which thereafter appeared in many other countries and languages, and became one of the seminal documents of the ‘alternative energy’ literature.
Lovins returned to his native US in the mid-1970's, and there published, in the October 1976 issue of Foreign Affairs ‘Energy strategy: The road not taken’.
Energy applecarts all over the world rocked on their axles.
Expanded to book-length, as Soft Energy Paths , it gave a new catch phrase to the language and, made Lovins a household word in the US — albeit to American nuclear interests in particular, something of a four-letter word.
Lovins's adversaries were both numerous and powerful; and they drew some consolation from his tendency to write prose of baroque opacity, sometimes more than 50 per cent footnotes, and accessible only to the dogged.
Then, in the late 1970s, Lovins met and married another activist named Hunter Sheldon.
During a flying visit to London a couple of years ago, Lovins was heard to declare that his wife's next project was ‘to translate Soft Energy Paths into English’.
Since that time the Lovins have worked in double harness, to impressive effect.
Their output has been prodigious — and most of it has been perfectly intelligible, even to those who would rather it were not.
Brittle Power is very much a continuation of the Lovins canon: the concerted challenge to most of the percepts apparently underlying current official thinking about energy — this time overturning the most ponderous applecart of all.
Official energy pronouncements, whatever their other shortcomings, have hitherto always fallen back on ‘national security’ as their ultimate justification.
The Lovins turn this argument unceremoniously on its head.
They assert that, far from ensuring national security, official planning in the US is making the energy system progressively more vulnerable — to everything from thunderstorms to terrorists.
Part one of the book considers ‘What can go wrong’ and ‘How systems fail’, noting that the energy system is especially at risk.
Among the reasons discussed are the presence of dangerous materials such as explosives and toxins; the centralisation of supplies, long-haul distances and limits on substitution of one supply for another; the inflexibility of energy delivery systems; and, in planning, the high capital intensity and long lead times.
Part two develops this theme, identifying ‘disasters waiting to happen’ associated with liquified natural gas, oil and gas, power stations and grids, and nuclear power.
The pages are studded with striking examples of the vulnerabilities which have caught society off guard time and time again — and which seem likely to keep on doing so ever more frequently, with ever more devastating consequences.
The notorious Lovins footnotes are here an essential accompaniment, giving an astonishing variety of primary sources.
Part three redefines ‘national energy security from the ground up, focusing on the criterion of ‘resilience’.
No brief summary can possibly do justice to the depth of the analysis; but it has already been tried out on some uncommonly hard-nosed customers, and elicited their approbation.
The foreword is written jointly by a former chairman of the US Joint Chiefs of Staff and a former Under secretary of the Navy.
This book is, like the earlier writings under the Lovins byline, uncompromising and unsettling.
Some of Lovins's old colleagues will be frankly unhappy to see him laying such stress on ‘the nation’ as a subgroup of humanity.
On the other hand, if ‘the nation’— any nation — were not so vulnerable, its professional defenders could not skim off so much of its wealth as protection money.
Brittle Power may be written for American readers; but it deserves careful perusal everywhere.
Not everyone would realise instantly that the best way to reduce tension in the Middle East might be to insulate American lofts.
There are good, and bad, trains
Jane's world railways,Jane's pp 654, £50 
Mick Hamer
JANE'S World Railway's 1982 is a fascinating, amazing book — or at least, I find it so.
It has much the same sort of fascination as a dictionary, or a encyclopedia.
You look up one entry and are immediately seduced by adjacent items, just out of curiosity.
For instance Jane's will tell you that Via Rail, the Canadian passenger railway, runs 12 intercity services every day with LRC trains.
The LRC trains (LRC stands for light, rapid and comfortable) have tilting bodies, which allow them to take bends faster, just like Britain's ill-fated advanced passenger trains.
The LRCs have a maximum speed of 200 km/h, but are limited to 155 km/h because of the need to timetable them between slower freight trains.
Jane's also reveals that Spain has tilting trains as well, the Talgo Pendulares, which have a maximum speed of 180 km/h and ply between Paris and Madrid.
However,Jane's is rather more coy about tilting train failures .
It publishes just a picture of the Italian ‘Pendolino’ referring to it as a ‘prototype’in the caption.
(Italian Railways found that a high proportion of passengers became travel sick on the train.)
And it refers to Britain's own advanced passenger train as carrying ‘its first fare-paying passengers in a record-breaking run from London to Glasgow before being withdrawn from service for further trials’.
From the modern to the antique, or almost; China is still building steam locomotives, of the class Qian Jin.
In all, China has over 9000 steam locomotives.
For those who want a complete directory' not only of the world's railways but also of manufacturers of railway equipment of every kind, from coaches to couplings, then Jane's is your book — provided you have £50 to spare, which is £7 less than a second class return from London to Newcastle.
Mystic star and psychohistorian reborn
Foundation's edge by Isaac Asimov 2010: Odyssey two by Arthur Clarke Granada, pp 367 and 217. £7.95 each 
David Langford
SCIENCE FICTION breeds more science fiction and success breeds sequels: these two have been a long time coming Forty years since the first Foundation tale, 14 since 001: A Space Odyssey —can Isaac Asimov and Arthur C. Clarke repeat their successes?
Each book effectively recreates the tone of its predecessor(s); Asimov's being remarkable as a novel of the 1940s written in the 1980s.
Each slips new readers the story so far, Clarke in lucid flashback or reflection, Asimov with surprising clumsiness.
Each faces the problem of adding to an existing work once thought complete.
Asimov's problem is greater, certain implications of his original trilogy being slightly distasteful.
Beginning with the fall of a Galactic Empire, paralleling the Roman one, the books yearn for an enlightened Second Empire.
‘Psychohistorian’ Hari Seldon predicts the path to glory and establishes his Thousand Year Plan: a Foundation of scientists to develop imperial muscle, a hidden Second foundation of devious mind-manipulators to safeguard the plan and eventually to step in as destined rulers.
The objective sounds rather like fascism, and liberal Dr Asimov has had second thoughts.
So a new factor must be introduced.
Five hundred years on, the Seldon plan is working too well to be true: the First Foundation deduces (again) the existence of the second, the second that of…a third?
A suitable deus ex machina , anyway.
In the ensuing interstellar search — thuddingly reminiscent of Second Foundation — the characters run true to Asimovian form, sitting in boardrooms or (indistinguishably) spaceship cabins to discuss the big situation out there.
Rarely does anybody go ‘out there’ to look.
After some 200000 words, there's a confrontation as various parties struggle over the fate of the galaxy; despite mental strife, group minds and energy screens this still consists of people sitting down to discuss the big situation.
Seldon's plan gets the boot and cosmic — if not terrifically original — concepts are bandied all in the manner of Greek plays where Messengers arrive to report an offstage battle.
The narrative style, in keeping with this, is reasonable, rational and a trifle arid.
The long, Slow build-up is distinctly portentous, and no ultimate revelation could quite deliver the promised goods.
Without actually wrecking the trilogy,Foundation's Edge is vaguely anticlimactic. 010: Odyssey Two is more colourful.
Clarke's knowledge seeking technophilic characters are little better-drawn than Asimov's, but you won't catch them sitting in windowless cabins.
Constantly they gaze Out There, and Clarke's descriptions of the view are evocative as ever — Saganesque, one might say, except that Clarke was at it long before Sagan. 010 follows logically enough from 001 , book and film.
A Russo-American expedition heads for Jupiter and the abandoned spaceship Discovery, the murderous but deactivated HAL computer (not HAL's fault he turned nasty, he was driven mad by security regulations), and the lurking black monolith which sent astronaut Bowman through that lengthy light-show and metamorphosis into mystic star Child.
Onward: a race with a Chinese super-spacecraft, primitive life on Europa, salvage of the Discovery and HAL, Bowman's disembodied return, many a gaudy travelogue, destruction/creation on a planetary scale, and home truths about the relative cosmic worth of ourselves and slimy things on Europa.
Even though it finishes almost exactly where 001 did,010 contains good stuff.
‘It's the best thing I've done,’ he says of 010 , as he has of other books.
No, but it's better than Foundation's Edge .
The problem of Clarke as visionary and mystic is his growing temptation to explain .
That enigmatic black monolith dwindles to an all-too-reasonable von Neumann machine, its godlike makers to folk only slightly upmarket from ourselves.
Bowman as transfigured star Child was awesome; Bowman as poltergeist isn't.
Clarke explains his mysteries right into the ground, even while making his astronomical facts blossom.
(Sometimes they blossom purple, but they do blossom.)
Besides being a smoother narrator, Clarke scores over Asimov by stirring in more new elements, reworking fewer old ones.
Extrapolated Voyager data easily outshine Asimov's out-of place tachyons and token black hole.
But Clarke's habit of injecting tension via arbitrary deadlines (’ You must leave within 15 days’)is even less satisfactory than Edge's endless build-up to promised Revelations.
Lamarck: a French apercu
Lamarck the mythical precursor by Madeleine Barthelemy-Madaule,MIT, pp 174, £12.25 
Peter Medawar
THE AUTHOR disclaims any intention of giving an account of Lamarck's life and work, her purpose being to examine ‘several key Lamarckian concepts in order to shed light on the relation between ideology and science’.
Lamarck is presented to us as a man misunderstood, misrepresented, undeservedly neglected and as the subject of calumnies that made him appear as ‘the enemy of religion and teleology, even as a mechanistic materialist’.
It is hardly surprising that Jean-Baptiste Pierre-Antoine de Monet,le chevalier de Lamarck remains a rather shadowy figure when we learn from Alphaeus Packard, his would-be biographer from Brown University, that he ‘left neither tomb, nor letters, nor manuscripts’.
The subversive implications of Lamarck's thought — in particular the implication that a person's character, destiny and deserts are not wholly determined by his breeding — aroused some disfavour: Napoleon did not like Lamarck.
He preferred men whose thoughts threatened ‘neither the Bible nor the ruling classes’.
The most valuable part of this book, and that which makes it worth reading is the discussion of the life of Lamarck and of Lamarckism considered as an important episode in cultural history.
The author does well to illustrate by quotation from the Philosophie Zoologique Lamarck's own conception of Lamarckism — and it is interesting that Lamarck's first and second laws are by no means incompatible with Darwinism.
It is well known, indeed, that Charles Darwin accepted these Lamarckian notions, but what Lamarckism stands for today is the notion that adaptive changes that occur within an animal's own lifetime somehow are imprinted upon the genome and thus become part of its heritage.
There is no hard evidence for this opinion — no phenomena have been described that are not equally well explained by the action of selection.
August Weismann was utterly opposed to Lamarckism and Weismann's opinions so far prevailed that A. D. Darbishire in his authoritative Breeding and the Mendelian Discovery (London, 1911) put the  matter thus.
‘The doctrine preached by Weismann was that to start with a body and enquire how its characters got into the germ was to view the sequence from the wrong end: the proper starting point is the germ.
The real question was…
‘How are the characters of an organism represented in the germ that produces it?’
Or, as Samuel Burler has it, the proper statement of relations between  successive generations is to say that a hen is merely an egg's way of making another egg’
Our author, entirely uninfluenced by the dismissive judgements of her distinguished compatriots Jacques Monod and Francois Jacob, hankers after evidence that lends colour to the possibility in principle of an imprinting of somatic characteristics upon the genome, believing in particular that the comparatively recent discovery of the possibility of mapping RNA upon DNA (’ reverse transcription’) entitles her to think in terms of‘reverse translation’— that is a mapping of amino acid into nucleotide sequences.
However, I do not know any other human being who believes this to be possible in principle.
I must regretfully report that this part of Madeleine Barthelemy-Madaule's book is very inexpert and amateurish — a judgement to my mind confirmed by her citing Professor H. Graham Cannon as an authority on the subject.
I wonder if Lamarckism will ever lose its appeal for laymen.
It seems so right ; it seems only fair that the consequences of an organism's adaptations and own endeavours become part of the heritage of its young.
A young Australian colleague of mine, with a Canadian collaborator, published (Somatic Selection and Adaptive Evolution , Chicago UP) some wayout views on inheritance of acquired immunological tolerance which would have been immensely important if they had been true.
With the agreement of my closest colleagues and the director of the MRC's Clinical Research Centre, Dr C. C. Booth, I provided Dr Ted Steele with an environment in which he could complete his experiments in the friendly but critical atmosphere provided by immunologists who were trying to repeat his results themselves.
In the outcome there was, in our judgement, nothing at all in Steele's idea.
I believe that like W. Dougall's work and M. F. Guyer's and S. A. Smith's it will slowly be forgotten.
But while it was still a live issue, it was amusing to see how ready people were to accept Steele's defence that it was through the machination of such a crusted establishment figure as Avrion Mitchison that Steele had been invited to repeat his work in a scientific environment for the purpose of discrediting it — a defence that compounds bad science together with bad scientific journalism.
But these considerations, which are no fault of the present author's, should not be allowed to diminish pleasure in and admiration for the parts of her book under review that have to do with the history of ideas.
Robots with young masters
AS A young child Seymour Papert was fascinated by pulleys.
So when his teacher later elaborated terms such as‘ratio’, he understood immediately what they meant — not as mathematical abstractions but as elements of the real world.
Today Papert is a professor of maths at MIT and those early experiences, extended during his work with Jean Piaget, have convinced him that the way to true understanding is through exploratory interaction with tangible things.
Talking Turtle (BBC2, 14 February) was Horizon's thoroughly stimulating presentation of Papert's work — in particular his invention of LOGO, the first high-level computer language specifically designed for education, and of small robot turtles, programmed by LOGO which encourage the development of mathematical skills.
‘Papert asks why half the population are maths phobics, afraid of numbers, and woolly headed about abstract concepts,’ the narrator announced Any suspicion that this was the preface to yet another attempt to instil numeracy via some twist of new math, quickly disappeared.
For the guts of Papert's approach is to make geometry and other once-dusty disciplines concrete.
Turtles, programmed by youngsters to move around the floor and describe shapes with pens on their under-bellies, are the means to that end.
Here is a genuinely new route to learning.
The kids were fascinated, absorbed, extended, entertained.
For those of us who fret about ways in which modern technology distances us from understanding this programme was a revelation.
Here one way, in a generation, to conquer flaws that have so impoverished education.
Professor Papert deserves high marks for missionary zeal.
His ideas are being applied in settings as diverse as a rich Dallas school (one computer for every five pupils) and an institution for the severely handicapped (who use their turtles to thereby explore space in a way otherwise denied them).
He has even taken his gear to Senegal.
And here a note of caution.
Does Papert really believe that, without radical political steps, robot turtles can bring rich rewards in dealing with technologically advanced nations?
Perhaps it was the clash of Third World beach and Dallas skyscraper which triggered my uncharitable scepticism about his extraordinary Utopianism.
A robot of a different kind is on hand every Wednesday teatime on Channel 4.
Konrad is the star of Start Here, a charming and deceptively lightweight programme of ‘scientific adventures for children of all ages’.
An inordinately well-planned effort, it packs a considerable amount of information into its half hour.
Last week's edition on ‘jumping molecules’(16 February) majored on changes of state, and strung together numerous familiar experiments and many less common ones.
Konrad showed his young helpers how to make a simple thermometer, illustrate the Davy lamp principle with a kitchen sieve; and set a warm, upturned wine glass gliding across a smooth surface like a miniature hovercraft.
But if was the sequence of images and ideas that was most entrancing.
Heat made visible by a heat camera led to an explanation of its role in turning solids into liquids, and liquids into gases.
Thence to ways of measuring heat, and a neat series of demonstrations of metal expansion, heat conduction and convection, and their practical effects.
The subject headings for Konrad's show would probably look little different from those of a corresponding school syllabus.
But here they are given real life, with quiet style.
And there is no gratuitous information to get in the way.
Such painless instruction must be the product of much planning and work.
LETTERS
Cash for drugs
The UK chemical industry is one of the most successful parts of the economy producing around 10 per cent of the net manufacturing output and placing Britain among the top four chemical exporting nations.
Despite this marked success, or because of it, it is time that serious consideration is given to the industry, particularly the pharmaceutical and agricultural chemical sections.
It is difficult to evaluate the worth of, or motives behind, the production, marketing and distribution of chemicals used for medication, food preservation or pest control.
The companies involved are obviously in business to make a profit.
Unfortunately, as history has shown, some of the companies are guilty of misconduct in the pursuit of such profit.
The level of undiscovered malpractice is a matter for conjecture although such evidence is continually coming to light, as illustrated in the manner in which leading drug/pesticide/herbicide companies callously exploit the Third World.
The US government has recently produced legislation providing up to $25 million in tax benefits for companies which produce the so called orphan drugs (compounds that are uneconomical to produce).
The total number of people who will benefit from such drugs is unknown although the figure for those who would receive treatment from currently recognised orphan drugs is in the region of 200000.
This evidence alone poses a serious question of ethics with regard to the pharmaceutical industry.
The major British companies have all suffered considerable loses in the past few years with the cancellation of Proxicromil (Fisons), the halting of research on Tiotidine (ICI) and questions surrounding other drugs such as Ranitidine (Glaxo).
The research and development costs of these drugs are said to be close to £10-£15 million.
It would therefore seem an opportune moment for the government to impose stricter regulation and policing of the pharmaceutical/pesticide/herbicide branches of the chemical industry, including a more severe form of export control in order to protect the Third World.
It would also be an appropriate time to institute similar legislation to that of the US government in order to keep company profits stable, thereby maintaining research levels, and at the same time ensure that people may benefit from drugs that would otherwise not be available because they were not profitable to produce.
Andrew J. Crump
 Tring 
Fit to work
May I, as someone who has recently come off the dole, comment on Donald Gould's article (Forum, 20 January, p 180).
I agree that most of us need work — but I would point out that it is partly because when you're unemployed and dependent on the state for support, you don't have enough money to use your leisure time in the way you might want to.
Furthermore, in order to organise yourself for leisure, you need to be reasonably sure, and to accept the fact that you will be unemployed long enough to make organising something worthwhile.
(An example is starting daytime adult education classes, or getting involved in voluntary work.)
At present, if you do the latter, you also run the risk of making yourself unavailable for paid work and therefore ineligible for welfare benefits.
Eventually politicians and the general public will have to accept that there will never be full employment again, and will have to provide a living for those unlikely ever to get jobs.
Until that happy day, the only way to achieve an enjoyable and comfortable life is to work for it.
 Rosemary Sharples Manchester 
Donald Gould spoke for many of us I imagine, when he characterised the  honours of the extended Christmas break as a microcosm of a workless society, a foretaste of a robotised world (Forum, 20 January, p 180).
It is surprising that so few people have suggested possible reforms.
The first might be to move away from our present weekly cycle of five ‘working days’ and two ‘leisure days.’
I put it in inverted commas, because many of us just do different kinds of non-waged work at the weekends, or work at providing leisure facilities.
There are a number of reasons for breaking the existing cycle, and replacing it with a system in which people would work for so many hours a month, not  necessarily as many as at present.
Offices, shops, factories, would be open all the time.
The fist reason is that our society is composed of a variety of religious groups, of whom only 20 per cent are  practising Christians.
The second is that many processes simply cannot be shut down for the weekends.
Power stations, oil refineries, dairy farms, newspapers, hospitals, simply have to go on at the weekend, and often through nights as well as days.
Shift workers would enjoy far more normal social lives if their leisure was not superimposed on a seven day cycle of work and leisure, which they cannot share.
Our capital resources, both leisure facilities and industrial plant, would be more rationally used if we abolished the weekend.
An additional benefit would be that more people could find part-time work, and adjust their working hours to their family commitments, or to the demands of part-time study.
If our society began to move towards more flexible cycles, in which different communities and groups would adopt different patterns, we would create more employment, as employers would have to cover a shifting pattern of working activity.
 Christopher Roper Belton, Leicestershire 
Good Ideas
Some years ago you published articles and follow-up correspondence on the problems of the individual inventor.
I am in the process of organising a conference which touches on this problem, and is concerned with getting the different sections of the innovative and business communities to talk to each other and try to understand each other 's point of view.
I would like to ask your readers if they would write to me concerning their experiences in trying to get an idea developed to the production stage, all of which will be treated in the strictest confidence.
I am interested in success stories as well as complaints about maltreatment, and would be glad to hear the point of view of anyone on the side of the investor.
The information will be of great help in preparing my remarks to the conference which will take place in Oxford in April.
 Michael Harris Irex.
 Snow House 03 Southwark Street.
 London 
Not alone
I refer to  Professor Frank Tipler's arguments (’ Are we alone in our galaxy?’vol 96, p 33) against the possibility of existence of extraterrestrial intelligent being.
(His comments are in quotation mark).
First, ‘It is highly improbable that single-celled organisms (on another planet) could ever develop into complex intelligent beings.’
Nonetheless, here we are; if it can happen on one planet with humans, it could happen on others with non-human species.
We are proof that the  almost-impossible can occur.
In addition, and despite the astronomical odds against it, there are already non-human species which are capable of learning and problem solving; birds, dolphins and dogs to name a few.
Citing mathematical probabilities clearly does not establish the nonexistence of  extraterrestrial being.
Secondly, ‘If such a species (extraterrestrial) existed, there would be evidence of it on Earth or in the Solar System.’
Not really, perhaps such beings only recently (less than 500 years ago) developed radio communications or space vehicles, and the radio signals or vehicles have not had time to spread very far.
Imagine, if you will, one Aztec priest arguing with another in the year 1452: ‘I have made calculations that indicate it is nearly impossible for intelligent beings to exist in this hypothetical world you call Europe.
At its distance from the equator there would be inadequate Sunlight to grow the main source of human energy, corn, and insufficient warmth in the winter to sustain life.
I have made calculations that indicate that transoceanic travel is not only feasible but could be easily achieved by an intelligent species only slightly in advance of us.
If such a species existed, there would therefore be evidence of its existence in Mexico.’
David H. Minsker Merck Institute for  Therapentic  Research Pennsylvania 
Minefield
David Albury and Joseph Schwartz (’ Why the safety lamp increased accidents,’10 February, p 362) add little to an oft-told tale.
Their heart is in the right place, but their use of statistics is cavalier.
During their period production trebled in the coalfield.
In the 18 years 1798–1815 inclusive, for each million tons sold there were 0.62 explosions and approximately 11 deaths; in 1817–1834 inclusive the cost was 0.68 explosions, a 10 per cent increase, but with the loss of only 8.7 lives: for 1839–1844, this had fallen further to 6.5 lives, But the three periods are not easily comparable; the new production came not from the old collieries described but from new and ever deeper ones to the south and east made accessible after 1815 by steam-and-gravity operated railways.
The safety lamp killed, like iron rail, flat ropes and cages, not by reducing safety, which it clearly didn't, but by making it possible to expose vastly increased numbers of miners to that deadly mixture, geology and profit-hungry entrepreneurs.
For its analysis Davy had far less competence than Stephenson.
 E. Clavering, Atherstone, Warwickshire 
From where I write, I can see the village of Wylam, the birthplace of Gorge Stephenson (’ Why the safety lamp increased accidents,’10 February, p 362).
That excellent article was marred by four misprints in a list of seven collieries, which should have read: Wallsend Willingon, Percy Main, Hebburn, Jarrow, Elswick and Benwell.
In the old mining village of Clara Vale, on the other side of the River Tyne from Wylam, lives a retired pit overman and rescue team worker, Mr J. C. Bell.
He used Stephenson's double gauze safety lamp up until the 1940s, and quoted to me the number of permitted gauze apertures.
As a member of the Stella Coal Company rescue team, he used Stephenson's lamp as a methane detector.
The flame was turned down very low.
If it burned in a blue equilateral triangle, there was 2½ per cent methane in the air and ‘the men had to be gotten out’.
I have found, many times, that the practical science of these old miners is astounding; for instance, they made predictions of the effect of barometric pressure on the level of water in the shaft of flooded mine workings, which confounded the scientists of the National Coal Board.
What value do we place on practical scientists today?
 Lewis M. Routledge Northumberland 
Leaky waste
The sediment at the bottom of the sea permits nuclear waste to leak out at the rate of 1 metre per 10000 years not 10 years as appeared in last week's article (Technology, 17 February, p 442).
ARIADNE
Fritz Lang's famous film  Wetrupulis  .
which is about the future and about as accurate as any forecasting of the future turns out to be, a robot agitator is formed in the shape of a young woman.
The process necessitates rings of light oscillating up and down the body of the robot.
Apart from the lightning that brings Frankenstein's monster to life, I can think of no other appearance of physics in films that incidentally have science in them.
What we get is chemistry.
Almost always anyone with a white coat in a film is messing about with retorts, pouring liquids into flasks and changing the colour of the contents.
He is frequently wrapped in the mists of carbon dioxide and seen against a background of bubbles travelling along glass tubes.
Even when brains are being removed from their dead owners and implanted into living people, or fiends from outer space being fought to a standstill, nine times out of ten the magic weapon is the result of dubious chemistry.
It must be the influence of Jekyll and Hyde, which has been strong since John Barrymore grew long teeth and took to scuttling about dark expressionist streets, bashing and killing.
PETER Brancazio, of Brooklyn College's Department of Physics, contributes a paper to a recent scientific meeting in New York on the physics of judging a fly ball.
A fly ball, I take it, is the baseball equivalent of a skier in cricket, so the problem of how a fielder knows where to go, where to place his hands to catch, it is the same.
Brancazio points out that no-one can be taught how to make the right judgments.
It is, in his words, completely self-taught on a non-verbal level.
There have been attempts at explanation.
One theoriser, Seville Chapman, put forward the idea that a fielder used trigonometry without realising what he was doing, making unconscious calculations from the rate at which the tangent of the angle of the elevation of the ball changes.
(Brancazio, clearly a literary chap, called his paper, ‘Looking into Chapman's Homer’, a joke more obvious in the US).
He scouts Chapman's explanation on the grounds that aerodynamic forces change the trajectory of the ball from that of a perfect parabola and that would ruin the results of calculation based on the tangent.
Deeper levels, he surmises, are at work.
So are much larger questions.
Nobody is quite sure how anyone accurately judges where a moving object is in space and adjusts body movements to cope with it appropriately.
It is not only a matter of two eyed vision, because one-eyed people can also do the trick.
Brancazio suggests that sensors in the inner ear may be providing the information that sends a fielder to the right spot, not doing it well to begin with, but improving with experience.
For what it is worth, I think he may be right because it is possible to find objects in space from remembered information.
If you look at, say, a door in a lighted room for a second and then switch the light out.
you will be able to place your hand on the door-knob in the dark pretty accurately.
Until recently when I went to a conference on security in libraries and other collections I had not the slightest knowledge of the seamy side of that world or any idea that it had one.
Since then I have heard of hundreds of books being nicked from what was the British Museum Library and of surreptitious razor blades removing priceless illustrations from ancient works.
I had thought that high crime was  dog-earing and the highest of all writing comments in the margin.
Over the weekend I heard of the case of the disappearing Times Atlas , the one in five volumes.
In a famous library somebody found that the first two volumes had vanished.
Nobody had been seen carrying the two large and heavy books out.
A careful watch was mounted and nothing observed.
Nevertheless volumes three and four also vanished, as if in a conjuring trick.
It occurred to someone in the library that whoever had stolen the four volumes would certainly be after the fifth to complete his collection, so instead of watching people they watched the surviving book.
Lo and behold, the thief was caught red-handed.
He had been using an ingenious method.
The library was heated by warm air fanned through a grille.
He had been unscrewing the grille, dropping the books into the duct behind, and replacing the grille.
The books fell to the basement boiler room, where they were recovered by the thief.
He then marched out of the front door, beyond the scrutiny of the library staff.
Hardly a baffling puzzle for Holmes, I agree, but it shows what the fever to own books, or just to have them around to consult, may drive someone to do.
I like to be charitable.
The thief may simply have been stealing the books to sell.
BOY, DID I catch it for my remarks about George Orwell's 1984.
Abuse, suggestions of courses of action for me to follow that are physically and technologically impossible were much to the fore.
It all reminded me of what I received when I dared to make some mild criticism of the habits of cyclists and for much the same reason.
Few of the writers of the letters stuck to the point.
I had said that the world in 1984 will not be much like that in Orwell's novel.
I did not say that the world was in a sorry state, that it contained no dangers or that there was in absence of sinister-looking developments.
What I said was specifically about particular features described individually in the novel.
I hope that is plain.
I had an unpleasant suspicion that some of the letter writers were rather disappointed that 1984 will not see an enormous ministry for rewriting history and so on.
Daedalus
IN MAKING float glass, molten glass is floated on molten metal, so as to smooth it perfectly on both sides.
Daedalus mused that if the metal was not uniformly heated, upwelling convection cells would form within it.
They would perturb the metal glass interface, imposing a shallow largescale dimple pattern on the resulting glass sheet.
Daedalus sees this as the basis of a splendid new pictorial technology.
A conventional dimple pattern pane, of frosted glass, he points out, is a complex lens.
Illuminated from behind, it shows a complicated pattern of highlights (where light is focused) and dark regions (from which it has been diverted).
With a carefully enough computed dimple pattern, such a sheet could show any desired image.
It would be a sort of stained glass, drawing its picture not in colour but in brightness.
So DREADCO physicists are deducing the contours needed to produce elementary images, and seeking ways of imposing these contours on a molten metal-glass interface.
Convection cells will probably not do.
But if the metal is placed in a big magnetic field (the Earth's field may do), then electric currents in it will produce well-defined surface-perturbing mechanical movements.
Under computer control, these should exactly define the imaging surface.
For a contoured-glass image to be seen at, say, 30 m, the typical radii of curvature of the glass will be quite shallow, about 15 m.
This elegant new art form will be made even richer because different viewpoints will reveal different images.
An observer only 10 m away will see an image produced by those elements of the glass surface with radii of curvature around 5 m.
With enough computational skill, a contoured ‘stained-glass’ window in a church, say, could show a whole sequence of devotional images as someone walked down the aisle towards it.
Sideways movement would produce much smaller variations, enough to give an image of vitality and movement.
But no matter what path an observer followed, it would not be possible to provide him with stained-glass cinema.