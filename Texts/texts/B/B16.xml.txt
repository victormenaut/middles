

Relationships between Two Variables
Analysing Contingency Tables
In the previous chapter, percentage tables were introduced as a way of making contingency data more readable.
This chapter follows on directly; the properties of percentages and proportions will be scrutinized more closely, and other ways of analysing contingency data considered in the quest for a summary measure of the effect of one variable upon another.
First, however, we must come back to the question of how to read a contingency table when one variable can be considered a cause of the other.
(We shall shift from percentages to proportions from now on, since we need measures of effect which can be multiplied together.)
Which way should proportions run?
When we have a hypothesis about the causal relationship between variables, this can be conveyed by which of the proportions one uses in the analysis.
Fiegehan and his colleagues (1977) found age to be closely related to poverty: old people in Britain often subsist on very small incomes indeed.
The causal explanation must be that old age causes poverty, not that poverty causes people to be old; in a cross-tabulation of age by poverty, it is more natural to examine the proportion of each age group who are poor rather than the proportion of each income category who are old.
This can be formalized into a rule when dealing with contingency data: Construct the proportions so that they sum to one within the categories of the explanatory variable.
This rule is worth memorizing.
The idea is directly analogous to the treatment of interval level variables in chapter 6: we looked at the distribution of unemployment, the response variable, within each region, the explanatory variable.
The response variable thus provides the proportions, and the explanatory variable the categories.
The rule is illustrated by the accompanying diagram.
Note that it cannot be formulated as ‘always calculate proportions along the rows’; this would only work if the explanatory variable was always put in the rows, and no such convention has been established.
This is illustrated in exercise 8.4.
The base for comparison
In chapter 6, each individual value of a response variable (data) was decomposed into a conditional median (fit) and an unexplained component (residual).
Effects were then defined as the difference between the grand median and the conditional fit.
The same idea can be used with contingency tables, but the effects are usually derived by making comparisons not with a typical value such as the grand median but with one of the categories that has been chosen as the base for comparison.
To illustrate this, consider once more the example used in the previous chapter.
Inflow and outflow mobility tables were introduced in that chapter without reference to any causal hypothesis.
However, it is plausible to imagine that class background has a causal effect on the type of school that the son attends.
The explanatory variable is therefore father's class, a three-category variable.
In accordance with the rule propounded in the previous section, the proportions attending each school type should be calculated first within the service class, then within the intermediate class, then within the working class.
Figure 8.1 repeats the cross-tabulation of class background and a collapsed version of school type first shown in figure 7.8; the full raw frequencies have been included as they will be helpful in the following discussion.
Numbers only have meaning in comparison with other numbers.
To decide whether 0.237 of working class children attending selective secondary schools is high or low, it can be compared with the 0.397 of intermediate class children and 0.719 of service class children who attend those schools.
One category is picked to act as the base for comparison with all other categories.
The base category acts in analogous manner to the fitted median with interval level data.
By making comparisons with  this base, quantitative estimates of the causal effect of one variable on another can be made, and positive and negative relationships between nominal level variables can be distinguished, as we shall see shortly.
Figure 8.1 Attendance at selective secondary school
Which category should be selected as the base for comparison?
The decision is to some extent arbitrary, but there are several relevant considerations.
Since the base category will be used in every comparison, it is desirable that there should be a substantial number of cases in it; we do not want comparisons to be made with an unreliable figure.
For the same reason, it should be a category that is of substantive interest.
Moreover, if there is one category that is markedly different from others, this is a good one to choose as the base, since it will focus attention on the difference.
Finally, when picking the base categories for several variables whose interrelationships are to be examined, an attempt should be made to keep negative relationships between variables to a minimum: double negatives are as confusing in data analysis as they are in prose.
Which categories, then, should be selected as bases for comparison among father's class and school type?
Since the working class is the largest group and the group which concerned the educational reformers of 1944, it is the natural choice of a base for the class variable.
If we then pick non-selective education as the base for comparison in the school type variable, we will almost certainly avoid negative relationships.
In summary, the service and intermediate classes will be compared with the working class in their attendance at selective as opposed to non-selective schools.
In order to represent one three-category variable like school type in a causal path model, we have to present it as two dichotomous variables.
Instead of coding the class background of respondents as 1, 2 or 3 to denote service, intermediate or working class, for example, the information is effectively presented as two dichotomous variables — whether someone is in the service class or not, and in the intermediate class or not.
Someone who was neither service class nor intermediate class would, by elimination, be working class.
Choosing one category as a base effectively turns any polytomous variable into a series of dichotomous variables known as dummy variables .
Figure 8.2 shows how the effect of a three-category explanatory variable on a dichotomous response variable can be portrayed in a causal path model.
Social class is represented by two dummy variables; the effect of the first is denoted b 1 and the effect of the second b 2 .
A line is drawn under which the base category of the explanatory variable is noted; the fact that some working class children attend selective secondary schools (path a ) reminds us that there are some factors influencing attendance at such schools that this particular model does not set out to explain.
Figure 8.2 Causal path model of class background and schooling
Summarizing effects by subtracting proportions
In figure 8.2, the effect of being in the service class on the chances of attending selective secondary school is denoted b 1 , and the effect of being in the intermediate class is denoted b 2 .
How are these to be quantified?
There is no answer to this question that commands universal acceptance.
In this section we shall consider d , the difference in proportions (Davis 1976).
This measure of effect has two virtues: it is simple and intuitively appealing.
In later sections we shall look at alternatives.
As long as we keep cool when deciding which proportion to subtract from which, the procedure is simple.
Attention is restricted to the non-base category of the response variable; in this example, it is the proportion of people who attend selective school that is at issue, and the shadow proportion who do not attend is ignored.
The effect,d , is calculated by subtracting this proportion in the base category of the explanatory variable from this proportion in the non-base category of the explanatory variable.
In this particular example, path b 1 represents the effect of being in the service class as opposed to being in the working class on the chances of attending a selective secondary school.
It is found by subtracting the proportion of the working class attending selective secondary schools from the proportion of the service class who do the same; in this case,d = 0.719 -0.237, or +0.482.
The result is positive, as we expected: service class children are more likely to attend selective secondary schooling than working class children are.
Now we can quantify this: 0.482 more service class than working class children attend these schools.
If we had selected different base categories, we could have ended up with negative values of d .
If, for example, we were trying to explain attendance at non-selective schools, the d for the service class would have been 0.281 -0.763, or -0.482; the magnitude of effect would not have altered but the sign would have been reversed.
Path b 2 represents the effect of being in the intermediate class on the chances of attending a selective secondary school.
We might expect this to be lower than the effect of being in the service class.
It is.
In fact,d = 0.397 -0.237, or +0.160, but it is still positive; 0.160 more intermediate than working class children go to selective secondary schools.
While the paths b 1 and b 2 are the focus of our attention, it is also important to remember the other causes which lead to people attending selective secondary schools: class membership is not a complete determinant of who goes to these schools, since some working class children do attend.
Path a reminds us that some people from working class backgrounds attended selective secondary schools.
The value of path a is given by the proportion of cases in the base category of the explanatory variable who fall in the non-base category of the response variable.
In fact, nearly a quarter of working class children went to selective secondary schools; the value of this path is therefore 0.237.
It represents  the starting point, the fitted value to which the other path values should be added; for this reason it does not have a sign attached.
The quantified model is shown in figure 8.3.
The model allows us to recast the DFR equation for cells in a table, rather than for individual values.
We decompose the proportion of service class children who attended selective secondary school (0.719) into a fitted component (0.237) and an effect (+0.482).
Figure 8.3 Quantifying model in figure 8.2
Some readers will have come across the idea of expressing a simple relationship between an explanatory variable X and a response variable Y as Y = a + bX .
If the idea is familiar to you, you may like to note here that proportions can also be expressed in this way.
The overall proportion Y attending selective secondary school is 2811/8014, or 0.351 (figure 8.1).
This can be decomposed as: where X 1 and X 2 are the proportion in the service class and intermediate class (0.134 and 0.308) respectively: 0.237 + (0.134 × 0.482) + (0.308 × 0.160) = 0.351 We shall consider equations like this for interval level variables later in the book; you may find it useful to come back to this paragraph after you have read chapter 10.
Properties of d as a measure of effect
The difference in proportions,d , has been used to summarize the effect of being in a category of one variable upon the chances of being in a category of another.
This measure has several advantages.
People understand it intuitively (Hunter 1973).
It retains the same numerical value (while changing its sign) if the other category in a dichotomy is chosen as the base for comparison.
Furthermore, it can be used to decompose overall proportions, as shown in the previous section, and it can be decomposed itself when other variables are brought into the picture.
It does, however, have some properties which are less well understood, and which, in the view of some data analysts, can make it unsuitable for analysing some contingency tables.
If the proportions were run in the opposite direction, the value of d would change; exercise 8.2 asks you to confirm this.
Some statisticians dislike this property: they prefer symmetric measures of association which take the same value whichever way round the causal effect is presumed to run.
Quantitative summaries of causal effect such as d , however, are nearly all asymmetric , taking different values depending on which variable is presumed to be the cause of the other.
Those of us who believe that causality is central to the philosophy of data analysis prefer measures of effect, which force us to be explicit about causal order, to symmetric measures of association.
Secondly, because proportions are bounded numbers, we may wish to distinguish differences between proportions in the middle of the range from those between extreme proportions.
In the above example, the proportions attending selective schools were all in the middle range, varying from 0.24 in the working class to 0.72 in the service class.
But imagine a society in which only 0.01 of the working class attended such schools, while 0.10 of the service class did.
The d between service and working class would be much smaller, +0.09, but we might not want to conclude that the second society displayed smaller class differentials; after all, ten times as many service as working class children attend selective schools in the latter case, while only three times as many do in the former.
There are other strategies we might adopt to solve this problem.
We could look at ratios between proportions rather than differences.
Or we could apply some kind of transformation which would stretch out the tails of the distribution, which would let us stick with arithmetic procedures and avoid multiplicative models.
Both ideas will be discussed in the next section.
Just as a simple proportion is a bounded number, so d is also.
The bottom boundary, the ‘floor’, is easy to understand: if, for example, class has no effect on school type, then all classes will have approximately the same proportion of children at selective schools, and the lowest possible magnitude of d will be zero.
But the top is bounded in a different place in every different table, depending on the marginal distribution of the two variables.
It is, in theory, possible to get a d of 1.00; this would happen if all the service class children went to selective schools and nobody else did.
But this could only occur if the number of selective secondary school places was exactly the same as the number of service class children.
The marginal distributions of both explanatory and response variables set limits to the size of effect that is possible; to put this formally, we say that d is a marginal dependent measure.
Changes in the marginal distribution of the response variable will always produce changes in differences in proportions, even if the cells are still distributed in the same proportion; if, for example, the supply of selective school places doubled but the class composition of the schools remained the same,d would change.
However, not everyone believes that the boundedness of proportions and of d s is undesirable.
The popular appeal of proportions and percentages is probably precisely because people understand that they cannot go below 0 or above 1; the boundaries set a frame of reference in which people can interpret a particular result.
The marginal dependence of d can also be seen as a virtue once it is fully understood.
One could take the view, for example, that important constraints on social equality are imposed by the opportunities available in society, regardless of who avails themselves of them, and that we do not want a measure that is insensitive to such constraints.
As usual, we need to have a clear view of precisely what we are trying to summarize before deciding which measure does the job best.
Alternatives: ratios of proportions and odds
Proportions, as we have said, can be interpreted in terms of chances: the probability of an individual attending a selective school can be quantified as the proportion of children attending such a school.
Since probabilities can be multiplied as well as added, one way of making effects among small probabilities comparable with effects when the probabilities are nearer 0.5 might be to look at ratios rather than differences.
In figure 8.1, we could have expressed the differentials between service and working class as a ratio rather than a difference; service class children had 0.719/0.237 or 3.03 times the chance of attending a selective school of some kind than working class children did.
Some people find it much more appealing to express probabilities in this multiplicative way.
Ratios between two proportions are not, however, regularly used in analysing contingency tables.
Adding and subtracting are easier operations than multiplying and dividing.
Furthermore, ratios do not retain the same decimal value when the base for comparison is altered: if the ratio of A to B is 7/1 or 7.0, then the ratio of B to A is 1/7 or 0.143.
It also turns  out that the ratio of proportions is rather cumbersome to handle when dealing with many variables at once, and no-one has yet proposed a way of decomposing it into component effects as they have with d s and with measures based on odds.
If the sound of hooves on the turf makes your heart flutter, you may prefer to think of chance in terms of odds .
The odds of an outcome are given by dividing the number of times the outcome occurred by the number of times it did not occur.
Proportions can always be translated into odds.
The first two columns of figure 8.4 show the results for a sample of proportions.
The probability of one in ten is the same as odds of one to nine or 0.1111, a 50 per cent probability corresponds to odds of one to one, or ‘evens’, and so on.
Figure 8.4 Expressing probabilities as odds
The second column of figure 8.4 shows that the upper ceiling has been removed once the proportions are expressed as odds; odds can become infinitely large.
They do however still have a lower boundary at zero, and the whole distribution is very lop-sided; outcomes with probabilities less than evens are squashed into the number range 0 to 1, whereas probabilities above evens can range from 1 to infinity.
Logarithms effect a miraculous change on the odds.
The third column of figure 8.4 shows the result of taking logs of the second column.
The floor of zero has been removed: miniscule odds translate into large negative log odds.
Moreover, symmetry has been restored to the concept of chance.
Probabilities of 0.99 and 0.01, symmetrical in that they sum to 1.0, translate into log odds of +2.00 and -2.00.
This transformation of a probability, log [p /(1- p )], is known as the logistic transformation.
It has a characteristic shape when plotted against the raw probabilities, as  shown in figure 8.5; it is S-shaped and is approximately linear in the middle part of the distribution.
Figure 8.5 Characteristic shape of the logistic curve
There are often substantive reasons for expecting proportions to respond to an explanatory variable in something resembling this flat S shape.
We might argue, for example, that promoting a father from the most menial labouring job to a semi-skilled factory job is still unlikely to lead to his son going to a selective school, since so few working class children go.
At the other end of the scale, promoting a father from being manager of a middle-ranking enterprise to a top-ranking enterprise is also unlikely to alter the son's chances much, because in all probability he already attends a selective school.
The greatest effect of social mobility might be expected to be in the middle of the range, perhaps when fathers move from manual to non-manual jobs, for example.
An increasingly popular measure of effect is the difference not in proportions but in log odds between two categories.
This turns out to be much the same as looking at ratios of odds, but avoids cumbersome multiplicative arithmetic.
Class effects on schooling
In order to illustrate the construction of these different measures, consider again the original cross-tabulation of school type by class  background (figure 7.5).
If we wanted to summarize the extent to which any type of school selected disproportionately from the children of particular class backgrounds, we might use the difference between the service and the working class in the proportion attending that school.
Thus, since 0.266 of service class children attended secondary modern schools, while 0.747 working class children did, the d for secondary modern schools would be -0.481; similarly, the d for HMC schools would be 0.118–0.003, or +0.115, and so on.
This is shown in the first three columns of figure 8.6.
Figure 8.6 Probabilities of attending various types of school
However, since so few children attended some of these types of school,d is often calculated from proportions at the extremes of the scale; if we rank the class exclusivity of schools on the basis of the magnitude of the d s, we seem to be told that the secondary moderns were the most selective, followed by the grammar schools.
The ratios of proportions in the fourth column of figure 8.6, calculated by dividing the first column of proportions by the second, tell a rather more convincing story.
The private schools are the most select in class terms: almost forty times as many service as working class children attend HMC schools.
The grammar schools and secondary moderns are similar in terms of class exclusivity.
In each case, the proportion attending in one class is approximately three times the proportion attending in the other; the similarity between the two numbers (0.36 and 3.16), however, requires careful inspection to spot.
What about measures based on odds rather than probabilities?
Figure 8.7 shows the worksheet for calculating the log odds and difference in log odds for the same data; the odds of a service class child attending secondary modern school are obtained by dividing 0.266 by 0.734, or 0.362, and so on.
The difference in log odds gives exactly the same rank order as the ratio of proportions did: the private schools (HMC then  non-HMC) are the most exclusive in terms of selecting service class as opposed to working class children, followed by direct grant schools, then grammar schools, comprehensive schools, and technical schools, with secondary moderns bringing up the rear.
Figure 8.7 Odds of attending various types of school
When the probabilities get very small, as they do with some of the school types,d is not a very suitable measure of effect.
Any measure based on ratios (or, what amounts to the same thing, differences in logs) is to be preferred.
Conclusion
There has been some controversy in recent years about how best to analyse contingency data.
Percentages and proportions are popular because they are easy to calculate and their magnitude is simple to interpret.
However, models based on subtracting one proportion from another are only acceptable for proportions in the middle of the range.
Odds ratios or differences in log odds can work better when the proportions are very small or large; they are, however, more complex to interpret for all except seasoned punters who are used to comparing the likely returns on different bets (Seaver et al.1978).
We have also learned an important lesson about the philosophy of data analysis in this chapter.
It is possible to use different techniques and arrive at different answers.
The ignorant response to this is to give up in despair, and to slump back agnostically into the comfortable armchair.
The wicked response is to select the technique that gives the desired answer.
The response of the good data analyst is to welcome the discrepancy, and to examine the data even more closely to understand why the techniques differ; new insights could be on the horizon.
Exercises
8.1
The responses (see table) to an interview on public expenditure cuts were collected from a sample of residents of two wards in Greater Manchester in the winter of 1980–81.
The researchers compared the attitudes of loyal Conservative or Labour Party voters in 1979 with Conservative defectors in their views on public spending on the welfare state (education, social services and health) and on law and order (police and armed forces).
Present the results as two separate tables of proportions and causal path diagrams and discuss the findings.
8.2
The desire to isolate the factors associated with child abuse is understandable; social workers and other professionals could be given a list of tell-tale signs, and they could then keep a particularly close eye on families at risk.
One way in which such factors are isolated is by comparing parents known to batter their children with a control group of parents who have no history of child abuse (Lynch and Roberts 1977, for example).
On the basis of data such as the following, younger mothers are thought to be particularly at risk.
Calculate both row and column proportions, and calculate the two d s; confirm that d is an asymmetric measure of effect.
Decide which d summarizes the causal relationship better.
Adjust the second row of the table to reflect a true incidence of child abuse of 20 in every 10,000.
What happens to d ?
8.3
Brown and Harris (1978) argue that the factors which lead to depression in women are of two types: some actually provoke the onset of depression (provoking agents) while others make women more vulnerable to the operation of provoking agents (vulnerability factors).
In a random sample of women in Camberwell, the researchers found the following relationships between provoking agents and depression, first among a sample of women who were vulnerable and secondly among a sample of women who were not.
Calculate two different measures of effect in both tables.
8.4
Using the HEIGHT dataset, construct two tables to show the cross-tabulation of a husband's social class by whether he smokes or not, first placing class in the rows and smoking in the columns, and then vice versa.
Indicate your views about the likely causal relationship between these two variables by selecting the appropriate percentages in each case.
Smoothing Time Series
Time series
Economists are held to treat one month's figures as a freak, two months' as a fact and three months' as a trend.
In this chapter we shall look at ways of smoothing the edges off the jagged initial appearance of data plotted over time; we shall look at the observations three at a time, taking seriously the spirit of this somewhat sarcastic remark, to get indications of the trend.
This chapter is relatively free-standing, and could be read at any point after chapter 2.
The number of people receiving supplementary benefit for each year from 1948 to 1978, as shown in figure 9.1, is an example of a time series .
Other examples might be the monthly Retail Price Index over a period of ten years, or the quarterly balance of payment figures during the last Labour government.
The examples all have the same structure: a well-defined quantity is recorded at successive equally-spaced time points over a specific period.
Problems occur when any one of these features is not met — for example if the recording interval is not equally spaced.
For exposition, a convenient special notation is used:y 1 ,y 2 ,y N  , or y t  in general;y t  refers to the value of the quantity,y , recorded at time t .
It is conventional to code t from 1 to N , the total period of observation; for example, the years 1948 to 1978 would be coded from 1 to 31.
Smoothing
Time series such as that shown in the second column of figure 9.1 are displayed by plotting them against time, as shown in figure 9.2.
When such trend lines are smoothed, the jagged edges are sawn off.
Two smoothed versions of the numbers of unemployed supplementary benefit claimants are displayed in figure 9.3 and figure 9.4.
The version in figure    9.4 is smoother than the version in figure 9.3, and each is smoother than the raw data plotted in figure 9.2.
Figure 9.2 Unemployed supplementary benefit claimants: unsmoothed
Figure 9.3 Unemployed supplementary benefit claimants: first smooth
Most people, if asked to smooth the data by eye, would probably produce a curve similar to those in figures 9.3 or 9.4, each of which has  been derived using a well-defined arithmetic procedure described later in the chapter.
Smoothing by an arithmetic procedure can sometimes, however, reveal patterns not immediately obvious to the naked eye.
Figure 9.4 Unemployed supplementary benefit claimants: second smooth
The aim of smoothing
Figure 9.2 was constructed by joining points together with straight lines.
Only the points contain real information of course; the lines merely help the reader to see the points.
The result has a somewhat jagged appearance.
The sharp edges do not occur because very sudden changes really occur in numbers of unemployed receiving supplementary benefit; they are an artefact of the method of constructing the plot, and it is justifiable to want to remove them.
According to Tukey (1977:205), the value of smoothing ‘is the clearer view of the general, once it is unencumbered by detail’.
Smoothing aims to remove any upward or downward movement in the series that is not part of a sustained trend.
Sharp variations in a time series can occur for many reasons.
Part of the variation across time may be error.
It may be grouping error as discussed in the previous paragraph.
It could be sampling error; the main data used in this chapter was collected in monthly sample surveys, each of which aimed to interview a cross-section of the general public but each of which will have deviated from the parent population to some extent.
Similarly, repeated measures may each contain a degree of measurement  error.
In such situations, smoothing aims to remove the error component and leave the underlying true trend.
But the variable of interest may of course genuinely swing around abruptly; the monthly count of unemployed people rises very sharply when school-leavers come on to the register, for example.
In these cases, we may want to smooth to remove the effect of events which are unique or which are simply not the main trend in which we are interested; it is good practice to plot the rough as well as the smooth values, to inspect exactly what has been discarded.
In engineering terms we want to recover the signal from a message by filtering out the noise.
The idea is not new to us.
We should by now be familiar with the general formula for decomposing data: Data = Fit + Residual The process of smoothing time series also produces such a decomposition of the data except that we mainly use the alternative, more suggestive form of words.
Data = Smooth + Rough This choice of words helps to emphasize that we impose no a priori structure on the form of the fit.
The smoothing procedure may be determined in advance but this is not the case for the shape and form of the final result: the data is allowed to speak for itself.
Put in another way, the same smoothing recipe applied to different time series will produce different resulting shapes for the smooth, which, as we shall see in the next chapter, is not the case when fitting straight lines.
As so often, this greater freedom brings with it increased responsibility; the choice of how much to smooth will depend on judgement and needs.
If we smooth too much, the resulting rough will itself exhibit a trend.
Of course, more work is required to obtain smoother results, and this is an important consideration when doing calculations by hand.
The smoothing recipe described below generally gives satisfactory results and involves only a limited amount of computational effort.
Most time series have a past, a present and a future.
The upward trend in the numbers of unemployed getting supplementary benefit, for example, continued in the 1980s; the numbers trebled until two-thirds of all the unemployed received this benefit, despite the fact that it was never designed for them.
The goal of the smoothing recipes to be explained in this chapter, however, is not the extrapolation of a given series into the future.
Consumer confidence
In complex market economies, where the decision to produce and the decision to consume are taken by different people at different points in  time, it is important for manufacturers to have some idea of the likely demand for products.
Individual manufacturers can monitor their own stock and sales to look for trends.
Some market research companies specialize in providing audits of the trends in sales of particular product types across all manufacturers.
But increasingly attempts are made to monitor a more general concept: the degree of confidence consumers have in the economy and in their own purchasing power.
George Katona was one of the pioneers of this sort of work.
He criticized neo-classical economics for assuming that the actors in a market-place had perfect information and acted with supreme rationality to further their financial best interests.
He suggested instead that economists and psychologists should link forces to study how producers and consumers actually make decisions, how they plan, what they believe, why they purchase commodities when they do, and so forth(Katona 1951).
Since the early 1970s, the Commission of the European Economic Community has sponsored a regular monthly survey into consumer confidence in all its member countries.
Individuals are regularly asked about their perceptions of the economy as a whole, about inflation and unemployment levels; then they are asked about their household finances in particular, their expectations of buying consumer durables and their attitudes towards saving.
This survey provides a particularly rich source of data because of the long time span covered.
Gallup does the fieldwork for the British wing of the survey.
The fieldwork is conducted monthly on a quota sample of two thousand individuals selected to be representative of the adult population of Great Britain; more details about opinion polling companies and their methods are given in the appendix to this chapter.
The results of each survey are published in the Gallup Political Index every month, except during election periods, when the European Commission takes the view that member countries should not publish opinion data for fear of influencing the outcome of the election.
In this chapter, data is presented from four of the questions, which elicit general perceptions of the economy and household finances.
Respondents are asked: ‘How do you think the general economic situation in this country has changed over the last 12 months?’.
They select a response from a card:
got a lot better
got a little better
stayed the same
got a little worse
got a lot worse
There is a parallel question on how they think the situation will develop in the next twelve months.
Then they are asked: ‘How does the financial  situation of your household compare with what it was 12 months ago?’
This is followed by a question on how it will change over the next twelve months.
These questions have similar response categories.
There are several ways in which the five responses might be summarized into a single score for each month which could then be traced over time.
The method used in figure 9.5 is to cut the distribution in two and to display the percentage in one or other group; here the percentages endorsing the two pessimistic response categories have been amalgamated (it is slightly inaccurate to describe those who think the economy deteriorated in the past as ‘pessimists’, but it is a convenient shorthand).
An alternative would be to subtract the proportion of optimists from the proportion of pessimists.
Another more comprehensive scoring system for the same questions is used in the dataset ECONOMY.
Figure 9.5 Consumer confidence items — percentage of pessimistic responses
Techniques
Figure 9.6 shows pessimistic perceptions of the economy in the past plotted over time without being smoothed.
The curve is jagged because the values of raw time series data at adjacent points can be very different.
On a smooth curve, both the values and the slopes at neighbouring time points are close together.
The general remarks on effective display made in the appendix to chapter 7 are important to recall when plotting, and some further remarks on this subject will be made in the next chapter.
When plotting monthly or quarterly data, graph paper ruled into twelve divisions instead of ten is invaluable.
Figure 9.6 Pessimistic perceptions of the economy over the past year: unsmoothed
To smooth a time series we replace each data value by a smoothed value that is determined by the value itself and its neighbours.
The smoothed value should be close to each of the values which determine it except those which seem atypical; we therefore want some form of resistant numerical summary — some local typical value.
This involves two decisions: which neighbouring points are to be considered local and which changes are atypical?
The answers to these questions must depend in part on the particular problem but this chapter presents some multipurpose procedures which give generally satisfactory results.
These procedures answer the two questions as follows: take one point either side as local and treat as real an upward or downward change of direction which is sustained for at least two successive points.
Summaries of three
The simplest such resistant average is to replace each data value by the median of three values: the value itself, and the two values immediately adjacent in time.
Consider, again, the percentage of respondents who believe that the economy got worse over the previous twelve months (column 1 in figure 9.5).
To smooth this column, we take the monthly figures in groups of three, and replace the value of the middle month by the median of all three months:
In January, February and March, the median is 47 per cent so February's value is unchanged.
In February, March and April, the median is also 47 per cent, so the value for March is altered to 47.
The process is repeated down the entire column of figures.
Since, for the purpose of this exercise, we are supposing that the December 1983 and November 1985 rates are unknown, we simply copy on the first and last values, 40 and 55, for January 1984 and October 1985.
More sophisticated rules for smoothing these end values are available, but discussion of them is postponed for the present.
The data, the smoothed values and the residuals are shown in the first three columns of figure 9.7.
(In this chapter, we shall adopt the convention that all numbers that change when they are smoothed are shown in bold print.)
Notice the large residuals for the somewhat atypical results in May and November 1984 and February and June 1985.
The effect of median smoothing is usually to exchange the jagged peaks for flat lines.
One other possible method of smoothing would be to use means rather than medians.
The result of using the mean of each triple instead of the median is shown in columns 4 and 5 of figure 9.7.
As with the median smoothing, the residuals in the seemingly atypical months are large, but the sharp contrast between the typical and atypical months has been lost.
Close inspection reveals that mean smoothing creates relatively large residuals in months adjacent to the strikingly atypical months, where perhaps common sense would suggest otherwise; if the percentage in February 1985 represents some kind of error, for example, then the less resistant mean has spread this error over into the adjacent months.
However, as we might expect, the median smooth is more jagged than the mean smooth (shown in figure 9.8).
A sensible compromise would be  first to use medians to set aside atypical behaviour, and then to apply some form of mean analysis to the median smooth to round off the corners.
We will return to the details of how to do this later.
Figure 9.7 Worksheet: running medians and means of three
We could stop after one pass through the data, but we can also repeat the running three-median procedure on the values just smoothed to produce a smoother result.
If we do this, most values will not change; in this case, only the value for July 1985 changes on the second pass through.
This procedure is repeated until it produces no change; usually two or three passes through the data (iterations)are sufficient.
The worksheet for repeated median smoothing is shown in figure 9.9; column 3 is headed ‘3R’, a shorthand to denote repeated medians of three.
When working by hand, it is only necessary to record those values that change upon iteration; in this text the values that change are denoted by bold print, but the other numbers are copied over for clarity.
Figure 9.8 Pessimistic perceptions of the economy over the past year: comparison of median and mean smoothing
To sum up, the recommended procedure so far is:
1
Plot the data first, as arithmetic smoothing may not be required.
2
List the times and data in two adjacent columns, rescaling and relocating to minimize writing and computational effort.
Judicious cutting or rounding can reduce work considerably.
3
Record the median of three consecutive data values alongside the middle value; with a little practice, this can be done quickly and with very little effort.
4
Pass through the data, recording medians of three as many times as required.
5
Copy on the two endpoint values.
Hanning
Although smoothing by repeated medians of three is adequate for most purposes and successfully dealt with seemingly atypical values, the results still have a somewhat jagged appearance.
One way to smooth off the corners would be to use running means of three on the 3R smooth.
We can do better than taking simple means of three, however.
This would give equal weight, one-third, to each value; as the data has already been smoothed it would seem sensible to give more weight to the middle value.
A procedure called hanning , named after its protagonist, a nineteenth century Austrian meteorologist called Julius von Hann, goes some way to meeting these criticisms.
Given any three consecutive data values, the adjacent values are each given weight one quarter, whereas the middle value, the value being smoothed, is given weight one half.
This is achieved in the following way: first calculate the mean of the two adjacent values — the skip mean — thus skipping the middle value; then calculate the mean of the value to be smoothed and the skip mean.
It is easy to show that these two steps combine to give the required result.
In practice, we first form a column of skip means alongside the values to be smoothed and then form a column of the required smoothed values.
This procedure is depicted above for the first three values of the repeated median smooth, shown in full in figure 9.9: Thus 47 is the value to be smoothed, the skip mean 43.5 is the mean of 40 and 47 and the smoothed value 45.2 is the rounded mean of 47 and 43.5.
Figure 9.9 Worksheet for repeated median smoothing and hanning (3RH)
A new element of notation has been introduced into figure 9.9: the column of hanned data values is labelled ‘H’.
We can now summarize the smoothing recipe used in this figure as ‘3RH’.
The results are plotted in figure 9.10.
Hanning has produced a smoother result than repeated medians alone.
Whether the extra computational effort is worthwhile depends on the final purpose of the analysis.
Repeated medians are usually sufficient for exploratory purposes but, if the results are to be presented to a wider audience, the more pleasing appearance that can be achieved by hanning may well repay the extra effort.
Figure 9.10 Pessimistic perceptions of the economy over the past year: median
Figure 9.10 now tells a pretty clear story; the proportion of people who believed that the economy had deteriorated in the previous year climbed from around 40 per cent at the beginning of 1984 to a peak of 67 per cent in February 1985, but declined thereafter.
We shall not make any comments about this until we have had a chance to inspect a longer time span.
Residuals
As we have learned elsewhere, much can be gained by examining residuals, here called the rough.
Residuals can tell us about the general  level of variability of data over and above that accounted for by the fit; we can judge atypical behaviour against this variability, as measured, for example, by the midspread of the residuals.
We noted in chapter 1 that we want residuals to be small, centred around zero and patternless, and, if possible, symmetrical in shape with a smooth and bell-shaped appearance.
Displaying them as a stem and leaf will reveal their typical magnitude and the shape of their distribution.
Figure 9.11 shows the stem and leaf display of the residuals from the repeat median and hanning smooth (the 3RH for short); it shows that the residuals are small in relation to the original data, fairly symmetrical, centred around zero and devoid of outliers.
Zero-modifying the residuals 
Figure 9.11 Residuals from the 3RH smooth
Note that a space on the stem in figure 9.11 has been devoted to residuals of precisely zero.
Resistant numerical summaries have many desirable properties, as was discussed in chapter 2, but they can generate an excessive number of zero residuals, and thus give an unrealistically small measure of variability.
This is particularly true when only median summaries have been applied to a fit; inspection of column 3 of figure 9.7, for example, reveals that the residuals from the 3R smooth alone contain a large number of zeros.
When this occurs, Tukey suggests removing half the number of exact zeros and then basing all subsequent calculations on the modified set of residuals, a process known as zero-modifying (Tukey 1977:223).
Figure 9.12 shows the zero-modified residuals from the 3R smooth.
Before zero-modification, the middle line of the figure would have been twice as long, with 14 zeros.
Since 7 of the 14 zeros have been removed from the 22 residuals, the modified number of residuals is 15.
Figure 9.12 Zero-modified residuals from 3R smooth
Blurring the smooth
As the rough represents the variability around the smoothed line, it is sometimes appropriate to use it to indicate the typical degree of variation around the smoothed curve.
This is achieved by a process known as blurring .
Instead of plotting each smoothed value as a point, a vertical bar of constant height centred upon the smoothed value is drawn.
Blurring has a double function.
First, the vertical bars can give a somewhat smoother appearance to an otherwise jagged result; blurring can thus be viewed as an alternative to hanning.
The second advantage is that the length of the vertical bar can be used to indicate the typical variability of the rough.
It is conventional to use twice the median of the absolute values of the modified residuals as the length of the vertical bar used to blur the smooth.
Of course we are not restricted to blurring the repeated median smooth.
In fact for many presentation purposes a blurred version of the repeated median/hanned smooth, including outliers, would represent a good summary of the data.
Pattern in the residuals
There are two generally useful ways to examine residuals for pattern.
They can be plotted against the explanatory variable (here time) once more, to see if all the trend has indeed been extracted; this is discussed in the next section, under the heading ‘reroughing’.
Or they can be plotted against the fitted (here smoothed) values, to look for indications of non-constant variability; if the residuals get bigger as the smoothed values get bigger, this usually means that the the analysis would be better carried out on another scale.
As we shall see in chapter 11, such non-constant variability is usually dealt with by a power transformation of the scale of measurement.
Exercise 11.4 has been set to demonstrate this point with time series.
If we are smoothing with repeated medians, the appropriate transformation can simply be applied to the smoothed values and new  residuals calculated.
However, this cannot be done after hanning; it is necessary to repeat the hanning on the transformed repeated median smooth.
Refinements
There are a number of refinements designed to produce even better smooths.
We can only give cursory attention to these here but more details are given in books by Tukey (1977) and Velleman and Hoaglin (1981).
Endpoint smoothing
So far we have been content to copy on the initial and final values for January 1984 and October 1985 (y 1 and y N  ) but we can do better.
Instead of copying on y 1 , we first create a new value to represent y at time 0, December 1983; this will give us a value on either side of y 1 so that it can be smoothed.
This value is found by extrapolating the smoothed values for times 2 and 3, which we shall call z 2 and z 3 ; this is shown graphically in figure 9.13.
Figure 9.13 Creating a value for t
To compute this new value without recourse to graph paper, the following formula can be used: For example, a hypothetical value for December 1983 is given by (3 × 45.2)—(2 × 46.7) or 42.2 (data derived from figure 9.9).
To provide a  smooth endpoint value, we replace y 1 by z 1 , the median of y ,y 1 and z 2 ; in this case, the median of 42.2, 40 and 45.2 is 42.2, so this becomes the new, smoothed endpoint value.
A similar rule is used to smooth y N by creating a new value,y N+1 .
The letter E is added to the recipe formula to indicate that the endpoints have been smoothed; the total smooth is now ‘3RHE’.
Breaking the smooth
Sometimes time series exhibit an obvious change in level and it may be sensible to analyse the two halves separately, producing two roughs and two smooths.
In such cases, the two sections often exhibit markedly different levels of variability.
This seems to be the case in figure 9.1, for example, at the point where national assistance changes over to supplementary benefit.
Reroughing
Smoothing by taking repeated medians is very powerful, and can sometimes produce a result that departs more from the pattern of the original data sequence than we would like.
Reroughing is a procedure designed to recover pattern from the discarded rough values.
The residuals are smoothed using the same recipe as before, and the results are added back to the results of the first smooth; this is illustrated in exercise 9.1.
This procedure, called reroughing (or sometimes twicing ) takes further the idea of iterating that we met earlier in this chapter.
You will find that many exploratory techniques require repeated steps before a final fit is found.
Trends in economic pessimism
Having learned the mechanisms, let us now return to perceptions of the economy.
In figure 9.14, negative perceptions about the performance of the economy in the previous twelve months and pessimism about the economy in the following twelve months are plotted on the same scales over a six year period.
The story line in the smoothed version of panel (b) is a lot clearer than in the rather jangled panel (a).
If people's perception of the past performance of the economy and their prediction of future trends was accurate, one would find two identical curves which faithfully followed economic performance, with one lagging twelve months behind the other.
There are several ways in which the curves in figure 9.14 depart from these idealized perceptions and forecasting abilities of rational economic man.
Figure 9.14 Pessimistic perceptions of the economy 1979–85:(a) unsmoothed (b) smoothed by 3RHE
First, the proportion of pessimists about the future is clearly and consistently lower than the proportion who perceived deterioration in the economy in the past; there must be a significant number of people who think things got worse in the last twelve months, but who are perpetually hopeful that the rot has stopped.
Secondly, the two lines do track very closely together, but not with a twelve month lag as one might expect; the two curves are almost superimposed.
People may be projecting the present into the past, re-evaluating the past on the basis of the present, or being influenced by some broader underlying general forces of optimism and pessimism.
(One might subtract the perception of the past from the perception of the future and smooth that once more as an index of optimism over time.)
Thirdly, the shape of the curve does not match objective indicators of economic performance: on whatever measure one chooses, the economy performed disastrously in 1981, and picked up slightly in 1983, but perceptions during 1982 and 1984, perversely, move in the opposite direction.
The effect of political events is more clearly visible in the picture.
Pessimism declined sharply during the Falklands War (April-June 1982), for example, and before the two elections (May 1979; June 1983).
The interesting exception comes in the lead up to the 1979 election, when people were very harsh about the past period (during a Labour administration) but hopeful for the future (which was to be under Conservative administration); however, gloomy expectations about the future soon followed that 1979 election.
Summary
In this chapter, techniques have been presented for smoothing time series data.
They can be performed relatively easily and effectively by hand.
More powerful elaborations of the simple ideas presented here are also available in computer algorithms; readers should consult the Minitab manual to see what is done there.
In most of the examples discussed in this chapter, the finished product is a smooth curve which resembles what we might have drawn if we had smoothed the raw data by eye; looking from the smooth back to the rough we could usually see the trend in the raw data.
Why bother smoothing?
Well, it can sometimes reveal patterns not immediately obvious to the naked eye; an example of this is shown in exercise 9.3.
It can make a story line clearer, which is always an advantage.
It can sometimes, for example, help reveal that two time curves are tracking together, as with the unemployment data in figure 6.1 for example (where two curves with different scales were superimposed), or with past and future perceptions of the economy in panel (b) of figure 9.14.
All powerful tools can be misused, of course.
It is always worth having a look at the roughs plotted over time, and thinking hard about what has been discarded in the smoothing operation.
Moreover, there is a danger than data that presented very little pattern originally can be smoothed into an artefactually interesting story; exercise 9.4 has been designed to enable you to explore this point.
But, for the data analyst who is prepared to use judgement as well as arithmetic, smoothing can clarify many otherwise ragged situations.
Exercises
9.1
Smooth the data on negative perceptions of household finances in the past (column 3 of figure 9.5).
Try to plot the result on approximately the same scale as figure 9.10 so that you can compare the result with the economy in general.
Discuss your results.
(A very similar series over a longer time span can be found in the dataset ECONOMY.)
9.2
Most of the evidence about whether industrialism raised or diminished the living standards of the working class has centred on the wages and prices prevalent at different periods, data which is patchy and hard to interpret.
In an inspired contribution to this debate, Floud and Wachter (1982) ask what happened to the heights of working class people in this period.
A complete set of records has survived which shows the heights of recruits to the Marine Society, a charity which trained young boys for the navy.
The authors wanted to estimate the mean height of the population from which recruits were drawn.
Unfortunately, the Society would not accept boys below a certain minimum height, and this minimum varied over time.
They therefore estimated the missing lower end of the distribution of heights on the assumption that the whole distribution was Gaussian in shape (see Wachter 1981).
The values for fifteen year olds are given in the accompanying table.
Ignoring the problem that the time intervals are not equal, smooth and plot the series.
What can you say from the result about the effects of early industrialism on the physical health of the working class?
9.3
The dataset SCOTLAND shows the rate of stillbirths in Scotland in the period 1944 to 1983, broken down by social class.
Using Minitab, plot the rates in classes I and V, then smooth them and plot them once more.
The Minitab resistant smoothing command is RSMOOTH; the default smoothing recipe is not identical to the one explained in this chapter.
Plots can be drawn on the same picture using the instruction MPLOT.
Then calculate a measure of the differential between these two classes, smooth it and plot it once more.
9.4
In the previous exercise you may have discovered that social class V had between 150 and 250 per cent as many stillbirths as social class I. Using Minitab instruction IRAN, create a column of random data in the range 150 to 250.
What should happen if you smooth this?
Try it out several times, and compare results with your friends.
What do you find?
Appendix: opinion polling in Great Britain
Opinion polls represent only a small fraction of all the social research which is conducted in Britain, but they have become the public face of social research because they are so heavily reported: on average there is at least one poll story in each copy of every national or local newspaper in Britain.
Predicting who is going to win an election makes good newspaper copy.
The newspaper industry was therefore among the first to make use of the development of scientific surveys for measuring opinion.
In all general elections in Britain since the Second World War, polls have been conducted to estimate the state of the parties at the time, and the number of such polls continues to grow.
By-elections and local elections are now also the subject of such investigations.
For most companies, political opinion polling is a way to get their name known, but the bread and butter of their business comes from market research.
Opinion polling is closely linked to the newspaper industry; National Opinion Polls Ltd (NOP) is owned by Associated Newspapers, for example, and Gallup earns an important part of its income through a contracted column for the Daily Telegraph .
The political loyalties of the different companies are also well known: Harris works for the Conservative Party, while Market & Opinion Research International (MORI) is usually chosen by the Labour Party.
The interviewers who work for market research companies are usually women who wish to work part-time.
They are trained on short training sessions run by the individual companies.
Many interviewers, however, work for more than one company, which makes it hard for any individual company to implement standards different from the rest.
Opinion polls in Britain are almost always conducted on quota samples .
In such a sample, the researcher specifies what type of people he or she wants in the sample, within broad categories (quotas), and it is left up to the interviewer to find such people to interview.
In a national quota sample, fifty constituencies might be selected at random, and then quotas set within each constituency on age, sex and employment status: interviewers would then have to find so many women, so many unemployed and so many young people.
In the better quota samples, such quotas are interlocked : the interviewer is told how many young housewives, how many male unemployed and so on to interview.
The idea is that when all these quotas are added together, the researcher will be sure that the national profile on age, sex and employment status will have been faithfully reproduced.
Many people have doubts about such sampling methods.
Interviewers are bound to seek out co-operative people, those who are not very busy and so on, thus inevitably leading to biases.
It is not always easy to get up to date information on which to set the quotas, especially in a small area sample.
The result is only representative on those variables selected for the quota, and may be quite unrepresentative on other factors.
Little research has been done into the problems generated by quota sampling since studies over thirty years ago pointed up some major problems (Moser and Stuart 1953; Stephan and McCarthy 1958).
The major defence pollsters give is that quota samples generally predict the outcome of elections pretty well.
There are three important compendiums of opinion polling results.
Gallup's findings can be obtained from the Gallup Political Index .
NOP also publish a monthly digest of their findings:NOP Political and Economic Bulletin .
And MORI produce a monthly summary of the results of their own surveys and those of others, called British Public Opinion .
All of these are obtainable from the company upon payment of a fairly hefty subscription.
The latter two are formally published periodicals, and should therefore be obtainable through libraries.
All three deposit their surveys at the ESRC Data Archive at the University of Essex, but the data arrives in a form that can be quite hard to read, and it can take several months for the Archive to be able to supply even small amounts of the raw data in a form usable on most college computers.
Scatterplots and Resistant Lines
Introduction
The British National Health Service set out to provide health services to everyone free of ‘limitations based on financial means, age, sex, employment or vocation, area of residence or insurance qualification’(NHS Bill 1946).
Before the NHS was established, critics had noted that the ‘inverse care law’ seemed to apply: those regions in which the need for health care was the greatest had the fewest resources.
After the first thirty years of operation of the NHS, however, there had been disappointingly little change; in 1976, the Court Report noted that the variations in regional provision of service were still much the same as they had been in 1948 when the NHS began.
A new initiative was launched to address the problem, to try to reverse the inverse care law.
The Resources Allocation Working Party (RAWP) was set up with a brief (RAWP 1975: 5): To review the arrangement for distributing NHS capital and revenue…with a view to establishing a method of securing, as soon as practicable, a pattern of distribution responsible objectively, equitably and efficiently, to relative need.
The recommendations of the Working Party have been used as the basis for financial allocations to the Health Service regions since 1977.
They were implemented, however, at a time of general recession and reduction of public expenditure; critics accused the report of hiding cuts behind egalitarian language.
The idea of determining resources according to need was only applied to the division of resources between regions, never to the total amount of resources to be allocated.
Money was redistributed from London and Oxford to the North; the report was welcomed in the North and criticized in London and Oxford (Radical Statistics Health 
Group 1977).
In this chapter, some of RAWP's calculations and assumptions will be investigated.
The methodological focus of this chapter is to learn techniques for dealing with the relationship between two interval level variables; such data is often called paired,X -Y data, since for each case we have a pair of values which we want to display together.
We shall learn how to construct a suitable display and how to interpret it and summarize it effectively.
Chapters 1 and 2 are essential reading for understanding this chapter, and chapters 3 and 6 are also useful background.
Scatterplots
To depict the information about the value of two interval level variables at once, each case is plotted on a graph known as a scatterplot , such as figure 10.1.
Visual inspection of well-drawn scatterplots of paired data can be one of the most effective ways of spotting important features of a relationship.
Figure 10.1 A scatterplot showing a moderately strong relationship
A scatterplot has two axes — a vertical axis, conventionally labelled Y and a horizontal axis, labelled X .
The variable that is thought of as a cause (the explanatory variable) is placed on the X -axis and the variable that is thought of as an effect (the response variable) is placed on the Y -axis.
Each case is entered on the plot at the point representing its X and Y values.
Effective plotting requires practice, and achieving a good  result can take time; the appendix to this chapter describes some of the ways in which plots can be improved.
Scatterplots depict bivariate relationships.
To show a third variable would require a three-dimensional space, and to show four would be impossible.
However, the value of a third nominal variable can often usefully be shown by using a different symbol for each value of a third variable.
(Minitab achieves this by means of a letter plot.)
Scatterplots are inspected to see if there is any sort of pattern visible, to see if the value of Y could be predicted from the value of X , or if the relationship is patternless.
If there does appear to be something interesting going on, there are several useful questions that can be asked next:
1
Is the relationship monotonic ?
In other words, does Y rise or fall consistently as X rises?
The relationship in figure 10.1 is monotonic.
A U-shaped relationship would not be.
2
Are the variables positively or negatively related?
Do the points slope from bottom left to top right (positive) or from top left to bottom right (negative)?
3
Can the relationship be summarized as a straight line or will it need a curve?
4
How much effect does X have on Y ?
In other words, how much does Y increase (or decrease) for every unit increase of X ?
5
How highly do the variables correlate ?
In other words, how tightly do the points cluster around a fitted line or curve?
6
Are there any gaps in the plot?
Do we have examples smoothly ranged across the whole scale of X and Y , or are there gaps and discontinuities?
Caution may need to be exercised when one is making statements about the relationship in the gap.
7
Are there any obvious outliers?
One of the major goals of plotting is to draw attention to any unusual data points.
In this chapter we shall investigate the answers to some of these questions in an example drawn from a debate about health policy.
Indicators of health need in England and Wales
Two different types of indicator are customarily used by health policy-makers when planning and evaluating health services: input and output measures.
On the one hand, attention can be focused on inputs : resources, both financial and human, that are devoted to health.
The indicators that are traditionally used are the money spent on health care or the number of health workers per head of population.
On the other hand, one can look at indicators of the success of these resources, at output measures of the health of citizens.
The latter measures are much  more difficult to obtain, and relationships between them are the subject of this chapter.
In order to allocate funding for the different categories of health care, RAWP had to produce indicators of relative need in the different regions of England and Wales.
We shall examine how they arrived at an indicator of relative need for non-psychiatric hospital in-patient services (which accounts for over half of the total NHS budget).
The most important single indicator of need is crude population size; the Registrar-General's mid-year estimates of the population of each region were used.
Regions also differ, however, in the structure of their population.
Some have more old people (who make relatively heavy use of health services) and women of child-bearing age (who require maternity services) and so on.
RAWP therefore weighted the crude population size in each region to take account of its demographic structure.
The weights were derived from hospital bed utilization rates in each age-sex category; if, for example, elderly women accounted for three times as many bed-days as middle-aged men, they counted three times as heavily in calculating the weighted population total.
However, need for hospital services is not just a function of demography.
Regions differ in social, industrial and cultural ways which give rise to different patterns of specific disease.
A sensitive indicator of health need should reflect these disease patterns.
There are, however, formidable obstacles to collecting reliable information on morbidity (disease).
RAWP first used the treatment rates in various categories of disease, but later dropped this since they were strongly related to the availability of the treatment in the region, and thus risked confusing supply factors with need.
The authors considered several alternative indicators of health need, and opted in the end for standardized mortality rates (SMRs).
Essentially, these express the number of deaths occurring as a proportion of the number of people at risk in each region in such a way that they take into account the fact that regions have different age and sex distributions; their construction will be explained fully in chapter 14.
They calculated these standardized mortality rates for each cause of death, and then used them as weights in the allocation formula: areas with higher death rates from a particular disease got more money to treat that disease.
It is disease, however, not death, which is expensive.
It is therefore important to know how well death rates indicate disease rates; if the link is weak, this would be very significant to resource managers.
Data from the Third World suggests that it may be dubious: mortality is only a good indicator of the overall health of a population when infectious diseases are a major problem (US National Center for Health Statistics 1973).
Data on morbidity and mortality
The main conceptual tools of epidemiology are the incidence rate and the prevalence rate of disease.
The incidence rate measures how many new cases of a disease appear in a given period, whereas the prevalence rate measures how many cases in total exist, either at one point of time (the point prevalence rate), or in a fixed period (the period prevalence rate).
The distinction is analogous to that made in chapter 6 with respect to the unemployed — the number of new people who join the claimant count (the flow) versus the number unemployed at any one time (the stock)— and in chapter 5 with respect to income versus wealth.
The incidence rate is necessary for studying the causal factors associated with illness, but the prevalence rate is better at reflecting the cost of disease to a community.
With chronic diseases, in particular, it is important to have a good prevalence measure.
Respondents to the General Household Survey are regularly asked to report on their subjective state of health.
From these reports, we may identify a general category of the chronically sick : people who replied ‘yes’ when asked if they had a long-standing illness, disability or infirmity which limited their activities in any way.
The chronic sickness rate is a point prevalence rate, telling us how many people report long-standing health problems at one point in time.
This morbidity measure can be used to provide a limited test of the RAWP assumption.
Figure 10.2 contains some paired data for all the regions of England and Wales, showing their morbidity and mortality rates.
The morbidity rates were originally drawn from the General Household Survey and the mortality rates from the Registrar-General.
Since the mortality rates are standardized by the age and sex structure of the region, the illness measures in figure 10.2 have been similarly standardized.
Figure 10.2 Standardized mortality and morbidity rates 1972–3
The data relates to overall death and sickness rates, whereas disease-specific SMRs were used in the RAWP formula.
However,
RAWP themselves used similar data to validate their claim that death rates were good predictors of sickness.
This particular dataset covers two years where RAWP used only one in their validation exercise, and was compiled for an article in the Lancet which was critical of the RAWP formula (Forster 1977).
Linear relationships
The scatterplot of the chronic sickness rate by the death rate is shown in figure 10.3; the pattern is not terribly tight, but inspection of the plot suggests a monotonic, positive relationship.
Figure 10.3 Regional sickness rate by mortality rate: scatterplot
In order to summarize the relationship between two interval-level variables, we will try to fit a line if we possibly can.
When describing the apparent relationship, instead of making the somewhat vague generalization ‘the higher the X , the higher the Y ’, the linear summary permits a more precise generalization ‘every time X goes up a certain amount,Y seems to go up a specified multiple of that amount’.
Straight lines are easy to visualize geometrically, but they can also be expressed algebraically.
Equations of the form: always describe lines.
In this equation,Y and X are the variables, and a and b are coefficients that quantify any particular line; figure 10.4 shows this  diagrammatically .
Figure 10.4 Anatomy of a straight line
The degree of tilt or slope of the line is given by the coefficient b ; the steeper the slope, the bigger the value of b .
The slope is usually the item of scientific interest, showing how much change in Y is associated with a given change in X .
The intercept a is the value of Y when X is zero, or where the line starts.
Frequently, the intercept makes little substantive sense — a mortality rate of zero is an impossibility, for example.
If it is important to avoid a meaningless intercept for any reason, one could add or subtract an appropriate constant from all the X s; interested readers can follow the idea up in Mosteller and Tukey's text (1977: 58–61).
The slope of a line can be derived from any two points on it.
If we choose two points on the line, one on the left-hand side with a low X value (called X L ,Y L ), and one on the right with a high X value (called X R ,Y R ), then the slope is  If the line slopes from top left to bottom right,Y R -Y L will be negative and thus the slope will be negative.
We only want to try to run a straight line through a cloud of data points if the relationship looks linear.
Never try to fit a line before you have plotted the data to see if it is a sensible thing to do.
Where to draw the line?
Let us turn now to the relationship between the chronic sickness and mortality rates.
Inspection of the scatterplot suggested that it would be worth trying to fit a line; the task is to find one which will come as near as  possible to the data points.
A technique such as smoothing will not do because it does not ordinarily produce a linear outcome.
Figure 10.5 Running a line by eye through points in figure 10.3
Before considering how we might do the job mathematically, let us just draw in a line by eye, to go through the centre of the data points.
One possible line is shown in figure 10.5.
This line goes through two data points, the values for the Greater London area and for the rest of the South East.
This means that calculation of the slope is straightforward, according to the formula in section 10.4: it is given by finding out how much Y changes for a unit change in X , namely  We can now make a fairly precise summary statement: on average, 19 more people per 1000 are chronically ill for each death;(mortality was measured per 10,000, while illness only per 1000).
The slope can be thought of as a numerical expression of the strength of causal effect of one variable on another.
It can be modelled on a causal path diagram as shown, in exactly the same way as differences in percentages were in contingency data.
The slope of a line is directly analogous to a difference between two proportions: both tell us how much one variable changes for a given change in the other.
Now that the line has been fitted, the residuals tell us how actual chronic sickness rates differ from expectations formed on the basis of death rates; the West Midlands region, for example, has less chronic sickness than you would expect from its death rate, but East Anglia has more.
We are naturally led to ask why this should be; if we were happy with this line, the next step might be to examine the pattern of occupational or environmentally related diseases within each region to try to understand the pattern in the residuals.
However, drawing a line so roughly has its limitations: the eye can deceive and the heart may secretly desire a particular outcome.
It would be better to fit a line which met some predetermined criterion.
There are many different rules one could try to follow:
1
Make half the points lie above the line and half below along the full length of the line.
2
Make each point as near to the line as possible (minimizing distances perpendicular to the line).
3
Make each point as near to the line in the Y direction as possible (minimizing vertical distances).
4
Make the squared distance between each point and the line in the Y direction as small as possible (minimizing squared vertical distances).
The choice of criterion is a matter of judgement.
When drawing a line by eye, many people seem to try to follow rule 1 or rule 2.
The technique explained in this chapter, resistant line fitting, produces a line which makes the absolute value of the deviations in the Y direction as small as possible (rule 3).
Another very popular criterion for line-fitting is minimizing squared deviations from the line in the Y direction (rule 4); this technique is known as linear regression .
It is less resistant than the technique shown in this chapter.
Fitting a resistant line
The method of line fitting adopted in this chapter involves joining two typical points: the X -axis is roughly divided into three parts, conditional summary points for X and Y are found in each of the end thirds, and then a line is drawn connecting the right-hand and left-hand summary points.
We choose to use the outer thirds because we want the line to be drawn between two points as far away as possible without being so far out that they risk being unreliable.
Some data analysts prefer to use the outer quarters (Open University 1983); the larger the number of cases the less the decision matters.
In either case, the line thus calculated is only a first approximation, and will be tuned up, as we shall see in the next section.
Ordering and grouping
In dividing the X -axis, the aim is to get one-third of the cases into each of the three parts.
To do this, the cases are reordered so that the X values are in order, as shown in the first two columns of figure 10.6.
Notice that the corresponding Y value has been kept with each X , and the Y values are therefore not in order.
(Ignore the third and fourth columns for now.)
Dividing the X -axis into three is in principle straightforward, but in practice there are snags, especially where there are not many data points.
Here are guidelines which are usually helpful:
1
The X -axis should be divided into three approximately equal lengths.
2
There should be an equal number of data points in each third.
3
The left and the right batch should be balanced, with an equal number of data points in each.
4
Any points which have the same X value must go into the same third.
5 No subdivision of the X -axis should account for more than half the range of the X -values found in the data.
Since these rules are not always compatible, compromises will be needed.
In this example, the number of data points is not an exact multiple of three, so the second guideline could not be met; balance in the two outer batches has been preserved by putting three points into each of them them and four into the middle.
Obtaining the summary value
A summary X and Y value must now be found within each third.
The summary X value is the median X in each third; in the first third of the data, the summary X value is 109.5, the value for the other South East.
Similarly, the median Y in each third becomes the summary Y value, here 189.6.
This does not have to be the value paired with the summary value for X  , although in this instance it happens also to be the value for the other South East.
The summary X and Y values for each of our batches can be read off figure 10.6:
It is left to the reader to plot these points on figure 10.3, and to connect the first and third.
The middle summary point is not used to draw a straight line, but it should not lie too far from the line if the underlying relationship really is linear.
It can be used to provide a more systematic evaluation of  linearity.
The method involves calculating two half-slopes : the left-hand half-slope is calculated between the first and the middle summary point, and the right-hand half-slope between the middle and the third point.
If the half-slopes are nearly equal, the relationship is fairly linear.
If one is more than double the other, we should not fit a straight line.
Figure 10.6 Worksheet for calculating a resistant line
Deriving the coefficients of the line
The slope and the intercept could be read off a graph.
It is, however, quicker and more accurate to calculate them arithmetically from the summary points.
The slope is given by 
This is not very different from the slope of the eyeballed line.
The intercept is the value of Y when X is zero, a pretty meaningless value when X is a mortality rate, as we noted above; we just treat it as a scaling factor, needed to predict a given Y value from a given X value.
It is obtained by inverting the equation for a line; if Y = a + bX , then a = Y -bX .
Either the upper or lower summary X values could be used to find the intercept:a = Y R -bX R , for example.
But we shall get a more accurate estimate of the intercept if the mean of all three summary values is used:
Because we used the upper and lower summary points in finding the slope, the a L and a R estimates will always be the same.
The intercept is given by the average of 7.9, 13.7 and 7.9, i.e. 9.83.
The full prediction equation is therefore: Chronic sickness = 9.83 + (1.66 × Death rate) We would predict, for instance, that East Anglia, with a standardized death rate of 108.2, would have a chronic sickness rate of 9.83 + (1.66 × 108.2) or 189.4.
We can find such a predicted, or fitted, value, for each case.
The method is similar to that used in chapter 6, where we predicted the regional median unemployment rate for each local area within that region; the difference is that the prediction from a linear equation will only be the same for two cases if they have identical mortality rates.
The full set of predicted values is shown in column 3 of figure 10.6; the column is headed Ŷ (pronounced ‘Y-hat’), a common notation for fitted values.
In fact, East Anglia's sickness prevalence rate is 15.6 higher than the predicted 189.4, namely 205.
Residuals from the fitted values can also be calculated for each region, and these are shown in column 4 of figure 10.6.
NOW all the data values can be recast in the traditional DFR form: Data (205) = Fit (189.4) + Residual (15.6)
Inspection of residuals and polishing the fit
The residuals from the fitted values are obtained by subtraction, as shown in column four of figure 10.6.
They are displayed in figure 10.7.
We would always like residuals from a fit to be small and patternless.
Their size can be assessed by comparing them with the original spread in the chronic sickness rates; this will be discussed at length in the next section.
But can any more pattern be extracted?
As we saw in section 10.5, we are looking for a line which will make the residual Y s as small as possible.
Joining two crudely calculated summary points is unlikely to produce a line with precisely that property, especially  when, as here,N is very small.
The procedure is therefore iterated, and the final fit is converged upon slowly by repeating the process until the residuals are patternless — a procedure known as polishing the fit .
Figure 10.7 Residuals from line in figure 10.6
To do this, the residuals are next treated as new Y data, and the procedure of line fitting is repeated; the fourth column of figure 10.6 becomes the new column of Y s, the X s remain as they were, and the calculations are performed as before.
The new slope might be positive, in which case the new fit would be added to the old, or it might be negative, in which case it would be subtracted from the old.
The fit is polished as many times as it takes for the residuals to show no more evidence of a relationship with the X values — for the slope to be zero; the slope usually changes by gradually smaller and smaller amounts, and converges on a stable result.
The slope in figure 10.6 is not much changed after polishing, so the technique is illustrated in exercise 10.1.
Polishing the fit in this way is analogous to reroughing in the last chapter.
Many of the techniques of exploratory data analysis require the repetition of procedures to converge on a fit that minimizes the residuals; this can make the techniques rather laborious, but it is one side of the trade-off required to get methods of analysis which are resistant to outliers.
The procedure can, of course, easily be handed over to a computer.
The residuals can also be used to indicate whether we have fitted the correct functional form or not.
For this purpose, they are best plotted against predicted Y values.
If the relationship is mildly curvy, or if the spread of the Y values is not constant for all X values, this may stand out more clearly in the plot of residual Y versus fitted Y than in the original scatterplot.
What to do if the relationship is curved is discussed fully in the next chapter.
Predicting morbidity from mortality
Let us return now to the policy question: how well do death rates predict sickness, the condition that requires the cash?
Forster is right that the correlation between the variables is far from perfect; the data points are spread quite widely to either side of the line.
We want residuals to be small.
They represent the failures of prediction; the larger they are, the worse the fit.
But how are we to evaluate their size in any particular instance?
The general answer that we first came across in section 6.7 is: the residual spread should be small in comparison with the original spread.
In this case the residual d Q is 20 (figure 10.7), compared with an original d Q of 26 (derived from column 2 of figure 10.2); the spread has been reduced to around three-quarters its original size.
Is this a big reduction?
First consider two extreme cases which delineate the boundaries.
If the association was perfect, all the points would lie on the line, and there would be no spread in the residuals; 100 per cent of the original spread would be accounted for, and we would describe the two variables as being perfectly correlated.
If there was no relationship at all, the spread of the residuals would be the same as originally, and there would thus be no reduction; we would say that there was no correlation between the two variables.
Reducing the spread by 25 per cent is not a very dramatic reduction; it is nearer zero than 100 per cent.
So regional death rates do not predict regional self-reported sickness rates very well.
Critics of the decision to include death rates in the RAWP formula have implicitly argued that they should correlate nearly perfectly with sickness rates; in the light of such evidence, they have advocated dropping them (Forster 1977; Barr and Logan 1977).
However, an inadequate indicator may be preferable to no indicator; failure to include death rates in the formula would mean that funds were even less related to need than at present.
Perhaps self-reports of sickness should be substituted for death rates in the RAWP formula.
However, we have no guarantee that the sickness indicators themselves are reliable.
Moreover, attempts to classify self-reported data into disease categories are notoriously unreliable, and a disease-specific measure of need is required since the costs of treatment differ so widely.
Every currently available indicator of health need is inadequate in one way or another.
Treatment rates for different diseases reflect availability of the treatment rather than prevalence of the disease.
Self-reported sickness is of unknown validity and unobtainable within reliable disease categories.
Death rates seem not to be a very good indicator of disease rates either.
Is the attempt to distribute resources according to need therefore impossible?
Perhaps death rates will have to suffice until a  more serious attempt is made by health care professionals to ascertain the regional variations in disease independently of treatment.
Conclusion
In this chapter we have looked at the extent to which chronic sickness rates as reported on the GHS are predictable from death rates.
The full relationship was first examined by means of a useful pictorial device: the scatterplot.
This relationship was next summarized by fitting a straight line.
The strength of the association between the mortality and morbidity was given by the slope of this line, indicating how much sickness goes up for each point increase in the death rate.
The spread in overall sickness rates was compared with the spread in residual sickness rates to obtain a measure of the degree of correlation around the line.
Those who have been exposed to the confirmatory techniques of linear regression may recognize the analogous measures.
In regression, the criterion for line fitting is to minimize squared residuals, the ‘least-squares’ rule 4 of section 10.5.
It is the variance, not the midspread, which is broken down into a fitted (‘explained’) and residual (‘unexplained’) component.
The correlation is given by the Pearson's correlation coefficient r .
Regression techniques have their advantages: the lines can be derived in one fell swoop from a formula, and do not require iterating.
Moreover, if the residuals are well behaved (Gaussian, without freak values) then the calculation of the likely error associated with the coefficients is fairly straightforward.
However, error terms are often highly non-Gaussian, and outliers from the line are the rule rather than the exception.
Regression techniques, because they set out to make the squared distances of the residuals from the line as small as possible, can be unduly influenced by a few exceptional data points.
They are therefore much less resistant than the techniques introduced in this chapter.
The slope,b , is mathematically very close to the proportion difference,d .
It is an asymmetric measure, just like d : the slope depends on which variable is treated as the response variable, just as d depends on which way the percentages have been run; exercise 10.2 has been set to illustrate this.
Symmetric methods of line fitting exist, such as principal components analysis and factor analysis, which summarize the extent to which two variables cluster together (rule 2 of section 10.5), but they are not covered here.
In the third part of this book we shall introduce various data analytic techniques to control for the effect of a third variable.
There will not be the space, unfortunately, to extend the methods introduced in this Chapter, and to show how to summarize linear relationships between three variables.
However, the principle is straightforward.
The residuals from the fitted line can be thought of as values for a variable which have  been adjusted to take the explanatory variable into account.
If we want to assess the relationship between X and Y but are worried that both are associated with a third variable,Z , whose effect we therefore wish to control, we adopt a two-stage procedure.
First we fit a line to Y -by- Z and X -by- Z , and calculate the residuals from each line.
These residuals are then the new X and Y values controlling for Z , and we can fit a line to the relationship between residual Y versus residual X .
Exercise 11.5 is designed to give you an idea of how this might work.
Exercises
10.1
A key assumption in economics is that money can be used to buy things that satisfy people's wants and make them happy (‘utilities’).
Surveys within different countries seem to confirm this; the wealthier people in those countries are actually happier than the poorer.
The following data, assembled by Easterlin (1974:105), however, examined the relationship across various countries from surveys conducted around 1960; the personal happiness rating was the average reply to a scale where 0 indicated that respondents were very unhappy and 10 that they were very happy.
If money can buy happiness, what would you expect the relationship between the two variables to look like?
Plot the data points  and discuss the apparent relationship.
Then calculate a resistant line and find the slope and intercept.
How well does the line summarize the scatterplot?
Polish the fit and adjust your estimate of the slope.
10.2
Plot the two variables in figure 10.2 the other way round from the plot in figure 10.3, as if one wanted to predict the mortality rate from the chronic sickness rate.
Draw in a line by eye, read off the slope and intercept, and confirm that the line is different from the line fitted in the chapter.
10.3
It is hard to assess the IQ of young children.
Rather than set formal tests, some researchers prefer to base their inferences on the child's performance on less formal tasks; the Goodenough draw-a-man test, for example, scores how sophisticated children's pictures are.
Other researchers have criticized this test for being insufficiently rigorous.
The dataset EDUCATE contains the results of the Goodenough test at age 7 and standard tests of verbal and non-verbal ability at age 11.
Plot non-verbal ability at age 11 against the Goodenough test scores, fit a resistant line, sketch the line on the plot and decide how well you think the Goodenough test at 7 predicts non-verbal ability at 11.
You will need to use Minitab instructions PLOT and RLINE for this exercise.
Appendix: guide to effective plotting
Some general suggestions about how to present numerical material clearly, about labelling, definitions and so on, were given in the appendix to chapter 7.
In this appendix, some further consideration is given to how to draw clear and informative pictures of data (scatterplots and bar charts in particular).
The tool-kit 
A pencil is the first prerequisite, so that the inevitable errors can be rubbed out; softer leads need sharpening more often but stand out better.
You will find different coloured pens useful.
Rulers should be perspex so you can see underneath them as you rule; check the edges are smooth.
Graph paper is essential.
It is of very varied quality; look for paper ruled into divisions of ten, and with every tenth line ruled heavy and every fifth medium.
If the grid lines are printed in blue they will not show up so clearly when the plot is photocopied (which is usually an advantage).
In an emergency, tear a sheet from a pad of lined paper, turn it on its side and slide it under the next sheet.
Special types of graph paper can be useful in different circumstances.
Divisions into twelve are invaluable when plotting monthly data (and a nuisance otherwise).
If you are plotting something which requires a log transformation, graph paper exists which enables you to plot directly on to a log scale (as shown in figure 11.6).
A variable that has three categories (such as three parties' share  of the total vote) can be represented on triangular graph paper.
Probability graph paper exists to show the extent to which a distribution deviates from the Gaussian shape.
It takes a bit of time to learn to use these more specialized sorts of graph paper but it is worth the effort.
There are many aids to make plots look more professional: devices for lettering, for drawing smooth curves, for stippling and cross-hatching areas with different patterns.
There are also different kinds of drawing boards which will hold the paper firmly down and provide moving X and Y axes.
You should browse in your local art shop.
Drawing the axes
Ensure that the axes are long enough to cover the whole range, or be prepared to omit points from the graph.
You do not have to draw each axis to the zero point, but you must label each axis clearly to show what you have done.
Altering the scale of the axis can quite dramatically affect the appearance of a plot.
When constructing scatterplots, make the Y -axis one-half to two-thirds the length of the X -axis; as a guide, think of exercise paper, which is usually of these dimensions, turned on its side.
Don't use awkward subdivisions of the scale; stick to units, twos and fives; computers can calculate accurately how to plot on scales rising by sevens but you will make mistakes.
Label the axes and their units of measurement.
When you are doing the first draft, label as many points on the axes as possible.
Plotting the points on a scatterplot
Plot each point carefully, using a symbol such as a cross; if more than one point lands on the same spot, you could plot the number of points represented (i.e. the numeral 2 if two points are superimposed).
Inspect the result and decide if it would look better if you stretched or shrunk the scale.
Drawing a bar chart
Arrange the bars in some sensible order, such as in order of their lengths.
There is no special significance to the width of bars, but it should be uniform.
A good rule of thumb is to make the spacing between the bars one half of the width of the bars.
The bars should be solid, not just drawn in outline.
Bar charts are sometimes drawn vertically in columns.
In general, however, labelling the categories is easier if they are arranged horizontally.
Back to back bar charts can be used as back to back stem and leaf displays were to compare two distributions.
The bars may be subdivided to show the components of a second variable within categories of the first.
Displaying the results
Smart presentation of results should always be done on plain paper.
If it is thin enough you will be able to trace the outlines of a plot originally drawn on graph paper.
Trace the axes, but only mark sufficient points on the scale to enable the magnitudes to be assessed.
A small number of faint grid lines (or lines of white  space on solid bar charts) may sometimes be added if it is important that the reader should be able to gauge precisely the level of particular points.
Hand or computer ?
The plotting routines available in most statistical packages are still rather crude, especially those which rely on the line-printer as their printing device; plots on machines designed for text mean that the resolution (i.e. number of subdivisions possible on either the horizontal or vertical axis) is usually poor; many values that are in fact different can end up being plotted on the same point.
Specialized software and hardware for plotting is improving all the time; there are several acceptable purpose-built packages now available, especially for drawing bar charts and circular pie charts.
However, it is important to learn how to plot by hand.
Many decisions about how to display the data have to be standardized within a package, and they do not always lead to sensible or pretty results.
Consult Velleman and Hoaglin (1977) for a useful discussion of the problems of computer plotting, especially of EDA techniques.
Further reading
The classic work on plotting and graphs used to be a textbook by Carl Schmid (1954), which is still worth consulting.
It began life as an appendix to a pre-war American survey textbook, and then ran into several editions in its own right.
There are also some useful and amusing guidelines in Darrell Huff's perennial best-seller How to Lie with Statistics (1973).
More recently, Edward Tufte has published a masterly compendium on graphics (1983).
It is on the one hand full of practical hints about all aspects of plotting, with many clear examples.
But it also provides something of the history of graphics, and the visual principles which have gradually evolved to which the technical artist should adhere.
Tufte divides the ink marks made to present a graphical display into two: data ink and chartjunk.
His entire book is devoted to ways of improving the proportion of the ink that is devoted to conveying aspects of the data, and of erasing chartjunk; this leads him to suggest some simplification of boxplots, for example.
Transformations
We now shall take up an issue that has been touched on several times before: power transformation of the scale of a variable in order to make its analysis easier.
This chapter has been placed after chapter 10 since one of the most appealing uses of such transformations is to unbend curvy lines.
However, it follows on very naturally from the issues raised in chapter 3, and some may want to read it directly after that.
Some of the illustrations require understanding of boxplots, introduced in chapter 6, and line fitting, introduced in the previous chapter.
The wealth of nations
The stated goal both of leaders of poor nations and of agencies and banks in the richer countries is the ‘development’ of the poorer countries.
The nature of that development, however, has been a matter of some dispute.
National income, or its rate of growth, has most often been used in the West to indicate success.
To many poorer countries, however, the idea of turning into a replica of one of the industrialized countries, pursuing high money incomes and high growth rates as goals in their own right, appears neither feasible nor desirable.
In this chapter we shall first take a look at how the most commonly used measure of national wealth — gross national product (GNP)— is constructed, and consider the distribution of GNP across several countries.
We shall return to the question of whether GNP is in fact a good indicator of well-being later, and consider a newer approach which examines the extent to which the basic human needs of citizens are being met.
Most countries in the world attempt to monitor the total value of their output, or gross national product .
This can be defined abstractly as the sum of values of both final goods and services and investment goods in a  country.
Final goods are things that are consumed directly and not used to produce something else; if all goods were included in the estimate of GNP, then the cost of flour would be double-counted when the final cost of bread was included.
However, a final good is not easy to operationalize.
Logically, even consumption activities such as eating could be viewed as an investment required to sustain the producer; this is perhaps clearer in the case of the agricultural labourer's meal which is essential to production, than the executive's expense-account lunch which may actually impede it.
However, rules have been developed to standardize what is to be included in the definition of final product; meals, for example, are always included as final goods.
Goods and services which in some countries are circulated by being exchanged on the market are circulated by the state in others; health care and medicines are a good example.
It is clearly desirable that the amount that a nation spends on health be included in the estimate of GNP, so the total expenditures of the state as well as private individuals are included.
Moreover, part of a nation's wealth is spent on investment goods, and not on consumption goods; these are therefore also included in the calculation.
Two methods can be used to estimate GNP.
One can either directly estimate the value of all the final goods and services (a variant would be to estimate what every branch of production adds to  the value of the goods it uses as raw materials).
Or one can assess the earnings which are received by those involved in production, both wages and profits, interests and the like.
The job of the statisticians employed by government to produce national accounts is to piece together the picture as best they can, using both methods, and as much of the available data as possible.
Standard economics textbooks detail the accounting methods typically used (e.g. Samuelson and Nordhaus 1985) and the Blue Book Sources and Methods volume details the methods used in Britain (Central Statistical Office 1985).
A distinction is made between domestic and national product.
If one focuses on all the production that takes place within national boundaries, the measure is termed the gross domestic product (GDP).
If, on the other hand, one focuses on the production that is undertaken by the residents of that country, the income earned by nationals from abroad has to be added to the gross domestic product, to arrive at the gross national product.
In a country where most of the goods and services exchange for money, GNP can be defined and estimated fairly reliably, given sufficient care.
In countries where large proportions of goods and services are produced by those who consume them or are exchanged on a very small scale without coming to the market, estimates have to be made, and these are of varying accuracy.
‘We should ask national income estimators conceptual questions such as: which of the activities a farm family does for itself without payment, such as haircutting for example , have you  included in the national income?’, says a leading development economist (Seers 1979: 15).
GNP is commonly used as a measure of well-being of individuals in a country.
For this purpose, it is often expressed per head of population, which also brings problems of estimation.
Most countries organize censuses of their population on something like ten-yearly intervals, but not all do, and they certainly do not do them at the same point in time.
The quality of many of these censuses is low, and error rates of 20 per cent are not unusual.
Moreover, population size changes and thus the errors are not constant.
In order to compare the GNP of different nations, the income has to be expressed in a common currency unit.
US dollars are conventionally used, but the method of conversion to that scale is problematic.
The World Bank method, used in the data in this chapter, is based on official exchange rates.
This leads to biases in estimation of GNP when the official exchange rate over- or under-values that country's currency.
In some cases where the discrepancy between the official and black market rates is very marked, the World Bank declines to publish GNP statistics.
There are therefore many problems in measuring GNP.
The value of the statistics from poor countries which have neither a large statistical staff nor routine data collection activities is often especially questionable.
The World Bank does its best to adjust the estimates made by the individual countries for comparability, but the process is inevitably inexact.
The distribution of GNP per capita Let us now consider the distribution of GNP in a sample of countries in the world, as shown in figure 11.1.
The boxplot of the distribution of GNP per capita is shown in figure 11.2.
The distribution of incomes across countries looks similar to the distribution of incomes one finds within a country: it straggles upwards, the midspread is above the median, the mid-extreme is above the midspread, the lower whisker is very short and there are upper outliers.
There are relatively few countries at the top of the spectrum: uncomfortably many have per capita incomes that are very low indeed.
If we consider the boxplots of GNP per capita for all the countries in the world, broken down into different country groups (figure 11.3), they also straggle upwards, in data batches at different levels, with different midspreads and shapes.
One reason for the upward straggle is the existence of a floor of zero dollars below which no country can fall (in theory), whereas there is no ceiling.
Moreover, the batches form a characteristic wedge shape: batches with lower medians have lower midspreads, and those with higher medians have higher midspreads; this is always a tell-tale sign that a transformation might be in order.
Figure 11.1 GNP per capital in 1984 in 15 sampled countries
Figure 11.2 The distribution of GNP per capita in 1984: boxplot
Figure 11.3: Distribution of GNP per capita in 1984 within country groups
The upward straggle of income distributions is, in one sense, a truth about the world that we must not obscure.
It does pose difficulties for the data analyst, however.
Differences at the lower end of the scale are obscured by the massive differences at the top end.
Multiple boxplots such as those in figure 11.3 are hard to summarize succinctly: not only do typical income levels in each group vary, but the spread and shape also vary.
Finally, if income were plotted against another interval level variable, the relationship would almost certainly be curved rather than straight.
In this chapter, we shall consider a family of transformations of the scale of measurement which help make the variables easier to handle in data analysis.
The log transformation
We have met one of these transformations — the log transformation already.
Taking logs of a dataset has the effect of counteracting upward straggle.
Figure 11.4 shows what happens if we take a logarithm of every  number in figure 11.1; the resulting shape is shown in figure 11.5.
The higher values have been pulled down towards the centre of the batch, bringing Kuwait and Sweden into the main body of the data, and the bottom of the scale has been stretched out correspondingly.
The shape is now more symmetrical.
Figure 11.4 Logging the numbers in figure 11.1
It was not necessary to transform every single data value in order to draw the boxplot in figure 11.5; it was sufficient to transform the median, the quartiles and the extremes, and to recalculate the midspread and adjacent values.
Only order-based summaries such as medians can be transformed in this way; it is not the case that mean (log X ) is the same as log (mean X ), for example.
There is an even easier way to see if the log transformation would help promote symmetry.
Graph paper exists which has equal divisions along one axis and logarithmic divisions along the other.
Raw data can be plotted straight on to such paper, as shown in figure 11.6.
Care has to be taken with the adjacent values, which cannot be obtained by reading off distances on the graph paper; they must be obtained arithmetically.
Log paper comes in several numbers of cycles ; the specimen in figure 11.6 contains three cycles, allowing the highest number to be as much as 10 3 or 1000 times as high as the smallest; four cycle paper would allow it to be as much as 10 4 or 10,000 times as high.
The principles of logarithms were discovered in the seventeenth century; they gave a tremendous technical spur to navigation, astronomy and to the growing commercial sector, facilitating tedious calculations, like nineteen months' interest at an annual rate of 2.79 per cent.
In the  days of calculators and computers, we no longer use log tables to speed up hand calculations.
But logs have a vital role to play in data analysis, providing one of the most useful ways of re-expressing data that straggles upwards.
As we saw in chapter 3, logs convert multiplicative processes into additive ones, since log (ab ) = log (a ) + log (b ).
Whenever we work with data values that have been generated by a growth process, we will have a better chance of revealing regularities in their behaviour if we convert them first to logs.
Figure 11.5 Logging GNP per capita in 1984 in 15 selected countries
The ladder of powers
Figure 11.6 Distribution of GNP per capita: plotted on three-cycle log graph paper
Not all variables straggle upwards, however.
Consider life expectancy, a measure indicating the number of years a newborn infant could typically be expected to live if patterns of mortality prevailing for all people in the year of its birth were to stay the same throughout its life.
The distribution  of life expectancy across countries is not symmetrical: the lower half of the distribution is more spread out than the upper half (figure 11.7); many countries are pushing up against what looks like some kind of a ceiling of around seventy-seven years, while some poorer countries trail down in the forties and two countries (Sierra Leone and Guinea) even  and leaf display of raw data register a staggering thirty-eight years.
A log transformation of the life expectancy distribution would make the downward straggle even more pronounced, since logs have the effect of stretching the bottom end of any scale.
Figure 11.7 Life expectancy in the world in 1984: stem
Figure 11.8 Life expectancy in the world in 1984: boxplots of raw and transformed data
There is a general family of power transformations that can help promote symmetry and sometimes Gaussian shape in many different data batches.
Look what happens, for example, when the life expectancy in each country is raised to powers greater than one (figure 11.8).
Squaring the values makes the batch slightly more symmetrical, and cubing them  even more; the effects are not dramatic, but the improvement is visible.
The effect is the opposite to taking logs: squaring stretches out the upper values and compresses the lower ones, and cubing does so even more powerfully.
Both transformations keep the data points in the same order, just as logging did.
There are an infinite number of possible powers to which data can be raised.
The commonest values are shown in figure 11.9, placed, as Tukey suggests, on a ‘ladder’ in terms of their effect on distributions.
There are many other points besides the ones on this ladder of powers , both in between the values shown and above and beneath them, but we shall rarely have any need to go beyond those shown.
Figure 11.9 The ladder of powers
Since these transformations must preserve the order of the data points, all the transformations which are powers of less than zero are multiplied by—1.
The transformation is then strictly the negative reciprocal and not the reciprocal; otherwise, the order of 2 and 3 would be reversed, as the reciprocal of 2 (0.5) is larger than the reciprocal of 3 (0.33).
If we start from the raw data values X 1 we can either proceed up the ladder of powers by squaring or cubing each number or down the ladder by taking square roots or reciprocals.
Going up the ladder of powers corrects downward straggle, whereas going down corrects upward straggle .
We went up the ladder of powers when we squared the data.
It was not far enough, as there was still downward straggle, so we moved further up the ladder to cubes.
What about the mystery exponent,X ?
Any number raised to the power of exactly zero is unity; clearly, it would be no help to make all the numbers identical.
But we can treat the zero exponent on the ladder of powers as the log, since its effect on the shape of data batches fits exactly at this point; it corrects upward straggle more powerfully than taking roots, but it is not as strong a transformation as the reciprocal root, or reciprocals.
There are two refinements to notice about power transformations.
In general, exact zeros cannot be transformed in this way (the log of zero is undefined), so it is conventional to add a very small amount (usually one-sixth or one-half) to all the values in a batch containing zeros before transforming.
The second problem comes with negative numbers.
If all the numbers are negative, the simplest thing is to multiply them all by –1.
If some are negative and some positive, it may be possible to add a constant to make them all positive, or it may be necessary to consider treating the positive and negative numbers separately.
The goals of transformation
The number systems we use as yardsticks should be thought of as being made not of wood but of elastic which can be stretched or shrunk to our convenience.
Transforming the original numbers by taking logs (or by one of the other transformations considered below) is an essentially trivial operation: the order of the numbers is preserved, and they can easily be recast in their original form by taking antilogs.
There is nothing God-given about any particular system of measurement; intelligent life on another planet might easily have evolved a method of assessing people's incomes which involved multiplying by a fixed amount for each increment.
Ideally, we should feel as comfortable working with logged GNP per capita or life expectancy cubed as we feel about working with the raw numbers.
However, it is reasonable to demand a more positive rationale for transforming data, especially as the resulting numbers seem so unfamiliar.
There are five principal advantages to be gained, listed below in rising order of importance.
1
Data batches can be made more symmetrical.
2
The shape of data batches can be made more Gaussian.
3
Outliers that arise simply from the skewness of the distribution can be removed, and previously hidden outliers may be forced into view.
4
Multiple batches can be made to have more similar spreads.
5 Linear, additive models may be fitted to the data.
Symmetry on its own is not very important, but the advantages of the Gaussian shape were discussed in chapter 3.
The third goal attempts to  focus the data analyst's attention on data points that are unusual for a substantive reason, not just because of the shape of the distribution.
Equality of spread in multiple batches promotes comparability between them; it is hard to summarize differences in level when spreads also vary.
Linear, additive models are easier to work with than more complex mathematical models.
The last two goals are the most important, and we shall consider them further in the following sections.
But it is often the case that, by finding a transformation that will promote equality of spread or linearity, it is possible to achieve the first three at the same time.
If these goals can be achieved, a loss of the intuitive appeal of the simple number scale will have been worthwhile.
For those who find it hard to work with or explain coherently to others a set of numbers which have been raised to a power or logged, Mosteller and Tukey (1977: 194) suggest a technique which they call ‘matched re-expression’ to rescale the transformed values to fall within the main range of the original number scale.
Promoting equality of spread
It is important for the spread to be independent of level in data analysis, whether fitting lines, smoothing, or dealing with multiple boxplots.
No simple statement can be made summarizing typical differences in GNP between the country groups in figure 11.3, for example, because they differ systematically in spread as well as in level.
A tell-tale wedge-shaped pattern appears in the multiple boxplots: batches with higher medians tend also to have higher midspreads, a sign that usually indicates the need for transformation.
Figure 11.10 shows the effect of taking logs on the distribution of GNP in the different country groups.
Logging GNP per capita goes a long way towards holding the midspreads constant by making them similar in size.
This means that statements can be made describing typical differences in wealth between the country groups without needing to mention the differences in spread in the same breath.
But, by transforming, progress has also been made towards the first three goals: the batches are more symmetrical and bell-shaped, and some of the outliers in the original batch were not really unusual values, but merely a product of the upward straggle of the raw numbers.
There are no far outliers in the logged distribution, and the outliers that remain do seem to differ substantively from the body of the data.
It was always debatable whether Turkey should have been included as a European country; its GNP suggests that it fits more comfortably with other Asian countries.
Libya's unusual wealth for an African country stems from the fact that it is an oil-producing country with a relatively small population.
This picture also says forcibly some other pieces of  information which we might perhaps not have guessed: that Portugal and Haiti are very poor countries, and that Trinidad is a very wealthy country, in relative terms.
Figure 11.10 Logged GNP per capita in 1984 by country group
It is not always easy to spot the fact that the spread increases as the level increases.
The fact may stand out in higher relief if the residuals are plotted against the fitted values.
We should be concerned whenever there appears to be a positive association between the level and spread (or between residuals and fitted values), whatever data analytic technique is being used.
Exercise 11.4 has been set to illustrate that the problem can occur with time series data and how transformations can help there also.
Alternatives to GNP as a measure of welfare
Before we look at the last goal of transformation, unbending curved relationships, it will be helpful to return briefly to the debate about the goals of development.
There are formidable problems in estimating GNP reliably in many countries of the world.
Even if these were surmounted, two fundamental questions would remain about using the average wealth of a country as an index of the well-being of its citizens.
First, as you discovered in exercise 10.1, while the wealthier members of any society claim to be more happy than poorer members of that society, the  cross-cultural association between the average amount of wealth in a country and the proportion who claim to be happy is extremely weak.
Moreover, the measure says nothing about how the wealth is distributed; a country could raise its GNP by expanding capital intensive industries which leave the poorest sectors of that society completely untouched.
Alternative indicators of well-being have therefore been sought.
Summary measures of inequality, such as quantile shares or Gini coefficients, are not available in enough countries, as you can verify in the WORLD dataset.
Moreover, measures such as the Gini coefficient treat inequalities at different points in the income distribution as equivalent, whereas many development economists have argued that the goal of economic aid should be to meet the basic needs of all the citizens in any country; this usually involves focusing on how well a society is doing by its poorest members.
While the logic of this ‘basic needs’ approach is appealing, there is still room for argument about precisely which needs are basic.
Many writers on welfare have viewed life expectancy rates as the most fundamental indicator of well-being in a society.
They have the advantage that they can be calculated for most countries in the world.
However, a country could have a moderately high average level, while some sections of society still had very short life expectancy.
Long life expectancy also indicates the success of development rather than the potential for it.
A case has also been made for using educational variables as an alternative.
Suggestions have included the proportion of adults who can read, or the proportion of females attending primary school; one can be sure that the higher either of these indicators go, the more the basic educational needs of all members of a given society are being met.
Moreover, an educated workforce is argued to be one of the important prerequisites for economic expansion and advance.
You can explore the relationships between some of the basic indicators published by the World Bank in the dataset WORLD.
Unbending curvy lines
In this section, we shall consider the relationship between life expectancy and national wealth in 1984.
(It is arguable that life expectancy in 1984 would respond to the prevailing GNP sometime in the past, but we shall ignore that refinement here.)
The scatterplot in figure 11.11 reveals a clear relationship between the two variables.
However, the relationship is curved; fitting a straight line will not provide a sensible summary.
Either a curve must be fitted, a job which is difficult to do well, or the data must be manipulated so that a straight line becomes a good summary.
Logging GNP per capita and cubing life expectancy did the best job of promoting symmetry and Gaussian shape in these two variables taken  individually.
The same transformations also help clarify the bivariate relationship (figure 11.12): the scatterplot is more nearly linear, the relationship is capable of easy summary, and previously hidden unusual values are revealed.
Figure 11.11 Life expectancy by GNP per capita in 1984
We fit lines whenever possible because they are simple, not only for our computers but also for our own brains.
If you prefer, however, you can think of fitting a line to transformed data as equivalent to fitting a curve to the raw data; in effect one is saying that the relationship between the two variables takes the form of a particular curve.
The curvy pattern in figure 11.11 was very clear, but sometimes, when the relationship is not so strong, it is hard for the eye to tell if a transformation is required.
A useful diagnostic guide is given by the half-slope ratio, introduced in section 10.6.
As a rule of thumb, we should explore the possible improvement of fit that a transformation would bring whenever the half-slope ratio is greater than 2.
The overall picture in figure 11.12 suggests that life expectancy can be predicted pretty accurately from a country's GNP: wealthy countries  have healthier populations.
GNP could be vindicated as a measure of welfare by this finding.
Its defenders have certainly been reluctant to give it up in the face of criticisms, for fear that ‘without it, the macro-economists would be adrift in a sea of unorganized data’(Samuelson and Nordhaus 1985).
Figure 11.12 Cubed life expectancy by logged GNP per capita in 1984
Life expectancy is still an average measure, however, and might conceal problems for some groups within wealthy countries.
And there are deviant countries.
It is clear from both the untransformed and the transformed plot that the oil-producing countries tend to have low life expectancies for their level of wealth.
Figure 11.12, also reveals that China and Sri Lanka have unusually high life expectancy rates for their low level of economic development, a fact that was not apparent before the transformation.
As we shall discuss in the next chapter, there is a lot more work to be done before the causal process underlying this relationship is laid bare: we do not know whether it is through buying a better diet or better medical care, for example, that richer countries improve their life expectancy.
(Exercise 11.5 casts some light on this.)
Determining the best power for transformation
There are many clues in the course of data analysis that suggest that it might be better to work on a transformed scale.
We have concentrated on the three most important diagnostic signs: upward or downward straggle in individual batches (figure 11.2), wedge-shaped data where batches with higher medians have greater spread (figure 11.3), and curvy lines in a scatterplot (figure 11.11).
Identifying the need for a transformation, however, does not tell us which one will do the best job of achieving the five goals mentioned above: so far we have guides to diagnosis but not to cure.
There are three different ways we can get such guidance: from our substantive knowledge of the world, by experimenting with the ladder of powers, and by constructing special diagnostic plots.
We may have a theoretical reason for believing that the variable we are studying will require a particular transformation.
We have already noted that a log transformation often helps when the data is the result of some process of growth.
The square root transformation will often work well in cases where the data is a rare occurrence, like suicide or infant mortality.
There are situations where the reciprocal of a rate would make more sense than the original rate: ergonomists, for example, might find it more natural to look at the time it takes a person to produce a fixed number of items rather than at the output a person produces from a machine in a fixed period of time.
In the absence of a rationale for a particular transformation (or in the face of competing rationales) the ladder of powers provides a useful guide.
When investigating a transformation to promote symmetry in a single batch, we first examine the midpoint summaries — the median, the midquartile, and the midextreme — to see if they tend to increase or decrease.
If they systematically increase in value, a transformation lower down the ladder should be tried.
If the midpoint summaries then trend downwards, the transformation was too powerful, and we must move back up the ladder somewhat.
We continue experimenting with different transformations from the summary values until we have done the best we can to promote symmetry and Gaussian shape.
In trying to unbend curvy lines, there is another way of deciding how to proceed on the ladder of powers.
Curves which are monotonic and contain only one bend can be thought of as one of the four quadrants of a circle.
To straighten out any such curves, first draw a tangent to see what you are trying to achieve.
Then imagine pulling the curve towards the tangent (as shown in figure 11.13).
Notice the direction in which you are having to pull the curve on each axis, and move on the ladder of powers accordingly: down in the Y direction? go down on the ladder of powers with Y , and so on.
To straighten the data in figure 11.13, for example, the curve has to be pulled down in the Y -direction and up in the X -direction; linearity will therefore probably be improved by raising the Y variable to a power lower down on the ladder and/or by raising the X variable to a power higher up on the ladder.
Figure 11.13 Guide to linearizing transformations for curves
If the curve is not a single bend, monotonic curve, power transformations will probably not straighten it out, though they may help.
As we saw in chapter 8, a logistic transformation can help straighten out a flat S-shaped curve (figure 8.5).
Transformations for more complex curves are rarely needed.
When there is a systematic relationship between the level of the batch and the spread of that batch, plotting the log of the d Q against the log of the median for each batch produces a useful diagnostic picture.
Tukey suggests that, if a line is sketched to fit the points,(1 -slope) will yield the power which should help promote equality of spread.
Thus, for instance, if the line had a slope of 1, a log transformation would be indicated; if the line had a negative slope, it would be necessary to raise the data values by a power of more than 1; if there is no relationship and the line has zero slope, power transformations are not likely to help.
(A similar way of finding the best power for transformation will be explained for median polishing in chapter 15.)
0 Conclusion
We have looked at the distribution of two variables in this chapter: an indicator of the monetary wealth of a nation, GNP per capita, and an indicator of the material standard of living of a nation, the average age to  which people can expect to live.
Neither variable was symmetrical in its raw form.
Altering the scale of measurement of each of these variables altered the shape of the distribution of each.
A general family of transformations — involving raising the data values to different powers was introduced as a guide to correcting straggle: if the straggle is downward, go up on the ladder of powers, and vice versa.
The log transformation was found to fit nicely at the zero position on the ladder of powers.
The main goal of transformation is not aesthetic, however.
The aim is to express numbers on a scale of measurement which makes data analysis easier, often by allowing simple models to be fitted, and thus enhancing our ability to understand the data.
In particular, we saw how such transformations can help make the d Q of different batches more similar, and help unbend curvy lines; the result in both cases is to enable the data analyst to re-express the data simply in the conventional form: data = fit + residual.
Power transformations are a very important part of the researcher's armoury; while the exponents of exploratory data analysis stress them (Tukey 1977; Mosteller and Tukey 1977), their use is applauded by many statisticians (e.g. Kruskal 1978).
Although it may take some practice to get used to the idea of changing the seemingly natural number scale, you will soon find that you automatically consider whether a transformation would aid analysis when you first look at a batch of data.
The most difficult problem comes with conveying the effect of transformation to lay audiences, who may be suspicious of statisticians ‘fiddling with the numbers’; someone might fear, for example, that by taking logs in figure 11.10 the real upward straggle in national wealth has been hidden.
Data analysts must not be put off using the best techniques available in case they are misunderstood, but they have an important responsibility to explain what they have done to try to ensure that misunderstandings do not arise.
For presentation purposes, this usually involves converting key elements of the analysis back to the original scale.
It may be possible to explain line fitting with transformed data in terms of fitting curves.
However we achieve it, great care must be taken to make the exposition clear to a non-technical audience.
Exercises
11.1
Using logs to the base 10 (see the appendix to this chapter), what is:
(a)
log (1)
(b)
log (0)
(c)
log (pqr )
(d)
log (p/q )
(e)
log (p n  )?
Write down the value of:
(f)
log 10 (2)
(g)
log e (2)
11.2
The validity of official statistics on suicide has often been questioned; some critics have claimed that different national suicide rates reflect the extent to which coroners in those countries are prepared to categorize deaths as suicide, rather than real national differences in propensity to suicide.
If the more extreme versions of the criticism were true, immigrants to a country should exhibit suicide rates similar to that country, rather than to the country they came from (Sainsbury and Jenkins 1982).
The following data shows the suicide rates per 100,000 of male Australian immigrants from various countries and the comparable native suicide rates.
Summarize the distribution in both batches.
Is a power transformation required?
How well do the immigrant and native suicide rates correspond to the native Australian suicide rate of 16.1?
11.3
Using the dataset TOWNS, identify a transformation that will pull in as many of the upper outliers in the town sizes in 1981 as possible without creating new lower outliers.
(You may wish to exclude sparsely populated local areas on the grounds that they do not qualify as towns.)
11.4
Plot the legitimate and illegitimate fertility rates in the SCOTLAND dataset on the same scale.
Describe the trends in both curves.
Then take logs of both variables and plot them again.
Does your description stay the same?
11.5
Using Minitab, read the WORLD dataset into the worksheet.
(a)
Find a transformation suitable for the number of people per doctor.
(b)
Plot life expectancy cubed versus number of people per doctor as transformed in (a).
Can you predict life expectancy from such an input health indicator?
(c)
Plot the number of people per doctor as transformed in (a) versus log GNP, fit a line to the relationship, and calculate residuals.
(d)
Repeat exercise (c) for life expectancy cubed versus log GNP.
(e)
Plot residual life expectancy versus residual number of people per doctor, as in (b).
Re-evaluate the extent to which life expectancy can be predicted by number of people per doctor when GNP has been controlled.
Appendix: powers and logarithms
Exponents
A number y can be raised to any power , say n .
This is written as y n  .
It means that we multiply y by itself n times.
The power n is called the exponent of y .
The most common exponents are two and three: squaring and cubing a number.
The principle is general, however, and any number, positive or negative, whole or fractional, may be used as an exponent.
Two other common exponents are 0.5 (taking square roots) and -1 (the reciprocal or 1/ y ).
The rules about manipulating exponents are as follows:
Logarithms
What is a log ?
The idea of logarithms is based on exponents.
Any positive number X can be re-expressed as 1O y  where y is the power that 10 must be raised to to obtain X .
When a number is re-expressed in this way,y is called the logarithm of X .
The log 10 of 3, for example, is the exponent of 10 needed to get 3.
It is therefore smaller than 1, because log 10 (10) is 1, and larger than 0, because log 10 (1) is 0.
Any positive number can be used as the base for logarithms; you can have logs based on 10, or 2, or 7, or 2.71828 (called e) and so on.
The two most common are log 10 and log e .
The latter are known as natural logs; the functional abbreviation is ‘LN’ in computerese.
Any two differ only by a multiplicative constant, so for data analysis, each is as good as any other.
How do logs undo a multiplicative process ?
The log of a product is the sum of the logs of the factors: log (abc ) = log (a ) + log (b ) + log (c ) Conversely, the log of a ratio is the difference of the logs of the numerator and denominator: log (a /b ) = log (a )-log (b )
What are some anchor points in the log 1O  scale ?
(Logs cannot be taken of negative numbers.)
How do you work out a log ?
The easiest way to find the log of a number is on a calculator: enter the number and press the LOG button.
If you haven't yet bought a calculator, you will have to look it up in either the old-fashioned log tables used for arithmetic calculations or in simplified ‘break tables’ of logarithms (see Tukey 1977).
Introducing a Third Variable
In the third part of this book, we consider ways of holding a third variable constant while assessing the relationship between two others.
In chapter 13 we discuss how this is done with contingency tables; in chapter 14 the technique of standardization is presented, and you learn how to construct a standardized mortality ratio; in chapter 15 the techniques of chapter 6, of decomposing variation into a fitted and a residual component, are extended to situations with two explanatory variables.
However, before proceeding to the techniques of controlling extraneous variables, we must devote a chapter to discussing the logic of the procedure.
Chapter 12 is devoted entirely to thinking about the causal issues at stake.
Causal Explanations
You will by now have developed some facility with handling batches of data, summarizing features of their distributions, and investigating relationships between variables.
We must now change gear somewhat, and ask what it would take for such relationships to be treated as satisfactory explanations .
Why did the chicken cross the road?
An explanation is a human construction.
It is an answer to the question ‘why?’
In everyday terms, a successful explanation is simply one that satisfies the person who asked the question.
Since people who ask questions about the world vary in their interests, curiosity and knowledge, what counts as a successful explanation is also likely to vary greatly.
The question ‘why?’ is notoriously ambiguous.
It can have many different kinds of answers.
Some are motivational: ‘in order to….’; some are causal: ‘because…happened first’; some are typological: ‘because it is an instance of…‘; some invoke the existence of a social rule: ‘because it is the custom’.
The type of answer required will be given by the answerer's perception of what it is that is making the questioner curious.
For this reason it is impossible to come up with universal rules dictating how explanations are to be provided.
However, scientific explanations are a very particular subset of answers to the question ‘why?’.
When scientists ask why something happens, they are asking for a general causal account.
If they were to try to give an answer to the question at the head of this section, they would probably try to give a general account of factors which encourage or discourage chickens from crossing roads.
Causes exist in the real world; they are not just human constructions to help us understand it.
They have been called ‘the cement of the universe’(Mackie 1974).
They are processes which, once started, end up producing a particular outcome at a later point in time.
To say that X causes Y is to say that, if X changes, it will produce a change in Y .
Some philosophers have tried to define cause in terms of statistical association, but such attempts have been unsuccessful; they are radically different concepts.
The time recorded on two different watches, for example, can be perfectly associated: the time on one of them can be correctly predicted from the time on the other, but not because the time on one of them causes the time on the other; altering the time on one of them would have absolutely no impact on the other.
Many different component causes can add together to produce a particular outcome, a process known as multiple causality.
Given this, we should not expect that the relationship between one cause among many and an effect to be perfect.
Much everyday reasoning about causes, however, seems to demand perfect relationships: ‘Smoking doesn't cause lung cancer; the man next door to us got lung cancer and he had never smoked a cigarette in his life’, implying that the only cast-iron proof would be for all smokers to get lung cancer and for no non-smokers to get
Some people get very upset about the idea that there might be any causes operating in the social world; they fear that causal influences on human action rob people of their freedom of choice and dignity of action.
This is a mistaken fear: if causes are the cement of both the natural and social universe, refusal to consider their existence will not stop them operating; it will merely mean that such causes are not uncovered, and, ironically, therefore will not be harnessed to give people greater control over and choice in their environment.
In fact, there is nothing to prevent us thinking of choice, intentions and motives in causal terms.
The stock in trade of the psychologist is to understand some of the causal determinants of motivations and to show when conscious intentions really do cause behaviour and when they do not.
Many different social sciences — economics, geography and sociology in particular— show how individually intended actions combine to produce social outcomes which may not have been the intentions of the actors.
Direct and indirect effects
Multiple causality means that two or more causes tend to work together to produce an effect.
Moreover, the variables contributing to the effect may themselves be causally related.
For this reason, we have to keep a clear idea in our heads of the relationships between the variables in the whole causal process.
In investigating the causes of absenteeism from work, for example, researchers have found different contributory factors.
We shall consider  two possible causal factors: being female and being in a low status job.
Let us construct a causal path diagram depicting one possible set of relationships between these variables.
Figure 12.1 Causes of absenteeism
The diagram in figure 12.1 represents a simple system of multiple causal paths.
There is an arrow showing that those in low status jobs are more likely to go absent.
Being female has a causal effect in two ways.
There is an arrow straight to absentee behaviour; this says that women are more likely to be absent from work than men, regardless of the kind of job they are in.
This is termed a direct effect of sex on absenteeism.
There is also another way in which being female has an effect; women are more likely to be in the kind of low status, perhaps unpleasant, jobs where absenteeism is more likely irrespective of sex.
We can say that being female therefore also has an indirect effect on absenteeism, through the type of work performed.
You can think of figure 12.1 as a real causal process, at the moment known only to God.
Controlling the world to learn about causes
It is one thing to declare confidently that causal chains exist in the world out there.
It is quite another thing, however, to find out what they are.
Causal processes are not obvious.
They hide in situations of complexity, in which effects may have been produced by several different causes acting together.
When investigated, they will reluctantly shed one layer of explanation at a time, but only to reveal another deeper level of complexity beneath.
For this reason, something that is accepted as a satisfactory causal explanation at one point in time can become problematic at another.
Researchers investigating the causes of psychological depression spent a long time carefully documenting how severe, traumatizing events that happen to people, such as bereavement or job loss, can induce it.
Now that the causal effect of such life events has been established, the  research effort is turning to ask how an event such as unemployment has its effect: is it through the loss of social esteem, through the decline of self-evaluation and self-esteem, through lack of cash or through the sheer effect of inactivity (Eales 1986)?
In order to answer such causal questions, careful observation of what goes on is simply not sufficient.
There was a celebrated individual who devoted a large part of his life to carefully recording everything that he observed; upon his death, this complete set of observations was presented to the Royal Society in the hope that it would be of use to scientists.
It was, of course, utterly useless.
Deliberate learning situations have to be constructed if we want to pin causes down and further our grasp on the world.
Central to the creation of such learning situations is the idea of control .
There are two ways in which scientists attempt to impose controls on the wayward world in order to learn.
The first involves controlling the setting of the research to prevent certain variables operating.
This is the method of the hard sciences like physics.
Unlike physicists, however, social scientists cannot easily construct social circuits from which the effect of sexual magnetism is just banished, for example.
The second type of control is therefore also necessary; it involves drawing inferences by comparing like with like.
Let us consider both types of control a little more fully.
Sometimes social researchers are not able to achieve any control at all over the research setting, and are forced to observe the world as it occurs naturally.
At the other extreme, they may decide they must contrive an artificial research setting in order to exclude the operation of unwanted variables.
There are a continuous set of possibilities in between, and the particular design chosen is a matter of judgement.
In a study investigating the effect of a particular teaching method on speed of learning, many factors could be held constant if a laboratory experiment were conducted — the identity of the teacher, the way the material was introduced and so on; a trial in real schools would be more realistic, but also more susceptible to the slings and arrows of fortune in the classroom.
Researchers who were interested in people's views on blood sports could either hang around waiting for respondents spontaneously to bring the subject up, or they could ask directed questions about this on a structured questionnaire, taking care to ask everybody exactly the same question.
A balance has to be struck, since too much control of the research setting can lead to situations that lack naturalism and to indicators that lack validity; for example, the results to structured questions on a topic may not reflect the views respondents would express in any other situation.
It is obviously desirable to obtain as much of this type of control as is consistent with naturalism.
Many people believe that it is the careful controlled setting of a laboratory that makes experiments very powerful situations in which to  draw causal inferences.
They are wrong; highly controlled settings can be achieved without any experimental manipulation.
What differentiates true experiments from non-experimental enquiries is the attempt, either in the laboratory or field, to produce an effect among groups which have been randomly formed; in the simplest experiment, the researcher deliberately alters the X values of an experimental group, and sees what effect this has on their Y values by comparing them with a control group.
Unlike the first type of control, which was a spectrum, the second type — the making of controlled comparisons — forms a natural dichotomy: controlled experiments and non-experimental enquiries.
In the former, the researcher can draw very strong inferences from comparisons between randomized groups.
The importance of their being formed at random cannot be overemphasized; control groups start life the same as experimental groups in all respects simply by virtue of having been formed at random.
When such preformed randomized control groups do not exist, inferences have to be drawn post hoc from comparisons between unrandomized groups.
The causal inferences that can be drawn from experiments are direct and unproblematic, at least in comparison with the inferences that can be drawn from non-experimental enquiries.
If randomized control and experimental groups end up substantially different, something that happened to them in the experiment almost certainly caused this.
If two uncontrolled groups prove to be different in some respect, we can only treat this as evidence of a causal relationship if we are convinced that they are not also different in some other important respect, as we shall
Do opinion polls influence people?
Let us take an example to illustrate the different inferences which can be drawn from experiments and non-experiments.
Some people believe that hearing the results of opinion polls before an election sways individuals towards the winning candidate.
Imagine two ways in which empirical evidence could be collected for this proposition.
An experiment could be conducted by taking a largish group of electors, splitting them into two at random, telling half that the polls indicated one candidate would win and telling the other half that they showed a rival would win.
As long as there was a substantial number of people in each group, the groups would start the experiment having the same political preferences on average, since the groups were formed at random.
If they differed substantially in their subsequent support for the candidates, then we could be almost certain that the phoney poll information they were fed contributed to which candidate they supported.
Alternatively, the proposition could be researched in a non-experimental way.
A survey could be done to discover what individuals  believed recent opinion polls showed, and to find out which candidates the individuals themselves supported.
The preferences of those who believed that one candidate was going to win would be compared with those who believed that the rival was going to win; the hypothesis would be that the former would be more sympathetic to the candidate than the latter.
If the second survey did reveal a strong relationship between individuals' perception of the state of public opinion and their own belief, should this be taken as evidence that opinion polls have a causal effect on people's voting decisions?
Should policy-makers consider banning polls in pre-election periods as a result?
Anyone who tried this line of argument would be taken to task by the pollsters, who have a commercial interest in resisting such reasoning.
They would deny that the effect in any way proves that polls influence opinion; it could, for instance, be that supporters of a right-wing candidate are of a generally conservative predisposition, and purchase newspapers which only report polls sympathetic to their candidate.
In short, comparing individuals in a survey who thought that candidate A would win with those who believed that candidate B would win would not be comparing two groups similar in all possible other respects, unlike the experiment discussed above.
An experiment would have a better chance of persuading people that the publication of opinion polls affected individual views.
It is, however, possible that the experimental data would not be thought conclusive either; most of the experiments that have been done of this type have been rather artificial (Marsh 1985a).
The famous social scientist, D. T. Campbell, once proposed a more naturalistic experiment, in which scores of towns would be selected and formed into two groups at random, the newspapers in each town would be persuaded to take part in the experiment by publishing phoney articles about the state of candidates, and comparisons would be made at the end between the two groups of towns (Campbell 1951).
It will come as no surprise to learn, however, that this experiment has never been conducted.
Experiments are strong on causal logic, which accounts for the enthusiasm some social scientists have had for them.
But the situations in which they can be carried out are few.
Some have tried to get round this problem by constructing small scale models of the world that they really want to study, simulating wars, prison situations and so on.
But only social psychologists who research aspects of small group behaviour have managed to achieve any kind of realism with such models.
For practical and ethical reasons, many interesting and important issues cannot be researched by experiments: the effect of low dosage radiation on human beings, of young maternal age on child abuse, or the effects of authoritarian upbringing on fascist political views, to name but three examples.
By and large, therefore, most social science data is non-experimental, and this leads to some challenging difficulties with the process of drawing causal inferences.
We cannot directly infer a causal effect from a statistical effect.
Assumptions required to infer causes
Does this mean that non-experimental data is useless for addressing causal issues?
Not at all.
It does mean, however, that the process of drawing inferences is more tentative than in experiments, based on if-then reasoning: if it is the case that the true causal story about the variables is as we imagine (playing God in the way that we did just now with absenteeism), then we would expect to find a statistical effect of X on Y .
Any effect discovered is merely consistent with these assumptions; it does not prove that they are true.
If it is not discovered, however, it is highly likely that there is something wrong with the assumptions; the data can certainly dampen over-enthusiastic imagination.
Researchers rarely conduct research with a finished model of the causal process they want to test in mind.
They usually build up to a God's eye view of the causal processes slowly, starting from a simple relationship, imagining how it might be more complex, testing to see if that is in fact the case, and so on.
This process is known as elaboration , and involves a fruitful interaction between theory and data.
Imagine a common situation.
A survey is conducted and an interesting statistical effect of X on Y is discovered.
There are two basic assumptions that have to be made if we wish to infer from this that X causes Y .
These involve the relationship between X and Y and other variables which might be operating; they are designed to ensure that when we compare groups which differ on X , we are comparing like with like.
Before giving an exposition of these assumptions, we need a bit more terminology: other variables can be causally prior to both X and Y ,intervene between X and Y , or ensue from X and Y , as shown in figure 12.2.
These terms are only relative to the particular causal model in hand: in a different model we might want to explain what gave rise to the prior variable.
Figure 12.2 Different causal relationships between variables
Let us discuss each of the two core assumptions in turn.
Assumption 1 X is causally prior to Y .
There is nothing in the data to tell us whether X causes Y or Y causes X , so we have to make the most plausible assumption we can, based on our knowledge of the subject matter and our theoretical framework.
There are some rules which can guide us.
Things which are not open to change, such as a person's age, are treated as causes; indeed, some researchers like to reserve the term ‘cause’ for such factors.
The time ordering can sometimes help out; since causes occur before effects, knowing which variable occurred first can help.
However, this is not watertight; human beings can anticipate and respond to future events before they occur.
Sometimes a theoretical framework prescribes that particular factors are considered causally prior to others; Marxists, for example, assume that in the last instance economic variables take precedence over cultural, political variables.
And sometimes careful measurement can indicate whether the occurrence of a variable is independent of a possible cause.
One particular problem comes from situations in which we suspect that X and Y influence each other in a reciprocating process.
There is no way that non-experimental data can be made to yield two independent estimates of the effect of X on Y and of Y on X ; we have to plump for one or the other.
In such reciprocating systems, the magnitude of causal effect of X on Y or Y on X depends strictly on the exact time at which we conduct the survey.
However, such systems tend to settle down after a time; as long as the feedback process is not in full swing, we can often assume that the net effect has balanced out in one direction or the other.
Assumption 2 Related prior variables have been controlled.
All other variables which affect both X and Y must be held constant.
In an experiment, we can be sure that there are no third variables which give rise to both X and Y because the only way in which the randomized control groups are allowed to vary is in terms of X .
No such assumption can be made with non-experimental data; if we compare non-experimental groups which vary on X , we cannot automatically assume that they are alike in other respects.
We have to control for the other ways in which they might vary.
To illustrate this point, imagine a survey of all the fires occurring in a particular neighbourhood.
If the number of fire engines which turned up was correlated with the amount of damage done at those fires, a positive relationship would probably be discovered.
Beware of letting simple-minded politicians bent on public expenditure cuts get their hands on such bivariate statistics, however.
Should fewer fire engines therefore be sent to fires?
No; control for a prior variable (size of the fire) and the relationship will be shown to be negative.
There are different ways to control for a third factor when investigating a relationship between two variables.
Precisely how third variables are brought under control will be discussed in the rest of the book.
For the moment, just imagine holding variables constant; to control for the size of the fire, for example, one might only consider cases where an isolated car had caught fire.
If we want to infer that the relationship between X and Y is a direct causal effect, rather than an indirect causal effect, a third assumption must be made:
Assumption 3 All variables intervening between X and Y have been controlled.
This assumption is not required before you can assume that X causes Y , but it is required if you want to know how X  is causing Y .
The distinction between controlling for a prior variable and for an intervening variable is drawn more sharply in the next section.
In general, variables that are brought into the picture and controlled are called test factors .
Controlling for them tests the original relationship between X and Y , and checks that it holds up.
In order to infer that the effect of X on Y is a direct causal effect, any variable which is related to both X and Y and causally prior to at least one of them must be controlled.
Never forget that these assumptions are just that; we can never prove that a variable is prior rather than intervening or ensuing.
To order the variables and decide which should be brought under control, we have to use all the theoretical and rational resources available to us; we cannot appeal to the data for help.
(An excellent and eminently readable discussion of the whole logic of control in causal models can be found in Davis 1985.)
Controlling for prior variables
In the next two sections we shall pay special attention to situations in which an original effect disappears when a third variable is brought under control.
The importance of such an outcome is very different depending on where in the causal chain the third variable comes.
Obviously, if it ensues from the two variables originally considered, it does not need to be controlled.
But there is a big difference between controlling for a prior  variable and finding that the original relationship disappears and controlling for an intervening one with a similar result.
Let us first consider a hypothetical example drawn from the earlier discussion of the causes of absenteeism.
Suppose previous research had shown a positive bivariate relationship between low social status jobs and absenteeism.
The question arises: is there something about such jobs that directly causes the people who do them to go off sick more than others?
Before we can draw such a conclusion, two assumptions have to be made.
The first decision is whether the status of the job influences the absentee rate or the absentee rate influences the type of job people get.
As we argued earlier, we cannot usually allow a model which depicts reciprocal causation; while absence-prone individuals may have difficulty getting good jobs, the former effect is probably the stronger.
The second assumption is that there are no uncontrolled prior variables influencing both the type of job and the absentee rate.
In fact, we already thought that sex might fit into this category: it is likely to be associated with status (women tend to do lower status jobs) and absenteeism (domestic commitments might make women more absence-prone than men).
It is also the case that people's sex cannot be held to be an effect of their job or their work record; sex must be assumed to be causally prior to both of these variables.
Sex must therefore be held constant while the relationship between job type and absenteeism is ‘tested’.
While we are at it, we will check whether we were right to believe that being female is a causal influence upon job type and absenteeism.
There are many possible outcomes once the relationship between all three variables is considered at once, four of which are shown in figure 12.3.
We shall systematically ask about each outcome: would it change our original interpretation of the bivariate effect?
In the first outcome, we discover that being female does affect likelihood of absence, but being female does not increase the chances of being in a low status job.
The strength of the effect of type of job on absenteeism would not change by controlling for sex in this case.
In the second outcome, we discover that females are more likely to be in low status jobs, and that people in such jobs are more likely to go absent, but that being female, once type of job is controlled, does not affect absentee behaviour directly.
Once again, the strength of the relationship between job and absenteeism would remain the same as in the bivariate case.
The first part of the definition of a test factor should now be clear: test factors need to be introduced only when they are related to both the variables under consideration.
However, the third situation is radically different.
Being female dictates the type of job, and being female affects absentee behaviour, but once sex is controlled there is no link at all between the type of job and absenteeism.
The direct effect of job on absenteeism is shown to be zero.
A causal interpretation of the bivariate effect would have been entirely faulty: it was purely a product of women being both more likely to be in low status jobs and more likely to be absent.
Or, to put it another way, changing the status of a job would not have any impact on the behaviour of its incumbents.
Figure 12.3 The effect of job status on absenteeism: controlling a prior variable
If the relationship between two variables entirely disappears when a causally prior variable is brought under control, we say that the original relationship was spurious ; by this we do not mean that the bivariate effect did not really exist, but rather that causal conclusions drawn from it would be incorrect.
We can now introduce another meaning for that verb  ‘to explain’: in this situation, many researchers say that the proportion of females in a job ‘explains’ the relationship between the status of the job and absenteeism, in the sense that it accounts for it entirely.
But what of the fourth situation which is actually the most likely outcome?
It was the situation portrayed in figure 12.1.
We discover that there is a direct effect of both being female and job type on absentee behaviour, and an indirect effect of being female on absenteeism through the type of job women tend to hold.
Since the direction of the direct and the indirect effect is the same (which need not always be so), the size of the effect of job type on absenteeism would not be as large once sex was controlled as it had seemed in the bivariate relationship.
We now know that the strength of that original relationship contained a spurious component .
Controlling for intervening variables
Superficially, the act of controlling for a variable which intervenes between the two original variables of interest is much the same.
The third factor is held constant while the original relationship is reassessed.
But the logic of the procedure is very different.
Imagine now that we introduce, as a test factor, a variable which represents the extent to which the respondent suffers from chronic nervous disorders, such as sleeplessness, anxiety and so on.
Such conditions would be likely to lead to absence from work.
It is also quite conceivable that they could be caused in part by stressful, low status jobs.
Let us therefore assume that nervous disorders act as an intervening variable.
What will happen to the original relationship if we control for this test factor?
Figure 12.4 shows similar possible outcomes.
As before, in the first two situations controlling for the third variable will not affect the estimate of the causal effect of the type of job on absentee behaviour.
In the first, nervous disorders are just an additional cause of absenteeism, but are unrelated to the type of job.
In the second, nervous disorders have no effect on absenteeism, despite the fact that they are caused by poor jobs.
But in the third, the relationship between job type and absenteeism disappears when the existence of nervous disorders is brought under control.
This test factor is said to interpret the relationship between the two variables; it opens up the black box to show how the effect occurs.
This is radically different from showing that the original effect was spurious.
It is still the case that the type of job affects the absentee behaviour.
We now know how the causal effect works: poor jobs lead to more stress-related disorders, and these in turn lead to absence from work.
In the fourth situation, nervous disorders partially interpret the  relationship between the two variables, but there is still a direct effect remaining after that variable has been brought under control.
Figure 12.4 The effect of job status on absenteeism: controlling an intervening variable
The process of drawing inferences from non-experimental data is usually one of slowly elaborating a relationship between two variables, testing that it contains no spurious component due to the operation of a prior variable, and testing to see if one can pin down whether the cause influences the effect directly or through an intervening variable.
Ultimately, of course, whether a cause is held to be direct or indirect is a statement about the state of scientific knowledge at the time; while one variable may provide an illuminating explanation for a puzzle at one  point in time, it is likely to provoke further questions about how it operates at a later date.
Positive and negative relationships
There is a further important refinement to the preceding discussion that must now be addressed.
The effect on the original relationship of controlling a test factor is affected by whether the third variable is positively or negatively related to the other variables.
Test factors can sometimes suppress and sometimes enhance the size of the original effect, as we shall see.
Look back to figure 12.3, at outcome IV.
We noted that controlling for sex would have reduced the size of the original effect, because there would have been a spurious component stemming purely from the fact that more women are in low status jobs and more women go absent.
In this case, the test factor was positively related to both the variables.
Now consider two other possible outcomes, as shown in figure 12.5.
Figure 12.5 Other outcomes for figure 12.3
In situation V, the test factor, sex, is related negatively to both the other two variables.
Being female makes you less likely to be in a low status job, and less likely to go absent.
The original bivariate effect would have been larger than the effect once sex is controlled in this case, because once more it will contain a spurious component.
Test factors which are either positively related to both the other variables or negatively related to both of them are called enhancer variables .
However, in case VI, sex is negatively related to one of the variables (absenteeism) and positively to the other (job type).
What will happen to the original effect when sex is controlled?
The size of the effect will  increase , because the original effect was being artificially suppressed by failing to control for sex.
The fact that women were less likely to go absent but more likely to be in unfavourable jobs meant that we were misled about the effect of low status jobs on absence before we controlled for sex.
Test factors which are positively associated with one variable and negatively with the other are called suppressor variables for this reason.
Sometimes the action of a suppressor variable can be so strong that controlling for it can actually reverse the sign of the effect.
If women were much more likely than men to be in low status jobs, and if female employees almost never went absent from work, it might seem that people doing low status jobs were no more likely or even less likely than others to absence.
Suppressor variables such as this which are strong enough to reverse the sign of the relationship are called distorter variables .
(If you have been stimulated by all this consideration of hypothetical possibilities to find out what relationships actually hold between sex, job type and absenteeism, you might like to read Chadwick-Jones et al.1982.)
Conclusion
Only when we are sure that all possible test factors have been controlled can we feel confident that we understand the causal process at work.
Since no survey ever measures all variables, this requirement is never met in full.
But in the better, more carefully planned investigations, the variables which are the most important test factors are measured, and brought under control in the analysis.
The same point is made another way when we demand that our residuals should be patternless.
If there are important test factors which have been excluded from the model, the residuals from the model will contain an important degree of pattern: they will be systematically related to the omitted variable.
We may or may not be aware of this.
Causal inferences are constructions built upon foundations of assumptions, and cannot be more valid than the assumptions.
If this induces a feeling of unease in you such that you start routinely checking the concrete around the foundations of inferences drawn from social science data, so much the better.
Your job, however, is to mend any plausible cracks you observe — to do a better survey, measuring and controlling important new variables — not to walk away from the edifice declaring it to be a hazard.
Be sure to remember how poor lay reasoning about causation is: not to even try to collect the data required to test a hypothesis about the relationship between smoking and lung cancer would be to leave the doors open only to those who jump to conclusions on the basis of a sample of one.
Those of you who have been fingering your calculator buttons anxiously can now relax: the excursion into philosophy is over, and we return to the nuts and bolts of describing patterns in batches of numbers.
But take with you the lessons of this chapter.
In the absence of an experiment, a statistical effect of one variable on another cannot just be accepted as causal at face value.
If we want to show that it is not spurious, we have to demonstrate that there are no plausible prior variables affecting both the variables of interest.
If we want to argue that the causal mechanism is fairly direct, we have to control for similar intervening variables.
The act of controlling for a third variable can have many possible results.
It can both suggest that an effect previously believed to exist does not exist and that one thought not to exist does exist.
It can enhance or suppress its magnitude.
It can even reverse the sign of the original effect.
The first-order task is to think logically about which variables need to be included in any model, and what form their causal relations are.
While it is important to know that your sample size is big enough for safe conclusions to be drawn (that effects are ‘statistically significant’), this is secondary in comparison with the issue of whether a relationship can be given a causal  interpretation or is merely the spurious result of the operation of third factors; the relationship between the number of fire engines and the amount of damage caused could be derived from a sample size of ten thousand and still utterly mislead if taken at face value.
This chapter was therefore important in linking the second and third parts of the book.
It should have convinced you of the importance of proceeding beyond bivariate relationships to considering systems in which three or more variables are operating together.
Exercises
12.1
Decide on balance which variable you think would be the cause and which the effect in the following pairs:
(a)
party supported in an election and the type of newspaper read
(b)
wage rises and inflation (both measured over time)
(c)
unemployment and ill health
(d)
attitude towards abortion and religion
(e)
the rise of capitalism in a country and the religion which predominates in that country.
12.2
Consider three variables: age last birthday, number of years of full-time education and favourableness towards nuclear defence.
Draw a causal path diagram indicating the relationships you would  assume to exist between these variables.
Suppose the bivariate effect of age on favourableness towards nuclear defence was strongly positive.
What would you expect to happen to the magnitude of the effect once you had controlled for number of years of full-time education?
Three-variable contingency tables
The civic culture
After the Second World War, intellectuals in both Europe and America set about trying to explain why two relatively advanced countries, Italy and Germany, had been unable to defend their liberal democracies against the rise of fascism.
Many different contributory factors were suggested, from national differences in personality structure and child-rearing practices to political institutions.
In the early 1960s, Almond and Verba published an influential contribution to the debate entitled The Civic Culture .
The thesis of the book was that democracy could not be safeguarded by attending to political institutions alone; a culture had also to exist among the population which combined tradition and modernity, encouraging attitudes of loyalty and respect for the institutions of government while at the same time fostering a degree of political activism.
Such cultures would encourage citizens to participate in the political process, but only occasionally and within the limited rules of the democratic game.
A survey was conducted in five countries which were critical cases for the hypothesis: Britain and the United States of America as countries which had the most successful democratic states, Germany and Italy as countries that had experienced fascist regimes within twenty years, and Mexico as a less well-developed country struggling to establish its democratic process (Almond and Verba 1963).
In each country, a random sample of the electorate were questioned about their attitudes towards the political process — their perceived ability to affect political change, their participation in various political activities, their attitude towards parties they did not support and so on.
One of the major conclusions of the study was that the stability of democracy in the USA and Britain was indeed due to the achievement of a finely balanced civic culture.
Citizens in those countries retained allegiance to the political process, content most of the time to leave  politics to elites, while believing that they could influence the outcome of both local and national decision-making if necessary.
This belief, regardless of whether it was justified or not, both stopped leaders acting contrary to public opinion and persuaded citizens to accept the legitimacy of laws they did not themselves agree with.
The belief was in some senses a ‘democratic myth’, but citizens participated in just enough well-behaved political activism to be able to believe in it.
Almond and Verba conducted their fieldwork in 1959, in an era of unprecedented growth and low unemployment, conditions which were perhaps conducive to consensual party politics and lack of impassioned political activism.
It is interesting to ask whether the fine balance of acquiescence and participation has survived into a very different era.
In the 1984 Social Attitudes Survey (see the appendix to this chapter), one of Almond and Verba's key questions was replicated.
Respondents were asked:
Suppose a law was now being considered by Parliament which you thought was really unjust and harmful; which, if any, of the things on this card do you think you would do?
1
Contact my MP
2
Speak to an influential person
3
Contact a government department
4
Contact radio, TV or newspaper
5
Sign a petition
6
Raise the issue in an organization I already belong to
7
Go on a protest or demonstration
8
Form a group of like minded people
The first four are considered personal actions and the last four collective actions.
Figure 13.1 Forecast of action taken in prospect of unjust and harmful law
Comparison can be made with the responses in Almond and Verba's survey, as shown in figure 13.1.
The question in the 1959 survey was open-ended, and it is possible that the great increase in preparedness to  act is an artefact of the changed method of question administration.
But the shift in the relative emphasis given to collective action in recent years is probably not explicable in this way.
The shift is so striking that it has led one commentator (Young 1984: 22) to talk of an explosion of ‘civic assertiveness’.
It makes one ask whether the delicate balance that Almond and Verba pointed to has shifted.
Is civic assertiveness now so strong that citizens would actually be prepared to break laws which they considered to be unjust?
If so, what gives rise to such attitudes?
These are the questions that will be addressed below.
The techniques to be presented in this chapter are designed to examine the relationship between three variables in a contingency table.
They are an extension of the techniques considered in chapters 7 and 8 (the first four sections of chapter 8 in particular) and they also build on the arguments about the need for controls presented in chapter 12.
We shall use differences in proportions as the summary measure for the effect of one variable on another, rather than any of the alternatives discussed in chapter 8.
For the sake of simplicity, we shall stick to analysing dichotomies, but the principles established in this chapter are easily extended to situations where the explanatory variables have three or more categories.
Controlling for a prior variable
Respondents to the Social Attitudes Survey in 1984 were asked: In general would you say that people should obey the law without exception, or are there exceptional occasions on which people should follow their consciences even if it means breaking the law?
Overall, somewhat more than half (57 per cent) thought the law should be obeyed without exception, and slightly less than half (43 per cent ) believed that it was occasionally right to follow conscience and break the law.
However, believing something is the right thing to do in principle is very different from actually doing it oneself.
Respondents were therefore also asked: Are there any circumstances in which you might break a law to which you were very strongly opposed?
This question resulted in almost one-third saying that they themselves might break the law.
While still a minority, the group would be large enough to create widespread disruption if they could be mobilized collectively.
It is thus both interesting and important to discover what factors lead this third of the population to defy the civic culture of assent.
One plausible area for explanation might lie in the experience of material security or insecurity.
Although incomes in the 1980s were substantially higher in real terms than they were at the end of the 1950s, there has been no sustained decrease in inequality; in fact, as we saw in chapter 5 (figure 5.5), income inequality in Britain increased sharply after 1976.
Perhaps it is those on low incomes, watching others getting richer, who are prepared to break the law; if we look at the statistics of actual law-breaking, after all, criminal prosecutions are most often brought against people from the poorer sections of society (Baldwin and Bottoms 1976).
This hypothesis can be investigated by consulting figure 13.2, in which the sample has been subdivided according to whether respondents lived in households with a gross annual income from all sources of less or more than £6000 in 1984 (termed somewhat inaccurately ‘the rich’ and ‘the poor’in the discussion which follows).
As we learned in chapter 8, these results could be depicted in a causal path diagram as shown below.
The model tells us that 0.238 of poor respondents say they would be prepared to break the law (the baseline).
To establish the total proportion who would break the law, we must add to this a factor which reminds us how many rich people were in the sample (767/1326, or 0.578) times their increased propensity to break the law (+0.144).
Figure 13.2 Preparedness to break the law by household income: row proportions
The result is quite striking: the richer respondents claim to be more prepared to break the law than the poorer ones, despite their apparent lesser chances of actually breaking it from the conviction statistics.
Many questions are raised.
Does the greater risk of brushing with the law  among the poorer sections of society bring with it greater fear of the consequences?
Are the rich more prepared to break the law because they are more likely to view laws as unjust?
Are the rich and poor perhaps thinking of different laws when answering this question?
Or are poorer respondents simply less prepared to admit to an interviewer that they would be prepared to break the law?
Before we embark on a major explanatory exercise, however, we must be sure that the effect is truly causal, and not just the spurious result of joint association with a prior explanatory variable, as explained in chapter 12.
We have to think of possible test factors which are related to both income and preparedness to break the law.
We control for them, and see if the relationship between income and reported willingness to break the law remains.
One variable which is a candidate for such a test factor is age.
Age and income are strongly related in almost all samples, and the Social Attitudes Survey is no exception, as figure 13.3 shows; the exact age of the earnings high point varies, but for almost everyone old age brings with it a diminution of income.
Figure 13.3 Age by household income: row proportions
Similarly, the literature repeatedly suggests that age is a factor associated with a preparedness to break the law; both in rebellious attitudes and in actual brushes with the law, the young preponderate (Marsh 1977: 69–70; Walker 1987).
This finding is replicated in figure 13.4; overall, 0.215 more young people than old people say they would be prepared to break the law.
In short, age is associated with both income and willingness to break the law.
There is thus prima facie evidence to suggest that we should control for age when assessing the causal impact of income.
The method of control we shall use involves literally holding one variable constant while assessing the relationship between two others.
To hold age constant, we consider the relationship between income and law-breaking among people of identical ages.
(In fact we will use only a dichotomy of age by crudely grouping people above and below 45, but we  shall ignore that complication for the time being.)
We therefore need a new table which shows the three-way table of age by income by attitudes to the law (figure 13.5); the relationships cannot be inferred from inspection of figures 13.2, 13.3 and 13.4 alone.
Figure 13.4 Preparedness to break the law by age: row proportions
In chapter 8, rules were formulated which dictated which way to run the proportions when dealing with the hypothesized effect of one variable upon another: proportions were calculated so that they summed to 1 within the categories of the explanatory variable.
In a three-variable table with one response variable and two explanatory variables, the proportions are calculated to sum to 1 within each of the cells formed by the categories of the explanatory variables.
In other words, we look separately at old poor people, old rich people, young poor people and young rich people, and calculate in each of the four groups what proportion would be prepared to break the law.
Figure 13.5 Preparedness to break the law by age by household income: frequencies
This is shown in figure 13.6.
The columns showing the proportion who would not break the law are, strictly, redundant, since the information can always be derived by subtracting the proportion who would from 1.0; in future tables such as this, these shadow proportions will be omitted.
Figure 13.6 Preparedness to break the law by age by household income: row proportions
In contingency tables, to control for a variable we look within its categories.
To control for age when assessing the effect of being rich on preparedness to break the law, for example, we look separately at the young and the old.
To control for wealth when assessing the effect of age on preparedness to break the law, we look separately at the rich and poor.
However, complex tables soon get quite hard to read systematically.
We now turn to causal path models to guide us as we summarize the various causal effects.
Causal path models for three variables
The full set of paths of causal influence, both direct and indirect, that we would want to consider, are represented in figure 13.7.
Care must be taken over the signs of relationships, specifying which category has been selected as the base for comparison (see section 8.2).
In the causal model in figure 13.7, we are trying to explain propensity to break the law; the  base is therefore ‘not breaking the law’.
The base categories selected for the explanatory variables are old and poor, to try to avoid negative paths; if we had used the young as the baseline, we would have certainly produced a negative effect of old age on preparedness to break the law, for example.
Figure 13.7 Preparedness to break the law by age by household income: causal path diagram
Each arrow linking two variables in a causal path diagram represents the direct effect of one variable upon the other, controlling all other relevant variables.
The rule for identifying the relevant variables was given in chapter 12: when we are assessing the direct effect of one variable upon another, any third variable which is causally connected to both variables and prior to one of them should be controlled.
Coefficient b shows the direct effect of being one of the richer respondents on preparedness to break the law.
To find its value, attention is focused on the proportions who say they would break the law, ignoring proportions who say they would never break it (figure 13.6).
The effect of being rich is obtained by subtracting the proportion of poor people who would break the law from the proportion of rich people who would.
But age (X 2 ) must be controlled since it is connected to both X 1 and Y and prior to both of them.
So two different calculations are made; the effect of being rich among the young is 0.433–0.391, or +0.042, and that among the old is 0.266–0.172, or +0.094.
Two d s result, one for the young and one for the old.
In general, in three-variable contingency tables, to find the direct effect of X 1 on Y controlling for X 2 we consider each category of X 2 in turn, and subtract the proportion who are Y in the base category of X 1 from the proportion who are Y in the non-base category of X 1 .
This is a bit of a mouthful, but it provides a systematic way of describing relationships as positive or negative; it reminds us, for example, whether young people are more or less likely to contemplate breaking the law.
How is a single number summary of the d s to be found?
For the purposes of this chapter, we shall simply take the arithmetic mean; the d among the young is +0.042, among the old is +0.094, so the average effect (coefficient b ) is +0.068.
Like all summaries, this average d only makes sense if the coefficients being averaged are broadly similar; we shall discuss what to do if they are not in section 13.6.
There are, of course, more sophisticated and sensitive ways of combining the two d s.
One fairly obvious procedure would be to weight each d by the number of cases it was based on.
One could go further and give more weight to differences with lower sampling variability, but that takes us into confirmatory statistics and beyond the scope of this book.
The effect of being rich (+0.068) is seen to be pretty small.
Confirmatory techniques exist to assess how likely a difference of proportions of a given magnitude is to arise in sample data when it has been drawn from a population in which no such difference exists.
As a rule of thumb, when d s get down much below 0.05, we can regard them as so small that they might just be a sampling fluke; we will conclude that  for all practical purposes there is no effect of one variable upon another, and erase arrows with very small path coefficients from our model.
The original effect of being rich in figure 13.2 (+0.144) was spuriously high; it was a product of the fact that young people are more likely to be rich and young people are also more likely to contemplate breaking the law.
The operation of these two age effects is not, however, strong enough to actually reverse the sign of the relationship between income and law-breaking.
The general conclusion still holds: the poorer groups in society seem somewhat less willing than the rich to challenge society's rules if they feel a law is unjust.
We can assess the direct effect of age (X 2 ) on preparedness to break the law controlling for income in the same way.
Among the poor, 0.391 of the young and 0.172 of the old are prepared to break the law — a difference of +0.219.
Among the rich, the difference is +0.167.
The average (coefficient c ) is therefore +0.193.
So the direct effect of being young (+0.193) is seen to be much stronger than the direct effect of being rich (+0.068).
Being young also has an indirect effect upon preparedness to break the law because young people are more likely to be rich, and, as we have seen, rich people are somewhat more prepared to break the law.
It is not necessary to control for anything, since there are no other variables connected to both age and income and prior to one of them.
We therefore consider the effect of age on income as shown in the original bivariate table in figure 13.3.
(This effect could have been calculated from the marginals of figure 13.5, and can be called a marginal relationship.)
While 0.760 of the younger respondents were rich, only 0.374 of the older group were, a difference of +0.386.
So coefficient a is +0.386.
Causal path models are excellent devices for forcing the data analyst to look at the appropriate marginal relationships in tables.
There are also two paths,d and e , in figure 13.7 which represent the other unspecified causes; all variables in a model which have causal paths leading to them must also have arrows reminding us of the proportion unpredicted by the model.
The values are obtained from the proportion of the base groups who are in the non-base categories of the response variables.
Path d is given by the proportion of the old who are rich (0.374 to be precise, from figure 13.3).
And path e reminds us that some old and poor respondents said they would be prepared to break an unjust law; the value of coefficient e is therefore 0.172 (figure 13.6).
These paths are the final coefficients to be entered on the quantified model (figure 13.8).
We can be sure that the model in figure 13.8 is better than that derived from figure 13.2.
However, we cannot even be sure that it has got the causal effects absolutely right.
Their accuracy still depends upon the correctness of our assumptions about causal order and the operation of other variables; if we had either specified the causal order incorrectly, or failed to control for other important variables, the coefficients would be meaningless.
Worse, nothing in the data itself would alert us to this fact.
Figure 13.8 Assigning coefficients to figure 13.7
Science is a collective enterprise; over time, researchers build up a body of wisdom which tells them which are the important variables to include when modelling a particular process, and which must be controlled.
Summarizing causal effects: direct and indirect
Causal models can be manipulated in two different ways.
First, they allow direct and indirect causal effects to be calculated and compared.
This model in figure 13.8 suggests that being young affects attitudes towards breaking the law in two distinct ways.
There is a direct effect of +0.193.
But there is also an indirect effect, because the young are more likely to be rich (+0.386) and the rich are more likely to be prepared to break the law (+0.068).
To calculate the effect of an indirect causal path, the values of adjacent paths are multiplied.
Thus the indirect effect of age via income in this model is (+0.386 × +0.068), which is +0.026.
The multiplication of paths means that indirect effects are nearly always small.
To calculate the total effect of one variable upon another, the values of all the paths, direct and indirect, between the variables are summed.
Thus the total effect of being young on preparedness to break the law is 0.193 + 0.026, or +0.219.
This is pretty near the 0.215 difference in figure 13.4.
(It is not exactly the right answer because of the rough averaging procedure we used to arrive at the direct effects.)
In short, causal path models can show us how a bivariate relationship decomposes into direct and indirect effects, an essential part of a scientific understanding.
Secondly, such models can be used to predict the proportions who say they would be prepared to break the law.
We can predict the overall proportion as follows:
To see how this works, it is necessary to calculate the total proportions who come into the non-base category of X 1 and X 2 from figure 13.5; 0.530 of the sample is young and 0.578 is rich.
Therefore, the overall proportion who are prepared to break law is predicted to be 0.172 + (0.530 × +0.193) + (0.578 x +0.068) = 0.314.
We can check that this is pretty near the correct proportion (426/1326 = 0.321); once again, it is not exactly the same because of the crudeness of the averaging procedure.
Equations such as this are known as reduced form equations .
They are used principally in forecasting, where the aim is not so much understanding the nature of the effects but predicting the net change that will occur in Y if X goes up a unit.
Controlling for an intervening variable
Most people acknowledge that there will be some political consequences of rising levels of unemployment, but there is no unanimity about what the effect will be.
Some fear that it will lead to a breakdown of the civic culture that Almond and Verba so admired in Britain.
Others believe that it will lead primarily to apathy and despair rather than rebellion and protest.
The Social Attitudes Survey can shine some light on this relationship, since it collected information on respondents' experience of unemployment in the past five years, as well as the respondent's current economic status.
The data seems to support the first belief: of those who had had some experience of unemployment in the previous five years, 0.480 said they would be prepared to break the law, whereas only 0.300 of those who had no such experience were (a difference of +0.180).
As we saw in chapter 12, there is another quite different intellectual reason for wanting to control for a third factor when assessing the relationship between two variables.
We may have discovered a statistical effect but do not understand how it operates; the brute fact that people who have experienced unemployment are more rebellious in spirit does not itself explain why this occurs (see diagram).
If we can find a mystery  variable which completely captures the causal mechanism, the effect of unemployment experience on law-breaking will disappear when the mystery variable is brought under control.
One explanation for the mechanism might be that the experience of unemployment leads to a generalized lack of trust in the institutions of authority and the state, which in turn makes people prepared to contemplate breaking the law.
There is, in the survey, a set of questions which can help us investigate this; respondents were asked:
Listed below are a number of organizations or services.
From what you know or have heard about each one, can you say whether you are generally satisfied or not satisfied with the service that each one provides?
Preliminary analysis of these questions suggested that dissatisfaction with six of the organizations was importantly related to preparedness to break the law: the press, local government, the civil service, banks, the police and the local doctor.
A scale was formed by simply scoring the number of times the respondent said that he or she was satisfied; the resulting scale started with a minimum of 0 and a maximum of 6, but it was dichotomized at the median value into a scale of political alienation with two values (high and low).
Figure 13.9 shows the cross-tabulation of preparedness to break the law by alienation by experience of unemployment.
Those who are alienated from the institutions of authority and the state are certainly more prepared to break the law than those who are not; among those who have been unemployed, the effect is +0.140, and among those who have not it is +0.171, an average effect of +0.155.
However, when we control for such views, the relationship between unemployment experience and preparedness to break the law does not disappear; in fact, it is almost as strong as it was in the bivariate table: +0.175 among the unalienated and +0.144 among the alienated, or +0.159 on average.
Figure 13.9 Proportion prepared to break the law by alienation by experience of unemployment in last five years
If, once the intervening test factor had been controlled for, the relationship was reduced to zero, we would say that the original effect had been fully interpreted .
This did not occur here; the experience of unemployment cannot be interpreted as causing preparedness to break the law by altering respondent's general level of trust in the institutions of authority and the state.
It is left as an exercise for the reader to think of other mechanisms which might be at work.
Interactions
Generalizations are at the heart of social scientific activity; we aim to discover causal processes which could potentially affect everyone in society.
When we find that the experience of unemployment makes people more likely to contemplate breaking an unjust law, we assume that the reasons for this are general; we suppose that the increased likelihood would operate for anyone who happened to undergo the experience of unemployment.
In this example, the assumption held good in the test we submitted it to: the experience of unemployment was broadly similar for those who were unalienated as it was for those who were alienated; we could feel confident about averaging the two d s.
When no generalization can be made about the causal process at work, we say that there is an interaction in the relationships.
An interaction can be formally defined as a situation in which the effect of one variable upon another depends upon the value of a third variable; when asked how much effect X has on Y , we are forced to answer: ‘it depends.’
Interactions are sometimes also called ‘conditional relationships’; in other words, the relationship varies under different conditions.
To illustrate this point, let us examine a further set of findings about preparedness to break the law in the Social Attitudes Survey.
In their study of civic culture in 1959, Almond and Verba repeatedly noted that the better educated in all five countries that they studied were more likely to participate in the political process, and to believe that they could do something to change laws which they felt were unjust through the conventional channels of political participation.
We can examine whether the Social Attitudes Survey in 1984 finds the same pattern; we might expect, on the basis of this reasoning, that the more educated people would be less likely to say that they would break an unjust law.
Educational level is a hard variable to measure in most cultures: are we interested in formal qualifications, the number of years spent in full-time education, the content of what was learned during the educational process or what?
A simple indicator of qualifications is not very practicable in Britain because so many people left school in the past without any formal qualification to show for it.
However, the number of  people who return to education once they have left school or college is so low that the age of finishing full-time education is often used as a simple indicator.
The bivariate relationship between terminal education age and preparedness to break the law suggests a different conclusion about the relationship between education and respect for the law in Britain in 1984: more of those who left school at 16 or above say they are prepared to break the law (0.364) than do those who left at 15 or younger (0.274), a difference of +0.090.
However, we would expect the effect of terminal education age to differ among people of different generations: 16 was the minimum school-leaving age for sample members aged 28 or less, whereas any respondents aged 80 or older did not even have to stay at school till they were 14.
It therefore makes good sense for us to control for date of birth when looking at the effects of terminal education age.
The cross-tabulation is shown in figure 13.10.
Figure 13.10 Proportion prepared to break the law by age by terminal education age
Once age is controlled, the effect of education upon attitudes towards breaking unjust laws changes.
Among those aged 46 or more (approximately those born before the Second World War), the relationship is as it seemed from the bivariate table: the more highly educated are more prepared to break the law.
But among the post-war generations, the relationship has the opposite sign: the less educated are the ones who say they are more prepared to break the law.
Neither effect is large, but the result is sufficiently different for us to feel uncomfortable about averaging the two effects; it would not do justice to the situation to say that on average there was no effect of education once age was controlled.
There is, in short, an interaction present; the effect of education on law-breaking depends upon when one was born.
Once an interaction has been found in one of the effects in a table such as figure 13.10, it will also be found in the other.
Sure enough, the effect of age on preparedness to break the law is larger (+0.250) among those  with low education than among those who stayed on at school or college beyond 15 (0.143).
Age is always an ambiguous variable in survey research.
Unless one has data from repeated surveys across time, there is no way of telling whether one is dealing with pure age effects, pure period effects or an interaction between the two, termed generation or cohort effects.
If we had several surveys at our disposal, and those aged 45 or less were always more prepared to break an unjust law, regardless of when the survey was undertaken, this would be an example of a pure age effect.
If we found that responses in later surveys were more favourable towards breaking the law among respondents of all ages, this would be interpreted as a pure period effect.
When age and period interact, we may assume we are dealing with the unique experiences of a generation growing up under particular conditions.
Because there are interactions by age in figure 13.10, it is likely that we are dealing with a generation effect.
Because the data comes from a survey conducted at one point in time, we cannot tell if the relationship is conditional upon age or period, however.
If, for example, we were to find the same results in the Social Attitudes Survey in the year 2006, we could assume that these results are conditional upon age.
However, we might find the same relationship among all sections of society by 2006; breaking unjust laws might become the hallmark of the less educated of all ages.
It is to be hoped that repeated surveys such as the Social Attitudes Survey will be conducted for many years to come in order to allow these important distinctions to be made.
The method outlined in this section for detecting interactions involves looking for differences in the magnitude of the ds .
It is not the only way to decide if the relationship between two variables depends upon the value of a third.
You might find it useful to look back at exercise 8.3.
The authors' argument may be put more technically now: they suggested that there was an interaction in the effect that certain provoking agents had upon the risk of clinical depression; these agents operated much more strongly on women who were in a vulnerable condition than on those who were not.
In the suggested answer, we noted that if they had fitted a multiplicative model, the effect would be very similar.
Differences in ds only measure the amount of interaction in an additive model.
There are formal procedures for deciding how large a difference in the ds needs to be before we decide to take the interaction seriously, but these are beyond the scope of this book.
As a rule of thumb, with samples of around 1000 individuals we may say that, if the difference in proportions is greater than 0.1, then an interaction is present, and it is unwise to average the effects.
General causal models cannot be drawn up when interactions exist between the variables; the only solution is to draw up a separate causal model for each of the groups for whom the effects of the variables are different.
Conclusion
In this chapter, techniques for building up systems of the joint influence of variables have been outlined, using differences in proportions as the measure of strength of effect.
Causal path diagrams have been extended to three variables to show how the factors are hypothesized to interrelate; these diagrams are useful because they force explicit decisions to be made about the causal order of the variables, and lessen the risk that the analyst will control for the wrong variables.
They force consideration of the marginal relationship between the variables where this might be important.
The techniques of control used in contingency tables involved literally holding a variable constant by considering its categories one at a time.
When the variable to be controlled was ordered (as age and income were), we simply split it around the median.
This can, however, introduce what is called category error ; people in the category ‘below median income’ do not all have identical incomes.
The danger is that the younger people with below median incomes actually have lower incomes than older people with below median incomes.
The more categories that are used, of course, the less room there is for category error.
The techniques themselves are identical whether the variable being controlled is a prior or an intervening variable in the relationship being investigated.
The interpretation of the result is however very dependent on which is the test variable.
If the relationship between two variables disappears when a prior variable is controlled, the original effect has been explained away.
If it disappears when an intervening variable is controlled, the mechanism linking the two variables has been interpreted.
When four or more variables are under consideration at once, the importance of modelling the relationships visually before doing any data analysis is even greater.
Four variables are not considered in this text, but they do not require any new principles beyond those outlined in this chapter.
The rule enunciated earlier about which variables to control for is quite general and extends to any number of variables.
Exercise 13.3 has been set to give you an opportunity to try reading a table with four variables in it.
You may have heard of a technique called ‘path analysis’ and have wondered if it referred to the methods discussed in this chapter.
Path analysis usually refers to a technique of modelling relationships between variables using regression coefficients as the measure of the strength of effect.
(These are analogous to slopes calculated from a resistant line.)
However, the logic of causal modelling is exactly the same as that discussed here.
The points made in chapter 12 about test factors, suppressor and enhancer variables, about intervening and prior variables, about the importance of detecting interactions and dealing with them separately, all apply equally to path analysis.
If you understand  how such models work using proportions, you should find their use with other measures reasonably straightforward.
Learning exactly which proportions to calculate in a contingency table, which variables to control for by looking within their categories, and which to ignore by collapsing over their categories, takes some practice.
There is no quick substitute.
Exercises
13.1
We saw in this chapter that the rich are more inclined to say that they would break an unjust law than the poor.
Draw up a path diagram depicting the relationships you would expect to hold if party support were introduced as a test factor.
Then inspect the table below.
Are the relationships as you predicted?
13.2
The following table shows where a sample of school-leavers who had either been on a government Youth Opportunities Scheme (YOPS) or been unemployed for six weeks by the beginning of October 1978 had ended up by April 1979.
The sample was obtained by selecting one in five of the 42 per cent of people who left school in Scotland in 1977–8 with few or no qualifications (i.e. without at least a grade O in the Scottish Certificate of Education).
The table shows whether the respondent had tried to obtain an O grade pass or not.
The purpose of the Youth Opportunities Scheme was to prepare the less qualified for employment.
On this evidence, did it succeed?
In order to answer the question, dichotomize the response variable and present the table in proportional terms.
Is it possible to summarize the relationships you find in a linear causal model?
13.3
Much important social research results from war.
During the Second World War, many aspects of life in the US army were investigated, including the degree of social mobility in the army and attitudes towards promotion policies and opportunities.
In a study conducted during the Second World War (Stouffer et al.1949), soldiers in two different sections of the army, the Military Police and the Air Corps, were asked: ‘Do you think a soldier with ability has a good chance for promotion within the army?’
The following table shows the proportion who answered ‘a very good chance’ by section, by educational level and by rank.
This is a complex table, because it contains four variables; work through the effect of each explanatory variable systematically, looking at the relevant marginal relationships as well.
What do these findings tell you about attitudes towards promotion in the US army?
How do attitudes to promotion relate to differences in the proportion of officers in each section?
13.4
What can you discover from the dataset CLASS about the chances of being in a job which offers an occupational pension scheme (column 16)?
What are the independent effects of income (column 15) and social class (column 5)?
To answer this question you will a need to give the Minitab command TABLE a third argument .
Appendix: the British Social Attitudes Survey
Introduction
The early Victorians who pioneered the collection of social statistics were interested in knowing what people thought as well as what they did.
In the nineteenth century, however, those who conducted the research did not really believe that their subjects would tell them the truth reliably if they asked them for information directly, and so they drew inferences about people's ideas, religious beliefs, political commitments and so on from the type of literature they had on their shelf or the pictures they had on their walls.
It was the poverty researcher, B. S. Rowntree, who, around the turn of the twentieth century, pioneered the revolutionary idea of asking the subjects of research to be respondents to surveys.
After the Second World War, interest in the attitudes and beliefs of the public grew, and several important one-off surveys were conducted.
But the main features of social reality monitored on official continuous surveys such as the General Household Survey, Family Expenditure Survey, Labour Force Survey and National Food Survey were objective social conditions and demographic characteristics.
Although the GHS did include some attitudinal questions, its emphasis was not primarily subjective.
In order to remedy this deficiency in our knowledge of modern British society, the British Social Attitudes Survey was established in 1983.
Social and Community Planning Research, an independent, non-profit institute specializing in social surveys and social research, began conducting an annual survey to investigate public attitudes to a wide range of social and political issues.
The aim was to provide important benchmark data on trends in social attitudes, a sort of continuous subjective social accounting to supplement the objective accounting of the Blue Books.
The survey is now also part of an international comparative project in which many key questions are repeated in several industrialized countries.
This survey has been unusually successful in attracting financial support from a very wide range of sources.
Seedcorn money for the first round of fieldwork (in 1983) was provided by the Economic and Social Research Council and by the Nuffield Foundation.
Since 1984, core funding has been provided by the Monument Trust, a Sainsbury foundation, and other funds have been obtained from various government departments and quangos, for their specific areas of concern, and from industry.
At the time of writing, funding has been secured for the first five years; it is to be hoped that the data will prove so useful that it will become indispensable to British social science.
The data is explicitly destined for public use.
Each year, a summary volume is published, describing in broad outline the main findings of the fieldwork the previous year (Jowell and Airey 1984; Jowell and Witherspoon 1985; Jowell et al.1986; Jowell et al.1987).
The data is then made public; the full dataset and the commands to set it up for processing by the statistical package SPSS- X can be obtained from the Economic and Social Research Council Data Archive at the University of Essex for the cost of processing.
The sample size for the first three years of the Social Attitudes Survey was between 1700 and 1800.
In 1986, the sample size was increased to 3100; core questions were asked of all the sample, while other questions were asked of a random half of the respondents.
The following description of sampling methods relates to the 1984 survey, but the sample design is similar every year.
The sample
The universe sampled was adults aged 18 or over living in Great Britain (i.e. excluding Northern Ireland) at the time of the survey.
The sample was selected in four stages.
First, 114 parliamentary constituencies were sampled from a list of all the constituencies arranged in order of region and in order of broad demographic profile of the constituency within region.
The probability of a constituency being selected was proportional to its size.
Within each constituency, a polling district was selected, again with probability proportional to size.
The third stage involved selecting 22 addresses in each polling district.
The electoral register was used as a sampling frame of addresses (institutional inmates were excluded for practical reasons — so few of them are willing or able to answer survey questions).
A random point was selected in the list of names, and then every Nth elector was noted, where N was the required fraction for the particular polling district to yield 22 addresses.
The fourth stage was the selection of the individual for interview at that address.
The procedure was designed to compensate for the fact that the electoral register is not a very complete list of individuals; it therefore depended on whether the adults resident had changed since the register was compiled.
If the household was identical to the register entry, the elector on whose account the address had been selected had effectively been selected at random, and was therefore nominated for interview.
If not, a new selection process was required: all the adults in the household were listed and one was selected at random; this happened in 30 per cent of households.
The probability of selecting the original address had been proportional to the number of electors originally on the register; this was a sensible procedure if the number of electors had not changed.
However, at addresses where the number of electors had changed, the probability of any individual being selected had also changed.
In subsequent analysis, therefore, all responses from individuals at addresses which had changed electors were weighted by the number of adults at the address divided by the number of electors originally on the register for that address.
Fieldwork
The survey was conducted by Social and Community Planning Research in spring and early summer of 1984, and the response achieved was as shown.
The questionnaire
The contents of the Social Attitudes Survey questionnaire are decided through a process of consultation involving many different outside bodies — researchers in government and quangos, academics and others involved in social policy formulation, and colleagues mounting equivalent surveys in the USA, Germany and Australia.
The questionnaire in 1984 took an average of 61 minutes to complete.
Respondents were also left a self-completion questionnaire and asked to fill it in and either give it to the interviewer when he or she called back or return it by post; the response rate to this was 93 per cent.
The subject matter of the questionnaire was wide ranging.
The survey probed attitudes towards the political process and the respondent's view of his or her own role in it, towards the monarchy, House of Lords, EEC, NATO and Northern Ireland, nuclear weapons, Britain's economic problems, taxation, pensions, the respondent's own job and job security, the welfare state and system of social security, health, housing, education, crime and the criminal process, poverty, social class, race and moral questions of various kinds.
Full demographic information was obtained about each respondent, and further information was obtained about other household members.
The questionnaire is included as an appendix to the report (Jowell and Witherspoon 1985).