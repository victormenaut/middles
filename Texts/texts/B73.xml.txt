

 painful  experience 
DRUGS ARE not quite as ‘scientific’ as the pharmaceuticals industry would like us to believe.
For example, it is not possible to develop ‘tailor-made’ painkillers with predictable effects.
This is partly because people, and their pains, do not respond equally to a particular drug.
That is why the production of analgesics is almost as much an art as it is a science.
For this reason, we should not be surprised when new pharmaceutical preparations produce untoward side effects.
This means that Britain's watchdog on pharmaceuticals — the Committee on Safety of Medicines (CSM)— needs to be somewhat more alert and responsive to the hazards than appears to have been the case.
Painkillers are by far the most common drugs prescribed by doctors in Britain.
Minor analgesics and preparations dispensed to make rheumatism less unbearable accounted for more than 33 million prescriptions on the National Health Service (11 per cent of the total) in 1980.
The cost to the NHS, even before adding the bill for dispensing the drugs, was £105 million (l2.6 per cent of the total drugs bill).
It is against this background that we must see the recent withdrawals of a number of analgesics from the market in Britain.
Three widely-prescribed drugs have come under question following the discovery that they led to serious  undesirable side effects.
And yet in all three cases the CSM either acted tardily or not at all.
Zomax and Opren have succumbed to questions about their safety and Distalgesic is under investigation because it is linked with more accidental deaths and suicides than any other drug.
The aim when developing painkillers is to produce a drug as potent as the narcotic analgesics such as morphine, but without their addictive effects and other undesirable impacts.
Unfortunately, we have no way of predicting who may suffer an allergic reaction to a particular drug.
Zomax, Distalgesic and Opren (this issue, p 729) came under fire after being linked with unacceptable side effects.
All were prescribed as painkillers, with both Zomax and Opren widely prescribed for arthritic patients.
Half the active substances used for rheumatic conditions also appear in the 100 or so painkilling preparations available.
In just two years Opren captured well over half the market for drugs to treat arthritis.
It could not have done so had there not been considerable lack of confidence in these other analgesics and the 80 or so non-steroidal anti-inflammatories use to treat arthritis.
Pain, at all levels, is a highly individual sensation.
Two people may suffer pain from the same apparent origin; and yet their pain will not yield to the same analgesic.
Nor is one drug effective against all types of pain.
That is an argument for having a range of effective analgesics, but hardly for continuing to multiply their numbers indefinitely.
While it is easy to understand why the drug makers pursue the will-of-the-wisp of the ultimate painkiller; it is less easy to understand why the Committee on Safety of Medicines licenses them with no evidence of improvement in either safety or effectiveness.
Laying it on thick
THE BUTTER Information Council is what is known in the terms of peasant wisdom as a fool unto itself.
Nobody seriously doubts that butter is lovely stuff.
Nobody can long sustain the argument that all fat per se is bad, and few would argue at great length that a diet containing small amounts of saturated fat (which butter decidedly is) is unacceptable.
Some ingenious souls have even gone so far as to suggest that the correct attitude to fat, which makes sense in nutritional, agronomic and culinary terms is to aim in general at eating a low-fat diet, and at one in which most of the fat in the diet is polyunsaturated: but to ensure that the small amount of saturated fat that did creep in is as delectable as possible, which, of course, with slight deference to beef dripping, means butter.
In some countries the dairy producers have taken a comparable line, and manage to live profitably while accepting the growing evidence against high-fat diets in general and saturates in particular.
The Swedes, for example, produce excellent spreads containing both butter and a high proportion of polyunsaturated fat.
But the Butter Information Council (BIC) has chosen to take a hard line.
In its full-page and horrendously expensive advertisements in the national press, and now (the latest manifestation) in a booklet with a cover that at only a few metres distance looks like gold-tooled morocco, it comes perilously close to transgressing those rules of the Advertising Standards Authority that ensure that all ads are honest, fair, accurate, unimpeachable and altogether above reproach.
The little booklet, which is turning up in the oddest of places, tells us for instance that ‘Butter is a natural product — alternatives are different.’
Does this have meaning, one asks?
If it does not, as seems to be the case, can it fall within the advertising authority's requirement for truthfulness?
Is there a philosopher in the house?
The booklet tells us further ‘Butter is a healthy food, there's no evidence to the contrary.’
But (one splutters) surely there is epidemiological evidence that too much Fat is a bad thing, and experimental evidence that saturated fats are more harmful than polyunsaturates, and not even the BIC would deny that butter is one of the great saturates of our time?
No conclusive evidence, certainly.
No proof (a word much beloved of non-scientists), absolutely.
But no evidence, not even of the teeny bit suggestive kind?
And what about ‘Butter has been in man's diet for thousands of years, so you can have confidence in it’?
In China they've been eating mouldering cabbage for aeons and it gives them cancer of the oesophagus.
What's the argument?
Yet the booklet also tells us, ‘only a small proportion of the fats you eat comes from butter’.
And so it does.
That's precisely where we came in.
THIS WEEK
Grants pay for counterfeiter's factory
BRITISH taxpayers have helped to pay a man with a series of convictions for selling counterfeit brands of audiotape to manufacture millions of metres of video-tape.
Nobody is saying where this new tape is going.
Rajinder Anand is the managing director of Intermagnetics, which opened a new video-tape factory in Wrexham, north Wales, last September.
It had the help of finance from the Welsh Development Agency and publicity from Nicholas Edwards, the Secretary of State for Wales, who provided a video-taped message for the launch.
The company bought a six-page advertisement in The Times newspaper to announce the new factory.
The factory is now manufacturing enough tape for 100 000 VHS video-cassettes every month.
But, after six months, Intermagnetics has still not finalised a licence with the  Japanese video-firm, JVC, to sell tape for its VHS video-system.
And since the factory opened, Rajinder Anand has been fined for distributing large numbers of counterfeit audio-cassette tapes.
Three months before opening day he was sentenced to 14 days in Brixton Prison for contempt of a High Court undertaking not to deal in any more counterfeit tape.
Intermagnetics, of Santa Monica, California, has been a well-known name in magnetic tape for several years.
It is now owned by the Agra group of companies, based in Dubai.
Its directors are four Sikh brothers named Ariand.
The trading name, Agra, is an acronym of their first names.
Intermagnetics-Agra now has 11 video tape plants around the world, either operational or under construction.
They have the potential to produce 28 million video cassettes a year.
The company estimates this at approximately 14 percent of the world market.
There are Intermagnetics factories in the US, France, Singapore, Hong Kong, Taiwan, Thailand Turkey, Egypt and India.
The company chose Wrexham partly because of the generous financial aid available.
The British government's Welsh Office says the project was the culmination of discussions started in 1980 when Edwards led an industrial mission to the US.
The Welsh Development Agency says that to ensure that the Wrexham project got under way as quickly as possible ‘it cooperated fully’.
Wrexham is a special development area, so Intermagnetics is entitled to a regional development grant of 22 per cent on all capital expenditure on plant, machinery and buildings.
Because the money is not subject to corporation tax, the grants are, in effect, worth twice as much.
In addition there is selective financial assistance under the Industry Acts.
These grants are discretionary and judged by the needs of the area and the jobs created.
They too stand at around 22 per cent, but are phased over the period of production.
According to the Department of Industry Intermagnetics was offered £400 000 as a discretionary grant and has also received £100000 in training grants from the European social fund.
Then there are loans, at 3 per cent less than the market rate, from the local Coal and Steel Community fund for firms that create jobs for examiners.
When the factory opened in September 1982, Agra and Intermagnetics hosted industrialists and financiers from Japan, the United Arab Emirates, Turkey, Taiwan, Hong Kong, India and the US.
More than 200 special guests gathered for a dinner nearby.
One of the technical journalists present was surprised at what he saw.
The video-tape being produced was obviously defective, even to the naked eye.
There were large patches of material missing from the tape's coating.
JVC is well aware of the need to keep a tight control on the quality of video-tape sold under its VHS brand name, for use in VHS home video-recorders.
Only a few firms have won manufacturing licences because, unless the tape is of very high quality, it will produce poor pictures and damage the machines in which it is used.
Last week, six months after the Wrexham factory opened, Intermagnetics acknowledged that it does not yet have a VHS licence.
JVC could only say that the matter was still being considered.
In The Times supplement Intermagnetics claimed that initial production capacity was 2 million two-hour VHS video-cassettes a year.
The company now says that it is producing some 20 million metres of VHS tape per month — enough to fill more than 100 000 cassettes.
But none is sold under the Intermagnetics name.
So what is happening to the tape being produced in Wrexham?
The company says only that they are ‘being used within the group to get some money back’.
The Agra family has already fallen foul of the law for selling tape under improper names.
The Birmingham Post on 19 January this year reported that Birmingham magistrates fined Rajinder Anand £3600 for supplying more than 250 000 counterfeit audio-cassette tapes to distributors throughout the country.
Anand pleaded guilty to 18 specimen charges of supplying counterfeit cassettes contrary to the Trade Descriptions Act.
On 18 October, last year Rajinder Anand pleaded guilty to four similar charges at Bedford Crown Court.
He was fined £1000 and ordered to pay costs of £2200.
In October 1980 Rajinder Anand and his brother Gurcharan Anand gave an undertaking to a High Court judge, Mr Justice Graham, that they would refrain from handling any cassettes that bore the name Sony but were not genuine Sony products.
Sony claimed that the undertaking was broken and in March 1982 Mr Justice Walton said that he found Rajinder Anand's excuses ‘a deliberately-invented story’ and ‘a pack of lies’.
He committed Rajinder Anand to Brixton Prison for 14 days for contempt, fined his brother £2500 and their company, Global Impex, £5000.
The Anands appealed, but in May 1982 three judges unanimously upheld the sentence.
Lord Justice Waller said he was ‘quite satisfied that the Judge had ample grounds to make him sure that the appellants had been telling lies’.
The facts are all on the record, but the British government seems happy to continue financing the Wrexham factory to produce millions of video-cassettes a year without an apparent legitimate market.
British leader in biotechnology faces cash crisis
FOUR MONTHS after announcing a discovery of worldwide importance, one of Britain's most promising biotechnology companies, Speywood Laboratories is in serious financial difficulties.
Its backers, which include the government's British Technology Group, have told the firm to cut back on research and make a profit by next year or face closure.
The dispute raises a central question: are Britain's financiers sufficiently visionary to decide the strategy for Britain's new generation of hi-tech companies?
Speywood has a world lead in developing a blood-clotting protein that could change the lives of thousands of haemophiliacs.
Last November David Heath, Speywood's founder, announced that research, funded by the company at London's Royal Free Hospital and under the direction of Dr Edward Tuddenham, had isolated the elusive blood protein, factor VIII, that clots blood.
Now the company needs an additional £1 million, which its backers the British Technology Group and Prutec, the venture capital fund set up by the Prudential Assurance company, say they will give — but only at the expense of an ambitious programme of research.
A deal signed with the American biotechnology firm, Genentech, for the mass-production of the protein opened up the prospect of supplying a massive world market for haemophiliacs.
The agreement divided up that market, estimated at £200 million a year, between them.
But Speywood's position as a fully-equal partner in this venture is now at risk, because Heath, and his company's backers could not agree on a long-term strategy for the company.
At stake say some British biotechnologists, is Britain's lead in blood-protein genetic engineering technology, which could pass to competitors in the United States and Japan.
Also, it costs Britain each year £3 million to import enough human blood, mainly from the United States, for factor VIII extraction and this blood carries with it the risk of disease.
Heath wants to use the promise of riches from the blood products to maintain his large-scale funding of research in British universities and to expand into mass production of the products of that research (the job which Genentech wants to do for factor VIII).
But BTG and Prutec, which each invested ‘2 million in Speywood last year, want the company to concentrate on technology it already possesses — developing its techniques for purifying pigs’ blood.
Manufacturing factor VIII, says Don Seymour, Speywood's new managing director, should be done under product licence with Genentech.
Prutec chief executive, Derek Allam told New Scientist : ‘Although we saw Speywood as combining manufacturing on the one hand and R&D on the other, they got the balance wrong.’
He says that Speywood did not carry through the business plan presented to get the money.
‘The basis we went in on was as a company which had a product to sell, not as a company which funds R&D.’
A BTG spokesman says that the ‘business nose of the company’ should be the polyelectrolyte method of purifying pigs' blood, which has been perfected by the company.
He went on ‘the basic business, should have been established first.
The genetic engineering programme was not there one year ago’.
In an effort to sharpen the ‘business nose’, Heath has been shunted sideways, to become deputy chairman, while Don Seymour, a businessman, has been installed at the head of the company with the intention of making it profitable by 1984.
Seymour is now scrutinising all the university projects funded by Speywood.
He says that many will be dropped — at least until the ‘core’ business is put on a sound footing.
When profits start accumulating, money will go back into R&D.
It will probably go on extending the purification technology to human blood.
The crisis at Speywood is linked to the growing uncertainty about the future of the British Technology Group.
This year the Treasury slashed the group's core budget in half, with the aim of making it self financing.
But BTG denies that this means that it must drop risky ventures.
Nevertheless, with BTG required by ministers to look to short-term profitability, sources of ready funds for British biotechnology have all but dried up.
Prutec, a venture capital fund set up 18 months ago by Prudential Assurance, with £20 million to spend on high-technology projects, has yet to invest in any British biotechnology company, other than Speywood.
Allam admits that US firms look more attractive because ‘the concentrations of scientists are greater’.
Other investors have taken a similar line.
At Rothschild, for instance, they defend a decision not to invest in British  biotechnology by saying that there are no good commercial ideas in Britain.
 Universities plan to speed sale of biotechnology
UNIVERSITIES and biotechnology companies in the US are considering a new plan to speed the transfer to industry of genetic engineering techniques developed in university laboratories.
The proposal calls for the creation of a new non-profit body, the University Licensing Association for Biotechnology (ULAB), which would market biotechnology techniques patented by universities.
The biotechnology companies would then directly buy a licence for a particular technique rather than negotiating with individual universities.
These universities would reap fees from the licensing.
Their income would depend on how often their patented technique was used.
ULAB would take a cut from the licensing to cover running costs.
The idea has been floated by Stanford University and the University of California, which together hold the patent on the Stanford procedure for gene-splicing developed by Herbert Boyer and Stanley Cohen.
Niels Reimers, director of Stanford's office of technology licensing, told New Scientist that there was substantial support For the idea from both universities and industry, though the establishment of the corporation would require ‘considerable effort and commitment’.
ULAB patents, Reimers stressed would not involve the ‘entire gene-cloning process’, but rather specific biological tools or techniques used by industrial scientists.
It was necessary, he said, to inject some order into what was becoming an increasingly complicated problem — how to give industry quick access to the growing number of biotechnology techniques being developed by universities while ensuring that the university contribution was acknowledged and rewarded.
At least 200 separate patents applications from universities existed for the biotechnology tools that industry wanted to use.
In some cases, a company may need a dozen licences from a dozen universities for any particular genetically-engineered product.
Many scientists also favoured the idea of pooling biotechnology patents because it would reduce the possibility of secrecy and the delay of publication.
Reimers said: ‘In university laboratories there has been a growing concern that desire for proprietary know-how or rights may stifle the open communication of scientists, particularly between scientists who have involvement with different companies’.
Industry has already put some money into the idea.
Seven companies contributed $3000 each to finance a feasibility study by a student from the Stanford Graduate School of Business.
The student, Mark Edwards, visited 20 companies and talked to university scientists and administrators.
His report is being used as the basic plan for ULAB.
Kenya to ban dangerous pesticides
KENYA is drawing up a list of pesticides and medicines to be banned under laws that will pass through parliament this year.
This follows reports that foreign companies are using dangerous pesticides in places where safety precautions are impossible, and that other companies are still promoting drugs that are banned or controlled in Europe and the US.
Philip Leakey, Kenya's deputy environment minister, told New Scientist last week that the problem of ‘dumping’ by foreign companies is continuing, despite mounting pressure around the Third World.
Last year the British American Tobacco company stopped spraying aldrin in its Kenyan plantations after reports in New Scientist (vol 94, p 67).
Most Western governments ban or severely restrict the chemical.
Last week the Nairobi Daily Nation reported that drug stores were selling some medicines containing anabolic steroids and chloroform as being ‘suitable for children’.
Leakey said ‘there is no question that companies are guilty of promoting and exporting these [dangerous]chemicals into developing countries.
We are victims of the industrial world’.
He says agricultural chemicals could threaten water supplies in rural areas.
‘If we let all the chemicals from a coffee farm get into a river we will have a cumulative problem.’
It is ‘very difficult’ to persuade farmers in remote areas to take safety precautions and wear protective clothing.
‘The best way is to regulate the type of chemicals coming into the country.’
The pesticides law will ban chemicals that require special safety precautions unless farm owners can show the government that their workers are able to use them safely.
Leakey said that chemicals containing the herbicide 2,4,5-T would fall into this category.
The Pesticide Products Control Bill should pass through parliament this year.
Leakey could not say what penalties it would introduce for offenders.
But one of the biggest curbs on the unnecessary use of pesticides could be Kenya's chronic shortage of foreign currency.
Leakey said he tells farmers who complain about the cost of chemicals to employ labourers to clear pests.
‘One farmer came back and said that employing 300 Kenyans cost one-fifth as much as weedkiller,’ he said.
‘But we still have to combat the promotional skills of chemical companies.’
BR bolts advanced train together again
BRITISH RAIL has modified the bolts on the axles of its much-troubled advanced passenger train (APT).
This follows the discovery in December last year, at the end of a proving run from London to Glasgow, that some bolts on an axle had become loose.
The same bolts were the cause of the APT's 200 km/h derailment in 1980, at Carnforth.
British Rail then said that the accident was ‘caused by a fault in the assembly of one of the bogie's wheelsets’.
However, since this derailment, BR engineers have inspected the  bogies at the end of each run, and it was one of these inspections which found the loose bolts last year.
BR's engineers are confident they have now solved the problem.
Each axle on the APT is hollow, because it contains the hydro-kinetic brake.
The axle is made of three sections, one central cylinder and two conical stub axles at either end.
The conical stub axles and the cylinder were connected by being bolted to an aluminium flange.
It was these bolt which had worked loose.
David Boocock, the engineer in charge of modifying the APT, told New Scientist that part of the solution was to lengthen the bolts, by about 18 millimetres.
But the major design change was to replace the aluminium flanges by steel ones.
On the train's last run an axle bearing had overheated causing differential expansion.
Since aluminium expands more than steel the steel bolts had worked loose.
Although the same bolts worked loose and caused the 1980 derailment, Boocock said that there was ‘no question of a bearing failure on that occasion’.
He said that the cause was ‘incorrect assembly, as far as can be ascertained’.
Mick Hamer
Hi-fi or Euro-gabble
LAST WEEK the BBC signed a £25 million deal that will bring two extra channels of television direct into British homes from an overhead satellite.
But a new round of haggling is now certain over the quality of the sound that will go with the pictures.
The choice is between better-quality sound or more channels of sound.
United Satellites — a consortium of British Telecom, British Aerospace and GEC — has guaranteed the BBC seven years' service, at £12.2 million per channel per year, from satellites launched on the European Ariane rocket.
The government, meanwhile, has told the BBC that it must use a system of picture transmission developed by the Independent Broadcasting Authority, called MAC.
This carries up to eight channels of sound for each vision channel and opens up the prospect of broadcasting a soundtrack in several languages simultaneously.
But there is an alternative.
The BBC could use the system to provide fewer channels, but a much higher quality of sound.
BBC engineers are divided between hacking a Scandinavian proposal to standardise across Europe on eight-channel sound in a gaggle of different languages or, as many want, to go for fewer channels carrying the kind of sound quality available on the new digital discs that are now in British shops.
Poisoned vegetables
ONE-THIRD of the vegetables grown by Londoners in their gardens and allotments contain more lead than is allowed in current food regulations.
Dr Brian Davies of the University College of Wales will claim today.
Davies's research also shows that some 40 per cent of land in inner London is unsuitable for growing vegetables.
The publication of Davies's work launches the spring campaign of CLEAR, the Campaign for Lead-free Air.
The survey follows last week's publication by CLEAR of the results of a national survey of lead in the dust of school playgrounds and the pavement outside.
Several schools exceeded 5000 parts per million for lead in dust.
The worst results were from a school in Bournemouth.
Video blackout warning
BROADCASTERS are warning that a deal struck between the BBC, the Musicians' Union and the actors' union, Equity, on the sale of video-recordings of TV  programme mean an end to the release of minority interest programmes, like science documentaries, on video-tape or disc.
The BBC has promised the unions that even extras will get an advance on royalties — currently £5 — before a single recording is sold.
The ITV companies pay royalties only after sales, but they will soon have to negotiate a new deal.
According to one ITV producer, a deal of the kind agreed by the BBC would mean that many past video releases like The World at War and The Botanic Man would never find their way onto video.
And plans for future issues of science topics will have to be scrapped.
Reservoirs Act implemented
MINISTERS at the Department of the Environment have decided, after all, to implement the Reservoirs Act that parliament passed in 1975.
This is despite their repeated claims that the act, which tightens up rules on the safety inspection of large dams and calls for a national register of dams, was necessary.
In January.
however, the House of Lords Select Committee on Science and Technology attacked ministers for complacency over reservoir safety.
Last week Lord Skelmersdale told the Lords that ‘the government's decision is that the time has come to implement the 1975 Act…. it is the large number of reservoirs for which no one appears to take responsibility which gives rise to the greatest concern, he added.
Confusion hits Reagan's private weather — watch
PRESIDENT REAGAN'S decision to sell off the United States's weather satellites, which was announced last week, has thrown the world's meteorological community into confusion.
Not only that, the civil servants entrusted with carrying out the auction seem unclear how to do the job.
Somehow they must disentangle the satellites (which are for sale) from the land-based computers and data banks, which make sense of the satellites information but which are not apparently for sale.
Last week the President instructed the Department of Commerce to seek firm proposals from private industry to take over the government's remote-sensing satellites.
Up for sale are both its meteorological satellites and the Landsat craft that carry out land surveys of the globe.
America has five civilian meteorological satellites (not counting the ones that the US Air Force runs).
They either hover above the Equator or pass over the poles.
Data from these vehicles are given freely to other nations in a global system coordinated by the World Meteorological Organisation.
The task of sorting out proposals from private industry-falls to John McElroy, the administrator of the National Environmental Satellite, Data and Information Servis (NESDIS).
The organisation is based in Suitland, near Washington DC, and operates both the meteorological and Landsat craft.
McElroy's job — and that of most of the other 1100 people who work for NESDIS — would disappear if he discovers that firms are willing to take over.
The front runner is Comsat, a satellite company that already has interests in communications and TV.
Comsat has offered to buy all the satellites and Earth based control hardware for $300 million.
It says it can make a profit by selling the data around the world — and save the US taxpayer cash by reducing public spending.
The US's weather and Landsat craft cost about $250 million per year to run of which only about $20 million is recovered.
But the bureaucratic complexities start with the decision about what to do with the computers run by the National Weather Service, which, like NESDIS, is part of the government's National Oceanic and Atmospheric Administration.
The computers process the satellite data to turn them into useful information.
Any firm taking over the craft would need similar processing capacity.
On the other hand, forecasters in the weather service have access to a lot of non-satellite data — from recording instruments on the ground for instance— which, presumably, a company would need to make any sense of the data from space.
There is a similar question mark about the future of the archival centres that NESDIS runs.
Computers at the centres hold information of vital importance to any private forecaster.
The government — and Congress, which will finally decide the issue — will also have to weigh up whether to sell the Department of the Interior's data centre in South Dakota, that distributes Landsat pictures.
On an international front, there are rumblings of discontent from the World Meteorological Organisation.
Officially, the organisation would not comment on the proposed change.
According to the organisation, the process under which the US government makes available weather data freely to other nations would continue as before.
The only difference would be that the government would pay a private firm to provide the data in the first place.
But some weather researchers at the organisation think that the scientific value of the data could be reduced if a commercially minded company is at the helm in the US.
Further, the principle of freely swapping weather data could be undermined by a firm setting out to market the information at the highest price.
Priddle takes up the poisoned chalice for PWRs
 ROBERT Priddle, under-secretary at the Department a Energy this up at the Sizewell inquiry to bare the soul of his department's strategy.
It should never have happened.
Apparently the offer from the department to submit itself to cross-examination came about because of a gaff in communications between the department and counsel instructed on its behalf by the Treasury Solicitor.
Having announced that it would take the stand, however, the department feared the consequences of backing down.
So, this week, Priddle bit the bullet.
He faced questions from 17 organisations all keen to exploit, inconsistencies in the department's published evidence.
One particularly embarrassing area for the government, and for Priddle himself, is the question of investment in energy conservation.
Priddle's division inside the department last year wrote a draft report on conservation for energy secretary, Nigel Lawson.
But Lawson shelved it, apparently because it urged a change of policy, and asked his economics and statistical division for another version, which was published.
Then there is a report by Whitehall scrutineer, Sir Derek Rayner, which is highly critical of the way the government has handled energy conservation.
His as-yet unpublished review concludes that conservation has had little impact on overall energy policy.
It criticises the duplication of R&D between different government departments and argues that a new division should be created at the department for energy conservation.
Rayner wants an energy-efficiency office to assume control of all mainstream R&D on conservation, including that done by the Building Research Establishment, Another area of contention surrounds the department's assumptions that coal and oil prices will rise in the next few years — a prospect rather difficult to square with the growing coal mountain in Britain and OPEC's slashed oil prices.
Questioners also want to know if the government's acceptance of an amendment to the present Energy Bill — which will force the electricity supply industry to consider combined heat and power schemes (CHP) as a statutory duty — heralds a shift in policy.
. The Nuclear Installations Inspectorate this week told the inquiry that it has identified 82 unresolved safety issues affecting the design for Britain's first PWR station at Sizewell.
They range from earthquakes to cooling systems.
Another one behind
LONDON had a little drizzle on the evening of 28 April 1981.
This was  unfortunate for passengers waiting for the 31 bus, as an article in the current issue of the research journal London passenger transport shows.
The timetable chart (top) shows how the bus was supposed to run and the one below how it did run.
Only six out of 15 northbound buses due to run actually appeared on the route.
The journal says that the evening service ‘can only-be described as disgusting; the last -TWO northbound buses were cancelled — and the one before ran early.’
Safety belt rip — off
GREEDY garages in Britain are taking advantage of the new legislation on seat belts in cars by taking anxious parents for a ride.
They are overcharging for fitting childrens' safety seats.
A snap survey in the West Country by New Scientist found that a number of garages want £8 or more for what should be just a few minutes' work.
Charges for similar vehicles in France vary-between £5 and £10.
The highest quote came from an Alfa Romeo main dealer.
The £56 (for fitting an Alfasud seat) included a metal bar to reduce the space taken up by the safety-straps in the boot.
But technical staff at Alfa Romeo's headquarters in Britain were amazed that charges should be so high.
‘It only takes a few minutes,’ said one.
Across the Channel, garages were astonished at the level of charges in Britain.
One Alfa Romeo dealer quoted less than £5 and another said ‘£7 at the very most’.
A mechanic for Britax France refused to believe that British installation charges did not include the cost of the seat as well, ‘It takes 10 or 15 minutes at the most,’ he said.
One hang-up for the profit-motivated British garage is that they feel it is not worth taking on work for less than a tenner.
So sometimes they-will not carry-out the work themselves, but rather drive the car to a specialist centre and charge for the time.
British garages also work more slowly than their French counterparts.
A number of British garages refused to quote for the job directly, giving only-their hourly-rates and an estimate of how long it would take.
One-and-a-half hours was typical, though a number of fast workers reckoned they could buckle down and get a baby seat fixed in one hour flat.
‘It's very  possible that garages do take people for a ride,’ acknowledged a spokesman for Kangol, one of the major baby-seat manufacturers.
‘They may feel they're charging what the market will bear.’
Enemies unite to clean up Caribbean
IN COLOMBIA next week, 27 nations will sign a treaty to protect and develop the waters of the Caribbean.
Many of the countries signing the convention — particularly the smaller islands such as Barbados, Grenada.
Haiti and St Lucia — depend on clean coastal waters, because fishing and tourism provide much of their income.
But the convention only covers pollution at sea, whereas most coastal pollution arises inland, from industrial discharges, untreated sewage, fertiliser run-off and erosion.
At risk are the coral reefs, mangroves, lagoons, marshes and estuaries that support much of the region's wildlife.
The main threat to the deep seal is oil spills.
Attempts to change the land-based activities that cause coastal pollution would have far-reaching economic, political and social consequences.
The watershed of the Caribbean extends across a huge area from the industrial cities of the northern US, which discharge waste into the Mississippi, to the Colombian Andes.
In order to ensure that all 27 countries will sign the treaty, however, the negotiators have deleted all references to coastal waters from the original draft.
The United States wanted the treaty to apply only outside the 12-mile limit of territorial waters, but it was overruled.
The final draft refers only to the marine environment, which, according to Patricia Bliss-Guest, UNEP's legal advisor, eliminates large parts of the Gulfs of Mexico, Venezuela, and Campeche, as well as extensive coastal areas throughout the rest of the region.
‘If that is the definition.’
Michael Wright, a lawyer on the staff of the World Wildlife Fund, told New Scientist , ‘then there are some ridiculous anomalies.’
The treaty, cc-ordinated by the United Nations Environment Programme (UNEP), will make strange bedfellows of a number of enemies.
The United States will sign, along with Cuba and Nicaragua: Colombia, Venezuela, and Guyana, each of which claim parts of one another 's territories, will join forces.
And conservatively ruled Jamaica is teamed with its ideological foe, the leftist government of Grenada.
The treaty, to be known as the Cartagena Convention after the city where it will be signed, comes after seven years of negotiations.
UNEP officials hope that the treaty will be augmented by subordinate treaties, or protocols, dealing with subjects such as endangered species and seabed exploration.
A protocol on oil spills, which will also be open for signing at Cartagena, does mention ‘the marine and coastal environment’.
But it is hedged around with qualifying clauses that restrict a country's responsibility to act.
Signing the convention will not oblige the 27 Caribbean nations to take any action.
Signatories agree simply to ‘take all appropriate measures to prevent, reduce and combat pollution’ of the marine environment.
When 16 Mediterranean states signed a similar ‘framework treaty’ in 1976 they considered it so insubstantial that they insisted on all parties to the treaty also signing at least one of the more detailed and binding protocols.
It is not yet certain whether the parties to the Cartagena Convention will make a similar decision.
One cause of the cynicism that surrounds the adoption of the convention is the fate of an earlier agreement among the same parties.
In 1981 they adopted an action plan for the Caribbean and pledged $1.2 million to a trust fund to finance environmental projects.
The United States was the only country which refused to contribute.
But so far the countries have paid in less than $140 000.
Most of that, ironically, came from the smallest countries such as St Kitts, Nevis, Grenada, St Vincent, and Barbados.
The region's richest powers — including Mexico, Venezuela and Colombia — made big promises, but haven't paid up.
Officials are embarrassed by the fact that the total in the fund is still so small than under United Nations rules, none of it can be spent.
Kohl considers shake — up for research
THE PROSPECT of a shake-up in the West German science establishment is being discussed in Bonn, following the runaway victory of Chancellor Helmut Kohl in last week's general elections.
One idea being canvassed would centralise all research under the science and technology ministry and its powerful minister, Heinz Risenhuber.
Another sees Riesenhuber in charge of a new ministry of the environment, where he could head off the political challenge of the Green movement which enters the West German parliament for the first time after the election successes.
The environment has hitherto been a fief of the interior ministry.
Whatever the organizational changes few people in Bonn expect any fundamental shifts in science policy.
Officials see the main thrust as: more freedom in basic research to allow decision making by scientists rather than government more encouragement for private enterprise to invest in research a push to persuade state research bodies to do more contract work for industry and rely less on government funds.
Kohl's Christian Democrats will continue to back nuclear power.
But falling forecasts of energy demand make a new drive towards nuclear power unlikely.
Nuclear research will continue however.
Projects include the Fast-breeder reactor demonstration project and a high temperature gas-cooled reactor.
Sacked nurse takes ECT case to Europe
ONE OF Britain's first conscientious objectors in psychiatric nursing is fighting to win the right to refuse to carry out electroconvulsive therapy (ECT) on mental patients.
Les Parsons, an ‘exemplary’ third-year student at Broadland School of Nursing, was dismissed last July after he refused to continue administering ECT.
Last week an industrial tribunal in Norwich upheld the sacking.
‘I plan to appeal the decision and if necessary take the case to the European Court of Justice,’ Parsons says, ‘It is a moral issue: ECT's mode of action depends on the damage it causes to the brain.’
The tribunal stressed throughout that its role was only to assess whether the health authority had followed proper procedure.
In December the Shenley psychiatric hospital in Hertfordshire dismissed another student nurse, Dee Kraaij for a similar offence.
She plans to appeal to an industrial tribunal.
Since the invention of ECT in 1938, electric currents have been used to induce seizures in the brains of many patients suffering from a wide range of mental disorders.
The technique is less popular today, having been superseded by psychotropic drugs.
ECT is now largely restricted to patients suffering from ‘endogenous’ depression — often working class women who become depressed, even though no dramatic misfortune has befallen them.
Most psychiatrists regard ECT as the most effective and rapid treatment for these cases of severe depression.
But the beneficial effects are often transitory.
‘ECT is a temporary solution,’ says Professor
Frederick Jenner of Sheffield's Royal Hallamshire Hospital.
In several countries, such as West Germany and Spain, and in California, ECT is rarely used.
The treatment is controversial because it can have unfortunate ‘side-effects’.
Impairment of memory and general confusion are commonplace after ELM and sometimes persist.
Little is known about its long-term effects.
‘It is an empirical treatment, rather than a scientifically-established one,’ says Larry Gostin of the charity, MIND, No one knows how ECT exerts its effects.
Presumably the metabolism of brain cells is disrupted and some cells die.
Professor Steven Rose, a neurobiologist at the Open University, says: ‘The treatment is analogous to attempting to mend a faulty radio by kicking it.’
Even psychiatrists in favour of ECT acknowledge that it can be misused.
A report by the Royal College of Psychiatrists two years ago found that
‘ECT is usually left to junior members of the staff…with little training and guidance’, A leading psychiatrist in the field told New Scientist that ‘the commonest misuse of ECT is on people who are really unhappy, distressed or sad, rather than ill with a depressive illness.’
Ward nurses are beginning to argue that they often know the patient better than the busy consultant possibly can.
Paul Walsh, senior nursing officer in the psychiatric unit of Wexham Hospital in Slough, was sacked recently when he refused to forcibly inject a patient who was regarded as lucid by the nurses.
Walsh said that the patient had previously suffered severe side-effects from the drug.
The dispute led to mass resignations among the nursing staff and the closure of the 70-bed unit for two months last year.
Under the new Mental Health Act, passed last year, a patient who objects to treatment is now guaranteed a second opinion — but treatment still goes ahead if both doctors agree.
Nurses and doctors are legally entitled to refuse to perform an abortion, but the unions representing nurses seem reluctant to lobby for a similar right to object to ECT.
‘The worry is probably what else you could object to, in the long-term drug therapy, for instance,’ says Simon Hebditch of MIND.
MPs are beginning to take an interest in the issue.
Last June David Ennals tried to introduce an amendment to the Mental Health Act which would have allowed nurses to withdraw from ECT.
But it was defeated.
Several other MPs on both sides of the House of Commons may soon be urging legal reform.
Soviet military research powers on
THE SOVIET UNION is employing 900 000 scientists and engineers on research and development — 200 000 more than the United States.
More than half these are involved in the arms programme.
So says the US Pentagon in a book,Soviet Military Power 1983 , published last week.
The Pentagon claims that the Soviet Union devotes 15 per cent of its gross national product to defence, compared with 7 per cent in the US, and the figure will approach 20 per cent by the late 1980s.
The Pentagon expects the Russian strategic rocket forces to complete re-equipping with the latest series of intercontinental ballistic missiles (ICBMs) by the mid-1980s.
By then, the totals will be 520 SS 11s, 60 SS-13s, 150 SS-17s, 308 SS 18s and 360 SS-19s.
These missiles can carry several warheads each, bringing the total to 6400.
Many of Russia's ICBMs are accurate enough to destroy American Minuteman ICBMs even though they are housed in protective silos, says the Pentagon.
Russia's first Typhoon-class submarine, which displaces 25000 tonnes (more than the British aircraft carrier HMS Invincible), has recently started test firings of the new SS-NX-20 ballistic missile, which can carry several nuclear warheads over a range of up to 8300 km.
Another new type of submarine, the Oscar, can fire its 16 cruise missiles over a distance of 500 km to attack ships.
The third new nuclear-powered design, the Alpha has a titanium hull and can dive deeper than any Western submarine.
The Alpha cruises at 75 km per hour — faster than any other.
The Pentagon expects the new Blackjack strategic bomber, which has swing wings like those of the USAF's B-I, but is bigger, to enter service in 1986 or 1987.
Blackjack can carry nuclear cruise missiles with a range of 3000 km.
The Russians unlike most of their Western counterparts, place great emphasis on civil defence.
The Pentagon estimates that 150000 Russians work full time on civil defence during peacetime, This would rise to 16 million in war.
The efforts cost $3000 million every year.
One area where the gap between the Soviet Union and the West is most obvious is in space.
Russian satellites weighing a total of 300 tonnes go into space every year — 10 times as much as those launched by the US.
On any given day, between 70 and 110 Russian satellites are orbiting the Earth.
More than half of these are purely military, and only 15 per cent are entirely civilian.
The Russians are now developing three new space launchers.
The largest of these will be able to lift six to seven times the maximum load that the space shuttle can carry.
The Russians now have more than 150 major factories building ships, aircraft, missiles, armoured vehicles, artillery, ammunition and explosives.
During 1982 alone, the Nizhniy Tagil Railroad Car and Tank Plant built 2000 tanks.
The Pentagon believes that the Russians are slowly but surely catching up with Western technology, often with Western know-how.
In the field of direct-energy weapons (’ death rays’) the Russians are well ahead.
Their high-energy laser programme, concentrating on chemical lasers, is three to five times the size of its US equivalent.
The Pentagon believes that, using existing technology, the Russians could deploy laser weapons as early as the mid-1980s.
Extraterrestrials have landed on Antarctica
The southern icy continent has been yielding a harvest of strange meteorites
Ursula B. Marvin.
WITHIN the past decade, the thick ice sheet that covers Antarctica has yielded more than 5000 fragments of meteorite.
The vast majority are specimens of stony meteorites, types already abundant in the world's museums; but a few have proved to be entirely new species.
In addition, about 36 fragments of metallic nickel-iron meteorites have been collected, one of which contains minute diamonds, and is the second of its kind known in the world.
Indeed, the ice sheet's frozen cargo may include meteorite specimens derived not only from the fragmentation of asteroids and possibly of comets but also from the Moon and Mars.
This week, about 20 scientists, attending the Lunar and Planetary Science Conference at NASA's Johnson Space Center in Houston, compared results of preliminary studies on a meteorite found by a US party in the final days of its 1981–82 expedition to Antarctica.
The 31-gram specimen, about the size of an apricot, has properties in common with‘soils from the lunar highlands.
If the evidence proves conclusive, this will be the first piece of the Moon ever found on Earth.
In addition, new data strengthen the idea that a group of nine unusual stony meteorites may have come from Mars.
Two of the specimens were found in Antarctica and one each in Egypt, France, Brazil, the US, Nigeria, India and Australia.
Thus, years after the US and the USSR last sent space probes to the Moon to gather rock samples, a rich harvest of exciting new samples from space is turning up on Earth and which often raise more questions than they answer.
TO SEARCH for Antarctic meteorites is an  exhilarating adventure.
It takes one to the high, isolated polar desert at the height of the summer season.
Tent camps are set up, always within sight of spectacular mountain scenery, and daily searches are made by snowmobiles.
The Sun is always above the horizon and the temperature ranges from about 10o over to 15o below zero (Fahrenheit).
Bright and windless intervals, ideal for working, alternate with high winds, overcast skies, and blowing snow that keeps the parties tent bound.
The remarkably productive research programme aimed at collecting meteorites in Antarctica, currently furnishes research materials to at least 90 groups of investigators in 13 countries.
It illustrates the part that accident can play in science.
Nobody predicted that Antarctica would be a promising place to search for meteorites.
Indeed, when a collecting programme was first proposed to the US National Science Foundation in 1973 it was severely criticised by reviewers, who claimed it would be an expensive and essentially hopeless venture to search the vast polar wastes for meteorites.
Certainly, previous experience had not been encouraging.
All the expeditions to Antarctica before 1969 had together found only four meteorites.
The Australian geologist Douglas Mawson discovered the first in 1912 when he spotted a black stony meteorite in the snow near the coast of Adelie Land (Figure 1).
No more were found until 1961 when a party from the Soviet Union discovered two fragments of a broken nickel-iron meteorite lying in a glacial moraine near Lazarev Base.
A year later, US geologists found on a moraine in the Thiel Mountains two portions of a rare type of stony-iron meteorite, called a pallasite, consisting of individual crystals of olivine,(Mg, Fe) 2SiO4, scattered through a matrix of metal.
In 1964 another US team found an iron meteorite lying on bare rock in the Neptune Mountains.
All these were chance discoveries by scientists engaged in other pursuits.
Three of the meteorites were found on rocky terrain where they may have fallen directly or been deposited by melted ice.
To search for meteorites among the dark cobbles and boulders of dolerite that abound in such areas would indeed be an unrewarding task.
By chance, in December 1969, Japanese glacial geologists surveying broad fields of blue ice inland from the Yamato Mountains ( officially , the Queen Fabiola Mountains) at about 70°S; 37°E, stumbled upon nine black meteorite fragments lying within a short distance of one another.
Although they had no special interest in meteorites, the geologists collected the specimens and shipped them to Japan, assuming they were all pieces from a single meteorite shower.
Dr Maqsako Shima first reported mineralogical studies of the Yamato specimens at a meeting of the Meteoritical Society in Davos, Switzerland, in August 1973.
She had analysed four of the specimens and found that each belonged to a completely different class of stony meteorite!
This unprecedented discovery indicated one of two things: either at least four meteorites had fallen at the same place in Antarctica (an event of vanishingly small statistical probability), or fragments of four meteorites, which had fallen at random on the interior ice sheet, had been carried to the Yamato Mountains site by ice motion.
Suddenly, in the light of this possibility, Antarctica looked like a uniquely favourable place to search for meteorites.
Professor William A. Cassidy, of the University of Pittsburg, listening to Shima's tale, resolved to search for meteorites on the other margin of Antarctica, near the US base on McMurdo Sound.
His proposal was such a departure from traditional Antarctic programmes that three years elapsed before support was provided and field preparations completed.
Meanwhile, Japanese scientists returned to the ice fields of the Yamato Mountains, specifically to search for meteorites, in the southern summer of 1973.
That year they found 12 more specimens.
The following season they collected 663, and 307 specimens in 1975.
Returning in 1979 to search ice patches near the Belgica as well as the Yamato Mountains, they found about 3000 more specimens!
In four polar summers nearly 4000 specimens were added to the world's meteorite collections (see Box I).
The first American collecting party, led by William Cassidy, arrived at McMurdo Station in November 1976.
There they joined Japanese geologists who had also come to McMurdo Station that season to search for meteorites.
American and Japanese scientists worked together for three seasons, sharing equally in the specimens discovered.
The Japanese experience at the Yamato Mountains suggested that when meteorites were concentrated it happened behind mountain barriers where patches of bare ice lay stagnant.
The continental ice sheet that lies three kilometres thick at Dome C in East Antarctica (Figure 3) creeps slowly coastward in all directions, carrying meteorites that have fallen on its vast, 13-million-square-kilometre surface and been frozen-in for thousands, or possibly millions, of years.
Most of the specimens probably reach the edge of the continent and float away in icebergs, which gradually melt and drop their meteorites to the sea floor.
However, it appears that, if the ice motion is slowed or temporarily halted against a barrier, the snow will be stripped away and the bare ice rippled and eroded by dry winds that continually course down the ice cap.
Meteorites are brought to the surface and concentrated in relatively small areas by a combination of wind ablation and an upward push of the ice (Figures 2 and 4).
Ice motion causes the meteorites to become concentrated in the same sort of way that mountain streams concentrate deposits of gold or other heavy minerals in ‘lenses’ or into layered structures.
After examining satellite and aerial photographs for promising ice fields behind the Transantarctic Range, the 1976 joint US-Japanese party decided to search an icy area near Mount Baldr (Figure I).
The season began in spectacular fashion when, within the first 20 minutes after the helicopter landed, Keizo Yanai, of the Institute of Polar Programs in Tokyo, discovered two stony meteorites lying a few hundred yards away.
But those were the first and last meteorites found until the six week season was ending and the party was preparing to leave Antarctica.
Then a helicopter pilot flew them to an area of bare ice studded with dark rocks near the Allan Hills (76°S; 156°E).
There, in two visits, they collected 47 fragments, 33 of which were pieces from one large 480kg stone.
Since then, field parties have returned to the Allan Hills region every year and collected more than 1200 specimens.
Observations made to date indicate that, on the average, the concentrations at the Allan Hills are denser and the specimens somewhat larger than those at the Yamato Mountains area.
About 4000 meteorite fragments have been collected from expanses of bare ice measuring about 4000 sq.
km near the Yamato and Belgica Mountains: about one fragment per sq.
km.
At the Allan Hills about 1200 specimens have been collected from 75 sq.
km of bare ice: 16 fragments per sq.
km.
In both regions the most commonly collected specimens are stony meteorites weighing 4–8 grams, but there is a statistical bias toward smaller specimens in the Yamato ice fields and larger ones at the Allan Hills.
No definitive explanations have been worked out for the differences between the two concentrations that lie 3000 kilometres apart in Antarctica.
Possibly the Allan Hills present a more complete barrier to ice flow than do the Yamato Mountains, which may let numerous specimens ride past them.
This topic is currently being studied.
Early measurements indicate that there is a significant difference in the terrestrial ages, or lengths of time since the meteorites fell to Earth, between Antarctic meteorites and those collected on other continents.
Terrestrial ages are based on measurements of isotopes, such as aluminium-26, chlorine-36, manganese-53 and carbon-14, which are produced when meteorites orbiting unshielded through space are bombarded by cosmic rays.
These isotopes begin to decay as soon as the meteorites enter the Earth's atmosphere, where they become shielded from cosmic rays.
Terrestrial ages determined on Antarctic chondrites (the most abundant type of meteorite found throughout the world, see Box 2) range from about 1000 to 700 000 years, with some clustering of ages in the range of 300 000 to 600 000 years.
Most meteorites collected elsewhere in the world fell within the past 200 years, although some dates of fall range back a few thousand years.
No doubt the ice sheet preserves specimens that would weather away more quickly in other regions.
The more ancient Antarctic specimens provide an opportunity for meteoriticists to compare the types of planetary debris that followed orbits around the Sun and across the Earth's path half a million years ago, with those colliding with the Earth today.
By means of a geodetic network of stations the dynamics of the ice sheet — its rates of forward motion, surface ablation, and upward push against the mountain barrier — has been extensively investigated.
The first such stations were erected in 1978 across the Allan Hills concentration area.
Subsequent annual measurements, made at more than 20 triangulated stations, have revealed that ice motion and ablation are not uniform from place to place or from year to year.
Instead of a simple forward and upward now, there may be a strong component of horizontal compression as the ice approaches the mountains.
Within a few seasons it should be possible to interpret the motion vectors quantitatively and to represent them in more realistic terms than in the cartoon of Figure 2.
Strange new finds
From the first, our meteorite collecting programmes have been motivated not for the sake of numbers alone but by the hope that large quantities of fragments would include samples of rare or completely new type of meteorites.
As I have already said.
that hope has been fulfilled.
Early in the programme a few specimens of achondrites were found in both the Allan Hills and Yamato ice fields.
It was also in the Allan Hills region that a rare diamond-bearing iron meteorite turned up (see Figure 5 and Box 2).
About 40 carbonaceous chondrite fragments have been collected in Antarctica.
some at the Yamato Mountains and others at the Allan Hills ice fields.
Those that have been analysed show traces of at least 20 amino acids, including glycine and yaminobutyric acid, in quantities of a few nanomoles per gram.
Minute as these quantities are, they constitute tangible evidence of the types of organic materials that existed in the Solar System more than 1000 million years before the appearance of life on Earth, the earliest traces of which are found in rocks about 3.4 x 109 years old.
The expectation of finding carbonaceous chondrites in Antarctica prompted the American teams, beginning in the 1977 season, to use sterile collecting procedures patterned on those developed for lunar samples returned by the Apollo missions.
Reliable results of organic analyses and of several types of isotopic determinations require the utmost in sample cleanliness.
And because the Antarctic ice sheet provides the cleanest and coldest natural storage on Earth, it is prudent to keep the specimens uncontaminated.
Of course, sterile collecting procedures add significantly to the difficulty of field work.
Supplies of Teflon bags, Teflon tape, stainless-steel shears and tongs, and aluminium numbering tags must be unloaded from a snowmobile at each meteorite find.
A flag is raised and the location of each specimen mapped with reference to other finds and to local reference points.
Two photographs are taken of each specimen in situ before it is sacked in two successive Teflon bags and shipped frozen to NASA's Johnson Space Center in Houston.
There rich specimen is opened in a nitrogen-filled glove box, photographed again, and the location, weight, and character of each subsample is meticulously documented before being allocated for scientific study.
To speak as I have of meteorite ‘concentrations’ may conjure the wrong image.
Sometimes, when one meteorite is discovered another may be visible nearby, but much more commonly four searchers may ride abreast over long stretches of blue ice and drifting snow before anyone sees a meteorite.
Few thrills can compare with that.
After travelling halfway around the globe to one of the remotest spots on Earth, encasing oneself in goosedown against the cold, mounting a snowmobile and riding through the vastness, the glimpse of a dark object starts the heart pounding.
Racing toward it, the excitement grows as one sees it is not a shadow, not a glacial cobble, but a meteorite — a piece of rock from another planet!
Sometimes in the wind and cold of the ice fields, a meteorite hunter (who is never allowed to touch a specimen by hand or glove) may misidentify a weathered specimen and ship a terrestrial ‘trash rock’ to Houston.
No matter — the collecting procedures now used by both the US and Japanese team preserve the integrity of our extraterrestrial finds.
The ‘lunar’ meteorite
The Antarctic meteorite (ALHA8 1005), which is suspected of coming from the Moon, was discovered far to the west of the main meteorite concentrations in the Allan Hills region.
Late in January, 1982, as the season was ending and the weather deteriorating, a member of the American team accompanied a visiting geologist on a long snowmobile traverse to examine the regional configuration of the ice sheet.
Many miles from camp they came upon a small specimen partially coated with a frothy greenish-tan crust.
At first glance they realised that the specimen differed from any meteorites they had ever seen.
Their impression was fully shared by the experienced meteorite processors who unwrapped the stone in Houston (Figure 6).
Later, a thin slice of the rock, cut for microscopic examination at the Smithsonian Institution in Washington, revealed a striking similarity between sample ALHA81005 and lunar highland breccias (welded soils).
The specimen is an aggregate of rock and mineral fragments and glass spherules welded together by streaky brown glass (Figure 8 and cover picture).
The prominent white clasts are fragments of anorthosites — calcium and aluminium-rich rocks that make up the bulk of the lunar highlands crust and give it the light colour that is visible from Earth.
Anorthosites occur on Earth and Moon, but have rarely been seen in meteorites.
Analytical results reported at the Houston Conference indicate that the pyroxene minerals (that is, the Calcium, magnesium, iron silicates (Mg, Fe, Ca) 2Si206, which are also common in terrestrial basalts) within the anorthosite clasts (fragments) have typically lunar ratios of iron to manganese oxides (FeO/MnO).
The lunar ratios differ significantly from those in achondritic meteorites.
The abundances and distributions of rare earth elements and of implanted rare gases, and the oxygen isotopic ratios in ALHA8 1005 are also typically lunar rather-than meteoritic.
We still await determinations of the ages of the rock itself or of any of its components, but the degree of cosmic-ray bombardment is being measured to see if it is consistent with the short interval required to project material from the Moon to the Earth.
The derivation of a sample from the Moon poses staggering dynamic problems.
To escape from the Moon's gravitational field, a sample must be accelerated to a velocity above 2.4 kilometres per second.
The only force generally believed to be sufficiently powerful is the high-energy impact of a large asteroidal fragment on the Moon.
Ballistics theory predicts that only deep-seated target rocks at ground zero would be accelerated to escape velocity; and all ground zero material would be melted to glass by the shock.
But rock ALHA81005 is not deep crustal material and is not shocked to glass.
It is a mixture of particles typical of the shallowest layer on the Moon — the lunar soils.
It has been no more severely shocked than many of the specimens picked up by the Apollo astronauts who journeyed to the Moon to find them.
Needless to say, this rock is forcing us to reexamine totally meteorite impact dynamics, and is broadening the range of materials we define as meteorites (see Box I).
If, despite all current indications, some future studies show that specimen ALHA81005 did not come from the Moon, that will make the sample all the more intriguing.
In that event, the Antarctic ice sheet has provided us with a sample of a planetary body we have never seen, but which has a Moon-like anorthositic crust and a Moon-like soil layer.
Martian meteorites
Whatever difficulties may attend the blasting of a lunar sample to Earth, those involving samples from Mars are quite simply horrendous.
The escape velocity from that planet is a prohibitively high 5 kilometres per second.
No target material should survive the shock pressures accompanying the requisite impact.
Nevertheless, there are nine known meteorites, including the Antarctic specimen shown in Figure 10, that some meteoriticists suspect come from Mars.
These strange achondrites have been termed ‘SNCs’— shergottites-nakhlites-chassignites being so named after three of the localities where they fell: Shergotty (India), Nakhla (Egypt) and Chassigny (France).
The first inkling that these stony meteorites might not be samples of asteroidal-sized bodies came when isotopic age determinations indicated that they crystallised only about 1.3 x 109 years ago.
This is remarkably young in comparison with the 4.5 x 109 year age of other meteorites.
What planetary body could have been sufficiently hot internally to generate igneous magmas so recently?
The question may seem strange in view of the present-day active volcanism on Earth.
But the Earth is a large planet and its radioactive elements have kept it warm and dynamically active since the birth of the Solar System.
The Moon, in contrast, melted almost completely soon after it formed but cooled rather quickly.
Its crust was already thick and rigid enough to hold open huge basins as early as 4.2 x 109 years ago; and the great floods of mare basalt that filled the basins apparently ceased to erupt about 3.1 x 109 years ago.
There is little evidence of subsequent igneous activity on the Moon.
The asteroids, with diameters of less than 1000 kilometres, were already cold 4.5 x 109 years ago.
Most stony meteorites formed at that time as did the irons, which had already solidified from cores or pools of molten metal that lay within their small parent bodies.
The SNC meteorites are not suspected of being material ejected from Earth following a major impact and which subsequently fell back to Earth.
Their chemical and isotopic compositions are meteoritic and they have had long histories of flight through space.
The Moon and asteroids are unlikely sources.
Where, then, did the SNC meteorites originate?
Could it be Mars?
Mars has immense volcanic cones on its surface and, for all we know, there was igneous activity 1.3 x 109 years ago or even more recently.
But in considering Mars as a possible source of meteorites we face, once again, the dynamic problems.
Most of the SNC meteorites have sustained shock, but not to any degree approaching that predicted for Martian target rocks.
The shergottites, for example, have igneous textures with interlocking crystals of feldspar and pyroxene minerals.
The feldspars have been shocked in situ to glass, but the pyroxenes have not, and the original fabric is still fully visible.
Dr Donald Bogard of the Johnson Space Center reported at the Houston meeting one more line of evidence favouring a Martian origin for the SNCs.
He has measured noble gases trapped within the meteorites and found them similar in composition to the Martian atmosphere analysed by NASA's Viking landers.
He speculated that the gases may have been injected into microcracks in the Martian rocks during an impact event, and that samples of these rocks were subsequently orbited to Earth.
Despite all the theoretical and intuitive objections to a Martian origin — the uncertainties of the evidence and difficulties of proof — excitement is mounting at the possibility that, without waiting for a mission to return samples from Mars, we may already have Martian samples at hand.
Meteoriticists are now searching for further specimens in the Canadian Arctic and there are plans for expeditions to northern Greenland.
Meanwhile, the news from the season just past is that the US field party has discovered three more large concentrations of meteorites in a newly explored region of Antarctica.
1.
What is a meteorite?
ACCORDING to present usage, the term meteorite applies to any natural object from an outside source that plunges through the atmosphere and is collected on the Each.
Even a certifiable Moon rock that makes its own way to the Earth will be called a meteorite.
The term does not apply, however, to material ejected after a major impact on Earth and which follows a suborbital path back through the atmosphere to the Earth's surface.
Japanese Antarctic finds
We do not know how many individual meteorite falls are represented by the wealth of Japanese meteorite finds in the Yamato and Belgica mountains.
Many meteorites explode during passage through the atmosphere and fall in showers.
(The largest shower on record, which pelted the Earth with an estimated 100 000 stones occurred at Pultusk, Poland, on the evening of 30 January, 1868.)
By international agreement, all pieces of a given shower are catalogued as a single meteorite and named after a nearby geographical feature (it can be a town, a post office or prominent natural feature).
Before the discoveries in Antarctica about 2100 individual meteorites were known worldwide.
Preliminary studies have led Japanese scientists to estimate that their Yamato Mountains finds represent several hundred discrete meteorites.
2.
How many kinds of meteorite are there?
AMONG METEORITES seen to fall worldwide about 96 per cent are stones , including 87 per cent chondrites and 8 per cent achondrites.
Chondrites are unmelted, fragmental aggregates of stony and metal grains and small spherical silicate bodies called chondrules, that have no counterpart in rocks of the Earth's crust.
Achondrites lack chondrules; they are igneous rocks or planetary ‘soils’.
An additional 3 per cent of meteorites are irons and 1 per cent are stony-irons , Some achondrites are basaltic in texture and composition and appear to be samples of lava flows from the surfaces of their parent bodies.
Most achondrites are ‘breccias’— rocks that have been crushed and recemented with angular fragments (clasts) lying in a finer-grained matrix, Before the Antarctic programme, two of the more common types of achondrites were classified as eucrites and howardites on the basis of the number of source rocks among their clasts and on the magnesium content of their  pyroxine minerals (Mg, Fe, Ca) 2Si206,— pyroxenes are the most abundant iron magnesium silicates in igneous rocks.
Eucrites were defined as ‘monomict breccias’, that is, derived from a single source rock.
Howardites were defined as ‘polymict breccias’, that is, derived from more than one source rock and containing pyroxenes that are characteristically more magnesium-rich than those in eucrites.
However, these  distinctions broke down when some specimens from Antarctica proved to be polymict but devoid of magnesium-rich howarditic pyroxenes.
Polymict eucrites ’ have now been established as a new class of stony meteorites.
Are they pieces of parent body that broke up and sent a special type of debris into a path crossing the orbit of the Earth hundreds of thousands of years ago but which is no longer falling on the Earth?
Not quite: one meteorite that can now be classed with the polymict eucrites fell at Macibini, South Africa, on 23 September, 1936.
Today, thanks to the recent finds in Antarctica, the Macibini stone is no longer unique, and plenty of polymict eucrite samples are available to scientists around the world who are examining the genetic relationships between these and other meteorites.
Ureilites are another rare class of achondrites, of which six specimens have been collected in Antarctica and five in the rest of the world.
Ureilites bear some similarities to certain ultramafic rocks from the Earth's lower crust or upper mantle.
The ureilites consist mainly of clots of magnesium-rich olivines and minor clinopyroxenes in dark matrices of carbon (graphite), ferrous sulphide (troilite), and nickel-poor metal.
Some of the graphite has been transformed to minute crystals of diamond and lonsdaleite (a hexagonal form of diamond) in aggregates similar to those produced by shock-wave experiments in the laboratory.
Because all known ureilites are much too small to have sustained high energy impact on the Earth, we conclude that they acquired their diamond-lonsdaleite intergrowths when their parent bodies collided with other objects while hurtling through space.
The same explanation is called upon to account for the single small diamond and lonsdaleite-heating iron meteorite found in the Allan Hills area.
This specimen, which weighs only about 10 kilograms, shows a thin, surficial zone altered by heat (the interior stayed cold), which indicates that it passed through the atmosphere as a small body and so undoubtedly made a soft landing on the ice sheet (Figure 5).
Only a very large body, weighing about 100 tons or more, will retain its cosmic velocity and plunge into the Earth with explosive force.
The only other iron meteorite known to contain diamonds, also in clumps with lonsdaleite, is Canon Diabolo, a huge mass of metal which shattered into hundreds of shrapnel-like fragments during the impact at enormous velocity and which excavated the I.2-km diameter Meteor Crater in northern Arizona.
Carbonaceous chondrites are among the more precious and intriguing classes of Meteorites.
Many of these dark, sometimes fragile specimens contain water and hydrocarbon compounds including amino acids and fatty acids.
None of these organic molecules shows evidence of originating from living matter.
Indeed, their optical properties reflect a non-biological origin.
The molecules may well have existed in the primeval nebula from which the bodies of the Solar System formed, about 4.5 x 109 years ago.
Microwave detectors have recently revealed the presence of organic molecules in interstellar space, and optical spectra show traces of them in comets.
It is possible that we have traces of interstellar dust in meteorites.
Most meteorites are believed to be fragments of collisional debris from asteroids, but there is some evidence that carbonaceous chondrites may be stony masses released from the icy nuclei of comets, which lose their frozen binding material as they orbit close to the sun.
One modern interpretation suggests that water- and carbon-rich carbonaceous chondrites formed by the hydration of originally dry mineral assemblages.
Why do whales come ashore?
Mass stranding of whales are quite common, as in East Anglia last  autumn But why they happen is still a mystery
Katharine Parry, Michael Moore, Captain G.Hulland
IN THE LAST WEEK of October 1982, the Wash, in eastern England, was the site of yet another mysterious episode of whale stranding.
Scores of pilot whales (Globicephala melaena)invaded the shallows and 30 or so died.
This provided us with an opportunity to investigate the whales to see if we could discover anything about them that might explain why they had beached themselves.
Whale strandings are nothing new around the British isles, and careful records have been kept since 1913.
These records show that strandings, especially of pilot whales, have increased over the past 25 years.
Indeed, mass stranding of toothed whales (Odontoceta) are relatively common around the world.
But baleen whales (Mysticeta), such as the blue whale and hump back, which use their vast curtains of whalebone to sieve a living from the sea, are very seldom stranded.
Sometimes isolated toothed whales become stranded when, as a result of disease, they seek the shoreline to avoid drowning; after all, they are air-breathing, and if they cannot swim, they drown in deep water.
But there is little evidence that disease plays an important part in mass strandings.
Occasional reports suggest that a single ailing individual can precipitate a mass stranding: whales are often reluctant to leave their comrades particularly if the sick animal is the leader of the group, and they may strand themselves rather than depart.
The events in the Wash have been documented with considerable precision.
In the week before the stranding several people, mainly fishermen, claimed to have seen whales entering the Wash, perhaps in pursuit of the fish that make up the bulk of their diet.
Then, on Friday 29 October, inshore fishermen reported that there were up to 100 whales dead and alive, in the vicinity of Clay Hole (see map).
Later one of us (GH) confirmed that there were between 30 and 35 pilot whales there, and some were indeed dead by dusk.
The next day, seven carcasses were found early in the morning on Old Sand and Herring Hill.
They ranged in size from 2.4 metres to 9 metres.
That afternoon two more carcasses turned up at the northern end of Butterwick Low, and another two were reported from the Norfolk coast, close to Cromer.
Also on the Saturday, a pod (group) of live whales was spotted over Toft Sand.
It was just before low tide, and the whales were in about 2 m of water.
A group of volunteers, led by Captain Hulland, used inflatable boats and a launch belonging to the Boston Ports Authority to shepherd this pod towards the deeper waters of Boston Roads.
As we were going through Freemans Channel the pod  baulked , refusing to move.
Odd individuals kept swimming away, only to return a short while later.
After an hour or so of this the group swam slowly and steadily away in a north-easterly direction along the Boston deeps, and they were watched following this course until the light failed.
On Sunday there were reliable reports of a pod of live whales off Skegness, and two more carcasses were found on the south bank of the river Witham and another near Tabs Head.
Between 10 and 16 live whales were seen milling around the mouth of the Nene at 8.30 that morning; low water was at midday, and at about 5 that afternoon the pod was seen swimming off to the north on the rising tide.
This was the final reliable sighting of live whales.
The stranding had left at least 28 pilot whales dead.
We took the opportunity to perform a postmortem on one of them, a 5 ½ m male.
We found he was in good shape, but had no food in his intestines.
There were a few thorny-headed worms (Acanthocephala spp) in the small intestines, but not many other gut parasites.
All the internal organs looked pretty normal to the naked eye.
There were some granulomatous area on the lower edges of the lungs, possibly caused by migrating worms, but these seemed to be old lesions and not evidence of a newly acquired disease.
The heart looked normal.
When we looked in the blowhole, the whale's equivalent of nostrils, we found a few nematode worms, just over 2.5 cm long.
These proved to be Stenurus globicephalae , and they were also present in much greater numbers in the pterygoid air sinuses close to the middle ear cavity (see Figure).
We examined the lining of these air sinuses, but could find no damage caused by the worms, and there was no sign of worms in any of the passages of the lungs.
The carcass, unfortunately, was in quite an advanced state of decomposition by the time we got to it, so we could not look at the detailed histology (cell structure) of the internal organs or the central nervous system.
We examined the air sinuses of two other carcasses from this stranding, and in both we found Stenurus worms.
Martin Sheldrick, of the British Museum (Natural History) has investigated and catalogued the cetacean strandings around Britain in modern times.
(This job has devolved onto the BMNH from the Queen, who owns all stranded whales but no longer takes an interest in them.)
He found Stenurus in all the other bodies of this stranding.
So, is there any connection between the nematode infection and mass strandings?
Mass strandings have been known since the time of the ancient Greeks; Aristotle himself recorded them.
Then, as now, people were at a loss to help the whales back to deep water, and even more so when it came to explaining the phenomenon.
Many theories have been suggested and most back to the whale by the environment and any objects, such as fish, nearby; the whale builds up a picture of its surroundings from these echoes.
It is possible that an individual's echolocation system is impaired or disrupted when the whale is close to gentle sloping sandy beeches.
It is certainly odd that mass stranding usually involve deepwater species, not only pilot whales but also sperm whale and white-sided dolphins.
Inshore species, such as the familiar bottle-nosed dolphins, the white-beaked dolphin and the harbour porpoise, rarely strand in large numbers.
Toothed whales usually travel in pods and hunt fish and quid by pursuing them at high speed.
It may be that when the prey reach shallow water the whales become disorientated, and that some become stranded.
The social cohesiveness of the pod then draws other individuals into the shallows and may cause further beaching.
Perhaps the inshore species are more familiar with shallow beaches and don't get disorientated.
Certain stretches of beach are notorious for frequent strandings, but there are no records of strandings along rocky coasts.
A rocky shore almost certainly provides a clearer echo than a sandy slope or mud flat.
Other physical factors may be implicated in mass strandings.
Local storms at sea and strong equinoctial tides may affect whale migration routes that pass close to the coast.
Dr Margaret Winowska, of the Anatomy Department at Cambridge, thinks there is a link between magnetic storms, which are common in spring and autumn, and whale strandings.
Combined with human activity — including unintentional harassment by motor  vessels and even underwater explosions — magnetic disturbances, storms and tides could precipitate a mass stranding.
But what about the lungworm,Stenurus ?
It has been found in the air sinuses of many species of whale at strandings around the world.
Indeed, it is practically ubiquitous.
But even though the air sinuses may be almost full of these worms, and they may also be present in the cavity of the middle ear, they have not been found in the inner ear.
Yet it is in the inner ear that the returning ultrasonic echoes are received, and where one might expect to find problems.
It could be that sound transmission from the eardrum along the auditory  ossicles to the inner ear would be impaired by worms in the middle ear.
But the ear bones of toothed whales are heavy and quite rudimentary, and we do not think that they are very important in transmitting received ultrasounds.
In any case, a recent mass stranding of pilot whales on the eastern coast of the United States failed to reveal any Stenurus in the air sinuses.
In the absence of any satisfactory or complete explanation of mass strandings, some people have thought that the whale are committing suicide.
This doesn't seem likely.
If suicide were a way of getting rid of undesirable genetic characteristics, why do strandings still occur?
They ought to have been eliminated by now, or is there a mutation that continues to crop up from time to time ?
Perhaps the survivors of a stranding are less likely to be stranded themselves at a later date.
Or maybe there are populations of whales that never strand.
These arguments would not convince a student of natural selection.
One curious theory is that stranded whales are seeking physical stimulation.
In other words, they have been trying to scratch themselves on the sandy bottom and get stranded by accident.
None of the theories is particularly convincing, and none explains one of the most harrowing features of the recent stranding in the Wash.
The beached whales are quite obviously very distressed, constantly calling out.
This only reinforces the unwillingness of free-swimming whales to leave their comrades, and even after their companions had died the free whales stayed, and only too often fell victim themselves.
We may now be able to observe and record strandings in ever-increasing detail, but we still know very little of what lies behind them.
Further research may yet explain the enigma, but there are so many factors to be investigated.
When we do know what causes whales to beach, we perhaps will have more chance of persuading the stranded ones to return to the safety of deep water.
The art and craft of fluorescent lamps
The crafts seek little stimulation in  technolgy reg=technology .
The arrival of compact fluorescent lamps is an exception: they have inspired lighting designers
John Bell
PHOSPHOR CHEMISTRY, electronics and a passion for energy conservation are most unlikely ingredients to have inspired a flash and flurry of activity in the arts and crafts.
Two disciplines not known for their loving attachment to high, or any other height, technology.
The ingredients began to mix about 10 years ago when the passion for saving energy became fashionable.
Electronics is a universal tool that has been around for a while and which can be used to control electrical circuits — not a common art form.
The clue to the flourishing creativity lies with phosphor chemistry, which is essential to the manufacture of fluorescent lamps.
A hunt for energy-efficient lighting, for unglamourous places such as offices and waiting rooms, led to the development in the late 1970s of stable fluorescent powders highly resistant to strong ultraviolet light.
Manufacturers used the phosphors to coat the insides of 26-mm diameter tubes (12 mm narrower than previous tubes) and added some electronics to create markedly more efficient light sources.
Offices, shops and industry in general bought the new lamps in their thousands, but the manufacturers did not rest there.
Development work continued and in about 1980 they began to launch a series of compact lamps, with tube diameters as little as 16 mm, in novel and innovative shapes and sizes.
It is these lamps — the Philips SL and PL, the Thorn 2D and the Toshiba Neo Ball among them — that have stimulated design of lighting fittings.
The story of fluorescent lighting goes back to 1930 when research began at the GEC research laboratories in Wembley.
The lighting engineers, led by A.H.McKeag, developed the first, white tubes which were installed in the radio control room of the Queen Mary.
The same team discovered the halophosphate group of phosphors which are now used in 90 per cent of all fluorescent tubes.
How the lighting industry got from this point in its technology to today's sources is a tale of technical give and take.
Several requirements have to be considered when designing a fluorescent lamp.
They are lumen output, efficacy, lamp life, lamp colour (its appearance to the eye) and colour rendering (how a colour appears in its light).
These lamps range in length from 150 mm to 2400 mm with diameters of 16, 26 or 38 mm.
Their ratings vary from 4 W to 125 W.
Lighting engineers were happy to reduce lamp diameters from 38 mm to 26 mm, because they could then offer the customer 20 per cent more efficient use of electricity.
They were also happy to use the new triphosphors (each of which gives a narrow band of visible light), because these give better colour rendering.
But there was a price to pay for their pleasures.
When the tube diameter was decreased, operating and ignition voltages increased.
This was not too much of a problem with a 1200-mm tube filled with argon.
With shorter (and longer) tubes the gas had to be changed because, with argon, the operating voltage became too high with respect to the mains and control-gear voltages.
A compromise was needed; a mixture of krypton and argon proved suitable.
The 26-mm lamp brought a need for rationalisation.
The lamps with krypton save energy so they are regarded by the lighting industry as ‘first choice’.
Triphosphor lamps with krypton give up to 70 per cent more light than the standard 38-mm argon-filled lamps.
But the 26-mm lamps have limitations, outside of the problems of colour rendering.
The triphosphor spectrum is inadequate for critical colour work that might be done in, say, printing houses, textile factories or hospitals.
So the lighting industry has had to seek additional phosphors to provide the demanding colour rendering of such installations.
New lamps with additional phosphors are, in fact, being developed to meet these needs.
It is all this research into stable fluorescent powders that has made the new compact fluorescents possible.
The first compact fluorescent source was the Philips SL, which appeared in 1980.
Its control gear is in one unit and it uses only 25 per cent of the energy required by an ordinary household, incandescent light bulb of comparable light output.
The SL's U-shaped tube is folded upon itself and enclosed in what looks like a glass jam jar.
The SJ lamps are similar to incandescents as regards colour appearance and colour rendering.
They have an average life of 5000 hours (control gear 10 000 hours) compared with 2000 hours for a coiled-coil incandescent lamp.
There are clear prismatic and opal bulb versions with bayonets or Edison screws.
The four available ratings 11. 13, 18 and 25 W (with light outputs of 450, 600, 900 and 1200 lumens) can be compared with 40, 60, 75 and 100 W lamps.
Since its introduction the SL lamp has found a profusion of commercial, security and amenity lighting applications.
It is being heavily promoted in the domestic market on the Continent.
The standard SL has three drawbacks: price, weight and size.
Philips cannot improve on the price, particularly now that the lamp is available with an electronic ballast.
But this is a development that has allowed improvements upon the lamp's weight and size.
Eighty per cent of the weight of a 450 gram standard SL is taken up by the ballast.
The weight of the electronic version is 250 g and it is about 185 mm long.
The electronic version is being test marketed in the United States.
Philips says that electronics will make the SL more efficient in one of two ways: by maintaining brightness and reducing power consumption, or by retaining the power consumption and increasing brightness.
It hopes to adapt the life of the electronic control gear to the life of the lamp so that it becomes a throwaway item and bring it in line with the ‘convenience purchase’ of the coiled-coil lamp.
Shortly after the appearance of the SL, Thorn EMI Lighting introduced the 2D by launching it with a range of fittings designed by Conran Associates.
The 2D is entirely different in concept and measures 134 mm square by 27 mm deep.
The lamp is separated from its control gear, although the Starter is in the lamp circuit.
The 2D has the same colour quality and light output as an ordinary 100 W light bulb but it uses only 21 W of electricity (16 W for the lamp and 5 W for the control gear).
It has a life of 5000 hours.
Price of the lamp when it was first introduced was £3 for the lamp and £5 for the gear.
The decision to design the lamp and gear separately was made so that consumers did not need to pay for control gear each time they bought a 2D lamp.
Many leading designers have since designed fittings for the 2D.
The lamp has a colour rendering index of 82 Ra (the colour rendering index is an accepted standard which compares the appearance of a colour under one light source with its appearance under a reference light,) and a colour temperature of 2800 K. The lamp runs very cool; it is not uncomfortable to hold one that is lit.
Its light output is 1050 lumens, compared with 1230 lumens for a 100 W incandescent lamp.
On Tuesday.
Thorn EMI announced a 28 W 2D.
It is 200-mm square and produces 2050 lumens.
At or about the same time as the 2D was announced, Philips unveiled the PL lamp.
This uses the same technology that spawned the SL.
It takes the form of two parallel fluorescent tubes bridged at one end.
A fast-acting starter switch is held inside the lamp cap and contact is made through two lamp pins.
The ballast is separate.
PL lamps offer a 70 per cent energy saving.
As with the 2D the manufacturer has designed a number of fittings for it.
The PL is made in ratings of 7, 9 and 11 W (control gear 4 W extra) which give light outputs equivalent to 40, 60 and 75 W filament lamps.
The PL9 is just 165 mm long overall.
Philips thinks that the PL has a great deal of commercial potential.
So much so, that the company is developing versions in greater lengths and diameters to replace existing U-bend fluorescent tubes in modular, square luminaries.
The company believes that architects do not favour linear lamps and will welcome the smaller point-source of light provided by this single-ended lamp.
The glare from the smaller lamps will restrict their use to well-screened fittings, probably of the louvre type, with efficient reflectors.
The shapes of the new compact lamps have helped to stimulate ideas in the design of fittings.
It will be interesting to see what inspiration will be drawn from another potential source for indoor lighting — the high pressure sodium lamp.
These lamps are usually found lighting spots such as railway sidings and the inside of potato warehouses.
One London architectural practice has already experimented with lighting its own offices with high pressure sodium lamps ‘bounced’ off the ceiling.
If the sodium pressure is high enough, then the lamp's colour temperature and colour rendering can be made virtually identical to those of ordinary light bulbs.
There are problems with the way the sodium attacks the materials of the lamps and the very high temperature that the lamps have to run at.
Already one firm has developed a 30 W source of this type which gives a light like a 100 W light bulb.
Unfortunately the problem of strike and restrike (it can take seconds before the lamp will light again once it has been switched off) still appears to be insurmountable.
So it seems the future of compact fluorescent lamps is secure.
How fluorescent  lighting works
A TYPICAL hot-cathode fluorescent lamp consists of a UV-doped glass tube coated inside with fluorescent powder, filled with argon and containing a drop of mercury.
Tungsten wire electrodes, coated with thermionic emitter, are sealed into each end.
A discharge passes between the electrodes when the lamp is switched on (Figure 1).
Light is produced primarily by the phosphor coating converting short-wave radiation to visible light.
The radiation, which comes From the arc in the mercury vapour, is mainly ultraviolet with a wavelength of 253–7 nanometres.
The discharge consists of electrons and ions.
On average, the electrons travel from the cathode to the anode.
The ions, whose average progress is slower, move in the other direction.
The inert gas argon is added to help to start the discharge because the vapour pressure of the mercury is very low.
The gas pressure must be carefully controlled.
If it is too high, the lamp will be difficult to start.
If it is too low, the lamp will be inefficient and its life will be shorter.
A fluorescent lamp must be connected to a stabiliser, or ballast, to limit and control its operating current.
The lamp must also have a starter to heat the electrodes to a temperature where they begin to emit electrons.
(Ballast and starter are collectively known as ‘control gear’.)
Basically, current is fed from the mains into the ballast.
There it is refined by a capacitor which is usually connected in series across the AC supply, The current passes from the ballast to the cathode; it is also relayed, via the starter, to the anode.
When both electrodes have been pre-heated an arc is struck between them (Figure 2).
The main role of a ballast (which is the block-shaped object usually found inside the lamp fitting) is to stabilise the lamp current.
Fluorescent lamps have what is called a negative voltage-current characteristic, This means that it is the nature of the discharge not to be self-sustaining.
A ballast keeps the discharge going by continually
‘topping up’ the supply volts to the lamp (Figure 3).
If the lamp is connected to a 50 Hz AC supply then the sine wave form of the current is, in effect, continuously switching the lamp on and off.
The ballast also reduces the resulting flicker to an acceptable level.
The recent development of the electronic ballast switches on a new era in lighting technology.
However, its advantages will not be fully realised until the recession slows, sales pick up and unit costs fall.
Electronic ballasts can save up to 30 per cent of the energy consumed by a conventional coil-core wire-wound ballast.
This is possible for two reasons: a reduction in internal losses and increased lamp efficiency due to a much higher operating frequency.
The higher frequencies of 25–35 k.
Hz eliminate flickering and stroboscopic effects.
Some electronic units will start a lamp in less than 0–5 seconds; dimming the source to 5 per cent of normal output is also possible.
There are many types of fluorescent lamp available so the range of conventional starters is equally varied.
The most common is the switch start circuit.
The standard glow switch, as it is known, has been given a paradoxical new life by the recent arrival of energy-saving lamps.
Conventional quick-start transformer circuits and some electronic starters are unsuited to these new, narrow-diameter (26 m m) tubes.
It seems that the lamp and control gear industries are at odds with each other.
The glow switch is housed in a small canister with two contacts (usually plugged into the side of the fitting).
A capacitor is built into the canister and connected in parallel across the lamp and starter.
This helps to suppress radio interference.
The switch itself is a glass envelope filled with rare gases and containing two contacts, at least one of which is a bimetallic strip.
When the mains voltage is turned on, a glow discharge in the rare gases heats the bimetallic strip.
This completes the circuit in the switch so a current flows to the lamp's electrodes and heats them, The glow discharge stops when the contacts touch; the strip cools off and the contacts reopen.
The lamp then lights because the current can now create a discharge between its electrodes.
This action may be repeated several times which is why fluorescent lighting ‘flashes’ when first switched on.
MONITOR
Magnetic monopoles fail to oblige the physicists
MAGNETIC POLES, it seems, always come in pairs: for every north pole there is a south.
However, over 30 years ago the theorist Paul Dirac suggested the possible existence of particles carrying single magnetic poles or ‘charges’— in other words, magnetic monopoles.
Now there is more interest than ever in discovering these monopoles.
Theories that attempt to unite Nature's forces within one framework suggest that monopoles should have been produced in the early stages of the Universe: and just over a year ago Blas Cabrera, a researcher at Stanford University, thought he might have found one (New Scientist .
vol 94, p 336).
But other experiments continue to draw blanks, as two recent papers in Physical Review Letters report.
And three physicists writing in Nature show that monopoles are not the answer to a long-standing problem of solar physics — that of the ‘missing’ solar neutrinos.
According to the grand unified theories that link together electromagnetism with the weak and strong nuclear forces, monopoles are very heavy, with masses around 10 16 gaelectron-volts (GeV).
This is about 10 16 times the mass of the proton, or  g (10 nanograms).
Such heavy particles can not be created at even the highest energies particle accelerators can reach, but they could have been produced copiously in the aftermath of the big bang, with which, cosmologists generally believe, the Universe began.
Up to times as little as  after the big bang, the Universe would have been hot (energetic) enough to create magnetic monopoles, and some of these should still be around.
Cabrera's possible detection of a monopole last year aroused a great deal of excitement, but at the same time raised the question of why he had succeeded, where the many other experimental searches had failed.
One way to reconcile the results was to assume that monopoles move relatively slowly, at only 0.1 per cent the velocity of light or less.
Such slow-moving particles would not be detected in conventional particle-physics experiments, which register a particle's passage by its ionisation of atoms in the detecting medium.
But Cabrera's detector, a superconducting loop, would pick up a monopole passing through it irrespective of its velocity.
Astrophysical arguments also provide limits to the possible velocities of monopoles.
If bound in our Galaxy they must be travelling at around 0.1 per cent the speed of light; if bound within the Solar System (as Earth is) their velocity must be nearer 0–01 per cent that of light.
Now a team from Stanford University and the University of Utah has searched for slow-moving heavy monopoles in conventional detectors in the Mayflower Mine in Utah.
D. E. Groom and colleagues report finding no monopoles with velocities in the region 1.4 x  to ax  of the velocity of light (Physical Review Letters , vol 50, p 573).
They conclude that there must be less than 5 x  monopoles per sq.cm per steradian per second in the vicinity of the Earth, and that ‘the Cabrera candidate is unlikely to have been a true  monopole -induced event.’
Interpreting data in terms of slow-moving massive monopoles is not easy, because no one is quite sure what the ionising effects of such particles might be.
Sidney Drell, from Stanford University, and colleagues have calculated the effects of a monopole on the simple atoms of hydrogen and helium.
They take into account, for the first time, the magnetic influence of the monopoles, and find that monopoles should deposit more energy in these materials than had been previously suspected (Physical Review Letters , vol 50, p 644).
Groom and his colleagues point out that similar calculations are badly needed for other materials that are used in monopole detectors, such as argon and methane.
Another experiment, this time in the Soudan iron mine in Minnesota, has set an even lower limit on the possible number of monopoles with velocities between  and  that of light.
A team from the University of Minnesota and the Argonne National Laboratory report finding no monopoles down to the limit of 4.1 x  per sq.cm per steradian per second (Physical Review Letters .
vol 50, p 65 5).
While monopoles fail to oblige experimenters and continue to evade detection, they also fail to oblige those astrophysicists who had thought that monopoles might be the answer to the problem of the missing solar neutrinos.
Neutrinos are particles produced in the thermonuclear interactions that power the Sun.
The problem is that calculations of processes in the Sun's interior suggest that some three times as many neutrinos should reach Earth from the Sun as are in fact detected.
One solution to the problem is that monopoles within the Sun catalyse certain nuclear fusion reactions, but not those that produce the neutrinos detected here on Earth.
J. S. Trefil and colleagues at the University of Virginia have looked into this suggestion in more detail (Nature , vol 302 p 111).
Their calculations of reaction rates in the Sun's interior imply that there must be at least 10 20 times as many monopoles in the Sun as is possible according to the limits set by the non-detection of monopoles here on Earth.
They conclude that ‘Catalysis of fusion by magnetic monopoles appears to be another non-solution to the solar neutrino problem’.
It seems that monopoles continue to present more problems than they solve.
How working women got a sweet tooth
ONE OF the painful prices human beings have paid for their predilection for starchy and sugary foods has been the premature decay and loss of teeth.
In a prehistoric population in North America the time when marked tooth decay (dental caries) set in has been pinpointed to around 1150 AD.
This was when the people living on the Georgia coast in the southeast corner of the United States began growing and eating maize.
Before that date it is known that the original Indian population of the Georgia coast hunted, fished and gathered their food.
Of special significance, Mark Spencer Larsen of southeastern Massachusetts has discovered that it was the females who showed the most marked increase in dental caries.
He has come to this conclusion after studying teeth from 124 individuals in a pre-agricultural group dating from 1000 BC to AD 1150 and 188 individuals from an agricultural group dating from AD 1150 to AD 1550.
These remains came in all from 33 different burial sites on the
Georgia coast (Journal of Archaeological Science vol 10. p11.
The reason for the different incidence of caries between the sexes, Larsen suggests, lies in the sexual division of labour prevalent then in Georgia and in many other past and present human societies.
When maize cultivation was introduced it was probably the females in the Georgia communities who did the growing and harvesting of the crops as well as all the preparation and cooking of the family's food.
For economic or social reasons (plus a sweet tooth?) it was they who seem to have made the biggest dietary switch from meat, fish and wild plants to largely maize, which, being rich in carbohydrates, caused their teeth to decay more markedly than before.
In their turn the males continued to subsist mostly on meat and fish from the animals they had caught.
Consequently they received more protein-rich and less carbohydrate-rich food in their diet and suffered less from dental caries than the females did in the period Larsen studied.
Carcinogens awaken sleeping genes
CANCER cells are almost by definition cells that have escaped from the controls that govern the behaviour of the individual cells in a multicellular organism.
And recent research has dramatically shown that one way for them to make the break is through the activation of cellular oncogenes — genes that are more or less inactive in normal cells hut seem to be altered or activated in tumour cells (New Scientist , vol 96, p418.
Now two Americans, Vincent Wilson and Peter Jones at the University of Southern California, have evidence that one of the actions of cancer-causing chemicals may be to jam the mechanism that normally keeps these genes — as well as other cellular genes — under control.
The mechanism thee were looking at is a chemical modification of the DNA known as methylation.
Methylation is now generally recognised as one way of switching genes off, and is particularly interesting one because it helps to explain a crucial but mystifying fact of multicellular life — the differentiation of the genetically identical cells of an embryo into the many different tissues of the mature organism.
To achieve that, different sets of genes must be shut off in different cells, and shut off heritably — so that, for example , a dividing liver cell produces another liver cell and a dividing skin cell another skin cell, despite having all the genes at its disposal to produce  any kind of cell it fancies.
The great appeal of methylation as a means of shutting genes off is that it has a known mechanism for perpetuating itself during cell division and thus ensuring its own inheritance.
That mechanism is an enzyme known as a maintenance methylase, and it is the activities of the methylase that chemical carcinogens disrupt (Cell , vol 32, p 239).
Wilson and Jones, in their investigations of this effect, did not test the carcinogens on cells, but on DNA extracted from cells and treated so as to make it mimic the methylated DNA of a dividing cell.
When DNA replicates itself before cell division, the old strand remains methylated but the freshly replicated strand is unmethylated.
The maintenance methylase detects the discrepancy and methylates the new strand in just those positions where the old one is methylated.
Wilson and Jones used preparations of half-methylated DNA to test the effects of a battery of carcinogens on the ability of the maintenance methylase to methylate the unmethylated strand.
They found that many of the chemicals substantially reduced the amount of methylation that took place — either by altering the DNA so that the enzyme no longer recognised it, or by inhibiting the enzyme itself in its action.
Of course the actions of carcinogens on methylase activity in a test-tube may not reflect what happens in tissues exposed to those chemicals.
But it has recently been shown quite independently by Andrew Feinberg and Bert Vogelstein at Johns Hopkins University that the DNA of tumour cells is much less methylated than that of normal cells from the same tissue.
All of which lends circumstantial weight to the idea that oncogenes may be activated by stripping them of their methyl groups — and also explains the common observation that tumour cells may sometimes express inappropriately characteristics of other tissue cells.
Alert readers of Monitor will have remembered a recent report on the experimental use of a demethylating drug for an inherited anaemia (New Scientist , vol 96, p 725).
The patients in that trial were already mortally ill.
Plainly in any less desperate case the risk of activating oncogenes would absolutely forbid the use of such a drug.
Artificial membrane sifts ions by changing voltage
MAN-MADE membranes that allow some charged molecules (ions) to pass through them but prevent the passage of others are important components of many medical and technological systems.
In kidney dialysis, for example, a membrane with a low resistance for the passage of small ions (such as sodium ions and other electrolytes) and a high resistance for large ions (such as blood proteins) is required.
But, unlike natural membranes (nerve cell membranes, for example) the ionic resistance of an artificial membrane cannot be varied once it is in place; and so the flux of ions across the membrane cannot be fully controlled.
Now, Paul Burgmayer and Royce Murray from the Kenan Laboratories of Chemistry at the University of North Carolina, have devised a membrane whose ionic resistance can be varied by changing the voltage applied to a gold grid embedded in it.
Journal of the American Chemical Society , vol 104, p 6139).
The movement of ions through a membrane is controlled by the nature and number of charged molecules fixed in it.
Negative ions pass through a membrane containing positive ions more easily than through one that is neutral or negatively charged.
Scientists have discovered several polymer films that they can make either neutral or charged.
They do this by coating a metal electrode with the polymer and then varying the voltage applied to the metal.
Unfortunately a solid metal electrode is impervious to virtually everything.
The Carolina chemists avoided this problem by depositing their polymer onto a very fine gold grid.
They glued the gold mesh between two glass slides with 0–24 sq.
cm holes pre-drilled through them.
This they immersed in a solution containing pyrole (a five membered organic ring molecule containing one nitrogen atom).
When they applied a voltage to the grid, the pyrole polymerised onto it.
After six minutes the chemists obtained a membrane 15 micrometres thick, that completely filled the holes in the gold mesh.
Burgmayer and Murray then used this membrane to separate two solutions containing negatively charged chloride ions.
When they applied a voltage of — 0.7 V to the mesh they found that the resistance to passage of chloride ions was ten times greater than at zero volts.
By taking the voltage to +0.5 V they returned to the original low resistance, and this cycle could be repeated many times.
The membrane starts off positively charged, and chloride ions can pass through easily.
At — 0.7 V it becomes neutral and the resistance rises.
However, the film must be taken to +0.5 V to make it positive.
The scientists are now trying to make the difference between the ‘on’ and the ‘off’states greater so that the membrane completely blocks transport in the off state.
Cell scientists don't yet know how natural systems control ion transport.
It will be interesting to see if nature's solution to this problem bears any resemblance to man's.
Enzyme deficiency linked to senile dementia
AT LAST there is a bright spot in the long dark history of Alzheimer's disease, the most prevalent senile dementia.
Neuroscientists from Baltimore have persuasive evidence that links the disease to an enzyme deficiency in a region of the brain that controls attention, learning and memory.
Writing in Science (vol 219, p1184), Mahlon DeLong and co-workers at Johns Hopkins School of Medicine say that this is the first case in which a specific form of dementia has been linked to particular neurotransmitters and nerve pathways.
(Neurotransmitters are chemicals that leap across the gaps between nerve cells to transmit messages in the central nervous system.)
Several lines of evidence suggest that patients with Alzheimer's disease are deficient in enzymes that regulate the creation and recycling of the major neurotransmitter, acetylcholine (choline acetyltransferase and acetylcholine esterase, respectively).
This deficiency is linked in some way to the death of nerve cells that arise in the forebrain and connect to many regions of the cerebral cortex.
These dead cortical cells form what the authors call ‘burned-out plaques’ made of the neurotransmitter's degradation products.
Following on from such work it was suggested that drugs which tend to increase the activity of acetylcholine might improve learning and memory.
But it is not clear which nerve cells and regions of the brain are involved.
Using staining techniques and toxins that specifically destroy individual nerve cells, neuroscientists have been able to trace the pathway of nerves that send acetylcholine signals in the higher cortex back to their origin, a small region of the forebrain known as the nucleus basalis of Meynert.
By dissecting the brain of a 74-year-old man who died after a 14-year history of Alzheimer's, DeLong and his co-workers showed a ‘profound and selective loss’ of Meynert cells, compared to brains of people who died without a history of dementia.
Five other victims of Alzheimer's disease showed the same loss of Meynert cells.
Until now, the role of the brain regions associated with Alzheimer's disease has been little understood; they are part of what for years was called the ‘substantia innominata’(region without a name) because it had no known purpose.
DeLong's own studies in primates, in which he damaged nerves leading from the nucleus basalis of Meynert to widespread regions of the cortex and then tried to use food to reward them for particular  behaviour , suggested that the region may play an important role in learning.
The possible implications of these animal studies for Alzheimer's are obvious.
Some patients suffering dementia as a consequence of Parkinson's disease or Down's syndrome show nerve damage virtually identical to that in Alzheimer's patients: in contrast, dementia due to Huntington's disease seems to be due to a specific deterioration of different nerve cells.
Interestingly, the dementia from this disease has different characteristics than the symptoms of Alzheimer's.
The Baltimore studies are indeed good news, but, DeLong stressed recently that they are no more than that.
‘What about the relation of cell loss to the symptoms?’ he asked.
‘We have by no means demonstrated that this deficit is responsible for all, or in fact any of the symptoms.’
The effects of these nerve cells on arousal and learning are very complex and still need to be sorted out, he added.
The Moon is all that rises
IS THERE a lunar rhythm to human sexual behaviour?
Not according to John Palmer, Richard Udry and Naomi Morris at the Population Center of the University of Carolina (Human Biology , vol 54, p111).
They investigated the sexual behaviour of 78 white American married couples (average age 26 years) over a 12 month period.
Husband and wife completed separate questionnaires each morning recording their copulations in the previous 24 hours to the nearest hour.
Each mailed the questionnaire to the institute that morning.
These couples averaged 2.44 copulations per week.
The most active couple managed 7.40 copulations per week and the least active 0.64 per week.
During the day there was a small peak in sexual activity at 7 am with a major peak at 10 pm in the evening.
In order to separate a lunar effect the team looked at the lunar day, the position of the Moon.
Only the phase of the Moon had an effect approaching significance: 14.6 per cent more copulations occurred during a full Moon.
Any lunar effect seems to be mashed by weekly sex patterns.
Predictably, couples had sex most often at the weekends the favourite day being a Sunday.
Does language begin in the womb?
Even before we are born the shape and pattern of wrinkles on the surface of the two hemispheres of the brain differ to an appreciable extent (see figure) -some of the most noticeable asymmetries being found in the regions of cerebral cortex associated with language.
But do these ‘imperfections’ imply that the two hemispheres differ in their cognitive abilities?
A recent paper from Paul Satz and his colleagues at the University of Florida (Science , vol 218, p 797) provides some of the answers to this long-standing problem.
In the 1860's the French anthropologist and anatomist, Pierre Paul Broca called attention to the fact that language disorders (termed ‘aphasias’) were far more commonly observed after damage to the left hand side of the brain.
Since Broca's pioneering work, a variety of studies have confirmed that the left hemisphere plays a dominant role in the comprehension and expression of written and spoken language.
The corresponding regions on the right hand side seem to be smaller, they control the rhythm, pitch and stress of pronunciation which impart the emotional flavour to all we say and hear.
Is this ‘lateralisation of function’ present in early life?
A number of studies purported to show that, unlike Broca's patients, children are often severely aphasic after right hemisphere lesions.
This, it was argued, suggested that in the first years of life the two hemispheres have similar linguistic abilities and that the left side became dominant only as speech itself developed.
One perplexing feature of this conclusion is that since the late nineteenth century far fewer children with right hemisphere lesions are aphasic.
This effect might result from antibiotics, brought into paediatric medicine in the 1940s.
Before this, childhood brain lesions were often due to the uncontrolled spread of bacterial infections.
A brain abscess in the right hemisphere could also be accompanied by diffuse damage to the left: that is, the aphasia in these children might not be related to damage to the right-hand side of the brain.
Perhaps then the apparent bilateral representation of language in young children was an artefact.
In the Satz study only those patients whose aphasia could not be unequivocally linked with focal brain damage were included in the statistics.
The differences between the adult and child data then became insignificant.
Satz concluded that cerebral dominance for language is established before the age of five.
During the 1960's Noam Chomsky popularised the view that human languages together share certain universal grammatic features, and that language is not learnt from scratch but rather acquired by brain centres sensitive to this underlying syntax.
Since the anatomical asymmetries of human language areas first appear in utero , the implication is that preliminary stages of language acquisition could begin before birth.
TECHNOLOGY
Computerised tank outshoots its rivals
THE Royal Ordnance Factory at Leeds yesterday delivered to the British Army the first production version of the Challenger tank, less than three years after the Ministry of Defence ordered the vehicle.The army is receiving more than 200 Challengers, costing about £300 million, to beef up its defences in Germany against Soviet tanks.
The Challenger, with its ‘Chobham’ composite armour, is the best-protected tank in the world and can also outshoot its  Eastern -bloc counterparts.
The MOD ordered Challenger when the tank that it had been developing, known as MBT80 turned out to be too complicated and expensive.
Much of the development work that found its way into Challenger had been under way for some years on behalf of the Shah of Iran.
After the Shah's fall, the Iranian government cancelled plans to buy more than 1200 Shir 11 tanks from the Leeds factory, which saw its order book fall from £1000 million to £30 million overnight.
The Shir 11 was an improved version of the British Army's standard Chieftain tank.
When MBT80 fell by the wayside, the Military Vehicles and Engineering Establishment at Chobham modified the design and came up with Challenger.
Modern shells and anti-tank guided missiles can, if they hit a vulnerable point, penetrate the conventional hardened steel armour that protects Chieftain and its crew.
The Chobham establishment therefore redesigned the hull and turret for the next version, Challenger.
The new armour is heavy, and a Challenger weighs a massive 60 tonnes.
Despite this, it is comparatively sprightly for a tank.
The Rolls-Royce Condor diesel engine produces 900 kW of power, sufficient to drive the vehicle at more than 70 km/h across Salisbury Plain during trials last autumn.
No previous tank could operate effectively at anything like that speed across rough country without the risk of injuring the crew.
Challenger is the first tank with hydrogas suspension, which gives a much smoother ride.
Challenger's 12 independent hydrogas units allow the wheels to travel up and down much further than with Chieftain's  bogie -type suspension, thus greatly reducing the accelerations that the vehicle itself undergoes.
Crew comfort is greatly improved as a result, and Challenger is a much more stable gun platform when firing on the move.
A computer controls Challenger's gun, so it can shoot accurately at moving tanks, even when the vehicle is itself driving across country.
Sensors on the tank measure wind speed and direction, air temperature and other factors that affect a shell's behaviour on its way to the target.
The gunner looks through his optical sight, lines it up with an enemy tank and squeezes a trigger to fire a laser that measures the range.
Information about the target's position passes automatically to the computer, which calculates where the gun should point so that its shell will hit the target.
The computer then instructs motors to slew the turret and raise the gun barrel by the appropriate amount.
Challenger has a good chance of hitting a Soviet tank with its first shell at a distance of more than 2000 m.
The new tank's gun, of 120 mm calibre, is the same as that fitted to Chieftain.
It will be more effective, though, thanks to a shell that has fins to stabilise it during flight.
As the shell emerges from the gun barrel at more than 15000 m/s, aluminium petals peel away to reveal a long, thin tungsten-alloy rod with fins at the rear to stabilise it and thus improve accuracy.
This ‘long-rod penetrator’ punches a hole through the armour of an enemy tank, destroying equipment inside and killing or disabling the crew.
All this is achieved by kinetic energy — the shell contains no explosives.
The army plans later to fit Challenger with a new gun operating at even higher pressure and firing an improved shell.
This high-pressure gun will have a barrel of electro-slag refined steel, which is less likely to fail.
The army will also later fit Challenger with a thermal imager so that the commander and gunner can see their target at night.
A thermal imager uses detectors of cadmium mercury telluride, which detect infrared radiation when they are cooled to very low temperatures.
Infrared radiation is also better than visible light at penetrating mist or smoke on the battlefield.
Britain tries again on video conferencing
British Telecom is about to have a second stab at selling services in ‘video conferencing’— the holding of conferences by business executives over video links.
The corporation has developed, at its Martlesham research laboratory, communications hardware that it hopes companies will install in their own offices for such conferences.
Half a dozen firms around Britain are testing the equipment for British Telecom.
If the trials go well, the corporation will begin selling the service later this year.
Since the early 1970s, British Telecom has run what it calls Confravision.
People who want to talk to others in different parts of the country — and see them as well— have to visit a special British Telecom studio.
The other participants in the meeting have to rendezvous at a similar studio, of which there are nine in Britain.
The ‘video conference’ then takes place for a fee of between £80 and £120 for half an hour.
The charge depends on the distance between the studios.
But Confravision never really caught on.
Only recently has British Telecom started modernising the equipment, introducing colour terminals for instance.
And business executives have disliked travelling to a special studio.
They reason that they might as well make the same effort journeying to meet the other people in person.
British Telecom says that selling a service in which the equipment is in the company's own offices stands a better chance of success.
But the corporation is not ready to talk about how much the service will cost.
Meanwhile, British Telecom has been beaten in the race to start transatlantic video conferencing.
Intelmet, a subsidiary of Intercontinental Hotels and the American satellite company Comsat, is organising conferences between London and New York.
The cost of a half-hour meeting varies from $325 to $5000 depending on the time of day and on the exact nature of the video conference.
For instance, participants can opt for ‘freeze-frame’ pictures, in which images of participants in the meeting are updated every few seconds instead of constantly moving.
Freeze-frame pictures consume less bandwidth on the satellite channel and so cost less.
The snag in the new venture is that, once again, participants have to travel to a special studio room in a hotel in London or New York.
Intelmet says that to make the service pay it will require just 10 regular customers every month.
Over the next couple of years, Intelmet plans to link another 30 hotels around the world.
Adding a new studio to the network costs about $1 million.
The London studio is lavishly kitted out with six cameras, equipment for sending a facsimile of a document in just six seconds, plus an audio device that automatically focuses the cameras, on whoever is speaking.
British Telecom plans to join the fray with its own transatlantic service, in cooperation with Satellite Business Systems of the US.
But the start of the scheme has been delayed until later this year.
Intensive care for trees
HOW can you tell whether a tree is healthy without chopping it down?
One way is to take a cross-sectional X-ray picture of the tree with computer tomography.
Though this technology is well-established in medicine, researchers in Japan's electric power industry think they are the first to take tomography outdoors.
Workers at the industry's central research unit wanted to determine how high-voltage transmission lines and smoke from power stations affect trees.
But felling trees, chopping them up and hauling them back to the laboratory for tests costs time and cash.
So last May the  researchers asked Professor Morio Onoe of Tokyo University's Institute of Industrial Science to build a portable computer-tomography unit.
The device takes X-ray pictures from many angles, under the control of an inevitable microprocessor.
The unit changes what it ‘sees’ into a digital form and records this onto a floppy disc, from which the data are translated by computer into an image of the tree's insides.
Thus the health, age and water distribution — water shows up black-can be determined.
Tree physiology and dendrochronology are just two of the possible applications for portable computer tomography.
Maintenance men could tell whether a pole — wooden or concrete — is dangerously cracked before shinning up it.
Conservationists could discover whether old wooden buildings are still sound, and obtain, into the bargain, information on climatic changes in previous years.
And if everything goes to plan, archaeologists will have a new way of dating wooden objects.
But several snags remain.
Whereas computer-tomography devices in medicine use as many as 700 detectors to produce images in 3 seconds, the portable unit's three sensors need up to 10 hours to make a respectable picture (though spot checks for cracks and rottenness can be made much faster).
At 50 kg the device is too heavy to take up Japan's steep hills — and it cannot yet produce on-the-spot pictures.
BBC hopes for surround — sound radio prize
THE BBC is breaking technical ground next week by transmitting a radio play made with an all-round sound reproduction system.
The big snag for listeners is that the equipment for receiving the surround-sound is not yet on sale.
So, at best, they will have to make do with tuning into the programme in stereo.
Nothing daunted, the BBC's engineers have designed a clever re-recording technique for receiving the sound and this could help them to win a  prestigious international prize next month.
Gilgamesh .
a play about the gods of the ancient world, is transmitted on Radio 4 next Monday with a repeat on 27 March.
It is the first BBC programme made with the Ambisonics surround-sound system in which sound information is captured that relates to height as well as horizontal distances.
In other words, with the correct equipment, listeners would have been able to hear thunder as though coming from above them while hearing ‘rain’ trickling around their feet.
Although British householders will miss out on hearing the intended sound effects in the play, judges at the Prix Futura radio and TV competition in Berlin next month will be more fortunate.
The BBC has entered Gilgamesh for a prize for technical advances.
Because more than 50 people will be involved in the judging, it is impractical to reproduce the programme as intended through eight loudspeakers around and above the audience.
So the BBC's engineers will reproduce the play with the correct equipment in an anechoic chamber at the corporation's research laboratories in Kingswood Warren.
The sound will then be re-recorded in binaural stereo using a dummy human head with a microphone set in each ear.
The stereo tape will then be replayed to the Berlin judges who will listen on individual headphones.
Better tapes
MANAGERS at BASF, the West German chemical company that specialises in making recording tape, believe the audio industry-could double its sales of musicassettes by using chromium dioxide tape and recording in a different way.
This would put less than 10p on the production cost of a musicassette selling for more than £5 in the shops.
But Thorn EMI thinks differently.
The company has just cancelled its contract with BASF for chrome tape and is opting for a cheaper brand of conventional ferric oxide tape.
The first musicassettes (pre-recorded tapes) were made in 1964, as a gimmick.
British homes now contain more than 20 million cassette recorders.
But most musicassettes still use only the very cheapest ferric oxide tape, so quality is poor and musicassettes are not popular with hi-fi buffs.
BASF says the recorders should use its chromium dioxide tape which suffers from less background hiss.
As an essential part of the BASF strategy the chromium tape is recorded with the same equalisation as ordinary ferric tape.
This gives the tape more headroom for high frequencies.
Although Thorn has backed away from chrome, other record companies are supporting it.
Famous Last Words a pop record released by A & M was widely advertised as available on chrome tape.
Big catch for mechanical fishing
AN INSATIABLE appetite for squid plus an ageing workforce add up to a full order book for a Japanese manufacturer of computerised fishing equipment.
In the past ten years, Japanese people have gone overboard for squid, consuming half a million tonnes annually.
Mothers love squid because it's good value (you can eat most of it) and easy to prepare (unlike, say raw fish which takes considerable  skill .
Children love it because it's easy to eat there are no bones.
Over two hundred kinds of squid are eaten in every conceivable way from raw to pickled.
Forty per cent of the total is dried, shredded and eaten along with beer.
To feed this demand the squid boats go out all year, sometimes as far as New Zealand.
These days, however, with the average fisherman aged around 50, the industry is turning to automation.
Many companies offer mechanical fishing equipment but so far only one, a firm in Shizuoka called Sanmei, has thrown in computerisation as well.
Squid travel in shoals.
The fishermen catch them at night, using bright lights to attract the molluscs' attention.
But the fish have to be caught on lines, as nets would damage their pulpy flesh.
The computer has been taught fishing tricks: it jiggles the line to make the squid think the bait is alive.
Each line carries between 40 and 50 hooks.
When the tension reaches a preset point as the line becomes heavy with struggling squid, the computer gives the order to reel them in.
Most boats carry four units, though some of the bigger ones have as many as twenty, costing about £1000 each.
A boat with eight units can pull in 3800 squid in 40 minutes.
Engineers have tried to mechanise other forms of fishing — for tuna and bonito — without much success as yet.
Banks step up support for new technology
BRITAIN'S banks are increasing their efforts to woo small companies involved with new technologies.
All four of the main high-street banks are attempting to adjust their lending policies so that more firms in this area are eligible for loans.
The banks are also  strengthening their links with university researchers.
A key thrust is that the banks are trying harder to understand what technology is all about.
They do this with training courses for managers or with special units that advise local branches on technical matters.
Helping small technology based firms is very much in the banks own interests, according to John Kirkwood, adviser on small businesses at Lloyds Bank.
He says financial institutions have recognised that little companies provide a base for industry and the seed corn for new ideas.
But banks have often had problems in fathoming the requirements of technology based companies, particularly new enterprises with no track record.
‘We're bankers, not scientists’, says Noel Dearing, manager of the small business section at National Westminster.
All four banks now employ specialists, either as part-time consultants or as permanent members of staff, to advise on new technologies.
National Westminster started its own scheme earlier this year.
It has a list of consultants around the country who examine requests for loans that involve esoteric technologies in computers or telecommunications for instance.
The cost of employing the consultant — up to £1000 for five days' work — is split between the bank and the company.
Lloyds runs a similar scheme but it involves just one institution.
Technical appraisals are conducted by workers at Cranfield Institute of Technology who are expert in the area involved.
The series of technical evaluations began in October for a six-month trial.
Of the first 20 projects the Cranfield examined-in product areas ranging from computerised cash registers to microwave assemblies for telecommunications, the bank will probably give loans to most, according to, to John Kirkwood.
The loans could vary between £10 000 and £300 000.
Barclay's has gone as far as to create a ‘high technology’ unit to examine requests for finance from possible customers.
Nick Moore, the head of the unit, says that the number of small firms involved in this area will continue to grow as a result, for instance, of researchers leaving universities with good ideas which they are anxious to commercialise.
Moore's staff of six also organises training programmes for Barclay's managers in local branches.
So far 1000 of those people have attended seminars aimed at increasing their technological awareness.
The Unit is involved not just in fixing up loans.
It advises the rest of the bank on the right general approach to new technology.
For instance, as a result of its interest in this area Barclay's has put up £1 million to sponsor facilities at the science park at Warwick University.
The bank is also putting cash behind a research centre for industrial automation at Durham University; and it has financed a study to determine whether ideas emanating from London's Imperial College have a chance of leading to commercial products.
Moore says that all these activities provide a better climate in which new technologies will grow.
The bank itself stands to benefit by providing financial services to technologically orientated companies that are successful.
The fruits of Barclays' policy are clearly visible in Cambridge, one of the leading centres for small firms, many of which started as a result of technologies developed at the city's university.
Barclays says it looks after the financial affairs of some 150 ‘high technology’ companies in Cambridge: three years ago the figure was 15.
Barclays also has a special loan scheme which it says is particularly suitable for enterprises starting up in new technologies that involve an element of risk.
With the bank's business-start loans, firms pay back the cash not with interest but with a royalty on sales.
Of the 370 or so firms to which Barclays is lending under the scheme, about 50 are developing new technologies.
All the banks say that the government's Loan Guarantee Scheme has stimulated small businesses involved with emerging technologies.
The scheme, started two years ago, is designed to support ventures which normally would not qualify for bank loans.
Under the project, the banks lend money in the normal way but the Department of Industry agrees to refund 80 per cent of it if the firm goes bust.
By the end of last year, almost £300 million had been allocated under the scheme to more than 7000 companies.
Loans, however are not the complete answer to the financial problems of technology-based firms that start up from scratch.
Colin Amies, electronics industry adviser at Midland Bank, says that obtaining equity finance is often more important.
He is saddened that many firms in this position are unwilling to accept an equity stake from outside institutions, on the grounds that this will reduce the firm's control over the venture.
‘There is not a gap in terms of money,’ says Amies.
‘There are now quite a few sources from which firms can obtain this finance.’
Amies's bank has its own subsidiary that takes a financial stake in new enterprises.
Since it started in 1979, Midland Bank Venture Capital has provided £35 million to 119 companies.
Another institution attempting to earmark ventures ripe for a dose of finance is Technical Development Capital (TDC), part of the Finance for Industry group, which is owned by Britain's big banks.
The organisation spends about £5 million per year on new investments in technology based companies.
Of TDC's 23 investments, most are in electronics and biotechnology.
The organisation wants to increase its investments at the rate of a dozen or so per year.
TDC's managers have tried to establish good relations with universities so that they hear about promising developments in time to support them with cash.
Areas on which the organisation is especially keen include semiconductors, telecommunications, factory automation, medical instruments and electronic office systems.
The year a land died
More than three million people are threatened by drought in an impoverished corner of Ethiopia.
The international community is doing little to help.
Michael Cross was the first British journalist to visit the area
FROM THE window of the ancient DC3 liner the highlands of Gondar look like an alien world.
The soil is the colour of brick dust, with only deep dry gullies to show that water ever flowed here.
To the north.
the bare lava peaks of the Simien mountains reach 4000 metres into the sky.
A few scattered huts show the land is inhabited.
In normal times, nearly 9 million people live in the four provinces of northern Ethiopia: Gondar: Wollo: Tigre and Eritrea.
Two thirds of them scratch a living from the soil.
But last year the rains failed them.
In some places they fell early, others a month late.
In some; places there was no rain at all.
The result was the same — the farmers lost their always precarious crops of maize, and the herdsmen saw their cattle die in their thousands.
By last month tens of thousands of people were on the road to the few relief centres that the government runs.
In all, the government says 3.2 million people are ‘seriously affected’.
In the historic town of Lalibela, Wollo Province, we first saw what ‘seriously affected’ meant.
The government's Relief and Rehabilitation Commission is handing out weekly rations to about 500 people camping around the local office.
The administrator, Tilahu Walle, says they are the lucky ones of the 200 000 people in the area who need assistance.
‘We have no grain at all to help the people who come.
A very large number have been turned away and told to go back home.’
Even the people who receive grain are hardly well fed — the ration is 2.5 kilos of grain per family per day, and a family could have 10 members.
Most relief agencies reckon 400 grams of grain a day, plus supplements of protein, to be the minimum necessary for survival in Africa.
The problem is one horribly familiar in the north east of the continent.
Ethiopia's last bad drought was in 1972, when perhaps 200 000 died (no one was counting at the time).
The 1970s saw similar droughts in Karamoja, Uganda, and Turkana in Kenya.
And to the west, the five-year drought in the Sahel, which killed a quarter of a million, reinforced in Western eyes the image of a continent of famine and natural disaster.
Famine caused by drought is not an unstoppable act of God.
It is simply the most dramatic manifestation of soil  degradation , or ‘desertification’, caused by poor agricultural techniques.
Such practices include cultivating on steep slopes so the topsoil runs off when the rains come, or ploughing downhill with the same end result.
And grazing too many animals on too little land leaves soil unprotected against wind or water erosion.
In the north of Ethiopia, such practices have been common for centuries.
The end product is an environment that is vulnerable to the slightest whim of the weather, and a dried out topsoil that disappears in the wind, leaving sand and bare rock.
After the Sahel drought, the 1977 UN Conference on Desertification adopted an international programme to prevent the disaster happening again.
But even after the distribution of millions of tonnes of food aid, and spending $162 million on measures to prevent soil loss, the spectre of another disaster hangs over the countries of the Sahel, Mauretania , Mali, Upper Volta, Niger, Chad and part of the Sudan are all threatened.
There are almost as many cattle as before the drought, and the 100 000 tonnes of food aid a year goes mainly to keep down the price of food in the cities.
For the farmers, life stays the same.
Thanks to the  vagaries of international politics, Ethiopia has had only a tiny slice of this aid cake.
It is possibly the poorest country in the world, with an annual per capital income averaging $110, and a chronic shortage of foreign exchange.
To make things worse, it suffered the turmoil of revolution in 1974, invasion by Somalia in 1977, and a bitter war against Eritrean secessionists that continues to this day.
According to the US State Department, Ethiopia's provisional military government spends 28 per cent of its budget on defence.
The country's main benefactors are the Soviet Union and the Eastern bloc — which can supply guns but not bread.
Because of its Soviet connection, plus an outstanding row over the nationalisation of an American spice company, Ethiopia does not qualify for US aid.
And because it was never colonised by a European power, it does not even have the conscience of a ‘mother country’ to turn to.
The United Nations Food and Agriculture Organisation's representative in Addis Ababa, Hans Dall, says Ethiopia receives less foreign aid than any other developing country — $8 per person per year.
The average figure for other Third World countries is $22.
This is the background to the drought of 1982, which the government says could be as bad as the one 10 years before.
The four provinces hit most badly are Gondar, Wollo, Tigre and Eritrea.
In the last two, war has added to the misery.
Two weeks ago, I visited Ebenat, one of the three relief camps in Gondar, to watch the distribution of grain from the UN's World Food Programme.
We reached Ebenat after a four-hour drive along dirt roads from the town of Gondar.
The camp lies on a flat plain, completely without vegetation.
Set up four months ago, it consists of a couple of corrugated iron buildings surrounded by the twig shelters of the 3000 families that the government says live there.
The refugees, small wiry people dressed in rags the same colour as the desert, huddle in the shelters, crouch in the shade behind the buildings, or in groups around the places where relief teams distribute what little food there is.
Another little group lines up with empty tin cans by the single water truck, waiting for the daily ration.
Each family of refugees receives 30 kilograms of grain a month, with 5 kg of dried milk or other protein supplement.
No one even pretends that is enough, and we saw several children with the shrunken limbs and wrinkled faces of marasmus.
The refugees brought other diseases with them, mainly eye infections and malaria.
There are no medical facilities whatsoever at the camp.
Wherever we walked people asked us to treat inflamed eyes, limbs swollen by filariasis, and all manner of festering sores.
One mother held up an emaciated child, and in sign language asked me to vaccinate the baby.
There is one small river at Ebenat, but that has become so polluted that the relief workers have to bring in water by tanker.
The supply is adequate for the moment, but with 500 families arriving every month, it could run out.
Another problem is the supply of wood for shelters and fuel.
The refugees have stripped the surrounding hills almost bare, and spend much of their time collecting branches.
But at least food is getting through to Ebenat.
A young officer of the Relief and Rehabilitation Commission, Getachew Ashagre, was able to rattle off absurdly precise statistics about the aid: ‘In the last six months, in Four Awrajas [districts], 164 467 people got relief assistance.
A total of is 463 quintals [2546 tonnes]of grain was distributed, and 15 229 items of clothing given away.’
Ashagre acknowledges that this is too little.
‘We had planned for 170 000 quintals for the six months…we distributed all we had.’
He said 87 people had died in the past two months — but that deaths occurring on the trek to the camp were not being recorded.
There are two other camps in Gondar district.
One of them, Amba Giorgis, receives its supplies, like Ebenat, by truck.
Ashagre said it was smaller than Ebenat, but could not say how many families were there.
But the largest camp, Zwi-Hamussit, is accessible only by air.
The relief commission has one aircraft that can land there, a Twin Otter.
It flies eight times a day from Gondar, carrying 1.8 tonnes of grain every trip.
The food goes to 5000 families, but two weeks ago the aircraft was grounded for servicing.
No one could say when it would be ready again.
In the central offices of the Relief and Rehabilitation Commission, Shimelis Aduna, the head of the organisation, puts in perspective the aid that is getting through.
‘We have been promised around 80 000 tonnes, we will need around 200 000 tonnes over the next 12 months.’
He said the government would not let people die if relief does not arrive, but as Ethiopia has no surplus food, no money to buy grain and no means of transporting it, it is hard to see how the government can avoid deaths.
Aduna said he gave international organisations an early warning five months ago, ‘but the response has not been good’.
The EEC has promised 20 000 tonnes of grain, the World Food Programme 15 000 tonnes, West Germany 4000 tonnes.
Ten thousand tonnes of rice has already arrived from Italy.
Ethiopia's Eastern bloc friends have given medicines, trucks, biscuits and milk powder.
‘The aid from the East coma to around $5 million,’ Aduna says, ‘rather that is what they say it is worth.’
Perhaps the greatest tragedy is that, given proper management, Ethiopia could be one of the world's most fertile countries.
The topsoil, where it has not been eroded, is good.
The temperature on the highlands is moderate, and the rainfall, properly managed, is enough to turn the country green.
In the past, the system of tenant farming offered no incentives for people to look after their land.
The revolutionary government has tried to change this by forming ‘peasant associations’(not always successfully) to manage the land and build a rural infrastructure.
The World Food Programme is helping with its largest ‘food for work’ scheme in Africa.
In the five years from 1980 to 1985 it plans to give food worth $140 million as wages for soil conservation work.
This is the work that will suffer if food aid is redirected to the drought victims — sowing the seeds for a new drought.
Even if the food does arrive, even if Ethiopia's overstretched infrastructure can manage to distribute it, the drought of 1982 will have dealt a devastating blow to the country's hopes of feeding itself.
One of the real achievements of the revolutionary government has been to reform land-ownership, in theory giving everyone the right to farm.
With the technical assistance of the Food and Agriculture Organisation it has begun digging terraces, and building dams to stop its topsoil disappearing.
The drought has already set one project, a national food reserve, back by at least a year.
The displacement of tens of thousands of people will make other development projects impossible.
Even if the rains come this year, they will do the people of Gondar no good.
The dirt roads will turn into torrents, stopping the relief trucks from getting through.
The inevitable epidemics will take their toll in the camps.
And back on the Farms of the refugees, the rain will further erode a topsoil without crops to hold it together.
It will add to the 5 million hectares of agricultural land already lost to soil erosion.
Meanwhile, the people of Gondar, Wollo, Tigre and Eritrea sit in their shelters waiting for an indifferent world to decide their fate.
Drugs monitor needs sharper teeth
Operon is the third British drug disaster in a generation.
We need to know what happened if it is not it is not, like thalidomide and practolol, to be swept under the carpet of history
Frank Lesser
THALIDOMIDE (Distaval) 1958–61.
Practolol (Eraldin) 1970–75.
Benoxaprofen (Opren) 1980–82.
Three British drug disasters in 25 years, the last two within the past ten years and since the Committee on Safety of Medicines was set up.
And the prospect?
According to Kenneth Clarke the health minister there's more to come.
Six months after Opren came off the market he proposed no improvements but whatever changes we make in our monitoring system ‘it is almost certain’, he assured us, ‘there will be another such incident sooner or later’.
Do we have to accept this forecast of inevitable doom?
It is based on the minister's assertion that there was no delay by the manufacturers, Dista Products Ltd. in giving the Committee on Safety of Medicines (CSM) information about accumulation of the drug in the elderly; nor by CSM in acting on this and on its own reports of adverse reactions.
But the true history of Opren raises serious doubts about this picture of events.
Opren, a drug for treating arthritis, received a product licence — which gave it the right to be marketed in the UK — in March 1980 from the then minister.
Already quite a lot was known about the non-steroidal anti-inflammatory drugs (NSAIs), used mainly to treat arthritis and other joint inflammation; about who was likely to receive prescription for them; and about the adverse reactions they had caused.
There were more than 80 NSAI preparations, containing some 30 different chemical compounds, listed in the Monthly Index of Medical Specialities (MIMS) when Opren first appeared there in November 1980, in the wake of a rip-roaring advertising campaign.
Aspirin is the oldest and best known NSAI: some argue that the benefits of its newer rivals are at best doubtful.
Opren was one of the chemical class of propionic acid derivatives, of which five were already on the market in many forms.
Two specific claims were made for the new drug.
First, it was said to have a unique mechanism of action.
Secondly, it was claimed to prevent arthritis from getting worse.
Neither has since been substantiated.
These claims did not affect CSM's duty to recommend the granting of a licence anyway, as long as it considered the drug safe and effective.
It was clear to everyone that most of the patients taking the new drug would be over 65, and that elderly people have greater difficulty in eliminating drugs from their bodies than younger ones.
So well known was the latter that the Department of Health and Social Security lists the elderly among patients ‘who may be at increased risk’.
Details of the results of treatment of the elderly in clinical trials of the new drugs should therefore have been given to CSM.
In fact, only about 52 of the 291 patients in the British pre-marketing clinical trials were over 65, and the comparable American figures were 86 out of 277.
The detailed results for the British elderly patients are ‘confidential’; but CSM was satisfied with them, and did not seek further detail.
The range of known adverse reactions to NSAIs extended from mild rashes, through bleeding in the stomach and the intestines, to fatal bone-marrow damage.
In fact, on the basis of general experience, as well as of Opren's own clinical trials, the makers warned from the outset that special precautions were necessary if patients' livers or kidneys were not working properly, or if they had stomach ulcers or intestinal damage.
They also warned that the drug could cause sensitivity to sunlight.
These warnings assumed even greater importance because Opren stayed around in the body for a long time.
The standard measure of this is the half-life; the time taken by the body to eliminate half the dose taken.
In fact this property was first seen as an advantage: it enabled the patient to tolerate arthritic pain and manage the stiffness of the joints usually experienced in the morning with only one dose a day.
This ‘advantage’ was much emphasised in the advertising campaign.
On 25 February 1981 the US Food and Drugs Administration refused marketing permission and declared the drug ‘non-approvable’.
By spring 1981 British GPs, who hold the key to this highly lucrative market, were prescribing the drug at an ever-increasing rate.
For reasons which are not yet clear — presumably the pre-marketing clinical studies were considered inadequate — Dista was collaborating in a series of research projects to discover how the bodies of elderly patients cope with Opren.
Physicians in geriatric departments were commissioned to work with medical researchers, employed by Dista and its American parent Lilly.
The results of at least four such studies reached Dista in May 1981.
Indeed, the joint author of the most quoted of them.
Dr Ronnie Hamdy of St John's Hospital, London, told New Scientist that, because the firm did the drug assays in its own laboratories, it knew the results before he did.
The authors published their reports at the 2nd Benoxaprofen Symposium in June, by which time the firm had the full texts of the assays.
Dista handed some of them over to the CSM in October, four months later.
The minister continues to maintain that ‘There was no delay’.
All four studies concluded unequivocally that Opren accumulated in the bodies of patients with ‘below par’ kidneys.
Three of the studies pointed out that this was common in elderly patients, and that this indicated they should receive lower and/or less frequent doses.
Only in the August 1982 issue of MIMS did the manufacturers recommend medics to prescribe ‘half-doses’ in the elderly.
Why, Dista was asked was there a delay of 14 months (New Scientist , vol 96, That question remains unanswered.
But we now know more about what happened between June and October, and beyond.
Dista says it told health department officials ‘verbally’ in July about the evidence of Opren accumulation in the elderly.
The minister says there is no record of this communication.
DHSS requires firms to notify any adverse reactions reported to them within a month of receipt.
The first record is in August, when Dista's representatives suggested the research might explain the bleeding seen in some patients' stomachs and intestines.
When Lilly finally handed over reports from the June symposium to the Committee on Safety of Medicines on 7 October it also proposed that the data sheets of information to doctors be changed to recommend ‘half doses to the elderly’, according to the DHSS press office, or ‘reduction of dosage to over 75s’ according to the health minister.
The committee discussed this suggestion at its routine meeting in November 1981.
Evidently there was no urgency.
On 17 November it told Dista it thought it would be ‘inappropriate’ to publish the proposed data sheet change.
The minister has since explained that the committee found conflicting evidence in a ‘preliminary report’ from Indianapolis, the home of Lilly's research laboratories.
The conflict was that ‘the drug appeared to be retained much longer in the bodies of the patients in Basingstoke (Dista's British headquarters) than in the patients in Indianapolis’.
Researchers say dose should be cut
Asked the name(s) of the author(s) of this report, the DHSS says ‘It has not been published — ask Dista.’
Dista won't talk.
But the most categorical report presented to the June symposium comes — by chance — from seven researchers at the Lilly Laboratory for Clinical Research, Wishard Memorial Hospital, Indianapolis; Lilly Research Laboratories, Indianapolis; and Indiana University School of Medicine, Indianapolis.
They said: ‘…we recommend that the dose of benoxaprofen be decreased (approximately 50 per cent) or the interval between doses extended (2.5 times)…if benoxaprofen is used in the presence of significant renal disease’.
And again: ‘Since a reduced creatinine clearance (a measure of kidney function) is not an uncommon finding in elderly patients, adjustment of doses of benoxaprofen to prevent abnormally high plasma concentrations should also be considered in the elderly patient.’
Lilly will not say whether it found a conflict in the evidence for accumulation it presented to CSM on 7 October 1981.
But it points out that its representatives were in September already handing out a booklet to GPs ‘which included the studies on elderly patients’ reported to the Paris symposium.
CSM says it did not ‘officially’ receive a copy of this booklet, though it is possible some DHSS officials may have seen it.
Sadly, experience suggests that most doctors would have thought the booklet to be just more advertising for Opren and thrown it straight into their wastepaper basket, unless the representative drew particular attention to the studies in question.
This, once again, is unlikely to have happened often.
Still, Dista did do something.
One other fact of the period between June and October in 1981 makes the apparent lack of urgency at CSM difficult to understand.
Opren was made available to hospitals here in May 1980, and pharmacists had stocks from which to dispense GPs prescriptions in October.
‘In the first twelve months after marketing,’ the minister told parliament, ‘CSM received an unprecedented number of adverse reaction reports.
About 2000 had been submitted by doctors by August 1981.’
He went on to say that’ 1500 related purely to reactions of the skin and nails…were predictable from the clinical trials…skin reactions were not generally serious…’
But did CSM tell Dista that the number of reports was ‘unprecedented’?
Neither party will say.
Did CSM discuss it at the November meeting?
These ‘leading experts’did agree to recommend lower doses for elderly patients 7 ½ months later.
What do the minutes record about that November meeting?
The number of reports is important for another reason.
The best-informed guess from those collecting ‘yellow card’ adverse reaction reports has long been that at most only 10 per cent of serious reactions, including death, and considerably less than 1 per cent of mild reactions come to the CSM's notice.
This means that by August 1981 some 200 000 patients may have suffered mild and transient, moderately severe, or severe reactions to Opren.
The validity of this projection has since been tested.
By August 1982 CSM had received over 3500 reports of adverse reactions to Opren.
At that time some 500 000 patients were receiving the drug on prescription.
Assuming that one in 10 were severe reactions — experience suggests the ratio would be much lower — that implies a total of 318 500 reactions, or two out of every three patients.
A study of 300 patients in the Rheumatology Department of Nomich Hospital on Opren, published in May 1982 by Dr J. P. Halsey and Dr N. Gardoe, found that 196 (65.3 per cent) reported side effects.
Half of these gave up the drug (British Medical Journal .
vol 284, p 1365).
The facts that might have prompted CSM to take a more serious view of Opren at its November 1981 meeting are: 1 its own unprecedented number of adverse reaction reports; which by 1 November 1981 included over 20 deaths which reporting doctors suspected to be due to an Opren reaction; 2 The reports of the Paris symposium, which it could have attended; and 3 Dista's suggestions for a change in the dosage recommendations.
GPs in this country saw no effective action until the August 1982 MIMS — a nine-month, apparently leisurely, gestation period at CSM, during which patients suffered and died.
‘CSM acted in October 1981…rationally, based on the scientific data that were then available’, says the minister.
‘I simply do not accept…that there was any avoidable delay in detecting and acting on the evidence of Opren’.
The minister's assessment of the scientific data, like that of Gwyneth Dunwoody, a Labour MP, was aptly described by the Minister himself in the parliamentary debate of 27 January 1983.
‘The politest thing one can say’, he said, ‘is that  that is the wisdom of hindsight by people who are not trained to know better in that area’.
‘The key point is that the studies did not contain any specific evidence that the drug was harmful’, said the minister.
‘…Dr Hamdy's report did not refer to deaths from jaundiced livers and kidneys.’
True, how could it?
But had the minister read the introduction to that paper he would have found the following: ‘The metabolism and excretion of compounds with a prolonged half-life, however, may be slower in old age as a result of impaired renal function commonly seen in this age group.
The continuous administration of such compounds at the normally recommended doses to elderly patients, therefore, may result in unnecessarily elevated and potentially harmful plasma levels’.
Hamdy talks but no-one acts
Say ‘metabolism’ to an undergraduate student of pharmacology and he will think ‘liver’; say ‘excretion’, and he will think ‘kidneys’.
Ask him what effect impaired excretion will have on drug concentration, he will say: It will go up.
And might add thoughtfully, if excretion depends upon metabolism in the liver, I wonder what's happening there.
In effect, that is what Hamdy was saving, with foresight.
There is a gap now in the Opren story.
In April 1982 the US's FDA licensed Oraflex (Opren's US version), nearly two years after CSM.
As with thalidomide — CSM did not exist then — and practolol, the adverse drug reactions of British patients protected their American cousins from three large scale drug disasters, simply by the FDA's delay in licensing.
By May 1982 another thousand adverse reactions may have been reported.
In that month a series of articles on Opren toxicity appeared in the British Medical Journal .
These included five reported deaths with jaundice in Northern Ireland.
Still no urgent action, by CSM, which was then negotiating a dose recommendation change with Dista, nor by the Minister, although then ‘the floodgates of notifications opened…
The evidence came in quickly’…and by late July was reasonably conclusive, and the licence was suspended’.
That is a delay of at least two months from the opening of the floodgates.
Observers of the DHSS's Medicines Division, including former employees, see nothing but panic at the moment when Kenneth Clarke, the new health minister, decided to suspend Opren's licence.
A press release from DHSS, dated 4 August 1982 declared Opren's product licence suspended ‘with immediate effect on grounds of safety.
The Chairman of CSM, Professor A. Goldberg, is writing to all doctors and pharmacists to inform them…
’ Goldberg's letter was attached and is dated 3 August 1982.
It, too, says Opren's licence has been suspended ‘with immediate effect on grounds of safety’.
When was the licence suspended, then?
And when was Dista told?
Goldberg told Dista after a special meeting of CSM on 3 August, but the suspension took immediate effect on 4 August, says DHSS.
‘The committee endorses this action by the licensing authority’, Goldberg's letter goes on, ‘and considers that, in the light of the apparent safety hazard, suspension of the licence is appropriate at the present time’.
Doctors and pharmacists all heard first of Opren's suspension from the media or from patients long before Goldberg's letter arrived.
Not much evidence here of people acting rationally.
I asked the committee to review the licence’, says the minister, ‘but by early August it was withdrawn’.
In August 1982 the minister received the further evidence CSM had asked for in November 1981 after the licence had been suspended.
‘The licensing authority has therefore not asked for the CSM's advice on it’, Clarke told Jack Ashley in a written answer to a question (which we had put to the DHSS three week earlier).
Now, were Opren the first drug disaster presided over by CSM it might, to parody Oscar Wilde, have been reasonably ascribed to misfortune.
As it is the second, we have to consider the possibility that it was just complacency, which the minister vehemently denies, or even downright carelessness.
The first failure was practolol in 1975.
There, too, the issue was CSM's failure to act on a drug already on the market, for a period of seven months after clear evidence of serious adverse reactions.
The evidence was sufficient to cause the New Zealand Department of Health to restrict its use to hospitals from 1 March 1975.
The same action was taken in the United Kingdom only on 1 October 1975, and then by the manufacturer, ICI, not by CSM.
Then, too, a demand for a public inquiry into drug safety was turned down — the minister was Dr David Owen — as it had earlier been over thalidomide by David Ennals.
Ministers' confidence in CSM is apparently unbounded.
That, however, did not prevent Clarke's immediate predecessor from turning down CSM's proposals for systematic post-marketing surveillance of new drugs, on grounds of ‘the paramount need to restrain public expenditure’, nor Clarke himself from rejecting CSM's recommendation to license the injectable contraceptive Depo Provera.
When Clarke wanted to prove the adequacy of CSM's resources to do its work he cited the fact that, in the three years since the government came to office in 1979, these had risen from £1.1 to £1.2 million a year — a cut in real terms, according to the retail price index, of well over 20 per cent.
Each new proposal by CSM to improve its machinery for ‘promoting the collection and investigation of information relating to adverse reactions’ has, according to Professor David Finney of Edinburgh University, a member of CSM, been ‘refused, or delayed indefinitely, for reasons of cost’(Times , 21 August 1982).
The unreadiness of governments to put money where the minister's mouth is, however notorious, not the issue.
The issue is that, despite the information available, CSM took no action to protect patients from practolol at least from January to October 1975; and again took no action to protect them from benoxaprofen from October 1981 to August 1982.
How could it happen?
Secrecy underlies inaction
The primary cause is probably what Jack Ashley MP called ‘the deplorable secrecy’ that surrounds the whole business of drug regulation in this country.
This in turn stems from the quite understandable confidentiality on commercial grounds imposed on CSM for all the information supplied to it by a drug firm.
This confidentiality provides the basis of ‘mutual respect’ to which CSM's chairman has referred.
In everyday practice — and CSM does work every day and not just on those when a practolol or a benoxaprofen blows up in its face — this leads to an informality of conduct of business which was carefully cultivated by the late Sir Derrick Dunlop from the earliest days of the Committee on Safety of Drugs, CSM's forebear.
It is probably best regarded as a typically British way of enabling two parties, representing different, occasionally even conflicting, interests to rub along together without too much friction.
Practolol and benoxaprofen show, however, that such a cosy partnership not only cannot stand the strain of a disaster, but also leads to a complete paralysis of action in the resultant crisis.
CSM fears to take the first step that might disrupt its partnership with industry.
The firm is pushed to continue as long as it can without breaking the law — indeed Dista can claim CSM positively discouraged it from taking action, a situation which, some observers claim, shows that the British drugs watchdog has power without responsibility.
Result?
Hundreds of people suffer, many die, unnecessarily.
Dista's failure is understandable.
It had done everything asked of it by CSM, waited three years and got its product licensed.
Opren was selling like hot cakes.
Yet it even made a suggestion to CSM that might have made a dent in its sales graph.
Its business was to sell as much as fast as it could.
It had made an investment and wanted a quick return, and more.
But these considerations did not stop Ortho-Cilag, the manufacturer of another anti-arthritic drug, Zomax, from taking it off the market last week after only five reported deaths in US and three in the UK.
CSM's business is drug safety.
It does not do experiments itself.
It monitors other people's, usually those of the drug companies.
(Some suggest that part of its secretiveness arises from a fear of becoming involved in the litigation instituted by injured patients.)
Its task does not end with a recommendation to permit marketing.
Indeed, and by statute, in some senses it only begins.
‘And yet, despite the Medicines Act and its regulations, CSM did little better with practolol once it had been marketed than was done without the legislation in the case of thalidomide’, we commented in 1980.
The urgency of measures to institute systematic surveillance to replace the CSM's present random and spontaneous collection of adverse reports can hardly be overstated’(New Scientist .
vol 88, p 636).
For ‘practolol’ in 1975 read ‘benoxaprofen’in 1981–82.
The evidence of the need for an independent public inquiry now into both is overwhelming.
Origins of the CSM
The ‘specially urgent need to take whatever steps were immediately possible to improve the safety testing of drugs’ in the light of the thalidomide disaster led the Joint Sub-Committee on Safety of Drugs to set up the Committee on Safety of Drugs in 1963.
It started work on 1 January 1964, inviting manufacturers voluntarily to submit reports on the safety testing and human trials of new drugs The Joint Sub-Committee also reported ‘that legislation on the whole subject is urgently required’.
That legislation was the Medicines Act 1968 which made statutory the previously voluntary arrangements.
In 1970 the Committee on Safety of Medicines was set up under the Act and began work in the following year…with the purpose of ‘a. giving advice with respect to safety, quality and efficacy in relation to human use of any substance or article (not being an instrument apparatus or appliance) to which any provision of the Act is applicable and b. promoting the collection and investigation of information relating to adverse reaction for the purpose of enabling such advice to be given.’
REVIEW
Fluctuating fortunes for fusion forces
Fusion: science, politics and the invention of a new energy source, by Joan Lisa Bromberg, MIT, pp 344, £24
Michael Kenward
It is  difficult to believe that a desire to put on a good show at an exhibition could shape a major research programme.
But that is just what happened to fusion research in the United States toward the end of the 1950's.
Joan Bromberg describes in some detail the US's preparation for the Second International Conference on the Peaceful Uses of Atomic Energy.
The conference and the exhibition that went with it were held in Geneva in 1958.
Before then all fusion research had been conducted  behind a screen of secrecy.
The US wanted to be able to remove that screen with a fanfare to reveal a machine that was producing fusion energy.
Scientists in the US and Britain were attempting to control thermonuclear fusion.
They were trying to tame the process that gives the hydrogen bomb its  devastating power-the same process that ‘fuels’ the Sun and the stars.
In the mid-1950's nuclear fission had still to be turned into a commercial power source.
So there was a chance that fusion, which would derive its energy from deuterium, an isotope of hydrogen and a constituent of ordinary water, could come along and render fission redundant.
The early fusion experiments looked as if they were making great strides toward the desired goal.
At least, that was how the scientists interpreted their  experimental results.
But fusion was at the time buried beneath a blanket of secrecy: not open to the usual processes of review that attend research available for the scientific community to read the scientific papers and arrive at their own interpretation of the results.
The quality of the research suffered as a result.
The various fusion machines that a had been built were producing neutrons-supposedly a sign that fusion was taking place but the neutrons had nothing to do with  thermonuclear reactions.
The neutrons came from fusion reactions between particles that had been accelerated to very high energies by magnetic fields the scientists were using to contain the very hot ionised gases that were supposed to support fusion.
The US and the UK tried to coordinate the way in which the results of their fusion research reached the world.
But when it came to it, national pride won out, and the UK forgot all about international agreements.
As a result the British Zeta results were splashed all over the  world 's newspapers (New Scientist , 20 January, p 166).
That turned out to be a mistake, Zeta's neutrons were not from thermonuclear fusion.
But the US also had its ‘false alarms’.
Lifting the secrecy curtain subjected the fusion programme to the scrutiny of the scientific community, and led to an infusion of new people and new organisations into the research programme.
The quality of work then began to rise.
Fusion is a fascinating example of government-sponsored research.
As Bromberg tells us at the beginning of her excellent mixture of history of science and politics, ‘The US government has supported a research programme in fusion energy since 1951, and in the 30 years through 1980 it has expended more than $2 billion.
Washington programme administrators have estimated that the total cost through the stage of commercialisation, will approximate $15 billion.’
With that much money involved it is not surprising that fusion has seen its share of political intrigue.
Bromberg conveys that intrigue well.
She tells of the struggle between the administrators in Washington and the scientists in the laboratories.
Over the years, control of fusion flowed from the laboratories to Washington.
And with that move the programme changed as the administrators began to pay more attention to the ultimate goal, a working power system, rather than the scientific research that had intrigued the scientists in the laboratories.
Also over the years the fortunes of different approaches to fusion have varied.
Here too Bromberg gives an excellent account of the rise and fall of different magnetic confinement systems.
(The aim of most fusion research is to devise a magnetic container shaped in such a way that the very hot ionised gas, known as a plasma, does not escape.)
After reading Fusion , you will know why one particular confinement system, tokamak, has come to dominate fusion research, and why large tokamaks are under construction — and continuing the rivalry between countries — in the US and Europe.
Fusion has gone through a number of different phases.
Bromberg describes these transitions, and the political transitions that went with them.
It all started with the inventor.
In the early days machines were dreamed up, usually by an individual, with little scientific  underpinning .
No one knew how a particular device would work before it was built.
After research had begun to throw some light on to the physics of plasmas, invention gave way to a more scientific approach.
Now that there is every reason to believe that we can build a fusion reactor there is growing attention to technology.
Bromberg gives just the right amount of scientific explanation.
After reading this you will not be an expert on fusion science, but you will realise that fusions fluctuating fortunes have had a lot to do with the way in which the science and technology developed.
It is fascinating to see how theory and experiment have vied for the lead over the past 30 years, with first one then the other leading the way.
But the basis of any such programme must be experimental result: ‘Experimental proof was vastly more persuasive that theoretical prediction in controlled thermonuclear research, where an unexpected experimental outcome was more the rule than the exception.’
Today fusion in the US is, as at many times before, at a  crucial stage.
A new experiment is about to come on line.
That experiment-the tokamak fusion test reactor (TFTR) -is nearing completion at Princeton, despite lukewarm response to the idea when it was first put forward.
As usual the budget for fusion research in the US is uncertain.
So far fusion has produced remarkably little interest outside its own community and the media, which welcome any significant scientific result with an unhealthy optimism.
But you do not have to be a fusion buff to appreciate Joan Bromberg's history of an important part of science.
If, as is very likely, experiments finally prove the ‘scientific’ feasibility of fusion in the next few years, there will be plenty of interest in the topic.
This book provides an excellent introduction to the science and politics of fusion.
It should appeal to all historians of science.
It cannot hope to be complete, but with luck Bromberg will even now be working on a detailed history of the TFTR experiment.
The man who gave us the meson
Tabito —‘the traveller’ by Hideki Yukawa,World Scientific Press, pp 218, £11 
Martin Goldman
HIDEKI YUKAWA is one of the acknowledged geniuses of modern physics: he invented the pi-meson.
In electro magnetism, the repulsion between two electrons can be pictured as the exchange of a photon — a particle that has to be massless to give the force its infinite range, its inverse square law.
Yukawa realised that the short-range attractive force between nuclear particles could be explained as the exchange of a massive intermediate particle.
None such had been observed — so Yukawa said, ‘go to higher accelerator energies and the meson will be!’
He was correct and won the Nobel prize.
Today that analogy seems almost trivial, yet, as Professor L. M. Brown points out in his stimulating introduction to this book, in the 1930s there was an almost pathological fear of new particles.
Wolfgang Pauli (no slouch) waited three years before committing his invented new particle, the neutrino, to print, and then only as a footnote.
So how did Yukawa dare to make such a revolutionary proposal?
The formative years of a genius are a perennially fascinating and tantalising subject.
What were the special environmental ingredients that built on the latent in-born talents?
In Tabito we get Yukawa's autobiographical musings on his early years.
For me, a number of special features emerged.
In an incredibly education conscious Japan, his father, an academic, expected his sons to become academics; and they all did.
Yet beyond this general expectation he did not pressure them too early, at one point he seriously doubted whether Hideki was fitted to benefit from university study.
Hideki's mother was educated and emancipated, but on marriage subjugated herself to the traditional Japanese wife's domesticated role.
Her only outlet was the success of her sons.
And Hideki was an introvert, who quickly learned to be independent and self-sufficient.
One wonderful story is that he decided against a career in mathematics when his teacher gave him a poor mark in an exam for answering a problem correctly but not using the method taught in class.
Teachers everywhere beware!
The birth of a new science
Classics in radio astronomy selected by Woodruff Turner Sullivan,Reidel, pp 400, $9.50 
Nigel Henbest
‘DIRECTIONAL characteristics of atmospherics at high frequency’ runs the title of a paper published in the Proceedings of the Institute of Radio Engineers just 50 years ago.
It doesn't have a world shattering ring to it.
Yet this paper led to our century's great revolution in astronomy, for here an American engineer, Karl Jansky, announced his detection of ‘static’, which turned out to come from the sky.
Thus was born the science of radio astronomy.
With hindsight, the emergence of any new branch of science seems inevitable, and its development a logical progression.
But it rarely happens that way.
In this book, Woodruff Sullivan traces the actual story of the birth and early growth of a new science in our own time, by reprinting a selection of 37 ‘key’ papers in radio astronomy.
From Jansky, the account moves forward to 1954.
In these two decades, astronomers had identified the brightest radio sources, worked out that extragalactic sources have a double structure, calculated that the continuum emission is synchrotron radiation, and both predicted and discovered the 21-cm line  emission from hydrogen atoms in space.
Sullivan also includes three early unsuccessful attempts (in 1896 and 1902) to detect radio waves from the Sun.
Sullivan has grouped the papers under five topics, and has fleshed them out with excellent introductions to each section and helpful editorial notes throughout.
The result is absorbing and highly readable.
The book complements the general survey of 20th-century astronomy papers in A Source Book in Astronomy and Astrophysics 1900–75 (K. R. Lang and O. Gingerich, Harvard UP, 1979) and the national sociological study of Astronomy Transformed: The Emergence of Radio Astronomy in Britain (Wiley-Interscience, 1976).
Classics in Radio Astronomy should be read by historians of science and by radio astronomers — particularly those who (like myself) did not live through the exciting early years of the subject.
So much of modern astrophysics has sprung from the seeds of radio astronomy that I would recommend a session with this book for anyone currently involved in astronomy research.
ET might get a crossed line
The world in space edited by Ralph Chapman,Prentice-Hall, pp 689, £39.95 
Peter Marsh
JUST SUPPOSE a creature from outer space were to visit the Earth and a group of world dignitaries assembled to greet him.
One of the visitor's first questions would, naturally, be: ‘How are you making out in space?’
At this point some vainglorious politician would step forward and present him with a book such as this one.
The impression that the being would take home is that Earthlings are making reasonable progress in rudimentary aspects of space science and technology; that the world is keen to spread the benefits of such studies from the industrialised to the developing world; and that all work in space science and technology follows the lead set by farsighted government bureaucrats and politicians.
All of which is what the people who meet the star traveller would like him to believe, even though it represents a far from comprehensive picture of what is going on.
The reason for the gloss that this book puts on the world's space affairs is simple.
It is the work of a gaggle of United Nations committees and was initially prepared as background reading for delegates attending last summer's mammoth Unispace conference organised by the UN in Vienna.
Thus anything the  slightest bit controversial is left out as are, with a few exceptions, references to what private individuals and companies are doing in sending objects out of the Earth's atmosphere in the interests either of research or for financial reward.
All this is not to say that The World in Space lacks value.
It gives a very good explanation of what the world has achieved to date in space science and technology.
(Here, however, tables and appendixes that would have listed, for instance, manned space trips are strangely  missing .)
The book also includes useful papers on how remote sensing and communications satellites and other results of space research can help the Third World, The emphasis on this area of work reflects, one must presume, the desire by developing nations represented on the UN committees to gain a greater share of the benefits of space research.
A glaring omission is, however, the lack of any details about military work in space.
The visitor from beyond the planets would obtain the impression that the Earth is a very peaceable place, when in fact three-quarters of all satellites launched have been controlled by military planners and virtually every country's space programme was originated by the desire of war chiefs to develop rockets that would carry high explosives or nuclear bombs.
In sum, this is a good book to have in your reference library — providing you have other sources of information on which to draw.
But the book's publishers should be warned: if searches for extraterrestrial intelligence ever pay off, then stand by for an avalanche of orders from interested parties.
Orson Welles teaches psychology a lesson
The invasion from Mars by Hadley Cantril,Princeton UP, pp 224, £4.45 
David Cohen
ON HALLOWEEN in 1938, Orson Welles produced one of the great special effects of broadcasting.
He accidentally persuaded millions of Americans that Martians had come and were devastating New Jersey with their heat ray.
It was, of course, just a play based on H. G.  Wells' The War of the Worlds but millions literally, did not realise.
They thought it was for real, and panicked.
Within days Hadley Cantril and a team of psychologists from Princeton University were interviewing listeners to see just what had made them so convinced and, in many cases, so panic stricken.
Their researches were first published in 1940.
Cantril argued that on the whole, the less educated were the most gullible.
Many people had switched on after the announcement that Welles's Mercury Theatre was doing a play.
Because of the cleverness of the script, they assumed that these were in fact proper news broadcasts.
Nearly a fifth of those who listened to the announcement, however, still believed the Martians had landed.
Cantril had no explanation, but claimed that the depression and the gloomy news from Europe, with Hitler rampant, made people all too ready to believe the worst.
The Invasion from Mars certainly contains some graphic case notes, such as the spinster who believed humanity deserved destruction for being too hedonistic; and the unemployed young man who thought that this finally scuppered his chance of getting to college and work.
Cantril saw this young man as hoping for cosmic disaster to free him from worries.
There are other good vignettes of people telephoning each other to say goodbye, huddling in corner stores and generally acting as they do in  scary SF movies.
As an example of psychologists reacting to a news-event, Cantril's study is a model of hard work.
None of what he found now seems novel but that is, perhaps, because the study has become a classic.
This leaves two interesting questions.
First, why did Princeton decide to reissue this work 40 years on?
The only answer I can think is that some enterprising editor believed that, with ET all the rage after Star Wars , the time was ripe for a study of how Earthlings behave when aliens land.
What is more interesting, perhaps, is have our perceptions of ‘aliens’ changed?
In 1938, people were only too ready to believe in the evil creatures from outer space.
Cantril, in 1966, said that he did not believe — we are now somehow too sophisticated to be taken in by anything so fanciful.
Unfortunately it could happen again and on a much more extensive scale.’
But, even though in 1983 we have our own depression and the shadow of the bomb hangs over us, we seem to want to believe in astral goodies, cuddly ETs who, when we have close encounters with them, make us deeper, more meaningful beings through imbibing their goodness and wisdom.
The force is with us.
Cantril died in 1969 and so cannot comment on this phenomenon.
It is a pity, because what dates his book is not its methods but the readiness to believe in fearsome things from outer space.
It may not be that we have become too sophisticated but that we are so confused we seek salvation even from out there.
That apparent change, I suggest, would be worth studying.
Prophet of the shape of things to come
The logic of fantasy: H. G. Wells and science fiction by John Huntington,Columbia UP, pp 191, $29.50 
H. G. Wells and the culminating ape by Peter Kemp,Macmillan, pp 225, £15 
Brian Aldiss
Charles Darwin's work forced his generation and the generations since to restructure the conventional ways in which they thought about humanity's role in the world.
Not the least effective of these restructurings were the scientific romances of H. G. Wells.
I have a 1920's edition of Wells, published by Collins, which tags him — The most widely read author in the world’.
This vast popularity was a testament not only to the striking and disturbing nature of Wells's ideas, but to the way he handled them.
John Huntington has analysed Wells's fundamental procedures in his fiction, showing how these changed and combined during various phases of his life.
At their best, the procedures include ironies and paradoxes which serve to illuminate the world Wells confronted.
This scholarly and agreeable volume demonstrates how Wells often builds a ‘two-worlds structure’ for his stories.
In The Wonderful Visit , the Angel and the Vicar are inevitably at odds.
When a summons is taken out against the Angel, the Vicar says, ‘Here is a real Angel and a real summons — how to reconcile them I do not know.’
As Huntington says, it is the total system with its inherent opposition and paradox which makes for the novel's interest.
It is the same with the two worlds in conflict in The Country of the Blind , that wonderful story of an opposition without resolution, and with Mars and Earth in The War of the Worlds .
In particular, there was the problem of evolution and ethics.
In an early essay on human evolution, from which Huntington quotes, Wells speaks of morality as being the padding which helps ‘keep the round Palaeolithic savage in the square hole of the civilised state’.
He sees in mankind two conflicting beings: the culminating ape and the artificial man, as he calls them.
Much of his fiction is spent dramatising or reconciling the dichotomy.
Wells employed two different ways of thinking about the future, which he once labelled undirected and directed thinking.
Directed thought is based on a scientific model, and seeks unitary answers about the future.
Undirected thought, in Huntington's telling phrase, ‘wanders in the maze of balances and conflicts which compose history’.
The former type of thinking can be judged by the accuracy of its predictions, the latter by the aesthetic pattern or moral complexity it achieves.
The Time Machine itself is an undirected thought vehicle; The Land Ironclads, prophetic and little else, are directed thought vehicles.
Huntington's argument goes a long way to making clear the disappointment a reader experiences if he approaches the Wellsian SF novels in chronological order.
After the first splendid burst, from The Time Machine to The First Men in the Moon , the quality deteriorates.
The Food of the Gods, The World Set Free, Men Like Gods , and The Shape of Things to Come become progressively more like tracts.
Undirected thought has been changed to directed thought.
Fancy is no longer free.
Wells lost his tolerance of contradiction in his anxiety to tidy up the world.
His seeking for single solutions coarsened his thinking and sank into abstraction.
Among the most engrossing parts of this book are those which demonstrate the confusion of Wells's thought as he seeks to evade conflict, for instance by proving that ethics and evolution are one.
As he becomes the champion of efficiency, his prose ceases to function in its old complex imaginative way.
More ominously, his  spiky affection for the common man becomes contempt.
The exposition extends its sympathy for both the younger and the older Wells, and good sense is lavished on the borderline books between — uneasy but stimulating mixtures like When the Sleeper A wakes and A Modern Utopia .
Huntington is shrewd when he reveals many implications in Wells's prose, and ends by making useful distinctions between utopia and dystopia, which he reviews as related, and anti-utopia, which he views as opposed to the other two.
Excellent critical insights are continually generated.
Nevertheless,The Logic of Fantasy has something of a two-world structure of its own.
After the examination of Wells's thinking comes an overview of those who have followed Wells, together with a slightly halfhearted gesture towards modern SF.
Eugene Zamyatin's anti-utopian We is neatly dissected to show at its core two contradictory imperatives, a commitment outside self, and self and wholeness.
‘Life asks both, but the novel sets them up as opposed.’
To read We is constantly to hive to rethink the issue.
Here the evolution versus ethics question is submerged in the other big one of our time, state for individual or individual for state?
This leads Huntington on to discuss some of Wells's successors, such as George Orwell and Ray Bradbury.
Perhaps these passages are too brief after the rewarding stretch on Wells.
But he makes clear the utopian nature of modern popular SF (within his own definition).
Peter Kemp's aim seems to be to make Wells sound smug.
Even his title conveys prejudice.
Wells did not regard man only as ‘the culminating ape’; I have quoted the passage from which the phrase comes, showing how Wells was painfully aware of our duality.
For instance, he collects on his little card index all references in Wells to feeding, eating, and patent medicines.
His objective seems to be to make Wells out as obsessive, though far more violent food images could be drawn from Dickens (’ I'll eat my head’, in Oliver Twist , etc).
Wells was on the brink of death by consumption when his early work appeared.
Food implied health.
He also uses the idea of mankind as food to emphasise the evolutionary truth of man as one more source of protein.
But Kemp has no space for theory, nor inclination to show Wells in his time, one among other writers.
He makes fun Orwells's notion of an elite; yet the Chinese are now confronted with the problems Wells discussed almost a century ago.
Elites, lovable or not, remain necessary.
Although Kemp's is a silly book, it contains enough of Wells's lively turns of phrase — even when used against him — to make it readable.
Perceptual puzzles for the brain
The art and science of visual illusions by Nicholas Wade,Routledge, pp 293, £19.95 
Philip Steadman
IT IS presumably the mustachioed face of the author that hovers elusively behind the undulations of the Zollner figure on the front of Nicholas Wade's book.
Zollner's illusion makes parallel lines seem to diverge by placing them on a zigzag striped background.
Here the diagonals become shimmering restless waves, as in the blinding canvases of Bridget Riley.
The picture (Visual Allusions)gives the playful flavour of the book as a whole.
The first section introduces the visual phenomena exploited by Op Art: moire patterns, distortions arising from the shape of the eyeball and the lens, afterimages, simultaneous contrast effects, subjective contours, all the principles of ‘good form’,— good continuity’ and figure round relationship explored by the Gestalt psychologists.
The second part covers ‘geometrical optical illusions’, a term as Wade says with ‘a rather archaic ring to it, echoing the mid-19th century Teutonic desire for precision’.
Here are the famous Necker cube, the Muller-Lyer illusion (equal length lines with inward- and outward-pointing arrowheads), the Ponzo figure (equal-length bars set within converging lines), Fraser's twisted spiral patterns (not spirals at all, but circles), the impossible objects (’ devil's pitchfork’, endless staircase, impossible triangle) and many, many more.
In the last section of the book Wade introduces new ‘Optical’ illusions of his own devising, in which the somewhat bland and  and diagrams of the Teutonic psychologists are deliberately complicated, enriched and compounded together with the trickery and flicker of Op.
Reversing staircases are embroidered with stripes, Rubin's ambiguous vase/faces emerge from the tottering black-and-white brick walls of Munsterberg's illusion, reversing cubes become whole reversing sets of vase/faces, in a display of graphic virtuosity which is dazzling in every sense.
Illustrations, nearly 300 of them, form the major part of the book.
A special feature is the series of transparent overlays supplied, some to generate the moire patterns, others to provide a novel representation of the geometrical illusions, whereby one part of the configuration is separated from the remainder, and the distorted circles are seen to be truly circular, the apparently diverging lines to be truly parallel.
Wade's purpose is not primarily theoretical, although he reviews those explanations which have been offered for the various classes of illusion.
In the end, however, he is sceptical of whether illusions ‘hold the key to unlock the mysteries of vision’, and seems to sympathise with those students of the subject who have abandoned any search for a general theory.
His intention is rather ‘to encourage scientists to consider more complex visual displays’, and to present the richness and fascination of his compound illusions for their own sakes.
As for the merits of the original illustrations as works of art, to my own taste at least the first impressions were of a certain period quality — with Wade's occasional curvaceous nudes and sports car profiles intruded into the abstract geometries bringing memories of Victor Vasarely's more lamentable lapses into commercial vulgarity, In the end, however, Wade's sheer enthusiasm and invention persuaded me into a renewed fascination.
Men behind man-made intelligence
Scientific temperaments: three lives in contemporary science by Philip J. Hilts,Simon & Schuster, pp 302, $15.95 
Ros Herman
‘THE ROBOTS are coming.
From now on, walk softly and carry a big can opener.’
Fortunately this quotation from Philip Hilts's new book is not an example of his style but one of the more lurid popular reactions to the prospect of mechanical brainpower.
What Hilts does attempt to put across is a more subtle viewpoint, that of a pioneer of artificial intelligence, John McCarthy, one of the three American scientists that he profiles.
In puncturing the mask of McCarthy's awesome intellect, Hilts acts on our behalf as both questioner and narrator.
He tells us — largely as he must have heard it from the horse's mouth — the history of programmed machines, the development of McCarthy's own interest in combining human common sense with the brute number-crunching force of early computers, and how this led to his own contributions, perhaps the best-known of which is the invention of LISP, now the standard programming language of artificial intelligence.
We also learn of McCarthy's radical intellectual upbringing and his rightwards conversion in the early 1970s, his hobbies, his family, and his happy but tragically-curtailed second marriage.
Through his tastes and his trials, his political naivety and optimism, McCarthy is led gently down the ramp from the awe-inspiring pedestal of the brilliant scientist to take his place in the milling crowd of common humanity.
We, the readers, no longer fear, but warm and pity.
Hilts takes a similar tack with his other two subjects, the cowboy physicist Robert Wilson, whose discovery of cosmic microwave background radiation confirmed the big-bang theory; and the restless, insatiable biochemist Mark Ptashne, who chose and cracked a problem — how the cell ‘represses’ production of proteins from certain sections of DNA — that daunted many of his senior colleagues.
In each case Hilts exercises his considerable journalistic skill to fill in different parts of the picture of a personality in a flowing, attractive, if rather thin, prose style.
Perhaps his greatest asset is his ability to let the story tell itself, and not to embroider description with implicit or explicit conclusions.
It is not long, however, before the reader realises that in investing so much time and effort in a small number of individuals.
Hilts has fallen under the spell of each in turn — not so deeply as to distort fact, but deeply enough to lose the sardonic, sceptical qualities that ought never quite to desert the journalist.
Hints at races for priority and battles for funding, disappear politely into the background as the protagonist's version, time and again, is taken as gospel.
Although it goes against the grain to say this, the exercise is valuable, if indeed it has the effect of providing an accurate version of a distinguished person's world view.
But it lies more in the realm of the hagiographer than the journalist.
Compared with recent serious journalistic books on science, such as the Eight Days of Creation and The Soul of a New Machine, Scientific Temperaments is a light confection.
In that it may prove all the more digestible to the popular audience, which might otherwise read about self defence against robots, it may be all the more valuable for that.
But to anyone with first-hand experience of the world of scientists, it has little new to offer.
How to make weather-talk
The weather of Britain by Robin Stirling,Faber & Faber, pp 270, £12.50 
Roy Herbert
THE BRITISH are said to be fascinated by the weather and talk of little else when the talk is small.
The idea may be something out .The Americans have weather programmes on TV that go on all the time, 24 hours a day.
They try to make the weather absorbing, or at least the programmes, by turning the presenters into characters, with jokes and fancy dress.
That argues that you can't make the weather interesting all the time.
Robin Stirling is a professional geographer and teacher.
It shows.
The nearest description of the text that I can manage is that it is kindly didactic.
For example, here is the beginning of the chapter on the elements of the weather.
‘Let us now consider the various elements, such as rainfall, hail, thunder, heat and cold, snow, sleet, fog, wind and sunshine that make up the weather.
We shall see how and when they occur, and how they vary in different parts of the country.’
That, although clear, is hardly captivating.
So it is a relief, occasionally, to get a quotation from such as Gilbert White, who, in one paragraph about the hard frost of 1784, sparkles like Jack himself in such even-toned and worthy surroundings.
It is a singularity of the book that it contains such a wealth of excellent and dramatic illustrations and deals with such titanic forces and events, but written in such a flat style.
There is no doubt that it contains a remarkably comprehensive account of what we know now about the weather and its causes in these islands, including what can be done with satellite observations.
Possessors of the book and of good memories could become the lions of weather-talk on commuters' trains.
But it will take work.
The history of weather, for instance, when notable snowfalls are considered: ‘19 October 1980.
Snow settled for a few hours in the Dundee area, causing traffic problems.
6 November 1980.
There was 5 cm (2 in) of snow in Jersey.
It remained on the ground for most of the day.’
It is all reminiscent of small earthquake in Chile, not many killed.
The book will be necessary, says the publisher, for those whose jobs and even lives depend on knowledge of Britain's weather.
Well, yes.
It adds, it will be absorbing for all those with a general interest in the subject.
Hardly.
The myth of reality
Physics as metaphor by Roger Jones,Wildwood, pp 254, £10 
Michael Shallis
THERE have been a number of books in recent years relating the sciences to philosophical, ethical and spiritual attitudes, and expressing an essentially holistic approach to all knowledge.
Physics as Metaphor is a part of this movement and yet it cannot easily be pigeon-holed alongside, for example, Fritjof Capra's The Tao of Physics .
For a start Roger Jones's book is intensely personal, almost, I feel, autobiographical; and his reference points do not lie rooted in Eastern mysticism, where so many similar books seem to be based.
Jones seems to have found elements of the trend of thought he is pursuing in modern Western culture, for example in Owen Barfield, Loren Eiseley, Michael Polanyi and Peter Ouspensky.
The book also moves close to a highly critical analysis of science and yet never becomes anti-science, only anti-scientific: Jones's own delight in physics enthusiastically drawing the sting out of his own criticism.
Physics as Metaphor is intended as ‘an idealistic reevaluation of the physical world’.
The author rejects the ‘myth of reality as external to the human mind’ and sees the Universe at large as the source of consciousness.
Such an expressed intention puts the book into the ‘holistic’ category and might alarm many scientists that what is to follow might be some kind of woolly metaphysical vagueness.
They would be wrong, however, because the key idea of the book is expressed in the title and thoroughly elaborated in the bulk of the text.
Physics, Jones argues, is a metaphor, a symbolic expression of man's search for meaning and understanding, and always a creative enterprise.
The four cardinal metaphors are the four foundations of physical science (space, time, matter and number); none of which has any objective, external status, rather they are ‘creations of the mind’.
Jones explores each in turn, calling on other metaphors to illustrate his points, but never strays far from mainstream physics.
In dealing with number, for example, he explores the psychology of numbers with an analysis of symmetry; he relates musical harmony both to Pythagorean mathematics and to Georg Cantor's work on infinite and transfinite numbers.
There is much material in these chapters to think about, whether the reader is a scientist or not, and alongside, threaded through the text, runs Jones's dislike of scientism and scientific idolatry.
The author does not like the way science has ‘stacked the deck’ in its own favour, arranging its metaphors to exclude the contradictory or ephemeral.
He calls, rightly, for the exposure and elimination of such idolatry and in his final chapters shows how a new science, recognising its own metaphorical nature and its own limitations, can provide more meaning and significance to human likes than the old physics did.
The objectivity of time, space and matter expresses a fear of death, tries to capture a physical immortality for mankind, but Jones argues for a metaphor for life.
As parts of a whole Universe we could be said to be responsible for everything, for we are an active part of an active creation.
The only weakness in the book for me was Jones's lack of a theological base, for he frequently verged on theological matters.
The strengths lie in its readability, its practical freshness (he gives examples of how to see the metaphors of physics through simple exercises), and its gentle and humorous approach.
I suspect it will not make the impact of Capra's work.
But it should, for it speaks about science wisely.
Science as a point of view
Rationality, and relativism edited by M. Hollis and S. Lukes,Blackwell, pp 312, £6.50 
John Little
SCIENTIFIC investigation of other societies and other ages has increasingly come under attack from relativists claiming that other cultures, and even other scientific paradigms, can be understood only from within, and only in their own terms.
Thus they claim that modern Western science is but one of a galaxy of alternative explanatory schemes, and that what constitutes knowledge and reasoning is relative to norms defined by society.
Students of language have often concurred with Edward Sapir when he wrote, ‘The ‘real world’ is to a large extent unconsciously built upon the language habits of the group.
The worlds in which different societies live are distinct worlds, not merely the same world with different labels attached.’
Surprisingly, philosophers and historians of science have frequently agreed: Thomas Kuhn and Paul Feyerabend argue that different systems of thought are not mutually expressible, that scientists within different paradigms live in different worlds.
Scientific enterprise is undermined by the extreme forms of relativism.
If the world that science investigates is largely a social construction then the history of science may show change but it will not show progress.
This collection of 10 essays by sociologists, anthropologists and philosophers is part of the backlash against these relativist views (represented in the beginning of this volume by Barry Barnes and David Bloor and, to a  lesser extent, by Ian Hacking).
Several authors portray the threat in vivid language.
‘A spectre haunts human thought: relativism,’ begins Ernest Gellner.
‘If relativism held with regard to reason…this would be a victory for the Kingdom of Darkness,’ writes W. Newton-Smith.
One weakness of Rationality and Relativism is that it is not always clear that the various authors interpret relativism in the same way.
Indeed, the editors identify five different forms in their introduction: moral, conceptual, perceptual, of truth and of reason.
But after the relativists' case is built up in the first two articles, no one has much to say for it, at least not the strong version that splits systems of thought into watertight compartments.
As several authors point out, the very fact that unequivocal translation evolves between any two communities in contact tells heavily against it (though if one extends the example to man/dolphin the issue becomes more cloudy, presumably because we have less in common with dolphins).
This is a book that will interest philosophers rather than scientifically minded laymen, who may become impatient with too much general discussion resting on too little reliable research.
Yet a careful reading of the various standpoints will give much food for thought.
The possibility that future generations will read our textbooks with about as much comprehension as we might scan a Renaissance text on the cabbala is rather unnerving.
The relativist often sets up standards of mutual understanding which are unrealistically high, and when we fail to reach them claims that understanding is impossible.
Their opponents often concentrate on showing that we can reach agreement on basic propositions and neglect the very real difficulties of gaining deep insight into alien ways of thought.
On the whole the authors avoid these sterile tactics and show an awareness of the strengths of the relativist position while arguing that it is mistaken.
What I looked for, but only occasionally glimpsed, was the recognition that, though differing frameworks of shared assumptions may be barriers to effective understanding, the rewards can be substantial — if not for what we learn about the alien systems then for what we may discover about our own previously unquestioned beliefs.
Such recognition could help temper the arrogance of some Western thinkers — an arrogance that goes a long way to explain why some have found relativism so attractive.
While not relaxing our critical standards and emphasis on observational success, it could open fresh possibilities.
As Francis Bacon, the patron saint of the scientific method, wrote four centuries ago, ‘The Universe is not to be narrowed down to the limits of our understanding — rather the understanding must be stretched and enlarged to take in the image of the Universe as it is discovered.’
Bridge between two cultures
The ‘scientific movement’ and Victorian literature by Tess Cosslett,Harvester, pp 188, £19.50 
Bernard Dixon
IT IS NOT difficult, as Dr Cosslett acknowledges, to see the values of Victorian literature as being at odds with those of science during the same period, Alfred, Lord Tennyson, for example, in his In Memoriam , portrays science as wanting to prove that we are ‘only cunning casts of clay’.
It is a view Tennyson firmly rejects:
Let Science prove we are, and then What matters science unto men, At least to me?
I would not stay.
Not only are examples of this sort easy to come by — in the works of Charles Dickens, Matthew Arnold, Thomas Carlyle and their contemporaries.
It has become standard practice to picture the two cultures as standing in the most acute  opposition at that time.
C. P. Snow may not have delineated the cultural divide until 1959; but commentators still return to Victorian England for the most potent illustrations of desiccated, materialistic science set against the life of the imagination.
Tess Cosslett decided to review the evidence afresh, and more closely.
Using contrary approaches — by examining the work of popularisers such as T. H. Huxley and John Tyndall, and by looking beyond the superficial, anti-scientific statements of imaginative writers — she has revealed an intellectual and emotional agreement far closer than we have been led to believe.
‘Scientific writers, novelists and poets,’ she insists at the outset, ‘can all be found putting forward similar views of humanity, society and nature, often by means of similar language and imagery,’
There is a hint of selectivity here, a suspicion that Cosslett's analysis may be as unrepresentative as that we have come to accept.
It is a suspicion which remains until the end of the book.
Nevertheless, the strength of her case is impressive.
The easier part to establish, of course, concerns the popularisers.
Huxley, Tyndall, W. K. Mifford, and Edward Clodd were indeed sensitive souls.
Re-reading them today one is reminded of what nonsense these individuals make of the bitter squabbles between Snow and F. R. Leavis nearly a century later.
It is when she focuses on novelists and poets that Cosslett faces a harder task, and she has had varying success with her four  principal figures.
The case for the scientific literacy and sympathy of George Eliot is well argued — but then it was familiar anyway.
On the other hand, the extent to which scientific ideas permeate George Meredith's poetry comes across with great force (and it is interesting to hear of Meredith attending a British Association meeting and siding with Huxley against Richard Owen over evolution).
Turning to Thomas Hardy,
Cosslett is far from convincing in her attempt to modify the view that Victorian science was a major element in Hardy's gloomy outlook on the Universe.
Her pleas that determinism need not imply hostility (’ it can instead call for cooperation’), and that the novelist was really both behind and ahead of his time in scientific terms, are scarcely compelling.
With her other major subject, however, Cosslett has new, persuasive things to say.
Tennyson is portrayed here as one who, despite his reservations about its temper, did understand science, and did not see it as antithetical to the sphere of imagination.
His attitudes towards nature Cosslett presents as very close to those of the popularisers —‘from a heroic facing of facts that seem to destroy his dearest dreams, to an imaginative perception of harmonious law and organic pattern pervading the constantly changing universe’.
A lecturer in English literature at the University of Lancaster, Tess Cosslett makes plain her motives in writing this book.
She has sought to highlight the positive ethical and aesthetic implications of Victorian science as they appear in literature (rather than looking for further ammunition for what she calls the sterile and artificial battle of literature against science).
And she has tried to defuse the threat which science undoubtedly can pose against creative writing.
The result is an adversarial but illuminating work which, though heavy going in places, should be compulsory reading for all students of English literature and all students of science.
The maths of ornaments and nautiloids
 Symmetry by Hermann Weyl,Princeton UP pp 168, £5.20 
Robert Dixon
SYMMETRY in border ornament and surface decoration is ancient history for artists, but it was not until the crystallographers started on three-dimensional lattices in the 19th century that the mathematics was fully analysed.
Hermann Weyl, in this classic essay originally published 30 years ago, shows us what that analysis looks like.
He surveys art, biology and physics with great skill to illustrate symmetry in its several forms — bilateral, translatory, rotational, ornamental and crystallographic.
He explains how the mathematical tools of congruence, transformation, invariance and groups are used to define symmetry and to classify its variety.
Why are there 17 (and no more) distinct groups of plane symmetry ‘with double infinite rapport’?
Weyl outlines the argument and moves on through seven spherical symmetries to the prospect of 230 crystal groups before coming to rest on thoughts of higher generality of principle.
As well as being visually inspired and scientifically informed, the book's main achievement is to review thoroughly the congruent symmetries.
Yet Weyl points us to ‘the underlying generality’.
There is a short detour to consider the inclusion of similarity, where Weyl finds symmetry in the chambered nautilus shell.
This is because the shell's spiral form remains invariant under the transformation of combined rotation and enlargement.
Does that stretch the common understanding of ‘symmetry’?.
Maybe.
So Weyl brings in the mathematical term ‘automorphism’ to denote any transformation that leaves a given figure invariant.
And then he halts, and (page 46) dismisses any further geometric possibilities beyond congruence and similarity.
This is a small but important point at which geometers and M. C. Escher do go further; as, for example, Escher's Sphere Surface with Fishes or his Circle Limit series.
Weyl would have been delighted.
Limited destruction? but intolerable
The illustrated history of World War Three by Dr John Bradley,Windward, pp 256, £8.95 
Brian Beckett
FACED with increasing social and political unrest in Eastern Europe, a future Soviet government orders the military occupation of its Warsaw Pact partners.
But, for reasons John Bradley does not quite make clear, Moscow also gambles on a wider war by invading West Germany.
Briefly, this is Bradley's scenario for a limited Third World War.
By not using nuclear weapons and with repeated assurances via the hotline of limited goals and negotiable conquests, the Russians face the president of the United states with ‘ agonising decisions’ and he hesitates in making any nuclear commitment for several vital days.
But, seeing Germany overrun, he finally orders the use of Us tactical nuclear weapons if a political solution is not agreed rapidly.
The French president, fearful of a US-Soviet accord taking no account of Europe's interest, orders — in consultation with the leaders of West Germany relocated in Paris — a nuclear strike on Kiev.
An hour after the incineration of Kiev, Lyons disappears in a retaliatory barrage of SS-20 warheads.
Happily, the warring parties then draw back from the unthinkable, negotiate a satisfactory peace and agree to serious talks on arms reduction.
This is a plausible piece of future history but, contrary to General Georges Buis's introduction, it is not especially ‘inspiring’ in its ‘portrayal of national defence in all its majesty’.
The majority of The Illustrated History of World War Three usefully chronicles history and military technology since 1945 but its bias is occasionally all too obvious.
It is difficult, for example, to reconcile the book's purportedly serious intent with the childish descriptions of Russia's leaders as a ‘bunch of near-senile senior citizens’ and (repeatedly) the ‘gnomes of the Kremlin’in a lengthy afterword by Professor M. Dziewanowski of the University of Wisconsin.
Politically, Bradley argues Charles de Gaulle's case for the independent French deterrent and for the Paris-Bonn link as the real linchpin of European security.
Militarily, it suggests that, even ‘limited’ nuclear attacks designed to avoid global catastrophe inevitably involve intolerable levels of destruction.
As an exercise in thinking about the unthinkable, the point is a counter to the idea of ‘tactical’ nuclear war as a first step in the ladder of escalation but, equally, it might be like trying to avoid any unwanted delays in Russian roulette by starting with a fully loaded gun.
Chemistry in the fatherland
The formation of the German chemical community (1720–95) by Karl Hufbauer,California UP, pp 312, £30 
Peter Austerfield
HITHERTO historians of Chemistry have paid little attention to German developments.
But Karl Hufbauer has provided a thoughtful analysis of how, before Germany was unified and chemistry professionalised in the 19th century, German chemists had already coalesced into a national, discipline-orientated community.
How this community developed along the intensely nationalistic lines it did and the subsequent crisis resulting from the clash of ‘German’ chemistry with the revolutionary ‘French’chemistry, forms the main thrust of this excellent book.
But wider issues are at stake.
Drawing on Thomas Kuhn's interpretation of scientific revolutions, Hufbauer shows how extra scientific factors, such as group identity, can influence change.
Using the debates between German chemists who supported or rejected the new chemistry, he paints a convincing picture to support and amplify Kuhn's views.
From a wealth of evidence the author shows that as powerful, influential and educated Germans embraced the values and beliefs of the Enlightenment, so they gave growing moral, material and manpower support to chemistry.
Based on G. E. Stahl's vigorous advocacy of a rational-utilitarian approach, an approach extolling the virtues of investigation and application, chemistry in Germany received particular favour as it lost its alchemical and other links.
Soon German chemists were becoming increasingly nationalistic and considered themselves superior to the ‘arrogant Italians French and English’.
Thus by the 1770s they were on the threshold of a national discipline-orientated community.
Effective communication nationally was the one factor missing, German chemists were not concentrated in a particular city, unlike their French counterparts in Paris, and thus a forum was needed.
This was amply provided by Lorenz Crell's Chemischehe Journal (later Chemisches Annalen)in 1778.
Above all else this journal gave solidarity to the community and promoted ‘German’ chemistry.
Crell in particular had no scruples about playing on his countrymen's cultural nationalism for the development of the fatherland's chemistry.
He maintained that an interest in chemistry was inborn in Germans, who also possessed a ‘cold-blooded spirit of research, slow but accurate reflection and unremitting patience’, which made the best chemists.
Crell's appeals to German nationalism and for chemists to ‘honour the fatherland’ produced the world's first successful chemical journal and firmly established the community.
A crisis occurred in the 1780s following publication of Antoine Lavoisier's anti-phlogistic system, dismissed initially by the community as a ‘passing French fad’ and something typical of the ‘flighty French’.
Cultural nationalism and the identity of the group influenced many German chemists to reject Lavoisier's theory.
The crisis did, however, complete the formation of the community by giving an awareness of social solidarity, German chemistry, based on the rival phlogiston theory (which had German origins) had to be defended.
How it was defended by those at the core of the community and how cracks began to appear at the periphery gives Hubauer the material to explore the hypothesis that extrinsic influences are likely to affect allegiances when scientists experience rival theories as incommensurable paradigms.
He presents a convincing case.
Historians of chemistry and social historians will find the book stimulating, persuasively written and a valuable source of reference material.
The appendices alone account for about half of the book.
Hufbauer's pioneering approach deserves a wide readership.
Conservation begins at home
Garden life by Jennifer Owen,Chatto & Windus, pp 212, £8.95 
Michael Allaby
ECOLOGISTS have tended to despise gardens.
They contain too many introduced and often exotic, species to which, probably, indigenous fauna are unable to adapt.
Consequently, rich and colourful though they may appear, they are of little value as habitat.
Jennifer Owen proves them wrong.
For 10 years she has managed her garden, in the suburbs of Leicester, in ways that encourage wildlife.
As her photographs prove, the garden looks attractive and it contains most of the items a conventional garden is supposed to display.
There are well-kept paths, a trimmed lawn, vegetables, flowers, and fruit, but the flowers and vegetables are grown together in the same beds, the soil is never left bare, and many of the plants she encourages would be condemned as weeds by most gardeners.
At the same time she has monitored the population and kept meticulous records.
She describes the construction, siting and use of the Malaise, light and pitfall traps with which she has caught a total of more than 300 species of Lepidoptera, more then 90 species of hoverflies, 46 species of bees, 40 of wasps, and more than 500 species of ichneumonids, eight of which were previously unknown in
Britain and two were believed to be new to science.
The book tells the story of one year in the garden, with a chapter for each month.
These say little about gardening as such.
They will not help the reader to grow brighter flowers or bigger cabbages.
They contain Owen's thoughts about the wildlife she studies.
This leads to some repetition, but not enough to detract from the valuable information the book contains, not all of which will be familiar even to the keen naturalist, and some of the thoughts are challenging.
Owen believes, for example, that lepidopteran populations fluctuate so widely due to entirely natural causes that the use of pesticides had little effect on them — although it does affect ground predators.
It is said that private gardens occupy 3 per cent of the land surface of Britain.
Jennifer Owen argues convincingly that this amounts to a very significant area of habitat, she shows clearly and simply how it may be improved, and for the dedicated wildlife gardener she says enough to encourage an attempt at recording.
Garden Life could turn out to be the most valuable contribution to conservation we have seen for some time.
Figure it out
A book of numbers by John Grant Ashgrove. pp 248, £6.95 
David Langford
THIS BOOK is not what it seems.
‘Numbers’ implies sub-Martin Gardner gym exercises, or boring pastimes where you turn the calculator upside down, or the stark numerological idiocy best summarised as a load of old  cabbalas .
Though touching briefly on all three, the encyclopedic John Grant mainly offers a pleasant novelty — a mass of numerically arranged information.
It's an ordered random walk through associations and connotations of the integers 1 to 100 and selected ‘interesting’ numbers from 101 to 500 — also pi, 666 and, with distinct mathematical shakiness, infinity.
The ordinals perhaps yield too many entries for elements popes and US presidents; most choices, though, are eccentric and witty.
I cull, in the only possible order: the 10 subscribers to London's first telephone exchange, why golf courses have 18 holes, the 36 metre tower which rounds up Germany's highest mountain to a neat 3000 metres, the 47 teeth of the mosquito, the 79 men kissed non-platonically by an ‘average’ woman in the US prior to marriage, the 159 hack SF books written by Britain's R. L. Fanthorpe in 13 years, the 163 villages erased by Krakatoa, the 380 kg of Moon rock still unexamined thanks to Senator Proxmire's money-saving efforts…
‘Like buying a car and refusing to put petrol in it,’ is Grant's characteristic remark on the last.
In the jackdaw tradition of Isaac D'Israeli's Curiosities of Literature (1791–1823), this is a browser's book enlivened by an engaging personality, the unlikely juxtapositions of curios facts and an absence of ‘two cultures’ apartheid.
Good fun; a pity it lacks D'Israeli's thousands of pages.
Rescue bids for endangered communities
PROGRAMMES on development frequently suffer from overkill, being too long and too much for the well-intentioned, but reluctant to slay with the subject and not turn to something less troubling to the conscience.
The reason, I've often reflected, is that programme companies, not entirely untroubled by conscience, feel that the occasional, massive genuflection enables them to live in virtue for long periods.
Central's Village Earth series, which began with in the footsteps of the Incas (ITV, 7 March), bids fair to be an exception.
What it lacked in glossy technique it made up for in sincerity.
‘The footsteps of the Incas’ part of the title was probably intended as a ‘come-on’but that, I think, is fair enough.
The series focuses on the work of individuals working in remote cultures and in this programme the individual was a Cambridge mechanical engineer, Martin Ede, who is working in the Andean heights of Bolivia among the Aymaran Indians.
His immediate concern is to get them to help themselves but not to do it so successfully that the state will throw in its hand altogether.
We saw Ede working on the building of a dam which would improve the water supply by 900 per cent and thereby reduce the hunger and disease that lakes a toll of half the children up to five, The other side of his work is to build up grass-roots organisations so the campesinos can protect their rights.
The agencies funding the scheme — the UN's  Association International Service (London) and ASEC, an inter-church organisation pursuing social work — had been accused of political activity, Ede explained, but that was unavoidable: the problems were political.
The 1952 revolution had freed the campesinos from the slavery of the haciendas but the Western practice of dividing and sub-dividing land through the generations had been adopted.
This meant that in some cases people were now cultivating a single furrow on a field.
The agencies were encouraging agrarian cooperatives.
Nationally what was needed was not so much cash as a rational development programme with long-term perspectives.
One admired Martin Ede's stamina.
Judging by the enthusiasm of the men, women and children who all work on the dam and piped-water project, he has made a start.
Revolutions, as that now — spurned revolutionary Chairman Mao said, begin with the first step.
The film was produced and directed by David Wright.
The Open Door programme Jobs for the Boys?
(BBC2, 9 March) was a further demonstration that technique isn't everything: earnestness counts.
It was made by the Women's Engineering Society (WES) with the aid of the Community Programme Unit.
Only one in 500 engineers in the UK is a woman and progress is much slower than in the US where the percentage has grown from 0–2 in the 1960s, when the Civil Rights movement stirred, to 10 per cent and is growing apace.
Jobs for the Boys ? talked to women engineers in various disciplines.
All were happy in their work and, once in it, seem to find that men accept them quite well.
There was general agreement that the struggle began much earlier — in the schools — and that before O-level.
The WES has a network of proselytisers doing something about that, explaining what an engineer is to schoolgirls.
In general, as the Finniston report made clear, there is widespread public confusion about this.
Sir Monty himself appeared on the panel at the end of the programme, expressing his opinion that the status of engineers was an intrinsic part of the problem.
I've no doubt he is right and that the WES, on this showing, is doing a splendid job.
The nagging question recurring in my mind, to which no one paid attention, was where, oh where, are the jobs for boys and girls going to be?
FORUM
Monkey business in AIDS research
Nancy Heneson attended a workshop on animal ‘models’
Maybe Madison Avenue is too much with me, but a recent encounter with the National  Institutes of Health left me convinced that biomedical research like air  freshener and tapered nappies, creates markets to ensure its survival.
Tell people day and night that they are beasts if they allow baby's thighs to chafe, of that they will lose  their friends unless they banish cat-box odour from their homes, and they will soon believe it, if not consciously, then in the little compartment of the brain that controls buying habits.
Anxiety moves the product.
And when the product is animal research hysteria over a new human affliction can sometimes sell even the worst schlock.
Witness NIH's most recent workshop on animal ‘models’ for use in acquired immune-deficiency syndrome (AIDS).
All the ingredients needed to revivify an ailing research enterprise were on hand: a hefty portion of anxiety over an enigmatic public health problem, seasoned with a dash of desperation over coming cuts in the budgets of NIH's seven primate research centres.
Add a tablespoon of media and voila — the perfect setting for two of the centres to toot their horns by claiming discovery of an analogue to AIDS in monkeys.
This is great news because everyone knows there are lots of things one can do to animals in the name of medical progress that one can't ethically do to people.
For those unfamiliar with the latest manifestation of Sodom and Gomorrah stateside, AIDS is just what its name says: a collection of illnesses which invade the bodies of people whose immune systems can no longer cope.
It is characterised by one or more so-called ‘opportunistic’ infections-often including a serious form of pneumonia-which may be accompanied by Kaposi's  sarcoma — a rare cancer ranging in severity from relatively manageable skin lesions to major organ involvement.
Young, white, gay men with multiple sexual partners are the prime targets of AIDS, but Haitian immigrants to the US, intravenous drug users and transfused haemophiliacs have also exhibited the syndrome (New Scientist , 16 December, p 713).
As far as is known, AIDS began fulminating in the gay communities of New York City and San Francisco in the late 1970s.
No one know its cause, but current theories favour a viral agent transmitted in blood.
Whatever its origin, AIDS is scary: 1051 cases have been reported as of February 1983, and it would seem that as yet no one has recovered fully; from AIDS the current mortality rate is 40 per cent.
What, one might then ask, does a bunch of Taiwanese and rhesus macaque monkeys which lived and died in laboratory captivity have in common with sexually hyperactive, urban gay men with AIDS?
Precious little, it seemed from presentations by the New England and California regional primate centres, except that the immune responses of both men and monkeys were profoundly suppressed.
Sixteen Taiwanese macaques died from viral hepatitis and trench mouth; 27 rhesus macaques (all female) died at the California centre in 81–83 of diverse bacterial and viral infections.
None had Kaposi's sarcoma.
None showed the pattern of imbalance between two types of cells in the immune system which is characteristic of human AIDs.
Nor is there solid virological evidence to link human AIDs with what the researchers proudly called ‘Simian AIDS’.
Animals kept in captivity for biomedical research are stressed even under the most humane conditions.
When one takes monkeys evolved for tree-top living and puts them in gravel-floored cages on the ground where they are constantly exposed to faeces, when one mixes three species of macaque in one cage, as was done at the New England centre, the stress factors multiply.
Stress deranges the immune systems of human being and monkey alike.
But to say that an immune deficiency here and an immune deficiency there constitutes one or even two closely related diseases is like saying that apples explain oranges merely because both of them contain a number of pips.
Could it be that the bureaucrats of primate  research saw a way to parlay an admission of poor husbandry into a public relations campaign for the primate centres?
The California people even suggested that the four major outbreaks of infection in their monkey colonies over the past 14 years were due to AIDS.
Opportunism, it seems, is not limited to microbes.
Unfortunately for the promoters, however, the effort backfired.
Clinical experts in human AIDS at the meeting were sceptical.
The US Center for Disease Control, with a task force of several hundred working on AIDS, was unimpressed.
Even the speaker who was to tie the whole thing together admitted that the monkey data would be put to better use in various studies on the general subject of immunoregulation.
Maybe scientists, unlike Mr and Mrs America, can see through false advertising.
I hope so, because more meetings on the order of this NIH dog and pony show can only hurt the cause of good biomedical research.
The US animal rights movement has not sunk to the level of sending letter bombs to government officials.
On the contrary, it is becoming politically more savvy and more persuasive all the time.
On 24 April, 100 animal rights groups plan to stage protest marches at four of the NIH's primate centres.
The animal research establishment would do well to get its own house in order instead of parading its failures before a public that still wants to believe in salvation through medical science.
Lack of fibre?
THE DEPARTMENT of Industry recently risked rebuff and organised a teach-in for the press on fibre-optic technology.
There would be no hard news, said the DoI, but if we were interested in learning the background it would bring together some experts on fibre optics to brief us on this new technology.
The DoI invited everyone on its list of journalists who is interested in information technology, a total of 250.
The teach-in organisers reckoned that if a dozen people turned up it would be worthwhile.
But 70 people said yes they would like to come.
Of these over 50 actually turned up to be educated.
This, the DoI press office ruefully admits, is a better turn out than it normally-gets for a major announcement on government policy by a senior minister.
Significantly, the journalists who couldn't find time to come, were those Fleet Street hacks with famous names who write most noisily on the pros and cons of optic fibre for the cabling of Britain.
Intellectual ferment
THOSE of our readers who drop into a branch of W. H. Smith's to pick up their copy of New Scientist may not have realised what hotbeds of intellectual ferment these unassuming stores can be.
For their benefit, we offer the following dialogue between two Smith's assistants, overheard recently during a slack sales period.
‘I don't think they should do it, these Greenham Common women.
Not being women, I mean.’
‘Why not?
They had a debate about it at Oxford or Cambridge recently and they thought it was alright.’
— Well, they would, wouldn't they, if they come from Cambridge.’
‘What do you mean?’
‘Well, they're all scientists at Cambridge.
They've got their jobs to think about.’
‘I didn't know they were all scientists.
I thought some of them were Greeks .’
‘No, I'm sure they're all scientists.’
‘Well, I thought they taught Greek as well.’
‘The headmaster of my old school was from Cambridge.
He was a scientist.
He had an MSc.’
‘Oh, that doesn't mean anything.
You can buy those at Cambridge.’
Sugar daddy
Martin Sherwood looks at the life of Sir Norman Haworth, the first British organic chemist to win Nobel prize
CARBOHYDRATES are a major class of natural substances, ranging from the simple sugars, such as glucose and fructose, to ‘macro-molecules’, such as starch and cellulose.
The unravelling of their chemistry has been one of the great achievements of 20th century science, a large part of it due to sir Norman Haworth, whose studies in this field spanned more than 30 years.
Haworth's introduction to chemistry came through the linoleum factory in Chorley, Lancashire, which his father managed.
The young Haworth left school at 14 to work in the factory and was required to pick up a knowledge of dyestuffs.
From this, he decided that he wanted to study chemistry formally and, in 1903, went to Manchester University, where the head of chemistry was William Henry Perkin jr, whose father had discovered mauveine, the earliest synthetic dye.
Although Haworth had intended to make a career in the chemical industry, he won a scholarship which enabled him to go to Gottingen for postgraduate work.
Here he studied under Otto Wallach, who was opening up the chemistry of terpenes natural products important as flavours and fragrances.
On his return to Britain, Haworth took up academic appointments, first at Imperial College, London, then at the University of St Andrews, Scotland.
He continued to study terpenes for a while but, under Thomas Purdie and James Irvine, who had established a strong school of carbohydrate research at St Andrews, he switched to this field.
Although he produced valuable results at St Andrews, his major contributions did not come until later, as half the time he spent there coincided with the First World War, when the laboratories were turned over to the production of pharmaceuticals and fine chemicals.
In 1920, Howarth moved to what is now the University of Newcastle upon Tyne and then, in 1925, to the University of Birmingham, where he spent the remainder of his career.
An important study Haworth made was on how the disaccharides — compounds, including table sugar, made up from two basic carbohydrate units — are linked together.
Monosaccharides carry several hydroxyl groups (OH) and, when a disaccharide is formed, two of these link together with the loss of the elements of water.
Haworth's basic method was to modify chemically the unreacted hydroxyl groups in a disaccharide and then hydrolyse it and identify the reaction products.
Haworth's major work, ‘The constitution of sugars’, was published in 1929.
By this time, he had put forward the idea that cellulose is a long-chain molecule composed of repeating saccharide units and that starch, also a macro-molecule, is made up from branched chains.
He had also put forward basic structural ideas about the monosaccharides, suggesting the five and six-membered ring structures, furanosides and pyranosides which are still sometimes referred to as Haworth formulae and appear in every organic chemistry text today.
Haworth was the first British organic chemist to receive the Nobel prize.
His citation was for his work on carbohydrates and on the synthesis of vitamin C. This, the first synthesis of a vitamin, he achieved in 1933, in collaboration with E. L. Hirst.
Albert Szent-Gyorgi had isolated ‘hexuronic acid’ a few years earlier from oranges and the adrenal cortex.
Haworth and his colleagues managed to obtain larger quantities from Hungarian paprika, from which they established its sugar-like structure and completed the synthesis.
Subsequently, he achieved a modified synthesis of the vitamin, which he had renamed ascorbic acid.
This became the basis for its industrial production.
During the second World War, Haworth took a completely different scientific route, working on the purification of uranium metal.
He subsequently became chairman of the panel which oversaw chemical aspects of the atomic programme and, after the war, chairman of the Chemical Research Board of the Department of Scientific and Industrial Research — the forerunner of today's Science and Engineering Research Council.
Time machine found — nearly
ASTRONOMERS excited by the discovery of the so-called ‘millisecond pulsar’(New Scientist , vol 96, p 562) seem to have missed one potentially important feature of the beast.
It bears a remarkable resemblance to the kind of natural time machine postulated by Frank Tipler, of the University of Texas.
Remember Tipler?
He is the mathematician who says that intelligent life in the Universe does not exist, because if it did we would be knee deep in space probes by now.
Before that he caused a few raised eyebrows among physicists and astronomers with his calculations that a working time machine could be built, or arise naturally, within the framework of relativity theory.
Tipler's description of a working time machine is a cylinder with the density of a neutron star, 100 km long and 10 km in radius, rotation twice every millisecond (New Scientist , vol. 87, p 654), superficially, such an object would be a lot like a fast pulsar, since pulsars are thought to be rotation neutron stars, but the fastest pulsar known when Tipler made his calculations was the Crab pulsar, with a period of 30 milliseconds.
The ‘milliseconds’ pulsar actually spins once every 1½ milliseconds, tantalisingly close to Tipler's limit.
If a 1½-millisecond pulsar exists, why not a ½-millisecond pulsar?
Such an object, dragging spacetime around with it, would scramble space and time up and make time travel a reality.
Either that, or Einstein's theory of relativity is wrong, so maybe the fast pulsar deserves even more attention than it is getting.
John Gribbin
A dose of bad medicine
Tam Dalyell believes drug substitution to be against the national interest
THE SCENE: A motor car showroom.
Customer: ‘salesman, I want a high quality Rover, coloured brown.’
Salesman: ‘sorry, guv, you'll have to take a black Datsun because it does the same job, and is cheaper!’
Greenfield is becoming the unlikely code-name for a highly explosive political issue.
Patrick Jenkin, currently Secretary of State for Industry, set up, during his previous incarnation as Secretary of Health and Social Services, an informal working group of 11 doctors chaired by a Principal Medical Officer of the Department of Health and Social security (DHSS), to consider ‘Effective Prescribing’.
The Greenfield committee, so named after its eminent chairman Dr James Greenfield prescribed 14 doses of medicine for an ailing National Health Service (NHS).
As often happens with well-intentioned parliamentary remedies, the foul taste of one of Greenfield's doses of medicine obscured all the others.
The bitter pill of generic substitution was leaked to the press, and created a totally unwanted side effect: an unholy row.
Temperatures ran high inside and out of parliament.
To explain just why, you will have to bear with me while I explain about the naming of modern medical potions.
Pharmaceutical products generally carry two names.
First, a brand name, which is really the manufacturer's trade mark.
The second is the chemical or generic name.
For example, ICI invented a new class of heart drug, the beta blockers.
It was given the trade mark, ‘Indral’ and the generic, or chemical name, propranolol.
If your doctor writes on your prescription, ‘propranolol’, it means your chemist can supply any form of this pharmaceutical product.
Either your doctor does not mind, or is unconcerned that there are other versions other than that of the inventor, in this case ICI.
Under a system of ‘generic substitution’, even if your doctor wrote Inderal your chemist would be obliged to provide you with the cheapest form of that product, irrespective of the manufacturer, irrespective of the country of origin.
Unless your doctor were to go to the additional trouble of writing on the prescription that he meant exactly what he had written, and was forbidding the chemist to substitute, you would get the cheapest product.
It's rather like the scene that I penned at the beginning of this column.
Now I must agree that the recommendation for generic substitution would provide savings for our poor  beleaguered NHS.
The DHSS estimates that it could save something around £30 million.
The Guardian , in its wisdom, plucks out of the blue a figure of £200 million.
Any savings, though, would be at a huge cost to the British pharmaceutical industry and companies such as Beecham, Boots, Fisons, Glaxo, ICI and Wellcome.
The effect would be to damage those companies with a strong research base, some of their products would be replaced by imports from Eastern Europe, Italy and the Far East — cheaper because they come from companies that do not support expensive R&D and a continuing technical back-up for their products.
Nowadays, from concept to production, the expenditure on research for a new drug can cost a cool £50 million.
For 20 years the company owes the patent rights on its production.
Yet over the past two decades the period of development, of safety testing, and of approval, has risen from 3 or 4 years, to something like 10 years.
Thus nowadays a company may have less than a decade in which to recoup its investment.
If a scheme for generic substitution were to go ahead, the loss to British companies would not be limited to the so-called ‘savings’ to the NHS, but the entire amount of the sales of such products.
Why?
Most countries have some form of price regulation for pharmaceuticals, and, of course, prices are linked internationally.
A reduction of prices in Britain, as with OPEC, would have to be followed worldwide.
The major British pharmaceutical companies are large exporters.
Around 15 per cent goes to the home market and 85 per cent abroad.
To push down the British price to that of the cheapest one quoted by any ‘fly-by-night’ would have a catastrophic effect on business worldwide.
Any so-called ‘saving’ to the NHS of products manufactured by British companies would have to be paid for five fold by the British companies, and would show up five fold in our balance of payments, and would mean significant loss in taxation to the British Treasury.
Last year, our pharmaceutical industry contributed more than £600 million to our balance of payments.
The drug companies are not simply ‘crying wolf’ when they say their success in high technology will be jeopardised if the Greenfield recommendation for generic substitution are enforced.
One has only to look across the Atlantic to Canada, where similar government policies shattered a once-successful Canadian pharmaceuticals industry.
Most drug research in that country has ground to a halt, and Canada is now a substantial net importer of medicines.
It would be an additional folly to impose generic substitution at a time when the Japanese government has singled out pharmaceuticals as a significant area for growth and one to which high technology is applicable.
Tokyo is encouraging Japanese companies to increase their research and to move out of Japan into Europe and the United States.
The parallels with the car industry are obvious.
What is the point of exhorting British firms to move into biotechnology, if measures are taken that will damage our successful pharmaceuticals industry?
It is an industry which even in times of recession has kept most of its 70 000 employees and taken on a welcome and regular flow of new recruits.
Perhaps the right hand, in the shape of Kenneth Baker, does not know what the left-hand, in the shape of the present health minister, Norman Fowler is up to?
We in Britain are not extravagant consumers of medicines.
We have a per capita consumption 25 per cent below that of the Swedes and the  Argentinians , 30 per cent below the Americans, 40 per cent below the Belgians and Swiss, and 50 per cent below the French, Germans and Japanese.
I say to ministers: put this particular bottle of ineffective medicine in the cupboard and forget about it.
Seeing silver stars
Heather Couper recalls the early days of London's Planetarium
MANY HAPPY returns to the London Planetarium — 25 years old this weekend.
Most of us are used to the familiar Baker Street landmark now, its squat green (copper) dome topped with a disconcertingly transparent Saturn in the place of a weather vane.
But how many can remember the feverish excitement when it first opened?
There had been nothing like it in the UK before.
It was mysterious, powerful, expensive — to an eight-year-old like myself, all part of the optimistic brave new world of big science.
As an aggressive, grubby schoolkid and a keen stargazer, I was desperate to be the first to go.
Circumstances dictated that I had to wait nearly two years (how did I survive?).
But that first visit confirmed me in my lifetime's obsession.
There was that sudden, breathtaking chill of cold, clean air as you walked into the dome.
The eggshell-blue sky — the colour of the end of a perfect day.
And incongruously, the great Zeiss star projector, rising Aphrodite-like from the waves of blue carpet, making stars, planets and galaxies spin timelessly around.
The public shows were given by live lecturers then, and to the eager young enthusiast — my opinion of myself, perhaps not shared by others — it was a glorious opportunity to be able to confront a real astronomer afterwards.
Poor Henry King, faced with an oversized 10-year-old demanding ‘Has eta Carinae varied recently?’
Times, of course, have changed.
The London Planetarium no longer strikes one with quite the same sense of awe, because planetariums are no longer new.
Today, uniformed warders break that first ethereal stillness with their peremptory warnings about smoking and taking pictures.
The public shows are taped.
Most evenings the dome reverberates to a double onslaught of the sound of heavy rock coupled with a laser lightshow.
But the London Planetarium has not lost its heart.
There are live presentations, to fire the enthusiasm of the thousands of schoolchildren who visit every morning throughout the year.
It acknowledges its position as a London Landmark (and one of the top 10 London tourist attractions) in hosting dozens of product launches, promoting goods ranging from books, colour transparencies and magazines to washing machines.
Critics may argue that it has not moved enough with the times, is not as up-to-date in its special effects as its counterparts across the Atlantic, but this perhaps highlights its attraction.
Under the urban direction of Radio 4 broadcaster John Ebdon — he of the ‘distinctive dark-brown voice’ according, that is, to the planetarium's press handout — the London Planetarium is very much a peculiarly British institution.
It shares a lot in common with Patrick Moore's long-running Sky at Night series, which celebrated its silver jubilee last year.
Both institutions — for what else is the Patrick Moore show?— have their roots in the tradition of the Victorian gentleman amateur scientist.
As a result, the London Planetarium remains approachable, fallible and human.
John Ebdon has always made much of astronomy's links with the past, culminating in 1980 with the opening of The Astronomers gallery — which tells the story of the subject in light and sound through the achievements of five famous astronomers.
To celebrate its silver jubilee, the Planetarium is putting on The Silver Star Show throughout 1983.
Get along if you can — watch a night pass in six minutes, go back to prehistory, or forward to the skies of the 1990s.
Above all, just enjoy the show.
There may be many planetariums in the world but the London Planetarium is still unique.
Your kids will tell you.
Open verdict
Barry Fox wakes up to morning television
ALTHOUGH YOU wouldn't think it if you watched it, TV-AM, the  commercial breakfast television station, started off with grand plans to offer viewers a little science with their cornflakes.
This idea was scuppered even before TV-AM went on the air with the flippant Frost formula which has proved so disastrous.
Only 300 000 people watch TV-AM compared with 1.6 million who tune into the BBC's rival show.
This also offers precious little science.
But people who have rigged up a television in their bedroom or kitchen, to watch the much-advertised breakfast TV shows are finding that some programmes that are quietly transmitted on BBC2 every morning at the same time are often far more interesting.
Each morning at around 6 am the BBC opens up with an uninterrupted series of Open University films.
Although these are intended to complement written work, they almost always stand up in their own right.
Half the fun of viewing them is that subjects come up at random.
A film on statistical analysis will follow one on blood clotting.
Then there's something on Newton's laws of motion and the Voyager mission, a fascinating insight into Victorian physics and a reminder of long forgotten sixth form electronics.
Obviously plenty of people find it more interesting than anything breakfast TV has to offer.
Since mid-January, the Open University's information service at Milton Keynes has been astonished to  receive a record 1711 letters from people who are not OU students but who want to know more about the schedules for OU transmissions.
A case for formentation
IF YOU ARE sufficiently distinguished you may well be lucky enough to be invited to address the prestige conference Advances in Fermentation ‘83 to be held in September.
You may well be asked by the conference director, Norman T. Shepherd to submit a synopsis.
If this is approved, the invitation would well be followed by a firm brief to produce a paper that could, at the BBC approved rate of reading, last anything from seven minutes to a little over an hour, at your discretion.
If then your paper proves suitable you will be told that to register for Advances in Fermentation ‘83, organised by Process Biochemistry, Penn House, Rickmansworth, Herts WD3 1SN would normally cost £152.
But as a speaker you will be asked to pay only £100.
Isn't that nice.
LETTERS
Leaden loyalties
I am glad to see from your report of the psychiatrist Professor Michael Rutter's lecture at the Royal Institution that despite his former membership of the Lawther Working Party on lead pollution, Rutter now acknowledges that the hazard from lead in petrol is so serious as to require a total ban (This Week, 3 March, p 567).
But I am puzzled by his apparent need to combine such praiseworthy recantation with a personal attack on myself, while elsewhere in his lecture piously deploring the introduction of personalities into the debate.
For the hazard he now claims to recognise is essentially that which several of us have been patiently trying to explain to psychiatrists and others for the past twelve years or so and one which is now officially acknowledged in several overseas countries.
No matter.
I salute him for having the courage to come off the fence; though he leaves many of his colleagues still perching there.
For the record, Rutter and I now appear to be essentially in agreement on the lead-in-petrol hazard, and in accepting that the effects of lead on children's intelligence is real.
We continue to differ on two aspects.
First, Rutter regards as comparatively small the reductions of two to seven points in IQ now being associated with lead pollution, whereas I view such effects as extremely serious when they are suffered by a major proportion of a whole generation of urban children.
Rutter himself had earlier pointed out that a drop of only five points in the mean IQ of a population, with unchanged distribution, will double the number of mentally retarded children having an IQ less than 70.1.
In fact, the numbers of educationally subnormal children in special schools in England and Wales increased progressively from about 18 000 in 1950 to over 107 000 in 1979.
Nobody suggests that this is all due to lead, but I am not aware that either Rutter or anybody else has provided any convincing alternative explanation for the phenomenon.
If, say, measles had shown such an increase, we should now be talking about a major epidemic.
Secondly, Rutter evidently holds that any  behavioural effects of lead are irrelevant to social phenomena, eg juvenile delinquency.
In this, one recognises that he is trying to defend the questionable but deeply entrenched politico-sociological dogma that social phenomena result only from social causes.
Thus he sought in his lecture to ridicule the suggestion made by Waldron and myself in 1974 that detoxification with penicillamine might be a useful alternative to prison (itself almost wholly useless) in the management of those types of offender exhibiting the hyperactivity syndrome.
In any case, Rutter's ridicule seems a grotesquely inappropriate response to our constructive and it now seems, prescient, suggestion made some six years before he first presented his own distinguished views on the subject of lead pollution.
 Professor Derek Bryce-Smith Department of Chemistry University of Reading 
Nuclear nuances
In his article reporting on the recent declassification publication of Dr Hans Bethe's 1954 article on the  development of the Super, Professor P. V. Danckwerts cites my book J Robert Oppenheimer — Shatterer of Worlds , as the trigger for the publication (Forum, 17 February, p 471).
He reports Bethe as considering the book to be misleading in its account of the development of the Super.
Bethe's article represents an invaluable first hand account of the crucial years in the development of the Super.
It is particularly interesting in the way that it counters the widely held view that Los Alamos was dragging its feet over the development of the Super even after the presidential directive in early 1950 for a crash programme towards producing a hydrogen weapon.
It also throws new and interesting light on the real needs for establishing the Livermore Laboratory for Dr Edward Teller.
However, it is only in these areas that I can perceive any major divergence in my account and Bethe's.
Both accounts demonstrate that, until Stanislav Ulam's observation that X-rays could be used to propagate an instant fusion reaction, Teller had been working on a fundamentally impractical design.
Both accounts also demonstrate that as soon as this new configuration was established, Oppenheimer described it as ‘technically so sweet’, and it was translated into practical terms in under two years, for the November 1952 ‘MIKE’ test.
 Peter Goodchild London W14 
Reprocessing cheap but not free
In their article ‘Britain is set to abandon nuclear reprocessing’(This Week, p 567, 3 March), Fred Pearce and Roger Milne have lent my words a meaning more than they will bear.
I know of no plans by the British nuclear industry to abandon reprocessing or to store fuel for 100 years.
As the article correctly acknowledges, generally magnox fuel must be reprocessed within a few years of discharge from a reactor, from an advanced gas-cooled reactor (AGR), fuel may be stored underwater for somewhat longer periods and for much longer in a dry store.
It is, however, still the CEGB's intention to reprocess early AGR fuel arisings in thermal oxide reprocessing plant (THORP) and the Board has reserved capacity in that plant.
The Board has taken no decisions about the timing of the reprocessing of subsequent arisings of AGR fuel or of PWR fuel.
The latter type of fuel lends itself to underwater storage for several decades.
Reprocessing of these later arisings of AGR and pressurised water reactor (PWR) fuel will have to be undertaken in plants that will succeed THORP.
The point of my remarks was to indicate that the longer timescale on which it is technically feasible to store AGR- and PWR irradiated fuels before reprocessing provides the CEGB with a flexibility not available in the case of magnox fuel.
This flexibility suggests that extrapolation of recent increases in the reprocessing costs for magnox fuel to the nuclear fuel cycle costs for AGR and PWR is unjustified.
As a consequence of the technical complexities of reprocessing highly irradiated oxide fuel from AGR and PWR, the Board expects to pay more for the reprocessing of a tonne of these fuels than a tonne of magnox fuel.
However, it must be remembered that each tonne of AGR or PWR fuel produces much more electricity (AGR it least five times, PWR at least 7 times) than a tonne of magnox Fuel This will result in the reprocessing component of the nuclear fuel cycle cost being less for AGR and PWR than for magnox.
John Baker Central Electricity Generating  Board  
life after robots
Joe Engelberger may seem ‘a real fun guy’ to John Bell, bursting with zest for life, but to me he is a typical example of technocratic ‘pace-setters’, imbued with the virtues of dynamism, expertise and unlimited ambition.
(’ We'll have robots like ladies have hats’, 24 February, p 528).
His motto seems to be ‘what is good for me, must be good for everybody else too’.
It is all very well reading Isaac Asimov and making robots that cut the grass, play ping-pong with the children or slave in households.
Somehow he thinks it remote from morality to face the facts; somehow he thinks it possible to be good without being wise.
Namely, he should try to answer some hard questions, one of them being formulated by Arthur C. Clarke himself: ‘The question is not what shall we do without work — but what do we live for?’
Or, have shorter working hours and more leisure time brought by the automation resulted in having more composers, writers painters, poets, sculptors, philosophers?
And what has brought increased affluence?
The best example is California — the shift of population from the countryside to the cities meant more cars, more houses where orchards used to be, less clean air, fewer clean lakes and rivers, etc.
First, it was the gradual transformation of woodlands and grasslands into farmland, and then years later building it up to accommodate the ever-growing influx of people.
In the last decade alone there has been something of a holocaust of the scarcest of our earthly resources, natural beauty.
Perhaps Engelberger's idea of the paradise on Earth is robots to substitute for human teachers, hospital nurses, and doctors.
While office staff and skilled workers are being automated into obsolescence, and executives replaced by decision-making machines, game-playing robots are rendering human partners unnecessary.
Parents will become superfluous, the robots will nurse and play with children.
We cannot be far from the day of the conversation robot that will relieve us of obligation to greet politely the occasional recognisable human that strays across our path.
 Igor Fodor  Darmstadt  West Germany 
Alcoholic hypnosis
Gail Vines and Michael Barnes refer in their article ‘Hypnosis on trial’(6 January, p 12) to an experiment by J. Stalnaker and E. Riddle in the 1930s in which  hypnotised subjects could blithely recite the Longfellow poem The Village Smith , confidently inserting their own words for forgotten lines or verses.
Sometimes at parties, I am able to recite the Cremation of Sam McGee or the Shooting of Dan McGrew , but only after being adequately ‘hypnotised’ with rum or kindred spirits.
In the cold light of day, my inhibitions would prevent these performances and without hypnotic effects of refreshing liquids I could not put together the  necessary words, my own and those of Robert Service, in an intelligible manner.
Is there scope for further research here?
 Webster Anderson Toronto Ontario 
Sizewell Cancer
Dr John Bonnell of the Central Electricity Generating Board would find the third cancer death at Sizewell less’ difficult to explain- (This Week, 24 February, p 509) if he consulted Dr Alice Stewart or Dr Broso.
We have been trying to din into the heads of the electricity boards an inkling that different people are susceptible to different levels of radiation exposure and that there is no safe level.
Maybe they will start to listen as more cases like Tony Adams's are documented.
International  Commission on  Radiological Protection standards must be raised not lowered.
 Linda McHenry Scottish Consumer Campaign, Edinburgh 
Physics Olympiad
Entries are now invited for the 15th Olympiad which will take place in July 1984.
To avoid clashes with A levels,first year sixth formers as well as those who are between school and university ought to consider entering.
It is worth mentioning that the final is not so theoretical as perhaps believed: 40 per cent of the marks are allocated in the practical paper.
 W. H. Jarvis Salewheel House Salesbury Road Preston PR3 3XU 
In Bernard Dixon's profile of Arthur Koestler (Forum.
10 March, p 675) a sentence in the fifth paragraph should have read: ‘Far better, surely, to be remembered as one who spawned a wealth of speculations which were constructive and exciting.’
ARIADNE
A NEWSPAPER removed from the back of a drawer proved to be dated 2 August, 1897.
It was The Echo a name that is slightly bogus to me, like the names of newspapers that people work for in fiction, such as The Megaphone, The Clarion , or The Bugle .
The copy was brittle and filthy, but, carefully unfolded, showed, to begin with, that the Great Game was well afoot.
News from the Indian frontier included a report that Chakdara had been relieved and that a fresh attack had been made by natives at Malakand.
Colonel Lamb's wound was above the knee, the report said, though it was feared that he might lose the leg.
But the issue was fascinating because of other things, heralding the rapid development of technology in the next century.
Mr Balfour had ridden on a motor car from Downing Street to the House of Commons, the start being witnessed by several members of the government.
America had, said the paper, just launched a new submarine torpedo boat, declared (by the Americans, I hope)‘to be the most unique vessel of that character ever invented’.
The vessel was built like a fish and its mouth could be made to protrude from the water.
‘Then…she may be fed her COMPLEMENT OF THREE TORPEDOES…’
Under a black layer of grime was another report of a visit to London of Signor Marconi, ‘the inventor of the system of telegraphy by which messages can be transmitted over a considerable distance without wires’.
The Echo managed to get an interview.
‘Will the invention supplant the ordinary telegraph?’
‘I do not think so, at least not for the present.
That was not intended…a message can be carried without wires I believe 20 or 30 miles.
I have not done this as yet, but I hope to…
I may possibly be able to greatly increase that distance but of that I cannot speak with certainty.’
CURIOUSLY,The Echo also struck a modern note.
It carried a short item about the Social Democrats in annual conference at Northampton.
A resolution had been tabled urging cooperation with the trade unions, while insisting that in the socialisation of the means of production, distribution and exchange lay the only hope of permanently bettering the means of the wage-earning classes.
Daedalus
They are catching up on Daedalus and he will have to go into strict training for a swifter sprint.
Hardly, as they say, was the printing ink dry on his description of inhalable foam with the added attraction of sensuous delights (in the privacy of your own foam) than an American firm announced its latest product.
The firm is described as a leading developer of top-secret weaponry.
It has been developing away on a polymer foam that is intended to fill an entire building ‘from floor to ceiling’ in a few seconds after an alarm is tripped.
Anyone in the building can breathe and move but is unable to see any thing, so the theory is that he wanders clueless in a cloud until the security-squad charges in with a chemical that breaks the foam up.
Uses for the foam or suggested ones, are for keeping bank vaults safe and for applying pesticides to crops without polluting the air, I do not see it catching on.
Drenching even a few rooms, with foam and then a chemical spray seems to me a high penalty for catching what American police forces call a perpetrator.
THE POETs are right, I tell you.
A day or two ago I was passing a garage.
Out from behind a petrol pump appeared a figure that was female, though it took a few seconds to realise it.
It wore an oil-stained wool cap over straggly grey hair.
The face was weatherbeaten and a small cigarette hung in the corner of the mouth.
A trail of ash led down to a ragged, greasy jacket, buttoned with extreme strain over two pullovers which reached to just above the knee of oiled and dusty denims.
A man advanced across the road.
‘Hello, petal,’ he said.
IT IS not every day, at my age, that I am asked to go into a dark cupboard with a man, so I was both flattered and cautious on doing so.
It was all harmless.
I was being asked to watch the peppermint effect.
This strange behaviour of peppermints had been observed by my friend while waiting in his car at night.
Nothing on the radio attracted him so, as a measure against boredom he took out one of the hard mints he always carries and, being a far from self-indulgent character he broke the mint sharply in half intending to eat it slowly.
It produced a tiny blue flash.
At first he thought that the flash of light had been something to do with a passing car, possibly a reflection.
But cracking another one in half when there were no cars about, he got another blue flash.
Since then he has spent, in total, several hours in persuading people to climb into cupboards, clamber into lofts and crawl under stairs and watch carefully as he breaks peppermints in the gloom.
The mints must be hard and dry for the best results and some produce, as I have seen, impressive flashes.
The effect is so fascinating that my friend has pockets full of peppermint bits and a sizable bill for Polo and Trebor, the mints that give the best results.
As far as he knows, only peppermints flash and only the hard, white kind.
The question is what causes the flash?
He scorned the theory that it was a static charge leaping across the gap and is more inclined to the view that somehow mechanical energy is being converted to light.
I know that I am providing an unusual excuse for those dastards interested in luring some member of the opposite sex into a dark and confined space, but I would be glad to hear about experimental results.
WOOD is one of the most elegant and efficient of constructional materials, but it is a fast-vanishing resource.
Seeking to economise its use, Daedalus reflected that most wooden structures are limited not by the strength of wood, but by its stiffness.
For structures which essentially have to support only their own weight, a much lighter and stiffer form of wood could prove advantageous.
In this connection Daedalus recalls the process of ‘popping’ popcorn and ‘puffing’wheat.
These plant grains are heated under pressure till their water-content has turned to high-pressure steam.
When the external pressure is suddenly released, the cell structure is forcibly expanded by the entrapped steam into an open porous matrix.
So DREADCO chemical engineers are trying the process out on wood.
Planks and logs are being saturated, not with water but with aqueous solutions of heat-setting resins.
The saturated planks are autoclaved under pressure; as their internal water boils to compressed steam, the resin is deposited around the fibres of the wood.
Then the sample is explosively decompressed.
The wood fibres are blown apart, but remain glued together at many individual points by the set resin, or connected by viscous strings of it if it has not quite set.
The result will be a wonderful new ‘puffed wood’.
Puffed wood should be mainly expanded across the grain.
The fibres will not lengthen much, but will spread apart laterally.
The new material will have the lightness and rigidity of expanded polystyrene, but with much of the fibrous strength of wood, especially as it is internally resin-reinforced.
The resin will make it rot-proof too, and it will also be a splendid thermal insulator.
It should revolutionise the housing and furniture industries as well as boat building.
Light, insulating, economical puffed-wood structures, using only 10 per cent by weight of the wood previously needed, will spring up everywhere.
It may even be possible to make neat little ‘scale-model’ houses from normal wood, transport them cheaply around the country, and then ‘puff’them up to final size on site.