

18
TRANSITION TO TURBULENCE IN SHEAR FLOWS
18.1 Introduction
All shear flows become turbulent at high enough Reynolds number.
Linear stability theory can indicate when a laminar shear flow must undergo transition to some other type of motion, and the example of its application to a boundary layer was discussed in Section 17.7.
However, as was pointed out there, the waves predicted by such theory are only the first stage of the evolution towards turbulent motion.
What happens subsequently?
Our knowledge about this comes primarily from experimental investigations.
That is not to say that there are no theories, at least of some stages of the transition of some types of flow.
However, the way in which the theories relate to the overall transition sequence is generally to be understood only by reference to the experimental observations.
Discussion of this would lead us into great complexity and it is appropriate to give a largely phenomenological description.
Many of the experiments have used the vibrating ribbon (Section 17.7) or some similar mechanical or acoustic arrangement to introduce controlled disturbances.
Although this technique was originally introduced to investigate the relevance of linear stability theory, it has proved a useful way of controlling flow development and ensuring that the same features are to be observed repeatedly at the same place.
Its use has thus been extended to experiments on the essentially non-linear developments further downstream.
The relationship of information so obtained to processes in naturally occurring transition is sometimes debated.
It is, however, generally supposed that the same sequence of events occurs but with greater fluctuation in the position of any particular stage.
If the background disturbance level is large, some of the later stages may be triggered directly without the earlier stages having appeared.
We shall be seeing some comparisons of developments with controlled and uncontrolled disturbances in Figs 18.9–18.12.
The remarks so far apply to any shear flow.
But the detailed dynamics of transition vary from flow to flow.
There is a useful general classification into two types: flows in which turbulent motion first occurs in small patches, and flows in which the randomness characteristic of  turbulence develops at a roughly equal rate throughout the transition region.
Only the former type produces oscillograms like those in Fig. 2.10 with contrasted intervals of vigorously fluctuating and almost constant velocity.
(We shall see oscillograms characteristic of the latter type in Figs. 18.11 and 18.12.)
Most observations support the generalization that the first type of transition occurs in shear flows adjacent to a wall or walls (boundary layers, pipe flow, etc.) and the second type in shear flows away from any wall (‘free flows' such as jets, wakes, etc.).
But doubt has been cast on this useful generalization by observations of a transition process in boundary layers, different from that to be described in Section 18.2 and much more like that usually observed in free flows.
We are evidently reaching the end to the usefulness of general remarks.
Let us look at some particular cases.
18.2 Boundary layer transition
We take up the story where Section 17.7 left off.
What happens after Tollmien-Schlichting waves reach the critical amplitude?
The sequence of developments to be outlined below is becoming known as K-type transition, with the implication that there are other types.
These complications are emerging from very detailed experiments with vibrating ribbons.
However, probably the K-type can be regarded as the principal type.
In particular, if one wishes to infer the nature of uncontrolled transition from experiments with controlled disturbances, as considered in Section 18.1, then this type may be the most relevant.
Certainly, the appearance and spreading of turbulent spots, described below as the last stages of transition, are commonly observed in uncontrolled transition (e.g. Fig. 17.18).
Most of our knowledge of K-type transition comes from the pioneering experiments by Klebanoff and his colleagues, hence the name.
Important details have been filled in by experiments in channel flow; transition is promoted by a vibrating ribbon close to one wall whilst flow in the other half of the channel remains undisturbed, so there is close resemblance to a boundary layer.
The first development of the Tollmien-Schlichting waves is that they become three-dimensional; their amplitude varies in the lateral direction parallel to the wall.
Simultaneously, they interact with the mean flow, so that the velocity profile also has three-dimensional variations.
Figure 18.1 shows one set of measurements illustrating this development.
The growth of these three-dimensionalities continues until there are transient local regions of very high shear.
Figure 18.2 indicates the variation of the velocity profile inferred from measurements with     hot-wire anemometers (Section 25.2), through one cycle of the wave at the lateral position where the wave amplitude is largest.
The next development is initiated in the regions of high shear, apparent in the figure for t' between 0·38 and 0·6.
Hitherto, although the structure of the motion has become increasingly complex, the time scale of the velocity fluctuations has remained of the same order as the period of the initial wave.
Now fluctuations with much shorter time scales appear, initially as spikes in the velocity vs. time oscillograms but developing rapidly to bursts of turbulent-like fluctuations.
The detailed changes to the boundary layer structure during this development are complicated, although they occupy only a small fraction of the total distance over which transition occurs.
They involve the formation of hairpin-shaped vortices, leading to a second region of intermittent high shear close to the wall (Fig. 18.3), where the turbulence generation occurs: we can give only this very inadequate summary here.
The upshot is that small areas of the boundary layer are turbulent.
These areas are rather regularly distributed in controlled transition, more randomly in uncontrolled transition.
The remainder of the transition process consists of the growth of these local regions of turbulent motion, whilst they travel downstream.
As they grow they merge into one another.
Eventually, all the non-turbulent regions have been absorbed and the boundary layer is wholly turbulent.
The localized regions of turbulence are known as turbulent spots.
A spot can be generated directly without the normally preceding stages by a large localized disturbance, such as a rod or small jet momentarily    injected through the wall or a small spark.
Much of our extensive information on spots has come from such experiments.
Spots are shown in Figs. 18.4 and 18.5.
The former is a view through a transparent wall on which the boundary layer is formed.
The latter is a view perpendicular to the wall and parallel to the flow, along the   centreline of the spot widthways.
A turbulent spot is essentially a localized region of fully turbulent motion.
Just after formation a spot may involve its own type of motion.
But, once it has spread so that its dimensions parallel to the wall are large compared with the boundary layer thickness, the motion over most of its area closely resembles that in a fully turbulent boundary layer to be described in Sections 21.5 and 21.6.
As can be seen in Fig. 18.4, spots have a characteristic shape in planes parallel to the wall, something between a triangle and a heart-shape, with the narrower part towards the downstream end.
The spreading rates in different directions are such that spots retain this shape as they grow.
The spreading process is one of ‘sideways contamination’; transition to turbulence in laminar fluid is triggered by proximity to turbulent fluid, rather than turbulence being ‘fed into’ the laminar regions.
The distinction is clearest if we anticipate ideas about turbulence energy in Section 19.3: the new turbulence at the edge of a spot acquires its energy not by transfer from the spot but by generation of fluctuations that can themselves extract energy from the mean motion.
As already stated, the net effect of all these developments is a fully turbulent boundary layer.
Hence, the story continues in Section 21.5.
This section has so far been concerned specifically with zero-pressure-gradient boundary layers.
Similar processes often occur in the presence of a pressure gradient.
The effect of an adverse pressure gradient is generally destabilizing — it decreases the Reynolds number at which corresponding developments occur — and that of a favourable gradient is generally stabilizing.
These changes arise from changes in the laminar velocity profile.
A different transition process that can occur when the pressure gradient is adverse has already been considered in Section 12.6: the sequence of laminar separation, transition, and turbulent reattachment.
Since transition occurs in the separated region, the dynamical processes are more related to those of Section 18.4.
Although the initial attached laminar layer might be stable, the final reattached layer remains turbulent.
18.3 Pipe flow transition
We return to the topic of pipe flow; the description of transition in Section 2.6 needs filling out.
Although this is in principle one of the simplest configurations and although it played such an important role in the early history of transition studies, the details of the transition process turn out to be relatively complex and are, quite possibly, not all known.
Pipe flow illustrates, in a more extreme way than other flows, the limitations to linear stability theory (Section 17.4), in providing only a sufficient condition for flow breakdown, not a necessary one.
Linear stability theory applied to Poiseuille flow indicates that the parabolic velocity profile is stable at all values of the Reynolds number;.
(This result has not been proved with full rigour, but is considered well established.)
Nevertheless pipe flow becomes turbulent at some Reynolds number between 2 × 103 and 105.
Almost certainly, both the departures from the parabolic profile in the entry length and the response to non-infinitesimal disturbances play a role in the interpretation of this fact.
Different geometries result in different detailed flows in the entry length, but the entering fluid will often be irrotational.
Then, an annular boundary layer grows on the wall, and the flow starts approximating to Poiseuille flow when the thickness of this becomes close to the radius of the pipe (Fig. 2.5).
When the thickness of this boundary layer is small compared with the pipe radius, it will be prone to boundary layer instability at high enough Reynolds number.
We may anticipate that there will be a stable length right at the start of the pipe (the Reynolds number based on boundary layer thickness being small here), followed by the unstable region, this being followed in turn by another stable region as the profile approaches Poiseuille flow.
If disturbances are amplified sufficiently in the unstable region, then transition to turbulence may be expected.
Evidently, this description of the start of transition is consistent with a high degree of variability in the maximum Reynolds number at which laminar flow can be maintained.
In the first place, small variations in the velocity profile, due to different entry geometry, may affect the extent of the unstable region.
In the second place, the maximum amplitude of velocity fluctuations reached at the end of the unstable region will be sensitive to the level of small disturbances present at its start; the appearance of local regions of turbulence probably depends on a certain amplitude being reached.
By taking great care to minimize the disturbance level, experimenters have maintained laminar flow up to values of  of around 1·0 × 105.
It is likely that in these experiments there was a local unstable region in the entry boundary layer, but with subsequent decay of the amplified disturbances.
When turbulence develops at Reynolds numbers above about 104 the region of boundary layer instability is probably an important feature of the transition process.
Turbulence has been observed to appear first of all in small spots restricted laterally as well as axially and presumably forming in the boundary layer.
These spots then spread in all directions and several of them merge to form a turbulent slug.
However, the lowest values of the Reynolds number (around 2 × 103) at which transition occurs are well below the minimum value (a little above 104) at which theory indicates the existence of an unstable region.
In many experiments, the entry geometry has involved sharp edges or corners and there was probably a region of separated flow.
This would be unstable at a lower Reynolds number than any attached boundary layer, and rapid amplification of disturbances would occur as shown in Fig. 18.6.
However, this is probably not the only way in which transition can be initiated at the lower Reynolds numbers.
Observations have been made, some of them with an arrangement unlikely to produce separation, of transition occurring at around 3000 in a manner similar to that described above for higher Reynolds numbers — turbulent spots originating close to the wall and then spreading to give turbulent slugs.
One can only say that growing turbulent slugs can originate and so transition occur at Reynolds numbers down to about 2000, provided that there are large enough disturbances.
Probably there is no unique process for the origin of slugs in this range; a large disturbance can take such a variety of forms.
The triggering disturbance can be another turbulent region.
Observations have been made of one turbulent spot appearing in the boundary layer a little way downstream of an older one, whose presence has caused sufficient disturbance.
Despite these complications in the detailed mechanics of transition, it is clear what governs the lower limit in Reynolds number for transition.
Once turbulent slugs are produced, the transition process is substantially the same at all values of the Reynolds number.
The turbulence    propagates into the neighbouring non-turbulent regions at each end of a slug.
The slugs thus grow in length at the expense of the non-turbulent region.
When the front interface of one slug meets the rear interface of another, the two merge to give a single slug.
Thus the intermittency factor increases with distance downstream, until all the non-turbulent regions have been absorbed and fully turbulent pipe flow results.
Figure 18.7 shows the rates at which front and rear interfaces travel downstream as functions of the Reynolds number.
The difference between them disappears when Re is about 2300.
Below this slugs do not grow, and fully turbulent flow is not produced at any distance downstream.
There is a short Reynolds number range over which localized regions of turbulence neither spread nor decay; the resulting features are called turbulent puffs and have a characteristic structure.
There is some variability in the figure quoted for the minimum Re at which transition can be produced by large disturbances, values going down to 1800.
Nevertheless, it is clear that the limiting factor is slug growth.
Observations have been made of the processes leading to slug production at much lower Reynolds numbers, but transition does not then result.
The region of intermittently turbulent flow is often very long.
This depends on the rate of slug production, which is sensitive to the  disturbance level.
Quantitative estimates thus relate only to particular experiments, but this region can be hundreds of diameters long.
We saw in Section 2.6 that the production of turbulent slugs can be either random or periodic in time, as illustrated by the oscillograms of Fig. 2.10.
The random production might be regarded as the normal state of affairs, periodic production occurring through a rather special mechanism.
Nonetheless, the latter is a phenomenon of some interest and significance and we now consider how it comes about.
The pressure gradient needed to produce a given flow rate is much larger when the flow is turbulent than when it is laminar (Fig. 2.11).
Conversely, the flow rate produced by a given pressure difference between the ends is much higher for laminar flow than for turbulent flow.
In most experimental arrangements, it is the pressure difference, not the flow rate, that is held constant.
Hence, in transitional flow, as a turbulent slug grows the flow rate reduces.
This inhibits the instability of the entry region, and the probability of another slug being produced becomes negligible.
Only when the front of the slug passes out of the far end of the pipe does the fraction of the pipe length in laminar motion increase.
The flow rate then starts to increase too.
When it has increased sufficiently, another slug is produced near the entry, and the cycle recommences.
Since the front of a slug travels downstream at about three times the speed of the rear (Fig. 18.7), there can be substantial variations in the fraction of the flow that is turbulent (Fig. 18.8) and thus in the flow rate.
If these variations pass through the criterion for instability (such as the critical Reynolds number of the entry boundary layer), the instability can be renewed at just the same phase of each cycle and the flow will pulsate with a well-defined period.
This happens only over a limited Reynolds number range.
At smaller Re, the difference between laminar and turbulent flow rates is too small.
At higher Re the flow becomes turbulent in only a small fraction of the total length and so the variations in flow rate are again too small.
As one   would expect, the Reynolds number range depends on the length/diameter ratio of the pipe (and periodic transition does not occur at all when this ratio is less than about 60).
One can, therefore, quote only examples of this range, and two are given below.
The Reynolds number ranges appear short, but this is deceptive; there is a large change in the fraction of the fluid in the pipe that is turbulent as one goes through the range, and so a small change in Reynolds number is associated with a large change in the non-dimensional pressure drop.
For l/d = 540, the range has been observed to start at a Reynolds number (based on a velocity averaged not only over a cross-section but also over a cycle of the pulsation) of about 4700; the intermittency factor at the outlet became unity at Re = 5900.
Corresponding values of the non-dimensional pressure gradient  were 2·1 × 105 and 5·0 × 105.
For l/d = 78, the Reynolds number range (with the same significance) was 5500 to 5700 and the range of  was 4·5 × 105 to 5·9 × 105.
In conclusion, it is now abundantly clear why the traditional view that there is a single critical Reynolds number, below which the flow is laminar, above which the flow is turbulent, cannot describe the facts.
Instead we have to introduce a set of Reynolds numbers relating to different events in the transition process.
We start at the high end:
1.
The theoretical linear stability limit of Poiseuille flow is .
We may guess that a pipe flow with an artificially induced parabolic profile at the entry could remain laminar to even higher Reynolds numbers than flows with a normal entry length.
2.
There may be a Reynolds number above which a pipe flow with a normal entry length will always become turbulent through the amplification of small disturbances.
If so, this Reynolds number is at least 105.
3.
Below this there is still a region of instability in the entry length but not a sufficiently large one to promote transition when the disturbances are small.
The lowest Reynolds number at which this exists is somewhat uncertain but around 104.
4.
When the flow is spontaneously pulsating, the Reynolds number periodically becomes larger than its average value making the entry length temporarily unstable.
The lowest average Reynolds number at which this provides an instability mechanism is again uncertain but is around 5 × 103.
5.
The lower limit to transition even for very large disturbances is provided by the growth or otherwise of slugs.
The critical Reynolds number for this is better defined at (2·1 + 0·3) × 103.
18.4 Transition in jets
In the cases we have considered so far — boundary layer transition and pipe flow transition — the main feature of the later stages was the spreading of localized regions of turbulence.
It was noted in Section 18.1 that transition can occur without this process.
It was also noted that the alternative type of transition may sometimes occur in a boundary layer.
However, it is in so-called free flows away from any wall that this type is the normal type.
We therefore choose such a flow — an axisymmetric jet — to illustrate the difference.
The breakdown of a laminar jet usually starts quite close to the orifice, where the velocity profile still depends on the details of orifice geometry and the flow upstream of it.
Hence, different experiments may not be directly comparable, and there may similarly be difficulties of comparison between experiment and theory.
However, the broad features of the transition process are always much the same, and, if we omit quantitative detail, can be described without reference to any particular jet.
Disturbances first appear as approximately sinusoidal fluctuations, indicating a selective amplification process like that in a boundary layer.
This stage can be satisfactorily related to linear stability theory — a stability loop of type B in Fig. 17.16 being relevant.
Free shear flows become unstable at lower Reynolds numbers than shear flows next to walls; the order of magnitude of the critical Reynolds number for a jet is typically 10 (compared with 103 for a boundary layer).
The ability of an applied periodic disturbance in the appropriate frequency range to promote the instability can have rather spectacular results in jets, as shown in Fig. 18.9.
In such experiments, the disturbance is usually provided as a sound wave from a nearby loudspeaker.
The acoustic wavelength is long compared with the wavelength of the instability, and the fluid thus experiences a periodic disturbance of negligible phase variation.
Pictures (a)—(c) of Fig. 18.9 show a smoke-carrying jet when acoustic disturbances were minimized.
Figure 18.9(a) and (b) have general illumination,(a) with a relatively long exposure so that details of the instability are blurred and (b) as a flash so that an instantaneous pattern is seen.
The close-up (c) is again an instantaneous picture, but with illumination through a slit showing one part of the jet.
A spontaneously arising periodic instability can be seen.
Pictures (d)—(f) show the same jet with the frequency from a loudspeaker selected to have maximum effect;(d) and (e) are the counterparts of (a) and (b).
Like (c),(f) has slit illumination, but this is stroboscopic at the same frequency as the sound.
Since the exposure extends over about 1800 flashes of the stroboscope, the clarity of the picture demonstrates the extreme regularity of the pattern in its initial stages.
It is clear from Fig. 18.9 and from other similar work that the instability can give rise to well-developed ring-shaped vortices while it is still in the periodic stage.
However, the motion does not remain periodic for any great distance downstream.
Breakdown to turbulent motion occurs.
An interesting feature of the transition process is vortex pairing, seen in Fig. 18.10.
The vortices merge in pairs to form more diffuse vortices with larger overall circulation.
Sequential vortex pairings may occur — giving, for example, a vortex originating as four separate vortices — but simultaneously irregular fluctuations make the regular features more difficult to detect.
Figures 18.11 and 18.12 show oscillograms of velocity fluctuations at various distances downstream, for, respectively, spontaneously arising fluctuations and acoustically stimulated ones.
The difference from Fig. 2.10, which is characteristic of oscillograms produced during transition involving spot growth, is apparent.
The flow becomes turbulent through the continuous development of irregularities throughout the flow, instead of the sudden local appearance of irregularities which subsequently spread.
19
TURBULENCE
19.1 The nature of turbulent motion
Frequent references to turbulent motion have been made in previous chapters, but detailed discussion of the nature of that motion has so far been postponed.
We now take this matter up.
No short but complete definition of turbulence seems to be possible.
One has rather to describe the features that are implied by the use of the name.
One can formulate a brief summary, rather than a formal definition, that attempts to encapsulate the description.
Perhaps the best is that turbulence is ‘a state of continuous instability’.
Each time a flow changes as a result of an instability, one's ability to predict the details of the motion is reduced.
(An example below will explain this statement more fully.)
When successive instabilities have reduced the level of predictability so much that it is appropriate to describe a flow statistically, rather than in every detail, then one says that the flow is turbulent.
This implies that random features of the flow are dominant.
One cannot, however, say that a turbulent flow is ‘completely random’; to do so would define turbulence out of existence!
As we shall see (particularly in Chapters 21 and 22) all flows involve organized structures.
The point is just whether the randomness is sufficient for the statistical description to be the most appropriate.
This approach seems likely to leave a ‘grey area’ of flows that one might or might not choose to call turbulent.
It is in fact a moot point whether one would expect to be able to classify all flows as either turbulent or non-turbulent — or, equivalently, whether during transition to turbulence one should be able to designate the point at which turbulent motion begins.
We will see in Section 24.7 that modern ideas about chaotic dynamics suggest that such classification might be possible.
However, in practice at present, there are certainly intermediate flows of which one might give a detailed description for one purpose and a statistical one for another.
The notion of loss of predictability is best understood through an example.
Consider the motion in a Kármán vortex street (Sections 3.3, 17.8) in the wake of an obstacle.
The velocity at a point fixed relative to the obstacle varies periodically and roughly sinusoidally.
The phase of      this variation is arbitrary, depending on the small disturbances at the time the flow commenced.
If, therefore, one asks for a prediction of the instantaneous velocity, without making any observations, this cannot be given within certain limits.
This lack of predictability arises from the instability producing the vortex street; in the steady flow, from which the vortex street develops, such a prediction could be made.
The degree of unpredictability is, however, small.
One requires only a single observation indicating the phase of the fluctuations for all the details of the flow to be determined.
When, with increasing Reynolds number, a further instability causes loss of regularity in the array of vortices, the unpredictability is increased.
One can, for example, no longer say that, if one has made an observation of the velocity, then the velocity will be the same one period later.
However, markedly systematic features may still exist — regions of high vorticity passing a point in a sequence, although not a completely periodic one.
The flow can still be described with more emphasis on these systematic features rather than random ones.
Ultimately, however, the randomness becomes so marked that such a description is no longer useful; only a statistical description gives information that applies to another experiment on the same wake (cf.
Section 19.2).
There is every reason to suppose that this loss of predictability occurs as a property of the Navier-Stokes and continuity equations, although these equations contain the determinism of classical mechanics.
It is not thought that the onset of turbulence represents in some sense a breakdown of these equations.
The relationship of predictability to determinism will be discussed in Chapter 24; in particular reasons for the above assertions will be given in Section 24.6.
In the meantime, it is useful to illustrate the essential reason why a deterministic treatment of turbulent flows is not possible.
Important features of the motion (for example the large eddies to be described in Sections 21.4 and 21.6) develop from entirely insignificant perturbations.
An example of this may be taken from a context in which it is rather familiar: atmospheric motions on the scale that governs the principal features of the weather.
(This type of motion is in the borderland that one may or may not choose to call turbulent, but it shows sufficient of the characteristics of turbulence for the present purpose.)
One of the difficulties of long-term weather forecasting is that very fine details at one time can govern major patterns at a later time.
Figure 19.1 shows two weather maps, separated by two days.
In the first, there are two similar-looking distortions of the pattern associated with the large cyclone over Canada, around 55°N, 62°W and around 43°N, 75°W.
In the period between the two maps, the former distortion has just faded out whereas the latter has amplified and migrated to become the significant cyclonic region at the south of  Greenland in the second map.
Subsequently, it merged with the other original cyclone to the north of Norway with the elimination of the high pressure ridge over the Atlantic.
19.2 Statistical description of turbulent motion
A statistical description is formulated in terms of average quantities, since these are repeatable from experiment to experiment.
The detailed nature of the averaging process will be considered below, but another example may indicate the general meaning of a statistical description.
Consider turbulent pipe flow.
A measurement of the instantaneous velocity at some point in the pipe is, on its own, of little use.
It does not indicate what the velocity will be at the same point at another instant or what it will be at any other geometrically similar point (i.e. a point at the same distance from the axis).
Nevertheless, one may expect a greater similarity between two geometrically similar points than between two geometrically dissimilar points.
This similarity is provided by the average quantities.
The mean velocity, for example, is the same at all points at the same distance from the axis, but varies with this distance.
The ideal aim of a theory of turbulent motion would be the development of a statistical mechanics analogous to those developed in the kinetic theory of gases.
Such a theory would have to be based on the equations of fluid motion instead of those of the dynamics of molecules interacting only through elastic collisions.
It is thus a very difficult task.
Work on these lines (beyond the scope of this book) has been attempted, but various, not necessarily valid, assumptions have to be made before progress is possible.
Consequently, much of our knowledge of turbulent flows comes from experiment.
Some of the quantities that enter into any statistical theory can be measured experimentally.
A physical description of the principal processes occurring within a turbulent flow can be developed from these.
Generally, a rather complex interaction between theory and experiment results, theory indicating which quantities might usefully be measured and the experimental results pointing the way for further theoretical developments.
The statistical description of a turbulent flow starts by dividing the velocity and pressure field into mean and fluctuating parts.
We may consider the procedure for one component of the velocity; the other components and the pressure are treated in just the same way.
At each point, the velocity component is written as U + u, where, by definition  (an overbar denoting averaging).
For theoretical purposes it is sometimes convenient to think of the average as an ensemble average; i.e. one considers a large number of identical systems and takes the average of the velocity at corresponding instants over all these systems.
In practice, the average is usually a time average; one observes and averages the velocity at a point over a period long enough for separate measurements to give effectively the same result.
Procedural difficulties can arise when the imposed conditions are unsteady, but we need not consider such situations here.
Thus throughout the following the average of any quantity Q signifies  where s is large compared with any of the time scales involved in the variations of Q.
U indicates the mean motion of the fluid.
Information about the structure of the velocity fluctuations is given by other average quantities, the first being the mean square fluctuation, is known as the intensity of the turbulence component, and  as the intensity of the turbulence.
It is directly related to the kinetic energy per unit volume associated with the velocity fluctuations,
The same intensity field can in principle be produced by many different patterns of velocity fluctuation.
Before we look at the average quantities most often used to examine the more detailed structure of the velocity field, we consider briefly an alternative representation.
This is in a sense the most fundamental statistical representation, although it is not the most convenient for the development of models of turbulent structure based on experimental observation.
The probability distribution function P(u) of a velocity component at one point is defined so that the probability that the fluctuation velocity is between u and u + du is P(u) du.
One thus has  The intensity is related to this, but the probability distribution function contains more information than the intensity.
Relationships between velocity fluctuations at different points (or times) are indicated by joint probability distribution functions.
For example a second-order function,, may be defined so that the probability that the velocity at one point lies between u 1 and u 1 + du 1 and that at the other point simultaneously lies between u 2 and u 2 + du 2 is .
In principle, for a complete representation of the turbulence, this process has to be continued to all orders.
Probability distribution functions are sometimes determined experimentally, but much more frequently further average quantities are measured.
Fuller information than is given by  about the fluctuations at a single point can be obtained by measurements of , etc.
Information about velocity fluctuations at different points (or times) is given by correlation measurements.
The correlation between two velocity fluctuations u 1 and u 2 is defined as  and the correlation coefficient as 
In this definition u 1 and u 2 are quite general quantities; but as examples, they could be simultaneous values of the same component of the velocity at two different points, or two different components of the velocity at a single point.
If the fluctuations u 1 and u 2 are quite independent of one another, then their correlation is zero.
However, any turbulent flow is governed by the usual equations and these do not allow such complete independence, particularly for fluctuations at points close to one another.
Hence, non-zero correlations are observed.
The concept of correlations, like that of probability distributions, can be extended to higher orders, by defining quantities such as.
A complete specification of the turbulence again requires one to consider all orders up to infinity.
In practice, detailed attention is usually confined to double correlations  with briefer investigation of triple correlations.
Experimental studies of turbulent flows often involve the interpretation of correlation measurements.
One of the reasons for working particularly with correlations is that those of low order lend themselves satisfactorily to physical interpretation, in ways to be discussed in Section 19.4.
We shall also be introducing later (Section 19.5) the spectrum functions which are the Fourier transforms of correlation functions.
However, we now have enough material to examine the way in which the equations of motion are developed for turbulent flows.
19.3 Turbulence equations
In the interests of conciseness and convention, it is necessary to use here the suffix notation for vector equations which has for the most part been avoided in this book (the other main exception being the appendix to Chapter 5).
For a full explanation of this notation see Refs..
Its basic features are as follows.
Each suffix can take values 1, 2 or 3, corresponding to the three coordinate directions; a vector equation can be read as any one of its component equations by substituting the appropriate value for the suffix common to every term; and the repetition of a suffix within a single term indicates that that term is summed over the three values of that suffix.
With the velocity divided into its mean and fluctuating parts, the continuity equation (5.10) is  that is 
Averaging this equation (the processes of averaging and differentiation are interchangeable in order),
Subtracting this result from the original equation, we have 
The mean and fluctuating parts of the velocity field thus individually satisfy the usual form of the continuity equation.
The same division applied to the Navier-Stokes equation (eqn (5.22) with F = 0) gives 
Carrying out the averaging process throughout this equation gives  which, with the aid of the continuity equation (19.10), may be rewritten  where, additionally, attention has been restricted to steady mean conditions by making the first term of (19.12) zero.
Equation (19.13) for the mean velocity U i differs from the laminar flow equation by the addition of the last term.
This term represents the action of the velocity fluctuations on the mean flow arising from the non-linearity of the Navier-Stokes equation.
It is frequently large compared with the viscous term, with the result that the mean velocity distribution is very different from the corresponding laminar flow.
The character of this interaction between the mean flow and the fluctuations can be seen most simply in the context of a flow for which the two-dimensional boundary layer approximation applies.
The turbulent fluctuations are always three-dimensional, but if the imposed conditions are two-dimensional, there is no variation of mean quantities in the third direction and terms such as(that would otherwise appear in the next equation) are zero.
Omitting such terms and terms that are small on the boundary layer approximation in eqn (19.13) gives the turbulent flow counterpart of eqn (11.8); that is 
This equation is applied to turbulent boundary layers, jets, wakes, etc.
Writing the last two terms of (19.14) as  shows that the velocity fluctuations produce a stress on the mean flow.
A gradient of this produces a net acceleration of the fluid in the same way as a gradient of the viscous stress.
The quantity , and more generally the quantity , is called a Reynolds stress.
The Reynolds stress arises from the correlation of two components of the velocity fluctuation at the same point.
A non-zero value of this correlation implies that the two components are not independent of one another.
For example, if  is negative, then at moments at which u is positive, v is more likely to be negative than positive; conversely when u is negative.
Transferring attention to coordinates at 45° to the x- and y-directions shows that this corresponds to anisotropy of the turbulence — different intensities in different directions.
Putting  gives  Figure 19.2 shows the geometrical significance of this.
One can readily see how a correlation of this kind can arise in a mean shear flow.
We may consider the case of positive  as shown in Fig. 19.3.
A fluid particle with positive v is being carried by the turbulence in    the positive y-direction.
It is coming from a region where the mean velocity is smaller and it is thus likely to be moving downstream more slowly than its new environment; i.e. it is more likely to have negative u than positive.
Similarly negative v is more likely to be associated with positive u.
The process is in general(but not in detail) analogous to the Brownian motion of molecules giving rise to fluid viscosity.
The analogy has led to the definition of a quantity ν T such that ν T is called the eddy viscosity.
It is important to realize that ν T is a representation of the action of the turbulence on the mean flow and not a property of the fluid.
It is moreover a representation that simplifies the dynamics of that action; because of the large-scale coherent motions (Sections 21.4, 21.6), the Reynolds stress at any point depends on the whole velocity profile, not just the local gradient.
Although it is sometimes useful for approximate calculations to suppose that ν T is an (empirical) constant, in general(19.18) should be regarded as the defining equation of ν T rather than an equation for .
Further understanding of the interaction between the mean flow and the fluctuations is obtained from the equation for the kinetic energy of   the turbulence.
Subtracting eqn (19.12) from eqn (19.11) gives  Multiplying this by u 1 and averaging  (where the rearrangement of terms has made use of the continuity equation (19.10)).
Since the summation convention is being applied, the mathematics involves multiplying each component of the dynamical equation (19.19) by the corresponding velocity component and then adding the three resulting equations.
For steady mean conditions the first term of eqn (19.20) is zero, but it indicates the physical significance of the equation; in view of the summation convention  and so each term in the equation represents some process tending to increase or decrease the kinetic energy of the turbulence.
With the boundary layer approximation applied to a flow which is steady and two-dimensional in the mean, eqn (19.20) becomes 
The left-hand side and the second term on the right-hand side are terms that become zero when integrated over the whole flow.
They represent the transfer of energy from place to place, respectively transfer by the mean motion and transfer by the turbulence itself.
As in a laminar flow (Section 11.7), the viscous term can be divided into two parts: one is essentially negative and thus represents viscous dissipation; the other (usually small) integrates to zero and so is another energy transfer process.
The input of energy to compensate for the dissipation must be provided by the only remaining term,.
We have seen that  is likely to be negative where  is positive, giving this term the required sign.
Although local regions of positive  can occur, they cannot occupy the majority of the flow or the turbulence cannot be maintained.
The equation for the energy of the mean flow contains a corresponding term of opposite sign.
The term thus represents a transfer of energy from the mean flow to the turbulence.
One can therefore say that the Reynolds stress works against the mean velocity gradient to remove energy from the mean flow, just as the viscous stress works against the velocity gradient.
However, the energy removed by the latter process is directly dissipated, reappearing as heat, whereas the action of the Reynolds stress provides energy for the turbulence.
This energy is ultimately dissipated by the action of viscosity on the turbulent fluctuations.
Frequently, the loss of mean flow energy to turbulence is large compared with the direct viscous dissipation.
19.4 Interpretation of correlations
Correlation coefficients (Section 19.2) play an important role in both theoretical and experimental studies of turbulence.
To illustrate how they can indicate the scale and structure of a turbulent motion, we now look at typical properties of double correlations.
Some of the ideas introduced rather vaguely here will be used more specifically in Sections 20.2, 21.4 and 21.6.
When u 1 and u 2 are velocities at different positions but the same instant, is known as a space correlation.
Its particulars may be specified by a diagram such as Fig. 19.4(a).
Most attention is usually given to correlations of the same component of velocity at points separated in a direction either parallel to that velocity component (Fig. 19.4(b)) or perpendicular to it (Fig. 19.4(c)).
We may call these respectively longitudinal and lateral correlations.
The correlation will depend on both the magnitude and direction of the separation, r.
Different behaviours in different directions may provide information about the structure of the turbulence, a point that will be taken up again in Section 21.4.
Here we pay more attention to the variation with distance, r = |r|.
When r = 0, u 1 = u 2 (provided they are in    the same direction) and the correlation coefficient R of eqn (19.6) is, by definition, equal to 1.
At large r the velocity fluctuations become independent of one another and R asymptotically approaches 0.
In consequence, the dependence of R on r takes typically one of the forms shown in Fig. 19.5. (r has a maximum value of 1 at r = 0 and so .
However, the curvature at r = 0 is usually large and experimentally measured correlations often appear to have finite slope at r = 0.)
A negative region in the correlation curve implies that u 1 and u 2 tend to be in opposite directions more than in the same direction.
For a longitudinal correlation this would imply dominant converging and/or diverging flow patterns.
There is often no reason to expect such patterns and one may expect that longitudinal correlations will usually give a curve such as A (Fig. 19.5).
On the other hand, lateral correlations may be expected to have a negative region, like curve B, since continuity requires the instantaneous transport of fluid across any plane (by the fluctuations) to be zero.
Such expectations are not always fulfilled; but, when they fail, this may itself be informative about the structure of the turbulence.
A correlation curve indicates the distance over which the motion at one point significantly affects that at another.
It may be used to assign a length scale to the turbulence; a length can be defined for example as , or as the distance in which R falls to 1/e, or, if the curve has a negative region, the value of r at which R is a minimum.
We shall see in Sections 19.6, 20.3, and 21.3 that this concept is extended to associate a variety of length scales with the turbulence.
The correlation of the same velocity component at a single point at different instants is known as an autocorrelation.
Such a correlation  depends, of course, on the time separation s in a similar way to the dependence of a space correlation on r.
It can be used to define a typical time scale of the turbulence.
When the turbulent motion is occurring in a flow with a large mean velocity, it is possible for the turbulence to be advected past the point of observation more rapidly than the pattern of fluctuations is changing.
An autocorrelation will then be directly related to the corresponding space correlation with separation in the mean flow direction, the same curve applying for both when one puts .
This transformation is called Taylor's hypothesis.
The extent to which it applies varies greatly between different flow situations.
A correlation between velocities measured at both different positions and different instants is called a space-time correlation.
Such measurements are very useful in indicating the trajectories of certain features (‘eddies', Section 19.6) associated with the turbulence, and have played an important role in some of the descriptions of the motion to be mentioned in Sections 21.4 and 21.6.
However, we shall not discuss them further in this book.
In principle, of course, correlations involving the pressure fluctuations as well as the velocity fluctuations may be formulated.
Equation (19.22) has already involved  — a pressure-velocity correlation.
However, such quantities are difficult to measure and so have received less attention.
19.5 Spectra
Another method of discovering the time scales associated with turbulent motion is, obviously, Fourier analysis.
The long-standing experimental method is to pass a turbulence signal (such as the output from a hot-wire anemometer, Section 25.2) through an electrical frequency filter.
The modern method, which is largely though not totally superseding the above, is to sample the signal at frequent intervals and then carry out the Fourier analysis digitally.
Either method involves subtleties, both about the definition of the quantity to be determined and about how well the procedure actually determines it.
(The numerical analysis in particular contains ‘traps for the unwary’.)
The reader is referred to other sources for a proper treatment of these matters.
Here just sufficient theory will be given to show the significance of the quantity measured.
This is most simply done in the context of the older experimental method.
The aim of the numerical analysis in the modern method is to determine the quantity  defined below.
We thus consider the effect of passing a turbulence signal through a frequency filter before the usual squaring and averaging.
Suppose that  the velocity signal is u(t).
Then the output from the filter is  where  is the response function of the filter; i.e.  is the output at time t when the input is a delta function at t = 0.
is a fluctuating function and one can measure its mean square, which is  where the average is over t, by the procedure of eqn (19.1), and so may be taken inside the integration with respect to t' and t".
But  where R(s) is the autocorrelation coefficient for time delay s.
We now introduce the Fourier transform  of the autocorrelation such that(R(s) being an even function).
Substituting in (19.24), But  is the amplitude of the output when the input is sinusoidal with angular frequency ω.
Thus 
If the filter is a good one, is much larger over a narrow range of frequencies, centred on ω O than elsewhere, and eqn (19.29) reduces to  where C is a calibration constant.
Thus this procedure measures the Fourier transform of the autocorrelation function.
Putting s = 0 in eqn (19.26) showing that  may be interpreted as the contribution from frequency ω to the energy of the turbulence.
(We have here considered one velocity component, but eqn (19.2) provides immediate extension from the energy associated with components to the energy as a whole.
is thus known as the energy spectrum.
As well as the frequency spectrum, one can define wave number spectra — Fourier transforms of the space correlations.
This is more complicated because one is now dealing with three dimensions, and the reader is again referred to other sources for the theory.
Suffice it to say here that one can define a quantity E(k), where k is the magnitude of the wave number, such that 
E(k) indicates the distribution of energy over different length scales.
It is an important parameter in many theoretical treatments of turbulent motion.
However, it cannot be measured experimentally; one would need simultaneous information from every point of the flow.
When applicable, Taylor's hypothesis (Section 19.4) can be used to derive a spatial spectrum from an observed time spectrum.
However, this is a one-dimensional spectrum with respect to the component of the wave number in the mean flow direction, and so is not in general a complete determination of the spectral characteristics or of E(k).
19.6 Eddies in turbulence
As we shall see in the following chapters, the division of a turbulent motion into (interacting) motions on various length scales is useful because the different scales play rather different roles in the dynamics of the motion.
This is often expressed by talking of ‘eddies of different sizes’.
A turbulent ‘eddy’ is a rather ill-defined concept, but a very useful one for the development of descriptions of turbulence.
The name does not necessarily imply a simple circulatory motion, but one can often identify characteristic features of particularly the large eddies.
This has led to such eddies also being called ‘coherent structures’(Sections 21.4, 21.6).
An eddy differs from a Fourier component in the following way.
A single Fourier component, no matter how small its wave length (that is, how large the value of k), extends over the whole flow.
An eddy is localized — its extent is indicated by its length scale.
However, small eddies contribute to larger wavenumber components of the spectrum; the  spectrum curve is often interpreted loosely in terms of the energy associated with eddies of various sizes.
For any separation, r, the correlation coefficient is determined by all eddies larger than ∼ r.
Only the largest eddies can thus be related directly to correlation measurements.
Conversely, the observable spectrum function has a value at wavenumber κ χ influenced by all eddies smaller than  (for reasons arising from the fact that only one-dimensional spectra can be observed.
Hence, it is usually most convenient to use correlation measurements to provide information about the larger scales and spectrum measurements for the smaller scales.
Correlations and spectra are not the only experimental tools for elucidating the structure of turbulent flows.
In Chapter 21 we shall see the importance of flow visualization.
Also there are other ways of processing turbulence signals.
Techniques under the general name of conditional sampling have become important in recent years.
These take a variety of forms and are thus difficult to summarize; basically statistical properties are measured whilst some condition is fulfilled, such as the velocity being above some level, the velocity varying particularly rapidly, or different velocity components being related so as to make a large contribution to the Reynolds stress.
There is a danger that the choice of condition may prejudge the structure under investigation, but with care such measurements can reveal much about the structure of the eddies.
HOMOGENEOUS ISOTROPIC TURBULENCE
20.1 Introduction
Many theoretical investigations of turbulence have been developed around the concept of homogeneous, isotropic turbulence — turbulence of which the statistical properties do not vary with position and have no preferred direction.
An approximation to such a motion can be obtained behind a grid, such as the one shown in Fig. 20.1, in a wind-tunnel.
The theories have thus been supplemented by observation.
However, we postpone consideration of experimentally based ideas about the structure of turbulence to the different contexts of Chapter 21.
Here, without detail, we use the context of homogeneous isotropic turbulence to develop some ideas relevant to all turbulent flows.
The energy production term in eqn (19.20) is zero in isotropic turbulence, and so the motion must decay through viscous dissipation.
In theoretical work, the turbulence is supposed to be generated at an initial instant and then to decay as time proceeds.
Behind a grid, there is strong turbulent energy production for the first ten or so grid mesh-lengths along the tunnel; the turbulence then becomes substantially isotropic and decays with distance down the tunnel.
(This, in principle, implies inhomogeneity, but the decay is slow enough for this to be neglected.)
We shall consider certain features of the motion applying at any stage of this decay process.
20.2 Space correlations and the closure problem
The assumption of homogeneity and isotropy much simplifies the formulation of space correlations.
These depend only on the distance between the two points and not on their location or the orientation of the line joining them.
Moreover, it may be shown that the general correlation, as in Fig. 19.4(a), may be expressed in terms of the longitudinal and lateral correlations of Fig. 19.4(b) and (c).
Thus only these two functions of r (denoted respectively by f(r) and g(r)) are needed for complete specification of the double velocity correlations.
When, additionally, the   continuity equation is introduced a relationship between these is found,
Hence, only a single function gives the complete specification.
The mathematics behind these statements runs as follows.
The correlation coefficient between velocity component u i at one point and component u j at a point r away is a second-order tensor R ij (r).
When there is isotropy 
For this to take the appropriate forms in the particular cases of longitudinal and lateral correlations,
Continuity gives  Substituting this in  gives  which reduces to eqn (20.1).
Figure 20.2 shows an experimental check of eqn (20.1).
Direct measurements of g are compared with ones calculated from measurements of f.
No use has been made so far of the dynamical equation.
Obviously, one would like to use this to determine f as a function of r.
However, one encounters what is known as the closure problem, a consequence of the   non-linearity of the equation.
The mathematical analysis is somewhat complicated.
The point of principle can be illustrated by much simpler equations, such as the Lorenz equations discussed in Chapter 24; the closure problem is therefore analysed in the appendix to that chapter.
For turbulence the problem manifests itself as follows: when one formulates an equation for the double correlation function it involves triple correlations, an equation for these involves fourth-order ones; and so on.
A variety of suggestions for an additional hypothesis to close the system have been advanced.
However, our knowledge of f as a function of r remains primarily experimental (Fig. 20.2).
20.3 Spectra and the energy cascade
An important equation in the theory of homogeneous isotropic turbulence is obtained by considering the Fourier transform of the double velocity correlation.
We omit the derivation and quote the result:
E is the energy spectrum of eqn (19.32); the dependence on t is shown as a reminder that we are dealing theoretically with a time-dependent situation.
The closure problem has come through in the appearance of  another function F in the equation for E; F is related to the Fourier transform of the triple correlation.
However, it can be given its own physical interpretation through its role in eqn (20.7).
The left-hand side represents the rate of change of the energy associated with wavenumber κ.
The second term on the right-hand side is a negative term involving the viscosity and is thus the energy dissipation.
It can be shown that  and so the first term on the right-hand side of eqn (20.7) represents the transfer of energy between wavenumbers.
Figure 20.3 shows graphs of E and  for a typical situation.
The latter has large values at much higher κ than the former.
Hence the viscous dissipation is associated with high wavenumbers; i.e. it is brought about by small eddies.
This is a consequence of the fact that turbulent flows normally occur at high Reynolds number.
The action of viscosity is slight on a length scale of the mean flow (e.g. a grid mesh-length).
Yet much more dissipation occurs than in the corresponding laminar flow.
This requires the development of local regions of high shear in the turbulence; i.e. the presence of small length scales.
The small dissipative eddies must be generated from larger ones.
The effect of this on the energy spectrum is contained in the second term of eqn (20.7); i.e. one expects the transfer of energy to be primarily from low wavenumbers to high.
This inference is confirmed experimentally by observations in grid turbulence of changes in the spectrum with distance downstream.
This interpretation of the behaviour of the terms of eqn (20.7) allows the development of a model of turbulence which has relevance not just to homogeneous isotropic turbulence but to most turbulent flows.
Energy fed into the turbulence goes primarily into the larger eddies.
(In grid turbulence this happens during the initial generation; in other flows to be considered in Chapter 21 it happens throughout the flow.)
From these, smaller eddies are generated, and then still smaller ones.
The process continues until the length scale is small enough for viscous action to be important and dissipation to occur.
This sequence is called the energy cascade.
At high Reynolds numbers (based on  and a length scale defined in a way indicated in Section 19.4) the cascade is    long; i.e. there is a large difference in the eddy sizes at its ends.
There is then little direct interaction between the large eddies governing the energy transfer and the small dissipating eddies.
The dissipation is determined by the rate of supply of energy to the cascade by the large eddies and is independent of the dynamics of the small eddies in which the dissipation actually occurs.
The rate of dissipation is then independent of the magnitude of the viscosity.
An increase in the Reynolds number to a still higher value — conveniently visualized as a change to a fluid of lower viscosity with all else held constant — only extends the cascade at the small eddy end.
Still smaller eddies must be generated before the dissipation can occur.
(Since, as we shall see, the total energy associated with these small eddies is small, this extension has a negligible effect on the total energy of the turbulence.)
All other aspects of the dynamics of the turbulence are unaltered.
This inference, that the structure of the motion is independent of the fluid viscosity once the Reynolds number is high enough, has important implications and will be considered again in Section 21.1.
It is given the (somewhat misleading) name of Reynolds number similarity.
The dynamics of the energy cascade and dissipation may be supposed to be governed by the energy per unit time (per unit mass) supplied to it at the large eddy (low wavenumber) end.
This is, of course, equal to the energy dissipation, ε.
This suggests (but see below) that the spectrum function E is independent of the energy production processes for all wavenumbers large compared with those at which the production occurs.
Then E depends only on the wavenumber, the dissipation, and the viscosity,
If the cascade is long enough, there may be an intermediate range (the inertial sub-range) in which the action of viscosity has not yet come in; that is  Dimensional analysis then gives  where A is a numerical constant.
This is a famous result, known as the Kolmogorov -5/3 law.
There is, however, a problem over the derivation of the result, for a rather subtle reason connected with the structure of the smaller-scale   motions.
Experiments show clearly that the energy dissipation does not occur roughly uniformly throughout the turbulence; there are patches of intense small eddies involving high dissipation and other patches where there is little dissipation.
We shall see in the next section why this should be.
The patchiness develops throughout the energy cascade; as the eddies get smaller, so the fraction of the volume in which they are active decreases (though the size of a patch is at each stage large compared with the corresponding eddy size).
This implies that within the patches the rate of energy transfer per unit mass increases with wave number, thus complicating the derivation of the Kolmogorov law.
The fractional volume of activity depends on how far down the cascade one is; i.e. on , where κ O is a typical wave number of the turbulence energy production.
This indirectly modifies (20.10) to  and so upsets the dimensional argument.
There has been extensive theoretical discussion about how this affects the Kolmogorov result, suggesting that  with n a little larger than 5/3 but not exactly known.
Any theory which changed n substantially would be inconsistent with the observations.
The Kolmogorov law is well supported experimentally.
Such experiments have to be performed at very high Reynolds number in order that the inertial sub-range should be of significant length.
Some of the best verifications thus come from natural flows rather than laboratory experiments.
Figure 20.4 shows a spectrum obtained in an oceanographic channel flow, produced by tides, with a Reynolds number of 4 × 107; the axes are logarithmic and the line has a slope of -5/3.
(This is actually the measurable one-dimensional spectrum, but it can be shown that if this is proportional to , then so is the energy spectrum.)
20.4 Dynamical processes of the energy cascade
The discussion in Section 20.3 of the energy cascade did not consider the mechanism by which the transfer of energy from large scales to small scales occurs.
It is instructive to consider first the related but more readily understood process of the mixing of a scalar contaminant.
Suppose a blob of fluid, as shown in Fig. 20.5(1), is marked in some way, for example by being heated or dyed.
If this blob is in a turbulent flow, its distribution will change with time in the way indicated schematically by successive configurations in Fig. 20.5 (see also Fig. 21.6).
Its distribution in space becomes more and more contorted by the velocity fluctuations, but so long as molecular diffusion plays no role, the marked fluid is always just the same fluid.
If the Péclet number is high, diffusion is negligible at first.
However, the highly contorted patterns involve very steep gradients of the marker and so ultimately diffusion becomes significant, causing previously unmarked fluid to become marked.
The higher the Péclet number, the more contorted the pattern must become before this happens.
This process is analogous to the cascade because it involves the appearance of smaller and smaller length scales until this is limited by molecular effects (diffusion or viscosity).
However, the energy cascade is a more complicated matter because it involves the interaction of the velocity field with itself instead of with a quantity not involved in the dynamics.
Any brief account of it must involve oversimplification, but three (not wholly independent) processes may be identified.
The first is the process of repeated instability considered in Section 19.1.
Each stage may give rise to motions not only of greater complexity but also involving smaller scales than the previous stages.
For example, one stage may produce local regions of high shear that can themselves be unstable.
Secondly, turbulence of a smaller scale may extract energy from larger-scale motions in a way analogous to the extraction of energy from a mean flow by the turbulence as a whole (Section 19.3).
Thirdly, there is vortex stretching.
The random nature of turbulent motion gives a diffusive action; two fluid particles that happen to be close together at some instant are likely to be much further apart at any later time.
The turbulence will have carried them over different paths.
This applies to two particles on the same vortex line.
The process of vortex stretching, considered in Section 6.6, will thus be strongly present — although occurring in a random fashion.
This increases the magnitude of the vorticity, but because of continuity also reduces the cross-section of the vortex tube.
There is thus an intensification of the motion on a smaller scale; that is a transfer of energy to smaller eddies.
This process may also be seen as a cause of the patchy distribution of dissipation mentioned in Section 20.3.
The vorticity intensification process will be strongest where the vorticity already happens to be large.
At any instant the production of small eddies is thus occurring vigorously in some places and only weakly in others.
21
TURBULENT SHEAR FLOWS
21.1 Reynolds number similarity and self-preservation
Shear flows constitute by far the most important class of turbulent flows.
We have traced the processes by which they become turbulent in Sections 17.6–17.8 and Chapter 18.
With the background of general ideas about turbulence in Chapter 19, we now look at the structure of fully turbulent shear flows.
In this and the next section we consider general ideas and illustrate them with various flows (depending largely on the best illustrations available).
Subsequently we shall focus particular attention on wakes and boundary layers.
Studies of turbulent flows centre on laboratory experiments.
Probably more than in any other branch of fluid dynamics, our knowledge and understanding would be slight without such experiments.
As always, it is necessary to know the range of applicability of any measurement — whether it is relevant to other similar flows or whether it is peculiar to the particular situation investigated.
Since the number of measurements needed for a reasonably full understanding of any turbulent flow is large, it is highly desirable to make observations of general applicability.
Two ideas help here.
The first is the concept of Reynolds number similarity already introduced in Section 20.3.
The larger eddies and the mean flow development are independent of the viscosity (so long as this is small enough to make the Reynolds number large).
This is true of the mean flow because the last term of eqn (19.14) normally dominates the last-but-one term and because the Reynolds stress is produced by the larger eddies.
(The contribution of different length scales to the Reynolds stress may be investigated by applying spectral analysis not only to the energy as in Section 19.5, but also to the Reynolds stress.
Figure 21.1 makes a comparison between the energy and Reynolds stress (one-dimensional) spectra in turbulent channel flow; the much more rapid fall-off of the latter at high wavenumbers is apparent.)
Hence, experiments at any (sufficiently high) Reynolds number provide information applicable to all values of the Reynolds number.
We shall see in Section 21.5 that some qualification of this concept is needed for the motion in the vicinity of a solid boundary.
The second idea is that of ‘self-preservation’.
This is the counterpart for turbulent flow of the occurrence of similar velocity   profiles at different distances downstream in laminar flow (as discussed in Sections 11.4 and 11.6).
However, self-preservation requires not only that the mean velocity distribution should be similar, but also that all the parameters associated with the turbulence should have similar distributions at different stations.
The equations of motion permit self-preservation only in particular cases.
For example, it can occur in a wake only sufficiently far downstream for the mean velocity deficit at the wake centre to be small compared with the total mean velocity.
Such flows approach asymptotically to the self-preserving form, although often very slowly; for reasons to be seen in Section 21.4, turbulent flows have a long ‘memory’ of upstream conditions.
When a flow is self-preserving, a description of the turbulent motion developed from measurements at one station can be applied to the whole flow.
The ideas of Reynolds number similarity and self-preservation taken in conjunction allow certain features of turbulent flows to be derived rather simply.
We may illustrate this most readily by considering the development of the mean flow of a two-dimensional jet.
As for a laminar flow, the jet is characterized, far enough downstream from the orifice, by M, the momentum transported per unit time over each cross-section.
Ignoring a small contribution from the non-linear effects of the velocity fluctuations,
Putting, analogously with (11.37),(the origin of χ being adjustable) conservation of momentum again gives 
Secondly, the concept of Reynolds number similarity implies that ν does not enter into the counterpart of relationship (11.45) and so  Dimensional requirements now imply that  that is n = 1.
Equation (21.3) now gives 
These results have been obtained more simply than the corresponding results for laminar flow.
In contrast, however, the treatment of laminar flow can be continued to indicate the detailed form of the velocity profile (eqn (11.54)), whereas nothing more can be derived about the turbulent flow without additional assumptions or experimental observations.
Figure 21.2 shows an experiment verifying the result (eqn (21.5)) that a turbulent jet spreads linearly.
This result is true also of axisymmetric jets, just the same derivation applying (although now ).
Thus such jets spread out in a conical shape.
21.2 Intermittency and entrainment
In many situations turbulent motion occurs in only a limited region — that region in which high shear has been generated.
Turbulent jets and wakes are usually surrounded by non-turbulent fluid; a turbulent boundary layer usually occurs beneath an inviscid irrotational flow.
In such cases the interface between the turbulent and non-turbulent regions is sharp.
It has, however, a highly irregular shape with bulges and indentations of various sizes, as shown in Fig. 21.3.
The bulges and indentations are carried downstream by the flow.
At the same time the detailed shape of the boundary is changing; each bulge and indentation can be identified over only a limited time.
At a fixed point (such as A in Fig. 21.3), random alternations between turbulent and non-turbulent motion occur.
Figure 21.4 shows oscillograms of the velocity fluctuations at different distances from the centre line of a wake.
It is possible to define quite accurately the fraction of the time that the motion is turbulent.
This quantity is called the intermittency    factor γ.
Figure 21.5 shows its distribution in a two-dimensional wake.
At the centre of the wake γ is 1; the motion is always turbulent.
Outside the wake γ is 0; turbulent motion never penetrates there.
But over a substantial fraction of the wake width, turbulent and non-turbulent motion alternate.
Similar intermittency distributions can be determined for other flows.
When dye (or smoke) has been introduced far upstream within the turbulent region, the boundary of the dyed region closely approximates to the boundary of the turbulent region.
The effect of intermittency can thus be seen in, for example, Figs 3.11, 18.9(b) and (e), and 21.6.
(It is less apparent in Fig. 21.2, because the optical technique averages in the direction normal to the picture and the bulges and indentations are three-dimensional.)
At the interface between turbulent and non-turbulent fluid, the turbulence spreads.
Fluid just in the non-turbulent region will a short time later be in turbulent motion.
This spreading is part of the process of   entrainment for a turbulent flow.
Entrainment by laminar flows — the fact that a jet, for example, draws fluid into itself from the sides — has been discussed in Sections 11.6 and 11.7.
In particular, through relationships (11.64)—(11.66), the entrainment was related to energy dissipation.
Turbulent flows have much higher entrainment rates than the corresponding laminar flows, a fact that may be related to the additional dissipation by the velocity fluctuations.
Associated with the entrainment of new fluid into a flow such as a jet there must be a process by which new fluid becomes turbulent.
Otherwise a decreasing fraction of the flow would be turbulent, and, for example, self-preservation could not occur.
This process is the spreading at the interface.
We can now see the reason why the interface is sharp.
Associated with the velocity fluctuations of any turbulent motion are intense vorticity fluctuations.
(The importance of vorticity in the dynamics of turbulence is  apparent from the discussion in Section 20.4.)
We will suppose that the flow in the non-turbulent region is irrotational, as is usually the case in the examples that have been mentioned.
The acquisition of vorticity by initially irrotational fluid can only be brought about through the action of viscosity (Section 10.3).
Thus the spreading of the turbulence at the interface involves the action of viscosity and must be effected by those eddies for which viscosity is significant; i.e. the small eddies.
The length scale over which the change from turbulent to non-turbulent (rotational to irrotational) motion occurs is the size of these eddies, and so the interface appears very sharp on the scale of the flow as a whole.
The shape of the interface is, on the other hand, influenced by eddies of all sizes.
The irregular and changing corrugations occur with a wide range of length scales.
In particular, the largest bulges and indentations are produced by the large eddies to be described in Sections 21.4 and 21.6; these eddies are responsible for the fact that the region in which γ is non-zero but less than 1 extends over a sizeable fraction of the flow (see, e.g., Fig. 21.5).
The flow outside the interface, although called non-turbulent, does involve velocity fluctuations.
These are produced by the neighbouring turbulent region.
Evidently the motion of a bulge in the interface changes the pattern of irrotational motion outside it.
However, these velocity fluctuations are entirely irrotational and are dynamically quite different from turbulent fluctuations.
They attenuate rapidly with distance from the interface.
We now see that the intermittency factor is most appropriately defined as the fraction of the time that vorticity fluctuations are occurring.
The processes at the interface constitute a subject of study in their own right.
In particular, one wants to understand the way in which the turbulence spreads.
We shall not consider this topic here except to make the following point.
Although the action of viscosity is essential to the spreading process, the concept of Reynolds number similarity implies that the spreading rate does not depend on the magnitude of the viscosity.
Experimentally this appears to be the case.
However, the earlier discussion of Reynolds number similarity (Section 20.3) does not extend to this process.
The detailed dynamics are uncertain, but, presumably, the situation is analogous with the energy cascade; although the spreading is brought about by the small eddies its rate is governed by the larger eddies.
The total area of the interface, over which the spreading is occurring at any instant, is determined by these larger eddies.
Figure 21.6 illustrates and summarizes the entrainment process described in this section.
Two sources, side by side, emit water into the uniform flow in a water channel.
The water from the lower source is   emitted sufficiently faster than the main flow that it forms a turbulent jet.
The water from the upper source is emitted at the same speed as the main flow; there is thus no shear and no turbulence generation.
This source merely provides a way of marking fluid with minimum dynamical effect.
In Fig. 21.6(a), both sources emit dyed water.
The jet is visible (it has a rather different structure from jets considered elsewhere in this book because of the motion of the surrounding fluid).
The way in which its spreading brings the dye from the other source into turbulent motion can be seen.
In Fig. 21.6(b), only water from the passive source is dyed, although the jet is still present; this shows more clearly the effect of entrainment on the initially laminar fluid.
The figure also illustrates the processes shown schematically in Fig. 20.5; the longer the dye streak has been inside the turbulent region, the wider is the range of length scales on which it has been distorted.
21.3 The turbulent wake
The understanding of the dynamics of turbulence in shear flows depends primarily on the measurement and interpretation of the parameters introduced in Chapter 19.
Further discussion thus has to focus attention on particular flows, and we now consider the two-dimensional wake to exemplify the procedures and the ideas that come from them.
The wake is typical of shear flows away from any solid boundary, known as free shear flows.
We shall see in Section 21.5 that additional ideas are needed for flows adjacent to walls.
As usual the Cartesian coordinate system used to specify directions has x in the mean flow direction, y across the wake, and z parallel to the axis of the body producing the wake.
Obvious first measurements, after the mean velocity profile of Fig.   21.5, are , the separate contributions to this  and , and the Reynolds stress .
Figure 21.7 shows the distributions of these across a wake.
The Reynolds stress is zero right at the middle of the wake, by symmetry, and, of course, it falls to zero outside the wake.
Its maximum is in the vicinity of the maximum of  (cf.
Fig. 21.5), in line with the general analogy between the Reynolds stress and a viscous stress mentioned in Section 19.3.  is much larger than .
It causes the wake to increase in width and decrease in velocity deficit with distance downstream.
The interpretation of these observations is assisted by information on the energy balance; which processes are supplying energy to the turbulence at each point and which are removing it?
Figure 21.8 shows distributions of each of the terms in eqn (19.22) measured in a wake.
The maximum energy production is close to the position of maximum Reynolds stress.
The turbulence is being kept going by the working of  this against the mean velocity gradient.
At the centre of the wake, the production is zero (since both  and  are zero there).
The dissipation, on the other hand, has a maximum at the centre.
This is balanced primarily by the advection term .
As the mean velocity deficit decreases with x, so, in accordance with self-preservation, the scale of  decreases; thus the fluid at the centre of the wake is losing turbulent energy as it travels downstream.
At the outer edge of the wake, on the other hand, the advection term has the opposite sign.
This corresponds to the supply of turbulent energy to previously non-turbulent fluid as the wake spreads.
Figure 21.8 shows that this energy is supplied by the outward transport of energy by the fluctuations themselves from the region where the production is large.
When measurements such as those described above are supplemented by measurements of correlations and spectra and by flow visualization   experiments, some ideas may be developed about the role of eddies of different sizes in the dynamics of the turbulence.
We have already seen that the smaller eddies contribute relatively less to the Reynolds stress than to the energy (illustrated for a different flow by Fig. 21.1).
More generally, the smaller eddies have a structure that is less characteristic of the particular flow than the larger eddies and the description of their behaviour developed from observations in grid turbulence (Chapter 20) may be applied.
The later stages of the energy cascade are similar in all flows.
It is because of this that observations in shear flows may be used for experimental investigations of the Kolmogorov law, eqn (20.11).
The larger eddies, which do play a role in the generation of the Reynolds stress, must be more characteristic of the particular flow, since the Reynolds stress distribution necessarily varies from flow to flow.
So long as the eddies are still relatively small compared with the length scale of the mean flow (e.g. wake width), their features are adequately described by the considerations of Section 19.3.
The anisotropy associated with Reynolds stress production (Fig. 19.2) arises essentially in the way summarized by Fig. 19.3.
Usually, the largest contribution to the energy of the turbulence is made by eddies large enough to be oriented in this way but small enough to be within one part of the mean velocity profile.
Still larger eddies extend across much of the flow and there will be appreciable variation of the mean shear within their length scale.
The ideas of Fig. 19.3 are then too great an oversimplification.
The large eddies play a role out of proportion to their contribution to the turbulent energy, both in the interaction between the mean flow and the turbulence and in the turbulent energy transfer process involved in Fig. 21.8.
We consider these large-scale motions in the next section.
21.4 Coherent structures: in general and in a wake
We are continuing to use the two-dimensional wake as a context for ideas that apply to other flows as well.
Some general comments about the large eddies are needed before we consider a wake specifically.
In recent years the larger eddies of turbulent shear flows have become known as coherent structures.
(It is a matter of some controversy whether the introduction of this name into the subject was essentially giving a new name to an older concept or whether it involved a significantly new point of view.
In my own opinion it was largely the former.)
The name emphasizes that it is never adequate to describe the fluctuations in a turbulent flow as totally random.
There is much evidence that the fluctuation field involves distinctive patterns of motion.
In any  given flow, similar, although not identical, patterns occur repeatedly.
Each such coherent structure is identifiable for only a limited time.
There may sometimes be a tendency for a few of the structures to occur in a group or with a temporary periodicity, but, in general, the random aspect of turbulence is manifested in when and where coherent structures are to be found.
Figure 21.9 shows a simple example of the evidence for the existence of a high degree of organization in the larger scale motions.
It shows measurements in a two-dimensional wake of the correlation of the y-components of the velocity at two points separated firstly by a distance rx in the x-direction and secondly by a distance rz in the z-direction (both measured at a distance from the centre plane corresponding to , cf.
Fig. 21.5).
In isotropic turbulence these two curves would be identical.
It is seen that this is far from the case; in particular has a marked negative region, whereas  is   always positive.
This implies that the return flow for velocity fluctuations towards or away from the centre of the wake occurs dominantly in the upstream and downstream directions and little in the transverse (z and -z) directions.
Such a marked contrast between the curves seems unlikely to arise unless there are coherent features in the large eddy motion.
The accumulated evidence of measurements of statistical quantities (including conditional sampling, Section 19.6), flow visualization, and numerical experiments (Section 25.5) supports this inference for all flows that have been investigated in depth.
It also, of course, indicates what the coherent structures are like.
Different flows have similarities and differences.
Some of the structures observed in two-dimensional jets are, for example, similar to those to be described for wakes below, and a unified account for all flows can be attempted.
It is, however, still found necessary to investigate each flow of interest separately.
The structures are commonly described in terms of models, such as those illustrated by Figs. 21.10 and 21.11 below or those described in Section 21.6 for a boundary layer.
The word ‘model’ implies a physical description that does not attempt to be complete or accurate in detail but that encapsulates what are thought to be the central features of the phenomenon.
Although the existence of coherent structures is well established, there is often controversy as to the most appropriate models.
Also, new data still often lead to significant revisions.
Thus current models may be superseded in due course.
The large eddies are the longest-lived features of a turbulent flow.
Their existence is thus the reason for the long memory and slow approach to self-preservation mentioned in Section 21.1.
The main discussion below of wake structure is intended to apply primarily to a self-preserving wake.
First, however, we consider briefly what may happen further upstream, partly to illustrate how the long memory comes about and partly to make a link with earlier discussions of wakes; i.e. we look at the ‘intermediate wake’,(intermediate to the ‘near wake’ immediately behind the obstacle and the ‘far wake’which has become self-preserving).
We have seen in Sections 3.3 and 17.8 that, over a wide Reynolds number range, a turbulent vortex street is generated as a stage in the transition process of a cylinder wake.
There is no sharp distinction between the later stages of transition and the earlier ones of turbulent motion.
Thus the residual vortices of the street form coherent structures in the turbulent intermediate wake.
This implies that changes in the transition process, due to a change in the Reynolds number or to a different obstacle geometry, will lead to changes in the form of the coherent structures.
In a self-preserving flow the structure should be independent of such changes.
It is uncertain just how far downstream this independence is achieved.
It thus needs to be said that, although one expects that the models described below will apply to the wakes of other obstacles, they are based primarily on observations with circular cylinders.
There appear to be two distinct types of coherent structure in a two-dimensional far wake.
These are shown in highly schematic ways in Figs. 21.10 and 21.11.
These models were introduced quite early in the history of the topic (incidentally pre-dating the name ‘coherent structure’).
Ideas about other flows, particularly boundary layers to be considered in Section 21.6 have evolved greatly in the same period.
This may suggest that our ideas about wakes should undergo similar evolution, but recent experiments have tended to confirm the earlier picture.
The type of coherent eddy structure illustrated by Fig. 21.10 consists of a jet-like flow outwards from near the centre of the wake, producing a bulge on the interface between the turbulent and non-turbulent fluid.
As it travels outwards, the fluid tends to curve round in the flow direction.
The return flow towards the centre of the wake is more diffuse.
The figure shows schematically the pattern of motion produced by several such eddies.
There is in fact some disagreement about how much longitudinal periodicity is associated with this type of motion and whether    the eddies on opposite sides are correlated in position.
Probably several eddies commonly occur simultaneously, as shown in the figure, with an approximately but not exactly even spacing.
It is these eddies that relate particularly to the brief discussion above of the correlation measurements in Fig. 21.9.
Also, these eddies are particularly apparent in experiments with dyed wakes.
One needs cine-film to learn much from such flow visualization, but the eddies can be seen in Fig. 3.11.
Figure 21.11 is a model of the other type of coherent structure.
In each half of the wake the eddy consists of two parallel vortex tubes of opposite sense.
There is some flow along these tubes as well as around them, so that a spiralling motion results.
The tubes may not be straight, but one does not have enough information to assign any other shape to them.
Each tube has its axis in an xy-plane, with the part near the edge of the wake further downstream than the part near the centre, and the two tubes are separated in the z-direction.
Such motions occur simultaneously on both sides of the wake so that the structure as a whole has the shape indicated in the figure.
Suggested mechanisms for the origin of coherent structures include two important ideas.
Firstly, the mean velocity profile may be liable to local instability, somewhat analogous to instability of laminar flow.
Because it may be triggered by the vigorous smaller-scale fluctuations, such an instability will normally occur intermittently.
The resemblance of Fig. 21.10 to a portion of a vortex street (Section 17.8) strongly indicates that this type of process occurs in a wake (though there is the difference that the turbulent eddies are of limited extent in the third direction).
Secondly, there are processes which select certain patterns of motion in  preference to others.
The idea of vortex stretching (Section 6.6) is central to these processes, and one notes that the vortex tubes in Fig. 21.11 are aligned so that they are being stretched by the mean shear — cf.
Fig. 6.10 (more formally, they are approximately along the positive principal axis of the mean flow rate of strain tensor).
A much fuller theory has been developed of how motions of this type can be generated through the action of the mean shear on initially isotropic fluctuations, but the details are not apparent without the mathematical analysis.
It is very likely that the two processes summarized above are simultaneous processes within an overall mechanism that is not yet fully understood.
Correspondingly, the two eddy types in Figs. 21.10 and 21.11 may be related in some way rather than occurring independently.
It is perhaps significant that stretching of the vortex tubes in Fig. 21.11 could be produced by the structure in Fig. 21.10 as well as by the mean flow, but this is a matter requiring further investigation.
21.5 Turbulent motion near a wall
The ideas developed so far provide a very incomplete story when the flow is adjacent to a solid boundary.
At such a boundary (at rest), the boundary condition that the fluid velocity is zero applies at every instant.
Thus it applies to the mean velocity and to the fluctuations separately,
The fact that the fluctuations drop to zero at the wall has the particular implication that the Reynolds stress is zero:
The only stress exerted directly on the wall is the viscous one.
Away from the wall, on the other hand, the turbulence generates a Reynolds stress, large compared with the viscous stress, in the usual way.
The total stress  (we are still considering a two-dimensional flow for which the boundary layer equations apply).
This cannot vary rapidly with y without producing a very large mean acceleration and thus requiring an improbable mean flow distribution.
(For example, in channel flow with no variation of mean quantities in the x-direction, τ varies linearly across the channel as it does for laminar motion — the first integral of eqn (2.6).)
Consequently, the viscous stress close to the wall must match up with the Reynolds stress further out.
Although τ varies only slowly, and    each vary rapidly, the former being much larger at the wall than in laminar flow but becoming very small away from the wall, the latter being large away from the wall and zero at the wall.
Figure 21.12 illustrates this by showing distributions of τ and of its two contributions measured in a zero-pressure-gradient boundary layer.
The region where the viscous stress makes a large contribution is a small fraction of the total boundary layer thickness (note the change in abscissa scale).
To generate this distribution of viscous stress, the mean velocity profile must rise steeply at the wall and then become comparatively flat.
Figure 21.13 compares a typical turbulent boundary layer profile with a corresponding laminar one.
Parallel considerations apply to turbulent pipe flow.
Figure 21.14 compares laminar and turbulent mean velocity profiles, firstly for the same flow rate and secondly for the same pressure gradient.
It is now clear that the presence of the wall causes the fluid viscosity to enter in a much more important way into the dynamics of turbulent motion than it does for free flows.
The concept of Reynolds number similarity is no longer so useful.
This effect extends to the fluctuations as well as to the mean flow.
Figure 21.15 shows distributions of  and of its components ,, and  across a boundary layer.
(The reason for the alternative coordinates will be seen later.)
Large variations are to be observed with strong maxima close to the wall.
(Figure 21.15 shows also the distribution of the   intermittency factor and it is evident that intermittency is affecting the intensity distributions only at larger values of .)
This observation can be interpreted in connection with the turbulent energy balance, Fig. 21.16.
The rate of energy production,, also has a large peak close to the wall.
The reason is related to the above discussion of the stress.
Very close to the wall  is small and so there is little energy production; far from it, is small with the same consequence.
Mathematically, and, if τ is treated as a constant, this is a maximum when 
Thus the energy production is largest in the vicinity of the changeover from a predominantly viscous stress to a predominantly turbulent one.
The energy balance diagram, Fig. 21.16, shows that over the region where the production is high the other important term is the dissipation; the remaining terms in eqn (19.22) are much less significant (apart from some rather complicated transfer processes very close the wall).
The inner part of the boundary layer is thus sometimes said to be in ‘local equilibrium’, meaning that there is a local balance between the process supplying energy to the turbulence and that removing it.
Towards the outer edge of the boundary layer the quantities in eqn (19.22) are much smaller, but all the terms are now important.
The dissipation somewhat exceeds the production and there is also a loss by advection — corresponding, as in a wake, to the supply of energy to newly turbulent fluid.
These losses are compensated by turbulent transport.
The turbulence in the outer region is maintained by that in the inner region.
More detailed consideration of these and related ideas has led to a division of the turbulent boundary layer into inner and outer regions.
The dynamical processes occurring in the latter are not dissimilar from those in a wake, but the inner region requires its own model.
The ideas that have been developed for this region can be applied to most turbulent flows adjacent to a wall: for example, to turbulent channel and pipe flow (although not, for example , to a boundary layer close to separation).
Because of the local equilibrium, the structure of the inner region is substantially independent of the outer flow.
We thus want to specify the flow in the ‘wall-region’ by a velocity scale characteristic of this region.
This is provided by τ W the value of at the wall, which has the dimensions of density × (velocity)2 .
Hence we  define  as our velocity scale.
u τ depends on the flow as a whole, but once it is specified, the structure of the wall region is specified.
It is confirmed experimentally that the turbulent intensity distributions scale with u τ.
For example, the maximum value of  is always about .
The relationship between u τ and the external velocity U O for a boundary layer depends (rather weakly) on the Reynolds number.
Under typical laboratory conditions, is in the range 0·035 to 0·05.
Conditions in the wall region are now specified by the three parameters: u τ, the distance from the wall y, and the kinematic viscosity v. The mean velocity U is a function of these, from which dimensional considerations give 
It is again confirmed experimentally that various turbulent wall flows have a common profile of this form.
We have seen that the viscosity is important only very close to the wall.
With increasing y it ceases to play a role long before parameters other than those in (21.14) have an influence.
One can then say that the mean velocity gradient depends only on u τ and y, although one cannot say the same for U because it is separated from its origin by a region in which v is important.
Dimensional analysis applied to (21.16) gives  where K is a universal constant (the Kármán constant) of turbulent wall flows.
It is found experimentally that K=0·41.
Integration of (21.17) gives, in a form corresponding to (21.15), where A is another constant.
This logarithmic profile is one of the most famous results in the study of turbulent flows.
In Fig. 21.17, the velocity profile of Fig. 21.13 is plotted with log-linear coordinates and the straight line corresponding to eqn (21.18) is evident.
The profile departs from the logarithmic form when , because of the importance of viscosity in this region.
Very close to the wall viscous action is dominant.
At the wall  and, taken in conjunction with the continuity equation  this gives  Hence, and treating τ as a constant in eqn (21.10)
We thus expect there to be a significant region right next to the wall in  which the velocity profile is linear,
The curve corresponding to this is included in Fig. 21.17 (the logarithmic plotting now serving to expand this region) and it is seen that the experimental points fall on it for .
This thin region is known as the viscous sub-layer.
Sometimes it is called the laminar sub-layer, but that is less accurate as it contains large velocity fluctuations; and  are free to rise more rapidly from the wall than .
Although the viscous sub-layer is very thin, a substantial fraction of the total mean velocity change across the boundary layer occurs within it.
The upper limit in y of the logarithmic profile occurs where dynamical processes relating to the boundary layer as a whole become significant.
This is observed experimentally to occur around , where  ta; is the total boundary layer thickness (defined, say, so that U = 0·99 U O; at y = δ).
The corresponding value of  (about 200 in Fig. 21.17) depends on the Reynolds number .
21.6 Coherent structures in a boundary layer
The fact that any turbulent flow involves large eddies with a coherent structure was introduced in Section 21.4.
Wall flows have some special features which we illustrate by considering boundary layers.
We have seen that models of these structures are synthesized from various types of measurement and observation; in the case of boundary layers, however, flow visualization has been particularly influential.
Again, still pictures can provide only a limited impression of what is seen in motion, but Figs. 21.18 and 21.19 illustrate important aspects.
The first thing that may be noted is that the contrast between different parts of Fig. 21.18 provides immediate evidence for marked organization of the structures (the point that was illustrated in the case of a wake by Fig. 21.9).
These photographs were obtained by illuminating a very thin layer of a smoke-filled boundary layer.
In all four pictures the illuminated plane is at 45° to the flow direction (and across the flow in the z-direction); but in parts (a) and (c), it is tilted downstream (i.e. the top of the picture showing the outer part of the boundary layer is downstream of the bottom showing the part close to the wall), whereas in parts (b) and (d) it is tilted upstream.
Parts (a) and (b) are from the same flow, as are parts (c) and (d)— the difference between the two flows being in the Reynolds number.
The very different patterns in the different       orientations in each flow must reflect orientation of the coherent structures.
In Figs. 21.18(a) and (c) the structures appear to be orientated approximately in the plane of the picture whereas in (b) and (d) they appear to intersect the new plane.
This interpretation is confirmed by correlation measurements of which an example is given in Fig. 21.20; this shows the correlation of x-components of the velocity as a function of separation in the x-direction, and we consider curve B for which there is also a (fixed) separation in the y-direction: the asymmetry of this curve about r x =0 illustrates the tendency for the large eddies to be tilted downstream.
The accumulated evidence, centred on the interpretation of the flow visualization experiments illustrated by Fig. 21.18, suggests that a predominant feature of boundary layer turbulence is the ‘hairpin' vortex or ‘horseshoe’ vortex shown schematically in Fig. 21.21; which name more accurately summarizes the geometry depends on the Reynolds number.
The smoke patterns in Figs. 21.18(b) and (d) are produced    by the intersections of the vortices with the plane, and the motions associated with the two arms of the hairpin can be identified in places.
Note that it is motions in this plane (and vertical in the pictures) that generate the Reynolds stress (cf.
Fig. 19.2).
The hairpin or horseshoe structure is also found in numerical simulations (Section 25.5) as is illustrated by Fig. 21.22.
This shows the projection on a plane tilted at 45° downstream (cf.
Fig. 21.18(a) and (c)) of a computed instantaneous vorticity distribution, and patterns that correspond to the structure are picked out by shading.
The structure has similarities to one half of the double roller eddy of wakes (Fig. 21.11).
The vortex stretching process outlined in Section 6.6 is undoubtedly again relevant.
However, it is thought that the boundary layer vortices derive their vorticity originally from the viscous sub-layer (which has, of course, no counterpart in a wake); this is then advected and stretched by a combination of the mean shear and the turbulent fluctuations to give the hairpin shape.
The evidence for this relates to the observed length scales of the vortices; the length of the vortices (l 1 , in Fig. 21.21) is of the order of the total boundary layer thickness, whereas the cross-section (l 2 ) is of the order of the viscous sub-layer thickness.
This means that the ratio l 2 /l 1 varies with the Reynolds number (is in fact approximately inversely proportional to Re).
It accounts for the differences between (a) and (c) and between (b) and (d) of Fig. 21.18.
There is, however, a suggestion that there is a hierarchy of vortices of different sizes, of which the thinnest are the most apparent in flow visualization.
Figure 21.19 illustrates other aspects of boundary layer structure.
In  this figure the flow visualization used the hydrogen bubble technique (Section 25.4), enabling ‘dye’ to be released in initially square patches from a fine wire stretched across the boundary layer perpendicular to the wall.
The two pictures show the same flow at different instants, at which respectively an ‘eruption’ and an ‘inrush’were occurring.
The model based on these two types of coherent structure — particularly the former — has been central to our understanding of turbulent boundary layers for two decades (possibly to the neglect of other aspects).
The relationship to the hairpin vortices described above is not wholly clear.
The most likely possibility is that a number (of uncertain size but probably Reynolds number dependent) of the hairpin vortices occur within an eruption and maybe also within an inrush — an interpretation suggested primarily by numerical simulation.
Another name for an eruption is a ‘burst’(but this is sometimes used to mean the process generating an eruption rather than the eruption itself; conversely, it has been used to mean a sequence of an eruption plus an inrush).
An eruption originates close to the wall, where there are regions, separated in the z-direction, of fluid moving faster than average downstream and fluid moving more slowly than average.
Fluid in the latter regions intermittently erupts into the main body of the boundary layer; the viscous sub-layer appears to ‘burst’.
The motion away from the wall is apparent in Fig. 21.19(a) and the spacing of the dye patches shows also that this fluid is moving downstream more slowly than average.
Eruptions have a characteristic structure.
Separate eruptions are similar to one another, but they are not identical; statistical fluctuations occur as with any feature of a turbulent flow.
In particular, eruptions vary in size; some, but not all, penetrate right through the boundary layer and contribute to the intermittency at its outer edge.
In its main features an inrush is just the reverse of an eruption.
Fluid moving faster than average downstream is carried in towards the wall.
This gives it an even more marked excess longitudinal velocity and this feature is particularly apparent in the inner half of the boundary layer.
The slight variation of the longitudinal velocity in Fig. 21.19(b), as indicated by the spacing of dye patches, implies that fluid close to the wall is moving much faster than average.
The eruptions and inrushes both have structures generating a large Reynolds stress.
In fact, between them, they are probably responsible for almost the whole observed Reynolds stress.
There is little interaction between the turbulence and the mean flow in the intervals between eruptions and inrushes.
It is likely that these coherent structures originate through an intermittent instability of the velocity profile.
This is partly analogous with the origin of the jet-like eddies in a wake (Fig. 21.10) discussed in  Section 21.4, except that it may not be so much an instability of the mean velocity profile as an instability of a profile itself temporarily generated by the turbulent fluctuations.
Because the eruptions burst from the viscous sub-layer, it is often suggested that they are produced by an instability there — particularly as some features of the motion in this region resemble features of transition to turbulence in a boundary layer (for example, the development of fast- and slow-moving regions mentioned above resembles the development of three-dimensionality illustrated by Fig. 18.1).
However, this interpretation faces the difficulty that essentially identical large-scale motions occur in boundary layers on rough walls, for which the flow structure close to the wall is quite different.
In Section 21.5, it was argued that the only length scale relevant to the boundary layer dynamics in the wall region but outside the viscous sub-layer is the distance from the wall y.
Some of the features of the coherent structures raise doubts about this conclusion.
Firstly, there is the observation noted above that the length scale l 2 in Fig. 21.21 is related to the viscous sub-layer thickness (i.e. is proportional to  and much smaller than y in the region concerned).
This makes it no longer obvious that v should be excluded from eqn (21.16).
Secondly, some features of the large eddies have a length scale given by the total boundary layer thickness even when y is much less than this; an example is given by curve A in Fig. 21.20, where R xx remains significant at values of r x of the order of  ta; and large compared with y.
This makes it no longer obvious that δ should be excluded from eqn (21.14).
Yet the logarithmic profile (21.18) derived from (21.14) and (21.16) is very well established observationally and there can be little doubt that the derivation of it correctly reflects the way in which the turbulence determines the mean velocity distribution.
The suggestion, mentioned earlier, that there is a hierarchy of hairpin vortices was made in part to help with the first of these problems.
The second has led to the idea that there is a ‘universal’ or ‘active’motion, with a length scale proportional to the distance from the wall, and an ‘irrelevant’or ‘inactive’motion, with a much larger length scale.
However, this matter cannot be considered resolved and may well be central to future development of our understanding of wall flows.
21.7 Turbulent stratified flows
There are several important ways in which turbulent shear flows may be modified — by a pressure gradient, by wall curvature, by rotation of the system, or by stratification.
As an example of such effects we consider stratified flows, which have received particular attention because of their meteorological applications.
Many of the important ideas have been developed in the context of such applications, principally in relation to the lowest layers of the atmosphere as the wind blows over hot or cold ground.
This section looks briefly at some of the basic ideas and illustrates them with the results of some laboratory experiments.
We are concerned with the predominantly horizontal mean flow of a fluid whose mean density varies vertically.
The mean velocity also varies vertically, and we shall confine attention to two-dimensional flow.
Hence, the specification of the situation is primarily in terms of the two gradients, and .
The velocity gradient can lead to generation of turbulence in the usual way through the action of inertia forces (Section 19.3).
The role of the density gradient depends on its sign.
If the density increases upwards, then buoyancy forces provide an additional source of energy for the turbulence.
If the density decreases upwards, then the turbulence must do work against buoyancy forces, which therefore produce a loss of turbulent energy additional to viscous dissipation; turbulence cannot persist when the density gradient is too large.
From the considerations of Chapter 15, we expect the quantitative formulation of the relative importance of inertia and buoyancy forces to be made in terms of some form of the Froude number (eqn (15.7)).
The role of the velocity gradient in the dynamics of turbulent flow suggests that U/L should be replaced by dU/dz.
Also it is convenient to work in terms of the reciprocal of the square of this Froude number; that is in terms of 
This is called the Richardson number (sometimes the gradient form of the Richardson number to distinguish it from other forms defined somewhat differently).
As was to be expected, it depends on the sign of the density gradient but not on that of the velocity gradient.
Negative Richardson number corresponds to a destabilizing density gradient; both shear and buoyancy give rise to turbulence generation.
When -Ri is small, the former is dominant and the motion is essentially of the type we have been considering hitherto.
When -Ri is large, the latter is dominant and the turbulence may be more like the free convection turbulence to be described in Section 22.7.
Positive Richardson number corresponds to a stabilizing density gradient; turbulent motion cannot be sustained when Ri becomes large.
Various experiments have been carried out to discover the more  detailed dynamics of these processes.
The simplest configuration in principle (although not in practice) is a flow with uniform velocity and density gradients.
Such a configuration has been achieved using a special wind-tunnel with graded heated elements and flow resistance grids at its entry.
It was used for investigations with positive Richardson number.
The numerical details of the results may not be generally applicable, since the flow was still developing in the downstream direction at the observing station (and the Reynolds number may not have been high enough for Ri to be the only parameter); but the results should indicate well the general trends.
The damping action of the stratification on the turbulence is illustrated by Fig. 21.23, which shows the variation of the temperature fluctuations relative to the temperature gradient as a function of Richardson number (since the geometry was constant, the fact that the ordinate is not non-dimensional is unimportant).
The turbulence is almost completely suppressed when Ri reaches 0·45.
Changes in the structure of the turbulence also occur.
Figure 21.24 shows the variations of the correlation functions  and  (where Θ is the temperature fluctuation); the former is the normalized Reynolds stress, whilst the correlation  plays a role in the transport of heat by the turbulence corresponding to the role of the Reynolds stress in momentum transport.
The latter falls off more rapidly, indicating that the turbulence changes in a way that makes it    relatively less efficient as a heat transfer mechanism than as a momentum transfer mechanism.
This can be understood physically in this way: a fluid particle that is displaced but then falls back to its original position without any mixing with its new environment does not transfer any heat, but it can transfer momentum through the action of pressure forces.
At the higher values of the Richardson number, the turbulence may be thought of as random superposition of internal waves (Section 15.4).
In other situations, complexities may arise from variations in the Richardson number, as defined above, from place to place.
As an example of the consequences of this we consider flow close to a horizontal upward-facing heated or cooled surface — sufficiently close that the velocity scale is determined entirely by the wall stress and is t τ as discussed in Section 21.5.
The temperature scale is then similarly determined by the vertical heat transfer, which, like the stress, varies little in the region under consideration.
If H is the rate of heat transfer per unit area (taken as positive if the transfer is upwards, for example from hot ground to cooler air), this scale is  u τ enters this expression because the temperature variations needed to produce a given heat transfer are smaller when the turbulence is more vigorous.
Specification of the problem in terms of u τ and Θ H is particularly useful in application to the atmospheric boundary layer, as these are often known when the dynamics of the whole system are not.
If stratification is having little effect on the dynamics of the turbulence, we know that the velocity gradient in the region under consideration is given by eqn (21.17), t 
Similar considerations applied to the temperature field lead to:
Whether the turbulence is indeed unaffected by the stratification is indicated by the Richardson number 
The Richardson number and thus the relative importance of the stratification increase with height.
It is useful to introduce the height |L| at which |Ri| = 1,
This is the Monin-Obukhov length; like the Richardson number it is defined to be positive when the stratification is stabilizing and negative when it is destabilizing.
|L| is more precisely the height at which |Ri| would equal unity if the profiles were unchanged by the stratification.
However, L can be used as a length scale in the analysis of the changes due to stratification.
Equation (21.27) may be re-stated by defining  and saying that φ = 1 when Ri = 0 (or L = ∞).
It may then be extended to    non-zero Ri by saying  provided that the conditions required for (21.27) are still fulfilled (i.e. z is within the wall layer but outside the viscous sub-layer).
Figure 21.25 shows some observations in stably stratified flow that confirm (21.32).
Equation (21.29) implies that, when z is sufficiently small compared with |L|, the effect of stratification is slight.
Provided z is still large enough compared with , the logarithmic profile will be observed.
This expectation is confirmed by the region in Fig. 21.25 for which φ = 1.
However, departures from this occur at lower values of z/L than one might guess on the basis of eqn (21.29); they are detectable for z/L above about 0·01 and very substantial when .
Generally, the effects of stable stratification tend to be underestimated by simple order-of-magnitude considerations (cf.
Fig. 21.23).
Moreover, analysis of the data in the above way disguises a significant aspect of the differences between a stratified boundary layer and a corresponding unstratified one.
where U O is the free-stream speed, is changed by the stratification.
(We are here considering primarily laboratory experiments where the comparison may be made directly.
In meteorological studies, the information for a comparison is unlikely to exist, and indeed U O may not be a well-defined quantity whilst u τ is.)
The  reason is the higher Richardson number in the outer part of the boundary layer.
Consider for example the case when Ri becomes large enough for the turbulence to be suppressed in the outer region, so that the Reynolds stress becomes small there.
It is this stress that keeps the fluid closer to the wall moving; in its absence this fluid is slowed down by viscous friction at the wall.
Experimental observations showing this effect clearly were made in the boundary layer under the top wall of a wind-tunnel, one section of which was heated.
Turbulence established before the heated section decayed in the stably stratified region.
Figure 21.26 shows velocity profiles at two distances downstream from the start of the heated section.
The deceleration of the fluid close to the wall is apparent.
(It is this effect which is responsible for the common observation of the wind ‘dropping’ on a clear evening as the ground cools by radiation.)
Figure 21.25 related to the flow far downstream of the start of wall cooling (the wall being a bottom one).
The effect of change in the outer layer on the inner is illustrated by the lines on the figure.
These show   how the data trend is shifted if φ is calculated using the value of u τ that would exist in the absence of stratification instead of the actual value.
(For the third set of data the shift is negligible.)
This illustrates better the total effect of stratification on the boundary layer (but the reduction of all cases to a single curve is lost).
We have looked at the effects of stratification on boundary layers primarily in terms of data for stabilizing stratification.
Similar principles apply to destabilizing.
Quantitatively the effects are somewhat smaller; the departure — now a decrease — of φ from unity at any given  is less.
When the destabilizing stratification is strong, becomes large in the outer part of the boundary layer and buoyancy is the main source of turbulence generation there.
A principal feature of the flow as a whole may then be the following: large eddies of the eruption type originate close to the wall as described in Section 21.6; as they move away from the wall they become increasingly influenced by buoyancy, until, at large heights, they resemble the free convection plumes to be described in Section 22.7.
21.8 Reverse transition
In the last section, we saw an example of turbulence suppression when stabilizing stratification was imposed.
Strong enough stratification can force the flow to revert fully to laminar motion.
Such a process, known as reverse transition or relaminarization, can occur in a variety of configurations; other examples include pipe and channel flows in which the Reynolds number is reduced by a change of geometry; boundary layers that enter a region of strongly favourable pressure gradient; boundary layers on convex walls; and shear flows in rotating fluids.
Reverse transition involves its own characteristic mechanisms; it is not just a matter of the turbulence energy production being insufficient to sustain the turbulence against increased viscous dissipation or some other process (e.g. buoyancy in a stratified flow).
The production mechanism is itself affected.
As an example, we may consider observations made in a channel of which the dimensions gradually change with distance downstream from 12·7 × 76 mm to 12·7 × 228 mm; the consequent drop in speed reduces the Reynolds number (based on the smaller dimension) from a value at which the flow is turbulent to one at which reverse transition occurs.
Figure 21.27 shows maximum values, with respect to position across the channel, of the intensity of longitudinal velocity fluctuations and of the correlation coefficient that provides the Reynolds stress, as functions of the distance downstream from the end of the   cross-section change.
One sees that, as the turbulence decays, the velocity components become less correlated.
The structure of the turbulence is thus changing in a way that produces a faster approach to laminar motion, perhaps because the generation of eruptions (Section 21.6) is suppressed.
22
CONVECTION IN HORIZONTAL LAYERS
22.1 Introduction
We had a preliminary glance at this topic in Section 4.4; but it was only a glimpse of a very large topic.
The reason that it has received so much attention is not primarily that it is of practical importance (although it has applications, e.g. Sections 26.2, 26.5, 26.6), but rather that it has become a context for the development of ideas about the consequences of instability and evolution towards turbulent motion.
As a situation in which nothing whatsoever of interest would happen but for instabilities, it is a natural candidate for this role.
The configuration with which we are concerned is that of Fig. 4.1(b): a layer of fluid is bounded by two horizontal rigid planes a distance d apart and at different constant and uniform temperatures T 1 and T 2 ; the lower plate is hotter than the upper .
Adopting current usage rather than historical accuracy (Sections 4.4, 4.5), this is called the Bénard (or Rayleigh-Bénard) configuration.
Variations of the theme, e.g. with different boundary conditions or with internal heating replacing heating from below, have been of some interest; but all the specific results in this chapter will relate to the conditions above.
The aspect ratio of the layer is defined as the ratio of the (smallest) horizontal dimension b to d.
In this chapter we suppose that b/d is sufficiently large that one may think in terms of a horizontally infinite layer, although we shall mention lower aspect ratio layers briefly and return to them in Section 24.7.
Horizontally restricted layers are generally considered to come into the category of Bénard convection provided that the boundary conditions on the end-walls are such that there is still an equilibrium solution (stable or unstable) of the equations with the fluid at rest.
We suppose that the Boussinesq approximation may be made and so the discussion of dynamical and thermal similarity in Section 14.5 applies.
For a reason that will become apparent in the next section, it is usual to specify Bénard convection in terms of the Rayleigh number   and Prandtl number  rather than the Grashof number Gr and Prandtl number.
The Nusselt number  has a particularly simple and useful interpretation when the length scale is the thickness d of a layer with temperature difference  across it.
It is the ratio of the actual heat transfer to the heat transfer that would occur by conduction alone if the fluid remained at rest.
Onset of convection is thus marked by Nu increasing above unity.
22.2 Onset of convection
The key point in any discussion of Bénard convection is that there is an equilibrium solution with the fluid at rest.
If motion occurs, it does so as a consequence of instability of this equilibrium.
Hence stability theory is needed from the outset.
For an infinite expanse of fluid with the density increasing upwards, the physically evident instability is contained in the set of eqns (15.25)—(15.27) for small disturbances in a stratified fluid.
The square of the Brunt-Väisälä frequency  is negative in this case.
Hence the frequency ω of eqn (15.38) is an imaginary quantity  and the amplitude of the disturbance is proportional to , with σ real and positive.
The case  corresponds to instability.
(As in Section 17.3 instability occurs whenever one amplifying solution exists.
The existence of a second decaying solution, which would occur on its own only if one had an initially large disturbance of just the right configuration, is irrelevant.)
For a layer of finite depth, the instability is modified by viscosity and thermal conductivity, together with the boundary conditions.
The previously amplifying solution may now become a decaying one (whilst the previously decaying one always remains so).
A full stability analysis is needed to discover when convection will occur.
The principles and general procedures of such analyses have been discussed in Chapter   17 — with Couette flow stability (Section 17.5) being the most closely analogous case — so we can consider the theory in outline.
Using Cartesian coordinates with z vertical, a velocity field of the form  together with temperature and pressure perturbations of similar form are superimposed on the equilibrium configuration.
The equations of motion are used to investigate the sign of σ (which turns out to be always real).
The results are found to depend only on the total wavenumber  and not on κ x and κ y individually.
Consequently the stability loop is the locus of σ = 0 on a plot of non-dimensional wave number  versus the Rayleigh number.
This locus is independent of the Prandtl number, and resembles the corresponding locus for Couette flow in Fig. 17.10.
The most important quantity is, of course, the Rayleigh number below which a  for all ξ and above which  for some ξ.
This comes out to be 
(Since the wavenumber has been allowed to take any value the layer is implicitly unlimited horizontally.
Also the value 1708 relates specifically to the boundary conditions — rigid, isothermal walls — to which we are confining attention.)
This is another of the successes of linear stability theory.
Whether or not motion occurs is most precisely determined experimentally by its effect on the heat transfer.
Figure 22.1 shows an example of the observed variation of Nusselt number with Rayleigh number.
Nu is equal to 1 when the fluid is at rest and greater than 1 when it is convecting (Section 22.1), and it is apparent that the onset of motion occurs close to the predicted value of Ra.
22.3 Convection just after onset
What is the consequence of the instability discussed above?
In other words, what sort of flow pattern will be found when the Rayleigh number is above, but not too much above, its critical value?
As emphasized in Section 17.4, linear stability theory does not in principle predict the type of motion that eventually occurs as a result of this growth — non-linear processes must always come into play before that stage.
Nevertheless we saw in the context of rotating Couette flow (Section 17.5) that there are some cases (summarized by curve A of Fig. 17.6) for which there are marked similarities between the unstable modes and the observed motion when the critical condition is just exceeded.
Bénard convection is in fact another such case.
Thus the fact that, for Rayleigh numbers only a little above critical, there is only a limited range of unstable wavenumber κ might be thought adequate information for a knowledge of the flow.
However, restriction to a single wavenumber does not uniquely specify the flow pattern, for reasons connected with eqn (22.7).
Not only may κ x take a whole range of values for a given κ, but also linear combinations of solutions of the form (22.6) with different κ x but the same κ are single wavenumber patterns.
In consequence, there are many single wavenumber patterns, some of them of a complexity that makes them not instantly recognizable as such; for example, one of them is a hexagonal pattern rather like Fig. 4.9.
All such patterns occur with equal probability on linear stability theory.
Consequently, the statement that the developed convection pattern is broadly similar to a single wavenumber pattern still allows a variety of  possibilities.
It is not surprising that, as noted in Section 4.4, the observed flow can depend markedly on departures from the simple specification of Bénard convection, notably temperature variation of viscosity (e.g. Fig. 4.9).
In this chapter, however, we are focussing attention on the behaviour when the effect of such departures can be assumed to be slight.
Then the pattern actually adopted consists of long parallel rolls; i.e. the single wavenumber pattern that it resembles may be taken as having (cf. (22.7))
This, of course, involves an appropriate choice of axes; and, since there is no preferential horizontal direction, the choice must be made after, not before, the rolls have formed.
The knowledge that this is what occurs comes primarily from stability theory — applied not to the rest configuration as in Section 22.2, but to the various possible convective structures.
This indicates that, were one of the other patterns to arise somehow, it would undergo a transition to the roll pattern.
We have seen an experimental realization of this type of convection in Fig. 4.7.
Figure 22.2 is a sketch of another pattern from a similar experiment (the lines correspond to bright lines in the shadowgraph).
In both cases there is a very clear roll pattern, but with conspicuous defects in it.
Such defects commonly occur in Bénard convection experiments, as may be understood in the following way.
Suppose that the temperature difference across a Bénard layer of very large horizontal extent is increased so that the Rayleigh number passes through its critical value.
Convection will be initiated in various parts of the layer, giving rise to the roll pattern discussed above.
The orientation of the rolls will depend on whatever small perturbations happen to be present as the temperature difference is raised.
In fact rolls of different orientation may be generated simultaneously in different parts of the   layer sufficiently far apart that they are not initially interacting.
There is a striking analogy here with crystal growth, except that it happens in two dimensions, not three.
When a crystal is formed, for example by cooling of a melt, crystal grains of different lattice orientation are formed in different places; as the whole material solidifies these meet on grain boundaries — the counterpart of the line from A to B in Fig. 22.2.
(Grain boundaries are also conspicuous in Fig. 4.7, particularly one running across the picture just above the middle.)
Counterparts of other types of crystal defect may also be found in a ‘convection lattice’; dislocations are to be seen at P and Q in Fig. 22.2.
22.4 Evolution with increasing Rayleigh number: general remarks
The fact that a convection pattern, occurring when Ra is a little above its critical value, commonly contains defects has very important consequences for the ways in which the convection may evolve as Ra is further increased.
The ‘grain boundaries’ and dislocations can have a strong effect on subsequent developments — as we shall consider in Section 22.6.
However, there is also much interest, particularly in connection with how stability theory and transition to turbulence are related, in knowing how a convection pattern without these defects evolves.
Just as in crystallography, if one wants a ‘perfect crystal’ one has to adopt special procedures to obtain it.
This is the situation to which we shall give fullest consideration (Section 22.5).
Although the critical Rayleigh number is independent of the Prandtl number, subsequent developments are not.
In general, corresponding developments tend to occur at a lower value of Rayleigh number when the Prandtl number is lower.
As an extreme example, in mercury, with Pr=0·025, it is difficult to observe any form of convection other than turbulent.
However, there are not only quantitative but also qualitative differences in the evolution at different values of Pr.
We thus have to consider a typical evolution rather than attempt to cover all possibilities.
That remark applies even though we are confining attention to cases in which ‘non-ideal’ features such as temperature variation of viscosity are supposed negligible.
Of course such features are never totally absent in experimental work.
However, one can do experiments in which it is reasonable to suppose, on the basis of a synthesis of experimental and theoretical results, that they are not grossly modifying the flow.
Much the same comment may be made about the effect of side-walls.
In this chapter we discuss the layer as if it were horizontally infinite, and thus consider experiments with large aspect ratio — accumulation of observational experience and theoretical results being needed to decide  what is large enough.
There is, however, some interest in the opposite extreme when the side-walls are very definitely constraining the flow.
Observations with apparatuses of relatively small aspect ratio have led to interesting comparisons with theories to be discussed in Chapter 24.
In this situation the flow is affected not only by the velocity boundary conditions imposed by the vertical walls but also by the way in which these walls affect the temperature field.
Consequently, there can again be a burgeoning of subdivisions.
What is important, however, is that in any particular apparatus one can observe a repeatable sequence of developments (e.g. as Ra is increased).
Quantitatively this is liable to be peculiar to the apparatus, but, at least sometimes, such developments occur in ways that seem to have very general significance.
That remark may sound paradoxical; clarification must await Section 24.7.
22.5 Evolution of defect-free convection
The principle of the experiments considered in this section has been mentioned in Section 22.4.
Very regular patterns of convection are deliberately induced.
This may be done for example by heating the layer radiatively through a grid of the appropriate geometry.
This heating is imposed before the vertical temperature difference and, of course, produces weak convection.
Then when the vertical difference is introduced making the Rayleigh number supercritical, the Bénard convection also adopts this pattern.
The horizontally varying heating may then be switched off, and the evolution of pure Bénard convection with this pattern investigated.
Controlling the flow in this way is obviously comparable with the introduction of periodic disturbances to control the development of shear flow instabilities (Sections 17.7, 18.1).
There is, however, the difference that in those cases the control is used to investigate the first instability whereas here it is needed only for the later stages.
This procedure, called pattern control, enables one to investigate, experimentally in addition to theoretically, what happens to a ‘perfect crystal’ of rolls (Fig. 22.3) as the Rayleigh number is increased.
We will suppose that the wavenumber of the rolls is similar to that that occurs without pattern control; i.e. the control serves only to remove the defects, not to impose an unusual wavenumber.
(More precisely, we suppose that the imposed wavenumber is within a range that exists stably in a Rayleigh number range a little above critical.
Experiments have been done with imposed wavenumbers outside this range, and some interesting instabilities observed by which the wavenumber adjusts to a stable value.
However, these will not be described here.)
The sequence of pictures in Figs. 22.3–22.8 shows convection patterns occurring at Rayleigh numbers ranging upwards from the critical value.
The pictures are shadowgraphs (see Section 25.4); the bright regions correspond to depth-averaged temperature being high and the dark regions to its being low.
Considered as a whole the pictures provide a nice illustration of transition to turbulence.
The first and last pictures contrast highly ordered motion at one end of the sequence with turbulent motion at the other end, and it is seen that there is a series of intermediate stages by which transition from one to the other takes place.
Incidentally it should be remembered that the first picture (Fig. 22.3) is actually the second stage of the sequence, because this pattern is itself the consequence of an instability that occurs only if the Rayleigh number is high enough (Sections 22.2, 22.3); however the first stage could only be represented by a picture which was ‘a perfect and absolute blank’.
It should also be noted that there is one difference between the earlier and later pictures of the sequence not apparent by looking at them.
The motion changes from being steady to unsteady, as discussed below.
Hence, Figs. 22.3 and 22.4 would look identical if they had been taken      earlier or later, but the other pictures would not — they would give the same overall impression, but details would be different.
In particular, the spatial irregularity apparent in Fig. 22.8 reflects irregular fluctuations in time.
As one goes through the sequence from ordered to turbulent motion, the proportions of information provided respectively by theory and by experiment alter.
The earlier stages can be discovered almost entirely by      theoretical analysis, with experiments serving largely to confirm the predictions (and incidentally to provide illustrative material such as that being used here).
At somewhat higher Rayleigh number theory still provides much understanding of the observations, but the experiments are less peripheral; e.g. they may indicate just what flow patterns should be included in the theoretical analysis.
The later stages, at still higher Rayleigh number, have not yet yielded to theoretical analysis and our knowledge of them comes entirely from experimental observation.
Let us look in more detail at the intermediate stages of the sequence.
A set of pictures, such as Figs. 22.3–22.8, at various values of the Prandtl number (determined, of course, by the availability of good illustrations) does not strictly represent a unified sequence.
However, so long as the figures are seen as illustrations of typical developments and not as a catalogue of all possible types of flow, this may not matter much.
It has already been remarked that corresponding developments occur at lower Rayleigh number when the Prandtl number is lower.
Consequently a development described as arising from an increase in Ra may sometimes be illustrated by a picture taken at lower Ra but also lower Pr.
The first development as Ra is increased from a value a little above critical is a change in the geometry of steady convection.
This is illustrated by Fig. 22.4.
The two parts of this figure are for different values of the Prandtl number.
Although, for the most part, we are not considering all alternatives, there is such a striking difference in this development for Pr greater than or less than about 10 that a single illustration would be inadequate.
In all of Figs. 22.3, 22.4(a) and 22.4(b), a uniform array of convection rolls has been established by the method described above.
At low enough Rayleigh number this pattern persists indefinitely (Fig. 22.3).
At higher Rayleigh number spontaneous changes occur.
These may generate rolls perpendicular to the original ones and of smaller wavelength, producing a rectangular pattern like that in Fig. 22.4(a) (known as a bimodal convection); or, at lower Pr, they may lead, via an instability illustrated by Fig. 22.4(b) to a new roll pattern of larger wavelength.
In either case, the new flow, once established, is a new pattern of steady convection.
The transition has not introduced any fluctuations in time.
The next development with increasing Rayleigh number does produce such fluctuations — periodic ones.
Figure 22.5 illustrates this, choosing the case in which the previous stage had produced bimodal convection.
A standing wave pattern has spontaneously arisen, causing the longer boundaries of the rectangle to oscillate.
The two pictures in Fig. 22.5 show the same flow at times separated by half an oscillation period.
A probe measuring the temperature or velocity at a fixed point within this flow would indicate a periodic variation (cf.
Fig. 24.9(A) for similar behaviour in a small aspect ratio apparatus).
Both the transition from one steady pattern to another and the onset of periodic unsteadiness can be understood as instability of the pre-existing type of convection — and indeed have been successfully analysed from that point of view.
Hence, the increasing complexity of the flow can be interpreted as the result of a sequence of instabilities, each giving rise to a new pattern which is stable for some Rayleigh number range but which itself becomes unstable at higher Ra.
The further developments seen in Figs. 22.6–22.8 can probably be interpreted in a similar way.
However, from this point on, there is no full theory; the description is almost entirely observational and so the interpretation involves more guesswork.
The later stages of evolution are dominated by changes in the pattern of fluctuation with respect to time — from the very regular periodicity considered above towards the irregular fluctuations characteristic of turbulence.
Associated with this, however, are changes in the spatial structure of the flow, leading first to replacement of the roll dominated  patterns by different patterns (e.g. Fig. 22.6) and ultimately to the disappearance of any permanent spatial structure.
(Figs. 22.7, 22.8).
In Fig. 22.6, the large polygonal features are permanent structures; that is to say, once the flow has been established the polygonal pattern remains unchanging so long as the Rayleigh number is maintained constant, although the details of just where the polygons locate themselves will be different each time the experiment is performed.
There is thus a steady mean circulation in any one experiment.
However, there are fluctuations superimposed on this; i.e. the flow within the mean circulation is unsteady and probably essentially turbulent.
These fluctuations are responsible for the ‘spoke-like’ pattern of bright and dark patches to be seen within the polygons of Fig. 22.6, although, because of the unsteadiness, the behaviour is not fully illustrated by a single picture of this sort.
The permanent spatial structure is not present at the highest Rayleigh numbers at which observations have been made (Fig. 22.8).
The motion can then be described as fully turbulent.
This does not, however, imply that the fluctuations are ‘featureless’.
We shall look briefly at the features of this motion in Section 22.7.
22.6 Evolution of convection with defects
However, we must first remember that the above account of evolution with increasing Rayleigh number derived from experiments with pattern control.
What happens without it (in what might be considered the ‘natural’ situation)?
Then the cellular pattern arising when Ra is a little above critical is likely to contain dislocations and grain boundaries (Section 22.3).
These have a marked effect on the development with increasing Ra.
In particular, unsteadiness may set in at much lower Ra than it would in their absence.
It is likely that instabilities similar to those occurring in ‘perfect crystal’ motion again occur, but promoted and modified by the spatial imperfections.
One can again observe initially periodic oscillations being superseded, with increasing Ra, by aperiodic ones; the details are plainly much more sensitive to small inevitable peccadillos of the individual apparatus than when one has pattern control.
Figure 22.9 illustrates the onset of unsteadiness in uncontrolled flow in a special way.
This picture was obtained by having the fluid illuminated along only one line and moving the camera so that the image of this line moved across the film.
The result is essentially a space-time representation of the flow, and the ‘ribbed’ pattern indicates the occurrence of periodic fluctuations.
The appearance of this pattern in some places and not in others presumably relates to the detailed spatial structure in two dimensions.
Figure 22.10 shows another space-time representation of the same type at a higher Rayleigh number.
One sees that the fluctuations are now occurring throughout but with a trend towards less regularity.
It is likely that the later stages of development and particularly the structure of the turbulent motion at high Ra are essentially the same whether or not the experiment has involved pattern control.
22.7 High Rayleigh number convection and turbulence
To understand the processes occurring at high Rayleigh number, it is helpful to look at the mean temperature distribution across the layer.
(The averaging is as discussed in Section 19.2 and may be either over time or over horizontal planes.)
This takes the form shown schematically in Fig. 22.11, with large temperature gradients close to the boundaries and a nearly isothermal region in the interior.
The reason is analogous to the reason for large velocity gradients close to the walls in shear flows (Section 21.5) but with heat transport replacing stress in the argument.
The total vertical heat transport is the sum of that transported by the motion and that conducted down the temperature gradient  (cf. also Section 21.7).
H must be independent of z, the vertical distance across the layer.
At high Rayleigh number the heat transport is large, in the sense that Nu > 1.
In the centre of the layer this transport is brought about by the first term of eqn (22.11): essentially just the fact that rising currents in the convection are typically hotter than falling ones.
Close to each boundary, however, becomes much smaller — the boundary conditions require it to be zero right at the walls — and the second term of (22.11) must become much larger.
Incidentally, the Nusselt number is given by the ratio of the temperature gradient at either wall to the temperature gradient that would exist throughout the layer in the absence of convection (dotted line in Fig. 22.11).
Throughout either of the sequence of developments with increasing Rayleigh number described in Sections 22.5 and 22.6, the temperature profile tends away from the linear form that occurs when the fluid is at rest and towards the form of Fig. 22.11.
This fact is actually of some importance in more detailed analysis of some of the instabilities described in Section 22.5.
But it is in the fully turbulent regime that it is most central to the discussion.
By this stage, the large gradient regions occupy only small parts of the layer.
In consequence, the most strongly unstable regions are those close to the boundaries and the dominant features of the flow — the counterpart  of the large eddies of shear flows described in Sections 21.4 and 21.6 — originate there.
We consider the hot bottom wall; similar processes occur close to the cold top wall, with the roles of hot and cold fluid reversed.
There are intermittent eruptions of hot fluid away from the bottom boundary.
Colder fluid moves close to the wall to replace the fluid in an eruption.
This is gradually warmed by conduction from the wall until there is a thick enough layer of hot fluid for another eruption to be initiated.
The process then repeats itself.
Each eruption gives rise to one or sometimes more columns of hot fluid rising through the interior region.
These features are sometimes called thermals, sometimes plumes.
Over a range of Rayleigh number (probably dependent on Prandtl number), the thermals penetrate right across the layer, generating transient stable blobs of fluid close to the opposite boundary.
Ultimately, however, at the highest Rayleigh numbers, the thermals lose their identity before reaching the opposite boundary.
The processes at each boundary now occur independently of those at the other.
They can be investigated by studying the motion above a single heated plate at the bottom of a large expanse of fluid (Figs. 22.12–22.14), corresponding in a sense to infinite Rayleigh number.
A tendency has sometimes been observed for several successive eruptions to occur with noticeable periodicity and for successive thermals to be in the same places each time.
However, this does not persist over a long time scale and is often not to be observed at all.
In general, in a system of large enough horizontal extent, one expects to      find a spatially random distribution of thermals with some of them just forming, some in vigorous convection and some fading away, with the interval between formation and fading away being very variable.
Figure 22.14 shows the random character of the instantaneous temperature field.
Thermal formation and persistence appears to be the dominant feature of convection regardless of Prandtl number (at least from values rather less than 1 to very much greater than 1; experimental evidence for Pr < 1 is limited).
There are, however, differences in the motion at different Pr.
Unless Pr > 1, there is vigorous disorganized small-scale motion as well as the rather coherent large-scale motion of the thermals.
The former occurs both within the thermals and in the slowly downward drifting cold fluid between the thermals.
At very high Pr, this is absent and individual thermals are essentially laminar flow structures.
The flow as a whole is then rather different from flows typically indicated by the name turbulent, but the randomness in space and time of the occurrence of the thermals makes the name still applicable on the point of view of Section 19.1.
23
DOUBLE DIFFUSIVE FREE CONVECTION
23.1 Introduction
We have seen in Chapter 14 that the density variations that drive free convection may be introduced into a fluid through either temperature variations or concentration variations, and that the two are closely analogous.
In this chapter we consider what happens when the two are simultaneously present.
It might be thought that the analogy is readily extended to cover this situation, but in fact a whole range of new phenomena arise.
Some of these are particularly striking because they occur in circumstances where at first sight one would expect nothing interesting to happen.
The most immediate examples of this are ones in which the imposed density variations are entirely vertical; as in Chapter 22, this implies that any motion is the consequence of instability of the rest configuration.
Consider, in particular, the case in which one of the two causes of density variation produces an increase with height and the other a decrease.
It is found that the former can give rise to convection even when the latter is sufficiently strong that the net effect of the two is a decrease; i.e. lighter fluid overlies heavier.
There are evident applications to oceanography.
For example, solar radiation may warm the surface layer of the sea but this may also give a high evaporation rate increasing the salt concentration; thus hot, salty water often overlies colder, less salty water.
The converse situation can arise when cold fresh water (e.g. from a river formed by melting ice) flows into the sea; if it is sufficiently cold it will initially remain close to the sea-bed and thus underlie warmer, salt water.
Partly because of these applications, the most widely considered combination is that of heat and dissolved common salt.
This combination led to the older name for the phenomena we are considering: thermohaline convection.
However, it is only one example of a more general situation — for instance one might have no temperature variations but two different solutes — and the usual name now is double diffusive convection.
The crucial feature necessary for the occurrence of the special phenomena of double diffusive convection is that the two components  should have different diffusivities.
If this were not the case, then the two components would necessarily remain coupled in a way that would allow little difference from convection due to just one of them.
When the two components are heat and common salt, in the notation of Sections 14.2 and 14.3, and 
However, a much smaller contrast between the two will still produce the effects under discussion.
In the following, the discussion is presented in terms of the heat-salt combination, because this is easily envisaged.
The more general case is given by replacing ‘heat’ by ‘the component with higher diffusivity’and ‘salt’by ‘the component with lower diffusivity’.
In this chapter we consider primarily the configuration mentioned above — a fluid layer with the net density decreasing upwards as a result of opposing contributions from heat and salt.
What happens depends on which is the destabilizing and which the stabilizing component; the two cases constitute Sections 23.2 and 23.3.
There are other configurations of significance (one is mentioned in Section 23.4) but we can illustrate the essential features of the topic with this one.
The obvious relevance to oceanography has already been mentioned, but it is far from being the only field of application.
Other places where the importance of double diffusive effects has been particularly recognized are materials science (e.g. crystal growth, Section 26.11) and geology (e.g. the relationship of such effects in magma chambers to observed layering of igneous rocks).
Further applications are discussed in Ref. [395].
23.2 Salt-driven convection
We start our discussion of a fluid layer with vertical density variations with the case in which the salt is the destabilizing component; i.e. variations in its concentration are the cause of the convection.
Thus if z is vertically upwards, the imposed conditions have  where the basic notation is that introduced in Chapter 14 and the suffix 0 indicates, as in Chapter 15, the imposed vertical variations.
We denote  the density changes due to salt concentration and temperature changes by Δρ c and Δρ T thus  where ρ r is a fixed reference density, and  Hence, we are considering 
In this situation the predominant phenomenon is that known as salt fingering, shown schematically in Fig. 23.1.
An array of long thin fingers of salty water descends, interspersed with a similar array of rising fresh water.
The motion is driven by the higher density of the salty fingers.
Why is it not inhibited by the fact that the water entering these is also hotter than that entering the upgoing fingers?
The answer lies in the difference in diffusivities.
It is essential to the dynamics that thermal diffusivity produces significant heat transfer between the downgoing and upgoing fingers.
Consequently, the temperature contrast between them at any level is smaller than the  temperature difference between top and bottom.
There is not much temperature-produced density contrast at a   given level; thus this does not much affect the buoyancy force.
The heat transfer can occur without a corresponding diffusion of salt because of the lower diffusivity of the latter.
The salt-produced density contrast of fluid entering the downgoing and upgoing fingers can be sustained over their height and thus produce a relative buoyancy force at every level.
This argument can be formulated more quantitatively in a way that both helps with the understanding of it and shows what determines the width of the fingers.
We suppose that  not just  This is not in fact necessary for salt fingering to occur but it simplifies the presentation.
When , it is possible for the horizontal concentration variations to be effectively the same as the vertical ones whilst horizontal temperature variations are much reduced from the vertical.
The former requires  so that the concentration is advected into the salt fingers little changed by diffusion.
In order of magnitude  where W is a typical vertical velocity in the fingers, L is the depth over which the convection is occurring (its exact definition depending on just how the system is set up) and  ta; is the width of the fingers (Fig. 23.1).
Thus 
On the other hand, thermal diffusivity is changing the temperature as fluid moves up and down the fingers.
Hence, i.e.  where ΔT V is a typical temperature difference between top and bottom and ΔT H that between downgoing and upgoing fluid.
Moreover, we are supposing that heat conduction makes  so we require 
In order to use (23.10) and (23.14) to constrain  ta;, we require an estimate of W from the dynamical balance between the buoyancy force and one (or both) of the inertia force and the viscous force.
The buoyancy force is provided by δρ c (which is, in the first place, the difference between  upgoing and downgoing fingers, but, in view of the above discussion, may be taken as the difference between top and bottom).
Hence, i.e.  (where the choice of length scales follows the principles introduced in Chapter 11).
However, in view of(23.14) unless the Prandtl number ν/; κ is very small (Pr  6 for water).
Thus the buoyancy force/viscous force balance applies and  This can be substituted into (23.10) and (23.14) to indicate the possible range of δ.
It is convenient to introduce a concentration Rayleigh number  Then 
The appearance of the fourth power here implies that the finger widths are quite closely determined by the dual requirements of large heat transfer (right-hand inequality in (23.20)) and small salt transfer (left-hand inequality) even when κ/; κ C is large.
The deduction has implicitly assumed that  ta; /L is small; since the instability producing the fingers occurs at high Rayleigh number (cf.
Section 22.2) this is internally consistent.
As mentioned above, one does not actually require κ/; κ C to be much greater than 1 for the occurrence of fingers.
The same mechanism can operate when κ/; κ C is only a little greater than 1.
It is then a matter of smaller and larger transfer of the two components, rather than very small and very large.
Obviously the size of the negative  that can be overcome by a given positive  decreases as κ/; κ C decreases.
So far the type of situation in which salt fingers occur has been specified in only rather general terms.
They certainly occur in a variety of detailed configurations and may well be a universal feature of convection driven by the lower diffusivity component.
Sometimes, however, they are only part of the full picture, as we shall see in examples below.
Linear stability theory applied to a configuration of the Bénard sort with appropriate concentration and temperature differences across the layer indicates motions of a salt finger type.
The wavenumbers of the unstable modes are determined by the considerations leading to (23.20) rather than being directly related to the layer depth (as they are in ordinary Bénard convection, Section 22.2).
Experimentally one cannot set up just this configuration because of the difficulty in imposing constant concentration boundary conditions (Section 14.3).
In general, the most readily practicable experiments are ones in which an initial density distribution is set up and there is then some evolution of the configuration during the course of the experiment.
A particularly straightforward procedure in principle and yet a very informative one is to add carefully a layer of hot salty water on top of one of cold fresh water (or the counterpart of this in which two solutes are used instead of heat and one solute).
The instability originates at the interface, which then thickens into a region containing salt fingers.
Figures 23.2 and 23.3 show vertical and horizontal sections of fingers generated in this way.
The layer containing the fingers does not continue to thicken until it fills the fluid region.
A quasi-steady state is reached with the original layers still existing above and below this layer.
(Flow visualization gives a picture like Fig. 23.4 below, but with only three layers.)
The top and bottom layers are, of course, initially homogeneous      in concentration and temperature and therefore inactive.
However, once the salt fingers are formed, they are pumping salty fluid into the top of the bottom layer and less salty fluid into the bottom of the top layer.
(The associated reduction in potential energy is the energy source for the whole motion.)
Because of the diffusion in the fingers, the temperature fields are not correspondingly affected to a great extent.
Hence, concentration driven convection occurs in these layers.
Overall the system has three length scales, only one of which is externally imposed: the total depth of the fluid, the thickness L of the salt finger layer, and the width  ta; of individual fingers.
The tendency for L to find its own maximum value leads to interesting developments if the initial density distribution is set up in a way that makes it initially larger than this maximum.
The finger-containing layer can then split, as shown in Fig. 23.4.
In this example the end result is five layers, two containing salt fingers and three with isothermal concentration-driven convection.
This observation is relevant to the interpretation of much larger numbers of layers observed in the ocean, and may be seen in the context of the very general tendency, discussed in Section 23.4, for layering to arise in double diffusive systems.
23.3 Heat-driven convection
We turn now to the reverse case in which the temperature distribution is the driving component.
Thus, instead of(23.4) and (23.7), we have  giving 
Unlike the previous case, the behaviour of a marginally unstable system and that of a vigorously convecting one do not have an obvious common feature.
The development from one to the other is somewhat obscure.
One can, however, understand the way in which the difference in diffusivities enables each type of motion to occur despite the overall stable stratification.
The counterpart for the present case of the linear stability theory mentioned above predicts overstability (defined in Section 17.4).
This prediction has been confirmed experimentally (Fig. 23.5), by gradually increasing the temperature difference across a salt-stratified layer so that the Rayleigh number passes through its critical value.
The way in which double diffusive processes produce amplified oscillations may be understood through a simple displaced particle   argument.
Consider a fluid particle that is displaced upwards, say, from its equilibrium position.
Such a particle is heavier than its new surroundings and thus tends to fall back to its original level and then overshoot.
In the absence of any diffusion whatsoever its behaviour is identical to that involved in the theory of the Brunt-Väisälä frequency (Section 15.4).
If, however, thermal diffusion occurs, without a corresponding concentration diffusion, the particle will be cooled when it is above its equilibrium position and thus surrounded by cooler fluid.
It thus becomes even heavier relative to its surroundings, making the overshoot larger than the original displacement.
Similarly, at the bottom, warming gives it buoyancy that makes the next oscillation still larger.
This argument may be made clearer by formulating it algebraically, extending the theory in Section 15.4.
As there, we denote the density at Δz = 0 by ρ (0).
Then the density of undisturbed fluid at height Δz is  (the suffix a signifying ‘ambient’), which may also be expressed  where N is the Brunt-Väisälä frequency.
A displaced particle originating at Δz = 0 has density 
We suppose, however, that the concentration diffusivity is so small that  the particle conserves its concentration,
Its temperature, on the other hand, does change, and we assume that its rate of change is proportional to the difference between ambient temperature and its temperature  which may be rewritten  where J and K are positive constants.
The dynamical equation, a modification of (15.21), is  which, since we are making the Boussinesq approximation, becomes 
Equations (23.28) and (23.30) form a pair of differential equations with respect to time for the displacement Δz of the particle and its temperature change ΔT in its displaced position.
We look for solutions in the form  (where, of course, the real parts correspond to the physical quantities).
Substituting in (23.28) and (23.30) Eliminating Θ/Z,; 
It simplifies the algebra to confine attention to the case in which the unstable thermal stratification is weak compared with the stable salt stratification so that the oscillations are only slightly modified from those described by eqns (15.21) and (15.22).
(Since we have taken the concentration diffusivity to be effectively zero, this is sufficient to give the  effect we are looking for).
Hence, we put 
We also take  (since K ∼ N when the thermal diffusion occurs on a time scale comparable with the oscillations).
Then (23.34) approximates to  Since N, K, and J are all real, ω'; is complex:
Substitution in (23.37) leads to  The crucial point is that  is negative.
Since   this implies that the modified Brunt-Väisälä oscillations gradually grow in time; i.e. there is overstability.
Two points may be noted about this analysis.
Firstly, the result only applies when the concentration and temperature gradients have the appropriate signs; positive  would make N imaginary and positive  would make J negative.
Secondly, substitution of the results for ω back into (23.32) or (23.33) shows that Θ/Z; is complex.
This implies that Δz and ΔT are not oscillating in phase.
(Taking real parts of (23.31), it implies that if we put , then .)
This was to be expected; it is an essential part of the mechanism that at any given value of Δz, the particle should be hotter when it is ascending than when it is descending.
As for ordinary convection, this is what drives the motion.
The above argument is, of course, a gross simplification of any full   fluid dynamical situation.
Also, as with our discussion of salt fingers in Section 23.2, although the double diffusive processes are conveniently understood in the context of large contrast between κ and κ c , a small contrast is sufficient to give rise to these processes.
Nevertheless the argument is an effective way of understanding why linear stability analysis of the full situation predicts overstability and thus what is happening in Fig. 23.5.
That in turn is important in understanding why motion occurs at all, but, as noted earlier, relates directly to observations only when the Rayleigh number is only a little above its critical value.
What happens when it is far above that value is known primarily from experimental work, although the dynamical processes involved can be interpreted.
Figure 23.6 shows typical temperature and concentration distributions in these circumstances.
The convection divides into a series of layers; nearly all the variation of each quantity occurs close to the edges of the layers.
Within each layer convection is occurring, but the density difference between the layers associated with the concentration difference prevents this convection penetrating from one layer to another.
Heat and salt are both being transported vertically, by advection within the layers and by diffusion down the gradients between them.
Within each convecting layer, the upgoing fluid must be lighter than the downgoing, and this   implies that the heat transport is dominant over the salt transport.
The temperature distribution within one layer resembles that in Fig. 22.11, the rising hot fluid being supplied from the hot bottom boundary layer.
The corresponding concentration boundary layer is thinner (Fig. 23.6(b)).
Consequently the density reduction due to the high temperature of the fluid going into an upflow is not cancelled out by a density increase due to high concentration.
This behaviour is possible only because of the difference in diffusivities.
Without it, the high concentration gradient between layers, compared with the temperature gradient, would give a higher salt transport than heat transport — the opposite way round from the relationship needed to sustain the convection.
(To prevent the argument from being too cumbersome, there is some loose usage above.
For example, it is strictly meaningless to ‘compare a concentration gradient with a temperature gradient’, because the two are dimensionally different.
Such improprieties would be removed by replacing ‘temperature (concentration)’ by ‘density change due to temperature (concentration)’with similar changes for ‘heat’and ‘salt’.)
The convection within one layer is not very different from Bénard convection.
However, we have seen (Chapter 22) that this takes a variety of forms.
There are thus various regimes of the double diffusive convection in which different detailed patterns occur within the same overall picture, but we shall not go into these details here.
The ways in which the experiments leading to the above description have been done are varied (although again constrained by the boundary conditions of some ideal configurations being impracticable).
As an example, we look at the case in which an initially isothermal column of liquid is set up with a stable salt gradient in it; the base of the column is then heated.
Layers form sequentially from the bottom, as the effect of the heating spreads upwards and more of the fluid starts to convect.
Figure 23.7 shows two stages of such a sequence.
23.4 Layering
The tendency to form layers seems to be the most pervasive feature of double diffusive convection, arising in one way or another in widely different experimental configurations.
We have seen it occurring in both types of double diffusive convection arising from vertical density gradients, e.g. Figs. 23.4 and 23.7.
These two patterns of behaviour both involve layers in which there is convection due to the driving component little modified by the presence of the other component.
There is, however, the difference that when heat is the driving component then layers are simply separated by narrow regions with steep gradients, but   when salt concentration is the driving component they must be separated by other dynamically active layers — the ones containing salt fingers.
We take one further example, although without any details.
This has two purposes, firstly to illustrate the above assertion about the pervasiveness of layering and secondly to act as a reminder that there are important double diffusive flows that do not arise from instability of vertical gradients.
Again a vertical stable salt concentration gradient is set up, and a heat source introduced.
In contrast with Fig. 23.7, the heat source is now a localized one.
In the absence of the salt stratification this would produce a plume like that in Fig. 14.2 or 14.7(a).
The behaviour with salt stratification is shown in Fig. 23.8.
There is again a plume, but additionally horizontal layers of double diffusive convection spread out around this.
The tendency for horizontal influence to extend into regions that are quite unaffected in the absence of stratification is loosely analogous with the same tendency in other types of stratified flow as discussed in Section 15.1.
24
DYNAMICAL CHAOS
24.1 Introduction
Turbulent flows have often been regarded as the most important yet least understood set of phenomena of fluid dynamics.
They have also been regarded as a topic distinctive to fluid dynamics.
In recent years it has been realized that many non-fluid systems can exhibit behaviour which shares important characteristics with turbulent motion.
(More precisely this fact was, at least in a general way, appreciated by some people in the second half of the nineteenth century.
It is only recently, however, that there has been widespread realization of the implications for the study either of turbulence or of other systems.)
Some of these systems are far simpler than any fluid flow; we shall see examples in Sections 24.3 and 24.4.
Knowledge and understanding of them can thus be helpful in our efforts to understand what is happening when flows become turbulent (although as we shall see in Sections 24.6 and 24.7, the extent to which the new ideas ‘solve the problem of turbulence’ can be — and has been — overstated.)
There are also some other fluid dynamical applications of these ideas, as we shall see in Section 24.5.
Hence, fluid dynamicists need an understanding of these developments.
The word ‘turbulence’ is specifically associated with fluid flow.
A name is needed for the more general set of phenomena, and the word ‘chaos’ has taken on a scientific meaning for this purpose.
Also, as we shall see in the next two sections, an important aspect is that the chaotic behaviour is exhibited by classical, deterministic systems; hence, the name ‘deterministic chaos’ is often used.
Chaotic behaviour can arise only when the governing equations are non-linear.
The fundamental advances have come theoretically through discoveries about the properties of various non-linear difference and differential equations.
We shall not go into any of the general theory here.
However, we shall use the particular case of the Lorenz equations to give a fuller explanation of the concept of deterministic chaos (Section 24.2).
Although the rigorous justification for supposing that deterministic chaos is a basic property of some non-linear systems (and not just a matter of inadequate control) comes from theory, its nature may be best illustrated by an actual physical system.
In Section 24.3, therefore, we digress from fluid dynamics to look at a non-fluid mechanical system.
We  shall also use an electrical system, in Section 24.4, to illustrate the topic of ‘routes to chaos’.
Both these systems are essentially demonstrations; they do not have obvious applications.
It should, therefore, be noted that chaotic behaviour of non-fluid dynamical systems is of importance in a whole range of applications; examples are solar system dynamics; non-linear laser optics; electric circuits with non-linear feedback; chemical reaction rates; dynamics of species populations.
Because some of the systems that exhibit chaotic behaviour are so simple, it seems strange that the realization that they can behave in this way is only recent.
It is most unlikely that such behaviour had never previously been observed with comparably simple systems.
However, it would almost always be undesirable behaviour in any practical system; presumably people reacted to it by saying ‘something has gone wrong’ and making adjustments to get rid of it.
Fluid flow turbulence, in contrast, is far too pervasive ever to have been regarded in this way.
24.2 The Lorenz equations
Amongst the equations or sets of equations that have been particularly significant in the development of ideas about chaos are the Lorenz equations, introduced in Section 17.3.
We remember in particular from that section that there are conditions in which none of the steady state solutions is stable; we left open the question of what happens then.
The Lorenz equations are actually a slightly more general set than we considered previously:
These differ from the previous set by allowing ; the case b = 8/3 has received much attention.
The equations were originally developed as a highly simplified model (mathematically a very severe truncation) of the equations of Bénard convection (Chapter 22).
That is perhaps more of historical than of current scientific interest.
If you wish to picture solutions of the equations, it is probably best to think of convection in a loop (Figs. 17.4, 17.5) even though that really applies only for b = 1.
Equations (24.1)—(24.3) give the rates of change of X, Y, and Z in terms of their present values.
It is significant, in the context of properties to be seen below, that they are thus ‘deterministic’ equations.
That is to say, if X, Y, and Z are known precisely at some initial instant, then their evolution for all subsequent time is in principle determined.
The principal results in Section 17.3 go over to the more general case with only minor modifications.
In particular, eqn (17.43) becomes 
For , all three steady solutions are unstable.
As r passes through r c , the two steady solutions involving circulation become unstable in the form of amplifying oscillations .
(r c exists only when ; for , the two solutions are always stable, but this case is consequently of less interest.)
What happens when ?
X, Y, and Z must vary continuously in time.
It is the form of these variations that is of special interest.
This is not indicated by the analysis in Section 17.3, for the reason given there that the non-linear perturbation terms become significant.
The principal way in which the behaviour has been elucidated is by numerical solutions of the equations; one starts with some initial condition for (X, Y, Z) and integrates forward in t.
There is now a body of more formal theory that provides understanding of why the numerical solutions behave as they do, but we confine attention here to empirically observed features of the solutions.
Before we consider results for , it is worth mentioning briefly what numerical solutions show for .
For the most part, such solutions ultimately tend to one of the stable steady state solutions — thus confirming, for example , that the consequence of the instability of the rest configuration when r > 1 is a transition to one of the two steady solutions with circulation.
However, there is a range in which different initial conditions can lead to different ultimate behaviour; for example, for the frequently investigated case of P = 10, b = 8/3 this range is 
In this range, solutions for some initial conditions tend to one of the steady state solutions whereas those for others exhibit indefinitely the sort of behaviour that is found for all initial conditions when .
Figures 24.1–24.3 show three examples of solutions for .
They are actually all for  and b =8/3 but various values of P. In each case the integration was started at a time sufficiently earlier than the start of the trace that the choice of initial conditions is not having a large direct effect.
Our discussion will refer particularly to the case in Fig. 24.2.
The other two cases are included primarily to emphasize that a wide variety of phenomena is contained within the Lorenz equations, although, since yet further variety can be obtained by varying r/r c and b, they can do so only by example.
In the solution in Fig. 24.1, X, Y, and Z vary periodically (although   far from sinusoidally).
This is perhaps the most obvious possibility, given that solutions with steady circulation become unstable with respect to growing oscillations when .
It is significant that it does indeed sometimes happen; we return to the question of when at the end of this section.
But our main interest is in the cases when the fluctuations are non-periodic, as in Figs. 24.2 and 24.3.
Figure 24.2 is in two complementary parts, one showing a short time stretch in detail and the other a much longer stretch without detail.
In the former, all of X, Y, and Z are shown — the relationships between their changes are illustrated and one could estimate from it the ways in which the various terms in the equations are bringing about the changes.
Figure 24.2(b) shows only X, and all details of variations between minima and maxima of this are omitted.
One sees that X (and Y) alternates between intervals during which it oscillates about a positive level and ones during which it oscillates about a negative level.
In one sense, therefore, this is a highly patterned behaviour (quite different from velocity fluctuations in a turbulent flow, Fig. 2.6).
It is nevertheless chaotic, as is seen when one considers the duration of each interval or equivalently the number of oscillations within   it.
It is apparent from Fig. 24.2(b) that this number varies widely and without obvious pattern.
Examination of long stretches of numerical data, together with other methods of analysis, have shown that it is indeed varying chaotically; that is to say, no matter how long the fluctuations continue, one will never find repetition of the detailed pattern.
An important aspect of such chaotic behaviour is sensitivity to initial conditions.
A small change in these leads to a solution that ultimately diverges from the original one.
The smaller the change the longer is the   time for which the two solutions remain close, but they never do so indefinitely.
If two such solutions were displayed as in Fig. 24.2(b), the overall impression given would be the same; however, sufficiently long after initiation, the times at which the changes of level occurred in the two solutions would be totally uncorrelated.
This has the implication that, although in principle exact prescription of the initial conditions determines the solution throughout subsequent  time, one has no way of actually finding this solution.
Any procedure of numerical integration will involve approximations that have the same effect as unknown small changes in the initial conditions (although they are introduced continuously, not just at an initial instant).
The relationship of a computed solution, such as that in Fig. 24.2, to the unknown exact solution is similar to that between two solutions with slightly different initial conditions.
More generally the concept of sensitivity to initial conditions has important implications for the predictability of systems governed by equations with this property.
In any real system there is always some lack of exactitude in one's knowledge of initial conditions.
Even if this is small, it means that the detailed behaviour becomes totally unforecastable in the long run.
Determinism in principle does not necessarily imply predictability in practice.
(In Section 24.3 we will look at an actual physical system that shows the implications of that statement rather effectively.)
It is only the detailed form of the fluctuations that is unforecastable.
Average quantities (e.g. the mean value of Z or the root mean square value of the fluctuations in X) will take the same values in different realizations of the same conditions; i.e. different computations, perhaps using different numerical procedures, for different initial conditions but the same values of r, P, and b.
This matter is considered more fully in the appendix to this chapter, as an illustration of the closure problem (Section 20.2).
Figure 24.3 gives an example of behaviour at high P, again in the form of a short detailed section plus a long schematic one.
X and Y remain small for much of the time but have a series of peaks.
These are almost equally spaced with the result that Z is almost periodic (but not exactly so — there are detectable variations in, for example, the minimum value of Z).
However, the peaks can be either positive or negative: and this is another example of chaotic behaviour; a sequence like that in Fig. 24.3(b) might be obtained by the toss of a coin — heads for a positive peak, tails for a negative.
(See Ref. [163]for more about the Lorenz equations at high P.)
The contrast between the periodic behaviour of Fig. 24.1 and the chaotic of Figs. 24.2, 24.3 was obtained by increasing P. It should not, however, be inferred that this is a simple trend.
The question of when solutions of the Lorenz equations are periodic and when non-periodic is in fact a matter of some complexity.
In particular, examples have been found of periodic behaviour occurring at higher r than chaotic for the same values of b and P. Changes are not necessarily in the direction of greater randomness the further one goes from the first instability of steady solutions.
We shall return to this point in Section 24.7.
24.3 Chaotic motion of a forced spherical pendulum
The concept of chaotic motion may seem somewhat abstract.
We therefore now look at one particular dynamical (although not fluid dynamical) arrangement that exhibits it.
This demonstration also forcibly makes the point that chaotic motion may occur even in remarkably simple systems.
The following description is based on observations with a demonstration apparatus.
The demonstration was motivated by theoretical work which provides the real justification for the interpretation given.
We will return to this point after the description of the demonstration.
We consider a pendulum that is free to swing equally in any direction, so that the bob can move over a spherical surface — an arrangement known as a spherical pendulum or a conical pendulum.
The point of suspension is oscillated sinusoidally in a straight line (the x-direction) with an amplitude small compared with the pendulum length.
This, of course, causes the pendulum to swing in the same direction.
If the driving frequency (f) is close to the pendulum's own natural frequency (f) the swing amplitude becomes large (obviously); the motion may then become unstable with respect to perturbations in the perpendicular (y) direction (far from obviously).
As a result, there is a range of driving frequencies (for quantitative details see Refs. [273, 274, 390]) in which the pendulum bob orbits within the spherical surface, rather than just oscillating on an arc of the surface.
It is this orbital motion that exhibits the phenomena with which we are concerned.
There is a surprisingly complex sequence of changes in this motion as one traverses the driving frequency through the main range.
However, we can illustrate the most important features by considering just two types of motion, each of which occurs over a significant sub-range.
(To a first approximation, one is likely to encounter the first type if f is a little higher than f and the second type if f is a little lower than f.)
Only the second type is a chaotic motion, but the first is worth mentioning for comparison.
Within one sub-range the pendulum bob moves on an elliptical orbit, with principal axes in the x- and y-directions, with the same frequency as the drive.
The motion is thus a highly ordered one, although different from what one might anticipate.
It is interesting to consider the predictability of this behaviour; as discussed in Section 19.1, we expect the fact that the motion is the consequence of instability of a different type of motion to imply some loss of predictability.
Suppose that one set the pendulum in motion, waited long enough for transients to die away, and then attempted to predict (on the basis of previous experience) what one would observe if one looked  at the pendulum.
One could in fact make a nearly completely correct prediction.
The only feature that one could not predict would be whether the pendulum was orbiting clockwise or anticlockwise.
There is no asymmetry in the system that makes one sense more probable than the other.
(An analogy may be made with the discussion of a vortex street in Section 19.1.
In both cases the behaviour is not completely predictable, but observation for only a short time makes it so for all subsequent times.)
We turn now to the other sub-range that we are considering.
(With the particular apparatus on which this description is based, this involves a reduction in the driving frequency of typically 3%.)
The motion is chaotic on a time scale long compared with the oscillation period.
If one observes the horizontal projection of the motion for just one or two periods then one sees a quite well-defined orbit; one can say whether the bob is moving on a circular, elliptical or linear path, how big this is, and how, for an ellipse or line, it is oriented.
If, however, one observes the motion for a longer time, one finds that the size, ellipticity and orientation of the orbit are continuously changing.
Moreover there is no discernible pattern to the changes.
Figure 24.4 gives an example (drawn from trajectories on the screen of a videotape of the motion) of how one might see the bob moving if one glanced at it at a succession of equally spaced times — although one would not expect to see just this sequence ever again.
An attempt at prediction, like that outlined above, would now have little chance of success.
Accumulation of observations would allow one to specify statistical properties of the motion, such as the average kinetic and potential energy of the pendulum over a large number of periods (cf. the statistical specification of turbulent motion, Section 19.2).
But it would not allow one to predict the detailed sequence of changes in any run.
Sensitivity to initial conditions (explained in Section 24.2) makes this different every time.
From the demonstration alone, it is difficult to be certain that the motion is chaotic, in the specific sense that the word is now used, and not just very complicated.
The fact that no pattern to the changes can be discerned does not guarantee that there is none.
The justification for the interpretation is theoretical analysis of the forced spherical pendulum.
Despite some unavoidable differences between the theoretical and actual pendulums, the phenomena exhibited by them show good correspondence.
The theoretical results can be subjected to specific mathematical tests (concerning the spectrum of the motion, cf.
Sections 19.5, 24.7) to establish their chaotic character.
There is every reason to suppose that changes such as those in Fig. 24.4 are intrinsic to the dynamics, not something that could be eliminated if only one had better control of the apparatus.
We have noted that chaotic behaviour can arise only for systems   governed by non-linear equations.
Non-linearity is in fact also needed to provide the coupling between the x- and y-motions that produces the latter.
Why is the pendulum a non-linear system?
It is a consequence of the large amplitudes to which the pendulum swings.
In the obvious notation, the restoring torque on the pendulum is mgl sin θ.
The theory works to the approximation 
If one were to make the linear approximation of , none of the effects under consideration would be obtained.
(This is the only non-linearity in the theory.
With the demonstration apparatus there are other non-linear effects present, particularly in the damping; the bob is a ball moving through the air at a Reynolds number , cf.
Sections 3.4 and 7.3.
But this does not seem to make much difference to the behaviour.)
24.4 Routes to chaos
It is evident from the mathematical and physical examples described in the foregoing sections that systems exhibiting chaotic behaviour also exhibit ordered behaviour for different values of the governing parameters.
They thus make a ‘transition to chaos’ as the parameters are varied.
The ways in which this transition can occur form a topic central to theoretical ideas about deterministic chaos.
In the present context they are important for attempts to relate transition to turbulence to transition to chaos, a matter we shall be considering in Section 24.7.
The topic of transition to chaos or ‘routes to chaos’ is remarkable for — what at first sounds paradoxical — its simultaneous universality and diversity.
Universality refers to the fact that totally different systems can exhibit the same route to chaos — the same not just in that they show the same broad features, but very closely the same including quantitative details.
On the other hand, there are various quite distinct routes, and a single mathematical or physical system may exhibit more than one of them; a change in some parameter can lead to a qualitative change in the route adopted as a second parameter is varied.
We cannot give an adequate treatment of this matter here.
The theoretical structure is large and in places complicated.
Also any account could well become rather rapidly out of date.
What we need is, firstly, a more specific indication of what is meant by a route to chaos and, secondly, some ideas on which we can draw in Sections 24.5 and 24.7.
For these purposes we will look at experimental observations with a particular system that provides effective illustrations.
Some might think this a rather idiosyncratic approach to a primarily theoretical topic, but it seems appropriate to this book.
Readers wanting a definitive account of routes to chaos should turn to, e.g., Refs. [88, 134, 340, 378].
The system we consider is the electrical circuit shown in Fig. 24.5.
A    coil, diode, and resistance in series are connected across an alternating voltage source; the capacitor shown in parallel with the diode is initially absent: we consider it later.
Changes in the component values, the particular diode, and the source frequency can give a rich variety of observations.
For our purposes it is sufficient to display the results of one particular experiment.
Figure 24.6 shows a sequence of photographs of an oscilloscope screen, on which the current through the circuit is displayed in the y-direction versus the voltage across it in the x-direction.
Through the sequence the source voltage is being increased with all else held constant; the x- and y-scales change between pictures, not necessarily in proportion.
In picture (a) the circuit is behaving as one might guess — the single loop on the screen indicates that the current varies in the same way for every cycle of the source.
However, as the voltage is increased much less obvious behaviour ensues.
In (b) there is a double loop, indicating that the pattern of current variation is different for alternate cycles of the source.
A particular voltage can be identified at which a transition from the behaviour of (a) to that of (b) occurs.
Further voltage increase gives another transition: the pattern of current variation repeats on only every fourth cycle of the source (picture (c)).
In (d) and (e) the current variations have become chaotic; the pattern never repeats itself exactly.
In (e) the current variation during one period of the source may be such that the path on the oscilloscope screen (the ‘phase space trajectory’) may lie anywhere within a certain region.
At the lower voltage of (d) there are gaps in the picture; although the behaviour is now chaotic, the trajectories remain fairly close to ones that were followed when it was periodic.
As the voltage is increased the ‘permitted’ regions gradually spread until the gaps are filled in.
Further increase of the voltage from that of (e) leads to a reversion to ordered behaviour.
Now the pattern of current variation repeats exactly over every three periods of the source (picture (g)).
Between (e) and (g) there is a range of behaviour not fully illustrated by a still picture such as(f), which looks like a superposition of (e) and (g): if one watches the oscilloscope one sees the picture alternating randomly between the chaotic pattern and the ordered one.
The typical duration that it spends in either mode is very long compared with the source period.
Pictures (h),(i), and (j) continue the story as the voltage is increased.
The repetition period of the current changes from three times to six times the basic period.
Then chaotic behaviour recurs, with the phase space trajectories being initially confined to bands and subsequently filling a whole region.
There is, however, a significant difference from the changes between pictures (d) and (e).
Now, instead of the bands gradually spreading to fill the gaps, there is a particular voltage at which the gaps are suddenly filled (a type of change known as a ‘crisis’).
One variant of the experiment is worth mentioning.
A small capacitance was introduced in parallel with the diode (Fig. 24.5).
The sequence of observations was broadly the same with one significant exception.
No region of alternation between pictures (e) and (g) occurred.
Instead the pattern jumped suddenly from one picture to the other as the voltage was varied.
However, there was marked hysteresis in the voltage at which this occurred; there was a range of voltages in which the behaviour could be either permanently chaotic or permanently ordered, depending on the side from which the range had been entered.
The above observations involve a variety of routes to chaos.
The developments leading from the simple behaviour of Fig. 24.6(a) to the first chaotic zone (d) are an example of a widely discussed route, the period-doubling sequence.
The interpretation of these observations, based on theory, is that there is actually an infinite number of changes like that from (a) to (b) or from (b) to (c).
At each step the period of the current variations doubles.
One thus gets a sequence of periods: 1, 2, 4, 8, 16,…, ∞.
Although the number of steps is infinite, the whole sequence occurs within a finite range of the input variable, in our case the voltage.
The period thus reaches ∞ at a particular voltage.
This means that the pattern of variation never repeats itself.
It has thus become chaotic.
This description, of course, implies that the range for period 2 n gets     rapidly narrower as n increases.
In any real experiment one will be able to detect only a limited number of stages.
It is worth emphasizing that the sequence is one of period-doubling, not of frequency doubling.
Each stage introduces a new sub-harmonic, not a new harmonic.
(Harmonics are present even for period 1, because the fluctuations are highly non-sinusoidal.)
The process is thus not the long-known one of the production of harmonics by non-linearity.
The observations with the  coil-diode circuit included a second period-doubling sequence after the window of ordered behaviour.
This time one may suppose that the sequence is: 3, 6, 12, 24,…, ∞.
It is essentially the same route to chaos.
We have, however, already noted that there is a difference in subsequent developments within the chaotic zone.
One may also consider what happens when one leaves the ordered window on the other side.
One is starting from an ordered behaviour, with period 3, and observing a transition to chaos as the voltage is decreased.
The route is now quite different.
It is in fact the intermittency route, effectively defined by the above observations.
In the  transition zone the behaviour alternates randomly between the behaviours on either side of it.
The intermittency factor, defined as the fraction of the time that the fluctuations are chaotic, varies continuously across the transition zone from 0 at the ordered side to 1 at the fully chaotic side.
(Fig. 24.9 will illustrate this in a different context.)
It should be noted that the causes of this type of intermittency are different from those of intermittency arising from alternate laminar and turbulent motion, as in Figs. 2.10 and 21.4.
Finally, the experiment with the additional capacitance has been mentioned to illustrate that the route can be changed by a small modification of the system.
Now, on any given occasion (decreasing or  increasing the voltage), the switch between ordered and chaotic behaviour takes place catastrophically, without an intervening zone of intermittency.
However, because of the hysteresis, there is still an intermediate zone — one in which either behaviour may occur permanently.
One other route to chaos, the quasi-periodicity route, not illustrated by the coil-diode circuit will be mentioned in Section 24.7.
24.5 Chaos in fluid dynamics
Certainly the primary reason why ideas about chaos have been seen as important for fluid dynamics is their potential relevance to turbulence.
We discuss this in the next two sections.
However, there are also quite different ways in which flows exhibit chaotic behaviour — with the connection to the general theory of chaos being perhaps more definitely established.
It seems likely that examples of such flows will multiply in coming years.
Thus, although some of the topics are outside the main scope of this book, we look briefly at this matter in this section.
Firstly, it is worth noting that if the Lorenz equations (Section 24.2) are considered as modelling convection in a loop (Figs. 17.4, 17.5), then the chaotic solutions of the equations do not correspond to turbulent flow in the loop.
They correspond to chaotic fluctuations of the whole circulation.
The question of whether the flow becomes turbulent (as Poiseuille flow becomes turbulent, Sections 2.6, 18.3) is distinct.
One could envisage any of the following: non-chaotic laminar flow; chaotic laminar flow; non-chaotic turbulent flow; and chaotic turbulent flow.
Relating this to actual flows, is restricted by the severe simplifications in deriving the equations, although there have been some experiments showing interesting behaviour.
Cases where the connection is more immediate concern various flows with free surfaces.
It has, for example, been shown theoretically that non-linear forced surface waves in a circular cylinder are governed by equations closely similar to those for the pendulum described in Section 24.3.
It has also been found experimentally that the columns formed by a layer of viscous liquid falling over an edge can move around chaotically.
As an example to illustrate the matter a little more fully we consider a dripping tap.
The interval between successive drips sometimes varies chaotically.
It is unclear just when this happens one is unlikely to be able to observe it in a casual experiment at the kitchen sink — but Fig. 24.7 shows observations made by varying the pressure behind a suitably shaped nozzle.
Like the system described in the previous section, considerable complexity is found; there is more than one transition to and reversion from chaos.
The full picture has not yet been elucidated.
Figure 24.7 thus does not represent a single sequence.
However, it shows cases in which every interval is the same, every alternate interval is the same (period doubled), every fourth interval is the same (period quadrupled — two examples with different detailed sequences), and the intervals vary chaotically.
24.6 Implications for turbulent flow
The implications of modern ideas about chaos for fully turbulent motion (as opposed to transition to turbulence to be considered in Section 24.7) are primarily concerned with our general understanding of the word ‘turbulence’.
Turbulent motion can now be seen as an example of deterministic chaos.
In a sense that has long been the case, since it has generally been supposed that turbulent flows are contained within a deterministic set of equations — the Navier-Stokes and continuity equations.
However, in the absence of a formal derivation, it has been possible to question whether this is really the case.
This matter can now be considered resolved.
Since far simpler deterministic systems exhibit chaotic behaviour and since we understand how this comes about, the view that the occurrence of turbulence implies a failure of deterministic equations is no longer tenable.
The new ideas may also help with the formulation of a more precise definition of turbulence, as we shall discuss at the end of the next section.
Beyond this, the implications for fully turbulent flow are slight.
Some of the simpler systems provide a context in which certain ideas about turbulent flow may be elucidated; e.g. the analysis of the closure problem in the appendix to this chapter.
But attempts to understand particular turbulent flows, as outlined in Chapters 19–21, have not been significantly modified or aided by the new developments.
It is necessary to stress this rather negative fact mainly because of excessive claims that have been made for the new ideas.
It has been said that ‘the problem of turbulence has been solved’.
Aside from the question of what is ‘the problem of turbulence’(there are many), this can give a quite false impression.
24.7 Implications for transition to turbulence
If we turn to the processes by which flows become turbulent, rather than their structure when fully turbulent, more positive statements can be  made.
We have seen in Chapters 17, 18, and 22 that these processes are diverse.
Studies of non-fluid systems undergoing transition to chaos and developments in the mathematical theory of this transition are also revealing a varied phenomenology.
It is of interest to see whether and where the two share common ideas.
In particular one may ask whether the established routes to chaos (Section 24.4) are to be found during transition to turbulence.
Since there is a body of theory associated with these routes, some of it of considerable generality, identification of one of the routes implies that the transition is at least partially understood.
The short answer is that several of the routes have been identified in fluid transition experiments, but that the significance of this for transition in general is currently very uncertain.
Quite a number of experiments leading to such identification have been with small aspect ratio Bénard convection (Sections 22.1, 22.4)[87, 181, 246]; small in this context means not much greater than unity.
Another fruitful configuration has been rotating Couette flow (Section 17.5).
We illustrate the point by presenting briefly the results of experiments in which two of the routes introduced in Section 24.4, the period-doubling route and the intermittency route, were found.
Figure 24.8 shows a sequence of spectra for increasing Rayleigh number measured in a Bénard apparatus.
The appearance of sub-harmonics    (f /2, f /4) of a previously present frequency (f) reveals period-doubling.
The continuous spectrum of the last diagram indicates that periodic fluctuations have been replaced by chaotic ones.
Figure 24.9 shows vertical velocity fluctuations in a different Bénard experiment.
Consecutive oscillograms correspond to increasing Rayleigh number, and one sees a change from periodic fluctuations to irregular ones through an increasing intermittency factor.
One other route to chaos, not illustrated by the experiment described in Section 24.4, has received particular attention in the context of transition to turbulence.
It is therefore illustrated in Fig. 24.10, although   a full discussion would take too much space.
The figure is a spectrum similar to those in Fig. 24.8 and shows that there are two basic frequencies (f 1 and f 2 ) present together with their harmonics and integer combinations .
This occurs as an intermediate stage between a single frequency spectrum (similar to Fig. 24.8(a)) and a continuous one representing chaotic fluctuations (similar to Fig. 24.8(d)).
There are several variations of the route, in which other intermediate stages, if any, differ.
Fluctuations with two or more incommensurate frequencies (i.e. frequencies of which the ratio is not a ratio of integers) are called quasi-periodic.
Hence, the route is known as the quasi-periodicity route.
An obvious question is posed by this diversity of routes: when does each occur?
The answer is not known.
In fact quite small changes in an apparatus can lead to an unexpected switch to a different route.
A more general open question concerns the extent to which these observations are typical of transition.
Will it be possible to relate transition, for example, in large aspect ratio Bénard convection or in shear flows to the above ideas?
The links with the observations described in earlier chapters are certainly not obvious.
On the other hand, the experiments in which particular routes to chaos have been identified required very precise experimental techniques.
Any of three outcomes seems possible at present:
(i)
known routes to chaos will be identified in other flows by more refined experiments;
(ii)
new routes to chaos will be found and related to these flows; or
(iii)
transition to turbulence is often inherently different from transition to chaos in simple systems (i.e. systems with few degrees of freedom are not a good guide to those with very many)
.
Two further general points are of interest.
Firstly, we noted in Section 24.2 that solutions of the Lorenz equations may change from chaotic to periodic as r is increased; also the experiment described in Section 24.4 showed a chaotic zone with ordered ones on either side of it.
Reversion to order can occur; systems do not necessarily get progressively more disordered as one goes further beyond a first instability.
Does this have implications for transition to turbulence?
We can be confident that, for practical purposes, the general notion that high Reynolds number (or its counterpart) implies turbulence is valid.
But there do sometimes seem to be trend reversals on the route to this.
Reappearance of periodic motion has been observed in rotating Couette flow.
In Sections 3.3 and 17.8, we saw that the vortex street frequency has ranges of decreased regularity; although these changes can be related to developments in the flow, there are tentative suggestions that they might also be viewed in the present context.
Secondly the standard routes to chaos imply the existence of a  well-defined onset of chaotic behaviour.
This is relevant to the question raised in Section 19.1 as to whether the demarcation between non-turbulent and turbulent motion is sharp, or whether there is a ‘grey area’.
In experiments described above (e.g. Figs. 24.8 and 24.10), the onset of turbulence was specified clearly by the stage at which the spectrum changed from a discrete to a broadband structure.
However, the generality of this is uncertain.
We saw, for example, in Section 18.4 that in  transition in jets and other free shear flows randomness appears to develop continuously; it would be difficult to assign a stage in Fig. 18.11 or 18.12 at which the motion is first turbulent, and it may be impossible.
The fact that this is an open question is obviously related to our earlier open question: can a standard route to chaos always be identified in transition to turbulence? and   
EXPERIMENTAL METHODS
25.1 General aspects of experimental fluid dynamics
We do not have space for a full description of all the experimental techniques used in obtaining the results discussed in this book.
This chapter can give only a general survey, intended to place the various methods in some perspective.
The techniques appropriate to different branches of fluid mechanics — and to different experiments within one branch — are diverse, and decisions about those to be used in a particular project require detailed consideration of the successes and failures of those used in previous related projects.
One must add to this that the limitations to an experiment often lie in the performance of transducers, and the experimentalist should always be on the alert for new possibilities.
The purpose of an experiment in fluid mechanics may range from direct verification of a theory (as in Figs. 11.2, 15.12 and 17.19) to a general exploration of the phenomena that occur in a given situation.
Most of the experiments that have contributed to the ideas described in this book fall somewhere between these two extremes, although the proportions contributed by theory and by experiment to the final story are very variable.
Most often one is dealing with a situation for which mathematical difficulties preclude a full theory, but in which it is still useful to refer to the equations of motion in deciding what measurements to make and how to interpret the results.
Studies of the energy balance in turbulent flow, as in Figs. 21.8 and 21.16, provide a straightforward example of this.
Even in topics for which there is a wholly adequate theory, primarily exploratory experiments may have played an equally important role.
For example, hydrodynamic stability is now one of the more highly developed theoretical branches of the subject but the need for this type of treatment of the equations of motion would not have been apparent without experimental observations of instabilities.
The design of an experiment involves careful attention to the requirements of dynamical similarity.
One must ask what range of phenomena one wishes to study and thus what values the relevant non-dimensional parameters should have.
Then one must consider how these can be achieved, or, if they fall outside the practicable range, what departures are least unacceptable.
In this process of design, there are three questions that frequently  arise:
(i)
will the work consist primarily of quantitative measurements or of observations of flow patterns?
(ii)
will the work be done with an existing installation or with specially built apparatus?
(iii)
what fluid will be used?
The distinction implied by the first question — transducing versus flow visualization — is not complete.
One can, for example, measure velocities by timing the movement of dye.
However, it does provide a useful general classification of experiments.
The decision depends partly on the previous state of knowledge of the topic under investigation — one is most likely to opt for flow visualization in a preliminary exploration — and partly on the efficacy of available transducers in the particular situation.
However, the two approaches are often complementary.
No purely qualitative study is likely to answer all questions about a flow.
On the other hand, measurements are often difficult to interpret without the assistance of flow visualization.
Within this book, rather frequent use of the results of visualization experiments has been made because the photographs provide ready illustrations of the flows under discussion.
The reader should not conclude that experimental fluid mechanics is primarily a matter of ‘look and see’; one always aims to express results as quantitatively as possible.
There is a third category of experiment, quantitative but not involving detailed probing of the flow.
In these experiments, some bulk quantity associated with the flow is measured.
Examples are the mass flux in pipe flow (Sections 2.3 and 2.7), the torques acting on the cylinders in rotating Couette flow (Sections 9.3 and 17.5), and the heat transfer in convection experiments (Sections 14.4, 14.8 and 22.2 — particularly Fig. 22.1).
The experimental methods involved depend very much on the particular experiment, so they will not be discussed further in this chapter.
Some fluid mechanics laboratories consist mainly of standard flow systems into which different experiments can be introduced.
Others consist mainly of equipment that has been built for particular experiments.
This depends primarily on the branch of fluid mechanics being studied.
The investigation of the flow past obstacles or of boundary layers requires a uniform flow with minimal velocity fluctuations.
To obtain this is in itself a complicated matter.
Hence, such experiments are normally carried out in a laboratory permanently equipped with a wind-tunnel (the name for any system providing a working air stream), a water flume or channel (similar systems with water), or a towing tank (a large tank of stationary water through which an obstacle can be moved).
A few of the many examples of results obtained with such equipment are Figs. 11.2, 12.9, 21.7 and 21.19.
Readers interested in more details of such techniques are referred to Refs. [22, 29].
In contrast, many experiments, for example in convection, are difficult to fit into standard systems, and  every experiment involves the construction of a special piece of apparatus.
Examples of observations made in such experiments include Figs. 15.2, 17.11, 22.1 and 22.3–22.8.
The choice of working fluid, unless dictated by the available standard equipment, is usually influenced by two considerations, the achievement of the desired values of the governing non-dimensional parameters and the performance of flow transducers.
Whenever possible, of course, either air or water is used.
The choice between these two often depends on the type of experiment; more successful techniques for velocity measurement have been developed for air than for water, whilst flow visualization is generally more successful in water than in air.
Other considerations may, however, enter.
For example, one might face a situation in which the fact that water more readily gave the desired values of the governing parameters (its lower kinematic viscosity is often advantageous in this respect) had to be set against the practical difficulties of containing it in an arrangement with movable probes.
Other fluids are sometimes used because they give better values of the governing parameters or because they have properties particularly appropriate to an experiment.
For example, silicone oils are widely used in convection experiments: they can be obtained with different viscosities, but otherwise similar properties, which provides a convenient method of varying the Prandtl number; and the viscosity varies with temperature much less than for many fluids.
25.2 Velocity measurement
Obviously the most important quantity to be measured in most flows is the fluid velocity.
Here we shall look at the principles by which various methods of measuring velocity work; the reader interested in the arrangements of a full working system and the procedures for operating it should follow up the references.
The general name for any instrument for measuring fluid velocity is ‘anemometer’.
There are three principal instruments for velocity measurement — that is to say, instruments that have found application in many different types of experiment.
These are the Pitot tube, the hot-wire anemometer (and similar devices) and the laser-Doppler anemometer.
The remaining techniques have not given rise to general-purpose instruments but have proved useful in particular experiments.
The Pitot tube is illustrated in Fig. 25.1.
The inner tube with a hole at the nose, S, of the instrument is entirely sealed from the outer tube.
Several holes (typically five), of which two are shown in the figure, round the periphery of the tube all lead into the outer annulus.
The   theory of the operation of a Pitot tube is contained essentially in eqn (10.19), Bernoulli's equation applied to the streamline that ends at the forward stagnation point of an obstacle placed in a stream.
If the Pitot tube points into the flow, the pressure Ps will occur at the point S and will be measured by a manometer connected to outlet 1 (the manometer must, of course, block the tube, so that there is no flow through it).
Calculation of the speed, u, from the relationship,, requires information about the pressure p.
This is provided by the peripheral holes, P. These are some distance downstream from the nose so as to be beyond the region of pressure variation.
Since the pressure difference across the boundary layer is negligible, the pressure at these holes is the static pressure p.
The average pressure from several holes is observed, as the pressure at a single hole would be more sensitive to misalignment of the tube than the ps-reading.
A manometer connected between outlets 1 and 2 reads the pressure  thus providing a direct measurement of u.
Provided that the Pitot tube is small compared with the length scale of variations of the flow, u and p can be interpreted as the speed and pressure that would exist at the position of the Pitot tube in its absence.
Pitot tubes have been most widely used in air, where they can measure speeds from about 1 m s -1 upwards.
With greater difficulty they can be used in water to measure speeds down to about 3 cm s -1 .
Since one applies inviscid theory to determine the velocity, it is essential for the Reynolds number of a Pitot tube to be high.
However, except for specially made tiny instruments, this requirement is fulfilled at all measurable speeds.
The main limitations to the use of Pitot tubes are their size and the slowness of their response; they cannot be used in flows of very small length scale, nor to measure rapid velocity fluctuations.
In most turbulent flows, for example, only the mean velocity can be measured with a Pitot tube.
The principle of operation of a hot-wire anemometer is virtually indicated by its name.
An electrically heated wire is cooled by the flow, the rate of cooling depending on the velocity.
In the simplest mode of operation, the current through the wire is maintained constant; its temperature and thus its resistance, measured by the voltage across the wire, depend on the velocity.
In an alternative, widely used, mode, a feedback circuit maintains the wire at a constant resistance and so at constant temperature; the current needed to do this is a measure of the fluid velocity.
Hot-wire anemometers have been most widely and successfully used in gas flows.
In general, hot-wires are more sensitive at low speeds than high; however, if the speed is too low, free-convection heat transfer takes over from forced convection, making the cooling insensitive to velocity.
Hot-wire anemometers can be used in air readily down to about 30 cm s -1 ; below this, measurements are more difficult although not impossible.
There are other probes that operate on exactly the same principle but are geometrically different: an important one is the hot-film anemometer; the heated element consists of a thin metallic film on the surface of a wedge-shaped thermally and electrically insulating base.
Because of their greater robustness, such probes are mostly used in liquids.
Use in water, or other electrically conducting liquid, also requires a very thin layer of insulation over the metallic film.
In some other devices semiconductor beads are used instead of metallic sensors.
Hot-wire (and hot-film) anemometers operate best in just those conditions where Pitot tubes fail.
They are small and rapidly responding.
They have thus become the principal instruments for studying fluctuating flows, in particular the phenomena of transition and turbulence.
They have the additional advantage of giving the information in electrical form, which can be processed electronically to give quantities such as intensities, correlations, and spectra.
Nearly all the measurements presented in Chapters 18 to 21 were made with hot-wire anemometers.
Although a hot-wire anemometer is simple in principle, its actual use is a matter of some complexity.
A large body of information — and a certain amount of ‘folklore’— has grown up around hot-wire anemometry.
This covers topics such as: the calibration of hot-wires (this is always necessary — hot-wires are not absolute instruments); the geometrical combinations of hot-wires needed for measuring different components of velocity fluctuations (a particularly important arrangement being two wires in the form of an X as shown in Fig. 25.2); the particular problems in achieving accuracy that arise when the velocity fluctuations are not small compared with the mean velocity; the problems associated with velocity measurements in the presence of temperature variations, to which a hot-wire probe is also sensitive; and much else.
The laser-Doppler anemometer measures velocity by measuring the Doppler shift of light scattered within the moving fluid.
The scattering centres are tiny particles of dust, small enough that they are always moving effectively with the instantaneous fluid velocity.
Usually there are enough such particles already present in any liquid or gas; if not, some are introduced.
The light source must be a laser for the beam to be sufficiently monochromatic.
Then the range of speeds that can be measured is very wide; fractional Doppler shifts as small as 10 -15 can be measured and thus speeds down to less than  — far lower than those normally encountered in fluid dynamics — though not all systems are capable of this.
Figure 25.3 shows the principle of operation.
The incident and scattered beams are inclined to one another so that the point of intersection locates the point at which the velocity is being measured.
The scattered beam interferes at the photomultiplier with an attenuated beam direct from the laser to give beats, the frequency of which is a measure of the Doppler shift.
Figure 25.3 is, of course, highly schematic; the full optical systems are much more complex than this, and take a   variety of forms.
There are also variations in the way in which the signal is detected and processed.
Sometimes the light is carried to and from the point of observation by optical fibres.
This has the advantages of not requiring high-quality optical windows on the apparatus, of making it easier to locate the measurement point, and sometimes of avoiding problems of refraction of the light by density variations.
It does, however, lose what is often one of the main advantages of laser-Doppler anemometry, the fact that there is no probe to disturb the flow.
Like hot-wire anemometers, laser-Doppler ones respond to rapid fluctuations in the velocity and thus can be used to study the details of transitional and turbulent flows.
They have, for example, been particularly useful in the studies of the details of transition that have been related to ‘routes to chaos’, as discussed in Section 24.7.
The practical difficulties of laser-Doppler anemometry obviously vary from flow to flow; sometimes it may be easy to mount a precision optical system around the flow, other times far from easy.
There are also various sources of inaccuracy, not all of which are obvious.
Again there is an extensive body of experience to be drawn upon.
The principle of using a Doppler shift to indicate flow velocity can be applied with sound waves instead of light waves.
This has not been developed into such a standard technique but has been used to investigate both laminar and turbulent flows.
One actually uses ultrasound, i.e. the frequency is far above the audible range.
Almost every effect of fluid motion must at some time have been tried as a means of measuring velocities.
Many experiments have used purpose-built probes rather than one of the standard techniques.
The topic is too diverse for a complete survey to be attempted here, but a few comments may be made.
Methods that are simple in principle are not to be scorned, though they do not always turn out to be simple in practice.
One obvious such method is the timing of the passage of marked fluid from one point to another, and many flow-visualization experiments have been made quantitative in this way.
The development of methods for the automatic scanning of flow photographs enables far more information to be obtained and is likely to become increasingly important.
Mechanical methods are also an obvious possibility, making use of the force or torque exerted by a flow on an obstacle.
They are widely used on the large-scale, a familiar example being the cup anemometer used in everyday meteorological applications.
They are more difficult to adapt to the small scale of laboratory work, but are sometimes effective.
Examples are observation through a telescope of the deflection of the free end of a cantilevered quartz fibre, and mounting a vane on the extended arm  of a moving-coil milliammeter.
Such arrangements can give high accuracy in low-speed laminar flows.
Finally, we mention two methods of which the main use is probably the calibration of a wind-tunnel or water-channel below the Pitot tube range.
This is important because many devices for measuring low flow speeds in turn require calibration.
The first is essentially the marked fluid method again, but with heat instead of a visible marker.
A fine wire is stretched across a wind-tunnel to be calibrated, an alternating current put through it, and the wavelength of the resulting temperature variations measured.
A probe — a thermocouple, for instance— is traversed along the tunnel, and the phase variations between the input to the heated wire and the output from the probe are observed.
This is tedious but it does provide an absolute calibration on which other devices can be based.
Probes for local velocity measurement, based on the timing of the passage of a heat pulse from a source wire to a detector wire, have also been developed.
Secondly, the frequency of a vortex street behind a cylinder (Sections 3.3, 17.8) is a measure of the velocity, once the relationship between the Reynolds number and the Strouhal number has been established.
The fluctuations can be detected with an uncalibrated hot-wire anemometer and so their frequency measured.
Again this technique has also been used in a special probe.
25.3 Pressure and temperature measurement
We need not consider at any length the methods used for measuring flow parameters other than the velocity, since these methods do not differ significantly from those used in other branches of physics.
There are various ways of measuring the pressure at a point on a wall.
The simplest is to link a small hole in the wall, similar to the ones in a Pitot tube, to a manometer.
This is widely used for steady or mean pressure measurements but cannot respond to rapid fluctuations.
Some form of pressure transducer is needed to measure these.
Examples are a piezoelectric crystal or a small diaphragm whose movement changes a capacitance, but the choice of devices is quite wide.
The measurement of pressure in the interior of a flow has been considered above in connection with Pitot tubes.
There is at present no satisfactory device for measuring rapid pressure fluctuations within a flow.
An important aspect of pressure measurements, as well as of velocity measurements with Pitot tubes, is the design of sensitive manometers.
The various types are described in Ref. [29].
It should be added that, whilst pressure measurements are often very useful in wind-tunnel and similar studies, the pressure variations occurring in many experiments, for example in the field of free convection, are too small to be measured.
In experiments on convection, particularly free convection, measurements of the temperature field are usually both easier and more accurate than measurements of the velocity field.
The former, therefore, often provide the main source of information about the structure of the flow.
However, we can consider the methods used very briefly, since they are, at least in principle, wholly straightforward.
The transducers most widely used are resistance thermometers and thermocouples.
A resistance thermometer often conveniently takes the form of a hot-wire anemometer probe with a very low current through it.
Thermistor beads are also often used as the sensitive elements of resistance thermometers.
The junction of a thermocouple can also be made very small, so all these devices can be made to respond rapidly.
Optical systems can also sometimes give quantitative information about temperature fields; however, these will be considered under the heading of flow visualization.
25.4 Flow visualization
The variety of methods of flow visualization is illustrated by the photographs throughout this book.
Here we collect the different methods into a systematic list, referring back to the other chapters for examples.
Again no claim is made that the list is complete.
Conceptually the simplest procedure is the introduction of smoke or dye.
The introduction of smoke into a gas flow without unduly disturbing it is rather difficult except in wind-tunnels specially designed for the purpose.
Also, the time scale is often too rapid for the eye to follow the phenomena; high-speed photography or some other special technique may be needed.
Hence, dye-in-liquid experiments are often preferred.
Nevertheless very good results can be obtained with smoke, as is illustrated by Figs. 14.6, 15.1, 17.18, 18.9, and 21.18.
A widely used method of smoke generation is to evaporate paraffin, or a similar oil, and to allow it to recondense as fine droplets.
Usually this is done in a special generator and the smoke is then injected into the flow, often in a purpose-built smoke tunnel.
However, the technique is also used in the form of a heated ‘smoke wire’ onto which the oil has been previously coated or is allowed to trickle continuously; this has some of the versatility of the hydrogen bubble method in water described below.
A particularly effective dense white smoke is produced by exposing titanium tetrachloride to the atmosphere, but this is both toxic and corrosive.
A convenient way of producing ‘instant smoke’ for simple exploratory experiments is the reaction between hydrochloric acid and ammonia vapours, but again its extensive use has its dangers.
Many of the photographs in this book illustrate the use of dye; a selection, illustrating different dyes and different ways of using them, consists of Figs. 3.4, 3.5, 13.6, 15.7, 16.4, 16.9, 17.14 and 21.6.
Convenient and effective dyes for introducing into water flows include potassium permanganate, gentian violet, and methyl blue.
The first has the advantage of producing particularly strong contrast, but at the cost of a sometimes inconveniently large density increase.
As alternatives to introducing dye, there are several ways in which marker can be produced electrically — the hydrogen bubble technique, the tellurium technique, the electrolytic precipitation technique, and the pH technique.
The first works best at high speeds, such as those in many water-channel experiments; the second and third at intermediate speeds; and the last at the low speeds likely to be encountered in convection and rotating fluid experiments.
In the hydrogen bubble method a wire stretched across the flow is the cathode of an electrolytic system, the anode being, for example, a wall of the channel.
Typically 10 V are needed with tap water, larger voltages with deionized water.
Provided the wire is very fine (typically 10–100 µm), the hydrogen bubbles produced at it are small and numerous enough to move with the flow and give the appearance of a white dye.
By insulating portions of the wire and/or pulsing the voltage, patches of dye can be produced, giving most effective pictures like those in Fig. 21.19.
A cathode made of, or coated with, metallic tellurium releases a dense brown dye, which is effective for flow visualization.
Care is needed to avoid toxic effects.
In a similar way a white colloidal cloud is produced at an anode made of certain materials.
Those containing tin (in water containing sodium carbonate) are particularly effective; solder is thus a convenient material.
This method, known as the electrolytic precipitation method, requires rather larger voltages than the others, typically 30–50 V.
The last of these electrical methods makes use of the fact that there is a change in pH (the measure of acidity or alkalinity) in an electrolyte in the vicinity of an electrode.
Hence, if the working fluid contains an indicator and is titrated to be close to the end-point of that indicator, the application of a voltage between a fine wire and some other point in the flow can produce a local colour change at the wire.
This method has two marked advantages: the production of the dye produces no density change or displacement of the flow; and the dye gradually  reverts to its previous state, so the system can be run continuously without becoming filled with dye.
It has the disadvantage that it can be used only in closed systems, not in flows where fluid is continuously entering and leaving.
The most usual indicator is thymol blue; this changes from amber (neutral) to dark blue (basic) at a cathode and so gives a clearly visible marker.
Figures 16.2 and 22.12 were obtained in this way.
With both this method and the tellurium method, it is important that hydrogen bubbles should not be produced.
For both methods, voltages in the range 1–10 V are satisfactory, and this gives no trouble in deionized water.
Variations in pH and thus in the colour of an indicator can be introduced in other ways.
For example, we saw in Fig. 15.9 how injection of very small quantities of acid and alkali produced regions of different colours (appearing as different brightnesses in a black-and-white picture) thus showing the main features of the flow pattern.
Other flow-visualization experiments make use of suspended particles (e.g. Figs. 4.4, 12.1, 16.17).
Of the various particles available, polystyrene beads are particularly useful in water, as their density is only slightly greater than that of water.
Particles in the form of small flakes take up different orientations in different regions of a flow; when light enters from one direction and is viewed from another, bright and dark patches reveal the structure of the flow (e.g. Figs. 4.8, 16.11, 17.8).
Aluminium powder has been extensively used in this way (‘silver' paint is a convenient source of sufficiently fine particles), particularly in silicone oils and other highly viscous liquids.
Other types of flake, including ones originating as fish-scales, are also available.
In all flow-visualization experiments it is necessary to give some thought as to what features of the flow are shown up.
Smoke and dye experiments usually show particle paths or streaklines (Section 6.1).
The electrical methods allow other possibilities; one can, for example, release dye all along a wire at a given instant and obtain information from its subsequent locus.
Similarly, suspended particles may be used in various ways.
Photographing them for an interval gives portions of particle paths, which, if short enough, can be used to synthesize a streamline pattern even in unsteady flow (e.g. Fig. 3.7).
Other techniques, such as using reflecting flakes, give overall information about the structure of the flow.
The last group of flow-visualization methods to be considered consists of optical techniques making use of refractive index variations in the fluid.
Such variations occur as a result of density variations associated with a temperature or concentration field.
They are thus particularly appropriate for studies of convection and stratified flow.
However, even in nominally constant-density flows it may be possible to introduce density differences which are large enough to allow the use of one of  these techniques whilst keeping the internal Froude number high enough for the flow to be unaffected.
All these techniques work best in two-dimensional configurations, as the observed pattern is the integrated effect of the passage of the light through the fluid.
In the shadowgraph method, parallel light enters the fluid and is deflected where there are refractive index variations.
If the second spatial derivative of the refractive index is non-zero the amount of deflection varies giving a pattern of bright and dark regions related to the flow structure.
Shadowgraphs appear in various places in this book, including Figs. 14.2, 14.5, 18.10 and 22.3 to 22.8.
In the schlieren method, parallel light is again used, but is brought to a focus after passing through the fluid.
A knife-edge or other stop at this focus blocks off some of the light.
If the light has been deflected in the fluid the amount passing this stop will be increased or decreased.
Changes in intensity thus relate to the first spatial derivative of the refractive index.
By having an optical arrangement in which the stop is at a conjugate point of the source whilst the observing screen is at a conjugate point of the fluid, one can obtain an image of the flow pattern with these intensity variations.
There are many variations in the details of the arrangement.
Amongst the schlieren photographs in this book are Figs. 3.12, 15.11, 21.2 and 26.22.
(It should be noted that the name ‘schlieren’ is occasionally used to refer to optical methods in general rather than this specific one, which is then known as the Topler-schlieren method.)
In an interferometer, light that has passed through the fluid interferes with light from the same source that has not passed through the fluid.
Whether this interference is constructive or destructive depends on the optical path difference, and so the pattern of bright and dark bands reflects the pattern of constant density surfaces (in a two-dimensional flow configuration).
Again there are various optical systems.
Figure 17.19 shows two interferograms.
A development of interferometry is the use of holographic techniques.
The initial interferogram is itself used as a diffraction grating to reconstruct an image.
There are various ways in which this principle can be applied.
In the one example in this book, Fig. 15.5, the net effect is similar to that of ordinary interferometry; the light and dark lines represent constant-density surfaces.
The advantage over direct interferometry is that the demands on the quality of the optical system are less severe.
25.5 Numerical experiments
Since the cases in which the equations of fluid motion can be solved algebraically are limited, numerical integration plays an important role.
This was the case even before the advent of electronic computers; a ‘classical’ example is the integration of eqn (11.28) to give the Blasius profile, Fig. 11.2.
However, modern computers obviously enable problems of much greater variety and complexity to be tackled.
In such work the proportion of numerical to algebraic analysis varies greatly.
The traditional approach, essential before the days of high-powered computers, was to proceed algebraically as far as possible and resort to numerical integration only when there was no alternative; the Blasius profile integration again provides an example.
This approach is still often adopted, as the analysis may provide insight into the significant dynamical processes.
However, it is not now the only possible approach.
At the opposite extreme a numerical approach is adopted from the outset; numerical analysis is applied to the full Navier-Stokes and continuity equations with appropriate boundary and initial conditions.
One then says that one is doing a ‘numerical experiment’.
The name implies an analogy with a laboratory experiment.
In either case the aim is to discover what processes and phenomena result from the physical laws governing the dynamics and expressed by the equations.
The mathematical properties of the equations producing the results are not directly elucidated (although one will, of course, often attempt to interpret the observations in terms of such properties).
For example, supposing that the flow investigated becomes more complicated than might be expected because of an instability, this fact would be discovered not by a stability analysis but by the observation, in the laboratory or on the computer, that a complicated flow occurred.
Numerical experiments, like laboratory experiments, must be planned with attention to the requirements of dynamical similarity (Chapter 7).
In laboratory work one may find that the desired values of the non-dimensional parameters are not actually achievable.
This is much less likely to be a problem in numerical work, which is therefore particularly important for studies of regimes inaccessible in the laboratory (e.g. convection in conditions where non-Boussinesq effects — see the Appendix to Chapter 14 — are significant, perhaps in connection with an application such as solar granulation, Section 26.6).
However, numerical experimentation has, of course, its own problems, lack of awareness of which can easily lead to spurious conclusions.
We have seen in various places in this book that flows often develop length scales quite different from the imposed ones.
Care is thus needed with any numerical procedure, on the one hand, that its grid size is small enough to resolve, for example, a boundary layer (Sections 8.3, 11.2–11.4, 12.4) and, on the other hand, that it extends into all regions of importance, such as a wake (Section 11.5), upstream wake (Section 15.2) or Taylor column (Section 16.4).
Extensive numerical work has been done on turbulent flows.
The  interpretation of laboratory experiments has been elusive (Sections 21.4, 21.6) and the aim of numerical experiments is to aid this.
Of course, these are not necessarily easier to interpret — techniques such as conditional sampling (Section 19.6) may again be invoked — but they can illuminate different aspects.
The very wide range of scales present in a turbulent flow (Sections 20.3, 21.3) produces particular problems for numerical modelling.
Indeed, except for flows at untypically low Reynolds number, even the most powerful current computers cannot handle all the data needed for a full numerical analysis of turbulent motion.
Various ways of circumventing this difficulty have been developed, usually including some representation of the effect of smaller eddies in an analysis of the larger eddies, but we cannot go into details here.
In this book only occasional direct reference has been made to the results of numerical modelling.
Most specifically, Fig. 21.22 is an example of results for a turbulent flow as discussed above.
Figures 3.3 and 6.2 show computed flow patterns past a circular cylinder; some algebraic analysis of the equations was involved as well as numerical analysis.
The derivation of Figs. 6.3–6.6 from Fig. 6.2 can be regarded as a sort of numerical experiment, although a very untypical one since all the dynamical results were contained in Fig. 6.2 and the experiment concerned only kinematic transformations of these results.