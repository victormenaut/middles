

Editorials
How go the NHS reforms?
Despite some progress they have done little to compensate for long term NHS underfunding
Implementing the NHS reforms has reached a critical stage.
With hospitals all over Britain restricting admissions, the problems of London becoming more evident by the day, and general practice fundholders stealing a march on non-fundholders, ministers are faced with a complex set of challenges.
Add to this the impending introduction of the reforms to community care and the prospect of a tight year of NHS spending in 1993–4 and you could forgive Virginia Bottomley for wishing she had a different portfolio.
In fact, the news is not all bad.
As the government is quick to point out, the level of resources allocated to the NHS has been generous in the past two years, and as a result productivity has increased and the longest waiting times have fallen.
Even more important have been the improvements brought about through separating the roles of purchaser and provider.
Both health authorities and NHS trusts have started to use their new powers to tackle longstanding weaknesses in the delivery of services and to bring about improvements for patients.
In the case of health authorities, the contracts that have been negotiated with providers have made more explicit the way in which resources should be used.
The introduction of contracts has helped to enhance the accountability of providers to purchasers and has opened up a debate about the standards of care that should be delivered.
This has been reinforced by the threat that contracts will be switched to alternative providers if the standards specified by purchasers are not met.
For their part, many NHS trusts have responded to the freedoms they now have to manage their affairs, to improve the position of low paid staff, and to introduce greater flexibility into the provision of services to patients.
In this way they are seeking to increase their competitiveness and enhance the attractiveness of their services to purchasers.
Those involved in trusts may be disappointed that they have not been allowed greater financial flexibility — a point underlined by Sir John Harvey-Jones in his Troubleshooter series on television — but a start has at least been made in improving the management of hospital resources.
General practice fundholders have also shown their ability to innovate and to use resources differently.
This includes providing additional services through primary care teams, negotiating for the provision of some outpatient services in practices, changing prescribing patterns to obtain better value for money, and using those hospitals that are prepared to deliver the standard of care specified by fundholders.
Despite these benefits it is too early to pronounce fundholding an unqualified success.
The reality is that the scheme has so far been limited to a small number of well managed practices, which for the most part were generously funded and chosen to succeed.
In these circumstances it would have been astonishing if fundholding had not produced improvements in services for patients.
Only longer experience of a wider range of practices operating in a more constrained financial climate will enable a proper judgment to be made.
One of the unanticipated gains of the reforms has been the shift of emphasis to primary care.
In part this has been promoted by fundholding, but more fundamentally it has been stimulated by health authorities engaging in a dialogue with general practitioners and giving greater priority to primary care as a result.
At the forefront of these developments is the Dorset Health Commission, an agency that brings together the district health authority and family health services authority.
The commission's decision to allocate £1 million of its budget for hospital and community health services to support developments in primary care illustrates the imaginative approach now being adopted by managers who have broken free of a mind set concentrating on acute hospital services and have started to use their resources to respond to need and not demand.
Developments across the country are uneven, but the shape of things to come can be seen in the greater provision of minor surgery by general practitioners, the increase in health promotion work in general practice, the employment of staff such as physiotherapists and dietitians to work alongside general practitioners, the establishment of shared care arrangements for treating conditions such as diabetes and asthma, and the introduction of ‘treat and teach’ schemes, in which specialists carry out some of their consultations in general practitioners' surgeries and develop the skills of general practitioners in the process.
Taken together, these changes suggest that the most important effect of the reforms to date has been to challenge the traditional balance of power within the NHS.
The old system of planning by decibels, in which acute services won the biggest share of resources, has been brought into question.
The emerging alliance between health authorities and general practitioners, and the stimulus offered by fundholders, has put hospitals under pressure and has started  to move resources in the direction of primary care.
Yet as constraints on funding begin to bite a new dynamic is becoming apparent.
This involves combined action by hospital providers, who have fulfilled their contracts with a quarter of the year remaining, and general practitioners, who as a consequence are unable to obtain hospital treatment for their patients, to put pressure on health authorities to increase the resources available to acute services.
Operating under budgets constrained by the government's public expenditure policies, health authorities can do little other than wait until the new financial year before they provide extra funds for hospitals.
In the meantime fundholding practices can use the spare capacity that exists.
As this happens equity is sacrificed as purchasing power rather than clinically diagnosed need determines which patients should be treated.
It can be only a matter of time before stories of patients being denied care because of lack of resources are in the headlines.
To this extent the wheel has turned full circle and the NHS is back where it was when Mrs Thatcher was so irritated by stories of bad news about health services that she announced her review of the NHS.
What this illustrates is that, notwithstanding the progress made in the past two years, the reforms in themselves have done little to compensate for the long term underfunding of the NHS.
Not only that, they have also accentuated the impact of constraints on funding by encouraging purchasers to favour those hospitals that are efficient and responsive to patients.
Those who gain from this process — whether in primary or secondary care — are matched by others who lose in the zero sum game that resource allocation in the NHS has become.
On the principle that losers always shout louder than winners, a winter of discontent is in prospect.
What price another NHS review?
How useful is activated charcoal?
Studies have left many unanswered questions
Charcoal will adsorb most poisons, at least to some extent — though laboratory studies suggest that lithium, iron, cyanide, and strong acids and alkalis are the exceptions.
Charcoal is prepared from vegetable matter and petroleum, and ‘activation’ creates a highly developed internal pore structure, thereby increasing the surface area from 2–4 m 2 /g to more than 1000m 2 /g.
The therapeutic potential of charcoal adsorption seems high, but three questions need to be answered.
Should charcoal be given indiscriminately to every patient who has swallowed a poison?
Could it replace the trauma, indignity, and inefficiency of induced vomiting and gastric lavage?
And which poisons can be eliminated more rapidly by repeated doses of charcoal?
Though a few reports suggest no benefit, others have shown that, when given 30 to 60 minutes later, a single dose of charcoal reduces the absorption of aminophylline, ampicillin, aspirin, carbamazepin, digoxin, doxepin, mefenamic acid, paracetamol, phenobarbitone, phenytoin, tetracycline, theophylline, and tolfenamic acid.
All these studies, however, were done on fasting volunteers given non-toxic doses and a comparatively large dose of charcoal (usually 50 g).
The results are of doubtful relevance to clinical settings in which an uncertain — but usually larger — amount of drug has been taken after food and often in association with alcohol and other drugs.
The lack of satisfactory studies on the use of activated charcoal in reducing drug absorption in poisoned patients is largely because the task is so difficult.
Comparative studies in volunteers have shown that activated charcoal is better than either syrup of ipecacuanha or gastric lavage in reducing drug absorption.
This conclusion has been supported by observations in patients poisoned with paracetamol.
Nevertheless, it has not yet been shown that in these circumstances charcoal reduces the need for an antidote.
Turning to the third question, repeat doses of activated charcoal are thought to act in several ways.
Firstly, the charcoal adsorbs unabsorbed poison still present in the gut.
This is particularly relevant in the cases of slow release preparations such as theophylline and of drugs that are absorbed slowly because they decrease gastric motility (for example, tricyclic antidepressants).
Next, charcoal adsorbs drugs that are secreted in bile, thereby preventing their enterohepatic recirculation.
Thirdly, charcoal binds any drug that diffuses from the circulation into the gut lumen, thus interrupting the enteroenteric circulation.
After absorption a drug will re-enter the gut by passive diffusion provided that the concentration there is lower than that in the blood.
The amount diffusing depends on the concentration gradient, the intestinal surface area, the permeability of the mucosa, and blood flow.
Immediate adsorption of the drug by charcoal in the lumen ensures that the concentration gradient is kept as high as possible and that diffusion continues.
A few unusual drugs such as digoxin may be secreted actively by the intestinal mucosa, but this process is unlikely to contribute more than passive diffusion does to the effect of activated charcoal on drug clearance.
Again much of the published evidence comes from studies in volunteers, which have shown that repeated doses of activated charcoal increased the elimination of amitriptyline, carbamazepine, dapsone, doxepin, digoxin, digitoxin, phenobarbitone, phenytoin, phenylbutazone, and theophylline but not of imipramine or salicylate.
Studies in poisoned patients have confirmed these observations in the case of carbamazepine, dapsone, digoxin, phenobarbitone, phenytoin, and theophylline.
There is also evidence that, contrary to findings in volunteers, activated charcoal will increase the elimination of salicylates, possibly because drug metabolising enzyme systems are fully saturated at the higher plasma concentrations attained in cases of acute poisoning.
A beneficial effect has also been claimed in dothiepin poisoning.
What conclusions can be drawn?
Most patients coming to hospital after an overdose are not at serious risk.
The challenge is to identify at an early stage those who are most at risk of developing serious complications so that appropriate treatment may be given.
More information is required before gastric lavage can be abandoned completely in favour of giving activated charcoal, but a reasonable alternative to lavage could be to give 50–100 g of activated charcoal to adults who have taken a substantial overdose of a toxic substance no  more than two hours previously.
The management of young children is more difficult — most episodes are poison scares rather than true poisonings.
Rather than give young children charcoal immediately on presentation, we suggest confining it to the few who develop symptoms — in a dose sufficient to increase elimination of the drug.
Repeated doses of oral activated charcoal have not yet been shown to reduce morbidity and mortality.
Further studies are required to establish its place and the dose to be given.
Until these data are available, severely poisoned adults should be given 150–200 g through a nasogastric tube over 4–8 hours with the aims of achieving a maximum reduction in elimination half life and an improvement in the clinical state.
The total dose given is probably more important than the frequency of dosing.
The cervical spine in rheumatoid arthritis
Needs careful assessment
Rheumatoid arthritis commonly affects the cervical spine, causing several well defined deformities.
Damage to the cervical spine from rheumatoid arthritis has been noted in 30% to 46% of necropsy studies and is second in frequency only to that seen in the metatarsophalangeal joints.
One in four inpatients with rheumatoid arthritis and between 17% and 86% of all patients with this disease have radiographic evidence of instability of the cervical spine.
These high rates reflect the anatomy of the cervical spine and the dynamic forces that act on it.
Each of the apophyseal and ligamentous articulations of cervical spine is susceptible to the same inflammatory changes as those in peripheral joints of patients with rheumatoid arthritis.
Furthermore, the cervical spine is constrained between a somewhat rigid thoracic spine and a skull weighing 6 kg; movement of the head, which has been estimated to occur around 600 times each hour, adds to the forces on the articulations.
Any segment of the cervical spine may be affected by the rheumatoid inflammatory process, but destructive changes are most prominent at the occipito atlantoaxial junction.
Atlantoaxial subluxation is the most common deformity and is due to destruction and resultant laxity of the transverse ligament.
This allows the atlas to move forward relative to the odontoid process of the axis when the neck is flexed.
In radiographs this is seen as a widening of more than 3 mm in the space between the anterior arch of C1 and the odontoid.
The corresponding reduction in the space posteriorly restricts the canal available for the spinal cord.
By contrast, posterior subluxation of the atlas is infrequent and is seen only in the presence of severe erosion and dislocation of the odontoid.
Recent studies using magnetic resonance imaging in patients with atlantoaxial subluxation have shown an inflammatory mass of granulation tissue around the odontoid arising from the synovial lining of the articulations.
This periodontoid mass is not visible in patients who have had surgical fusion of the first two cervical vertebrae or in whom deformity has progressed to that of atlantoaxial impaction (see below).
The bulging of this mass may further reduce the space available for the spinal cord and cause neurological deficits in patients with only a moderate degree of atlantoaxial subluxation.
When the disease affects one of the occipito atlantoaxial articulations (termed lateral mass) it may produce the syndrome of non-reducible rotational tilt of the head, the main clinical features of which are occipital pain, tender points in  the neck, and tilting of the head toward the affected side.
If both sides are affected collapse of the lateral masses allows the skull to descend on to the cervical spine and the odontoid to enter the foramen magnum.
This deformity has been termed cranial settling, superior migration of the odontoid, or atlantoaxial impaction and is seen almost exclusively in association with atlantoaxial subluxation.
Subaxial subluxation is a late development; it often affects several vertebrae, leading to a ‘stepladder’ deformity.
Extensive rheumatoid disease of the cervical spine results, then, in a combined deformity of atlantoaxial subluxation subaxial subluxation and atlantoaxial impaction — a devastating complication and a truly formidable therapeutic challenge.
Deformities of the cervical spine are seen most often in patients with rheumatoid arthritis of more than 10 years' duration.
They are usually associated with severe destructive peripheral arthritis, rheumatoid nodules, a high titre of rheumatoid factor, and treatment with corticosteroids.
Progression of the deformity is unpredictable in a given patient, but follow up for five to 10 years has shown worsening of the instability in 16% to 41% of the patients.
These percentages may be too low: with progression of the deformity to atlantoaxial impaction the magnitude of the atlantoaxial subluxation may seem on radiography to be reduced, giving the false impression radiographically of improvement.
Many patients with rheumatoid disease of the cervical spine remain asymptomatic for years, but they are at risk of a range of neurological complications and even sudden death from medullary compression.
Neurological abnormalities may be subtle and difficult to establish in the presence of deforming arthritis, muscular atrophy, and the neuropathy that may be associated with rheumatoid arthritis.
Patients may complain of intractable pain in the neck or the back of the head.
They may have symptoms of vertebrobasilar insufficiency with vertigo or drop attacks and may have signs of myelopathy.
Myelopathy, once it develops, is usually rapidly progressive.
In patients with subaxial subluxation myelopathy may occur with only slight subluxation because of the narrower diameter of the spinal canal below the axis.
Profound and complex neurological deficits may be found in patients with the combined deformity of atlantoaxial subluxation-subaxial subluxation-atlantoaxial impaction.
Atlantoaxial subluxation with subluxation of less than 9 mm carries the least risk of neurological damage, while atlantoaxial subluxation of more than 9 mm, atlantoaxial impaction, subaxial subluxation, non-reducible rotational tilt of the head, and combined deformities are all associated with a higher risk of neurological deficit.
Plain radiographs of the cervical spine in flexion and extension will allow recognition of atlantoaxial subluxation and subaxial subluxation.
In patients with atlantoaxial impaction, however, odontoid erosion and osteoporosis may make plain radiographs inadequate for assessing the extent of cranial settling and resultant penetration of the odontoid into the foramen magnum.
Various measurements have been advocated to define the extent of cranial settling.
McGregor's line, which assesses the protrusion of the odontoid process above the foramen magnum, is widely used in clinical practice.
Because of its superior contrast capabilities magnetic resonance imaging is the current first choice technique for assessing instability of the cervical spine.
Patients with a minor degree of atlantoaxial subluxation or with subaxial subluxation need treatment only with a soft cervical collar — which provides symptomatic relief, acts as a reminder to patient and doctor, and may provide some degree of protection from trauma.
In the presence of intractable cervical pain, neurological deficits, or myelopathy, or combinations of these, the recommended procedures are halo stabilisation and surgical arthrodesis.
The place of surgery in the early stages of instability of the cervical spine is less certain, nor is there any consensus as to whether progression can be retarded by early surgery.
In a retrospective study of 110 patients with rheumatoid arthritis who had surgical treatment we found recurrence of their cervical instability after a mean interval of nine years in 5.5% of patients with atlantoaxial subluxation who required only atlantoaxial fusion — but a 36% recurrence rate after a mean interval of 2.6 years in patients with atlantoaxial subluxation and atlantoaxial impaction who required fusion from the occiput to C3.
No patient with atlantoaxial subluxation and fusion of C1 and C2 progressed to develop atlantoaxial impaction.
Many patients with substantial deformities remain asymptomatic, but they are at increased risk of neurological damage with the passage of time.
They are also at risk if they need surgery or induction of anaesthesia for any other reason.
In one recent study 60% of patients with rheumatoid arthritis having total hip or knee replacements had radiographic evidence of instability of their cervical spine, and nearly half of these had no symptoms referrable to their necks.
Patients with rheumatoid arthritis undergoing any major surgical procedure should be assessed by having radiographs taken of the cervical spine in flexion and extension.
Indeed, all patients with rheumatoid disease of the necks, even though asymptomatic, should be followed up carefully for evidence of neurological deficit, and all should undergo periodic radiographic monitoring.
Health promotion and children and teenagers
Why it is mainly the government's responsibility
The Health of the Nation contains several targets directly affecting the health of present children and teenagers and future adults.
These include reducing smoking in 11–15 year olds by one third, reducing the proportion of energy derived from fats to 35%, reducing deaths from accidents by one third in under 15 year olds and by one quarter in those aged 15 to 24, reducing suicides by 15%, and halving the conception rate in girls under 16.
The idea that these targets might simply be achieved by a cosy consortium between the health and education services begins to crack with research reported by Nutbeam et al in this issue (p 102).
But how could we believe that health and education could be the main players in achieving these targets?
Was it arrogance and the need to be needed on the part of doctors and teachers or duplicity on the part of the government?
Most research suggests that the health of a nation is mainly due to socioeconomic factors with medical and educational interventions accounting for very little.
After 13 years of Conservative government this country is in rapid economic decline, and yet the medical and education professions seem intent on bearing responsibility for not being able to avoid the inevitable result — a decline in the nation's health.
Thus Nutbeam et al are disappointed that two well tried instruments for preventing children from smoking failed to have any effect, especially when the schemes worked elsewhere.
One of their interventions, the family smoking education project, had worked in Norway, but at the same time as the price, availability, and promotion of cigarettes were being controlled.
Children's motivations for certain behaviours are highly complex.
In a study of nearly 650 children aged 14 to 17, 98% knew that smoking harmed their health and 89% knew that passive smoking was harmful — yet one in five were, or had been, smokers.
This gap between children's knowledge about what endangers their health and how they use this knowledge is largely uncharted territory.
What we know is that simple interventions in a single area — like a school health education programme — are unlikely to work on their own.
We know that peer group pressure, cigarette advertising, imitation of parents, boredom, the need to experiment, and self image all affect children's decision to begin smoking.
We also have a good explanation of why children continue to smoke: cigarettes are highly addictive.
It is the proposed solutions that are simplistic.
To change behaviour requires tactics that match the complexity of the causes.
These should include asking the children themselves how to solve the problem, feeding back their own views to them, and enacting effective laws and enforcing them (in a recent survey carried out by the local trading standards department of 54 premises selling cigarettes in Oxford a 12 year old was able to buy cigarettes in 13 of them).
In addition, government policies need to be believable; banning cigarette advertising would almost certainly cut consumption.
Two papers in this week's journal show how much further ahead Australia is when it comes to implementing government policies that attempt to improve health.
The position of the health professional — doctor, health visitor, or nurse — is not to pretend that their bit of health promotion is going to have more than a small additive effect to all the other necessary inputs, and they should be aware that they may be wasting their time if the other inputs are not there.
Rather they should continue to point out that health promotion is mainly the government's responsibility, as are the economy and the laws of the land.
Drugs, secrecy, and society
Less secrecy about drug regulation is in the public interest
Later this month a private member's bill that would require the government to disclose information on the safety and efficacy of drugs to the public should receive its second reading.
The Medicines Information Bill is founded on two main principles: that those who keep secrets should not have the last word on where secrecy begins and ends and that openness should be the rule and secrecy the exception.
Secrecy confers power on those who know the secret while those who do not are at a disadvantage.
In pharmaceutical medicine the culture of secrecy is deep and strong, and much evidence exists of its negative effects on health, organisational performance, and honest scientific inquiry.
Secrecy hides not only what is known but how much is unknown.
When it threatens the conduct of science and the spirit of democracy it should be curbed.
British law requires the authorities to withhold all information about licensed drug products, including counterfeit medicines.
Even government policies on disclosure are secret because the deliberations of the Committee on Safety of Medicines and other parts of the control system are also entirely confidential.
At least one member of the committee has no objection to the committee's papers being publicly available and believes that most data in licence applications could, with little loss to anyone, be made publicly available.
The proposed new European Medicines Evaluation Agency may decide to publish in outline its reasons for granting licences, which would match long established practice in the United States and elsewhere.
Yet there has been no suggestion that this agency should say why licences are refused (as in Norway) or hold public inquiries when unsafe drugs are withdrawn (as in the United States).
Despite a series of drug disasters no public inquiry has ever been held in Britain.
Why is openness reserved for disasters involving trains, stadiums, boats, and planes?
The main reason is to protect the commercial interests of pharmaceutical companies, but in Britain (and many countries of the European Community) this has led to blanket secrecy because of the failure to distinguish between legitimate trade secrets (such as manufacturing processes useful to a competitor) and commercially sensitive information (including data on drug safety and problems with efficacy).
Officials believe that the public tends to make impossible demands and would be alarmed by disclosure.
For example, a senior drugs regulator said that the recent scare over human insulin had led to 100 or so patients stopping their drugs, with predictably disastrous results.
If this is true, and evidence for it is hard to come by, we must find better ways of avoiding such problems.
Perhaps it is the aura of secrecy, rather than the disclosure, that causes most difficulties.
But there are now stirrings for more openness and increasing awareness that secrecy is a problem, even from the Medicines Control Agency.
At the agency's recent annual meeting the Nobel laureate Sir James Black urged that the drug regulatory process should become an integral part of drug development — which it could be if the authorities opened up.
In the meantime, he complained of the waste of experimental data that were locked away and the emphasis on compliance rather than scientific inquiry.
‘The main enemy in drug development is ignorance,’ said Black, and more openness is needed to overcome it.
Openness is a tough discipline but essential to the development of trust.
In the long run, therefore, it should make business sense and may be the only thing that brings peace of mind.
GMC in the dock again
The council should investigate unscientific treatments
‘The jury is still out on whether self regulation by doctors is adequate,’ says Ian Kennedy, a professor of law and a former member of the General Medical Council (GMC).
The approval last year of a mechanism to deal with doctors whose performance is consistently poor was greeted by most observers as a step likely to sustain self regulation (although at least one former member of the GMC disagreed).
But a paper we publish today will not help the council's case (p 122).
Professor Anthony Kay describes a case in which the council avoided investigating what many would have expected to be the central issue — was the accused doctor offering a treatment that could undoubtedly do harm but for which there was no scientific evidence of benefit?
Dr Keith Mumby, a clinical ecologist, faced five charges when he appeared before the GMC last summer, but the charges did not include practising an unscientific form of medicine.
Indeed, the chairman of the committee on clinical immunology and allergy instructed it that the hearing was not a trial of alternative medicine or the provocation-neutralisation test, which lies at the centre of clinical ecology.
Yet clinical ecology has been severely criticised in the High Court and castigated by the Royal College of Physicians and the American College of Physicians; and the provocation testing used by clinical ecologists has been shown by a paper in the New England Journal of Medicine to be unscientific.
The GMC was founded to protect the public against quacks.
Its contract is to guarantee that the doctors consulted by members of the public are properly qualified and will give competent treatment.
If a doctor offers a risky and as yet scientifically unproved treatment the GMC surely owes it to the public either to stop the doctor offering that treatment (outside scientifically valid trials) or to stop the doctor practising at all.
The council may demur for two reasons.
Firstly, it might argue that so much of what doctors do lacks solid scientific support that it would be ludicrous to try to insist that all doctors practise scientifically valid medicine all the time.
But surely there is a whole order of difference between inserting grommets for glue ear (a much criticised treatment) and injecting people with extracts of gas and petrol fumes?
Secondly, the council may balk at the costs of determining whether a treatment is scientifically valid.
The courts often sit for months over scientific questions — for example, whether whooping cough vaccine caused brain damage — and the GMC may imagine itself stuck with cases lasting months and costing millions.
But doctors may be able to make swifter judgments than a lay jury, and anyway self regulation cannot be bought on the cheap.
To protect the public, to uphold the standing of the medical profession, and to safeguard self regulation the GMC needs to be willing to investigate treatments offered by doctors that are risky and unscientific.
PAPERS
Cancer in Cumbria and in the vicinity of the Sellafield nuclear installation, 1963–90
Abstract
Objective
To reappraise the epidemiological findings reported by the Black Advisory Group concerning a possible excess of malignant disease, particularly of childhood acute lymphoid leukaemia and non-Hodgkin's lymphomas, in the vicinity of the Sellafield nuclear installation, and to determine whether any excess of malignant disease had occurred among people aged 0–24 years in the area in the years after the Black report — that is, from 1984 to 1990.
Design
Calculation of incidence of cancer using data from population based cancer registries and special surveys.
Setting
England and Wales; county of Cumbria; county districts Allerdale and Copeland within Cumbria; Seascale ward within Copeland.
Subjects
All residents under the age of 75 years in the above areas, but with particular reference to those aged 0–24 years.
Main outcome measures
Numbers of cases and incidence particularly of lymphoid leukaemia and non-Hodgkin lymphomas in those aged 0–24 years, but including other cancers and age groups.
Results
Previous reports of an increased incidence of cancer, especially of leukaemia, among those aged 0–24 years in Seascale during the period up to and including 1983 are confirmed.
During 1984–90 there was an excess of total cancer among those aged 0–24 years.
This was based on four cases including two cases of non-Hodgkin lymphoma but none of leukaemia.
There was an increased, but non-significant, incidence of other cancers, based on two cases (one pinealoma and one Hodgkin's disease) occurring among those aged 15–24 years during 1984–90.
This was not observed in the younger age group or in previous years.
For the immediately surrounding area — that is, the county districts of Allerdale and Copeland excluding Seascale and in the remainder of Cumbria — there was no evidence of an increased incidence of cancer among those aged 0–24 years in either period.
Conclusions
During 1963–83 and 1984–90 the incidence of malignant disease, particularly lymphoid leukaemia and non-Hodgkin lymphomas, in young people aged 0–24 in Seascale was higher than would be expected on the basis of either national rates or those for the surrounding areas.
Although this increased risk is unlikely to be due to chance, the reasons for it are still unknown.
Introduction
In the past 10 years there have been many suggestions of an increased incidence of cancer, or of clusters of cases, in the vicinity of nuclear installations.
The most detailed investigations have concerned the Sellafield nuclear reprocessing plant in West Cumbria.
An advisory group chaired by Sir Douglas Black investigated the suggestion that there was an increased incidence of cancer in the vicinity of this installation.
This group produced a report discussing the discharges around the site and the extent of radiation exposures and giving estimates of the likely risks.
The report included a series of epidemiological analyses and also contained lists of patients resident in Seascale and the surrounding area.
The analyses covered a variety of diagnostic groups, age groups, and periods.
Few other areas have been the subject of systematic epidemiological studies: in the United Kingdom such studies include those of Dounreay, of Aldermaston and Burghfield, and of nuclear installations generally.
Since the Black report further cohort and case-control studies of the area around Sellafield have been carried out, but there has been no comprehensive analysis of cancer incidence.
This report includes analyses of the incidence of cancer among people aged 0–24 years during the period up to 1983.
These analyses are based on more complete data than were available to the authors of the Black report.
Although the data are not directly comparable with those in previously published analyses, they are nevertheless subject to the major criticism of the studies discussed in the Black report — namely, that the results were vitiated by biased selection of diagnostic groups, age groups, calendar periods, and areas.
Although the Black report does not contain any explicit statement about the period that it covers, none of the analyses on which it is based go beyond 1983.
Our report is mainly concerned with 1984 onwards.
In planning our analyses we were concerned to avoid the biases that affected the analyses of the period up to and including 1983; it was agreed in advance, at a meeting of a working group of the Committee on Medical Aspects of Radiation in the Environment, that the principal hypothesis to be tested should be that ‘no excess of leukaemia or other cancer in 0–24 year olds has occurred in the area of the Sellafield plant from 1984 to the present, and that the diagnostic groups, areas, and calendar periods to be analysed should be these set out below.’
Methods
diagnostic groups
In planning this report it was agreed that the analyses would cover both total malignant disease around Sellafield and also several individual diagnostic groups.
The diagnostic groups were defined as follows, the disease categories in brackets referring to the standard classification for childhood cancer:(a ) lymphoid leukaemia and non-Hodgkin lymphomas, including Burkitt's lymphoma, unspecified lymphoma, and hairy cell leukaemia (I(a), I(b), II(b), II(c), II(d), plus ICD-O M code 9940/3);(b ) all other and unspecified leukaemias (I(c), I(d), I(e) except ICD-O M code  9940/3);(c ) Hodgkin's disease (II(a));(d ) brain and spinal tumours, including non-malignant tumours (III(a) to III(e)); and (e ) all other malignant diseases (II(f), IV to XII).
Diagnostic group (a ) was chosen in the light of discussions in the report on Dounreay (paras 2.27–2.30) and of the conclusion of the working group that acute lymphoblastic leukaemia could be adequately distinguished from other leukaemia in our data.
Chronic lymphocytic leukaemia never occurs in childhood, and so in children lymphoid leukaemia is equivalent to acute lymphoblastic leukaemia.
Hairy cell leukaemia is now regarded as a variant of chronic lymphocytic leukaemia and has been grouped with it.
Langerhans cell histiocytosis (histiocytosis X) was not included in the analyses as this group of diseases is not now regarded as neoplastic.
Areas
The areas used throughout the study (figure) were (a ) Seascale ward;(b ) Allerdale and Copeland county districts (without Seascale), the two county districts nearest to Sellafield;(c ) Cumbria county (without Allerdale and Copeland).
All boundaries came into force with the local government reorganisation of 1974.
Cases were assigned to areas according to their residence address at diagnosis as defined for the national cancer registration scheme.
Calendar periods
Data are presented for 1963–83 and for 1984–90.
The period 1984–90 does not overlap with any of the analyses covered in the Black report.
Case ascertainment
For the analyses of childhood cancers including leukaemias — that is, those diagnosed in children aged 0–14 years — data were obtained from the National Registry of Childhood Tumours at the Childhood Cancer Research Group.
Cases are ascertained from cancer registries, the Northern Region Children's Malignant Disease Registry (for 1968 onwards), the Manchester Children's Tumour Registry (for cases occurring before 1974 in the area now called South Cumbria), death certificates, entries to the Medical Research Council leukaemia trials (1970 onwards), and the register of the United Kingdom Children's Cancer Study Group (1977 onwards).
Details of the methods of ascertainment of cases and verification of diagnostic and other information have been published elsewhere.
For the areas in our study there was a high degree of completeness of ascertainment from 1968 onwards for children aged 0–14 because these areas are included in the data collected prospectively for the Northern Region Children's Malignant Disease Registry and all these cases were included in the National Registry of Childhood Tumours.
The analyses for people aged 15–24 were based mainly on data from the Northern Region Children's Malignant Disease Registry, which originally covered only children aged 0–14 years but was extended, as a result of the recommendations of the Black Advisory Group, to people aged 15–24.
For 1969–83 registrations at age 15–24 were obtained from the Northern Region Cancer Registry and (for 1969–73 in what is now South Cumbria) the North Western Regional Cancer Registry; in general, no further effort was made to ascertain cases.
Ascertainment through regional cancer registries may not be complete, and so a special search of hospital and pathology department records was made to ascertain any cases of leukaemia or lymphoma in Allerdale and Copeland for 1969–83 that might not previously have been registered.
This resulted in the inclusion of a further four cases in addition to the 27 previously registered.
From 1984 onwards cases have been ascertained directly from hospitals throughout the Northern region.
Cumbria has been included in the Leukaemia Research Fund data collection study since it began in 1984.
The data collection study also ascertains cases of leukaemia and lymphoma directly from diagnostic sources within hospitals in its study areas, and these are crosschecked with cancer registration records; ascertainment for these diagnostic groups is believed to be virtually complete.
For 1984–90 a comparison between the Northern region's children's register and the data collection study found no additional cases for Allerdale and Copeland, but for the rest of Cumbria seven were added to the register.
Among people aged 25–74 the only analyses in our paper are of leukaemia and lymphoma for 1984–90, using data derived from the data collection study.
Population data
For the calculation of incidences we needed population estimates for five year age groups for each of the years 1963–90.
Census data and estimates from the Office of Population Censuses and Surveys were used wherever these were available.
For Seascale in 1986 estimates from CACI Ltd were used.
For other years estimates were made by linear interpolation, a proportionate adjustment being made if the total of the estimates so obtained for individual age groups did not agree with the independent estimate from the Office of Population Censuses and Surveys for all ages taken together.
Incidence
Incidences were expressed as annual rates per million population.
For ages 0–14 and 15–24 age standardised rates were calculated as simple averages of the age specific rates for the five year age groups they contained.
Standardised registration ratios were calculated by expressing the observed number of cases as a percentage of the expected number, the expected number being calculated by applying the national age specific rates for each five year age group to the number of people in the population being considered.
Comparisons with national data
On the one hand, the most obviously appropriate analyses of the incidences are comparisons of Seascale with the rest of Copeland plus Allerdale and of each of these areas with the rest of Cumbria, but such  comparisons are based on comparatively small numbers.
On the other hand, comparisons with national data may be less relevant in that there may be broad geographical variations either in incidence or in case ascertainment that would make it difficult to determine whether an increase in Seascale or Allerdale and Copeland was a local effect (and hence possibly related to Sellafield) or whether it affected the whole of Cumbria.
By calculating rates for each of these areas it is possible to examine the geographical extent of any apparently local increase.
National data of the same quality used for the present analyses were not always available, though even 20% under-registration, which is unlikely, would not have affected the conclusions of this report.
We compared the incidence in the study areas with national data using the following sources: for childhood cancer, data from the National Registry of Childhood Tumours for 1969–87; for young people aged 15–24, cancer registration statistics for England and Wales for 1971–86, though these data were not subjected to the review processes carried out for the specialist registries; for leukaemias and lymphomas in those aged 25–74, data from the data collection study covering about one third of the population of England and Wales.
Results
population estimates
Estimates for five year age groups and the calendar years 1963–90 are summarised in table I.
national data on cancer registrations
Age standardised annual incidence of specific cancers for England and Wales is given in table II.
cases of cancer in young people in seascale since 1953
Table III lists all cases of cancer diagnosed during 1953–91 in people aged 0–24 in Seascale.
We checked as far as possible the information for the cases listed in tables 2.1 to 2.4 of the Black report; in table III cross references are given to the cases listed in these tables of the Black report and, when necessary, the information has been corrected.
Ten cases diagnosed during 1963–90 (cases 4–13) were included in our analyses.
One from the most recent period, 1984–90 (case 10 in table III), was included in the Black report but with the year of diagnosis given wrongly as 1983 instead of 1984.
This case was notified to the Black Advisory Group during the course of its investigation and does not appear in any of the analyses in its report.
We therefore included the case in our analysis for the post-Black period 1984–90 as this information should be regarded as testing rather than generating the Seascale hypothesis.
One further patient (case 15 in table III) had a second address in another part of Britain, to which he should correctly be allocated under the rules followed by the national cancer registration scheme; he has therefore been excluded from the analyses.
Four other cases in table III were excluded from our analyses because they fell outside the period covered: cases 1–3 occurred before complete registration data were available, and case 14 occurred in 1991 after the decision had been taken to make 1990 the final year of the analysis.
cancer incidence at ages 0–14 years, 1963–90
Table IV shows the numbers of cases of cancer together with the age standardised rates in children aged 0–14 years for each diagnostic group in the three study areas during 1963–83 and 1984–90.
The rates of malignant disease and specifically of lymphoid leukaemia and non-Hodgkin lymphomas for children in Seascale were substantially higher than those for the remainder of Copeland and Allerdale, Cumbria, and England and Wales.
In Allerdale and Copeland (excluding Seascale) the rates for lymphoid leukaemia and non-Hodgkin lymphomas were lower than those for other parts of Cumbria and for England and Wales.
In the remainder of Cumbria the rates were higher than those for England and Wales.
Thus there is no evidence over the period from 1963 onwards that the excess found in Seascale extends to a wider area around Sellafield, though for the most recent period there was a slight increase in the incidence  of lymphoid leukaemia and non-Hodgkin lymphomas in the rest of Cumbria, particularly among children aged 0–4 years.
cancer incidence at ages 15–24 years, 1969–90
Results, mainly from data from the Northern Region Children's Malignant Disease Registry, for those aged 15–24 for 1969–90 are given in table V. In Seascale there were four cases, of which three were diagnosed during 1984–90 (one non-Hodgkin lymphoma, one Hodgkin's disease, and one pineal tumour).
Again this represents a considerable increase over the national rates whether one considers lymphoid leukaemia and non-Hodgkin lymphomas or all malignant disease and for both 1963–90 and 1984–90.
In the remainder of Copeland and Allerdale and in the rest of Cumbria the rates were unremarkable.
leukaemia and lymphomas at ages 25–74 years, 1984–90
Table VI shows the numbers of cases of leukaemia and lymphomas for 10 year age groups in the age range 25–74, together with age specific and overall incidence rates, in the three study areas during 1984–90.
In Seascale there were two cases of non-Hodgkin lymphoma, both occurring at ages 55–64.
On the basis of the national rates in the data collection study one case would be expected.
Thus the excess found among young people does not extend to the older age groups.
rates of malignant disease in seascale at ages 0–24 years, 1963–83 and 1984–90
The rates for Seascale were based on very small numbers.
The method used to carry out a formal analysis of the hypothesis that there is no raised incidence of cancer among young persons aged 0–24 was the same as that in the Black report and was based on a comparison with the national rates for England and Wales summarised in table II.
It is clear from a comparison of the rates in tables II, IV, and V that much the same results would be obtained if the rates for Cumbria or for Allerdale and Copeland were used.
Expected numbers of cases are calculated on the assumption that the true rates are the same as those for England and Wales.
In table VII we compared the observed numbers of cases with those expected for lymphoid leukaemia and non-Hodgkin lymphomas, for all other cancers, and for all cancers combined separately for 1963–83 and 1984–90.
In 1963–83 a total of six cases, of which five were lymphoid leukaemia and non-Hodgkin lymphomas, occurred.
The expected number of cases of lymphoid leukaemia and non-Hodgkin lymphomas on the basis of national rates is 0.49 (standardised registration ratio=1015); the expected number for all malignant disease is 2.18 (standardised registration ratio=275).
The probabilities of such high values occurring by chance are respectively p=0.00016 and p=0.024.
These probabilities are low and support the findings of the Black report, though they exaggerate the significance of the findings because there was no prior hypothesis, formulated independently of the observed data, in determining the diagnostic groups, age groups, periods, or area to be studied.
This criticism does not extend to analyses of subsequent periods.
In table VII we analyse also the data for cancer occurring among young people in Seascale during 1984–90, when a total of four cases occurred in those aged 0–24 years.
The expected number of cases of lymphoid leukaemia and non-Hodgkin lymphomas in this period and age group is 0.12 (standardised registration  ratio=1620).
For all diagnostic categories taken together the expected number is 0.60 (standardised registration ratio=667).
Whether we consider just the two cases of lymphoid leukaemia and non-Hodgkin lymphomas or the total of four cases there was a significant (p=0.0070 and p=0.0034, respectively) excess of cases in Seascale in this period.
Discussion
Two principal questions are considered in this paper.
Firstly, do the findings of the Black report relating to the period up to and including 1983 remain unchanged now that more comprehensive data sets and analyses are available?
Secondly, did the excess incidence of childhood leukaemia in Seascale found in the various analyses summarised in the Black report persist in later years?
The present report covers the periods 1963–90 for children aged 0–14 years, 1969–90 for people aged 15–24, and 1984–90 for leukaemia and lymphomas in adults.
As explained in the introduction, the diagnostic groups, age groups, calendar periods, and areas to be analysed were agreed in advance of the analyses being carried out.
The conclusions of the Black report are confirmed insofar as they relate to malignant disease occurring in young people between 1963 and 1983; on the basis of the six cases included in table III we conclude that the excess in Seascale is unlikely to have arisen by chance (table VII).
All of the six cases are included in the report by Craft et al .
We omitted from these analyses case 15 in table III because this person had an address in another part of Britain which was regarded as his area of residence for the purposes of the national cancer registration scheme.
Inclusion of this case would have strengthened our conclusions about the period 1963–83.
For the period before 1984 our analyses rely on much the same evidence as the Black report, though more complete registration data are now available.
There is, however, no way of overcoming the objection that analyses of Seascale data for this period are not amenable to any rigorous statistical evaluation because the area, age group, and types of disease to be studied were selected as a result of the observed clustering of cases.
This criticism cannot be applied to the results for 1984–90.
Even the case from this period that was included in the Black report (with the year of diagnosis wrongly given as 1983 rather than 1984) was diagnosed after concern had been raised about the high incidence in Seascale.
For those aged 0–24 there is an excess of malignant disease that is highly unlikely to have arisen by chance (table VII).
These more recent data therefore strengthen the suggestion that there is an increased incidence in Seascale among those aged 0–24 years, but whereas the original findings related mainly to lymphoid leukaemia in those aged 0–14 years, there were no leukaemias and only one case below age 15 during 1984–90.
Of the four cases found in this period two had non-Hodgkin lymphomas, one Hodgkin's disease, and one a pineal tumour; the excess is mainly attributable to non-Hodgkin lymphomas.
We have excluded from these analyses case 14 in table III because this case occurred beyond the period specified in planning the analysis (see introduction).
The occurrence of this case does, however, strengthen the conclusion that there is an excess of lymphoid leukaemia and non-Hodgkin lymphomas among those aged 0–24 years in Seascale.
As regards other cancers in this age group, there is a small, non-significant excess during 1984–90 but no overall excess if the whole period 1963–90 is considered.
There is no evidence that the raised incidence in Seascale extends to the two county districts nearest to Sellafield or to Cumbria generally.
There was an apparently raised incidence of lymphoid leukaemia and non-Hodgkin lymphomas in the rest of Cumbria in 1984–90 among those aged 0–4 years, but this is based on only 13 cases and is difficult to interpret.
Birth records have been obtained for the 42 children with cancer diagnosed up to the age of 4 years throughout Cumbria during 1984–90 in order to investigate the possibility that some of these children had been born in Seascale and then moved, but in fact only the child resident in Seascale at diagnosis was also domiciled there at birth.
explanations for our findings
We consider some of the main hypotheses that might account for our findings.
Firstly, the results may simply be due to chance since a search for clusters is likely to reveal some spatial aggregations of cases even if there is no causal explanation: this is particularly true if the age groups, areas, calendar periods, and diagnostic groups to be studied are not specified in advance.
When claims were originally made concerning a cluster at Seascale it seemed quite possible that this was the explanation.
The accumulation of further data since the original reports and the analysis in table VII suggest that this is not the correct explanation.
Secondly, the most obvious suggestion is that the cases are caused by the direct effects of environmental radiation on the child or fetus.
The results of calculations based on estimates of environmental discharges and on modelling of risks attributable to such radiation suggest that the doses delivered to the child or fetus were far too low to explain the cluster unless either the discharges were considerably underestimated or the assumptions made in computing the risks were grossly incorrect.
Thirdly, Gardner et al , in their case-control study of leukaemia and lymphoma diagnosed during 1950–85 among young people in West Cumbria, concluded that the excess occurred among children whose fathers had high levels of exposure to radiation before the child was conceived, and perhaps particularly in the preceding six months; they suggested that some cases were the result of paternal germ cell mutations, and that this could explain the excess in this geographical area.
Again, the level of risk implied by this explanation seems inconsistent with the dosimetry and previous estimates of genetic risk.
The measured dose of external radiation might be a surrogate measure for internal exposure to radionuclides or to chemicals; such alternative explanations are still open to the objection that there are no generally accepted data on humans to support this.
Our analysis includes the geographical area covered by Gardner et al but follows it too closely in time to provide data to test their findings; only cases 12–14 in table III (one non-Hodgkin lymphoma, one leukaemia, one Hodgkin's disease) were diagnosed after the period covered by the Gardner study and moreover all three were conceived before the parents moved to Seascale.
The only published study that can be directly compared with the Gardner report is that by Mc Laughlin et al on workers at nuclear facilities in Ontario; they found no increased risk of leukaemia in the children of fathers working in these facilities.
In particular, although the numbers of cases and the prevalence of exposures in the highest dose categories considered by Gardner et al were similar for the control fathers in the two studies, the Ontario study found no evidence of a risk associated with such doses.
Differences between the studies include the fact that Canadian workers ‘receive a substantial proportion (20–40%) of their total exposure as an internal dose (largely due to tritium),’ that workers in Ontario did not have the types of chemical exposure received by the  Sellafield workers, and that some of the control fathers with high doses were uranium miners.
Little is known about risk factors for childhood leukaemias and lymphomas.
In a series of papers Stewart and colleagues have shown a significant association, now widely accepted as causal, between obstetric radiography and childhood leukaemia and other cancers.
For children born in the late 1950s and early 1960s this could have accounted for perhaps 5% of cases; as Gardner et al showed it does not explain the increased incidence in Seascale.
Kinlen et al have carried out a number of analyses relating to areas in which there has been increased population mixing and have found an increased incidence of childhood leukaemia in some of these areas.
They attribute this to an increased likelihood of exposure to a leukaemogenic virus or viruses.
The high incidence in Seascale occurred over an extended period, and we are not sure whether this could be explained by Kinlen hypothesis.
A number of studies (see, for example, Draper et al have suggested that childhood leukaemia is more common among higher socioeconomic groups, and it has also been suggested that the risk of childhood acute lymphoblastic leukaemia is doubled in isolated towns and villages, but the excess in Seascale is too large to be accounted for in these ways.
In conclusion, we confirm that there is good evidence for an increased incidence of lymphoid leukaemia and non-Hodgkin lymphomas among young people in Seascale, though we are unable to identify the cause of this increase; nor can we say that our data and analyses either support or detract from the conclusions of Gardner et al .
Evidence of unmet need in the care of severely physically disabled adults
Abstract
Objective
To identify unmet needs in the care of severely disabled people aged 16–64.
Design
Detailed personal interview and physical assessment of physically disabled adults; personal or telephone interview with carers.
Setting
Somerset Health District.
Subjects
181 severely disabled adults and their carers.
Main outcome measures
Independence in activities of daily living; identity of requirements for assessing communication disorders; appropriate provision of services and allowances.
Results
53 (29.3%) of the 181 disabled subjects had unmet needs for aids to allow independence in activities of daily living — namely, 43% of subjects (41/95) with progressive disorders and 14% of subjects (12/86) with non-progressive disorders.
The prevalence of unmet need was higher among subjects whose sole regular professional contact was with health services personnel (48 (40.3%) of 119 subjects).
Only 18 (31.6%) of the 57 subjects with communication disorders had ever been assessed by a speech therapist.
Conclusions
This study shows that the needs of severely physically disabled adults in the community — especially those with progressive disorders — are being monitored inadequately by health professionals.
Introduction
The white paper Caring for People and the NHS and Community Care Act 1990 set out the government's policy framework for community care in the next decade.
A principal objective is to enable people to live an independent and dignified life in the community for as long as they are able and wish to do so.
The importance of effective assessment in ensuring high quality care of physically disabled people is emphasised, as the capacity to maintain independence may be influenced by the subsequent provision of aids, services, etc.
This study, planned jointly by Somerset Health Authority and Somerset social services department and carried out during 1989–90, focused on the quality of monitoring and management of the needs of a sample of severely physically disabled residents of Somerset Health District who were in regular contact with health professionals.
Subjects and methods
A total of 557 severely physically disabled adults aged 16–64 were initially identified from available records and consultation with health professionals, social workers, and voluntary services.
Included were adults whose primary disabilities were physical and permanent and who needed daily assistance from carers or other professionals or non-professional helpers.
This definition has been used in other studies.
Excluded were residents of institutions, mentally handicapped people, and those whose primary disability was deafness or blindness.
A 33% random sample of subjects (n=184) was selected for intensive study, of whom 181 (98%) agreed to participate.
Each person was interviewed at home by a doctor trained in physical disability.
Of the principal carers, 177 (98%) were interviewed in person and four by telephone.
Information about the subject's disabilities and handicaps and the current provision of health and social care, voluntary services, and allowances (subsequently validated against available records) was recorded on a standard questionnaire.
Physical examination ascertained independence in six activities of daily living: feeding; dressing; transfer from chair, bed, or toilet; bathing; toileting; and locomotion.
By applying a formula to the three highest scores from 13 areas of disability, as defined by the Office of Population Censuses and Surveys, 161 (89%) subjects were placed in category 10, and 20 (11%) subjects in category 9, the two highest bands of severity.
The 119 people who were wheelchairbound had their wheelchairs assessed for defects.
In all cases where unmet needs were identified referral was made to the appropriate agency or professional after agreement with the client's general practitioner.
Need has been variously defined, but in this study needs were deemed to be unmet if interventions were acceptable to the client and the following applied:(a ) for activities of daily living a person was dependent on help from the carer and this dependence could be reversed by provision of an aid;(b ) for communication disorders there had not been an assessment by a speech therapist;(c ) for services (day care, respite care) a referral had not been made to the appropriate agency and subsequent referral proved successful; and (d ) for benefits the client or carer was unaware of eligibility for benefits, an application had not been made, and subsequent application was successful.
Results
contact with services in previous 12 months
Using information on the health, social, and voluntary services in regular contact with the 181 physically disabled people in the 12 months before interview, we subdivided the sample into six groups (A-F).
The definitions for inclusion in these subgroups and the underlying diagnoses are summarised in tables I and II.
Members of the sample had consulted their general practitioners a mean of 7.0 times (range 4–15).
A total of 169 (93%) had received at least two hospital outpatient consultations in connection with the condition causing their disability, of whom 25 (15%) had also required inpatient admission.
One hundred and  fifty nine subjects (88%) were visited one to three times per week by the district nursing service.
Sixty eight (38%) had not had contact with social or voluntary services in the previous three years; 51 (28%) had been advised to contact social services ‘if the need arose’; and only 62 (34%) people had received regular visits from social services personnel (social workers, occupational therapists, etc).
activities of daily living
Table III summarises the numbers in each subgroup initially dependent on the carer but subsequently independent with respect to activities of daily living after provision of aids.
Overall, 53 subjects (29.3%) achieved independence in at least one activity: 36 (19.9%) achieved independence in three activities, 12 (6.6%) in two, and five (2.8%) in one.
Of the 119 subjects who were wheelchairbound, 12 (10.1%) had remediable defects in their wheelchairs.
Progressive versus non-progressive disorders — The diagnostic groups were broadly classified into progressive and non-progressive disorders (table II), stroke patients being placed in the second group for analysis.
The highest prevalences of unmet need were consistently found in groups A to D (table IV).
Overall, 41 (43%) of the 95 subjects with progressive disorders benefited from aids compared with 12 (14%) of the 86 with non-progressive disorders (p<0.001).
Hospital inpatients versus hospital outpatients — Among subjects with progressive disorders receiving hospital consultations (table IV), none who had been admitted as an inpatient in the past 12 months had unmet needs.
By contrast, almost half of subjects who had received solely outpatient consultations had unmet needs (p<0.001).
There was little difference in the respective proportions of subjects with non-progressive disorders (10% v 9%; NS)(table IV).
Contact with health professionals — Among subjects with progressive and non-progressive disorders the proportions with unmet needs were significantly higher (p<0.001 and p<0.001 respectively) in groups A to D, where regular contact was solely with health professionals, than in groups E and F, where there was also regular input from the social and voluntary services (table IV).
communication disorders
In groups A to E inclusive 57 patients with communication disorders were placed in three grades of disability.
Only 18 patients, including only half of the most severely affected group, whose speech carers found impossible to understand, had ever received an assessment by a speech therapist (table V).
In addition, five patients with motor neurone disease suffered from swallowing disorders, of whom only two had been assessed.
services and benefits
Table VI summarises the number of subjects in each subgroup who were accepted for respite and day sitting services and who were found to be eligible for the mobility and attendance allowances before and after the interview.
In groups A to D, in sole regular contact with health professionals, the differences were most pronounced with increased uptake as follows: respite care 48% to 92%, day care 55% to 89%, mobility allowance 56% to 91%, attendance allowance 55% to 93%.
Discussion
Inadequacy of services for young physically disabled adults has been emphasised in several reports.
This survey disclosed a considerable disparity in levels of unmet need in subjects whose sole regular contact was with health professionals (subgroups A to D) compared with those reassessed on a multidisciplinary basis by health and social services personnel.
It also highlights that functional deterioration, particularly in those with progressive disorders, may not be detected owing to inadequate or infrequent reassessments, or both.
Referral by health professionals entails assessing a patient's needs, monitoring changes in needs, and knowing the role of other agencies.2 However, significant unmet needs remained despite our study subjects consulting their general practitioners more frequently than subjects in other studies.
Increased emphasis is required on the identity of and response to the changing needs of physically disabled people, as evidenced by failure of doctors to detect functional deterioration in general practice and hospital outpatient consultations.
A hospital admission is frequently accompanied by a more in depth assessment, which may explain the better results for the 25 patients in this subcategory.
District nurses are considered to have an important role in the effective assessment and provision of community care.
However, despite contact with patients between one and three times per week, the unmet needs in groups C and D suggest that certain community nurses either may not be carrying out the assessment tasks effectively or may not be reassessing clients adequately.
The comparison of results in groups D and E highlights the important assessment role of occupational therapists as cited by other workers.
Those clients who received regular reviews fared better than those who were left to bear the responsibility of contacting the relevant services when the situation, in their opinion, so required.
The lack of perception of both clients and carers on progressive deterioration of function and the lack of information of what services have to offer mean that the ‘on demand’ service may not be enough.
This study also reinforces the conclusions of other studies by highlighting deficits in the availability of valid, accurate, timely, and accessible information on both services and allowances for disabled people.
The acquisition of independence from the carer in various activities of daily living was achieved in this study at relatively modest cost — £3300 (Somerset Social Services Department, personal communication).
Communication disorders are a source of considerable frustration and undoubtedly interfere with the quality of life.
In addition, help is required for motor neurone disease patients with swallowing disorders.
These results highlight deficits in the use of speech therapists in their assessment and treatment capacities.
We acknowledge that stroke patients may be classified in the progressive or non-progressive disorder category.
Their inclusion in the non-progressive category does not influence the main conclusion that deficits are highest in monitoring patients with progressive disorders.
We also acknowledge that the Office of Population Censuses and Surveys categories of disability severity have not been fully validated, but this scoring system was used to illustrate the broad similarity of severity in clients from each of the six subgroups (table I).
The important role of voluntary services, both in the  provision of information and in providing support, has often been underestimated.
This survey shows that, when available, their support is usually welcomed by both clients and carers and unmet needs are less.
In conclusion, deficiencies have been found in monitoring adults with severe physical disability whose sole regular contacts are health professionals.
District health authorities and family health services authorities will need to consider how best to improve the assessment of needs of patients as they plan to implement care in the community.
Long term follow up of severely ill patients who underwent urgent cardiac transplantation
Abstract
Objective
To assess long term survival (>5 years) and quality of life in severely ill patients referred for urgent cardiac transplantation.
Setting
Tertiary referral centres: before transplantation at the National Heart Hospital (late 1984 to end 1986); after transplantation at Harefield Hospital.
Subjects
Eighteen patients (15 men; three women) who had required intensive support in hospital before cardiac transplantation and were alive at short term follow up.
Interventions
Intravenous infusions of cardiac drugs (mean 2.2 infusions), intravenous diuretics (17 patients), and many other drugs before transplantation.
Intra-aortic balloon counterpulsation (four patients), temporary pacing (two), and rescusitation from cardiac arrest (three).
Patients had specialised nursing care on a medical intensive care unit in almost every case.
Main outcome measures
Long term survival in patients after urgent cardiac transplantation and perceived quality of life.
Results
Of 18 patients who were alive at short term follow up(mean (range) 19.4 (10–33) months), 14 were still alive in 1992 (69 (61–83) months).
Ten still worked full time, and 11 reported no restrictions in their daily activities.
Three of four patients who died in the intervening period survived >5 years after transplantation.
Overall, 17 of 18 patients survived at least 5 years.
Conclusions
In severely ill patients who undergo urgent cardiac transplantation and survive in the short term, long term (5–7 year) survival and quality of life seem good.
Introduction
Cardiac transplantation has now become an accepted therapeutic option for many patients with terminal cardiac failure.
A total of 3054 heart transplantations were reported to the registry of the International Society of Heart and Lung Transplantation in 1990, and overall actuarial survival rates at 1 and 5 years have been reported at 90% and 68% respectively.
Of more than 16000 heart transplantations performed since the first human to human operation in 1967, over 1700 patients survived more than 5 years after surgery.
The success of this fairly new treatment has led to increasing numbers of terminally ill patients being referred for consideration of transplantation, many of these being referred as a final option, when intensive support in hospital is required and when secondary end organ damage has often developed.
Organ donation has not kept pace with the demands for transplantation, and a considerable minority of patients die having been accepted for, and while waiting for, transplantation.
With the chronic shortage of donor organs a dilemma faces the physician who is referred a patient with terminal heart failure with or without secondary end organ damage who requires intensive support in hospital.
Should treatment be withheld and the available donor organs donated to ‘more suitable’ patients or should such ill patients be actively treated while waiting for a suitable donor organ, thus leading to a potential increase in the number of stable patients likely to deteriorate while awaiting ‘elective’transplantation?
In early 1988 we reported in this journal the short term outcome in 33 patients referred to the National Heart Hospital between late 1984 and the end of 1986 and who were accepted for urgent cardiac transplantation.
All required intensive treatment in hospital with intravenous infusions of cardiac drugs, in addition to various combinations of intra-aortic balloon counterpulsation, peritoneal dialysis, ventilation, and temporary pacing to sustain life, and none had any prospect of discharge from hospital without a transplant.
The seven patients who did not receive a transplant died in hospital, but 18 of 20 patients who survived to hospital discharge after transplantation were alive at short term follow up(mean (range) 19.4 (10–33) months).
In this report we assess the long term (5–7 year) survival, exercise capacity, perceived quality of life, and employment in these 18 patients.
Patients and methods
Follow up data for the 18 patients who were alive when the 1988 report was assembled have been  obtained from the most recent inpatient assessment at Harefield Hospital (1991–2), where all but one patient are reviewed in depth each year or more often if problems arise.
Details of exercise capacity, coronary anatomy, left ventricular ejection fraction, and medications taken were recorded from the notes, in addition to renal functional state, blood pressure, and associated medical problems.
quality of life and employment
Survivors were contacted by telephone over two days in January 1992.
Patients underwent a simple assessment of quality of life with regard to their perceived restrictions and their employment; their exercise capacity had been assessed with exercise testing during their most recent annual follow up visit.
Patients were asked (by DM or CW) whether they felt unrestricted, mildly restricted, moderately restricted, or severely restricted in their normal daily activities.
Their employment was recorded as full time (a housewife was considered as being employed full time), part time, retired, or unemployed.
Reasons for lack of employment were noted.
details of patients before and at transplantation
Of the 18 patients (15 men, three women) surviving short term follow up, all had required at least one intravenous infusion of an inotropic agent or vasodilator (mean (range) 2.2 (1–5) infusions) before transplantation in addition to intravenous diuretics in 17 cases.
Other drugs were used as required (anticoagulant agents (usually intravenous heparin), vasodilators, digoxin, diamorphine, plasma expanders).
Ten patients had non-sustained ventricular tachycardia or received anti-arrhythmic treatment, or both.
Seven patients received antibiotics for sepsis.
Three patients had clinically suspected or proved pulmonary emboli.
The patients' clinical state was usually of hypotension and sinus tachycardia, with a third heart sound almost invariably heard.
In 13 of 18 cases clinical examination confirmed evidence of biventricular failure.
Four patients required intra-aortic balloon counterpulsation.
This was planned but abandoned in a fifth patient when a suitable heart became available.
Indication for such an intervention was usually a combination of developing oliguria with decreasing peripheral temperature.
Two patients required cardiopulmonary resuscitation at some point in the hospital admission before transplantation, a further patient requiring rescusitation after an angiographic procedure.
Two patients required temporary pacing.
In those 11 patients who had been well enough to undergo radionuclide ventriculography, the mean left ventricular ejection fraction was 11.7% (range 6–20%).
Otherwise cross sectional echocardiography confirmed globally poor left ventricular function.
Almost all patients were restricted to bed in the medical intensive care unit during the index admission while waiting a suitable donor organ.
Four patients had considerable disturbance in renal and hepatic function.
Normal or near normal renal function was classified as previously described as a plasma urea concentration of <14 mmol/l and plasma creatinine concentration of <160 µmol/l; moderate renal dysfunction as that when concentrations were higher than those quoted above; and severe renal dysfunction as that when renal dialysis was instituted.
Hepatic dysfunction was defined as greater than twice normal activity of at least two hepatic enzymes.
underlying disease and type of transplantation
All patients had end stage cardiac failure not amenable to medical treatment or persistent ischaemia associated with poor left ventricular function.
The indication for transplantation for the 18 patients surviving in the short term was ischaemic heart muscle disease in 11 patients, dilated cardiomyopathy in six, including two with puerperal cardiomyopathy, and transient myocardial ischaemia with poor left ventricular function in one.
No patient had any coexistent illness apart from pulmonary emboli in three cases and secondary end organ dysfunction in four.
Sixteen patients received an orthotopic heart transplant, two receiving a heterotopic (piggyback) transplant.
Results
Of the 18 patients who were alive at the time of the 1988 report, 14 patients (11 men and three women, mean age 48 years) were alive and well in 1992 at a mean (range) of 69 (61–83) months after transplantation.
Of the intervening deaths recorded, one patient died suddenly 42 months after transplantation (heterotopic heart transplant and previous coronary artery vein grafts to the recipient heart) and another died of acute myocardial infarction at 65 months, having undergone percutaneous transluminal coronary angioplasty to a lesion of the left anterior descending coronary artery of the transplanted heart the previous year.
A third patient died suddenly after rupture of an aortic aneurysm 63 months after orthotopic transplantation, having been previously well and working full time.
A fourth died 61 months after orthotopic transplantation of carcinoma of the lung.
Therefore, three of the four documented deaths over the intervening period occurred in those who had survived for at least 5 years after surgery.
renal and hepatic state before transplantation and outcome
Figure 1 shows the relation between renal state before transplantation in the original cohort of 33 patients described in the 1988 report and long term (5–7 year) survival.
Eleven of 14 patients with normal or nearly normal renal function and three of five with moderate renal dysfunction (mean urea concentration 27.2 mmol/l; mean creatinine concentration 210 µmol/ l) who were discharged from hospital after transplantation remained alive in the long term.
Of the original cohort of 33, six of 14 patients with moderate hepatic dysfunction were discharged from hospital after transplantation, and four remained alive and well at long term follow up(three also had moderate renal dysfunction).
Fourteen of 19 patients with normal or mildly abnormal hepatic function were discharged from hospital after successful transplantation, 10 being alive at long term follow up.
Of the six patients who underwent intra-aortic balloon counterpulsation and were discharged from  hospital after transplantation two are alive, the four others having died at 10 weeks, 31, 42, and 61 months.
clinical state and quality of life
Table I shows the excellent preservation of left ventricular ejection fraction in the long term in the surviving patients: 11 of 14 patients performed more than 9 minutes of exercise with the standard Bruce protocol at the time of their most recent annual review (1991–2).
Despite the routine use of cyclosporin only two patients had a plasma creatinine concentration above 175 µmol/l.
Four patients had evidence of coronary artery disease on routine annual coronary arteriographic assessment but only two had significant disease.
Seven had hypertension, with nine having hypercholesterolaemia.
Table II lists quality of life score, employment, and number of family dependants.
To the question ‘How would you describe the restrictions to your daily activities: unrestricted, mildly restricted, moderately restricted, or severely restricted?’ 11 of 14 reported no restrictions, only one reporting more than mild restrictions.
Ten were working full time when interviewed, only two being unemployed (one by choice since surgery; the second for medical reasons).
overall survival
Of the 26 patients who received a suitable donor organ, 17 of the 20 patients who survived to hospital discharge lived more than 5 years and 14 of these were alive at a mean (range) of 69 (61–83) months after surgery.
This reflects a 53.8% long term survival for those who received a suitable donor organ and a 70% actual survival at almost 6 years' mean follow up in those discharged from hospital after surgery (fig 2).
Discussion
Though it seems reasonable to assume that the ideal candidate for cardiac transplantation is one who has irreversible cardiac failure and severe symptomatic restrictions despite all treatment but with no requirement for intravenous or interventional support and no secondary end organ damage, in practice many of the patients referred for consideration of transplantation require active support in hospital and have been referred in some cases because they have developed secondary end organ damage.
The mortality of these patients approaches 100% in the short term.
Our long term follow up study of patients who underwent urgent cardiac transplantation shows that many such patients can do excellently, both in terms of survival and quality of life.
Previous reports had suggested that such subgroups of patients did well in terms of survival in the short and medium term after transplantation, assuming that the development of renal failure requiring dialysis had not occurred before receiving a suitable organ, and quality of life has been shown to increase in absolute terms after such a procedure.
Of the 14 surviving patients in this report, all had required support with intravenous infusions of cardiac drugs before transplantation, and, in addition, some had developed secondary renal and hepatic dysfunction; clearly this does not seem to mitigate against a successful outcome to transplantation.
Of the original cohort of 33 patients considered for urgent transplantation, however, 16 had insertion of an intra-aortic balloon pump, but only two of these have survived long term.
Although it is difficult to reach firm conclusions from the small number of patients who underwent balloon counterpulsation, those few who have survived in the long term underwent such a procedure while their renal function was still normal or nearly normal and their renal state remained stable until transplantation.
Possibly early balloon counterpulsation to offset the expected deterioration in renal function might be a more worthwhile approach to management than later in an attempt to reverse such a deterioration in renal state.
If patients with moderate renal and hepatic dysfunction who do not require mechanical intervention before cardiac transplantation survive to hospital discharge their long term outlook is good.
In medicine the issue of economics is becoming evermore prevalent.
Cost-benefit for performing cardiac transplantation on such seriously ill patients  may be looked at more objectively when follow up is longer.
Though management in hospital of such patients before transplantation is undoubtedly labour intensive and expensive, many such patients return to normal working life.
A further consideration is that many have young families who depend on them.
This factor is particularly difficult to price.
These issues of survival and quality of life have to be further considered in the light that all such patients in this series who did not receive a suitable donor organ died during their hospital admission.
The long term results of cardiac transplantation are now excellent with five year actuarial survival of almost 70% when the results of heart transplantation from all institutions are combined.
Much of the improvement in survival has resulted from the now routine use of cyclosporin as an immunosuppressive agent.
Even for severely ill patients a good long term outlook can be expected for most of those undergoing transplantation; the overall survival of 70% at a mean of 69 months for those discharged from hospital after such an operation compares favourably with the long term results of cardiac transplantation worldwide.
Although no independent assessment of quality of life was performed in these patients, from the objective assessment of exercise capacity and left ventricular function in each case combined with the full time employment of most of the long term surviving patients, the patients' answers to a simple telephone questionnaire were probably accurate and did not reflect any inappropriate bias.
As expected, graft atherosclerosis becomes problematical in long term survivors of cardiac transplantation.
Of the 18 patients who were alive at short term follow up, one has since died of coronary disease; a second patient with coronary disease died of carcinoma of the lung; and four further surviving patients have angiographic evidence of disease.
Despite the use of cyclosporin (a nephrotoxic agent) in these patients only two had a plasma creatinine concentration above 175 µmol/l, confirming the findings of Lewis et al that the use of such an agent in the long term was associated with impaired but generally stable aggregate renal function in heart transplant cohorts.
von Scheidt et al assessed haemodynamic variables over a 5 year period (mean 26 months) in patients after heart transplantation and confirmed preserved and normal left ventricular contractility in most cases.
We have confirmed this finding over a mean of 69 months follow up, with left ventricular ejection fraction ranging from 42 to 83%.
At the time that the present series of transplant patients were referred for surgery our transplant centre was one of a fairly small number seeking suitable donor organs, not just in Britain but in continental Europe.
This allowed for fairly good availability of well selected donor organs thus more easily facilitating an urgent transplant programme.
Currently, with strong competition from many units throughout Europe for available organs, many patients similar to those described herein would die waiting for a suitable donor organ.
Many more organ donors, however, are available than are being assessed through existing organ procurement efforts.
Donor organs are also possibly lost due to physicians avoiding raising the issue with relatives, although many relatives may find some comfort from knowing that someone else has benefited from their loss.
With the chronic shortage, there has been a widening of selection criteria for the acceptance of donor organs and an extension of cardiac allograft ischaemic time in the hope of increasing the available pool of donor organs.
While in the short and medium term (up to 3 years) such an approach does not seem to compromise the results of transplantation, what the long term effects of such an approach will be are unclear.
Non-intra-aortic balloon counterpulsation techniques acting as ‘bridges to transplantation’ were not available to us for clinical purposes in 1985–6, but various recent studies have suggested that well selected patients undergoing such mechanical interventions (ventricular assist device, B ventricular assist device, total artificial heart) have a similar short term outlook to those undergoing ‘elective’transplantation.
The expense involved will, however, be justified only by the demonstration of a good long term outlook after such a management approach.
From the findings of this follow up report it seems feasible to combine aggressive treatment of cardiac failure (with its attendant end organ effects) with early cardiac transplantation in severely ill patients.
The long term results of transplantation in those requiring intensive support in hospital with infusions of inotropic agents, vasodilators, or both, in addition to more standard treatment seems excellent.
If intra-aortic balloon counterpulsation is to be used it should perhaps be introduced early in the management of such patients to prevent inexorable deterioration in renal function, rather than late in an effort to reverse such deterioration.
This policy will, while potentially reducing the time window for receiving a suitable donor organ, ensure a more optimal clinical state in those who do receive a suitable organ.
Patients deteriorating to the point when renal dialysis is considered should be withdrawn from the transplant list.
From the results of cardiac transplantation to date many more such patients could expect an excellent long term outlook if referred before developing secondary end organ dysfunction, but more importantly if the supply of available donor organs could be increased.
As of October 1992 all 12 patients living in the United Kingdom were alive and well.
Evaluation of two school smoking education programmes under normal classroom conditions
Abstract
Objectives
To assess the effectiveness of two school based smoking education projects in delaying onset of smoking behaviour and in improving health knowledge, beliefs, and values.
Design
Cluster randomised controlled trial of two projects taught under normal classroom conditions.
Schools were allocated to one of four groups to receive the family smoking education project (FSE); the smoking and me project (SAM); both projects in sequence (FSE/SAM); or no intervention at all.
Setting
39 schools in Wales and England matched for size and catchment profile.
Subjects
All first year pupils in the schools were included and were assessed on three occasions (4538 before teaching (1988), 3930 immediately after teaching (1989), 3786 at one year follow up(1990)).
Main outcome measures
Self reported smoking behaviour (backed by saliva sample) and change in relevant health knowledge, beliefs, and values.
Results
No consistent significant differences in smoking behaviour, health knowledge, beliefs, or values were found between the four groups.
For never smokers at baseline the rate of remaining never smokers in 1990 was 74% (594/804) in the control group, 65% (455/704) in the FSE group, 70% (440/625) in the SAM group, and 69% (549/791) in the FSE/SAM group (χ1 2 a d j =6.1, df=3, p=0.1).
Knowledge about effects of smoking rose in all groups from a mean score of 5.4 in 1988 to 6.4 in 1989 and 6.5 in 1990.
Conclusions
More comprehensive interventions than school health education alone will be needed to reduce teenage smoking.
Other measures including further restrictions on access to cigarettes and on the promotion of tobacco products need to be considered.
Further research will be needed to develop effective school based health education projects, which should be formally field tested under normal conditions before widespread dissemination.
Introduction
Smoking remains the commonest cause of premature death and ill health in the United Kingdom.
The two basic strategies for reducing smoking related disease are to support existing smokers in giving up and to dissuade young people from starting.
Although efforts continue to encourage people to stop smoking, in the past decade considerable attention has been given to reducing uptake of smoking by teenagers, particularly by using the educational opportunities available through the school system.
The prevalence of smoking among teenagers in Britain has been examined in an ad hoc way since the late 1960s.
Since 1982 biennial national surveys conducted by the Office of Population Censuses and Surveys have provided valuable information on adolescent smoking behaviour.
No significant change in prevalence was found between 1982 and 1990.
Interventions by schools to reduce smoking have been undertaken for many decades, although little attention has been given to assessing their effectiveness.
An international review of evaluated programmes published in 1978 concluded that most of these early programmes failed to influence smoking behaviour (although several had achieved educational objectives such as improving knowledge and understanding of the relation between smoking and disease).
The failure to reduce smoking was partly ascribed to a naive understanding of the relation between knowledge and changes in behaviour as well as to the use of inappropriate teaching techniques.
During the late 1970s and early 1980s several innovative and more sophisticated approaches to smoking education in schools were developed and evaluated.
These drew heavily on psychosocial theories to explain adolescent health behaviour (particularly social learning theory) and were designed to help young people to develop the personal skills needed to resist social pressures to smoke.
These programmes also used modern approaches to teaching and learning — for example using classroom videos and pupil led classroom discussion and seeking to include the family more directly in smoking education.
Two programmes that attracted particular attention were the Minnesota smoking prevention programme, which was developed in the United States in the early 1980s, and the family smoking education project, which was developed in Norway as part of a comprehensive five year research programme examining smoking among Norwegian schoolchildren.
Both projects reported success in delaying onset of smoking among adolescents and in achieving lower levels of smoking uptake.
In both cases only short term follow up studies have been reported.
These projects were adapted by the Health Education Council (now the Health Education Authority) for use in Britain.
For the family smoking education project this adaptation was straightforward and the basic educational principles and content are similar in the British and Norwegian versions.
The project was intended for use with first year secondary school pupils (aged 11–12 years) and involves an average of three hours of teaching over a series of classroom lessons.
The lessons are reinforced by a booklet for the pupils and a separate leaflet for the parents which encourages them to discuss smoking with their children.
The project focuses on the immediate health impact of smoking on the pupils and encourages parents to reinforce the messages from school and to show disapproval of smoking.
The project has been used widely throughout England, Wales, and Northern Ireland since becoming available in 1986.
The development and dissemination of the family smoking education project were examined as part of the development of the English language version, but the project's effect on smoking behaviour has not been thoroughly evaluated.
The Minnesota smoking prevention programme required teaching methods which were less familiar to many British teachers at that time.
The project went through lengthy development and field testing before the project teachers' guide and teacher training manual were published.
The British version of the programme  (smoking and me) became available in 1987 and was based on a series of five lessons intended for secondary school pupils aged 12–13.
All schools using the project are strongly encouraged to have at least one staff member attend a day long training course to provide background information and to familiarise teachers with the technique of pupil led discussion groups, which are an important feature of the project.
There are no pupil project materials and the lessons focus on the social consequences of smoking and on peer, family, and media influences on smoking.
Emphasis is also placed on practising skills for managing social situations in which smoking occurs.
Both teachers' and pupils' views of the project were examined in its development phase, but the project's effect on pupil smoking behaviour has not been formally assessed.
We conducted a two year study to assess the effectiveness of the family smoking education and smoking and me projects in influencing smoking behaviour.
The projects were examined individually and in combination.
Subjects and methods
We studied pupils from 39 mixed sex state comprehensive schools in four different education authorities in Wales and England.
The schools were not a strict random sample since in two of the areas schools were approached because of their past commitment to health education.
In the other two authorities the schools were selected randomly from school lists.
The schools were matched by size and catchment area and assigned to one of four groups: no planned intervention (control group; 10 schools), family smoking education project only (FSE group; 10 schools), smoking and me project only (SAM group; nine schools), and both projects in sequence (FSE/SAM group; 10 schools).
This method of assignment was intended to ensure that the groups contained schools from each of the participating authorities and were not widely different in terms of the social background of pupils, school size, and environment.
All pupils in the first year of the schools were included, ensuring that each group was sufficiently large to detect differences between the intervention and control groups of the same size as had been achieved in the original evaluation of the two interventions.
The basic study instrument was a self administered questionnaire which was completed on three occasions by all pupils.
The first questionnaire was completed in February to March 1988 before the smoking education projects were started.
Schools allocated to teach the FSE project taught it during the three months immediately after administration of the questionnaire.
Those schools allocated to use the SAM project taught it in the early part of the second school year (November 1988 to February 1989) and the first follow up study was conducted in March 1989.
The second follow up study was completed in March 1990.
The part of the questionnaire assessing smoking behaviour was largely derived from the Office of Population Censuses and Surveys studies and previous studies of adolescent health behaviour conducted in Wales.
Questions designed to evaluate the educational objectives of the projects were derived from other studies assessing self esteem and locus of control.
A separate question specifically addressing the knowledge elements of the projects was also developed.
Teachers supervised completion of the questionnaire according to a well defined protocol.
All teachers were personally briefed on this procedure, which is designed to minimise underreporting of smoking behaviour.
Saliva samples were also taken from all pupils in each of the three surveys.
The pupils were told before completing the questionnaire that they would be required to provide a saliva sample to check the accuracy of their reported behaviour.
This method, known as the ‘bogus pipeline’ technique, is reported to improve the accuracy of self reported current smoking.
The projects were tested under real life conditions by classroom teachers operating within the normal constraints of teaching.
Although clear guidelines were set down for teachers on the minimum time commitment and core content of each of the projects, the organisation and management of the projects were at the discretion of the teacher.
All teachers who taught the family smoking education project were briefed on the basic components of the project and provided with basic guideline notes, which included a teacher's record of the lessons.
This record provided a short report on the timing, method, and content of each lesson, together with an overall assessment of the usefulness of materials.
The results from this part of the study have been published.
The teachers who were selected to teach the smoking and me project were required to attend a one day training seminar which familiarised them with the project guide and the group leader approach to teaching.
One course was run in each of the four areas to a consistent format.
Teachers were also required to complete a record sheet providing basic details on each lesson taught together with an overall assessment of the project.
The results from this part of the project have also been published.
These two studies of the teaching of the project have been important in ensuring that the core elements of both projects were covered and have provided important additional information on the practicalities of teaching the projects and variability in actual classroom use.
data analysis
Because schools rather than individual pupils were assigned to intervention groups responses of pupils within a school (cluster) tend to be correlated and hence the effective sample size is less than the number of students surveyed.
The statistical analyses take into account this correlation and the nesting of schools within intervention groups, thus avoiding underestimation of the standard errors of estimates and spurious significant results.
Statistical methods are described separately for the continuous variables (knowledge, attitudes, and beliefs) and discrete variables (smoking behaviour).
Gender, mother's smoking status, father's smoking status, and father's occupation at baseline were considered potential confounding variables, particularly as differences in rates of smoking and levels of knowledge were evident among study groups at baseline.
Parental smoking was dichotomised (regular or occasional smoker v non-smoker, former smoker or not known), and father's occupation was categorised into four groups: manual, non-manual, unemployed, and not known (this last category made up 21% (943) of the 4538 responses).
The continuous variables knowledge, attitudes, and beliefs about smoking were assessed on five scales.
The knowledge score was based on 12 items.
For each item a correct response was given a score of 1 and an incorrect, not sure, or missing response was scored as 0.
For students with two or fewer missing responses the values on the individual items were summed to yield an overall score between 0 and 12.
The remaining students were excluded from the analysis.
A three point scale was used for each of the 12 self esteem items.
A response indicating high self esteem was coded as 2, low self esteem 0, and not sure or missing 1.
For students with no more than two missing responses  the individual values were summed to give a score between 0 and 24.
The remaining variables were measured on a five point Likert scale.
Scores were obtained by averaging the responses.
If there were too many missing responses no score was given for that student.
For perceived health values there were five items; no more than two responses were allowed to be missing.
External locus of control was measured on four items, no more than one of which was allowed to be missing.
Internal locus of control had two items and no missing items were allowed.
The proportion of missing values on the five scales ranged from 0.2% to 3.1% and was generally less than 2%.
For each scale the baseline score in 1988, changes from baseline to first follow up(1989), and changes from baseline at second follow up (1990) were compared among intervention groups.
Mixed model analysis of variance was used to test for the effects of intervention.
School was fitted as a random effect nested within groups.
The two projects were fitted as fixed effects.
Where there was no significant interaction (effect modification) between the projects, the separate effects of each project (main effects) were assessed.
Each model also included the potential confounders discussed above.
The maximum likelihood method was used to fit the models by the BMDP3V computer program.
The likelihood ratio test (χ 2 statistic) was used to test hypotheses.
Students were asked to indicate which of six statements relating to smoking behaviour best described their own behaviour.
The responses were later grouped into three categories:(a ) never smoker —‘I have never smoked a cigarette, not even a puff’;(b ) tried but stopped —‘I have only ever tried smoking once or twice but I don't smoke now,’ or ‘I used to smoke sometimes but I don't smoke now’;(c ) current smoker —‘I smoke sometimes but I don't smoke as much as one cigarette a week’or ‘I usually smoke between one and six cigarettes a week,’or ‘I usually smoke more than six cigarettes a week.’
Since one main aim of the interventions was to delay the onset of smoking, never smoking was considered an appropriate primary indicator given the age of the pupils at baseline (relatively few were current smokers or had previously experimented with smoking).
Non-smoking (never smoking combined with tried but stopped) was used as a second end point.
The proportion of students remaining never smokers at first follow up and at second follow up was assessed.
Rates of non-smoking in never smokers were also assessed at each follow up.
Analyses comparing rates of non-smoking among study groups at each follow up were repeated for non-smokers at baseline rather than never smokers.
Overall findings of these analyses are given to assess the sensitivity of the main results to the choice of target group.
The χ 2 test was used to test for overall differences in proportions across the four intervention groups.
To adjust for the effect of clustering, χ 2 a d j was calculated by dividing the resulting χ 2 statistic by  where m i  represents the number of students in the n th cluster (school) and ρ represents the intracluster correlation.
For each outcome the average interclass correlation across the four study groups was used as the estimate for ρ.
This method of analysis does not take into account the factorial design.
Logistic regression was used to model change in smoking behaviour at each follow up taking into account the factorial design, the clustering, and the potential confounders.
For each analysis, a series of models was fitted with the statistical package GLIM.
When variables were added to a model the change in deviance follows an approximate χ 2 distribution with degrees of freedom (df) equal to the number of additional parameters fitted.
By fitting appropriate models, after adjusting for potential confounders, the analogue of a mixed model analysis of variance table was constructed.
Tests of significance for intervention effects were then carried out by taking the ratio (χ 2 /df for the intervention effect) /(χ 2 /df for the interaction between school and interventions) to yield an approximate F statistic.
Results
In 1988, 5078 pupils aged 11 and 12 and in their first year of secondary school were eligible for inclusion in the study.
Of these, 4562 (90%) completed questionnaires, 4538 of which were valid for use in the analysis.
The percentage valid for use in the four groups varied between 92% and 86%.
No pupils refused to participate in the study, and as pupils were not warned about the administration of the survey we assumed that those registered pupils who did not complete the survey were either absent or had left the school.
Table I gives a summary of the sociodemographic characteristics and parental smoking of the four groups.
Overall, the groups were similar in age, sex, father's and mother's smoking status, and father's occupation.
There was a significant difference (χ 2 a d j =9.5, df=3; p=0.02) in the rates of reported never smoking between the groups (table II).
The FSE/SAM group had the highest proportion of never smokers (83%, 924/1113), and the SAM group the lowest (74%, 732/989); the 148 pupils for whom smoking status was not known were excluded from the data.
A logistic model indicated that this difference was not explained by the small discrepancies in the sociodemographic characteristics (F 3 ,3 5 =3.2, p<0.05).
Similarly, there  was a difference between groups in the rates of reported non-smoking (χ 2 a d j =9.2, df=3; p=0.03); this difference was no longer significant after potential confounders were adjusted for (F 3 ,3 5 =2.5).
Table III gives scores at baseline for knowledge, self esteem, health values, internal locus of control, and external locus of control.
After adjustment for sociodemographic variables the mean knowledge score in the FSE groups (FSE and FSE/SAM) was found to be significantly higher than that in the control and SAM groups (χ 2 =5.7, df=1; p=0.02).
No significant differences were found on the other four scales.
Baseline differences were allowed for in the follow up analyses by examining changes from baseline.
In 1989, 3930 (87%) of the 4538 pupils who completed the survey at baseline were surveyed again.
The follow up rates for the groups were control group 86% (1056/1229), FSE group 85% (960/1127), SAM group 88% (895/1021), and FSE/SAM group 88% (1019/1161).
In 1990, 3786 (83%) of the 1988 group were followed up.
Follow up rates were control group 83% (1024/1229), FSE group 81% (916/1127), SAM group 84% (854/1021) and FSE/SAM group 85% (992/1161).
Overall 94% (4262) of the original group participated in at least one follow up study (either 1989 or 1990), and 76% (3454) were followed up in both 1989 and 1990.
These figures suggest that loss at follow up was largely due to absenteeism on the day of the survey rather than migration.
Pupils were significantly less likely to have participated in the follow up studies if at baseline they had reported being smokers or having previously smoked or tried cigarettes, if their father or mother was a smoker, or if their father was unemployed or a manual worker.
These findings were consistent across all four groups.
changes in smoking behaviour
Table II gives the prevalence of smoking at follow up.
Table IV gives rates of self reported smoking in 1989 and 1990 among pupils who were never smokers in 1988.
A total of 3037 of the never smokers at baseline participated in the 1989 survey.
Rates of remaining a never smoker in 1989 for the 2981 (98%) for whom smoking status was known at this first follow up were 85% in the control group, 82% in the FSE group, 81% in the SAM group, and 84% in the FSE/SAM group.
No significant differences in the proportions of students remaining never smokers or non-smokers were found.
Similarly, no significant differences were found in the proportions who remained non-smokers among groups in 1989.
A total of 2958 never smokers in 1988 were surveyed in 1990, 2924 (99%) of whom gave a valid response for smoking status.
Rates of remaining a never smoker for this group were: 74% in the control group, 65% in the FSE group, 70% in the SAM group, and 69% in the FSE/SAM group.
The χ 2 analysis showed no significant differences in smoking status between the four groups at second follow up(χ 2 a d j =6.1, df=3; p=0.1).
The logistic model, taking into account the factorial design and potential confounders, identified a significant difference in the odds of remaining a never smoker between the groups using the family and smoking education project and those not using it ((F 3 ,3 5 =4.2, p<0.05), the groups using the project being less likely to remain never smokers.
Comparing the proportion of never smokers in the groups using the family and smoking project and those not using it by χ 2 analysis gave a result consistent with the results of the model (χ 2 a d j =3.7, df=1; p=0.05).
No significant differences were found in the proportions remaining non-smokers.
Similarly, no differences were found between intervention groups in the proportions of non-smokers at baseline who remained non-smokers in 1990 by either method of analysis.
changes in knowledge, attitudes, and beliefs
All four groups showed an overall increase in scores for knowledge, attitudes, and beliefs between 1988 and 1989 (table III).
The mean scores at baseline for the subgroup of students who were followed up were the same as for those not followed up.
Mixed model analysis of variance showed that the mean increase in knowledge was significantly higher in the FSE groups (FSE and FSE/SAM, χ 2 =8.3, df=1; p=0.004).
For external locus of control a lower increase in score was seen in the FSE and SAM groups than in the control group, but the increase in the FSE/SAM group was higher than that in the control group.
This is reflected in the significant interaction between FSE and SAM found for the change in external locus of control (χ 2 =8.0, df=1; p=0.005).
No significant intervention effects were found for the other scales.
Very little change in the score for health values was observed in any group.
The change from baseline in knowledge, attitude, and belief at the 1990 follow up are also given in table III.
A significant interaction was found between FSE and SAM in the model for change in external locus of control (χ 2 =4.4, df=1; p=0.04), the pattern of  change being similar to that seen in 1989.
No other significant effects were found.
Further analysis showed no differences in results between schools in which the projects were taught for only the minimum time compared with those that taught it for longer.
Examination of records available on smoking related activity in the control schools indicated that pupils in half of the schools had been exposed to some incidental and unplanned smoking education through events such as No Smoking Day or through associated teaching in home economics or biology.
In none of these cases could the exposure be classified as substantial enough to call into question the validity of the control schools.
Discussion
Our results are very disappointing.
They contrast with those from many studies in the early 1980s which showed a clear impact on teenage smoking behaviour but are consistent with findings from other recent and comparable studies.
Some small differences in the achievement of educational objectives were observed, but our results suggest that two of the best school smoking education projects in Britain have not achieved better results than non-specific population wide approaches.
The results are difficult to explain.
This study deliberately examined the impact of the projects under normal classroom conditions.
Previous success with the original Minnesota smoking prevention programme may have arisen from the experimental classroom conditions under which it was taught.
Results available from two recent trials of programmes based on the original Minnesota model also show disappointing findings in their impact on smoking behaviour.
In both cases these programmes were taught under real life conditions, by ordinary classroom teachers.
No corresponding studies for the family smoking education project have been published and there may be other explanations for the poor results.
The Norwegian project was directed at school pupils aged 13–14 years, among whom the prevalence of smoking was high.
The behavioural objective in Norway was to reduce established prevalence of smoking.
In the British version, which was directed at a younger age group (10–12 years) with a lower smoking prevalence, the objective was to minimise or delay uptake.
Furthermore, the trial in Norway was conducted during a period of consistent decrease in the prevalence of smoking among young people in the country and while a comprehensive tobacco control programme was being introduced.
This included controls on the price, availability, and promotion of tobacco products.
No similar conditions existed in Britain at the time of this study.
evaluation of programmes
Our results indicate the need for a closer examination of the intended behavioural outcomes in school based programmes.
Both projects went through limited field testing to examine teacher and pupil acceptability before widespread dissemination.
Given that the problem of teenage smoking needed to be tackled with some urgency at that time (and still does), such a course of action was understandable.
However, in the future such rapid widespread dissemination of promising innovations will need to be accompanied by enhanced efforts to monitor intended behavioural outcomes and by testing of school projects in real life settings.
Our results also point to a more fundamental need for British based research into the most effective ways of influencing rates of smoking among young people through schools.
For example, since the original design of both projects the age of onset of smoking has fallen.
Specific health education programmes at ages 10–12 (for the family smoking education project) or 12–13 (for the smoking and me project) may well be too late or offer no additional benefit to more general interventions at that age.
Strong attitudes may have formed by then and teaching of avoidance skills may be too late to immunise children effectively against the pressures to smoke.
Education programmes at earlier ages in primary schools might be more successful.
Other countries are also facing these problems.
Disappointing findings have recently been reported from long term follow up studies of school based interventions in North America.
Reviews of school smoking prevention programmes have shown continuing success in delaying onset of smoking, but school health education alone may not be sufficient to compensate for other substantial influences on teenage smoking behaviour.
Other influences include the supply and availability of cigarettes to young people, their price and promotion, and the example of adults, especially those who may be role models for young people.
Cigarettes are still relatively easy to obtain by young people, and current arrangements for enforcing legislation to restrict sales are largely ineffective.
In addition, young people's purchasing patterns can be influenced by the advertising and tobacco sponsorship of sports.
Restrictions on advertising and sports sponsorship can have an immediate impact on rates of teenage smoking.
Young people are also more likely to be sensitive to the high price of tobacco products.
A model for achieving a smoke free generation in Europe was proposed at the first European conference on tobacco in 1988 and was supported by the World Health Organisation and British Medical Association.
Since then a report of the Royal College of Physicians has also emphasised the need for a comprehensive approach to the problem which takes account of the wide range of factors influencing both the supply of tobacco products and demand for them by young people.
Such a strategy recognises a clear role for school health education but emphasises that achieving an impact on the minority of young people who choose to smoke will require more substantial and comprehensive interventions.
Fatal hepatic decompensation associated with interferon alfa
Interferon alfa is the most promising treatment for chronic viral hepatitis, suppressing viral replication in about 30% of patients with chronic hepatitis B or C. In patients with cirrhosis interferon alfa may improve the outcome of the disease and obviate the need for liver transplantation.
Inhibition of viral replication in chronic hepatitis B is usually accompanied by a transient rise in the activities of aminotransferases.
This inflammatory exacerbation may cause hepatic decompensation in cirrhotic patients.
We report on patients with chronic viral hepatitis who died of hepatic decompensation during or shortly after interferon alfa treatment.
Case reports
After a patient with chronic hepatitis B in our institute exhibited a flare of hepatitis during interferon alfa treatment and died we studied the frequency and clinical aspects of fatal hepatic decompensation related to interferon alfa treatment.
We sent a questionnaire to 19 European centres with considerable experience of interferon alfa treatment for viral hepatitis.
Sixteen hospitals from nine countries responded.
These centres had treated 2490 patients with chronic viral hepatitis with interferon alfa.
We studied cases in which the patient had a fatal aggravation of liver disease during or less than two months after interferon alfa treatment.
Eight cases from five hospitals were reported; the table gives details of these cases plus our case.
Histological examination before treatment showed that all the patients had chronic active hepatitis with cirrhosis.
Four had no signs of hepatic decompensation (ascites, jaundice, encephalopathy, or variceal bleeding) before treatment.
Clinical deterioration occurred in the first three months of treatment in seven cases.
In cases 7 and 8 the scheduled course of treatment was completed with clearance of viral DNA, but liver failure developed two and eight weeks later.
Five patients' aminotransferase activities more than doubled during treatment.
No apparent reason for the liver failure other than interferon alfa treatment could be detected in any of the patients.
Comment
Although these cases were selected from a large number in which interferon alfa was given, they suggest that the drug can dangerously aggravate liver disease and that caution is needed in treating cirrhotic patients.
A relation between liver failure and interferon alfa seems probable in the patients who did not have hepatic decompensation before treatment.
The deaths of patients who showed signs of decompensated liver disease before treatment might have been due to spontaneous progression of the disease and cannot be linked unequivocally to the interferon treatment.
Most of the patients developed ascites, jaundice, and encephalopathy that progressed even after interferon alfa was stopped.
Since five of the patients received <10 MU interferon/week fatal hepatic decompensation was not restricted to high dosages of the drug.
Relatively late discontinuation of treatment could be a reason for the unfavourable outcome in some cases.
There are several possible explanations for a link between interferon alfa and fatal hepatic injury.
Interferon alfa enhances lysis mediated by the immune system of hepatocytes infected with hepatitis B virus, resulting in a transient inflammatory exacerbation, which could be lethal in a liver with limited residual capacity.
Other possible explanations are that interferon alfa is directly toxic to hepatocytes and that it induces autoimmune chronic active hepatitis.
Despite the dangers of fatal decompensation, we think that interferon alfa should be considered for treating patients with cirrhosis.
Loss of viral replication by interferon can lead to a substantial regression of liver disease and probably prolonged survival.
In cases in which liver transplantation remains the only option, such a suppression of viral activity may reduce the risk of infection of the graft.
Patients likely to develop hepatic decompensation who receive interferon alfa must, however, be monitored closely by an experienced hepatologist, preferably in a centre with facilities for liver transplantation.
Drug Points
Hypersensitivity to dexamethasone
A 39 year old woman presented in March 1989 with inflammatory breast cancer, which was treated with combination chemotherapy followed by surgery and radiotherapy.
Local recurrence and bone metastases in February 1990 were treated with tamoxifen 20 mg daily.
Further local recurrence in October 1990 was treated with aminoglutethimide 250 mg twice daily with replacement hydrocortisone 20 mg twice daily.
In May 1991 the patient developed pleural and liver metastases.
Ibuprofen 400 mg four times a day failed to control pain, and on 4 June 1991 dexamethasone 2 mg three times a day and cimetidine 800 mg once daily were started for symptom control.
On 8 June 1991 the patient developed a generalised urticarial rash with bronchospasm, which was treated with intravenous hydrocortisone and chlorpheniramine.
Ibuprofen and cimetidine were stopped and dexamethasone continued.
She had two further attacks in the next two days.
On 11 June 1991 she received chemotherapy with antiemetic cover of intravenous dexamethasone 8 mg and metoclopramide 10 mg followed by dexamethasone 4 mg four times a day orally and had a further urticarial attack associated with bronchospasm.
At this point we suspected that she was hypersensitive to dexamethasone and therefore withdrew the drug.
There were no further attacks.
This case shows hypersensitivity to dexamethasone in a patient previously taking hydrocortisone for five months with no evidence of hypersensitivity.
Hypersensitivity to hydrocortisone has been well documented, and intradermal testing was thought to have a role in predicting safe administration of an alternative steroid.
In this case, however, pinprick testing followed by intradermal injections of hydrocortisone sodium succinate 100 g/l and dexamethasone sodium phosphate 4 g/l gave negative results and the patient declined further challenges.
Awareness of this hypersensitivity phenomenon is important as dexamethasone is increasingly used as antiemetic therapy and for raised intracranial pressure, acute cord compression, and other common clinical conditions.
Acute eosinophilic pneumonia induced by inhaled pentamidine isethionate
On 9 January 1991 a 25 year old woman with asymptomatic human immunodeficiency virus infection received a first aerosol of pentamidine isethionate for primary prevention of Pneumocystis carinii pneumonia: 300 mg of pentamidine isethionate was dissolved in 10 ml sterile water and inhaled in sitting position, over 15–25 minutes, via an ultrasonic nebuliser.
She was admitted to hospital on 21 January because of a productive cough and mild dyspnoea which had appeared four days earlier.
She had a history of recurrent eczema but no exposure to toxic products.
She had smoked one pack of cigarettes daily for six years and was taking no medication.
Her temperature was 38.2pC, and chest examination disclosed wheezing and ronchi.
The white cell count was 10.22×10/l with 2.09×10/l eosinophils.
Arterial partial pressure of oxygen was 10.8 kPa.
A chest radiograph showed non-systematic disseminated infiltrates, chiefly in the two lower lobes.
Bronchoalveolar lavage excluded P cystis carinii pneumonia.
Screening for infection gave negative results, but total serum immunoglobulin IgE was high: 7370 IU (normal<150 IU/l).
An oral macrolide antibiotic was administered because we suspected an atypical pneumonia.
One week later the symptoms disappeared.
Two weeks later the chest radiograph was normal and eosinophils were only 0.58×10/l.
On 11 February she received a second pentamidine isethionate aerosol; cough and dyspnoea reappeared two days later and eosinophils rose to 0.95×10/l.
A chest radiograph showed recurrence of the pulmonary lesions.
She recovered with no treatment, and P cystis carinii pneumonia prophylaxis was stopped.
She had no relapse during 18 months' follow up, and results of lung function tests were normal.
Local side effects, including cough and wheezing, during inhalation of pentamidine isethionate occur in 33% of patients.
Other adverse reactions due to systemic absorption, such as hypoglycaemia, rash, and acute renal failure, are rare.
This is the first report of acute eosinophilic pneumonia associated with nebulised pentamidine, whose half life in bronchoalveolar lavage fluid is at least 10–14 days.
The aerosol device is unlikely to have been the cause.
This adverse reaction is similar to that described for nitrofurantoin, sulphonamides, and penicillins and the mechanism is probably immunoallergic.
Visual failure and optic atrophy associated with chlorambucil therapy
We report a patient with visual failure and optic atrophy who was receiving long term chlorambucil for a low grade non-Hodgkin's lymphoma.
A 65 year old man noticed painless swellings in his neck and was found to have cervical, axillary, and inguinal lymphadenopathy without hepatosplenomegaly or systemic symptoms.
Cervical lymph node biopsy showed a non-Hodgkin's lymphoma of follicular type.
The patient received local cobalt beam radiotherapy (9 Gy) which produced regression of all lymph nodes, followed by maintenance therapy with chlorambucil 2 mg twice daily.
Cessation of chlorambucil after two symptom free years was followed by prompt recrudescence of inguinal lymphadenopathy necessitating further local radiotherapy (18 Gy) and maintenance chlorambucil (2 mg twice daily).
Five years after his illness began the patient complained of progressive visual impairment.
In April 1991 his visual acuities were 6/12 right and 6/24 left and the discs were noted to be pale.
Goldmann fields showed a marked constriction on the right and obliteration of the central 20p on the left.
Slightly raised intraocular pressures were controlled with timolol 0.25% twice daily but with no improvement in acuity, which by March 1992 had deteriorated to 6/36 right and 6/60 left.
Reduction in chlorambucil dose to 2 mg daily had no effect on visual symptoms.
The following investigations were normal or negative: full blood count; biochemical profile; thyroid function tests; serum vitamin B-12 and folate; syphilis serology; chest x ray examination; autoantibody screen; and cerebrospinal fluid pressure, cell count, cytology, and protein.
Computed tomography of the brain showed moderate cerebral atrophy.
Magnetic resonance imaging of the brain (before and after gadolinium) showed no evidence of intracranial lymphoma.
Flash and pattern reversal stimulation failed to evoke clear cortical potentials, and electroretinograms were unrecordable.
By exclusion chlorambucil was the most likely cause of this patient's visual failure and optic atrophy.
A direct effect of lymphoma on the optic nerves or chiasm was excluded by the normal magnetic resonance scan, and a non-metastatic complication was unlikely in the absence of lymphadenopathy or systemic symptoms.
Failure to record an electroretinogram suggests a global insult to the retina, compatible with drug toxicity.
Chlorambucil has rarely been reported to produce ocular side effects, although these are common with many cancer chemotherapeutic agents.
Keratitis, oculomotor disturbances, haemorrhagic retinopathy, and disc oedema have been reported, generally as isolated cases after many years of chlorambucil use.
Textbooks also mention lid oedema, hyperpigmentation and oedema of the conjunctiva, and dry eyes in association with chlorambucil use.
The Committee on Safety of Medicines (personal communication) has received only a single report of visual disorder associated with chlorambucil — namely, corneal opacity — and the manufacturers (Wellcome) have only a single report of optic neuritis, occurring on day 1 of chlorambucil treatment and not resolving on withdrawal.
The mechanism for these various reactions, including the current case, is unknown.
General Practice
Influence of Royal College of Radiologists' guidelines on referral from general practice
Abstract
Objective
To measure the effect on general practitioner referrals for radiography of introducing guidelines of good practice together with monitoring and peer review.
Design
Collection of referral data during 1 January 1989 to 31 December 1990.
Guidelines were introduced on 1 January 1990.
Setting
Open access radiology services provided by one non-teaching district in England.
Subjects
144 614 registered patients from 22 practices.
Main outcome measures
Number of referrals per 1000 registered patients for radiography of the chest, skull, spine, abdomen, limbs, and joints and for barium investigation and excretion urography.
Results
Overall referrals fell from 88.4/1000 registered patients to 77.2/1000 after the guidelines were introduced.
The commonest reasons for referral were for examination of the chest, spine, and limbs and joints and referrals for these fell by 9.4%, 17.5%, and 13.5% respectively.
Referrals for skull radiography fell by 30% (from 241 to 168).
Conclusions
By helping general practitioners to be more selective in their use of diagnostic radiology the guidelines reduced the rate of referral and thus patients' exposure to radiation.
Introduction
In 1981 a joint working party of the Royal College of General Practitioners and the Royal College of Radiologists recommended that direct access to radiological services is essential to family doctors; it shortens the investigation time and improves the quality of service offered by general practitioners.
These recommendations are supported by the results of several studies showing that practitioners generally use unrestricted access to diagnostic radiology responsibly and with discrimination.
A study by Stoddart and Holl, however, suggested that if practitioners adopted patient selection guidelines governing the appropriate choice of radiological examination the level of referral could be reduced by around 30%.
Keogan et al studied 2017 patients referred for chest radiography and recommended more selective use of chest radiography through the application of selection guidelines.
An experimental study from Plymouth reported a 23% reduction in general practitioner referrals after local guidelines were distributed.
This paper describes an audit of general practitioner referrals for radiography in one health district in England before and after the introduction of the Royal College of Radiologists' booklet Making the Best Use of a Department of Radiology .
An audit of the effect of these guidelines on hospital referral practice has been described.
Methods
The study, which had the full support of the local medical committee and the district medical advisory committee, was carried out between 1 January 1989 and 31 December 1990 in a non-teaching district in England.
The district was mainly rural with several small seaside and market towns.
A consultant radiologist was nominated as the local research coordinator and was responsible for the day to day running of the study and the preliminary public relations work.
Local general practitioners and the hospital medical staff of the district had agreed to the establishment of a radiology referral review committee for the period of the study.
The committee was set up to endorse the introduction of the college's guidelines as district policy and to oversee the collection, analysis, and monitoring of referral data from the district's radiology departments.
General practitioners and the main specialties were represented on the committee, which was chaired by the local coordinator.
A computerised data collection system had to be set up to monitor each general practitioner's referrals per 1000 patients on the practice list.
Baseline general practitioner referral practice was monitored during 1 January to 31 December 1989 and the guidelines were officially introduced on 1 January 1990.
The guidelines' acceptability and their effect on referral practice was observed during 1 January to 31 December 1990.
Before the guidelines were formally introduced the local coordinator apprised the local medical committee of their content and the nature and purpose of the study.
The coordinator or a member of the radiology referral review committee also visited all the larger general practices to explain the purpose of the study, to show the participating practitioners the guideline booklet, and to obtain their approval.
The committee monitored referral practice during the study but there was no reinforcement of the guidelines to assure compliance.
The family practitioner committee was unwilling to disclose the size of individual practices and so, to preserve anonymity, practices were grouped into nine geographical zones and their referrals represented as rates per zone.
Thirty practices with a combined list of 175 417 patients had open access to the radiology services provided by the district.
Many patients from eight practices in two of the zones were referred for examination to an adjacent district because radiology facilities were nearer.
These practices have been excluded from the analysis, which is therefore based on referrals from 22 practices with a combined list of 144 614 registered patients.
Results
Referrals from general practice made up 40% of the workload of the district's radiology service.
In all 79% (23949 of 30253) of general practitioner referrals were  for one of the seven examinations covered in the guideline booklet (chest, skull, spine, abdomen, barium investigation, excretion urography, and limbs and joints).
The highest referrals were for examination of the chest (8506, 28%), limbs and joints (7666, 25%), and spine (5224, 17%).
Before the guidelines were introduced the referral rate from general practitioners for examinations covered by the guidelines was 88.4/1000 registered patients (table I).
This fell to 77.2/1000 after introduction of the guidelines.
The referral rate fell in six of the seven zones.
The number of zones with a referral rate below 75/1000 registered patients rose from one (representing two practices) to four zones (17 practices) after the guidelines were introduced.
Zone D, the only zone with an increased level of referral after the guidelines, also had the highest level of referral before the guidelines.
Table II compares the actual number of referrals before and after introducing the guidelines by type of examination requested and shows the absolute change in terms of workload and cost.
This comparison is possible because the list size remained largely unchanged over the two year study.
The largest reductions were observed in referral for examinations of the skull (30.3%), spine (17.5%), limbs and joints (13.5%), and chest (9.4%).
Although together they made up only 8% of referrals in the year before the guidelines the reduction in barium investigation and excretion urography contributed 25% of the savings achieved in the second year.
Discussion
The reduction in referrals we observed and the 23% reduction reported in Plymouth Health District followed voluntary adoption of the guidelines by practitioners without any reinforcement of guidelines to ensure compliance.
Studies of hospital practice suggest that larger reductions could be achieved and sustained if the guidelines became a required standard of good general practice and formal peer review was introduced with steps to ensure compliance, particularly among practices with high referral rates.
The variation in referral rates among general practice was much less than that reported in hospitals.
The narrow range of referral rates after the guidelines for six of the seven zones (69.2–81.9/1000 registered patients) suggests an appropriate target referral rate of below 75/1000 registered patients a year.
Practices with referral levels above 100/1000 registered patients should urgently review their referral practice.
We found two practices (in zone D) with referral rates above 100/1000.
Both were sited in the grounds of a hospital with a radiology department so each had open and immediate access to radiographic examination.
After the guidelines were introduced there were 1582 fewer referrals for radiography and 223 additional referrals for ultrasonography from a registered population of 144 614 patients resulting in a potential saving of about £13 500 excluding ambulance costs.
This figure may be even lower in future following the publication, early next year, of a revised edition of the guidelines which will include a new section on diagnostic ultrasonography.
No concurrent increase in referrals from other sources was observed.
Radiological referrals from all sources in the district decreased in 1990: general practice by 9.4%, hospital inpatients by 15.4%, hospital outpatients by 14.6%, and accident and emergency units by 11.1%.
Generation of referral data should be a routine requirement for all NHS radiology departments.
Without this information the appropriateness of the referral practice of individual users or the whole organisation cannot be monitored.
This requirement should be specified in the tender document for the purchase of radiology services.
Since their publication in April 1990 about 30 000 copies of the college guidelines have been distributed to hospital doctors throughout the NHS.
Our study shows that the guidelines are acceptable to and suitable for use by general practitioners and suggests that they can substantially reduce referral levels and reduce patients' exposure to radiation.
Application of these results throughout the whole of the United Kingdom would reduce referrals by at least 0.6 million and produce potential savings of £5.4 million.
The Future of FHSAs
Empowering GPs as purchasers
This is the first in a series of articles on the future of family health services authorities
The NHS reforms gave general practitioners and primary health care teams a long awaited chance to exert greater influence over the pattern of services in both hospitals and the community.
Practices can now purchase as fundholders or exercise their new found powers through commenting on the purchasing plans of the health authorities.
In this way general practitioners have begun to be involved in making decisions about effecting change in the balance of services between primary and secondary care and in establishing priorities for the types of services they wish to see delivered in the future.
Family health services authorities have found themselves acting with and on behalf of district health authorities wanting to get closer to general practitioners and to understand better what they want purchased.
However, they have also found themselves caught between what district health authority purchasers with a population based public health focus want and what general practitioners want based on their patients' needs.
Educating GPs
Fundholding has undoubtedly had its successes, reflected in a sea change in the attitude of hospital clinicians and management towards general practice and recognisable improvements in the management and organisation of practices.
However, it still remains a scheme that is limited to a relatively small proportion of practices.
This is certainly the case in many inner city areas, where there has been philosophical and political opposition to the scheme and where the organisational barriers to becoming a fundholding practice have been considerable.
Meanwhile, purchasing authorities themselves have changed, particularly where previous districts have merged.
Family health services authorities have spent considerable effort defining not only a role in purchasing primary care but also working in tandem with district health authorities to begin discussions about extending purchasing across the interface between primary and secondary care.
Increasingly during this time almost all purchasing authorities have struggled with how to educate general practitioners and so empower them to use their influence constructively in the purchasing process.
This seems a two stage process.
The first stage is eliciting a general practitioner's interest and commitment to being involved in purchasing.
It may seem obvious to suggest that the level of understanding about purchasing among general practitioners and primary health care teams is extremely varied, but primary care has a long history of suffering from being physically distanced from other parts of the service and the discussions taking place there.
Recognising this as a structural problem and using educational and other networks to offer general practitioners maximum opportunity for discussion is a first step to facilitating their involvement.
The level of understanding they need to play an active part in the process and thereby challenge decisions taken is often underacknowledged.
Many general practitioners still need to be convinced that their views will be listened to and where appropriate acted on.
Practitioners who initially took a stance against involvement in purchasing because of their concerns over fundholding leading to a two tier system need to be persuaded that they are still needed in influencing purchasing decisions overall.
All of this must be achieved against a background of general practitioners in inner cities struggling with an increasingly challenging role as services providers in primary care.
They need to be encouraged to put minimum effort to maximum effect by focusing on areas where they and the public will be able to identify changes and value the results.
Secondly, priority needs to be given to establishing structures that will enable all general practitioners to be involved in influencing the views of the purchasing authorities, including those who have hitherto expressed little or no interest and those who already have a clear interest in participating.
Confusion has existed about how to achieve this.
There is also a lack of clarity over where the emphasis should be for promoting the involvement of general practitioners.
To date this has been placed on involving them in acute services where the current bulk of expenditure is for district health authority purchasers.
However, this may not be the most appropriate frame of reference for general practitioners for whom purchasing primary and community care may be much more relevant on a day to day basis.
Need for GP involvement
There are several reasons why general practitioners and primary care need to continue to stake their claim on involvement.
Firstly, general practitioners and other members of the primary health care team in effect purchase the bulk of health care, the resource implications of which are considerable.
Encouraging active responsibility for this is vital.
Secondly, general practitioners and primary health  care teams are the first point of contact for users of the health service.
They can therefore be considered to be close to the community they serve and have the potential to be advocates for the health needs of patients.
Local involvement of general practitioners, the new breed of practice managers, and other members of the primary health care team is needed.
Working with district health authorities they may offer some new solutions to longstanding problems, give greater priority to local need, and enable the development of services with the capacity to respond to changing needs over time.
This builds on their existing knowledge of local services and the potential for their development.
Thirdly, the current pace of change in ideas about what needs to be purchased is increasing.
The language that has developed to express these ideas is becoming increasingly more difficult for those outside the immediate discussion to understand.
This means primary care needs to continue to develop its own capacity to question the decisions that are being taken.
Finally, the reforms aimed to shift the balance of power in determining use of resources from hospital doctors to general practitioners.
This has been described as a golden opportunity for primary care to develop a much enhanced role.
What seems important, however, is that the transition is managed through an informed use of general practitioners' influence on decisions.
While relishing this opportunity there is a need for considered action.
Undoubtedly there is a need to continue to emphasise the importance of change in an area where exhaustion of general practitioners is clear.
There is a need to protect primary care from becoming a dumping ground for services which need to be provided but which they are currently not resourced to deal with.
General practice and primary care need to be centre stage to ensure that the rhetoric of a transfer of resources from secondary to primary care does not actually entail an overall loss of resources.
A range of possibilities
While much of this is difficult to achieve in practice, there are examples where changes and developments have been seen.
In south east London, for example, the status of general practitioners as effective contributors to the debate about services has grown and led to the recognition of an umbrella group set up to represent their views in purchasing.
General practitioners are also active members of focus groups that discuss particular areas of service such as diabetes.
Communication has improved and an outreach approach has developed, with practices being courted by both purchasers and providers.
The purchasing authority have made considerable efforts to collect general practitioners' views towards services.
A survey identified high levels of consensus around key areas for change in acute services which has made the setting of some priorities for change easier.
Perhaps more interestingly, it indicated general practitioners' overall high level of satisfaction with the quality of community health services but identified a wish for a much greater volume of services to be provided.
Initiatives such as the ‘quality alert mechanism,’ which enables a quick feedback of problem areas from general practitioners to the purchasing agency, also have to be seen as straightforward and practical moves to better enable monitoring of contracts through the year.
Many authorities are widening the scope of discussion with general practitioners to develop appropriate means of local involvement.
What seems to exist is a continuum of purchasing involvement.
General practice fundholders are at one extreme, with regional health authority top sliced budgets, although only very few practices are participating in the most deprived inner city areas.
At the other end of the scale are what can be called ‘sensitised district health authorities’ such as Tower Hamlets or South East London Commissioning Agency, where the district health authority retains all the strength of combined purchasing power but seeks to maximise general practitioners' participation in decisions about what is commissioned.
The most likely pattern, which is already being discussed, is a mix of these two extremes.
The following three examples are used to highlight possible options.
Example 1
Stockport District Health Authority has developed a locality model of purchasing with extended outposts in localities.
A purchasing plan constructed by the authority in close collaboration with the family health services authority is modified through local negotiation with practices.
While at the current time the main focus of this work has been to better assess need through localities, work is being undertaken to identify ways in which budgets could be allocated to localities and purchasing carried out at the local level.
This model also emphasises not only general practitioners' voices but all local voices, including those of nurses, community leaders, voluntary groups, and others.
Example 2
North Derbyshire District Health Authority has established ‘locally sensitive purchasing.’
While locality links are planned to aid general practitioners' involvement a major thrust of this initiative is to allocate the district budget to individual practices on an indicative basis.
This is a challenging model, attempting to allocate 75% of all district health authority expenditure on services rather than the 20–25% currently given to practitioners through fundholding.
Example 3
Closer still to delegated purchasing to practices is ‘practice sensitive purchasing,’ which is developing in Bath.
This seeks to divide the district health authority budget notionally between practices, thereby delegating purchasing authority to each practice.
This clearly has strengths both in building contracting from the ‘bottom up’ and emphasising equity in distributing resources.
However, the level of sophistication required both in allocating resources and in organisational competence within practices means it is unlikely to find widespread acceptance.
Which model?
There are four main questions which emerge from these discussions which are central to all of these proposed models.
These are: How do we continue to aim for a principle of equity in distributing limited resources across populations?
How are management costs and the administrative burden of any of these models minimised?
How do we develop systems that are sensitive to the needs of users as well as the expressed needs of practitioners? and, How do we maintain the practitioners' interest when the need for change is identified but managing a planned process of change will take time?
Further, there are underlying themes that are relevant to the subsequent discussion of possible models for general practitioners' involvement in purchasing.
There is a need for a continuing range of models which enable different levels of involvement both by practitioners and the wider community.
There is a need for debate with practitioners and the public to revise the local model.
While supporting the practitioners' role as proxy for the patient in purchasing, there is a need to recognise the limitations of this, and wherever possible we should be seeking the opinion of the public.
Any models developed need to maximise health gain while retaining the strength of the focus on individual patients.
It is clear that general practitioners have the potential to be able contributors to the discussion of what needs to be purchased and where, although the mechanisms by which this is achieved need a variety of well thought out and appropriate structures.
There is also a need to reassure general practitioners that proposed changes in service can be realistically achieved through their influence.
Summary
FHSAs have defined their role in purchasing primary care
FHSAs have also found themselves intermediaries between district health authorities and general practitioners
All of the purchasing authorities recognise the need to educate general practitioners on how to use their influence in the purchasing process
General practitioners should be involved in the purchasing process as they purchase the bulk of health care; are the first point of contact for the users of the health service; need to have input on what is purchased; and need to be able to manage the changes resulting from the shift in the balance of power towards primary care
The involvement of general practitioners in the purchasing process at present varies considerably among health authorities.
Several district health authorities have developed models of purchasing that enable different levels of involvement
Education & Debate
Phenylketonuria due to phenylalanine hydroxylase deficiency: an unfolding story
Efficient neonatal screening for phenylketonuria and the availability of complex diets for lifelong use have virtually eliminated severe mental handicap from the disease.
Nevertheless, there remains a high risk of fetal damage in offspring of women with the disease, and the possibility that the diets themselves may be harmful cannot be excluded.
Search for a preventive treatment for the disease has been greatly aided by advances in molecular genetics.
For example, in mice modified liver cells have been implanted, which have not only corrected the phenylalanine defect but have remained healthy for the normal life span of the animal.
Overall, however, prevention and treatment have not progressed as quickly as was hoped, and research and development must be pursued vigorously to take account of contemporary perceptions of the disorder.
Phenylketonuria (persistent hyperphenylalaninaemia >240 µmol/l, relative tyrosine deficiency, and excretion of an excess of phenylketones) occurs in approximately one in 10 000 births in the United Kingdom.
Except for 1–2% of subjects with defective metabolism of tetrahydrobiopterin, these infants have a recessively inherited deficiency in the hepatic enzyme phenylalanine hydroxylase.
The virtual disappearance of children with severe mental handicap from this cause is the result of highly efficient neonatal screening and early treatment with a diet low in phenylalanine.
Such a diet is complex and depends on the use of manufactured substitutes for many natural foods (meat, fish, eggs, nuts, dairy products, bread, cakes)(see figure).
This makes the diet difficult to sustain over long periods and management requires the services of a specialist metabolic team.
As the first generation of well managed subjects reaches adulthood there is anxiety about their neurological progress, both in early childhood and later, and about the effects of maternal phenylketonuria on the next generation.
Alongside the clinical concerns there has been significant progress in our understanding of the molecular genetics.
This paper reviews the clinical implications of some recent work and considers future issues for health service research and development with special reference to the United Kingdom.
Phenotypic and genetic variation
It has long been known that phenylalanine hydroxylase deficiency exhibits a wide and continuous range of clinical and biochemical severity, varying from a symptomless disorder with phenylalanine accumulation only just greater than in obligate heterozygotes to a severely handicapping condition with plasma phenylalanine concentrations over 20 times normal.
The enzyme deficiency varies from absence of detectable activity to a residual activity of up to 25% or more.
Recent genetic studies have provided an explanation for this variation.
Over 40 different mutations of the phenylalanine hydroxylase gene have been identified.
A high proportion of affected subjects are therefore compound heterozygotes rather than homozygotes, although particular mutations may occur with a frequency of over 60% in certain populations and there may be close association with particular haplotypes, indicating that founder effect has had an important influence on the distribution of mutations across nations.
The gene for phenylalanine hydroxylase, which is on chromosome 12, contains 13 exons and messenger RNA is not readily available.
A screen of coding regions for mutations still presents a considerable challenge even with the much improved technology made available by the polymerase chain reaction, and it is possible that very many different mutations remain to be discovered.
Association between genotype and phenotype has been observed and is supported by expression studies.
By using virus vectors phenylalanine hydroxylase genes carrying eight different mutations have each been inserted into a hepatoma cell line without natural hydroxylase activity.
The enzyme activity of each modified cell line was assayed and the results used to calculate the expected enzyme activity resulting from the various combinations of mutations in vivo.
In subjects carrying the various gene combinations estimated enzyme activity showed a remarkably good correlation with previously determined measures of biochemical severity (diagnostic phenylalanine concentrations, phenylalanine tolerance during treatment, and response to a standard protein load).
These advances in molecular genetics mean that by using a combination of haplotype and mutation analysis prenatal diagnosis is now possible in the great majority of couples who already have a child with phenylketonuria, although this has been undertaken infrequently because paediatricians and parents see early treated children as ‘healthy.’
Carrier testing is also practicable in close relatives but — except in communities with a high frequency of particular mutations — carrier testing will not be practicable in the general population, including the unrelated spouses of known carriers, until it is possible cheaply to scan the hydroxylase gene for the many known mutations.
The therapeutic potential of these genetic advances has been indicated by recent gene transfer experiments by Woo in an inbred strain of mouse with phenylalanine hydroxylase deficiency (S L C Woo, paper delivered at annual meeting of European Metabolic Group (Milupa) Copenhagen, May 1991).
Using virus vectors, Woo successfully inserted normal mouse genes for phenylalanine hydroxylase into cultured liver cells from the mutant mouse.
These modified liver cells were then reimplanted by injection via the spleen.
The injected cells remained healthy within the liver parenchyma and corrected the phenylalanine defect for the normal life span of the mouse (even though the cells made up only a small percentage of liver cells).
Neuropsychological impairment in early treated subjects
Untreated phenylketonuria is, above all, a disorder of the central nervous system in which varying degrees of delayed development and other signs of serious brain disease, such as epilepsy, become apparent in early infancy.
The benefits of early treatment in ameliorating the clinical impact of the disease are well established.
Nevertheless, early treated subjects as a group exhibit various detectable abnormalities (box 1).
Children and adults have mean intelligence quotients (IQs) roughly half a standard deviation lower than those of unaffected siblings and population norms.
The full clinical relevance of this reduction in IQ has been appreciated only recently following the reports of a steady rise of mean IQ scores in the general populations of Western nations, including the United Kingdom.
Reviewed in the light of these population shifts, the findings in subjects with phenylketonuria suggest that a high proportion of early treated subjects — not just a poorly managed minority — exhibit some degree of intellectual impairment and that the major impact is in early childhood before there is any question of relaxing or stopping treatment.
Interestingly, virtually all published studies from around the world have reported similar findings.
There is also evidence of slower acquisition of language and, in the school years, a higher frequency of learning difficulties and behavioural disturbance — hyperactivity, anxiety, and poor concentration being prominent features.
Measurement of specific abilities in children and young adults have shown slowed response times, deficits in sustained attention, and impaired problem solving ability.
Although these impairments must be of concern, we emphasise that most early treated children fall within the broad normal range of general ability and attend ordinary schools.
However, abnormal neurological signs (notably unusually brisk tendon reflexes and tremor) are common in older subjects, and overt neurological deterioration has been reported in a few early treated young adults.
Upper motor neurone disturbance rather than intellectual decline was a prominent feature, and magnetic resonance imaging disclosed abnormalities in the subcortical white matter.
Neurological deterioration in adulthood has also been recorded in some late and untreated subjects, and in a few in whom a neuropathological report was available the findings suggested active and diffuse demyelination as well as hypomyelination and reduced brain size.
Rather similar, though usually less severe, magnetic resonance imaging changes than those recorded in association with neurological deterioration have also been observed in symptomless subjects.
Of 26 clinic subjects aged 8 to 30 years studied in London, none had unequivocally normal appearances on magnetic resonance imaging, indicating that white matter changes are very much commoner than overt neurological disease.
The likelihood is that the changes on magnetic resonance imaging are a marker of abnormalities in myelin (such as vacuolation, expanded extracellular spaces, oedema, or demyelination).
Recent reports suggest that oedema may be an important component of the changes.
Relation between neurological problems and hyperphenylalaninaemia
The degree of intellectual impairment occurring in early treated preschool children is closely associated with the degree of hyperphenylalaninaemia to which the subjects have been exposed.
In a large British study intelligence decreased linearly and independently with increasing age at the start of treatment and poorer average control of blood phenylalanine concentrations.
Longer periods of unusually low phenylalanine concentrations were also independently associated with worse outcome.
Relaxation or withdrawal of treatment before mid-childhood has been associated with a further decline in intellectual ability.
Other studies have shown worse school progress in children who stopped diet at 6 years of age compared with children who continued treatment.
Transient changes in neuropsychological function have also been shown to occur in response to short term changes in plasma phenylalanine concentrations.
In the magnetic resonance imaging studies subjects who showed the more severe white matter changes had worse recent phenylalanine control and were more likely to have been on a normal diet without protein substitute for longer (A J Thompson, I Smith, D P Brenton, personal communication).
Phenylalanine control in early childhood seemed to play little part.
No evidence for a threshold of phenylalanine effects on intelligence or behaviour emerged from the analysis of United Kingdom data.
Subjects with milder phenylketonuria did consistently better than those with a more severe disorder, but this advantage disappeared when allowance was made for their better phenylalanine control.
The view that a ‘threshold of effect’ exists for the effects of phenylketonuria on brain development is based largely on the apparently normal intelligence of subjects with the mildest forms of the disorder (so called‘benign’hyperphenylalaninaemia), whose plasma phenylalanine concentrations are <1000 µmol/l (normal 50–120 µmol/l) and who do not usually receive treatment.
However, some IQ data for this group of subjects are available, and when these are re-examined in the light of revised population IQ norms a similar reduction in mean IQ is observed to that seen in early treated subjects.
An association between the degree of phenylalanine accumulation and mean IQ is also apparent — more severe form, mean IQ 98; milder form, mean IQ 103 (expected population mean IQ approximately 110).
Despite the weight of evidence linking the severity of impairment with the degree of hyperphenylalaninaemia there remain some difficulties in interpreting the data.
For example, a recent German study, which aimed at controlling blood phenylalanine concentrations between 60 and 300 µmol/l, produced IQ results no better than those in British subjects, in whom the  aim was more relaxed control (180–600 µmol/l), though the blood phenylalanine value was on average 100 µmol/l lower in the German subjects.
We do not know whether peaks (and troughs) in phenylalanine control are more (or less) harmful than persistent but moderate hyperphenylalaninaemia.
Nor is it certain that the reported associations between long term outcome and exposure to phenylalanine accumulation are entirely ‘cause and effect.’
The possibility that some neurological damage may occur before delivery and be more pronounced in infants with classic than atypical disease (and therefore be associated with rather than caused by worse phenylalanine control) cannot be completely discounted.
Nor can we discount the possibility that some factor in the diet itself has harmful effects.
Nevertheless, it seems highly probable that the persisting biochemical abnormalities (phenylalanine excess or some closely related change) at least make a substantial contribution to the neurological impairment.
Taken together these data link neurological outcome in early treated subjects closely to the quality of phenylalanine control throughout life.
This conclusion has important implications for the management of affected subjects, and guidelines on treatment need to be revised in the light of these recent findings.
Maternal phenylketonuria
There is a high risk of fetal damage in the offspring of women with phenylketonuria.
In classic phenylketonuria microcephaly, mental handicap, and impaired fetal growth are likely to occur in over 80% of subjects, accompanied by malformations in the heart or other organs in at least 20%.
Fortunately dietary intervention from before conception seems to have a favourable influence on outcome, which seems to be closely associated with the degree of hyperphenylalaninaemia very early in gestation.
Congenital anomalies are uncommon in the offspring of women with phenylalanine concentrations below 900 µmol/l at the time of conception.
However, head size, birth weight, and intelligence have been shown to be inversely and linearly associated with maternal phenylalanine concentrations, again without any obvious threshold in effect.
The data suggest that optimal outcome for the fetus can be achieved only when maternal phenylalanine concentrations are close to normal from early gestation.
In an ongoing study (A Stewart, D Brenton, personal communication) of 15 infants conceived under dietary control (mean phenylalanine values in first trimester 213–496 µmol/l — twice to four times normal) Griffiths developmental quotients at one year were within the normal range and head circumferences were at or above the 10th centile.
However, strict neurological assessment showed that even in these infants minor neurological impairments were detectable, which may indicate a risk of cognitive deficits later.
The findings suggest that in the management of pregnant women phenylalanine control needs to be, if anything, even stricter than in children with phenylketonuria.
Mechanisms of damage
In considering which strategies might be useful in trying to improve outcome in phenylketonuria it would be helpful to understand the mechanisms involved in the damage.
Despite the difference in degree there are obvious similarities in the character of the neurological abnormalities in early and late treated children, suggesting common mechanisms.
However, the identity of the critical biochemical events leading to cerebral damage, and to damage to the fetus in pregnancy, remains uncertain.
The ketoacid derivatives of phenylalanine, although potentially harmful, seem unlikely to reach high enough concentrations in the brain to account for neurological damage.
Owing to the competitive nature of amino acid transport across the blood-brain barrier and across the placenta, the brain in patients with phenylketonuria and the fetus in women with phenylketonuria are exposed to both high phenylalanine concentrations and low concentrations of the other large neutral amino acids, especially tyrosine.
One direct consequence of the amino acid changes is the well recognised reduction in dopamine and serotonin turnover.
The scale of the amine abnormality is proportional to the degree of hyperphenylalaninaemia and probably depends on the combined effects of competitive inhibition of tyrosine and tryptophan hydroxylases (by phenylalanine) and a deficiency of the amino acid substrates for these enzymes.
Transient deterioration in neuropsychological function has been shown convincingly during short periods of experimental hyperphenylalaninaemia, and it has been argued that the changes may be due to neurotransmitter deficiency.
However, this remains speculation and in any case seems an unlikely explanation for microcephaly, hypomyelination, and myelin loss.
Inhibition by phenylalanine of certain key reactions in  brain protein synthesis or in the synthesis of myelin sulphatides, or both, seems a more probable cause of myelin damage.
Whether common mechanisms underlie damage to the brain and to the fetus is not known.
The above findings suggest there are some additional therapeutic strategies which may be of value in limiting the effects of phenylalanine.
Animal and human studies show that uptake of phenylalanine by the brain can be substantially inhibited by increased plasma concentrations of other amino acids induced by administration of large doses of amino acids such as tyrosine, tryptophan, or the branched chain compounds.
The same is likely to be true of phenylalanine uptake across the placenta.
Therefore, the quantity, composition, and diurnal distribution of the amino acid supplements used in treatment may influence the effects of raised plasma phenylalanine concentrations, especially if these are not too far above the normal range.
Judicious choice of quantity and timing of amino acid intake could therefore be of benefit.
Pharmacological doses of tyrosine, tryptophan, or branched chain compounds may also have a therapeutic role when phenylalanine concentrations are higher.
An alternative approach to reducing phenylalanine accumulation is oral treatment with the enzyme phenylalanine ammonia lyase.
The aim is to improve dietary tolerance to phenylalanine by inducing breakdown of phenylalanine in the gut before absorption.
Both these approaches require further investigation in controlled trials.
Future research and development
A low phenylalanine diet cannot fully substitute for the fine tuning of phenylalanine turnover normally exerted by hepatic phenylalanine hydroxylase.
The dietary control of plasma phenylalanine concentrations requires rigorous restriction of natural protein intake, often to less than 6 g per day.
Frequent biochemical monitoring and regular ingestion of unpalatable substitutes for protein, minerals, vitamins, and energy are also needed.
It is particularly difficult to maintain smooth phenylalanine control in subjects with severe enzyme deficiency, in whom even a minor feverish illness or fall in energy intake may lead to a rise in phenylalanine concentrations.
Aiming at ‘normal’ concentrations runs the risk of inducing phenylalanine deficiency, which several lines of evidence suggest is harmful to both nutrition and brain development.
It is clear that better therapeutic strategies will be needed if we are substantially to improve outcome in subjects with phenylketonuria.
Given the difficulties in implementing treatment, the human and financial costs, and the concerns about neurological progress and fetal outcome, phenylketonuria is a potential candidate for gene therapy if this proves ‘safe.’
Although the philosophical climate in the United Kingdom is right for such a development and the epidemiological background is well established, much more laboratory work is needed on the molecular genetics, enzyme function, gene transfer to human liver cells, and relevant liver cell biology if patients in the United Kingdom are to benefit from any advances which may occur.
Even if molecular genetics ultimately provides a better form of treatment there is still need to evaluate and, where possible, improve our present dietary management (box 2).
Our working party has drawn up a set of revised guidelines on monitoring dietary management.
In addition, more information needs to be collected on the neurological status of early treated children from infancy onwards, and programmes of neuropsychological and neurophysiological assessment and brain imaging need to be developed to provide more precise measures of progress in individual subjects.
This would enable improved therapeutic strategies to be properly evaluated.
It is important that the national epidemiological project (the phenylketonuria register) should continue to monitor the screening programme and follow up adolescents and young adults, as well as women of fertile age and their offspring, so that long term outcome can be documented.
A similar recommendation has been made concerning the American collaborative study on phenylketonuria.
Health service provision for phenylketonuria
The services needed for screening, diagnosis, and long term management of phenylketonuria are highly specialised (box 2).
Because of the low incidence of the disorder such services can never be comprehensively and efficiently provided at district level.
A regional or supraregional service within a wider service for inherited metabolic disease is likely to provide the most effective approach.
Nevertheless, local services play an essential part in the screening programme and in the day to day care of affected subjects (box 3).
Many different disciplines need to be aware of the particular needs of such patients and the implications of new findings.
In particular, it is important that the reasons for continuing a difficult diet (which includes expensive phenylalanine free protein substitute and other special food products, biochemical monitoring, and experienced dietetic advice) are clearly understood in terms of the neurological risks to the patient.
Even more  important is the need for women of fertile age with phenylketonuria to be appropriately counselled and supported in order to ensure that their children are conceived under the best possible phenylalanine control.
This requires the use of effective contraception until the woman can maintain a strict diet under home conditions (demonstrated by biochemical monitoring at least twice weekly).
Conclusions
Outcome in early treated subjects with phenylketonuria is not as good as was thought just a few years ago and is much more closely associated with the quality of blood phenylalanine control at all ages than previously recognised.
As in diabetes even the very best treatment fails to achieve perfect metabolic control.
Maternal phenylketonuria is an important problem since the advantages of screening in one generation could be lost in the next unless preventive treatment can be implemented in a high proportion of affected women.
Continuing research and development is needed for phenylketonuria, and services for children and adults need to be updated to take account of our new perceptions of this disorder.
Box 1
Neuropsychological impairments in early treated phenylketonuria
Children on strict diet
Reduction in average intellectual ability (IQ >2 SD below population mean in 8–10%, of subjects compared with expected 2%)
Delayed acquisition of speech
Increased frequency of behavioural problems
Reduced educational progress
Slowed response times and impaired executive function on neuropsychological testing
Older subjects on normal or near normal diet
Increased frequency of electroencephalographic and visual evoked potential abnormalities
Changes in cortical white matter on magnetic resonance imaging
Abnormal neurological signs (unusually brisk tendon jerks and tremor); overt neurological deteri-oration in a few subjects
Box 2
Specialist services for phenylketonuria
Metabolic team for screening, diagnosis, counselling, and long term management
Biochemical services
Physician (paediatrician and adult physician)
Dietitian
Nurse specialist
Neurological assessment
Neurology
Neuropsychology
Electrophysiology
Magnetic resonance imaging
Genetics counselling, carrier testing, prenatal diagnosis
Clinical geneticist
Access to molecular genetics service
Obstetrics
Preconception assessment and contraception advice
Procedures for prenatal diagnosis
Fetal assessment — size, congenital anomalies
Box 3
Role of family doctor and community services
Screening process — communication with parents, blood collection, records (tests done, results received), audit of timing, coverage
Ensure access to specialist services
Special needs of affected children (where necessary, blood taking, telephone, housing, nursery placement, school, etc)
Prescribing of special food products
Promotion of long term dietary treatment and strict diet before conception
Family planning advice
Breakfast for 6 year old on low phenylalanine diet (8 g natural protein (400 mg phenylalanine) per day.
* Whole wheat cereal provides 2 g natural protein (100 mg phenylalanine).
Sugar is phenylalanine free.
Orange juice and jam provide another 50 mg phenylalanine.
Bread and mild substitutes and amino acid supplement (10 mg as paste with mineral and vitamins added) are virtually phenylalanine free and prescribable for phenylketonuria
Lunch for 6 year old on low phenylalanine diet (8 g natural protein (400 mg phenylalanine) per day*).
Crisps provide 1 g natural protein (50 mg phenylalanine).
Salad vegetables, fruit, and spread in sandwiches provide another 50 mg phenylalanine.
Bread substitute and amino acid supplement (10 mg as orange flavoured drink containing minerals and vitamins) are virtually protein free and prescribable for phenylketonuria.
Australian court decision on passive smoking appealed
The Australian tobacco industry has been on the very sick list for at least the past 16 years, with adult per capita consumption falling by about one third to its present annual level of 1827 grams.
Since 1983, the year when the first of a series of large scale mass media campaigns started and the momentum against tobacco advertising and smoking in the workplace increased, the average annual fall has been 2.54%.
Rothmans, the perennial market leader, saw its share price fall from $A16.50 to $A4.00 during the past year, wiping $A700 million off its market capitalisation.
But the Christmas of 1992 may be remembered by the Australian tobacco industry as one of its bleakest ever.
On 17 December, its officials woke to radio bulletins announcing that a bill to ban all remaining forms of tobacco advertising had, in the small hours, finally passed through both houses of the federal parliament with the support of all parties.
Tobacco advertising through sponsorship and billboards had been waiting like the last prisoners on death row for eight months following a cabinet announcement in April 1992 that the end of their last ditch stand was nigh.
(Grand prix car and motorcycle racing are to be exempted.
The brands involved in sponsoring grand prix(Marlboro, Camel, Gitanes, Lucky Strike, and Rothmans) each have minute brand shares in Australia, but, unlike France, which has recently lost its place on the grand prix circuit because of its refusal to allow tobacco advertising, Australia will continue to ‘export’ these images around the world in race telecasts.)
In late November a stay of execution seemed possible when some rodeo interests in North Queensland successfully lobbied the Labor caucus, arguing that the ban would mean destitution for this icon of Australian bush spirit, traditionally sponsored by tobacco.
Then the thousand or so readers of a few imported fashion magazines (which it seemed would be prohibited because they contained foreign tobacco advertisements) momentarily rallied key support from the free speech lobby.
Both of these hiccups were rapidly suppressed by amendments involving hardship clause replacement money and blind eye exemptions for minor transgressions like the trickle of foreign magazines.
The bill will see all remaining forms of tobacco advertising phased out by the end of 1995.
The Benson and Hedges cricket competition will then be no more; the increasingly national rugby league competition will probably be taken over by a beer, cola, telecommunications, or insurance sponsor.
Not two hours after digesting this news over their breakfasts, the same industry officials made their way to the Federal Court of Australia to receive the decision on their appeal over the February 1991 judgment by Justice Morling on a Tobacco Institute of Australia advertisement concerning passive smoking that was run throughout the Australian press in 1986.
Justice Morling had ruled in favour of a suit filed by the Australian Federation of Consumer Organisations that the advertisement was misleading and deceptive, breaching a section of the Trade Practices Act.
The Morling judgment centred on a sentence within the advertisement that stated: ‘And yet there is little evidence and nothing which proves scientifically that cigarette smoke causes disease in non-smokers.’
Justice Morling's judgment determined that the statement was indeed misleading and deceptive.
The judge made orders that restrained the Tobacco Institute of Australia from further publishing the advertisement and from making a number of statements based on the sentence cited above.
He also ordered that costs be paid to the Australian Federation of Consumer Organisations on an indemnity basis.
Estimates of the costs involved in the conduct of both parties' cases, which involved evidence being taken in Sydney and London over 91 days, plus 15 days in the appeal, are put at $A10 million.
The decision in the case was seen as having considerable worldwide significance and the Tobacco Institute of Australia immediately appealed against all the major findings of the judgment.
Results of the appeal
The appeal was heard by three judges of the Federal Court, Justices Shepherd, Foster, and Hill.
We consider the main findings and some of the more interesting arguments advanced by the judges in their 148 page judgment.
Of utmost significance was that all three judges upheld the finding that the critical sentence in the advertisement was misleading and deceptive and therefore was in breach of the Trade Practices Act.
The judges declined to accept the Tobacco Institute of Australia's argument that the sentence was not intended as a statement of fact but as merely an expression of opinion or as the platform of an argument in a community wide debate.
Each judge was emphatic that Justice Morling's decision and that reached by them on appeal rested on a consideration of the context and the wording of the claim that there was ‘little evidence’ and ‘none which proves scientifically’that cigarette smoke causes disease in non-smokers.
Much of each judgment was taken up with painstaking reviews of the historical and social context of the advertisement's publication, with the syntactical features of the sentence and its relationship to the rest of the advertisement, and with the undeniable fact that indeed there was considerable ‘evidence’ about the matters at hand at the time of the advertisement's publication.
Justice Shepherd emphasised that in placing the advertisement with its claims in the press, it needed to be appreciated that it would be ‘read by the intelligent and the wary and also by the unsuspecting, the gullible, and the impressionable.’
He stated that ‘it ought to be inferred that…one of the purposes of the advertisement was to enable it to be used by smokers as ammunition to persuade others that their habit was not dangerous to the health of anyone except perhaps their own.’
He concluded that ‘the meaning which the advertiser intended to convey was that there was not a thing, not a jot and not a tittle, which would prove scientifically that cigarette smoke caused disease.’
Like his colleagues, Justice Shepherd vehemently rejected this imputation in upholding Justice Morling's principal decision.
However, the appeal judges were critical of Justice Morling's willingness to enter into an assessment of the quality of the epidemiological evidence tendered by both parties, and of his comments about his  preferences for particular epidemiological evidence and witnesses.
Justice Foster said of the discordance between the evidence of the epidemiological witnesses called by the Australian Federation of Consumer Organisations and the Tobacco Institute of Australia, ‘It was not a disagreement which the learned primary judge or this Court could reasonably resolve.’
He concluded, ‘The matter…falls for determination not on the basis of accuracy, validity, or acceptability of the scientific evidence or aspects of it, but simply upon its existence.’
The judges thus concluded that detailed excursions into the epidemiological evidence were by and large immaterial to the matter at hand: the question of whether there was deception involved in the statement that there was ‘little evidence’ and the imputations arising from this statement for the general thrust of meaning in the advertisement as a whole.
Of epidemiology, Justice Shepherd said, ‘Despite its inexactitude epidemiology is a science’ and that ‘epidemiological studies…cannot be dismissed as ‘nothing’.’
The word ‘nothing’ in the advertisement was thus critical to the determination that deception had occurred.
For the Australian Federation of Consumer Organisations to succeed in its suit, it needed to establish that the Tobacco Institute of Australia's advertisement ‘was published in trade or commerce.’
The three appeal judges considered this issue at length and, again, all affirmed Justice Morling's decision that the advertisement was rightfully to be considered as being published for the commercial gain of the tobacco industry.
Justice Foster concluded that the advertisement ‘create[d] an irresistible impression that it was promotional material designed to advance the cause of cigarette smoking and to assist in the sale of cigarettes.’
Of the relationship between the Tobacco Institute of Australia (which itself does not manufacture or retail tobacco) and the tobacco industry, which supports and directs its staff and their activities, Justice Foster concluded, ‘There can be no doubt that a corporation, formed to promote the interests of a particular industry…acts ‘in trade or commerce’ when conveying representations about that industry's product to the general public.’
The implications of this statement will doubtless resonate throughout many an industry in the years to come.
The judges handed the Tobacco Institute of Australia something of a pyrrhic victory when they said they would set aside Justice Morling's injunction on the further publication of the advertisement on the legalistic basis that the Tobacco Institute of Australia had previously indicated to the Australian Federation of Consumer Organisations that it would not republish the advertisement anyway.
The judges also said that they would set aside the orders of Justice Morling that the Tobacco Industry of Australia could never, at any time in the future, replicate the claims contained in the offending sentence.
They argued that scientific progress and understanding could not be conceived of as a static process; with the advance of research into passive smoking, different conclusions might one day become apparent.
In summary, then, the Tobacco Institute of Australia was found guilty of publishing a misleading and deceptive advertisement.
It was also handed a symbolic but fairly meaningless victory in having two orders varied.
These concerned matters that were a pure technicality (being allowed to run an advertisement that they would have had no intention of ever running again) and a virtual truism (being told that future circumstances may arise in which they should be reasonably able to readdress the issues at hand).
But perhaps this interpretation is rather too literal.
Significantly, at press conferences after the judgment both sides claimed the result as a resounding victory.
In terms of a public health perspective, the decision certainly rubbed salt into the tobacco industry's already gaping wounds.
At its core was very bad news: it remains true that the Tobacco Institute of Australia was guilty in 1986 of misleading and deceiving the Australian public about the existence of evidence which might (according to many) be reasonably said to prove that passive smoking was harmful.
Smoking control advocates will be thus justified in broadcasting that the tobacco industry is (yet again) on the public record as having been shown to be deceitful in its communications with the public.
Doubtless there will be many highly strategic opportunities where this humiliation will be fully exploited.
But the tobacco industry is unrivalled at making silk purses from sows' ears.
It still maintains with blithe equanimity its opinion that active smoking, let alone passive smoking, does not cause disease — it has only been shown to have a ‘statistical association,’ much in the same way that sexual intercourse might be denied to ‘cause’pregnancy.
This is in spite of the scientific advisory committee of its own research foundation having made a unanimous public statement that they believe smoking is a causative factor in several major diseases.
The many pages of detailed argument in this judgment about the plurality and inexactitude of scientific consensus generally, and of epidemiology in particular, will provide the Houdinis in the industry's public relations sections with a feast of prestigious quotations and one liners.
These will ably assist with the perpetuation of the ‘more research is needed’ rhetoric that has become the industry's public mantra.
The passive smoking issue holds enormous fears for the tobacco industry.
The champagne went down very well on the night the Tobacco Institute of Australia's appeal substantially failed, but we fear that the hangover from this report may last rather longer.
In the 148 pages of this judgment lies quite priceless advice to the industry about how it might become more clever in the same ambitions that gave birth to this clumsily worded advertisement.
Each judge offers advice, often explicit, on how the offending sentence could have been published without falling prey to a misleading and deceptive charge.
For example, Justice Foster said, ‘Had the author [of the advertisement]wished to indicate that nothing more than an opinion was being expressed, he could have achieved this object quite simply by introducing the very same words ‘we think’ before the ‘there is little evidence’.’
Such passages to us seem prophetic of industry tactics we are likely to see in the 1990s.
If the Tobacco Institute of Australia is required to pay the Australian Federation of Consumer  Organisations $; A1.5 million when costs are determined, it may well consider the experience to have been money well spent.
It has received meticulous counsel from one of the nation's highest courts about what it might wish to say on the subject in the future.
Equally, though, we would prefer to think that the Australian Federation of Consumer Organisations's experience will inspire other Davids of the tobacco control world to stone the lumbering Goliath of the tobacco industry with ever increasing legal and tactical accuracy.
Alternative allergy and the General Medical Council
In July 1992 Dr Keith Mumby, a clinical ecologist, appeared before the professional conduct committee of the General Medical Council on five charges to do with his practice of clinical ecology.
He was found guilty of two of the charges — touting for publicity and failing to give a patient adequate medical attention — and admonished.
The GMC failed, however, to address the issue of the nature of Mumby's treatments — clinical ecology itself.
This is based on the idea that some patients are unusually susceptible to their environment, the diagnosis and treatment are based on an unstandardised provocation-neutralisation test.
A variety of medical bodies have failed to find scientific foundation for the technique.
The GMC's policy on advertising services to patients is inconsistent, and in this case it has shown a regrettable reluctance to deal with the issue of treatments that are not scientifically validated.
In July 1992 the General Medical Council's professional conduct committee considered the case of Dr Keith Mumby, a clinical ecologist.
The GMC called me as an expert witness.
In the event my evidence — on the scientific value of clinical ecology — played little part in the proceedings because the charges brought by the GMC touched only peripherally on Dr Mumby's clinical activities.
I describe the proceedings here, however, because they raise questions about the willingness of the GMC to protect patients from forms of diagnosis and treatments which have not been sufficiently validated and about its lenient attitude to a doctor who persistently touted for business by attracting the interest of tabloid journalists.
The Mumby case
Dr Keith Mumby graduated from Manchester University in 1971.
He did his preregistration year and a year of vocational training in general practice but then stopped working as a doctor until he opened an allergy clinic in 1982.
Since then he has been featured in many newspaper articles.
Highlights include ‘Allergy plight of nice-girl Nicky —‘one sip of vodka turns me into a sex maniac’’(News of the World magazine) and ‘Women could be turned on by a chunk of cheddar’(People ).
He had been arraigned before the GMC twice before, both times for canvassing.
In 1982 he was found guilty of serious professional misconduct and undertook not to let it happen again.
In 1987 he was found not guilty over a full page article in the Sunday Express .
Dr Mumby has been the target of investigative journalism at least three times; the last of these, an article in Scotland on Sunday in 1991, resulted in this year's GMC hearing.
On 13 July Dr Mumby appeared before the GMC's professional conduct committee charged:
1
that he touted for patients using a publicity agent;
2
that he caused avoidable distress by giving injections (as tests or treatment or both) in front of other patients and members of the public;
3
that he gave the names of two patients to journalists without first seeking their permission;
4
that he treated Ian Royan without taking a proper history or examination, or first contacting his general practitioner; and
5
that he injected Royan with a substance he knew would harm him, in the presence of the press, and failed to given him adequate medical attention.
Dr Mumby was found guilty of only the first and last charges, for which he was admonished.
The evidence for charge 1 included a letter from Dr Mumby in August 1987 to his ‘publicity agent,’ freelance journalist Brian Whittle:
Dear Brian,
Herewith the letter from Mrs Massey.
I think you will agree it's got the beginnings of a nice story.
To re-emphasise, I would like this one played a little bit special if you can.
Try to get it as a ‘Dr Mumby does it again’, not just a patient story.
The effect from the Sunday Express article is just beginning to wane slightly and a boost now would be absolutely terrific and see us right through to Christmas.
Dr Mumby said that the letter had been stolen and was therefore inadmissible, and that it was written in jest.
Whittle agreed that it was a typical Mumby joke.
Dr Mumby successfully defended himself against causing distress by performing allergy tests in front of others and of giving patients' names to the press.
Several witnesses, including other patients and Dr Mumby's staff, said that patients generally welcomed company during skin testing sessions, and all three expert witnesses (myself, Professor Anne Ferguson for the GMC, and Dr Jonathan Brostoff for the defence) said that privacy was necessary only in special circumstances.
Dr Mumby, supported by his staff, said that he always asked patients' permission before giving their names to journalists.
They all made it clear that handing patients over to the press was a regular occurrence (a point that none of the committee commented on or asked questions about).
One of the patients named in charge 3, Ian Royan, said he had never authorised Dr Mumby to give his name to any journalist but was telephoned by Archie Mackay of the Sunday Mail and agreed to rendezvous with him at Dr Mumby's next clinic.
These clinics were held irregularly on Sundays in rooms hired at the Copthorn Hotel, Glasgow.
He had not objected to being photographed but was upset to see photographs of himself and a feature in the Sunday Mail of 4 October 1990 headed ‘The sheer agony of a food allergy.’
Dr Mumby said he had a duty to put the potential benefits of allergy diagnosis and treatment in public view, which was why he attracted publicity in newspapers rather than professional journals.
He had organised the Sunday Mail article to repudiate ‘an awful paper in the New England Journal of Medicine ’(see below).
Dr Mumby's techniques
In answer to charge 4 that he had treated Royan without taking a proper history or examination or consulting his general practitioner, Dr Mumby said he took the clinical history in the form of a questionnaire which patients filled out in advance but he rarely examined patients because they had usually been examined many times elsewhere and because taking a history by questionnaire was an established technique of clinical ecology.
Dr Brostoff concurred.
Professor Ferguson and I said that a routine clinical history and examination (preferably in private) were essential in helping to establish the correct diagnosis and treatment of all patients, particularly in people who might be under the mistaken impression that their symptoms were due to allergy.
Professor Ferguson also emphasised the existence of serious functional symptoms which could be reinforced by suggestion in a susceptible individual.
Dr Mumby said, ‘It would be a waste of time taking Mr Royan's blood pressure or listening to his chest.
You can see he's a very strange man…if he twitches after eating meat pies and he stops eating meat pies and stops twitching it doesn't matter if it's psychological or not.’
Dr Mumby practises the Miller technique, the standard method of clinical ecologists.
He has seen about 6000 patients over the years and all except six had suffered from allergies.
Patients were tested for allergy with a wide variety of substances, including gas and petrol fumes, milk, coffee, yeast, soya, and onion.
Most patients reacted to injections of a number of substances and he made them up custom made ‘vaccines’ of supposed antidotes.
When they got symptoms they were to place a couple of drops under the tongue.
Patients were regularly retested (at a cost of £140 upwards) and their allergies were found to shift around capriciously so their vaccines had to be changed.
In evidence I said that allergen extracts should be standardised and prepared according to good manufacturing practice and that it was absurd to inject patients with extracts of gas and petrol fumes.
These cause irritant reactions but were not allergens.
Many substances, particularly food extracts, often give false positive reactions in allergy skin testing.
Conventional allergists use skin tests to confirm the diagnosis, not to make it.
I also expressed concern about the possibility, albeit rare, of producing generalised anaphylaxis in certain sensitised patients who are tested by intradermal injections rather than the ‘skin prick’ method.
For this reason I believed that Dr Mumby should always have had full resuscitative equipment readily at hand.
In reply Dr Mumby said that he had an oxygen cylinder and mask in his kit but no electrocardiogram or defibrillator.
‘I don't carry a defibrillator because what I do isn't dangerous, like conventional allergy tests.’
Charge 5 in fact addressed the potential harm of the substances used by clinical ecologists.
It alleged that Dr Mumby had injected Royan with substances that might harm him and failed to given adequate medical attention.
He had injected Royan with various substances in the hired suite at the Copthorn Hotel, Glasgow, and videotaped the session.
The video recording showed Royan going into spasms and gradually tipping over until he gently slid off his chair.
At this stage Dr Mumby gave him drops of dilutions of the substance into his mouth until he became his normal self again.
Dr Mumby said he told Royan, ‘Pull yourself together — the act's over.’
He disputed that Royan was at risk: he had given him the correct treatment and calm reassurance — which was the essence of his treatment.
Royan, who was unemployed owing to his health problems, paid £800 to Dr Mumby altogether.
Issues arising from the case
clinical ecology
The clinical ecology movement, founded in the 1950s by the American allergist, Dr Theron Randolf, is based on the belief that certain people are unusually susceptible to the adverse effects of their environment; this results in a disease which clinical ecologists call ‘environmental illness’ but which has several names, including ‘total allergy syndrome,’‘twentieth century disease,’and ‘food and chemical sensitivities.’
Environmental chemicals and foods are said to be responsible for an unlimited variety of symptoms which occur in the absence of physical findings or abnormal laboratory results.
Although the idea that the environment is responsible for a multitude of human health problems is appealing, the basic concepts of clinical ecology are unproved.
Clinical ecologists therefore attempt to diagnose and treat a disease which conventional doctors believe does not exist.
Provocation–neutralisation testing is performed in several different ways without any standardisation.
Some practitioners, including Dr Mumby, give subcutaneous  injections in a completely unblinded fashion and record the symptoms that ensue.
Others administer substances by intradermal injections and record the size of the cutaneous weal.
Either lower or higher doses are then injected serially until the weal or the symptoms disappear.
The last of these is then regarded as the ‘neutralising dose’ and is then used for treatment (usually in the form of sublingual drops).
In the New England Journal of Medicine article which incensed Dr Mumby the validity of provocation of symptoms by intracutaneous tests to identify food sensitivities was evaluated under double blind conditions.
The protocol was accepted by proponents of provocation testing, and clinicians who used this method participated in the study.
The article concluded that the frequency of positive responses to the injected extracts appeared to be the result of suggestion and chance and hence the method was not scientifically valid.
The United States Department of Health and Human Services specifically excludes provocation-neutralisation and similar forms of food allergy testing and treatments from reimbursement under Medicare.
Reimbursement is also not allowed under British private health schemes — except (bizarrely) when it is requested by a doctor who is, or has been, an NHS consultant.
There have been many severe criticisms of the techniques of clinical ecology, all concluding that the concept of ‘environmental illness’ is unfounded and that the claims of clinical ecologists are invalid because they do not properly control their studies or define objective parameters of illness.
Indeed the Royal College of Physicians stated, ‘The public should be warned against [all]methods of diagnosis and treatment which have not been validated’.
advertising
Not surprisingly, Dr Mumby's sentence was greeted with exasperation by the quality press, particularly in the areas where Dr Mumby practises.
The New Statesman Society was concerned about the ‘relative leniency of the GMC's disciplinary action.’
And Scotland on Sunday said, ‘The GMC is unsure of its ground when dealing with practitioners of alternative forms of medicine.
It shows that unproven fringe techniques can be used on the public with little policing from the body with a remit to protect patients from rogue doctors.
The GMC may have to rethink its policy on advertising.
On the one hand, the public and the profession surely cannot accept leniency when a doctor indulges in indiscriminate showbiz type advertisement.
On the other hand, there are proved services available but no mechanism by which the public can be readily informed about them.
The unsatisfactory policy of the GMC on advertising is further illustrated by the fact that general practitioners can include conventional allergy desensitisation as part of the services they advertise but an NHS hospital with consultants trained in allergic diseases cannot.
Yet the 1986 CSM Update on desensitising vaccines arose from concern about 26 deaths from anaphylaxis since 1957, five in the previous 18 months.
Virtually all the deaths occurred in general practitioners’ surgeries.
The GMC's case
At the beginning of the hearing the committee chairman, Sir Herbert Duthie, said that it was not a trial of alternative medicine or of the provocation-neutralisation test.
In fact this put severe restrictions on the committee's deliberations, and the chairman repeatedly had to advise counsel for both the GMC and the defence that it was not their function to comment on the relative merits or otherwise of alternative forms of medicine.
Why this reluctance to tackle the issue of the worth of this particular form of treatment?
A previous High Court judgment in the United Kingdom in 1991 (Lorraine Taylor v Airport Transport and Warehouse Services Ltd) had ruled that the methods of a clinical ecologist (Dr Jean Monro) were ‘in many cases bizarre and unscientific…and her methods and treatment have no parallel or place in the NHS routines.’
That court had, in fact, subpoenaed a draft copy of the Royal College of Physicians' report on allergy.
So it would have been possible for the GMC to try to challenge the basis of clinical ecology.
Moreover, the GMC has in the past challenged unorthodox treatments.
For example, in 1989 it charged Dr James Sharp over his adoptive immunotherapy treatment with ‘advising and treating patients with AIDS, AIDS related complex and HIV infection without sufficient knowledge, training or experience to treat the conditions competently’ and ‘offering the treatment without proper clinical trials…and despite inadequate independent scientific evidence to support it.’
One can only speculate that the GMC took the easy option and avoided testing the issue of clinical ecology head on because it feared a lengthy presentation of evidence on both sides, with the risk of an inconclusive result.
What should the GMC do?
The GMC must face the issue of alternative allergy practice, particularly when a diagnosis is given of an illness which conventional doctors believe does not exist and when potentially dangerous dubious substances are injected.
Clinical ecology is one of the more controversial forms of alternative medicine.
It has a cult-like following with the potential to exploit gullible people and reinforce obsessional behaviour.
The GMC should consider censoring all forms of diagnosis and treatment which, by reasonable standards, have consistently failed to show clinical efficacy.
There should be a close dialogue between the GMC and the royal colleges to ensure that procedures which are potentially harmful have been validated by careful placebo controlled clinical trials using generally accepted procedures.
The GMC should also reconsider its views on advertising.
It needs to be much more severe with outrageous advertisements but, equally, it should not obstruct the public's access to proved specialist services.
Health of nations: lessons from Victoria, Australia
Summary
In its white paper The Health of the Nation the government has announced its intention to give more priority to preventive health care.
Two examples from Victoria, Australia, show how coordinated legislative and voluntary sector action can have a substantial impact on public behaviour.
The introduction and enforcement of strict drink-driving laws and speed limits backed up by forceful television advertisements produced a large reduction in deaths from road traffic accidents, the death rate in relation to the number of vehicles in 1991 being among the lowest in the world.
Smoking has also declined in parallel with a phased ban on advertising and use of taxes from tobacco sales to replace tobacco sponsorship of sports and arts and fund health promotion.
From 1920 to 1970 death rates in Australian middle aged men stayed roughly constant as new killers replaced old.
But since 1970 mortality in this group has fallen by 40%.
With life expectancy now 73.9 years for men and 80.0 years for women, Australia has regained the favourable longevity ranking it enjoyed early in the century.
Australia is notable not only for the size of its rise and fall in deaths from chronic disease and injury but also for the strength of its institutional revolution in public health.
This revolution has a special relevance to the current British debate on the health of the nation.
We illustrate here some distinctive features of Australia's public health revolution by reference to the control of road traffic injuries and of cigarette smoking in the state of Victoria (population 4.4 million, 70% in Melbourne).
Control of traffic injury
Deaths from traffic accidents are a function of exposure and risk per unit exposure, with the latter falling as vehicle density rises (Smeed's Law: deaths per vehicle per year=0.0003× (vehicles/population)-.6 6 ).
In the 1960s Victoria's road death rate was 30–40% above Smeed's prediction and rates per unit population were among the highest in the world.
In December 1970 Victoria led the world in making the wearing of seat belts, where fitted, compulsory.
In the same year it established a statutory authority with responsibility for road safety and traffic management, with board representation from three state agencies (police, roads, planning), local government, and four non-governmental organisations (autoclubs, College of Surgeons, automotive industries, and trade unions).
In 1973 the speed limit was reduced to 60 mph (100 kph in 1974) and compulsory blood alcohol testing was introduced for accident victims admitted to hospital.
Random breath testing was introduced in July 1976 (limit 0.5 g/l blood) and mandatory periods of licence suspension depending on blood alcohol concentration in 1978.
In December 1986 the permissible concentration of alcohol was set at zero for the first two years of driving.
In July 1989 wearing helmets was made mandatory for pedal cyclists.
The development and passage of legislation was aided throughout by the location of the Victoria state parliament in the state's one major centre of population and by an effective and well advised all party parliamentary road safety committee that drafted the legislation and minimised partisan divisions.
Death rates fell steadily through the 1970s then levelled out and began to rise again in the '80s.
An intensive new campaign was begun in December 1989, which was extremely effective.
The £2.5 million ($A5.5 million) mass media campaign had two themes —‘Don't fool yourself, speed kills’ and ‘If you drink, then drive, you're a bloody idiot.’
Five 60 second television advertisements were designed to be shocking and fully realistic.
Actual hospital emergency staff were used: the aim was to convince each viewer that ‘it could be me.’
Police surveillance by automatic cameras and mobile ‘booze buses’ was greatly intensified (rates per million population per year: 1 230 000 photographic speed checks (92 775 infringement notices), 304 000 random breath tests (18 036 infringement notices)).
Speed camera records showed about 11% of drivers exceeding the speed limit in July 1990 compared with over 20% before the campaign.
The proportion of people killed who had blood alcohol concentrations above the limit also fell.
Deaths per 10 000 vehicles fell from 3.0 to 2.1 in 1990 and 1.9 in 1991 (<50% of Smeed's prediction); the mortality is now well below that in Britain (2.3 in 1989), which has one of the lowest rates in Europe.
It took Victoria just two decades to climb virtually the full length of the international road safety league table and it did so by actively engaging many organised elements of society.
Road crashes are expensive and preventing them saves money — by one estimate, over £100 million in Victoria in 1990.
For the Transport Accident Commission, one year's savings from reduced injury claims was many times its outlay of £2.3 million for the campaign.
Reducing smoking
In 1980 rates of smoking were increasing in Australian young adult women.
The tobacco industry was purchasing powerful political constituencies by sponsorship: not only individuals but also sporting and cultural organisations were dependent on tobacco.
In November 1987 the Victorian parliament passed a Tobacco Act that tipped the balance in favour of the antismoking forces and multiplied the funds available  for public health generally.
The act banned advertising outdoors and in cinemas; banned give aways, sales in small packs, and related promotions; raised the tax on tobacco by 5%; and allocated all the proceeds to an independent statutory trust known as the Victorian Health Promotion Foundation.
The board of the foundation is chaired by a leading medical scientist and includes business, sporting, cultural, and political leaders.
It has a budget of about £12.8 million (£2.90 per state resident) per year and is required to spend this in three main areas: buying out tobacco sponsorship and initiating public health sponsorship in sports, arts, and community organisations; funding health promotion programmes; and funding medical, especially public health, research.
The content of the act and its successful passage can be accounted for only by the sustained and effective political activity of the Anti-Cancer Council of Victoria, one of the two wealthiest, and probably the best organised, health charity in Australia.
Between February and October 1987 the director of the council, Dr Nigel Gray, liaised closely with the minister and shadow minister of health.
What began with a sympathetic ministerial response to a proposed tax funded buy out of tobacco sponsorship was strengthened by support from the council's 140 000 donors and from the medical and scientific communities, and ended with the creation of the Victorian Health Promotion Foundation.
In 1990–1, the foundation was able to sponsor 128 sporting and 134 cultural organisations, fund 125 health promotion projects, and fund 74 medical, mostly public health, research and training activities.
The antismoking campaigns are run by Quit, a body established jointly by the Victoria health department, the Anti-Cancer Council, and the National Heart Foundation in 1985.
Its sponsorship programmes have been developed from commercial precedents and in 1991 included a major league Australian football team, several other football organisations, two national basketball teams, some mass participation sports, and even a drama group.
Conspicuous support for sporting and other activities has contributed to the rising public approval of the Quit campaign and of antismoking measures generally.
In early 1991 after the Australian Federal Court found the Tobacco Institute of Australia guilty of publishing misleading information about the health effects of passive smoking, Quit wrote to 175 000 organisations informing them of the decision and inviting them to participate in its workplace campaign.
By September 1991, 78% of Victorians were working in environments where smoking was restricted or banned (unpublished data, Centre for Behavioural Research in Cancer, Australia).
Between 1983 and 1989 the prevalence of tobacco smoking in Australian men fell from over 40% to around 30% — around twice the recent rate of fall in cigarette smoking in British men.
Smoking prevalence data for 1991 in Victoria are encouraging — 27.3% for men and 24% for women.
The recent reductions in Victoria have been as great among blue collar workers (who watch 38% more commercial television: M Scollo, Victorian smoking and health programme, personal communication) as among white collar workers.
Rates of smoking in adolescents have been falling in Australia (fig 1) in contrast to their relative stability in Britain.
Australian studies confirm the effectiveness of campaigns to reduce smoking with major mass media components; the Victorian Health Promotion Foundation has made it possible for Quit to afford such components.
Programmes are now being directed towards preventing relapse in a smoking population that is increasingly composed of people who have tried several times to stop: among smokers surveyed in 1990, 42% reported having tried to stop in the previous year (unpublished data, Centre for Behavioural Research in Cancer).
Guided by its recent experience Quit has set as medium term goals adult smoking prevalences of 22% in 1994 and 18% in 1997 compared with the British government's goal in The Health of the Nation of 20% in 2000.
The Victorian model has spread to other states.
Tobacco advertising and sport sponsorship are due to be banned nationally.
Federal and state health ministers have agreed on regulations requiring that, from July 1993, half the surface area of cigarette packs is to contain explicit and detailed health information, including a free of charge ‘quit line’ telephone number.
A proposal to require plain generic packaging for all cigarettes, which the Victorian Anti-Cancer Council's Centre for Behavioural Research has shown makes them less attractive to adolescents, has been deferred for a year.
Conclusion
Through creative and complex interactions between voluntary and state agencies, new processes and institutions have emerged in Australia to foster health favouring change within an active civil society.
It has not just been a question of choosing between state action and individual responsibility, but rather of finding the means to link the two effectively.
If the reality of a public health revolution in Australia is accepted, to what extent can the dramatic reductions in mortality since the 1960s be attributed to it?
There is no defensible basis for a global answer to this question.
But partial answers can be defended.
In the case of traffic injuries, the temporal proximity of putative causes and their effects strongly suggests that a large part of the fall in mortality from this cause is attributable to centrally coordinated action.
In the case of trends in tobacco smoking (and by implication of trends in the diseases to which it contributes) the sum of Australian experience supports the view that centrally coordinated action that is adequately funded and deliberately built on broad based support can speed the fall in smoking prevalence.
However, three quarters of the fall in total mortality since 1970 has come from a reduction in deaths attributed to diseases of the circulatory system (figure).
On this larger canvas uncertainties abound, and there is scope for contributions from changes in the Australian way of life that were not primarily adopted for health reasons.
Postwar migration policy, for example, brought large numbers  of Greeks and Italians to Australia and their presence has done much to encourage the widespread adoption of putatively low risk Mediterranean diets.
Victoria may yet have lessons for its British parent.
Both share the tradition of a strong voluntary sector which, in Victoria, has found expression in health charities as determined to apply existing knowledge for prevention as to support the development of the new.
But they, and many other organisations throughout society, also have the benefit of strongly supportive national policies and of state guaranteed funds on a scale that is not entirely incommensurate with the task of changing health determining habits: for a population the size of England's, the total yearly Victorian Health Promotion Foundation's budget is equivalent to around £140 million, and much of it goes to the voluntary sector.
In England £0.25 million has been allocated in 1992 to fund preliminary voluntary sector work in support of the Health of the Nation initiative.
Age standardised rates of deaths from all causes and deaths attributed to diseases of circulatory system for adults aged 45–64, Melbourne, 1921 to 1990.
Source: Australian Institute of Health
Roads in Melbourne are among the safest in the world
Medical Education
Teaching the teachers
This is the sixth in a series of articles examining the problems in medical education and their possible solutions
No proper review of an education system should ignore the role of the teachers.
But in medical education the teachers are not easy to define.
Many current debates about the future of medical education are going on among small groups of specialists, with no input from the vast majority of people who do the actual teaching.
Many of the discussions are couched in educational jargon that effectively excludes many ‘jobbing doctors’ who do so much of the teaching.
Medical teachers in Britain may be divided into three main groups: a tiny minority who are trained in educational theory and methods (who often are not medically qualified themselves), staff holding official ‘teaching’ appointments but without formal teacher training, and NHS doctors who teach (in effect, most NHS doctors).
Very few medical teachers have had any formal training in teaching methods or educational theory, but in this respect medicine is little different from most university courses in Britain.
Medicine differs from many other professions, however, in the huge amount of teaching expected from all of its practitioners.
This principle is enshrined in the Hippocratic oath (box) and emphasised in the new contracts for NHS consultants, all of which incorporate a teaching commitment.
Can anyone teach?
This tradition that teaching is part of being a doctor rather assumes that everyone can and should teach.
It is not an attitude that would carry much weight in other educational circles, but it is easy to see its roots in the traditions of apprenticeship to a trade.
The medical adage ‘See one, do one, teach one’ is perilously close to the mark, but Dr Jolyon Oxley, from the Standing Committee on Postgraduate Medical Education, thinks that such a system has some merits.
In medical education there is a potential conflict between the desire to provide a broad educational experience and the need to ensure a technical training in how to be a doctor.
Dr Oxley emphasises that the technical aspects are best taught by the people who do the actual job —‘learning at the master's knee.’
But there is growing consensus that the broader functions of a medical education, which are assuming greater importance in the undergraduate curriculum, are not so easy to learn from someone untrained in educational method.
The Committee of Vice Chancellors and Principals of the Universities of the United Kingdom has recently called for more training in educational methods for all university teachers.
A national inquiry into the problems in medical education organised by the King's Fund identified the need for ‘professional expertise in curriculum development, teaching methods, and assessment’ and for opportunities to be provided for regular training of academic staff, and Professor Ron Harden and colleagues, of the Centre for Medical Education at the University of  Dundee, have identified staff development courses as an essential prerequisite for the successful introduction of major curriculum reforms.
If doctors are to provide broad educational experiences for their students they must be trained to do so.
Facilitating adult learning and developing self direction in students are skills in their own right.
In a recent survey of consultant staff supervising preregistration house officers in Yorkshire 79% admitted that they had had no training in educational method, yet three quarters stated that they would like it.
What are the barriers?
Most doctors claim to enjoy training and want to do it well, but various obstacles to good teaching exist in our present system.
Perhaps the most obvious is pressure of time.
Few people are full time medical teachers, and service requirements, management responsibilities, audit, and research all compete with teaching for staff time.
One respondent in the Yorkshire survey summed up the difficulties: ‘One has to recognise that the pressures on consultants are increasing steadily — workload, management, teaching, financial control, reduction of juniors’ hours…
Consultants are bound to fall down on one of these.’
This conflict of interests would not be so bad if teaching was seen to have an equal claim with the others on doctors' time, but too often it is pushed into last position in the list of priorities.
This was clearly identified in the consensus statement from the King's Fund: ‘Until teaching is recognised to be an important professional activity (comparable in status to clinical service, research and management) it is unrealistic to expect those involved to devote the necessary time and effort to planning and implementing any new curriculum.’
During my researches for this series I did not meet a single person who thought that teaching excellence receives adequate recognition in the medical world.
No doctor could hope to be appointed to a job or advance his or her career, even in a so called teaching hospital, on the basis of his teaching skills alone.
Teaching experience is often ignored in applications for medical posts.
Assessing teaching quality
The problem of ensuring that teaching receives equal weighting with research and administration is not unique to medicine.
The Committee of Vice Chancellors and Principals' report suggested that part of the explanation for paying little attention to teaching skills in appointing university staff is that many people believe that it is hard to measure teaching ability.
But the report concluded that undue emphasis is placed on inquiries about research experience in the mistaken belief that it is easier to assess a candidate's research abilities.
The report did, in fact, identify ways in which teaching skills could be assessed.
Among other things it suggested that teachers should be assessed on the clarity of their teaching objectives; the quality of their notes, handouts, and visual aids; qualitative assessments of their performance in lecturing, fieldwork, etc; the volume and range of teaching they undertake; the range of assessment techniques they use; managerial responsibilities and innovative approaches that they take on; and the number of invitations they receive as guest lecturers and speakers elsewhere.
An interesting experiment was conducted recently at McMaster University, Hamilton, Ontario, to see whether teaching tasks could be quantified sufficiently to form the basis for financial reward.
On the assumption that any reward system should be public, consistent, and reflect the values of the faculty, the researchers devised a questionnaire based on paired presentations of 10 common educational tasks.
For each pair eight longstanding members of the medical school staff were asked to indicate which task represented the greatest intellectual challenge and which the greatest amount of ‘hassle.’
There was remarkable consistency among subjects in the rankings obtained, and also the suggestion that tasks like teaching interviewing skills — which are difficult to recruit staff for — received high hassle scores.
The researchers concluded that such an approach might be extended to develop ways of rewarding people fairly for the educational tasks they undertake.
Solving the problem
A pressing need in reforming medical education is to redress the imbalance between teaching, research, and administration.
Not everyone can or needs to excel at everything, and unless people are allowed to concentrate on what they are good at we may be wasting valuable resources.
The Committee of Vice Chancellors and Principals' report suggests that more flexibility should ‘allow staff to be used considerably more effectively than under the present system, where research is considered the prime and often only road to reward and promotion and hence staff expect that the balance of their tasks should be broadly the same for all.’
At present funds are allocated to universities by the Universities Funding Committee on the basis of the research grants and scientific papers generated by departments.
Some attention should also be paid to the amount and quality of teaching that goes on.
The inclusion in NHS consultants' contracts of a formal commitment to teaching is a step in the right direction in that it acknowledges that most doctors teach to a greater or lesser extent.
Having established that principle, however, we should move on and demand greater flexibility in interpreting that commitment.
Within a department it must be possible for people who have particular interests and aptitudes for teaching to take on a greater share of the load.
Nor should we expect the very few who do not want to teach to continue to do so when they might be more usefully employed in management, audit, service, or research tasks.
Status for teaching
Allowing doctors to choose whether to spend time in teaching, or research, or management will work only if all of the options are seen to be of equal importance.
Dr Colin Coles, from Southampton, emphasises the importance of staff development for those who want to pursue teaching interests.
He also thinks that we must develop a culture that demands certain standards from all teachers and accords high status to the few who choose to develop their teaching skills further.
Reward does not have to be financial — there is already considerable kudos attached to being an examiner for the major postgraduate colleges and faculties, and we should try to find ways of extending such attitudes to other teaching responsibilities.
We should develop systems to reward teaching excellence, both on a daily basis and, possibly, through schemes like the merit awards.
We must also ensure that teaching is seen to be important, and a simple way to start is to insist that all doctors must document their experience when applying for jobs and that all appointments committees should ask about it.
Dr Jolyon Oxley of the Standing Committee on Postgraduate Medical Education warns that we must  not reach a stage where teaching is done ‘only by the professional educators.’
He thinks that it is more important to convince doctors that ‘teaching’ is a broad term and covers much of what they do every day and to ensure that they receive adequate training and support to carry it out well.
Even if we encourage some doctors to specialise in medical education, most of the day to day teaching will remain the domain of jobbing doctors.
We must ensure that they receive ample opportunities to improve their skills and monitor their progress.
The Standing Committee on Postgraduate Medical Education is due to report soon to the secretary of state for health on how staff in NHS teaching hospitals can be helped to teach better.
Among the likely recommendations are the provision of proper staff development courses in teaching techniques; providing protected time and resources for teaching; and better planning, management, and evaluation of teaching methods.
St Bartholomew's Hospital Medical College, London, now insists that all new appointees should attend at least one approved teaching course in the year after taking up a post.
Although the college makes no further formal demands, staff are encouraged to take part in regular updating courses.
Ideally, all doctors should participate in regular ongoing appraisal and training to ensure that they are providing a good service to their undergraduate and postgraduate students.
The job of training future doctors should be too important to leave to chance.
Sticks and carrots
Colin Coles suggests that the ‘carrot and stick of reward and reappraisal should be introduced more widely in medical education,’ with rewards for good teachers and help and, if necessary, penalties for bad ones.
Already some medical schools have made progress in implementing such schemes.
In 1978 a committee was established at the University of Washington School of Medicine, Seattle, to develop a programme for evaluating teaching in the school.
The committee identified two important functions of such evaluation — to improve teaching and to help to make more informed decisions about staff promotion.
The committee's recommendations led to the introduction of formal rating forms on which students graded staff performance in terms of organisation, clarity, and enthusiasm.
These assessments were found to have high interrater reliability.
A system of peer review was also introduced to make qualitative judgments about teaching abilities.
Members of staff inform the peer review committee of their teaching responsibilities and of any educational research, staff development courses, or local or national initiatives on teaching that they have attended.
A protocol for peer assessment by observing teachers at work was also designed.
The scheme, which took three years to devise, is now used in decisions about staff promotion, and since its introduction the average ratings for staff members have improved.
He who pays the piper…
Such innovative schemes are not confined to the United States.
Helen Pearson, lecturer in medical education at the University of Leicester, has introduced a scheme whereby SIFT money (service increment for teaching; the additional resources provided by the NHS to help offset the extra costs of providing health care in a teaching hospital) is allocated to hospital departments in proportion to the amount of actual teaching that students receive.
Students fill in detailed diary records of the teaching each week, recording the setting, time spent in direct teaching, additional time during which students were ‘learning something’ although no formal teaching was going on, grade of the person running the teaching session, etc.
Students fill in diaries on a rota basis, with regular cross referencing to check on the accuracy of the entries.
In 1991 information was recorded on 3500 student days in the third year alone.
During an introductory lecture the students are reminded that they are entitled to their teaching, and compliance with completing the diaries is high.
The data collected allow the medical school to calculate the time actually spent on teaching at each site.
SIFT money is then allocated in proportion to the direct costs of teaching in each unit.
The scheme was introduced in April of this year with recommendations to the hospitals about allocation to individual departments.
From 1993, however, the departments will receive their money directly, after the fund has been top sliced to pay for the hospitals' infrastructure costs.
The data allow the medical school greater control over the teaching going on in the hospitals.
One unit lost over £50, 000 when the scheme was introduced, because it was found to be doing much less teaching than had been estimated.
Information is also collected about the quality of teaching received, and although this has not yet been formally used in allocating money, one department did have part of its grant withheld for several months until it introduced clear teaching objectives.
Each department takes part in a six monthly review of its teaching quality based on the diary records, and Dr Pearson thinks that eventually the school would be able to move teaching contracts to where the good teaching is.
The scheme has made it clear to managers that the teaching contracts represent a substantial part of each hospital's budget, and Dr Pearson says that most managers are now very anxious to work with the medical school to ensure a good service for the students.
Conclusion
Almost all doctors are teachers to some extent — involved in formal or informal training or supervision of students, junior staff, and other professionals.
But, perhaps because everyone does it, teaching has a traditionally low status in the medical world.
Changes in the sort of education required by students mean that a more professional attitude to teaching must be developed.
We can no longer assume that because someone can  do the job they can teach the skill.
We must train staff to teach as effectively as possible and should encourage them to see this as an important part of their job.
We must also encourage a few enthusiasts to specialise further, taking responsibility for coordinating teaching in their departments.
This must be seen as a specialist task, on a par with other administrative duties and research commitments.
Proper financial reward should go to those who undertake this important task.
Teaching excellence should be rewarded, and there should be real penalties for individuals or units if they fail to fulfil their teaching obligations.
‘I swear by Apollo the physician…that by precept, lecture, and every other mode of instruction, I will impart a knowledge of the Art to my own sons, and those of my teachers, and to disciples bound by a stipulation and oath according to the law of medicine…‘
Most NHS consultants have a teaching commitment, yet few receive any training in educational method
London after Tomlinson
Managing change: the human aspects of the NHS
This is the ninth article in our series looking a the issues highlighted by the Tomlinson report into London's health care and medical research and education.
Whatever ministers actually decide about London following the Tomlinson report, the changes are likely to be largescale and affect many staff and patients.
Therefore how well those changes are handled becomes crucial to their success.
The NHS has much to learn from other industries and organisations that have been through similar changes.
Firstly, there needs to be an overall strategy for the change, rather than individual units trying to manage their own parts of it in an ad hoc way.
Secondly, how well those made redundant are treated is an important factor in maintaining the morale of those who stay behind.
For those affected by changes the NHS needs to provide full information, imagination, time, emotional and practical support, and money.
Though decisions need to be made quickly, their implementation should take as much time as is necessary.
The changes identified by the Tomlinson report are of such a magnitude and involve so great a culture change that the planning and decision making will need to be made with a great deal of care and integration.
The great danger is that each individual hospital or other part of the NHS affected will endeavour to tackle its own immediate problems without any awareness of help from practices elsewhere.
The size of the changes demands that all parts of the NHS (at least in London) pull together to provide a coordinated response.
Parallels with British Airways
This article explains in more detail why establishing effective strategies for change is so important rather than leaving everything to ad hoc decision making.
It draws on extensive experience of managing similar change in the private sector — namely, at British Airways, whose pilots and cabin crew in some ways resemble doctors and nurses.
In particular, there are parallels between pilots and doctors.
Both groups are highly skilled, they hold positions of great responsibility for other people's safety, and they have a public image to maintain.
Both groups strongly identify with their professional bodies and tend to feel more allegiance to their profession than to their individual employer.
In many cases they also have private businesses outside their mainstream employment (many pilots run small businesses in their spare time).
At the beginning of 1991 British Airways decided it must reduce its workforce by 4500 within six months.
The reductions were at all levels, including pilots and senior managers.
A traumatic change of this kind obviously raises major issues for the policymakers and the managers who have to bring it about.
Equally, it raises major issues of a different sort for the individuals directly affected.
How can the individual prepare best to manage the personal impact of the forthcoming upheaval?
For policymakers the key point to recognise is that the way that people whom the organisation wishes to lose are treated is paramount, not just for their sakes, but also for those whom the organisation wishes to keep.
There is extensive empirical evidence to show that if people who are leaving are treated well the quality of the service or product is maintained.
This is particularly true for staff engaged in delivering a service.
Studies of turnover and productivity following changes support this.
If the actions taken are brutal not only does the performance of the remaining staff deteriorate but the level of staff turnover also increases dramatically once good times return.
As a previous personnel director of ICI once said, treating people well makes good moral sense — and even better business sense.
Need for a coherent strategy
On the policy side, the Department of Health and the NHS (Management Executive) need to create a coherent strategy for implementing the changes.
The critical questions such a strategy needs to answer include:
What policies to adopt?
For example, will there be enforced redundancy?
If so, what criteria will be used?
What support will there be for redeployment and retraining: budgets, resources, relocation?
What role will the human resources function perform?
In counselling?
In providing information?
In pulling together best practice across the whole of London?
In ensuring equality of treatment between different sites?
When similar restructuring exercises have happened in industry a core group of policymakers has met, initially to produce policy guidelines but then to take the issues identified by personnel managers on the ground and to develop policy guidelines to deal with them.
A weekly exchange on progress, problems, people needing redeployment, opportunities, policy decisions, etc is needed between the policymakers and front line managers.
In the NHS these exchanges would need to include people from inner and outer London, at the very least, as outer London hospitals should provide opportunities for redeploying consultants and other staff displaced from inner London.
What employers should provide
There are five things that employers can provide for people affected by change — full information, imagination, time, emotional and practical support, and money.
Some of these cost very little, if anything, but all have been shown to ameliorate the adverse consequences of change.
Full information
The earlier that people are told the full situation and the rationale for the proposals the better.
People can begin to adjust and to think through their own preferences.
Better information is known to aid speedier recovery for patients: the position is no different with redundancies.
Imagination
Full information right from the start also allows time for the second thing, which is imagination, meaning the development of creative solutions to the problems.
In British Airways staff and their representatives were offered the opportunity to help generate ideas, and this resulted in very imaginative ways of reducing the cost of employing people without necessarily making them redundant or reducing their income.
The ideas included people developing alternative careers while working part time for the airline.
They also included the operation of ‘stand down,’ by which the airline retained scarce skills by allowing people to work elsewhere on part pay but having the opportunity to recall them at a month's notice.
Involving affected groups of people in creative problem solving can be very effective, both in arriving at novel solutions and in gaining their commitment and understanding for the changes.
Time
Time is another critically important commodity.
People need time to think through what the changes will mean for them, time to retrain, time to deal with the process of bereavement (which this is), time to work out what skills they have which can be transferred to alternative jobs, time to seek other opportunities, time to reconcile the family to the situation.
It is often tempting to bring about change rapidly, ostensibly to avoid protracted pain.
A better strategy is to announce the changes quickly and then implement them slowly.
Emotional and practical support
Emotional and practical support is the fourth requirement.
Ensuring that there are trained people available to listen and to provide practical help, including help with stress management and job hunting, is critically important.
Resources should be switched from other areas to cover these crucially important roles.
For a period of six months in British Airways all personnel and training staff were taken away from their normal duties and assigned to the task of helping with the process of change.
The adverse effects of the changes were dramatically reduced as a result.
A study showed that the level of stress related illness among employees in a department which provided support as described was much lower than in a similar department that did not take such precautions.
One especially effective initiative was a decision of the recruitment and training staff to turn themselves into an in house outplacement centre.
They continued to provide both practical help with job hunting and emotional support until people were placed, staying with them for up to a year afterwards when this was necessary.
Money
Finally, financial support is obviously of great importance.
People should receive a very clear statement of their financial position, together with the services of a financial advisor if appropriate.
Thinking through the principles
From the very beginning policymakers must make clear the principles which are going to inform their decision making.
For example, will there be compulsory redundancies?
Over what time scale will reductions have to be made?
Will everyone who asks be given severance or early retirement or will there be a selection process depending on performance?
Will there be help with relocation?
And so on.
It is far better to think through the principles in advance and to act consistently with them than to improvise.
Management is on much stronger ground in doing so, and the results are much more likely to be fair.
Managers will need help to understand people's needs during a period of transition and also their own reactions to change.
Both ICI and British Airways trained management and personnel professionals in counselling and change management before embarking on large programmes of change.
Recognising that the NHS is much more fragmented than a large company, it would be highly desirable to bring human resource professionals and senior managers together across London to think through how to share best practice and learn from one another as the changes unfold.
The effect on individuals
What can the individuals affected by the changes do for themselves?
A major difficulty is likely to be that doctors are usually on the side of giving support rather than receiving it and will probably find it difficult to recognise their own needs.
But everyone needs support to deal with a highly demanding environment.
A medical officer of a large multinational company once described people as being like oil rigs.
Of the three legs, one is home, one is social life, and one is work.
It is possible to cope with one of these legs being shaky and under pressure but not two at the same time.
Many people intent on pursuing an exciting and fulfilling career neglect the other two legs.
Allowing home and social lives to wither means that there are no other sources of support when work fails.
Given that many of the reforms proposed will not take place immediately, it is never too late to start building up these other important aspects of life.
A useful checklist to run through includes questions like: Is there someone I can trust to talk things through with?
Is there someone who will challenge me?
Is there someone I can bounce ideas off?
Is there someone I can  laugh with?
If not, how could I begin to build up a support network?
Once the first and crucial step has been taken of recognising that everyone needs help to handle what are very distressing events, the next step is to request and take advantage of all the support available.
The stages that people go through during a transition are well charted (see figure).
Understanding that the swings of mood are perfectly natural and that time is needed to work through all the stages helps the process.
Sensitive counselling at critical periods can help greatly too.
Another key area of preparation is in the creation of ‘stability zones’— constants in one's life which it is important to maintain.
People can handle change more effectively if they keep one thing constant rather than allowing everything to change.
Now is the time to identify the constants and protect them.
Safeguarding the security blanket can be very important in coping with considerable upheaval.
An obvious subject for preparation is to remind oneself of one's assets.
It is easy to overlook the range of transferable skills and experiences that one has accumulated in the course of a career and will now stand one in good stead.
Recognising that security really only comes from within, people need to recognise and appreciate those qualities that will help them to face an uncertain future.
In particular, it is worth examining earlier occasions when change was handled effectively and then explore how it was done and what skills and methods were used.
If the policy makers are willing to learn from some of the mistakes made in industry, where hasty changes were made which led to a dramatic brain drain subsequently, the unpalatable adjustments that will need to be made in London should create less harm than will otherwise be the case.
Stages in transition
Countdown to Community Care
Reaching out —community care in Bassetlaw
This is the fourth in a series of articles looking at the forthcoming changes to community care
Bassetlaw is a mainly rural council district in Nottinghamshire, just north of Robin Hood's Sherwood Forest.
Its population of 105 000 is concentrated in two market towns, Worksop — known as the gateway to the Dukeries because the wooded hills nearby once belonged to great ducal estates — and Retford, one of the oldest chartered boroughs in the country.
Unemployment among Bassetlaw's men last year was just less than England's overall rate of 9.7%.
This could increase, however, if Retford's local coal mine, Bevercotes Colliery, closes.
Its almost immediate closure was announced and then retracted last autumn, and its 600 or so employees are now waiting to hear how long the reprieve will last.
Manton Colliery, near Worksop, is scheduled to stay open but is no longer recruiting staff to replace those who leave or retire.
In the population census for 1991 nearly one in seven of Bassetlaw's residents said that they had long term illnesses, health problems, or handicaps that limited their daily activities or work.
How many of them need but do not receive community care is not known.
From April, however, there will be closer cooperation among the various statutory and voluntary services that arrange and provide care and, in the long run, this might lead to more efficient recognition of ill or disabled people who need help with daily life.
I visited Bassetlaw last month to see how its community care services work now and how they are set to change.
Making plans for Bassetlaw
joint planning
Bassetlaw's community care services will change along with those for the whole of the county of Nottinghamshire.
Despite goodwill and a developing sense of partnership among social services, health authorities, the family health services authority (FHSA), and the voluntary sector, the planning process has not been easy.
The main reasons are broadly political.
Firstly, the county's health authorities and councils do not share the same boundaries, and those boundaries that do exist are changing.
The district health authority of Bassetlaw, for example, merged with that in Central Nottingham last year to form a much larger North Notts district, and this year the nationwide reorganisation of council boundaries will reach Nottinghamshire.
Secondly, some people I spoke to thought that local planning had been slowed by uncertainty about last year's general election and the possibility that a Labour government might have diluted or delayed the community care reforms.
Implementing the county's plans will not be easy, either, because of underfunding.
The money being transferred from the Department of Social Security to Nottinghamshire for buying residential care will fall short of the amount needed by almost a fifth.
assessment and care management
The government's guidance on assessment and care management is loose enough to allow different interpretations.
In Nottinghamshire the social services departments will use teams rather than individual care managers to assess people and arrange packages of care.
To test the new procedures, however, county hall decided to spend some of last year's specific grant for mental illness on four new care managers.
In Bassetlaw the care manager for mental health is on maternity leave and the existing social work team is having to try out the new procedures.
Joy Gibson, senior social worker for mental health, told me that about 50 people with complex needs are being helped in this way.
Each gets a written care plan and a named key worker.
When the plan is up and running and all  the identified needs for care are being met, the managing team backs away and performs only intermittent reviews.
The system is too new for any conclusions to be drawn yet, but one problem has developed already.
The social work and psychiatric teams have different criteria for deciding who needs such intensive community care.
The psychiatric team puts the number of local mentally ill people with complex needs at around 150, three times the social work team's estimate.
Although this disparity reflects the real world of budget limits, it could scupper the care programmes that the psychiatry department is meant to set up for seriously mentally ill patients and make planning for discharge more difficult.
discharge from hospital
An all too common kind of crisis for community and primary care teams is that a vulnerable patient is suddenly discharged from hospital on a Friday afternoon without any formal referral or plan for aftercare.
To avoid this kind of disaster health authorities in England and Wales will soon have to ensure that proper preparations for community care are made before inpatients who need such care are discharged.
The down side, of course, is that hasty discharges often result from shortage of beds and thus the new procedures will probably block beds.
Geriatrics beds are those most likely to be blocked while assessment teams explore alternatives to residential care.
At present two thirds of all people admitted to Nottinghamshire's nursing homes go straight from hospital, and most are elderly.
In Bassetlaw the liaison sister for elderly people, Frances Fairclough, has been seconded to look generally at community care planning and specifically at discharge procedures.
Over the past year Mrs Fairclough has piloted a scheme with one general practice on discharge planning.
All patients from that practice who have been admitted to any department of Bassetlaw Hospital (except the units of psychiatry and paediatrics, which have their own similar systems) have been assessed on admission for their likely needs on discharge.
Using a special form, nursing staff have recorded and updated these needs.
When a patient in the scheme is discharged a copy of the form, which also has room for the ward doctor's summary and details of any prescription, is faxed to the patient's general practitioner.
So far, the scheme is working well.
But other aspects of the reforms are still bothering some of Bassetlaw's general practitioners.
the gp's role
One general practitioner, who works in a large multipartner practice in Worksop, said that the community care reforms were all a bit of a mystery.
Although he knew the basic principles of assessment and care management by social services, he did not know what his own role in the process might be.
Feeling overloaded with routine and emergency clinical work (there are no deputising services in Bassetlaw) and with administration, he did not see how he and his colleagues could commit any extra time to assessment.
One of the district's few fundholders was concerned that he had not yet had enough information on how he will be able to buy community health services in April.
‘No one has told us how this will work,’ he said.
‘I presented the district health authority with a list of questions on this three months ago and I've had no reply.
For instance, what will happen when we refer patients to the new community mental health team that's being set up?
Referrals to community psychiatric nurses are chargeable to the fund but those to social workers are not.
This could cause problems with data collection.’
He was also worried that social workers on the care management team would have the final say on choosing nursing care.
If he wanted to refer a patient to a nursing home and the social work team recommended district nursing in the patient's own home, he would not only be overruled but also have to foot the bill for the nurse.
Tony Ruffell, chief executive of Nottinghamshire FHSA, told me that preliminary research in the county suggested that each general practitioner would encounter only a few such difficult decisions a year — perhaps five or six.
Regarding the extension of fundholding to community health services such as district nursing and occupational therapy, Mr Ruffell said that fundholders would have to make block contracts in the first year.
Monica Gellatly, community care coordinator for the FHSA, explained why general practitioners were feeling so much in the dark about the changes.
‘We couldn't start training GPs until we knew what was going to happen locally.
Just describing the general principles and answering specific questions with ‘we're working on it’ wouldn't have been good enough.’
In January and February the FHSA is putting the record straight by sending all general practitioners in Nottinghamshire an information pack and inviting them to a range of training sessions on community care.
These sessions will include four evening ‘roadshows’ of presentations and workshops, illustrated with real examples of how the reforms will be handled locally.
Those who attend will be able to claim the postgraduate educational allowance, and the FHSA hopes that the turn out will be good.
Thus, general practitioners in Bassetlaw should soon know what kind of role they will have in assessing people for community care.
To facilitate such assessments a joint working party of general practitioners and the FHSA, chaired by Professor Idris Williams from Nottingham University, is producing a standard protocol.
The end result of the working party's efforts and a small pilot project in four representative practices should be a single assessment form for doctors to complete.
The Department of Health has not decided yet how much general practitioners will be paid for work that exceeds their contractual obligations, such as attending care management meetings and performing certain assessments.
Delivering care
Last year Bassetlaw's district general hospital in Worksop and its related community services became  an NHS trust.
According to Dr Peter Pratt, who heads the trust's community health directorate, the unit is particularly well set up to respond to the increasing emphasis on non-hospital care in the NHS.
He explained that the district hospital has developed a strong sense of community service, partly because it has always had to find ways of reaching a scattered population.
Staff are more willing, perhaps, than those in high profile academic centres to accept the idea that there will be a move away from a hospital based service.
One impending move is the closure of the last remaining ward in Worksop's old Victoria Hospital.
It houses long stay elderly patients who will move this year to a new community unit if all goes to plan.
Residential care for elderly people is, perhaps, the hottest issue for local planners: of all the districts in the Trent health region, Bassetlaw has the fastest growing population of people over 85.
This is mainly because many of the district's relatively cheap large houses have become part III and nursing homes, offering about 300 places in the private sector and around 150 run by social services.
elderly people
Of Bassetlaw's 18000 pensioners, more than 2500 live alone.
Fewer than half of the district's households that include a pensioner have a car.
It is easy to understand, therefore, that social isolation is a particular problem for local elderly people.
Joan Bower of the voluntary organisation Age Concern told me how her local branch takes services to its clients, rather than making them travel.
Volunteers run 17 luncheon clubs and three coffee bars around Bassetlaw, many of them in small outlying villages.
Last year they served some 19000 council subsidised meals to elderly people.
Both Age Concern and the social services department have set up befriending schemes, sending volunteers or care assistants to spend time with elderly people at home and often giving carers a break.
In addition to practical help, some carers looking after elderly relatives and neighbours may need emotional support.
Lynne Moody, nursing sister in Bassetlaw's day hospital for elderly people, runs an informal support group for carers.
Because the day unit concentrates on rehabilitation and has a fairly fast turnover none of the eight people who come to talk over tea or coffee has a relative attending the day hospital at the moment.
Mrs Moody would like to advertise the group more widely and would be happy to invite former carers whose elderly charges have died or gone into residential homes.
She has found that the decision to choose residential care can cause just as much bereavement and guilt as can death.
There is no separate department of geriatric medicine in Bassetlaw.
All four physicians admit elderly patients into the district hospital's general medical beds.
The medical teams already hold multidisciplinary case conferences to plan continuing care for elderly patients with complex needs.
After April they intend to use the standard discharge procedures that have already been piloted with one general practice, as mentioned above.
Dr M M Muthiah, consultant physician, told me that existing good relations with social services and other disciplines should ensure a smooth transition to the new style of community care.
He was worried, however, that adherence to the new pre-discharge procedures might block acute medical beds unless care management teams were funded adequately and could respond quickly.
Elderly people with mental illnesses get psychiatric care from the department of psychogeriatrics at Bassetlaw Hospital.
Those with dementia may attend the day hospital for the elderly one day a week and may be supported in the community by one of two specialist psychiatric nurses.
Penny Peysner, senior social worker at Bassetlaw Hospital, told me that the district had planned to open a special day centre for elderly mentally ill people at a social services residential home, using the mental illness specific grant.
That home, however, has just been closed down as part of county hall's budget cuts.
Mrs Peysner hopes that the money will be used instead to improve day facilities for this group at other homes or to set up a mobile day unit.
People with mental difficulties
‘We have been bashing out plans for care management and for better discharge procedures, and on paper we can offer community care very well,’ said Jim Walker, acting director of Bassetlaw trust's mental health services.
‘There will be even better scope for teamwork.
I don't think we could ever have made Caring for People work when the CPNs were here in the hospital and the social workers were 10 miles away in Retford.’
From April social workers, the CPNs — community psychiatric nurses — and a psychologist should be working together in a new community mental health resource centre in the middle of Worksop.
The centre will be housed in doctors' old residences and Joy Gibson, senior social worker for mental health, will head the team.
But Jim Walker told me that, despite these good developments, he was worried that the new system for community care might be underresourced.
All the services for mental health seemed to be at full stretch already, he said.
The expected shortfall in social services funding for community care had already led to tightening of the criteria that social workers will use to decide who is eligible for care management, and patients with moderate needs for care might lose out altogether.
In addition, the hospital's psychiatric unit could not cope with bed blocking: occupancy often reaches 90% in spring and autumn, leaving inadequate space for emergency admissions.
The recommendations of the Reed report, that mentally ill offenders should be cared for by local NHS psychiatric services, could tip the balance even more, said Jim Walker.
Ranby prison, midway between Worksop and Retford, would turn to Bassetlaw Hospital for its prisoners' psychiatric care.
This could add considerably to the existing demand to rehabilitate patients from Rampton special hospital, which also lies within Bassetlaw.
Patients with severe mental illness who need long term rehabilitation are relatively well served in Bassetlaw.
Worksop has two NHS run and fully staffed hostels in the hospital grounds and a 16 bedded hostel run by the charity Turning Point.
I visited these facilities two years ago, when the new community care legislation was being set up.
Last month Trevor Goodall, team leader of the Turning Point project, told me, ‘Bits of information on the community care changes are filtering through to us from social services, and we think that we will be involved in the assessment process.
Our existing residents will continue to get social security funding for their rent and we assume  that we will still get grants from the health authority and social services for our running costs.
We hope the changes won't alter things too much.’
Concentrating the resources for community care on people with severe mental illnesses makes sense.
Other people with less florid but equally chronic mental health problems, however, could find it much harder in future to get help from the busy statutory services.
I spoke to Jean Collis, coordinator of Bassetlaw MIND (the local branch of the national association for mental health), who was worried that people with chronic depression and anxiety would have to rely increasingly on voluntary organisations for help.
The local support groups and befriending schemes that MIND was running two years ago are expanding all the time, and a new advocacy service to help people with mental health problems deal with lawyers, the courts, doctors, and other professionals is taking off.
But Mrs Collis has found raising funds for these services particularly hard in the past year.
people with learning disabilities
Schemes for befriending and advocacy are also available for Bassetlaw residents with learning disabilities.
These are run by both social services care assistants and volunteers.
The community mental handicap team (a title it retains, although its members do not describe their clients as handicapped) has more than 10 years' experience of providing such innovative care to a mainly rural and home based population.
A survey in 1989 showed that the team knew of 350 local people with severe learning disabilities, of whom 217 lived with their families and 38 lived with single carers.
Bill Barker, senior social worker, explained that the team had served children as well as adults with learning disabilities until last year.
Under the terms of the Children Act, however, responsibility for helping these children now lies with the social services child care team.
Although this transfer of responsibility makes sense in many ways, it hampers continuity of care for a group of people with long term needs.
Such continuity might also suffer under the new legislation on community care.
‘Many families are struggling on, perhaps because they don't want to consider residential care or because the right sort of care isn't available,’ said Bill Barker.
‘Helping people with learning disabilities and their families is often a very gradual process.
I'm worried that the changes to community care might, paradoxically, spoil this long term relationship.
If our priority is to target help at those with most need and to back away when those needs are met, our contacts with families could become simply box-ticking sessions, and it would be harder to get to know them.’
People with learning disabilities who need residential care in Bassetlaw can go to one of four staffed homes which were set up partly by the health authority and are run by the Mencap Homes Foundation.
From April the rent of new residents will be funded by the council's community care budget.
Karen Sands, of the foundation, said that she had no particular worries about the changes in the short term.
She wondered, however, whether the philosophy of matching services closely to needs might eventually mean that existing residents who were relatively independent might be thought unsuitable for Mencap's homes.
‘We tell our residents that we offer homes for life, and we do not expect people to move on,’ she explained.
Dr C L Narayana, the consultant who covers mental handicap services for the whole North Notts district, works two sessions a week in Bassetlaw.
He told me that he too had no particular worries about community care and that the provision of residential care was very good.
The only shortfall, he said, was of facilities for patients with very difficult and challenging behaviour.
Balderton Hospital in Newark, the old mental handicap hospital for the county, is set to close this year, and Bassetlaw's small inpatient unit cannot provide long term intensive care.
people with physical disabilities
Community social services for people with sensory and physical disabilities are provided from the Eastgate Centre in Worksop.
A team of social workers and support staff offers advice and practical help and the day centre provides social contact for about 100 people a day.
Molly Allen, the disability team manager, explained how the service is moving away from the traditional model of care.
The team's philosophy is to encourage disabled people to help themselves and each other, particularly by running parts of the centre themselves.
Block funding comes from social services, and Mrs Allen does not foresee any change after April.
Community health services for people with disabilities, such as physiotherapy and occupational therapy, are provided by Bassetlaw trust.
Like others I spoke to, Dr Peter Pratt aims to send as many services as possible from his community health services directorate in Retford Hospital to the rural areas of the district.
For example, two new mobile units are now taking chiropody and dentistry to the villages.
As a member of Nottinghamshire's interagency planning team, Dr Pratt has been involved in setting up community care for the county.
He said that he was generally optimistic about the plans and thought that Bassetlaw's combined hospital and community trust was well set up to implement them, not least because the trust has good information systems.
Conclusions
Bassetlaw particularly needs good community care because many of the people who most need help live outside the towns and lack easy access to hospitals and town halls.
The district's services seem to reflect this need well already, perhaps because Bassetlaw does not have a teaching hospital to concentrate NHS resources or a city to exhaust social services.
Most importantly, the people who will have to implement the community care reforms seem to share the same vision and, despite certain reservations, the same enthusiasm.
Manton Colliery is no longer recruiting and Bassetlaw's other pit, Bevercotes, is under threat of closure
Bassetlaw's community care services have to reach a scattered, mainly rural population
Letter from Brasilia
Obstructive lymphatic filariasis
I was told in my training at the London School of Tropical Medicine and Hygiene that Patrick Manson, one of the school's founders, was unsuccessfully sued by a Chinaman for loss of living when he worked in Amoy, China.
The plaintiff used to spread a cloth over his elephantoid scrotum and sell sweetmeats from it to the passersby.
Manson took it off, leaving the Chinaman with a sadly depleted sales pitch.
During his years in China Manson did many such operations, removing tons of oedematous tissue.
It is convenient to have a winch with a big hook hanging above the operating table for these operations.
In this way you can hook the oedematous scrotum and winch it up with the anaesthetised patient prone.
Then the vital organs — testicles, spermatic cords, urethra, and penis — can be identified more easily among the mass of lymphoedematous tissue.
Bancroftian filariasis
Bancroftian filariasis, the commonest cause of these spectacular scroti, came to Brazil with the African slaves.
The filarial worm,Wuchereria bancrofti , is of the nocturnal periodic type.
Today we know such periodicity is governed by two biological clocks, one in a physiological tide of the host and the other entrained in the primitive nervous system of the microfilaria.
The adults are viviparous, producing active microfilariae that rest in the lungs during the day only to appear in the peripheral blood at night when the culex mosquito host is active.
In 1868 Otto Wucherer found these microfilaria in the haematochylous urine of a Bahian patient in Salvador, Brazil, while searching for Schistosoma haematobium eggs.
His name marks the genus.
Curiously Bancroftian filariasis in Brazil has remained restricted to certain suburbs of coastal cities linked to the old slave traffic such as Belém, Recife, Salvador, Rio de Janeiro, and Florianópolis.
Recently 17 patients with Bancroftian filariasis were reported in Recife.
Of these, 13 women had affected breast lymphatic vessels.
Lymphangitis in filariasis is classically retrograde, spreading down from the irritating worm.
The few men in this series of patients all had epididymal disease, and early inguinal and pelvic gland obstruction is characterised by the lymph scrotum (which has a velvety feel), craggy epididymitis, and hydrocele.
Sometimes microfilariae can be recovered in the hydrocele fluid.
The dramatic advanced lymphoedemas (figure) are now rarely seen in Brazil, but documentation exists in old watercolours.
Of course there are numerous causes of lymphatic obstruction, but almost all of the patients attending my lymphoedema clinic at the Hospital for Tropical Diseases in London in the ‘sixties had Bancroftian filariasis.
Often no circulating microfilariae were present since the adults were sterile or dead, so we relied more on serology for diagnosis.
All patients who had not received diethylcarbamazine were given an adequate course.
The basis of management is to avoid further damage to the prejudiced lymphatic system with the control of foot dermatomycoses and prompt treatment of streptococcal cellulitis.
It helps if an elastic stocking can be worn and the limb rested with support.
Operation is a last resort and was not very successful in my time.
Chyluria
I also had most of my experience with chyluria in London.
The senior surgeon at the Dreadnought Seamen's Hospital had a series of incomparable radiographs of bladder and renal chyluria.
A simple cystoscopy often clarified the condition.
If renal chyluria was present one ureteric opening would be puffing white urine into the bladder.
A disrupted lymphatic system communicating with the bladder could be localised and the connection fulgarated.
Retrograde pyelography often showed the connection between the renal pelvis and the dilated abdominal lymph vessels.
Usually, however, we did nothing.
In the past such kidneys had been wrapped in cellophane, inevitably producing renal hypertension.
My knowledge of chyluria progressed while working for the senior physician of the Hospital for Tropical Diseases.
We had a curious patient, an English nursing officer working in Nigeria, who had chylous urine but no evidence of filarial infection.
After examining her the chief pondered her problem outside the door of the ward.
‘Feed her a Sudan three sandwich,’ he instructed me.
In chyluria Sudan three is avidly taken up by all body fat and turns the urine pink.
It looks like smoked salmon and tastes like nothing on earth, but I gave it her the day before his next ward round.
Her most recent urine was saved for him to inspect.
It was pristine white.
He turned to the sister immediately: ‘Close the ward, put the patient in the dayroom, gather all the staff to examine the patient's locker, bed, bathroom, everything.’
He sat in the office having a cup of tea.
Behind the lavatory in the men's bathroom a nurse found a bottle of milk.
The patient had added this to her urine, hoping that her apparent illness would stop her having to return to Africa.
She was the first patient I saw with pseudochyluria.
Severe cases of elephantiasis are now rarely seen