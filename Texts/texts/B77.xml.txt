

Graduate employment
EMPLOYMENT is a tragedy, whoever it hits.
It is especially disturbing when the victims are young people who have never worked.
When the young unemployed include graduates with valuable knowledge, it is even more depressing.
While no one has any right to walk straight into a well-paid job for life, it isn't just the out-of-work graduates that suffer.
Many students can tell of months of frustration and many dozens of letters written in search of gainful employment.
(Many of those letters go unanswered by the personnel departments of large companies who would be horrified by such discourtesy in would-be employees.)
It is not that today's graduates have especially high expectations, they just want work.
Gone are the days when organisations automatically recruited new graduates irrespective of their degree topic on the basis that three years at university show that someone has the intelligence and application needed to hold down a job.
But that does not explain why 12 per cent of 1981's science graduates could not find work.
It is difficult to judge the extent of unemployment among graduates.
The Department of Employment does not gather such figures, especially under the new scheme of determining unemployment statistics.
Universities do try to collect statistics, but students have a habit of ‘disappearing’ after they have severed their university ties.
There is also a natural reluctance to own up to being a ‘failure’, so the students who do vanish probably include a higher percentage of unemployed people than do those who respond to the universities' questions.
Even a bald figure for unemployed science graduates can hide the fact that those in employment are not using their education.
For this reason we are asking our readers to tell us about their experiences in the jobs race.
We want to hear from science graduates of recent years, especially those who have had difficulty in finding employment.
The sort of information we would like is: What sort of degree do you have?
What type of work are you looking for?
How many jobs have you applied for?
What was the response, if any?
How long have you been looking for work?
Add any other information that you think may be relevant.
Write to Employment, New Scientist, Commonwealth House, New Oxford street, London, WC1A 1NG.
We will, of course, treat all information we receive as confidential.
The aim of this small investigation, which cannot hope to be truly scientific, is to investigate the extent of the problem and to see if there are any obvious patterns.
The employment of scientists is important for a number of reasons.
There must be a continuous flow of qualified people into every organisation that depends, even to a limited extent, on science.
For too long the employment pattern in Britain and probably other countries has been distorted by stagnation.
The shortage of opportunities at higher levels within most organisations has left people stuck in jobs for too long.
That means that no one has moved up to make room for newcomers at the bottom.
We will all pay for this stagnation.
In the future organisations will need experienced people who can ascend the hierarchy.
Where will they find the middle level if there are no youngsters around with relevant educational qualifications and some understanding of the organisation and its needs?
Strategic stockpiles
NEWSPAPER ARTICLES about the consequences of a shortage of oil (or, as now, what happens when there is too much of the stuff) appear almost daily but we hear too little about another vital industrial resource.
The economies of the Western world depend on the ‘strategic metals’ such as cobalt, chromium, manganese and platinum.
We have to import almost all of our supplies of these minerals.
Every few years, people in industrial circles murmur about what would happen if supplies were cut off, for political or commercial reasons.
Yet, in Britain, at least, little surfaces to make the average person pause for thought.
The government seems to be doing its best to keep things that way.
In May 1980, it announced a study on how the country could safeguard supplies to industry.
The discussion highlighted the idea of a state stockpile of rare metals.
Industry would draw on this in hard times.
But the Department of Industry, in whose province this matter falls, is extraordinarily shy about discussing the issue.
Almost exactly a year ago, Enid Jones, an assistant secretary in the department, told a select committee of the House of Lords: ‘We have done a big exercise on [how to safeguard supplies]but ministers have not reached a decision.
One of the problems is that we have not found a way of doing it cheaply, and this has caused great anxiety.’
Yet a spokesman at the department appeared recently to contradict this statement, saying the study is not yet finished and officials have still to report to ministers.
The time the ‘study’ is taking is worrying — and some key names in British industry are becoming restive (This Week, p 357).
The problems faced by Britain's loudspeaker industry a few years ago, when political upheavals in Zaire disrupted cobalt supplies, highlight the crucial nature of the  strategic metals.
The price of cobalt soared and the industry suddenly had to pour much time and money into redesigning the magnets in loudspeakers, using less expensive ceramic materials instead of cobalt.
A shortfall in supplies of chromium and manganese, which are used to strengthen steel and which Britain imports from South Africa, would knock the bottom out of the engineering industry.
It is no good arguing, as privately, ministers may be doing, that at a time of recession these considerations are unimportant.
Now is the best time to look at how Britain should conduct its industry when the economy recovers.
THIS WEEK
Computer net will check on UK visitors
 GOVERNMENT officials are planing to install a network of computers at dozens of British ports and airports to monitor the millions of travellers who enter and leave Britain each year.
The first steps were taken last week when an experiment to monitor ‘machine-readable passports’(MRPs) was launched at Heathrow airport.
Ministers have always denied that the MRP experiment is part of a larger plan.
Last month, the home secretary, William Whitelaw, revealed that fully-automated computer terminals at Heathrow, which will read the new MRPs, could be linked to a list of suspects held on a computer.
But he insisted that the Heathrow trial ‘will be entirely self-contained at Heathrow and will not be connected to any other computer system.’
Last year Timothy Raison, then a minister of state at the Home Office, said: ‘There are no present plans to link Heathrow airport with the immigration and nationality department computer, which is now at Bootle.’
But, according to Home Office memos shown both to New Scientist and to Computing magazine, ‘the computer systems might be linked to form a distributed network encompassing the whole country’, with the centre of the network located at the Home Office ADP unit in Merseyside.
The ADP (automated data processing) unit at Bootle is the first phase of a programme known as the Immigration and
Nationality Department Electronic Computer system (INDECS).
Since August 1980 the unit's computer has  identified visitors who overstay their permitted time in Britain by matching landing and embarkation cards.
It uses information about the arrival of visitors that is sent on cards from  points of entry to the Home Office's immigration and nationality department at Croydon.
The details are entered, via terminals linked to phone lines, into the Bootle computer.
The Bootle computer notifies the Croydon office if it does not receive notice of an embarkation card by the time the visitor's time us up.
The visitor is then deported.
Phase two of INDECS will involve automating the process further, The cards will be replaced by computer terminals at ports, which will automatically register those visitors who are given leave to stay in Britain for a fixed period.
The terminals will be linked to minicomputers, which will in turn be linked to the mainframe computers — ICL 296's — in Bootle.
This second phase of INDECS will be tied in with the computerisation of the Home Office's confidential suspects index — a list of names which officers in the immigration service carry with them to check against the names on travellers' passports.
The index contains some 18 000 names.
The intention, according to Home Office memos, is to hold these names on microcomputers so that all travellers carrying machine-readable passports can be automatically checked against the list by the terminal, as it reads the passport.
When a ‘hit’ is made the immigration officers must take certain action, according to a code letter which appears next to the name in the index.
The code’ X’for instance means ‘refuse entry.’
Other orders include ‘refer to special branch when gone’ and ‘press for details of journey.’
Names are entered into the suspects index by the Home Office, MI5, Interpol, HM Customs and Excise and the Foreign Office.
The Home Office refuses to discuss how names are chosen, but political activists are known to appear alongside international criminals.
When the index is computerised it will be practicable to increase greatly the number of names on the index.
The Home Office has another intelligence-gathering computer, at the Harmondsworth headquarters of its illegal immigration intelligence unit.
It stores names, addresses and telephone numbers of people suspected of aiding illegal immigration.
Most of the names in this computer are of black people.
The Harmondsworth computer is not part of the INDECS operation.
But, like the suspects index and INDECS, it will receive partial exemption from the Data Protection Bill, now in committee stage in the House of Lords.
Lord Avebury, the Liberal peer, intends to press the government for further details about the Harmondsworth computer and the plans to link passport-reading computer terminals into a national network.
‘My fear is that people who are not suspected of committing an immigration offence may find themselves on this machine, which could have startling ramifications for them,’ he said this week.
The Home Office confirmed this week that the Bootle computer — a Prime 550-uses a software package called status.
This is a powerful tool for ‘free text retrieval’ which, according to the 1978 Lindop report on data protection, is ideally suited to the retrieval of ‘every occurrence of particular items of information from a larger mass, and for discovering the relationship of one piece of information with another.’
Free text retrieval systems required specially close monitoring, said Lindop, because of their ability to browse through a mass of material.
Europe looks for value-for-money in research
JAPANESE, American and other foreign scientists are being asked by the European Commission to sit in judgement on the effectiveness of the EEC's £250 million annual research programme.
The programme has increase six-fold in the last 10 years and employs more than 2000 scientists at four establishments as well as commissioning research outside.
A new three-year ‘action plan’ to evaluate the value that Europe gets for its money will bring in more outsiders as well as more peer group reviews and ‘hearings’on the results of important project.
* Shilly-shallying over Super-SARA, page 354
Britain isolated over sea-dumping of nuclear waste
Christopher Joyce, Washington DC
THE WORLD'S leading dumper of waste at sea, Britain, may find itself without its favourite garbage tip after the London Dumping Convention (LDC) meets next week.
The seventh LDC could prove to be a watershed in the contentious history of ocean dumping.
Two miniature island republics in the western Pacific, Nauru and Kiribati, will arrive armed with a big stick — a proposal to ban immediately the disposal of any radioactive waste in the world's oceans.
Rumour has it that Spain, off whose coast Britain dumps nuclear waste each summer, may support a ban as well.
Meanwhile, the Scandinavian countries are bearing an alternate proposal to begin a moratorium on nuclear dumping no later than 1990.
Either course would have profound effects on Britain, which dumps annually some 80 000 to 90 000 curies of low-level waste.
One curie is equal to the radioactivity of one gram of radium.
Low-level waste is primarily the product of industrial and medical use of radioactive substances.
Ocean dumping of nuclear wastes was popular among the nuclear nations from the mid-1940s until the 1960s.
But now only Britain, Belgium and Switzerland, continue.
Britain dumps 90 per cent of the total and, with a new dumping ship being fitted out this winter, plans to increase this.
Instead of a ban, Britain wants tightly controlled and carefully-monitored dumping — essentially the status-quo.
It says a ban is not scientifically justified.
Whitehall's biggest potential ally is the United States, which is sending a large delegation to fight the ban.
Although the US no longer dumps, the government wants to keep its options open.
Last November, the US Navy concluded that it is safe to dump radioactive pressure vessels from 100 old nuclear-powered submarines into the ocean.
But then congress intervened by imposing a two year moratorium on all dumping.
No part of the squabble is more controversial than its scientific underpinning.
Representing Mauru and Kiribati is Jackson Davies, Professor of psychobiology from the University of California at Santa Cruz.
Davis has earned a reputation as an outspoken opponent of any kind of nuclear waste dumping at sea.
The two island republics cast their lot with him after Japan began eyeing the Western Pacific as a potential dumping ground.
In a technical document supporting the Mauru/Kiribati ban, Davies concludes that concrete-lined 55-gallon drums dumped near San Francisco and off the coast of New York are now leaking and that radioactivity is present in edible fish.
The conclusions are not contested by the US government.
‘It's not science,’ says Alex Perge of the Department of Energy's nuclear waste office, which has been studying the possibility of dumping tonnes of slightly contaminated soil left over from the Manhattan nuclear project.
The department's radio-ecologist, Charles Osterberg, says that radioactive isotopes of strontium, caesium and iodine now leaking near US coasts are virtually lost amid the vast quantities of their stable counterparts in the ocean waters.
Radioactivity does concentrate in sediments near the drums, many of which have imploded from the pressures 4000 metres down, Osterberg acknowledged.
‘But that's the safest place they could possibly be, in my estimation’ he told New Scientist last week.
Davies says deepsea fish are attracted to the drums, then move to shallower waters and pass on radio-activity through the food chain.
The US's Environmental Protection Agency employed marine scientists during the 1970s to study two dumpsites — one near the Farallon Islands off California, and the other near the Hudson Canyon near New York State's coast.
One crucial piece of research was performed by William Schell, a nuclear chemist now at the University of Pittsburgh in Pennsylvania.
Schell pulled up nine rattail fish from the Hudson Canyon and found high levels of Americium 241, a radionuclide not normally found in such fish, in the muscle and skin of three of them.
Davis and Greenpeace, an environmental group, have seized on this evidence.
But Schell says: ‘We don't really know how food-chain transfer works…
I don't think we have enough information to make strong conclusions’.
Schell added: ‘I never imagined those three fish…would create such a controversy’.
Schell sticks by his findings, but wants more samples.
The EPA, however, has virtually stopped sampling from ocean dumpsites — much to Schell's annoyance.
Scientists at the EPA, who helped analyse samples of sediment from the Farallon Islands say the public has over-reacted to findings of radioactivity there that were 200 times background levels.
Italy wants to dump Seveso's dioxin
Brian Price
 POISONOUS dioxin waste may be dumped in the Atlantic if proposals from the Italian government are accepted by the London Dumping Convention next week.
The waste comes from Seveso, near Milan, where an accident at a pesticide plant in 1976 contaminated a wide area with dioxin (TCDD).
On 1 October the Italians proposed to the convention's scientific committee that the reactor ‘pot’, which was at the heart of the explosion, should be dumped, 700 km off the Spanish coast in the area used annually by Britain for dumping nuclear waste.
But rumour is rife that the reactor pot has already been buried.
But the rumours are denied by the plant's owner, Hoffman-LaRoche, which says that the reactor is still being dismantled inside the sealed-off plant.
More than 2 tonnes of the waste, contaminated with 300 grams of dioxin, that was scraped from the inside of the pot is still being sought by environmentalists who believe that it, too, may land up in the sea.
The waste was driven from Seveso last autumn and tracked by Greenpeace to Marseilles and then Saint Quentin, north of Paris.
There the trail has gone cold for the moment.
HMS Sheffield thought Exocet was friendly
HMS SHEFFIELD, the first and most devastating British, naval loss of the Falklands War, was hit by an Argentinian Exocet missile because the ship's computer was programmed to recognise the Exocet as friendly.
Immediately after the sinking, all computers aboard the rest of the task force in the south Atlantic were  reprogrammed to correct the error.
Contrary to some past reports, the electronic equipment aboard the HMS Sheffield did detect the approaching missile.
And the computer successfully identified it as an Exocet.
But the Royal Navy, which was geared up to fight the Soviet Union rather than a country operating Western weapons, had not reprogrammed the computer to register Exocet as being hostile.
HMS Sheffield, like most of the Royal Navy's other modern warships, carried a set of equipment code-named Abbey Hill.
Equipment of this type, known as electronic support measures, or ESM, detects the emissions from all radar in the neighbourhood.
Antennas around the top of the ship pick up the radar signals and a computer works out details such as their frequency, the type of modulation and the intervals between pulses.
It compares this information with electronic ‘library’ that is stored in the computer of all radars that the ship is likely to encounter.
As ESM equipment does not send out any signals of its own, an enemy does not know that its radar emissions have been detected.
And the ship does not give away its own position since the ESM is completely ‘passive’.
After the Falklands conflict, the Ministry of Defence admitted that ESM was an extremely important aid in warning of attacks.
The problem with HMS Sheffield was that Exocet's homing radar was not on the computer's list of enemy equipment.
Most of the Royal Navy's frigates in the south Atlantic carried their own Exocets (Britain is the biggest customer for the missile), which they might well have fired against Argentinian ships in an all-out naval war.
If these missiles had triggered ESM equipment on all the British ships, unnecessary confusion would have resulted defence chiefs believed.
But after the sinking of the Sheffield, they changed their minds.
Immediately after the sinking of HMS Sheffield, the Royal Navy changed its policy and reprogrammed all Abbey Hill computers in the task force so that they would recognise the lethal Exocet missile as foe rather than friend.
During further Exocet attacks, the ESM equipment operated correctly — and the RN lost no more warships to this missile.
Later in the conflict, the light cruiser HMS Glamorgan was hit by an Exocet launched from a trailer on dry land, but the crew steered the ship so that the missile hit the vessel's stem and Glamorgan survived.
During other attacks, Abbey Hill provided warning soon enough for ships to fire rockets full of chaff — metallic strips that produced false echoes on Exocet's radar.
Atlantic Conveyor, a converted merchantman, did not carry either Abbey Hill or chaff launchers.
The Royal Navy has now launched a competition to select a new type of ESM equipment for its planned Type 23 frigates.
MEL at Crawley and Racal at New Malden are amongst the companies competing for the order.
This new equipment will be more automated than Abbey Hill, so the frigates will be able to bring their defences into action more quickly, without waiting for human operators to analyse the danger.
Health services are lining drug companies' pockets
AN UNHOLY alliance of multinational drug firms and national health services has raised drug prices unnecessarily high in much of Europe, according to a report to be debated today (Thursday) by the European Parliament.
The report, by the parliament's economic and monetary committee, attacks trade barriers, government price fixing and the dominance of a few big firms.
It complains that prices vary widely from country to country.
Often health authorities intent on promoting their national drug companies force up prices.
West
Germany, the cradle of the world's pharmaceutical industry and home to the two largest firms, has some of Europe's highest prices.
The committee also claims that tight controls have slowed the introduction of new drugs.
The committee wants drug prices to be harmonised throughout the EEC, an end to separate registration of drugs by each country and greater use of unbranded ‘generic’ drugs.
Greenfield put out to grass
BRITAIN'S doctors seem set to turn back the tide of support for cheap unbranded drugs — against the recommendation of the Greenfield report which was published last week.
Dr John Ball, a member of the Greenfield working party and chairman of the General Medical Services Committee of the British Medical Association, told New Scientist this week that he no longer backed the plan to substitute expensive branded products with cheaper ‘generic’ versions.
His committee meets to discuss the report next Thursday.
‘We made our recommendations about 18 months ago, in the belief that present arrangements for licensing drugs ensured that only generic drugs of the highest quality reach the market,’ Ball said.
‘But  recent events have led to anxieties over the quality of some of these drugs.’
Last year a Harrogate firm was fined more than £6000 for importing cheap drugs without a product licence.
And the British firm, Beecham, found counterfeit substandard forms of antibiotics on sale in Lebanon.
Three years ago ICI successfully prevented a wholesaler in East Anglia from importing and selling a substandard version of the company's lucrative Beta-blocker, Propranolol.
The Greenfield report recommends that prescription forms should contain a box, which doctors should tick if they want to insist on the branded drug, rather than an approved substitute.
But Ball's committee seems likely to press instead for a box which doctors should tick if they want a generic drug substituted.
There is little doubt that the effect would be to drastically reduce the number of generic substitutes supplied by pharmacists.
Meanwhile New Scientist understands that ministers have not taken up the offer of the Greenfield committee to hold further meetings to consider the issues of generic drugs further.
Space pay nosedives
STAFF at the European Space Agency are heading for a clash with officials from several member-countries who want to cut their salaries.
Current pay levels are already below those offered by other space agencies.
Britain, West Germany and the Netherlands want to reduce the scientists' pay by 4½ per cent over the next three years.
The staff say there is no formal structure for negotiating pay.
Embryology faces disruption
NEW GUIDELINES from the British Medical Association on the ethics of test tube fertilisation could disrupt research into human embryology.
According to the magazine,Pulse , a provisional version of the guidelines says that ‘spare’ living embryos may only be observed outside the womb for a maximum of 14 days.
The disposal of these ‘research’ embryos should, as far as possible, be according to the donor's wishes.
The guidelines say that embryos may only be frozen and stored if they are to be used for in vitro fertilisation later on.
The report also rules that genetic manipulation of sperm, embryos or their parts is unethical, and that surrogate motherhood is not acceptable, The BMA this week refused to comment on the leaks.
Branching out
FRANCE'S atomic energy agency is being roped in to boost non-nuclear technology.
The Commissariat à L'Energie Atomique is to work with the new French Agency for Energy Management to develop new energy techniques.
There are also plans for the commissariat to help out the large but troubled medical electronics firm Compangnie Générale de Radiologie.
Political shilly-shallying wrecks nuclear safety research
ANGER among scientists at the way Europe's politicians have mishandled the £200 million Super-SARA nuclear safety project reached new heights this week.
Sir John Adams, a former head of the CERN high-energy physics project and now scientific adviser to the European Commission, described the prevarications and indecision as ‘a disaster.’
And a team of ‘three wise men’ who reported to research ministers this week attacked ‘repeated delays’, ‘changes of direction’and ‘serious underestimates’in budgeting which have dogged the project.
Since its inception Super-SARA has slipped from being a pioneer project into the safety of nuclear reactor cores after a severe accident to an also-ran.
The report from the three wise men concludes: ‘The significance of Super-SARA, from a Community point of view, has already been severely eroded during the years that the project has been under discussion and it is expected that its significance will be yet further undermined before the completion of the project.’
The three men are Jean Teillac, head of France's atomic energy centre, Adolf Berkerhofer, head of the West German reactor safety institute and Niels Holm, the former head of the Riso research centre.
A major cause of the delays was the decision to widen the project from an investigation of the effect of large breaks in the pressurised water-cooling system around the reactor core to look at wider problems of severe damage to the fuel.
The report stops short of recommending that the project be abandoned.
But it told research ministers (who were still meeting as New Scientist went to press on Tuesday) that ‘it is essential to take an immediate final decision on the future of the programme.’
It said that the ‘benefit/cost ratio of Super-SARA is low and that, at the present time, the risk cannot be discounted of substantial cost overruns.’
The British government, which wants the project stopped, will take the judgement of the three wise men as a vindication of its position.
But scientists in the commission argue that Britain's opposition since the start has been a factor in the delays.
Britain favours buying information from other investigations of reactor safety, notably the United States  programme , run by the Nuclear Regulatory Commission.
The final nail in the coffin for super-SARA probably came last year when ministers failed to act on the advice of an expert panel headed by Sir John Adams.
Adams' report, one of a long line of studies, expert groups, advisory committees and internal and external task forces that have looked at Super-SARA, declared that the project was still viable if it got an immediate go-ahead.
But Sir John is now furious at the bungling and shilly-shallying of the past year.
As chairman of the Commission's Joint Research Centre's board of governors he has told the commissioner for science, Viscount Davignon, that European decision-making on science ought to be reformed to stop a repetition.
He pointed to delays, similar to those experienced by Super-SARA, that afflicted a decision of where to site the European Fusion Experiment, JET, which is now under way in Culham Oxfordshire.
The best-made tests on mice and men
CHEAP AND quick tests on cell cultures and bacteria can often provide enough information on the safety of chemicals for government regulators to reach decisions on their potential for doing damage to human genes.
The tests can often be more effective than more expensive and time-consuming tests on mice and other animals.
So says the National Academy of Sciences in a report to the Environmental Protection Agency, published this week.
The NAS's report is the latest attempt to steer a course  through the minefield of potential hazards from the hundreds of new chemicals that the public is exposed to each year.
It comes at a time when the Reagan administration is rolling back the controls established by successive governments in the 1970s.
The scientists warn that the lack of data on humans, the wide variety of potential genetic effects, coupled with the sheer number of genes involved (10 000 for each human sex cell) make it impracticable to try and assess the impact of chemical mutagens beyond the most important mutations in the first six generations.
The work of the NAS committee is part of the EPA's on-going GENE-TOX programme, which is assessing ways of interpreting the vast body of data on chemical mutagenesis.
The committee recommends a two-tier system of tests for identifying mutagens.
The first tier uses bacteria and two types of mammalian cell culture to detect mutations in genes and breaks in chromosomes.
If these tests are all negative, the chemical is presumed not to be  mutagenic .
If two of the tests are positive, the substance is presumed to be a mammalian mutagen.
If only one is positive the chemical is tested on the sex chromosomes of fruit flies.
If this shows a lethal mutation it is classified as a presumed mammalian mutagen.
If a large number of people are likely to come into contact with the chemical, the committee recommends testing on mice and other small mammals.
Throughout the report the committee acknowledges the need to balance the quick in vitro tests with the more expensive and time-consuming tests on animals.
The short-term tests are quite sensitive — they can detect significant changes with very small concentrations to chemicals.
But they cannot mimic the complex metabolism of a living mammal.
Conversely, the tests with animals are much less sensitive.
And there is no guarantee that either the metabolic pathways or the ability to repair genetic damage is comparable in mouse and man.
The committee says it is ‘unwilling to assume that negative mouse data necessarily outweigh the consensus of a variety of short-term tests.’
Another problem with the mouse-tests is that very high doses of a chemical must be administered to predict the effects of low-dose exposure on larger numbers of human beings.
According to the NAS report, it is very hard to work out the level at which a chemical begins to do damage.
The report says that, to be on the safe side, it is better to assume that there is no ‘no effect’ level.
And it backs increased monitoring of genetic damage in groups of humans, such as workers in chemical factories.
Nancy Heneson, Washington DC
British TV sets to get Japanese labels
A £12 MILLION gamble by Thorn EMI has paid off.
The company has landed a contract with JVC of Japan to make colour TV sets in Britain for JVC.
This is the first time that a Japanese firm has entrusted the manufacture of high technology consumer electronics equipment to a British firm.
In the last five years the UK colour TV industry has all but disappeared as firms from the Far East have taken over.
Matsushita and Sony built new factories in
Wales, Toshiba took over the Rank factory in Plymouth, Tatung of Taiwan took over the Decca factory in Bridgenorth, Mitsubishi took over the Tandberg factory in Scotland and Sanyo has bought the Philips factory in Lowestoft.
But Thorn EMI invested £12 million in its factories in Enfield and Gosport, to mass-produce a daring new TV design.
The TX range of Ferguson colour TV sets crams all the major components on a single, large printed circuit board.
Why a chemical firm sprayed Egyptian children with pesticide
Helen Howard
CIBA-GEIGY, the giant chemical company is defending its decision to spray six teenage children working in an Egyptian cotton field with a pesticide as part of a ‘field trial’.
The spraying of the pesticide, Galecron, took place in 1976, but only came to light during a recent Swiss TV programme.
The Swiss-based firm, Ciba-Geigy, says that the spraying of unsuspecting individuals is ‘rare’ but still happens.
It is only done after tests on animals show that ‘the product will be safe under normal conditions,’ a Ciba spokesman, Anita Friedland, told New Scientist .
In countries like Egypt, instructions to workers to stay out of fields after spraying and to wear protective clothing are widely ignored, she said.
Often ‘kids walk into fields by mistake during spraying.’
The tests are designed to ‘double-check’ that no harm would come to them.
She agreed, though, that any chronic long-term effects of exposure to Galecron would not be picked up.
Company publicity in Europe says that children must be kept away from Galecron.
Ciba-Geigy, which sold £7 million worth of Galecron spray last year, says it works with government officials to see that safety rules are obeyed.
But Hans Geissbehler from its agro-division says: ‘At a certain point the responsibility of the company ends.’
Galecron (the brand name for the formulation, chlordimeform) was widely used as a pesticide before it was taken off the market briefly in 1976 after it was found to increase tumours in mice.
Later it was reintroduced — but only to spray on cotton crops, where it was especially valuable because pests are resistant to DDT.
Ciba denies that Galecron causes cancer in humans but admits to other ill-effects, notably bloody urine.
Ciba has spent £3 million upgrading safeguards at its factory to keep its Swiss employees from coming into contact with the chemical.
A pressure group, the Berne Declaration, has shown New Scientist confidential company reports showing that levels of the chemical in field workers from Latin America and Egypt regularly exceed the maximum permitted for the company's own employees.
The fieldworkers report dizziness, headaches and diarrhoea, it says.
Last year the International Agency for Research on Cancer reported that Galecron's toxicity in humans is still undertested.
A batch of reports on the safety of Galecron, that were submitted by Ciba-Geigy to the World Health Organisation in 1978 have never been published.
Nuclear giants right over reprocessing contract
DOUBTS about how Britain will deal with waste from its nuclear power stations at the end of the century are fanning a row between the Central Electricity Generating Board and British Nuclear Fuels, the government-owned waste-disposal firm.
Traditionally the two organisations have presented a unified face to the world, but the mask slipped a little last week at the Snape Maltings, where the Sizewell inquiry ends five weeks in session this week.
At issue is an emerging crisis over the ‘back end’ of the nuclear fuel cycle.
By the time BNFL's latest, but delayed, plant for reprocessing spent fuel — the THORP plant — comes on stream in 1990, around 1300 tonnes of fuel from Advanced Gas cooled reactors (AGR's) will be stored in ponds at individual power stations.
AGR fuel is clad in stainless steel, which corrodes and so cannot be kept for long periods under water.
If the spent fuel cannot be reprocessed, alternative dry storage is needed.
Yet as the latest generation of AGR's comes into operation BNFL has no firm plans for a successor to THORP.
With a 10 year operational life, the new reprocessing plant is only intended to handle 6000 tonnes of spent fuel — two thirds of which may come from overseas.
To date the CEGB has not signed any contract for using THORP because it believes it is being offered worse terms than the BNFL's overseas customers.
A spokesman for BNFL refused to comment on its pricing policy but admitted ‘there is naturally some hard commercial bargaining going on’.
Against this background, the board's proposals for a massive central store to house AGR spent fuel (see last issue, p 289) becomes a crucial bargaining counter over BNFL reprocessing prices.
The store will be built in stages and could eventually have enough room in its 30 vaults to store 6000 tonnes of spent fuel for up to 100 years.
Dr John Wright, the director of the CEGB's technology planning and research division, stressed last week that this would give the board considerable ‘flexibility’ over future reprocessing options ‘in the event that BNFL's costs seem to be escalating.’
Wright said the board might go overseas for reprocessing, if necessary.
The store is being designed to receive fuel from 14 AGR reactors.
No site has been picked.
But there is sufficient space at the Sellafield complex in Cumbria, home of the BNFL's existing re-processing facilities, to accommodate the concrete blockhouse which could grow up to 343 m by 55 m.
Wright agreed last week that there would be advantages in locating the store close to reprocessing plant.
Cross-section of CEGB's waste-fuel store:After delivery in flasks to the store (top) the irradiated fuel would be dried and then transferred to special containers made of tow-carbon steel.
As well as a temporary mechanical feat, these containers would be seam-welded once the dried fuel has been received .
Corrosion-control of the containers and the vaults wilt be achieved by recirculating a portion of the warm outgoing air back into the inlet ducts.
The cell inlet ducts are designed so that they can be opened up or closed off to match the cell heat .
The cells will initially be totally closed: as containers are added and the temperature rises, airflow will be increased.
The containers will be ‘fed’ with dried fuel using technology developed by the board and the National Nuclear Corporation to load AGR's .
Florida high-lights
HIGH TECHNOLOGY has taken over at the Port Everglades power station, run by the Florida Light and Power Company.
The station has been converted to burn confiscated  marijuana which has been piling up in the warehouses of the local police forces.
Last year Port Everglades burnt more than 800 tonnes of marijuana.
One tonne of marijuana has a thermal value of 2.7 barrels of oil.
The company is now planning to convert two more stations.
Any takers for a satellite to spy for peace?
POLITICAL prevarication is blocking moves to set up an international agency to monitor military activity throughout the world using a network of spy satellites.
As the US and the Soviet Union discuss disarmament in Geneva the two super-powers continue to oppose plans for an international agency that would give other nations a look-in on their military manoeuvres.
The agency could be in business for less money than NATO spends in one hour, say its backers.
By providing reliable information on military activity, satellite surveillance could cut out the uncertainty which fuels arms spending.
And it could monitor the implementation of disarmament treaties.
In December the United Nations urged governments to get on with setting up a satellite system.
Last month members of the national parliaments of the 21 nations belonging to the Council of Europe called on ministers to look again at setting up a international agency.
It is now four years since the UN first backed the idea.
At the moment only the US and the soviet Union operate networks of military surveillance satellites.
They are not anxious for others to get in on the act.
However, China, France, Japan, India and the European Space Agency will all soon be able to offer satellite surveillance services as an adjunct to their other activities in space.
France first suggested the idea of an international agency in 1978.
And Hubert Bortzmeyer, the French space agency's military adviser, chaired a UN experts group that reported in 1981.
A year ago France apparently shelved a plan for a military observation satellite of its own.
But it will soon be considered again in defence budget talks, a French government official told New Scientist .
Satellite information now provided by the two big powers is often disputed.
In 1976 the USSR claimed that its spy satellites had revealed that a nuclear explosion took place in the Kalahari desert in southern Africa.
But the US said its satellites had ruled out the claim.
There are no independent arbiters.
An international agency could monitor compliance with international arms regulations, such as those banning the military use of chemicals and bacteria.
It could keep watch on military activity in the Antarctic on nuclear testing in defiance of the partial test-ban treaty and on the  stockpiling of toxins.
Additional ‘close-look’ equipment could also close in on international crises and warn of  military and guerilla movements.
It could spot border violations and blow the whistle on breaches of cease-fire agreements.
It would have its blind-spots however.
It would not be able to spot nuclear submarines, such as Polaris, for example.
Both superpowers are opposed to opening up their satellite data to other nations.
The US argues that wider access to satellite spies could be counter-productive.
The uncertainty about whether they are being observed discourages military activity in some nations, says Washington.
A number of nations now have the technology to spot, from space, objects as small as 2 metres across.
The US and USSR may be down to 20 or 30 centimetres.
The USSR apparently has a lead in radar equipment able to see through clouds.
To get monitoring underway quickly, Bortzmeyer's report for the UN suggests that existing satellites and ground receiving stations could be used.
All that is needed in addition is a centre for image-processing and interpretation, costing about million a year.
The next phase would give the agency its own ground receiving-stations.
Ten stations around the world would cost about $60 million to build and $20 million per year to run.
Finally it could get its own satellites.
Three satellites, with optical, infra-red and radar facilities, would cost around $200 million.
A ‘close-look’ satellite would cost as much again, The whole bill, says Bortzmeyer, amounts to just one per cent of the world's current spending on its war machines.
Is this an offer the world cannot afford to refuse?
Jeux sans frontiers — live from space
GOVERNMENT officials in France are discussing a plan to flood western Europe with French-language programmes, drawn from other European nations and Canada, The material would be beamed to roof-top antennae via France's national TV satellite, which is due to enter orbit in 1985.
The officials have started talks about the scheme with other French-speaking countries including Belgium and Switzerland and the provincial administration in Quebec.
The international compendium of French material would form one of the four channels of TV that France plans for its satellite.
It looks as though programmes from France's three current TV channels (all of which are run by TDF, the public broadcasting administration) will form a second satellite channel.
The craft would also relay two new channels, one run by a commercial organisation and the other a subscription service that TDF would run.
One further possibility is that France will lease one of the channels to Compagnie Luxembourgeoise de Telediffusion, the company that produces TV programmes in Luxembourg, CTL wants to operate its own TV satellite but is having trouble raising the money.
And the company runs the risk of offending the French government (which owns two of its shareholders) by beaming into France programmes that the country's rulers don't like.
Eurosatellite, an industrial consortium based in Munich, is building the French satellite, plus two others — one for West Germany and one that will act as a ‘spare’ in orbit for the first two.
Germany is having even more trouble deciding what to do with its satellite than France.
At present, it looks as if the craft (which will be launched in 1985) will carry only test signals to start with.
The present Christian Democrat government favours letting private enterprise run one or more of the three channels.
Meanwhile, in Canada, people are this month receiving their first taste of subscription TV.
Two companies are offering ‘pay TV’ over the whole of Canada with a further four operating a similar service in Ontario, Alberta, Quebec, Alberta and in the Atlantic provinces.
The programmes are beamed from Anik C, a  telecommunications satellite that went into orbit at the end of last year.
Britain may stock up on strategic metals
THE BRITISH government may be about to go on a spending spree — buying up stocks of rare metals for use by industry if stocks run short.
According to reports in the metal industry, ministers may soon drop their opposition to building a stockpile of imported metals such as chromium, cobalt and manganese that are vital to the British economy.
Three years ago a study by officials at the Department of Industry apparently backed the idea.
But ministers were put off by the cost.
Now underspending of £2000 million on this year's planned public expenditure may persuade ministers to dive into the metals market.
Many of the metals come from countries which are either politically unstable or have a near-monopoly.
Britain relies for manganese, chromium and cobalt on countries in southern Africa, where the chances of unrest over the next decade are high.
The UK obtains nearly all its niobium from one mine in Brazil.
And a strike in nickel mines in Canada a few years ago affected Britain seriously because they were by far the country's biggest supplier.
The recession has kept stocks of the key materials high.
But any economic upturn, could face British industry with a ‘panic’ about supplies.
A study in West Germany in 1978 found that a 30 per cent reduction in chromium imports over one year could produce a fall of 25 per cent in gross domestic product.
West Germany is now considering stockpiling key metals.
Among other western nations, France and the US already keep stockpiles.
The US's supplies are supposed to be for use only in national catastrophes such as war.
There was even a stock of down for emergency bedding until recently.
Some of Britain's biggest firms have joined the lobbying for a stockpile.
Ken Revell, chief technologist at BL Technology, says he is concerned at the time the government study has taken.
David Alexander, head of laboratories at Rolls-Royce's aero engine division, thinks that industry should not be asked to keep stockpiles itself.
‘At a time of recession it would be a hell of a burden,’ he says.
But the cost of keeping even small stocks of the rare metals is worrying ministers.
Purchasing the volume of nickel, cobalt and molybdenum that Britain consumes in just six months would drain some £150 million from public coffers.
Deciding when to release it — and at what price — would lead to more headaches.
But the pressure from industry is growing.
Meanwhile a leading advocate of stockpiling told New Scientist that if the government decides to go ahead, it should keep the news to itself.
Professor Jack Nutting of Leeds University said: ‘If you announce that a stockpile is being set up, this is the death of the operation.
It destroys the point of the exercise by driving up prices and disrupting the metals market.’
Cash drain threatens preservation of pastures
Catherine Caufield
THE WELL-PUBLISHED sacking of Sir Ralph Verney, chairman of the Nature Conservancy Council last month may turn out to be the only the second worst blow to the council this year.
New guidelines just issued by the government mean that the NCC and national park authorities will soon have to pay landowners huge amounts of compensation if they want to preserve scientifically valuable sites from intensive farming.
John Bowers, an agricultural economist at Leeds University, estimates that they will have to pay double the true ‘conservation value’ to protect sites — the rest goes on compensating for lost grants and agricultural subsidies of various kinds.
The guidelines, which have been issued by the Department of the Environment, govern compensation to farmers in national parks and sites of special scientific interest (SSSI).
Under the Wildlife and Countryside Act 1981 the NCC must offer a management agreement to any farmer on an SSSI whose application for an agricultural grant it turns down on conservation grounds.
In the case of farmers in national parks the park authority must offer a management agreement.
The new guidelines are bound to cause controversy because they effectively transfer the cost of agricultural support from the Ministry of Agriculture, Fisheries and Food to the NCC and the national parks' authorities, whose budgets are already stretched to breaking point.
The guidelines require a farmer to be compensated for the loss of ‘anticipated future profits’ as a result of his agreeing not to invest in certain agricultural improvements.
Those future profits include grants that he might have received from the government for installing drains (these can cover up to 80 per cent of the cost of the scheme) and the value of anticipated production, which may be doubled by subsidies under the EEC's Common Agricultural Policy.
It all goes on the conservationists' bill.
‘The guidelines make conservation look a damn sight more expensive than it is,’ Bowers, told New Scientist .
‘Conservation is being asked to take on the burden of social policies for rural Britain.’
The guidelines may turn out to be unworkable.
The Act requires the NCC or local parks authority to make a firm offer of compensation within three months of a grant application being rejected.
If no firm offer has been made within three months the farmer is free to go ahead with his original plans.
The council has only ten land agents and they must formulate management agreements for any of the 3800 SSSIs in Britain.
This makes it highly unlikely that the council will be able to meet the three-month deadline on any site.
Another worry is that the existence of guaranteed compensation will encourage some farmers to apply for grants for operations that they have no real intention of carrying out, simply in order to become eligible for compensation.
Already more than 100 management agreements are under discussion and the number is expected to increase dramatically now that the guidelines are in force.
How conservation will bankrupt the conservationists
TAKES 25 hectares of pasture that a farmer wants to drain and plough for winter wheat.
Net income on the pasture is £2450 per year.
But, under winter wheat, the income would be £9600.
The potential extra profit for the farmer is an impressive £7150.
Putting in drains costs £16250.
Grants reduce that to £10150.
If this were paid for over 20 years at 10 per cent interest, the annual cost would be £1200.
The extra income from winter wheat, less the annual cost of putting in the drains comes to £5950 — this is what the Nature Conservancy Council would have to pay the farmer as compensation for preserving his pasture.
But much of that extra income arises from subsidies given to the farmer in artificially high prices set by the EEC.
This amounts to 45 per cent of the value of the wheat.
Bowers calculates that, of the £5950 that the NCC pays, £500 goes in compensating for grants not received and £3150 in consumer subsidies that the farmer missed out on.
The remainder, the ‘true cost of conservation’ is just £2300.
French flock to computer centre
The Centre Mondial is a walk-in centre where ordinary people can try their hand at computers.
It also carries out research into Third World needs for microcomputers.
Both activities are inspired by a language called LOGO and a man named Papert
Christopher Roper
THERE IS a place in the leafy Avenue Matignon, just off the Champs-Elysées, where children and grown-ups can learn to use computers at their ease.
The walk-in centre is the result of two years' struggle by an international group of scientists to realise an ideal.
Their dream was nothing less than a revolutionary project to bring computers and ordinary people together.
Their belief is that we stand at the beginning of an age in which the microcomputer will truly become part of human culture.
An age in which people, who talk in one way, and machines, which talk in another, can begin a fruitful dialogue.
The founders' concern was to reverse the popular view of computers as a threat rather than a benefit to the peoples of the world.
Their idealism has been battered and a little compromised along the way but it was rewarded when the Centre Mondial Informatique et Ressources Humaines opened in Paris.
A good deal of credit for the organisation must go to Jean-Jacques Servan-Schreiber, the French politician and publicist, who established the centre with extraordinary speed.
Its conception was in early 1981; operational status was reached in March 1982.
A number of countries, including Kuwait, Senegal, India, Saudi Arabia and the Philippines, have expressed interest in collaborating with the centre's work.
But it must also be said that Servan-Schreiber's unwillingness to share the responsibility for management with the centre's scientists contributed to their subsequent departures.
The man who inspired many of the staff to come in the first place was Seymour Papert.
This South African, who held chairs of mathematics and education at the Massachusetts Institute of Technology (MIT), was the centre's first scientific director.
He is a folk hero in microcomputing circles for his development of LOGO (a high-level computer language popular with teachers) and his book Mindstorm .
The book, inspired by the Swiss educational theorist Jean Piaget, describes how contact with computers can help children develop a sense ‘of the deepest ideas from science, from mathematics, and from the art of intellectual model building’.
Papert has been described by Marvin Minsky, director of the artificial intelligence laboratory at MIT, as the ‘greatest of all living educationalists’.
On the ground floor of the plush Avenue Matignon headquarters, children sit absorbed in front of banks of Apple II computers.
Some are engaged in their own programming projects, or explore Turtle Graphics (the best-known feature of LOGO).
Others simply play variants of Space Invaders, Mission Control or Panic.
Friendly staff guide casual visitors to their first encounter with LOGO.
This can be disconcerting if your french is poor and all you want is an interview with Seymour Papert.
The free-for-all on the ground floor is a shop window of the centre's intentions and an affirmation of its belief that computing should be accessible to everyone.
The day I was there, all the children were boys, but this apparently has more to do with French culture than computer culture.
In practice, if not in spirit, there is a complete divorce between the ground floor, full of people who have walked in off the street, and the upper floors, where research and development on both hardware and software for the Third World take place.
When I visited the centre, last September, the clash of French and American academic cultures was disconcerting at first.
The atmosphere was casually chaotic, far more akin to an American university than to a French laboratory, but the secretaries were unmistakably French.
Everywhere, cursors blinked and winked from monitor screens.
Fittingly their messages were variously in English, French and Wolof (a West African language).
There are a number of projects in their infancy.
One group is developing hardware for a personal computer, sufficiently robust and inexpensive to be useful in the Third World.
The same group is also looking at interfaces to video discs, they hope to provide, perhaps, a medical dictionary on a screen.
The second major activity is the testing of experimental devices and programs in the Third World.
In addition is a project to explore applications of  personal computers in France, with emphasis on the needs of children, unemployed people and the elderly.
The interdependence of these activities at the centre is clear.
Computers which operate reliably in classrooms and offices in Boston, London or Paris, may quickly fail in a dusty village in Senegal.
It is conventional wisdom that software development lags several years behind the hardware.
At the Centre Mondial, it looks to the outside observer as if the problem is reversed.
The staff hoped that a French micro, the Thompson 07, could be modified for use in their first major pilot project near Marseilles.
But production of the modified machine could not start in time.
The centre's directors recognise that the price of a microcomputer still has to fall a long way before the machines can play an important role in Third World education.
But developments in Britain and the United States over the past two years suggest that micros need ultimately to cost little more than a tape recorder or a good transistor radio.
Dr Harry Goldberger, another MIT veteran who directs the centre's medical group, is interested in the British microcomputer ‘Husky’ which is used by meter readers and the army.
Its rugged construction and large memory may make it suitable for experiment; but at £3400 it is far too expensive for widespread use in the Third World.
The question of hardware touches a delicate problem.
Some critics see the centre simply as a marketing arm of the French electronics industry.
Such a charge was levelled in the US Congress last May when Servan-Schreiber and a delegation from the centre testified to the House Committee on Science and Technology.
The allegation was foreign to Papert and his colleagues, but it is true that Servan-Schreiber would be politically safer and the centre financially more secure, if French industry could contribute substantially to the hardware required for pilot projects.
The conflict between the scientist's idealism and the political pressures on Servan-Schreiber played a major part in the events leading to the departure of Papert last October.
Servan-Schreiber was non-executive chairman of the board.
In practice, he intervened in every aspect of administration.
Last autumn, without any consultation with the executive director, Professor Nicholas Negroponte, or Papert, control of the centre passed from the Ministry of Research to the Ministry of Communications.
The shift signified a fundamental change in the priorities of the centre and closer links with the French electronics industry.
The statutes of the institute were altered at the same time to give Servan-Schreiber executive control.
Papert did not resign.
He simply refused to recognise the new administration.
But effectively, both he and Negroponte had been shunted aside.
Papert went at once.
Negroponte, who is on two year's leave of absence from MIT decided to stay on to the end of the present academic year.
It seems likely that the team they gathered around them will now disperse.
Papert says that the idea for the centre was absolutely correct.
He blames himself for being naive about how such centres come into being, and about how they can be run.
He feels that he should have heeded those who said that political relations between state and industry in France, and between France and the Third World, precluded the autonomous international centre he had envisaged.
In fact, several of the warnings were from colleagues at the centre who had withdrawn their association from the centre early last year.
The future is not entirely clear.
Papert's ideas, as fundamental to success as those of Servan-Schreiber, transcend problems of hardware or software.
They are rooted in Papert's definition of himself as an ‘educational utopian’.
His model of what computer learning should be like is taken from the ‘Samba schools’ in Rio de Janeiro, where experts and stars gather a coterie of followers and students to prepare for the carnival.
He is sure that a computational ‘Samba school’, or something like it, will catch on somewhere.
Probably in California or New England in a middle income community which is already rich in high technology.
But Papert wants something more, as he wrote in Mindstorm : ‘I want to know what kind of computer culture can grow in communities where there is not already rich technophilic soil.
I want to know and I want to help make it happen.’
It is hardly  surprising that he should have jumped at the chance of establishing his ‘Samba school’ in Paris.
He seemed most excited by the project the centre has already launched in Senegal, where they have implemented LOGO in Wolof, the country's language.
Work done by the Senegalese group has convinced Papert that they are on the right track.
LOGO and the languages which follow could allow people of the Third World to recover control of their cultural and educational development for the first time since elite education began to be Europeanised last century.
Papert, as he reconsiders his future, refuses to regret the experience.
The centre had a free rein during the summer, when French bureaucrats were in aestivation, and he believes the stimulation and direction it gave to work in France, Senegal and Switzerland to be irreversible.
For Papert, the first months of the centre gave the idea of what would be feasible if genuine international cooperation between scientists were encouraged.
Papert also recognises that much of what he wants remains in the realm of aspiration.
Some of Papert's greatest admirers fear that although LOGO is the best of the new generation of languages, it cannot yet justify the high hopes vested in it.
Even before Papert's departure, they foresaw a conflict between the immense amount of long-term research needed and Servan-Schreiber's desire for quick results.
Papert and another of his closest colleagues in the development of LOGO, Guy Monpetit, are both former students of Jean Piaget, the Swiss educational theorist.
Piaget believed that educational development had to come from within the child, through a process of building and testing hypotheses within the microworld of a child's perceptions.
Sometimes Papert's writings and his enthusiasm for changing the structure of education seem to place him in affinity with such educational radicals as Ivan Illich and Everett Reimer, but this is misleading.
Most of Illich's ideas were developed in the Third World as a political response to the economic impossibility of universal ‘Western education’.
Illich asked whether such education was even desirable, let alone possible.
Papert builds on a far older European tradition of cognitive psychology.
(Piaget's most influential books were written more than 50 years ago.)
The applications of Papert's ideas to the Third World had more to do with Servan-Schreiber's priorities, than with the immediate concerns of the computer scientists the politician had gathered.
This is not to cast doubt on the sincerity of Papert and his colleagues.
It is to emphasise that Papert is fighting major battles over the nature of the relationship between computers and education.
His fight is not just for the Third World, but for North America and Europe as well.
He does not see computers as a mere aid to teaching, but as an integral part of providing a child with Piagetian materials to learn with.
LOGO's particular characteristics allow a beginner to build complex procedures out of very simple steps, to use a word to cover a list of small procedures.
This makes it an ingenious medium for the construction of microworlds, which abide by rules created by the child user.
Equally, LOGO can be used by a teacher to implant complex ideas from, say, theoretical physics, which can then be explored by a student.
Dr Jack Demaine of Loughborough University's Education department, has criticised the ‘deschooling’ ideas of Illich.
He sees Papert as going beyond Piaget.
Demaine thinks that LOGO holds the promise of giving children access to advanced concepts at a far earlier stage than Piaget would have thought possible.
Papert evidently dislikes many of the first uses of computers in education, but is more interested in their power to transform schools than to abolish them.
Professional teachers in the UK, even those who are enthusiastic about Papert's ideas, warn of the difficulties to be overcome in curriculum development and teacher training.
It is not so much a problem of hardware development outpacing software, or vice versa.
It is a more complex tension between the time it takes for any educational system to assimilate innovation, and the pressing need of computer manufacturers and software publishers to market new products.
Both teachers and entrepreneurs have to speculate about the impact of microprocessors on society.
They are under pressure to resolve questions which cannot be settled around a conference table.
Recognising the pressures on computer teachers, and the billions of dollars, pounds, francs or yen which give weight to those pressures, does not invalidate a central premise of the founders of the centre.
That is, the Third World needs to be involved from the start in the development of the next generation of machines, which will transform our lives as much as the car did.
It is clear when talking to people like Papert, Monpetit (who heads LOGO Computer Systems in Montreal), or Dr Harry Goldberger, director of the medical programme, that they are not simply colleagues.
They form part of a distinctive culture.
Revealingly, they often speak of themselves coming out of the ‘LISP community’.
LISP stands for LIST processing language, a favoured language of the artificial intelligence community.
LOGO is its most widely available dialect and runs on a variety of microcomputers, including Apple II, the BBC Micro and the Sinclair Spectrum.
Whether the Centre Mondial succeeds or fails as an exclusively French institution, or is reborn as an international entity, the ideas and purposes underlying its foundation will survive.
Computing capacity in the world is roughly doubling (in number and power) every year, and the Third World will not be immune from this growth.
LOGO emerged from the laboratories of MIT into personal computers in the 1980s.
It is a language that needs a large memory capacity and for the first time there were machines available to use it.
BASIC and its dialects were designed for more limited machines.
Papert said that people at MIT considered it was ‘as unacceptable for children to enter the computer culture by learning computer languages, such as BASIC as it would be to confine their reading of English poetry to pidgin English translations’.
Papert does not claim that LOGO either a final product or the ‘definitive computer language’; it is one of a growing family of such languages, which are in a very early stage of their developments.
The underlying premise of Papert, Servan-Schreiber and their colleagues at the Centre Mondial is that children and adults, lawyers and journalists, the rulers and the ruled, can all assimilate compute culture without either losing their own, or surrendering to some centrally imposed scheme of, knowledge.
The idea challenges scientists and non-scientists alike, including people who may never write a computer program in their lives, to come to terms with computers and understand what they are about
Paris centre grows from American roots
CENTRE MONDIAL grew out of the complementary ideas of two men: French politician Jean-Jacques, Servan-Schreiber and American scientist Seymour Papert.
Servan-Schreiber, the president of the centre, argued in World Challenge that the microprocessor should offer the Third World an escape from misery and poverty.
Countries in Africa and Asia should be able to skip stages of development suffered by the older industrialised nations.
In Servan-Schreiber's theory, the next generation of cheap personal computers, accessible to ordinary conversation in hundreds of different languages, would begin to replace cars and radios as the principal vectors of cultural exchange and development.
It was a theory that received a lot of ridicule.
Meanwhile, computer scientists at the Massachusetts Institute of Technology (MIT) were looking for ways to place their research into artificial intelligence at the service of people (as distinct from the service of the United States Department of Defence).
They had plans for an international centre, with a strong educational bias like the centre Mondial, to be sponsored by MIT and Harvard University.
Papert explains that Reagan's election in 1980 put paid to any hopes of obtaining public money to establish such a centre in the United states.
Budgets were being cut in every institution of higher learning, and the ivied towers of MIT at Cambridge were no exception.
But even beyond the question of funding, the climate for educational innovation in the US seemed unpropitious.
Papert met Servan-Schreiber in March 1981, just as Francois Mitterrand's star was rising to its zenith in France.
Papert and Alan Kay, who headed a Xerox research laboratory and was a pioneer of personal computing, were able to direct Servan-Schreiber's enthusiasm.
He was persuaded to refine his ideas to the point of conceiving the Centre Mondial as a workable and fundable project.
Mitterrand was impressed by both Servan-Schreiber's ideas and their publicity value.
The President of France commissioned a report on the shape the centre might take.
The report, largely written by Papert, was delivered in September 1981.
The President gave his blessing on 20 November, and the Council of Ministers made it official on 27 January, 1982.
The centre opened two months later.
The budget for its first year was set at F66 million and at F100 million for the next 12 months.
Papert left the centre last autumn after control passed from the Minister of Research to the Ministry of Communications.
The move changed the spirit of the centre; it became less concerned with education and more concerned with French computer sales to the Third World.
According to Servan-Schreiber ‘Centre Mondial is a place for the most eminent scientists to find a computational environment of unmatched quality.
We anticipate a population of researchers that by mid-1983, will number approximately 100 scientists.
The work will include at least three pilot projects in the Third World and a larger number of social experiments in France.’
Papert LOGO, and Turtle Graphics
SEYMOUR PAPERT believes that children learn by building their own intellectual structures which they then apply to reality.
No one teaches a child to walk, climb, shout, talk, play or to manipulate grown-ups; it  just knows.
According to Papert, the understanding of learning is genetic.
The infant's problem is to find the ideas ‘correct’ for it to learn with.
The structure that Pals used as a child was an intuitive understanding of gears.
From the age of one right through his schooling, the mathematician-to-be related the world to ‘mental gear models’.
LOGO is a high-level language specifically written to make computers make sense to children.
The theory is that experimenting with programs will do two things.
First, it will give the child a sense of power over the machine.
Secondly, it will develop intellectual structures in a young mind that are based on a feeling for, or an intuitive grasp of mathematical concepts.
Classically, learning LOGO begins with a child's own sense of space.
‘Walk in a square’, someone asks.
The child then has to work out how many paces to each side and where to turn through 90o.
The next stage is to introduce the Turtle.
This is a  hemispherical , transparent drawing machine about 10 cm in diameter.
It is controlled by a computer keyboard and it understands LOGO's simple commands.
The child types instructions like ‘FORWARD 50’ and ‘RIGHT 90’and Turtle draws a square.
The analysis needed is the same as that used to walk in a square.
Now the child sits at the computer screen.
There is a small triangle in the centre.
She types ‘FORWARD 50’ and the triangle leaps 50 units along the x -axis.
The square is completed and she has been introduced to Turtle Graphics.
Having discovered how to draw a square she types: TO ZX SQUARE.
The word TO tells the machine it is about to get an instruction.
The child then types four  times : FORWARD 50; RIGHT 90; followed by END.
The computer now responds to the command SQUARE by drawing a square 50 x 50 units.
Soon she will want to draw squares with different length sides.
This is easy, because she can edit her original definition as TO SQUARE SIDE.
The young programmer can then type SQUARE 10 or SQUARE 100 to produce squares of different sizes.
There many other procedural languages.
LOGO is not ‘just like English’ as the advertisements say; it has a syntax and rules which have to be learned.
The claim is that these rules can be built up from a simple base.
A child can produce satisfying results quickly based on his or her keyboard explorations.
These results are a valid introduction to central concepts of computer programming.
The child programs the computer, and not vice versa.
Turtle Graphics are not peculiar to LOGO.
They can be emulated by other languages.
The difference is that Turtle Graphics would not provide a valid introduction to those other languages.
The importance of LOGO is that it is a language, developed by the artificial intelligence community, to be implemented in primary schools.
It has been tailored for its purpose and has been tested extensively over the past 12 years.
LOGO could not be used as BASIC is used to run a small business.
On the other hand, LOGO may provide powerful, future tool for adults who find BASIC a turn-off yet want to learn computing.
Seymour Papert may be an educational Utopian, but he and his associate Guy Monpetit at LOGO Computer Systems in Montreal have one trick that other software houses will envy.
The LOGO disc they produce for Apple is virtually uncopyable.
You have to buy your own.
Dammit.
Why the safety lamp increased accidents
Today's myth has it that the Davy miner's lamp brought safety to Britain's coal pits.
The reality is exactly the opposite.
The introduction of the lamp allowed more coal to be dug and more profits to be made.
But more miners died in the process.
David Albury and Joseph Schwartz
IN 1815 Sir Humphry Davy, later to become president of the Royal society, invented what came to be known as the Davy miner's safety lamp.
This lamp, through its ability to reduce explosions, was claimed to produce a great improvement in the working conditions that the miners had to endure.
John Paris, in his biography of Davy published in 1825, wrote: ‘I have been able to present to the world a complete history of those proceedings which have so happily led to discovery of which it is not too much to say that it is at once the pride of science, the triumph of humanity and the glory of the age in which we live.’
Far from reducing accidents, however, the lamp led to an increase in explosions and fatalities.
In the 18 years (1798–1816) prior to the introduction of the lamp there were 27 explosions and 477 deaths in the coal mining districts of
Durham and Northumberland.
In the 18 years after its introduction (1817–35) there were 42 explosions and 538 deaths.
Between 1839 and 1845, 224 men and boys were killed by explosions.
In 1848 an experienced mines inspector and engineer could write in A Treatise on the Winning and Working of Collieries : ‘Explosions of gas have unfortunately become so numerous in late years that it would be impossible in the absence of specific records to enumerate them.’
And by 1874, Richard Fynes, a historian sympathetic to the miners could write: ‘Experience, however, proved that [the lamps]were the most deadly instrument ever devised in mining operations and were the cause of more sacrifice of human life than ever had occurred before.’
The actual story of the lamp is not, however, one of good guys (the scientists) versus bad guys (the mine owners): it reveals, rather, how the interests of those in control affect the course of a research investigation.
The Davy lamp was the direct result of the mine owners' concern to recover coal, not from deeper shafts but from existing workings that were inaccessible because of a process known as ‘creep’.
When the veins of coal were mined, pillars of coal had to be left to hold up the roof of the mine, rather like the pillars in a multistorey car park.
The weight of the roof pushed the pillars down and the resulting pressure also forced the floor to buckle and move upwards.
The downward motion of the pillars and the upward motion of the floor gradually combined to shut off the passageways and close the mine.
The pillars of coal left behind were compressed, releasing large amounts of an explosive mixture of air and methane called firedamp.
As early as 1738 mine owners were complaining that two-thirds of the mines were unworkable because of creep and the large amounts of explosive methane that were released.
The owners' research problem was to get a light that would function in the methane-rich atmosphere of the ‘crept’ workings.
Existing lighting was supplied by the hazardous open flame of candles, oil lamps or by a steel mill, a method of producing sparks of light by holding a flint against a spinning steel wheel.
Such mills were not only expensive, they were also unusable in the so-called fiery seams of the crept workings.
In 1815 Davy solved the problem.
He devised a cheap lamp that would burn in the methane-rich atmosphere of the crept workings without instantly exploding.
The monetary value of the lamp, as opposed to its humanitarian value, was greatly appreciated by all the major principals concerned.
John Buddle, a mine inspector and owner's agent with whom Davy had consulted, wrote to Davy on 1 June, 1816: ‘I am convinced that with the happy invention of the safe lamp large proportions of the coal mines of the empire will be rendered available, which otherwise might have remained inaccessible.’
The owners of the Durham and Northumberland collieries showed their appreciation by presenting Davy with a set of silver plate worth £2500 (a miner's wage at the time was £50 a year) at a testimonial dinner on 11 October, 1817.
Inscribed on the centre piece were the names of the Duke of Northumberland, the largest colliery owner, and 36 owners and officials from 26 collieries in Durham and Northumberland.
At the presentation, Sir Humphry did not pass up the chance to impress upon the business world the great value of science to their endeavours: ‘Science, gentlemen, is of infinitely more importance to a state than may at first sight appear possible; for no source of wealth and power can be entirely independent of it; and no class of men are so well able to appreciate its advantages as that to which I am addressing myself.
You have not only derived from it the means of raising your subterranean wealth, but those also of rendering it available to the public.’
In 1818, the Walker colliery which had been closed for the preceding 30 years was reopened.
In a short space of time the crept workings in Wallsend, Wellington, Percy Main, Bebburn, Jarrow, Elswich and Berwell were all reopened.
The problem from the owners' point of view had been solved.
But when the problem is looked at from the miners' point of view a rather different history comes into view.
The problem is no longer how to excavate the crept workings but how to make the mines safe.
As early as 1662, 2000 miners from Tyne and Wear had petitioned the King about insufficient ventilation in the mines.
They demanded that a second shaft be sunk to afford protection against the aftermath of explosions — the main cause of death in a methane explosion being not the explosion itself, but poisoning by carbon monoxide or suffocation by choke damp (carbon dioxide) or other products of combustion.
The owners turned a deaf ear to such an expensive demand.
In 1816, the year Davy's lamp was introduced, J. H. H. Holmes, a mining inspector, published a book containing ‘accounts of the explosions from fire damp which have occurred for the last 20 years; their causes and the means proposed for their remedy and for general improvements of the mining systems by new methods of ventilation.’
Holmes pointed out that Davy's lamp had many faults.
First, the methane could explode by entering too quickly through the gauze.
Secondly, the wire gauze could detach itself from the lamp body, permitting the flame to escape and explode in the surrounding atmosphere.
And finally, Holmes noted that ‘the lamp is liable to accident by falling pieces of coal, by dusty atmosphere clogging the gauze making it red hot, by coal particles igniting on the hot wire mesh.’
All of these accidents occurred regularly in the years after the lamp's introduction.
In 1835 a select committee on explosions in the mines rejected all the lamps currently in use because they were all liable to internal explosions in methane blowers.
And the protagonists of Davy's lamp themselves were forced to admit there were problems.
John Buddle, the inspector at Hebburn colliery, wrote in his June 1816 letter to Davy that accidents would still happen, either because of fate or by individual negligence.
‘It would however be quite unreasonable to expect the accidents were never to happen when the wire gauze lamps are used; for it must be remembered, setting aside the chance of their being damaged by some of the casualties incidental to coal mining, they are to be entrusted to the management of a body of men among whom negligent individuals will be found.’
But the owners had their lamp.
Holmes's recommendations for ventilation were rejected.
Davy's lamp was so simple.
And cheap too!
Why bother?
Despite a spirited correspondence in both the London and Tyneside newspapers about the need for ventilation and the defects of Davy's lamp, Holmes was unable to get his proposals considered by the rigid and uncompromising owners.
The miners, for their part, continued to be well aware of the importance of ventilation.
They quickly learned that Davy's lamp was particularly unsafe when the methane was released in jets, or ‘blowers’ as they were called.
Under these conditions the methane jets pushed the candle flame outside the gauze, causing explosions.
Richard Fynes noted that: ‘The men were sufficiently endowed with natural interest to be observant of the effect of wind upon the ventilation of the mines, and even as late as 1822, before barometers and thermometers were generally used in the pits to indicate the state of the temperature, if the wind were blowing from the southeast threatening rain, the men refused to work.’
And, in 1849, before the House of Lords select committee on the cause of accidents in the mines, a miners' petition argued that the owners were practising a false economy in not supplying a ‘sufficient quantity of brattices, doors and stoppings to convey a sufficient quantity of wholesome air’ to miners underground.
But how did it happen that the Davy miner's lamp worked out so well for the owners and so badly for the miners?
To understand this, we first need to see how the problem of safety in the mines came to the attention of Sir Humphry Davy.
On 25 May, 1812, the Felling pit in Durham exploded, killing 92 men and boys.
It was the worst mine explosion in 20 years and a culmination of a series of explosions caused by the owners, eagerness to bring out coal from the crept workings.
The survivors, their friends and families, and the friends and families of the dead men and boys were outraged.
In the words of J. H. H. Holmes, ‘They turned the poignancy of their feelings into distrust and imputations upon the proprietors and overseers of the mines.’
Six weeks later, when the remaining bodies were brought out, militant miners, veterans of the 1819 miners strike had agitated successfully enough for Holmes to comment: ‘Their great grief was disturbed by agitators and others to create distrust and confusion by acrimonious and malignant observation.’
Something had to be done.
A year later, on 10 October, 1813, a group of prominent citizens formed the Sunderland Committee to deal with, as they put it, ‘these dreadful calamities’.
Matters were not helped when the same mine exploded two months later on 15 December, 1813.
The committee called in George Stephenson, Reid Clanny and Holmes who were working on safe lamps and ventilation.
They did not call miners.
One of the committee members, Reverend John Grey, knew Davy and the committee agreed that ‘the philosopher’ should be consulted.
Davy, unfortunately, was on his first continental tour.
The matter rested there until his return, during which time Clanny and Stephenson were working on their own versions of a safe lamp.
As Davy wrote later, John Buddle, the mine inspector, convinced him that, ‘as far as ventilation was concerned, the resources of modern science had been fully employed; and that a mode of preventing accidents was only to be sought for in a method of lighting the mines free from danger.’
Taking several samples of firedamp in glass bottles, Sir Humphry returned to London telling Buddle, ‘I think I can do something for you’.
Thus Davy's brief was rigidly defined.
He spoke to no miners.
He was told — and he believed — that the problem was not one of ventilation.
His brief, in short, was the owners' brief — to build a lamp that would work in the methane-rich atmospheres that existed in crept workings.
It was not to investigate mine safety but to design a lamp.
Davy returned to the Royal Institution in London on 30 October, 1815.
In two weeks he transmitted an answer to the Royal Society in a paper that is often cited as a prime example of the scientific method.
Davy reported that if a candle were surrounded by a wire gauze mesh, the gas would diffuse into the gauze enclosed space and burn there without exploding.
The wire surfaces cooled the burning gas as it came into contact with them to a temperature below the ignition point of the gas outside the cage.
This was the desired ‘safety’ lamp.
‘It is evident then that to prevent explosions in coal mines, it is only necessary to use air-tight lanterns supplied with air from tubes of small diameter or from openings covered with wire gauze…
Common lanterns may easily be adapted to the purpose.’
The lamp was tried by Buddle and Davy at the Hebburn colliery on 1 January, 1816, with good results.
That is, the thing did not immediately explode.
Davy had solved his problem.
Davy's experiments are often cited as a classic example of the methods used in 19th century physics and chemistry research.
He purified the substance to be tested.
He determined that the most explosive mixture of the purified methane and air was in the ratio of 1:8.
He tested the 1:8 mixture in bottles of various sizes until he found that it would not explode in long narrow tubes that offered a large cooling surface.
And, by extending this line of argument, he found that surrounding the flame by a wire gauze had the same cooling effect.
He explored the variables systematically to come up with a solution.
But, of course, safety had been defined out of the problem.
Davy had found a way to burn a candle in a methane-rich atmosphere.
It turns out that despite the accolades of later historians, Davy had formidable competition for the creation of a lamp.
George Stephenson, later to become famous as a master engineer and designer of Britain's railway locomotives, held little truck with ‘natural philosophy’.
He was employed at the time at Killingworth colliery, in charge of the steam engines used to raise coal and water from the mines.
Being an ‘illiterate mechanic’, Stephenson had no time for the niceties of laboratory research.
Instead he designed lamps on the spot and took them straight down into the mines to test them on the jets of methane.
He discovered that a glass-enclosed lamp with small openings at the top and bottom to let the air in and the smoke out made a safe lamp.
He tested his first successful model on 27 October, 1815 in Killingworth colliery, two months before Davy tested his at Hebburn colliery on the first day of 1816.
The stage was set for a nice priority fight.
Who would get the credit, the ‘illiterate’ Stephenson or the ‘philosopher’Davy?
Stephenson grew increasingly irritated at being ignored by the owners and the newspapers.
Two sections of the middle class girded up for a fight; the rising mechanics and practical men of industry versus the established professional men of science and culture.
The London Morning Chronicle editorialised on 16 December, 1816 that Mr Stephenson, ‘an ingenious but illiterate mechanic’ had made a contribution, but ‘the real fact is that Sir Humphry's contrivance is simple, convenient and efficacious.
He has rendered a great service to humanity by the invention’.
Stephenson, for his part, organised directly among the coal owners for whom he was rendering a valuable service.
At a meeting in Newcastle, the Committee of Coal Owners in Newcastle voted in favour both of Stephenson's claim for priority and to give him some money for it.
As Goethe, writing in Germany in 1823, remarked: ‘Questions of science are frequently career questions.
A single discovery may make a man famous and lay the foundation of his fortunes as a citizen…
Each and every newly observed phenomenon is a discovery, every discovery is property.
Touch a man's property and his passions are immediately aroused.’
MONITOR
Schizophrenia: the case for viruses
COULD schizophrenia be an infectious disease, transmitted between genetically susceptible people and occurring in seasonal ‘epidemics’?
This suggestion, made recently by Tim Crow at the MRC's Clinical Research Centre at Harrow and published in the Lancet (vol I, p 1735, is still highly speculative, but his report draws attention to the fact that the biological nature of this much feared illness could soon be understood.
For the psychiatrist, the diagnosis of schizophrenia depends on the presence of a number of characteristic symptoms.
The patient may suffer from hallucinations (typically auditory), delusions, and complain that his actions are being controlled by some ‘alien’ force.
These symptoms are often termed ‘positive’ since they are in a sense added to normal experience.
However, the illness may also be associated with additional, ‘negative’ symptoms, such as poverty of speech, loss of drive and emotional responsiveness, and occasionally intellectual impairment.
The relative diagnostic importance of these symptoms has been in dispute until quite recently, when evidence for a variety of biochemical and structural deficits in the brains of schizophrenics began to emerge.
In the late 1960s it was found that the drug amphetamine could induce some of the symptoms of schizophrenia in otherwise normal subjects.
Amphetamine produces its effects by causing certain neurons to release more of the neurotransmitter, dopamine — one of the many chemicals used in the brain to transmit signals from one cell to another — suggesting that schizophrenics either produced too much, or were too sensitive to the actions of the transmitter.
The ‘dopamine’ hypothesis is now well established.
Most of the drugs effective in treating the illness are also known to interfere with dopamine's action on nerve cells.
This view is supported by postmortem studies of brain tissue which have shown that there are more dopamine sensitive sites on the surfaces of cells taken from schizophrenics than are found in normal brains.
Dopamine is not the only transmitter affected by the disease.
More recently reductions in two other brain peptides, cholecystokinin and somatostatin have also been described in the brain tissue of schizophrenics.
These chemical studies have now been complemented by the use of brain scanners.
Some of these computerised instruments can reconstruct three-dimensional X-ray images of the living brain, while others, in conjunction with the use of radioactive tracers, can map its metabolic activity.
In both respects the schizophrenic brain appears to be abnormal.
The fluid filled spaces or ventricles appear to be enlarged, and the blood flow to the front of the brain is reduced.
Far from being a ‘disease of the mind’, as was once supposed, schizophrenia can now be regarded as an ‘organic’ disorder similar in many respects to Parkinson's and Alzheimer's diseases, in which pathological changes and abnormalities are more easily identifiable.
So what is the ‘cause’ of schizophrenia?
During the past 50 years numerous studies have shown that the relatives of schizophrenics have a higher than expected likelihood of contracting the disease.
This genetic influence is most clearly seen in the case of identical (monozygotic) twins in which at least one of the pair suffers from the disease.
The key to these statistics is the ‘concordance rate’, the proportion of twins in which both individuals suffer from the illness.
If there were no genetic susceptibility then the incidence of schizophrenia in the second twin would be expected to be the same as in the general population.
Instead, the concordance rate has been found to lie between 35 and 58 per cent.
In the case of fraternal (dizygotic) twins it is also relatively high — estimates range from 9 to 26 per cent.
However, the fact that the figure for identical twins is not 100 per cent makes it clear that schizophrenia is not a simple inherited metabolic disorder.
In the Lancet paper, Crow takes a close look at this and other anomalies in the genetic data.
For example, brothers and sisters who differ in age share genes to the same extent as dizygotic twins, and so in a purely genetic disease would be expected to have the same concordance rates — but they do not.
Twins are far more likely to share the disease than siblings of different ages.
In addition, the likelihood of concordance is far greater in twins (or sibling pairs) of the same sex.
Another clue comes from a paper by the Japanese psychiatrist Abe who has shown that the second twin is far more likely to develop the disease if they are living with an affected twin around the time of onset, as compared to the concordance rates for twins who are living apart.
Taken together, these facts suggest that a genetically susceptible individual must be exposed to some  environmental factor in order to succumb to the disease.
This would explain why children of the same genetics, age and sex, living in the same house are more likely to both contract the illness than any of the other combinations studied.
Could this environmental factor be a virus?
Crow points out that some forms of virus infection can be accompanied by schizophrenic symptoms.
The concordance patterns for schizophrenia are very similar to those in other diseases, such as polio and tuberculosis, in which the genetic and environmental factors are well established.
And like many viral diseases, schizophrenia seems to be seasonally related, with the majority of hospital admissions occurring in early summer.
The evidence marshalled by Crow is strong, but as yet inconclusive.
The identification of viruses affecting brain tissue is notoriously difficult, but this is perhaps one of the most obvious strategies for future research.
In addition, application of recombinant DNA techniques could be used to isolate and characterise some of the genes associated with schizophrenia, as is being done currently with the muscular dystrophies and Huntington's chorea.
As soon as the genetic component of schizophrenia is understood the search for the elusive environmental factor can begin in earnest.
Another coffee for the road?
WHY Do we drink coffee? one answer is to keep us interested in what we are doing at the time — typing, say, or repairing a car.
What makes coffee such an effective stimulant is not entirely clear.
Caffeine is the most popular candidate, affecting the brain's adenosine receptors (Nature vol 301, p195); but Australian researchers have discovered something in coffee that acts like morphine.
This could even be the reason why drinking coffee is so addictive.
Working at Prince Henry's Hospital in Melbourne, J. H. Boublik and colleagues found that instant coffee powder (both the normal and decaffeinated versions) contained something that specifically-bound to brain opiate receptors.
Whatever this substance X was, displaced both naloxone (a synthetic morphine substitute) and enkephalin analogues (enkephalins are the body's own morphine-like substances.
That is, it showed the classic behaviour of a genuine ‘opioid’.
It was found in fresh and instant coffee alike, but not in tea, cocoa, soup, yoghurt or cheese!
(Nature , vol 301, p246).
Various chemical tests showed that X was not caffeine or morphine, being a much larger molecule.
It dissolved in ether, and seemed resistant to proteolytic digestion; this implies that it may be an alkaloid like morphine, rather than a peptide like the enkephalins.
It is uncertain whether the coffee plant manufactures this chemical for its own mysterious purpose, or whether it is made as an accidental byproduct of the roasting process (the smell of coffee originates from the latter source).
The oddest thing about X is that like naloxone, it blocks the opiate receptor; this is opposite from morphine and the enkephalins.
There is quite a lot of X in coffee — probably' enough to affect directly our own enkephalin receptors — but whether it is the major stimulant remains to be seen.
Its affinity for the opiate receptor means, however, that it could be addictive in the same way as morphine.
Coffee drinkers, have an excuse at last!
Night — shift spiders warn birds of their webs
MOST spiders weave webs that are all but invisible, but some species include a very conspicuous broad band of silk across the middle of the web.
Arachnologists have long been puzzled by these patches.
The old theory was that they somehow made the web stronger mechanically, a belief reflected in the name stabilimentum.
Now, after experiment rather than speculation, it seems that stabilimenta are really early warning landmarks for birds.
Tom Eisner and Stephen Nowicki, of Cornell University, noticed that the spiders that use stabilimenta build long-lived webs that can stay up for several days.
Webs without stabilimenta are more delicate; the spider tends to build at night and take the web down before dawn, recycling the silk next evening.
This suggested to Eisner and Nowicki that the stabilimentum might be a visual marker, warning birds of the web's presence.
This would be of obvious benefit to the spider, whose web would last longer, but it would also help the bird to avoid getting dirtied by sticky spider silk.
To test the theory, Eisner and Nowicki compared webs with and without artificial stabilimenta.
They found night-spinning spiders and waited until about 2 am, when the webs were finished, before removing the spiders.
Then they marked half the webs with artificial stabilimenta and came back at two-hourly intervals to check on the longevity of the webs.
During the dark the two sorts of web lasted equally well, but once dawn had broken the difference became clear.
By noon more than 60 per cent of the webs with stabilimenta were still intact, while only 8 per cent of the unmarked webs had survived.
To check that it was indeed the visual marking that preserved the webs, rather than any mechanical strengthening, Eisner and Nowicki had one set of webs in which they suspended the stabilimentum with black threads next to, but not touching, the web.
There was no difference in longevity between these and the more conventionally marked webs.
Further evidence comes from an actual encounter between bird and web.
During 7½ hours of observation, the biologists saw one collision between a rufous-sided towhee and a web.
The bird faltered momentarily.
The web was utterly destroyed.
Birds aren't the only problem for spiders.
Large mammals too might be warned of the webs, but so might prey.
Eisner and Nowicki suggest that the occasional missed meal is more than adequately compensated for by the preservation of the web.
They also make the point that the one spider that makes daytime webs without stabilimenta,Nephila clavpes , has bright yellow silk, which, they say, makes the web conspicuous enough without the need for resorting to additional warning markers.
(Science , vol 219, p 185).
Multiple sclerosis therapy is under pressure
MULTIPLE sclerosis — a mysterious deterioration of the central nervous system — has long eluded attempts to find a cure.
But an effective treatment may be near at hand.
Breathing oxygen at twice normal atmospheric pressure can help chronic sufferers, researchers at New York University find (New England Journal of Medicine , vol 308, p 181).
Forty patients with advanced multiple sclerosis received either pure oxygen or a mixture of 10 per cent oxygen in nitrogen, for 90 minutes a day.
After 20 sessions, 70 per cent of those breathing pure oxygen tired less easily and became more mobile and co-ordinated.
Only 5 per cent of the control group, breathing oxygen and nitrogen, showed any improvement.
Minor ear problems and reversible shortsightedness were the only observed side effects of the treatment, but caution is needed.
Hypoxia has been known to induce seizures and transient blindness.
Unfortunately improvement was short-lived, lasting only a few weeks in those with more severe forms of the disease.
But a few patients remained healthier a year later.
A paper by Dr Philip James of the University of Dundee published by the Lancet last year amplifies an idea first suggested in the 1930s that the disease may be due to the blockage of blood vessels of the nervous system by fat globules (Lancet , 1982, vol 1, p 380).
This idea evolved after scientists  recognised the similarity of damage to the brain and spinal cord seen in divers and in sufferers of multiple sclerosis.
The lodging of fat globules in capillaries damages the veins.
The resulting leakage of plasma from veins is a recognised feature of multiple sclerosis and is know to cause shedding of the fatty covering of nerve fibres (the myelin sheath).
Computed tomography indicates that vascular events can precede the symptoms of multiple sclerosis and that death of nerve fibres occurs considerably later.
Boguslav Fischer and his co-workers at the New York University Medical Centre suspect that the hyperbaric oxygen treatment may work by improving oxygen supply to small veins associated with damaged nerves, leading to improved conductivity in those nerves still functioning.
The longer-lasting remissions experienced by patients with relatively mild symptoms suggests that an enhanced oxygen supply may even be able to stimulate some kinds of repair, perhaps re-myelination of damaged nerves.
Hyperbaric-oxygen treatment is also known to suppress the immune systems in experimental animals, and researchers suspect that multiple sclerosis may be an autoimmune disease related to a viral infection.
A team of Boston scientists led by Stephen Hauser report, in the same issue of the New England Journal of Medicine , that a combination of immunosuppressive drugs can halt the progress of the disease in patients with advanced progressive multiple sclerosis (vol 308, p 173).
Unfortunately one of the drugs — cyclophosphamide, administered with ACTH — has been linked with bladder cancer and leukaemia, so this treatment remains a last resort for victims of multiple sclerosis.
Slow walkers may be slow learners
SLOW walkers are slow learners?
An old wives' tale?
Not according to Phil Silvia, Rob McGee and Sheila Williams of the University of Otago Medical School in New Zealand (British Journal of Disorders of Communication , vol 17, p 133).
As part of a long term study of child development these workers assessed 954 seven-year-olds of an original sample of 1037 children born between 1 April, 1972 and 31 March, 1973 in the city of Dunedin, New Zealand.
They measured the IQ of these children using the Weschler Intelligence Scale for Children and assessed reading ability using the Burt Re-arranged Word Reading Test.
Scores on these tests were compared with a mother's record of when her baby first walked and talked.
Babies walking later than 18 months were categorised as slow walkers; those talking later than 24 months were classified as slow talkers. 9.3 per cent of their seven-year-olds were slow walkers, talkers or both.
Children who were slow to walk or slow to walk and talk had significantly lower IQ scores and experienced greater reading difficulties than those who were not delayed in walking or talking.
In fact, 66.7 per cent of children with delayed walking and talking had low IQ scores (less than 89 points — the average score is 100 points) and reading difficulties (reading age of less than six years of age).
This compares with 3 per cent in normal children.
Surprisingly, slow talking on its own was not associated with later reading difficulties or low intelligence.
Only 2.4 per cent slow talkers experienced later problems.
The Dunedin group hope to use slow walking to identify problem babies.
Early intervention could prevent some of the problems and costs of special education that occur in later life.
The mathematics of hallucination
IN THE 1960s a mystique surrounded hallucinogenic drugs like LSD because they seemed to enable users to alter their perceptions of reality, and explore their ‘inner minds’.
Jack Cowan, working at the California Institute of Technology, Pasadena, California, thinks that at least part of the hallucinogenic experience may result from an instability of neural activity in the visual cortex.
He has devised a model based on the mathematics of fluid dynamics, that attempts to explain the genesis of simple geometric patterns seen during the early stages of drug-induced hallucinations (International Journal of Quantum Chemistry , vol 22, p 1059).
At the beginning of a drug-induced hallucination the subject often sees simple, coloured, geometric patterns.
These fall into one or more of four basic forms: grating or network, tunnel or funnel, spiral, and cobweb.
The hallucinations move independently of the eyes, suggesting that the patterns are generated in the visual cortex of the brain rather than on the retina.
The visual cortex consists of tightly packed columns of cells, each column corresponding to a particular point in the visual field in a way that can be mathematically defined.
Using the mathematics of ‘map’ the four basic hallucinatory patterns onto the visual cortex gives quite surprising results.
Tunnel and spiral patterns transform into parallel lines or stripes of neural activity; lattice and cobweb hallucinations transform into regular networks, or lattices.
Cowan was struck by the similarity between these patterns and those seen in the fluid convection under certain conditions.
If a layer of liquid is heated uniformly from below, a temperature gradient is established between the top and the bottom of the layer.
When the temperature gradient exceeds a critical value, convection currents start — the liquid all wants to rise to the top of the layer, but some must fall to the bottom.
The situation is unstable.
To resolve this instability regular patterns of rising and falling liquid can be set up.
Cowan reasoned that the patterns in the visual cortex might be the result of an analogous instability in the neural activity.
Cells close together in the cortex are likely to have a number of interconnections whereas cells farther apart may have few or none.
The level of activity in cortical cells varies, and their ability to excite other cells varies accordingly.
When the excitatory interaction is weak, only cells close to a stimulated cell will be excited; when it is strong, cells over a wide area are excited.
Some interconnections are inhibitory, and varying the strength of the inhibitory interaction works similarly.
Inhibitory interconnections are very important for preserving stability in neural activity.
Cowan believes that a phenomenon known as lateral inhibition is responsible for the patterns generated by hallucinogens.
Lateral inhibition means that one cell's excitation inhibits its close neighbours.
The best known example of the phenomenon is in cells of the retina, where its effect is to heighten contrast.
Cowan suggests that the strength of the excitatory interactions increases relative to that of the inhibitory interactions under the influence of the drug.
When one cell is excited, it inhibits those close by, but excites a large number of distant cells.
These in turn inhibit some adjacent cells but excite others further away, and so on.
The normal stabilising mechanisms are out of control and the whole cortex becomes involved.
However, because there is still some inhibition the neural activity stabilises as adjacent areas of excited and inhibited cells.
The solution to this problem, like that of the boiling liquid, is found in the formation of regular patterns.
Cowan set up a mathematical equation that represented the neural activity, and built lateral inhibition into it.
He then varied the ratio of excitatory to inhibitory interaction strengths.
When the ratio strayed above a certain value the cortical activity became unstable and patterns were formed.
Depending on the exact value of the ratio, the model produced stripes or lattices.
He concluded that his theory could account for the hallucinations.
Does all this have any foundation in physiology?
Cowan thinks it does.
He estimated the separation between the stripes of excited neurones from reported hallucinations to be 2 millimetres.
This corresponds to the spacing between ‘hypercolumns’ in the visual cortex, identified by David Hubel and Torsten Wiesel.
These hypercolumns are blocks of cells that signal local properties of visual objects (such as orientation) in their particular areas of the visual field.
He suggests that hypercolumns are coupled together by excitatory fibres.
The stripes are produced by excitation in adjacent rows of hypercolumns.
He also concludes that the dominant interaction within each hypercolumn is inhibitory.
Cells do exist that can influence the excitability of the cortical neurones, in the locus coeruleus and the raphe nucleus, deep within the brain.
Both act to decrease the excitability of the neurones.
Cowan says it is possible that the hallucinogens act by depressing one of these groups of cells.
Cowan makes a number of approximations in order to make his theory manageable.
Whether it is an accurate account of the genesis of these hallucinations remains to be seen.
However, it is a remarkable piece of interdisciplinary thinking, linking fields as diverse as fluid dynamics and neurophysiology.
Wholly amazing discovery
IT IS POSSIBLE to reduce the amount of salt people consume by making the hole in the salt shaker smaller and placing the shaker out of reach.
This dramatic conclusion has been reached by a team of Australian scientists after a study supported by a grant from McDonald's Family Restaurants, and the results are reported in detail in Nature (vol 301, P 331).
The motivation behind this research, carried out by H. Greenfield, J. Maples and R. B. H. Wills, of the School of Food Technology, University of New South Wales, is the recent concern in the medical profession that too much salt in the diet may be one cause of the high incidence of hypertension among people in the developed countries.
The techniques used by the team depended on cunning placing of salt shakers, identical except for hole size, in a public cafeteria and on Quantas (sic) aircraft, with shakers weighed before and after use.
Less than a quarter of the people observed using the shakers tasted their food before adding salt, suggesting that the salt-shaking habit is not related to the taste of the food and is essentially a ritual activity.
So, the smaller the hole the less salt used in the ritual — with one caution.
The ‘optimum’ hole size is around 3 sq mm, say the Australians, because ‘with smaller hole sizes some consumers attempted to make the hole larger with sharp implements such as forks’.
But it is possible to reduce salt consumption further by ‘placing the salt shaker at some distance from the table’.
Next week we will have a report for grandmothers on how to suck eggs.
TECHNOLOGY
Britain re-arms for the 1990s
BRITAIN's Ministry of Defence is speeding up plans to buy new ships, radars and weapons.
The ministry bought several major items of new equipment ‘off the shelf’ during and immediately after the Falklands war.
Now it has launched a series of competitions to select the best ways of filling the gaps in Britain's armoury.
Last December the Royal Navy ordered the first two Type 22 frigates of a new design, with much heavier armament than design, predecessors.
The present Type 22s, such as HMS Broadsword and Brilliant, which shot down several Argentinian aircraft with Seawolf missiles, have long been criticised for their puny armament.
Although the Type 22 frigate is substantially longer than a Type 42 destroyer, it carries neither the sea Dart long-range anti-aircraft missile nor the Vickers Mk 8 gun.
The new Type 22s, ordered to replace the sunken Type 42s and Type 21 frigates, will carry the Vickers gun.
During the Falklands war, this type of weapon fired several thousand of its 114 mm-calibre shells with pinpoint accuracy against enemy land forces.
The crew of the Type 21 frigate HMS Avenger also claims to have shot down an Exocet with one.
The new ships will carry a lightweight version of the seawolf, using new radars that Marconi is developing.
They will also be armed with eight new anti-ship missiles, compared with four Exocets on their predecessors.
The Royal Navy is evaluating at least four types of missile for this role.
These include a version of the Sea Eagle, which British Aerospace is developing to arm RAF Tornado aircraft and Royal Navy sea Harriers; the MM.40 long-range variant of Exocet; the McDonnell Douglas Harpoon from the US; and the Franco-Italian Otomat.
All these apart from MM.40 have a range of about 100 km, compared with 40 km for the basic Exocet.
Present Type 22s carry small Bofors guns.
The new ships will have two sets of rapid-fire radar-controlled multi-barrel guns to shoot down missiles.
The contenders for this order comprise Seaguard, made by Contraves in Switzerland; Goalkeeper, with Dutch radars and an American gun; VM30, with the same gun but British radars and computers; and an improved version of the American Phalanx that the Royal Navy hastily bought last summer to equip its new aircraft carrier, HMS Illustrious.
The Royal Navy is also running a competition to select a new radar for its surviving Type 42 destroyers, Type 21 frigates, its aircraft carriers and the planned Type 23 frigates.
Last month four companies, Plessey, Marconi, MEL and Thorn EMI, put in bids for the radar.
This ‘Type 996’ will replace the 1950s-vintage Type 992, which suffered from a number of deficiencies in the Falklands.
Rough seas reflect radar signals, producing false echoes which can blind an old radar such as the Type 992.
The Type 996, though, will be able to spot incoming anti-ship missiles such as Exocet in time for the  vessel to defend itself.
MEL is part of the Philips group, and its contender is heavily based on a radar known as Smart which another Philips company is developing in Holland for the Dutch Navy.
Although MEL in Britain would build about 70 per cent of any such radars that the Royal Navy ordered, the other British firms are worried that expertise would be lost if an overseas design won.
The RAF will also receive new weapons to plug the gaps the Falklands war exposed.
The Ministry of Defence (MoD) has awarded Hunting Engineering a contract to complete the development of the JP233 runway destroyer.
In the RAF's first attack on the runway at Port Stanley, carried out by a Vulcan V-bomber which flew from Ascension Island, only one of the 21 bombs dropped hit the runway.
Repeated attacks by Sea Harriers, with conventional 450-kg bombs, were no more effective.
The Tornado strike aircraft, now coming into service with the RAF, will carry two JP233 pods under its fuselage.
These contain two types of ‘munition’, which eject as the aircraft flies low and fast over the runway.
One type of munition blows a hole in the concrete surface, and the other parachutes down to hamper repair operations.
When a bulldozer or other vehicle touches the bomb it explodes.
Another project that the ministry has suddenly accelerated after two years of inaction is a new missile designed to destroy enemy radars.
Since the beginning of December, experts have been studying a brand-new missile called Alarm from British Aerospace, and the American equivalent known as Harm.
Lucas Aerospace has teamed up with Harm's US manufacturer, and would get half of the work on any Harms ordered for the RAF.
The Royal Air Force wants up to 2000 rounds of whichever type the ministry selects.
Each missile has a small radar receiver in its nose.
This detects signals from radars on the ground that may be aiming missiles or guns at the approaching aircraft.
The Tornado would launch a Harm or Alarm at a safe distance.
The missile steers toward the source of the signals, and explodes when it is close enough to destroy the radar.
During the Falklands war, the RAF had to buy anti-radar missiles from the US.
But many did not operate correctly.
The MoD expects to select the new missile design this spring, but the weapon will not be in service until 1986 or 1987.
It will complete an impressive array of hardware — ready, for the next war.
Key page 652 for a happy ending
IF YOU LIVE in the south of England and own a Prestel viewdata set, keep your control panel handy at 7 pm next Monday.
As New Scientist revealed two weeks ago (27 January, p 217) you will have the chance to vote on how you want a love story to end.
You could also win a new dress — or have your comments about TVS's show The Real World typed up live on screen.
The makers of The Real World have dreamed up a box of stunts to demonstrate the potential of what they call ‘viewer reactive television’.
But the programme's producer, Peter Kinkead, says it is more than a gimmick — despite the fact that there are only about 5500 Prestel sets in TVs's catchment area.
‘There are 1 million home computers in the country which could be adapted for Prestel…there is the potential of a quantum leap in Prestel usage.
The programme will demonstrate Prestel's potential for banking, shopping and retrieving information.
One highlight will be the ‘fashion show of the future’.
The first viewer to select an outfit from the parade will receive it free the next day (Kinkead claims it is a uni-sex, uni-size garment).
And viewers who want to tell TVS what they think of the idea can send messages via the Prestel Mailbox service.
A selection of these will flash up on screen during the half-hour programme.
But according to Kinkead, the  highlight : should be the love story.
Viewers will see the first, pre-recorded, scenes, then a freezeframe that will ask them how they want the story to end.
Live actors will then take over, according to the wishes of the Prestel-owning democracy, If you want to know more read Prestel page 652.
Superconducting highway to low — noise chips
A RESEARCHER with IBM has come up with a device that might possibly replace the transistor in integrated circuit devices.
The catch is that it operates only at temperatures just above absolute zero.
Nevertheless Sadig Faris, of the Thomas J. Watson Research Center at Yorktown Heights, New York, believes that its other properties could make it sufficiently attractive to provide the necessary cooling.
The new device, called a quiteron, exploits the strange properties that some substances develop at very low temperatures.
As they are cooled through a critical temperature, they suddenly become ‘superconductors’, with no electrical resistance.
Semiconductors rely on gaps between the characteristic energy levels of electrons in the material; while these remain large, currents cannot flow.
But the gaps can be overcome by applying an external voltage, which helps the electrons to jump the gap, allowing current to flow.
The quiteron works in a similar way, although the energy gaps involved are about a thousand time smaller than for semiconductors — several milli-electronvolts (take out the word electron to arrive at the corresponding driving voltages), This difference is behind the quiteron's big advantage: it dissipates far less power than the conventional device.
A chip built with quiterons would need to lose far less heat than a conventional one, so the devices could be more closely packed on a chip.
Also its signals would contain a lot less noise, particularly important in measuring and handling very weak signals.
Low-noise amplifiers for radio astronomers could well be one of the quiteron's first applications.
The quiteron work consists of three layers of superconductor (see diagram).
In one experimental version.
S1 and S2 are niobium, and S3 is a lead-indium-gold alloy.
Niobium oxide and silicon monoxide insulators separate the three areas.
The superconducting gap in S2 is suppressed by knocking the material out of its superconducting state.
This could be done by heating it (although it would be difficult to avoid heating the other layers as well), but the layer reacts more quickly if an applied voltage between s1 and s2 rapidly increases the power density inside the material.
This state of ‘nonequilibrium’(straight heating would have kept the system in equilibrium) lowers the resistance of the junction layer between S2 and S3, and a substantial current flows where little current flowed before.
Thus the quiteron acts as an amplifier or a switch, just as a conventional semiconductor might.
The quiteron is not the first superconducting device that engineers have considered for chips.
The Josephson junction, based on superconducting effects described and explained in work for which Cambridge physicist Brian Josephson won a Nobel prize in 1973, is also the subject of much research.
But Faris thinks that the quiteron may be more useful.
One reason is that it is a three-terminal device, which can act as an amplifier or switch on its own.
Because the Josephson junction has only two terminals — going in and coming out, like a diode — it would have to form part of a more complex circuit.
Faris claims that unlike the Josephson junction, the quiteron is insensitive to stray magnetic fields, and returns to equilibrium automatically when the external excitation is turned off.
Another big plus is that its two separate states are very different — it is easy for other devices to detect which ‘state’ a quiteron switch is in.
The switching speed looks good too.
Faris is sure that it is lower than 300 picoseconds, although he does not have the equipment to prove his prediction that it is less than 50 picoseconds (10 -12 seconds).
Transistors, however, have a lower limit of 20 picoseconds.
The size of the device — which Faris expects to be able to scale down to 0.1 micrometres across — makes it suitable for use in very and ultra-large scale integrated circuits.
The low heat dissipation will also help, because the device can be packed more densely on the chip.
Faris thinks the quiteron could compete with semiconductor transistors, but the catch may be the cost — which IBM will not reveal at this stage.
Robot taps wells that other drills cannot reach
THE OIL-DRILLING business is in for a shake-up if a new drill that will be tested this month at an abandoned well near San Francisco is successful.
The people who designed the drill say it is capable of drilling for oil in almost any direction, and will penetrate deposits that today's drills cannot reach.
The advantage of the device, called the ‘Robot Drill’ is that it can bore through rock at angles above 60o to vertical — which is the limit that existing so-called reach drilling can manage.
Also, operators at the surface can reel in the drill like a fishing line, and replace the bit in one tenth the time it takes with conventional systems.
The Robot Drill works by gripping the sides of its own hole, and anchoring itself until the bit has made space in which it can move on.
It can drill around corners, sideways, in a curve, and even uphill.
The bit anchors itself in one of two ways.
Either hydraulic ‘bladders’ or hydraulic pistons expand to grip the sides of the well, then retract so the bit can advance.
Whichever device is used depends on the conditions — the bladder is more suitable for soft rock.
Recent advances in sensing devices, which tell the operators what the drill is doing underground, have made the Robot Drill possible.
It was the brainchild of Robert Horstmeyer, a graduate of Stanford University in California.
Horstmeyer built and tested a working model of the drill at Stanford, and in return gave the university stock in his company, Advanced Drilling.
Horstmeyer says that oil drilling is tied to an 80-year-old principle of brute force — adding weight to rotary drills and using the force of gravity.
The methods have been refined over the years, but not radically changed.
The inventor wants to recover oil from abandoned wells which rotary drills cannot reach.
Reaching these wells will involve linking the drill to sophisticated sensing devices which can detect oil-bearing formations.
Horstmeyer has raised $200 000 from 32 investors, all with connections in the oil industry, to launch Advanced Drilling.
He expects to raise more money from a small corporations which will pay for 12 months research and development work at the abandoned well.
If the drill is a success, it could reduce the numbers of offshore rigs needed for drilling at sea.
It could also find applications in coal mining, geothermal wells, and for pipe conduits under roads, where it is not practical to drill straight down.
State adviser banks on new technology
ONE OF the Department of Industry's top scientists is leaving to advise Barclays Bank on investing in new technology.
Colin Hicks, the technical assistant to Oscar Roith, the department's chief scientist and engineer, will join a ‘high technology’ unit at Barclays to identity areas in which the bank can lend money.
Hicks, whose salary at the bank will be paid by the department, will rejoin the civil service after 18 months.
He says he hopes to gain ‘a different branch of experience through getting an insight into the financial world’.
Hicks, 36, started his career in chemistry research.
‘I think that the banks have been a little frightened of new technologies.
Anything that I can do to point out that technology is not so high-risk as many think will be in the UK's interests.’
The new recruit will increase to six the people in Barclays' unit.
Nick Moore, the team's leader, is a banker who previously spent two years on secondment to the Department of Industry.
Moore says that the bank has developed a general policy that loans to small, high-technology firms can provide a good source of business.
One of the main jobs of the unit is to advise branch managers about technical projects that are worth backing.
According to Moore, banks have never been particularly reluctant to back high technology ventures.
‘What we are doing now is to make it a lot easier for a person with a good idea to get financial support.’
One result of Barclays's policy is the number of high-technology firms to which it is lending money under what it calls its business start loan scheme.
Through this, the bank lends cash to small enterprises, who repay the loans in the form of a levy on what it sells.
Barclays defines as ‘high tech’ 46 of the 371 businesses it supports through the scheme.
Another British bank, the National Westminster, is also planning to cash in on science and technology.
It has drawn up a list of some 30 technical consultants, with interests ranging from marine science to energy, which the bank will call in for advice on esoteric projects that it is asked to fund.
Names on the list include the Production Engineering Research Association, Cranfield Institute of Technology and the University of Manchester Institute of Science and Technology.
The one stumbling block is that people who come to the bank for loans have to pay half the consultant's fee — which could come to several hundred pounds.
Barclays provides its services for free.
One — armed rotor
AT FIRST sight, this wind turbine in West Germany (below) appears to be missing a rotor blade.
But the scientists who designed it, at the University of Stuttgart, believe the single-bladed rotor will power wind turbines of the future.
Wind power enthusiasts claim that a big advantage over solar power is that it is not necessary to cover the whole of the ‘harvest area’.
The actual hardware, the turbine blades, covers only 2.3 per cent of the area exposed to the wind.
But exposing a large, slender structure to the elements creates problems.
When the wind gusts, rotors need either to flex or be very strong.
Professor Franz Wortmann, of the institute of aerodynamics at Stuttgart, believes that a single-bladed rotor can solve some of the problems.
He has built a test tower, with an eight-metre diameter rotor, to prove it.
‘We started from the point of making the mass as low as possible,’ Wortmann says, ‘We found that by avoiding the turbulence of two rotors, we were able to achieve a rotor speed of 450 kilometres per hour at the tip — the fastest in the world.’
The next step will be to build a bigger turbine, with a span of 50 metres.
This may require new materials — the experimental rotor is built of wood, which Wortmann says has the best damping.
Graphic example of ideologically — sound computing
IN the past few years, the cooperative movement in Britain has gained more of a reputation for shoring up outdated technologies than for pioneering new ones.
But the success of a small co-op in London called Computercraft could soon be changing all that.
Three and a half years ago, six computer programmers gave up their regular jobs to form Computercraft.
Their idea was to set up a cooperative to supply computer skills to voluntary groups and other co-ops, and to develop new software for the purpose.
Most importantly, they wanted to prove that a cooperative venture could compete on the open market with conventional firms — while turning down work that did not fit its principles.
If Computercraft achieves its target of a £200 000 turnover this year (so far it has doubled every year), it will be well on the way to proving that its ideas work.
It will also have learned a few lessons in how not to go about setting up a business.
The first lesson was not to run before you can walk.
‘It was a mistake to try to go too fast,’ says one of the founders, Richard Collings.
‘We all gave up our jobs, so right away we had six wages to pay.
This lead to tensions and conflicts.’
Another lesson Computercraft learned was to sort out the politics before getting started.
But when the business started rolling in, there was less time for arguments.
One of the co-op's big successes was designing the software for a computer graphics system called the Bit Stik.
The Bit Stik itself is a hand-held joystick control, which links up with an Apple II microcomputer.
It was the invention of a team of plastics engineers and graphics designers, who formed a company called Robocom.
At the end of 1981, Robocom commissioned Computercraft to write the software for the Bit Stik.
It was on the market six months later.
The strength of the system is it allows someone with no knowledge whatever of computers to draw high-quality graphics on a comparatively low-powered microcomputer.
It sidesteps the usual limitations of screen resolution by a powerful ‘zoom’ mode which enables the operator to enter fine detail, then to shrink it until it becomes virtually invisible.
This means that the only limitation in detail is the type of disc storage available.
Projects such as the
Bit Stik have enabled Computercraft to carry out more idealistic projects — while paying realistic wages to the members.
The group's philosophy is that computers should increase, rather than decrease, workers' participation in industry, For example, large cooperatives could install a computer in canteens, on which workers could experiment with different ways of management, or discover various implications of increasing wages, for example .
PATENTS
State secret
FEARS that the Trademarks Registry might be moved out of London have been allayed.
Instead it is leaving the Patent Office's building in Chancery Lane for twelfth and thirteenth floors of state House in High Holborn.
While the move will reassure metropolitan-minded trademark agents — who feared they might have ended up dealing with an office in Wales — it will create some problems.
State House already houses a recruiting office for the Royal Navy and Marines, and visitors must apply for a temporary security pass at the ground floor entrance.
The registry says these passes will be ‘readily available’— which is obviously incompatible with military security.
And the agents are likely to rebel against time-wasting vetting every time they go to work.
Timely turn-off
ROBERT FRANKLIN of Los Gatos, California, has come up with a neat way of ensuring that electric gadgets such as irons and hair curlers turn themselves off when left unattended.
This would save energy and cut down the risk of fires.
PCT application 82/03520 explains how an automatic shutoff unit can either be built into a domestic appliance or installed as an add-on unit to existing equipment.
The user pre-sets the timer to put a limit on how long the appliance may stay on while not in use.
A sensor in the appliance detects motion or touch, and starts the timer as soon as the appliance is put down.
It resets the timer each time the appliance is picked up.
The timer sounds an audible alarm when it is about to run out, and switch off.
If the user wants to keep the appliance switched on, he touches it to trigger the sensor and reset the timer.
If the alarm gets no response, the timer goes ahead and switches off in the interest of safety and economy.
BP flies an alternative kite
OIL GIANT BP is looking hard at alternative sources of energy.
The company is building an experimental 30-kilowatt solar power station near Southampton, and has filed a string of patents on an idea for wind-assisted oil tankers.
British patent application 2 098 946 outlines a plan for a kite sail for ships, while 2098950 gives some details of how to launch it in the air.
The main sail is a vast kite folded and packed in a tube like a gun barrel on the ship's deck.
It is attached by a line to a much smaller pilot kite, stored in a compressed-air launcher alongside.
The launcher shoots out the pilot kite, which opens, catches the wind, and pulls out the main kite.
This then opens, and flies high over the ship from the end of a strong cable.
BP suggests that, apart from assisting oil tankers in long hauls across the ocean, the kite could be a useful platform for photographic or radar equipment.
It could also carry pollution monitors, crop sprayers or telecommunications equipment.
The idea of the kite sail itself is not new (New Scientist , vol 88 p 700).
Its proponents claim that it has the advantage of functioning at high altitudes, where winds are strong and stable.
It would also be easy to take down and stow in stormy weather.
Most importantly, it should be cheaper than some grandiose schemes being floated to bring back the age of sail.
Hells briefcase
TAKESHI IMAI, of Sao Paulo Brazil, has filed a European application in German on a unique form of personal transport.
Application 64 141 describes a miniature motor cycle which folds down into a briefcase.
The driver lets the train take the strain for the main journey.
On arrival, he opens up the briefcase to reveal his personal transport.
It looks rather like a motorised version of a child's two-wheeled scooter, with upright handlebars.
But instead of scooting, the rider stands on two side plates, while a small petrol engine drives the rear wheel.
Perpetual folly
JOHANN SCHYMS of Manosque, France, may be in for an expensive disappointment.
He has filed a PCT application (82/04174) in 30 countries for what is unashamedly a perpetual motion machine.
The old British patent laws prohibited applications for perpetual motion machines as unworkable and a waste of Patent  Office time.
Under current laws there is no such prohibition.
Schyns has re-invented the old idea of a wheel with unbalanced spokes.
Twenty four spokes slide over a fixed cam, so that as they move they change length and unbalance the wheel.
The result, says the inventor, is that the wheel is permanently out of balance and forced to rotate.
So it produces usable power for an electric generator, without any input.
Unfortunately, as with all other perpetual motion machines, it will grind to a halt because of friction in the moving parts.
The inventor will then find his very heavy investment in patent filing fees wasted.
Smokey blues
ANDREW BOETTNER of California has filed a PCT application on a gadget to make life easier for singers in smokey nightclubs.
It is a humidifier clipped to the microphone.
The device contains a carbon dioxide cylinder which released gas into a coiled chamber.
A wick supplies the chamber with distilled water from a reservoir.
As the gas leaks out of the coiled chamber it picks up water and forms a mist around the singer's head.
It should last four hours, the inventor claims.
Let your calculator do the talking
A BRAZILIAN company has filed an international (PCT) application on a card calculator which identifies its owner.
It is a security device for banking or shopping by telephone.
Application 82/04169, filed by Shause sA, describes a modification of calculators that emit different bleep tones when each key is pressed.
This one has a pre-programmed sequence, which corresponds to the owner's individual code.
To identify himself, the shopper dials into the teleshopping system, and triggers the card's memory by tapping out his code number.
The decoder at the other end converts the sequence of beeps back into a code which identifies the caller.
Only the card's genuine owner knows what sequence of keys to press.
Viruses, cancer and acute Infection
Viruses attack cells by several distinct routes.
The more we know of the details, the more possible it becomes to control them
Andrew Scott
THE PROCESS of viral infection has been aptly described as an act of hijack.
Viruses invade animal, plant and bacterial cells, and commandeer the complex molecular machinery of the cell for their own uses — most notably the rapid production and release of more viruses.
Many aspects of this biological piracy remain poorly understood and research into the mysteries of viral infection is one of the most active areas of study in the whole of biology.
The complexity of these ‘simplest’ forms of life is sometimes bewildering.
To describe viruses in general terms is certainly simple enough: they consist of a piece of genetic material (DNA or RNA) encased within a protein coat.
Sometimes the protein coat is itself enclosed within a fatty membrane.
The genetic material may be as small as a single gene, while some protein coats are made of multiple copies of only one specific protein molecule.
Other viruses have a complex structure in which many different proteins are arranged in a highly ordered way around a large piece of DNA or RNA.
To trace the life cycles of these various types of virus is far from easy.
The paths that viruses pursue when they infect begin to diverge as soon as they encounter the outside of the cells they invade.
Before a virus can infect an animal cell it must first bind to specific receptor molecules embedded in the cell membrane.
The receptors are probably glycoproteins (proteins with regions of carbohydrate attached) which perform some important function in the normal activity of the cell.
The vital coat proteins have presumably evolved sites that will bind to these glycoproteins, which then serve as the unwitting doormen, allowing viruses to enter the cell.
There is considerable debate about how viruses actually get inside animal cells and the mechanism of entry probably varies, depending on the type of virus and cell involved (see figure p 374).
One idea is that viruses can simply pass through the cell membrane, perhaps aided in some way by the receptor protein (B 1 in Figure).
But a lot of evidence suggests that entry occurs by endocytosis — a well-documented process by which cells take up material from their environment.
The cell membrane first of all folds inwards to form a deep pit enclosing the virus (B 2 ).
Once the virus is completely surrounded the spherical pit breaks off and reseals to leave the virus inside the cell but enclosed within a membrane coat.
When two membranes touch
A different mechanism has been suggested for those viruses that are already enclosed within a membrane in their free-living state.
When two membranes touch one another they can fuse into one, and fusion of the viral and cell membranes in this way could allow the virus to enter (B 3 ).
Dr Kai Simons and his colleagues at the European Molecular Biology Laboratory recently undertook a detailed study of the entry of Semliki Forest virus (which can cause encephalitis in mice) into animal cells.
Simons claims that this work provides the first reliable description of how an animal virus enters the cell and initiates infection.
It came up with a complex route which involves both endocytosis and fusion.
The process begins when the Semliki Forest virus, which is enveloped in a membrane, enters the cell by endocytosis, leaving the virus surrounded by a double membrane (B4).
The outer membrane of this double-membraned structure then fuses with the membrane of a cell body called a lysosome.
Lysosomes contain enzymes which digest and modify material brought into the cell by endocytosis.
As shown in the Figure, the virus escapes the action of these enzymes by fusion between the viral and lysosomal membranes.
This releases free viruses into the cytoplasm of the cell.
Simons' group has also demonstrated that several other viruses, including influenza virus, also follow the entry path used by the Semliki Forest virus.
If this route proves to be common to many animal viruses it might point to new ways in which viral infections could be attacked with drugs.
Viruses often seem to enter bacterial cells by a completely different process in which the viral protein remains on the outside of the bacterial membrane while the genetic material is ‘injected’ into the cell.
Viruses get inside plant cells mainly by direct entry at sites of cell damage, often caused by the piercing mouthparts of insects and other animals that carry the viruses.
Once inside an animal, cell viruses usually disintegrate into separated protein molecules and genetic material (C).
Again, the mechanism is unclear.
It may be the spontaneous result of exposing the virus to the general chemical environment of the cell; or specific enzymes, either carried by the virus or present in the cell, might catalyse the break-up.
The act of piracy can then proceed; the viral proteins and genes exploit the raw materials and enzymes of the cell to manufacture more viruses.
This process can follow many complex and varied paths depending on the type of virus involved, but, in general, two main tasks must be accomplished.
The genetic information stored in the viral DNA or RNA must be used to produce the viral proteins that it codes for (D in Figure).
Secondly, the viral genetic material must be replicated many times to provide a copy for each new virus particle (E).
The genes of viruses can be either double or single strands — DNA or RNA (See chart).
This means that there are at least four possible pathways of gene replication.
Of course all the paths are based on the assembly of complementary DNA or RNA strands according to the familiar base-pairing rules of James Watson and Francis Crick.
The simplest viruses rely on the  enzymes of the infected cell to perform both protein synthesis and gene replication.
Some Parvoviruses (which can cause abnormal fetal development and defects of growing tissues in rodents), for example, contain only a single gene.
This gene codes for a protein molecule which later splits into the three proteins of the virus coat.
The enzymes of the infected cell copy the gene into messenger RNA.
The cells then use their own protein-synthesising machinery to translate the messenger RNA into the viral protein.
The infected cell enzymes also link together the nucleotide building blocks of DNA into copies of the virus genetic material, which are then packaged into the newly-made protein coats and released from the cell.
Each step in the viral life cycle is catalysed by enzymes from the infected cell which would normally be performing similar tasks in the life cycle of the cell.
This is the real subtlety of viral infection.
Viruses with enzymes
At the other end of the scale are viruses which contain more than 200 genes.
These genes hold the information needed to make many structural proteins and enzymes peculiar to the virus.
The enzymes are used to catalyse various steps in the viral life cycle, including the often specialised tasks involved in replicating the different types of genetic material and producing viral messenger RNA.
Viruses that produce many of their own enzymes are more versatile than their simpler colleagues, but even the most complex viruses depend at some stage on the proteins of the infected cell.
Once the genetic material of the virus has been replicated and large amounts of the coat proteins have been made, new viruses are assembled.
For many viruses (such as E-F in Figure), this seems to occur spontaneously, but in other cases (shown by route D-F) it is assisted by special viral proteins.
Completed viruses are then released from the cell.
At least some animal viruses are released by a budding outwards of the cell membrane (reversing the process of endocytosis) to produce a free virus surrounded by a piece of membrane taken from the infected cell (G in Figure 2).
After release, viruses remain inactive until they come into contact with and infect another cell.
Thus the infection spreads through the tissue.
The cycle of infection outlined so far is the pathway of acute viral infection, as in rabies or influenza, in which rapid replication is followed by the release of new viruses to attack other cells.
In most cases the infected cells eventually disintegrate and die, their own metabolism fatally disrupted by the presence of the virus.
The disintegration of infected cells provides another mechanism for the release of newly-formed viruses.
Acute infections cause many different diseases depending on the types of viruses, animals and cells involved.
Animals fight the infection with their immune system (which can produce antibodies capable of neutralising viruses or can kill infected cells) and by making interferon, the cell's natural anti-viral drug.
But some virus infections can follow another path, other than the acute cycle of replication.
This alternative path leads to integration of the viral genetic material into the DNA of the infected cell's chromosomes (I).
All of us probably carry viral genes, integrated into our cellular DNA.
These genes are duplicated along with the chromosomes at each cell division and can be passed down from parents to their offspring.
Once viral genes have become integrated into chromosomes their activity is usually altered or totally suppressed.
They often seem to be in a ‘latent’ state in which no new viruses are produced and the cells escape the damage caused by acute infections.
Such latent viruses can be re-activated by a variety of poorly understood influences (including ultra violet radiation, carcinogens and other chemicals) to produce a sudden outbreak of the viral disease.
This is what happens when, in some cases, integrated viral genes can convert the infected cell into a rapidly dividing cancer cell.
For most viruses the replicative and integrative pathways appear to be unrelated alternatives.
Very little is known about what triggers most animal viruses to follow either path; indeed it seems possible that integration is a random and accidental process that does not occur at any specific sites on the chromosomes.
Supporting this idea is the observation that if foreign DNA from any source is introduced into a cell, a small proportion of it will eventually integrate into the cell's chromosomes.
This property has been exploited to introduce new genes into the chromosomes of animal cells (New Scientist , vol 95, p 562).
For one very special class of viruses however, integration into the cell's chromosomes appears to be an essential part of their normal life cycle.
These are the retroviruses (shown as H in Figure), whose genetic material is a single strand of RNA.
Retroviruses come supplied with a very interesting viral enzyme called reverse transcriptase (because it reverses the normal process of ‘transcription’ in which DNA is copied into RNA).
This enzyme copies the RNA genetic material of the virus into double-stranded DNA.
The DNA copy is then integrated into the chromosomes, from where it is in turn copied into both messenger RNA (used to produce viral proteins) and the RNA copies of the viral genetic material needed for incorporation into new viruses.
It seems, however, that the viral genes cannot produce proteins or be replicated until they are in the form of integrated DNA.
The DNA of retroviruses is integrated much more readily than the DNA of other viruses, but the mechanism of both forms of integration in animal and plant cells is still poorly understood.
More is known about the process of integration in bacterial cells, and a plausible mechanism has been constructed.
Scientists are extremely interested in the integrative path of viral infection because all of the viruses that have been found to cause tumours (either cancerous or benign) appear to integrate their genetic material into the infected cell's chromosomes.
The suspicion that viruses might cause cancer can be traced back as far as 1911.
In that year Peyton Rous of the Rockefeller Institute in New York reported that solid tumours could be transmitted between chickens by filtered solutions from which all bacterial and animal cells had been removed.
Since these early studies, many viruses have been shown to cause cancer in animals, particularly the retroviruses with their requirement for chromosomal integration as part of their normal life cycle.
Practical and ethical problems make it difficult to prove that viruses cause cancer in humans.
Demonstrating that a virus isolated from a human cancer can cause further cancers in other humans is clearly an unacceptable experiment!
Nevertheless, it seems unlikely that humans enjoy a privileged protection from cancer viruses not shared by the rest of the animal kingdom.
How can viruses induce cells to enter the cycle of rapid multiplication that then leads on to the development of a tumour?
One of the most exciting developments in biology over the past few years has been the identification of the specific genes that allow some viruses to cause cancer.
At least 17 of these ‘cancer genes’ have been identified, and in every case they appear to be identical or very similar to normal genes found in the chromosomes of healthy cells.
This startling discovery has supported the idea that cancer develops when a cell contains too much of a perfectly normal cellular protein.
Alternatively, the protein may be modified so that its activity is increased.
By introducing extra highly-active copies of the gene for one of these proteins into a cell, a tumour virus could bring about increased production of the critical protein.
The precise role of these proteins is not yet known, but is the subject of intensive investigation.
Integration of the viral genes
Nevertheless, some viruses that lack known cancer genes have also been found to induce cancer.
It seems likely that they achieve this by integration of the viral genes next to the cellular copy of a cancer gene.
The cancer gene might then have its activity controlled by the region of the viral DNA that controls the activity of the viral genes.
This could again lead to increased production of the ‘cancer-causing’ protein, transforming the cell into a cancer cell.
These discoveries raise intriguing questions about the relationship between viral genes and the normal genes of the cell.
It seems likely that the tumour viruses originally ‘stole’ their cancer genes from cellular DNA, and it may be that the transfer of genes between viruses and cells is a very common event.
Researchers have recently discovered small regions of genetic material in animal cells that can become detached from the chromosomes, enjoy an independent existence for a while, and then re-integrate at a different chromosomal location.
These mobile pieces of DNA (called transposons) share many features in common with the genetic material of some viruses and it is possible that viruses have evolved from them.
The structure of a cell's genetic material may soon be appreciated to be much more fluid than previously supposed, with a grey area emerging between truly chromosomal genetic material and the mobile genes of transposons, viruses, and as yet undiscovered entities.
Research over the next 10 years should greatly clarify the issue.
From a medical viewpoint, the outline of viral infection given so far presents much too simple a picture.
There are many baffling viral diseases that cannot be readily explained as the result of an acute infection or the integration of viral genes into chromosomes.
Many of these diseases take the form of persistent or chronic infections.
Measles virus, for example, usually follows the cycle of acute infection until it is defeated by our defence mechanisms and the disease disappears.
In a small number of cases, however, the virus can persist in the body for several years, eventually causing a disease called sub-acute sclerosing pan-encephalitis (SSPE).
SSPE is a chronic, progressive form of encephalitis which can cause behavioural changes, dementia,(myoclonic) jerks and eventually death.
The brains of its victims are found to contain areas in which the death of nerve cells is accompanied by demyelination (the break up of the fatty sheath surrounding nerve fibres, which is essential to their correct functioning).
How can measles virus escape the body's natural defences to wreak such havoc?
Much remains unknown about viral persistence but in general it results from stalemate in the battle between the virus and the body.
Persistent infections occupy the middle ground between acute life-threatening infections that can overcome the immune and interferon systems, and infections that readily succumb to these defences — albeit after a short burst of disease.
Persistence can occur if a virus escapes the full force of the defence mechanisms (for example if the patient's immune system is suppressed for any reason), or if the virus is not particularly lethal to the cells it infects.
How viruses persist
Occasionally errors occur in the replicative cycle of a virus and defective viruses begin to appear in cells.
These defective viruses have usually lost a portion of their genetic material or suffered a single mutation that prevents them completing the full replicative cycle.
They may be unable to make some of the viral proteins that should trigger the immune system into action, leading to a weakened immune response against the infection.
At the same time they can interfere with the replication of normal viruses in the cell by using up raw materials.
Thus a balance of forces can result from a weakened infection which induces a weakened immune response, leading to persistence.
The eventual cause of the serious symptoms of persistent infections  may in fact be the immune system, confused by the unusual situation and attacking its own healthy tissues in an auto-immune response.
Such an auto-immune response against nerve cell myelin sheaths is strongly suspected as the cause of multiple sclerosis, and may cause the demyelination seen in SSPE.
Some persistent viruses may find refuge from the immune system by harbouring in regions of the body, such as the nervous system, which are relatively inaccessible to the cells responsible for immunity.
Herpes virus is known to persist in the nervous system between recurrent outbreaks of symptoms.
Sometimes antibodies can be produced that bind to a virus but do not succeed in preventing it from entering and infecting cells (called non-neutralising antibodies).
In both these situations the residual effects of the immune response might restrict the damage caused by the virus  sufficiently to allow a persistent infection to be tolerated by the body.
What ever the mechanisms involved, persistent infections are implicated in many troublesome and damaging diseases such as SSPE, multiple sclerosis, arthritis, recurrent herpes and many more.
When considered alongside the effects of acute infections such as colds, influenza, meningitis and rabies) and the probable involvement of some viruses in human cancer, then the need for effective therapies to combat viral disease becomes clearer.
The forgotten energy crisis
Energy for cooking is one of the biggest human needs.
Yet planners  ignore it.
To do so invites a human and ecological catastrophe
Anil Agarwal
MENTION the energy crisis and what comes to mind?
The gas-guzzlers of the American freeways?
Spot-prices on the Rotterdam oil market?
It is easy to forget that most of the energy that the real world consumes is in the million of stoves burning gas, kerosene, wood and coal in homes across the Third World.
Even though India is the world's tenth largest industrial power, half of the energy its people consume, excluding animal energy, is spent on cooking food.
This is nearly twice what agriculture and industry consume.
In many underdeveloped African countries, cooking may take three-quarters of all energy.
In most developed countries, cooking would account for less than 5 per cent of national energy consumption.
The amount used on cooking is high in absolute as well as in relative terms.
A Third World family of six would commonly burn about 3.6 tonnes of wood per year, nearly 12 times the average that a British family consumes.
The wood-stoves that cook the food are extremely inefficient.
However, energy planners in the Third World tend to overlook this essential need even though it is the most crucial for human survival and the most sensitive to environmental conditions.
For India, despite the massive development of oil and coal, non-commercial sources of energy, such as firewood, agricultural wastes and cow dung, are crucial.
In 1975–76, 133 million tonnes of firewood provided India with 28 per cent of its total energy.
Another 73 million tonnes of dung and 41 million tonnes of agricultural wastes are burnt each year.
These non-commercial sources provide as much as 87 per cent of India's cooking energy.
Coal and kerosene contributed only 8 per cent of the total cooking energy in 1953–54, and rose to a peak of 14 per cent in 1970–71.
After the oil price rise, this dropped to 13 per cent in 1975–76.
It is a fallacy, although a common one, that firewood, coal, dung and  agricultural wastes are used mainly in the villages.
As much as 56 per cent of the domestic energy consumed in cities comes from non-commercial sources.
According to India's planning commission, nearly three-quarters of households in towns and cities depend on non-commercial energy for cooking.
Firewood provides half the cooking energy in Indian cities and 70 per cent in villages.
The price of coal and kerosene is rising rapidly, and the forests are being denuded.
People will find it progressively difficult to meet their basic need for cooking energy.
As a result, the price of both commercial and so-called non-commercial fuels is rising rapidly.
Between 1970–71 and 1980–81, per capita income rose by 143 per cent, and the wholesale prices of all commodities rose by 150 per cent .
But the wholesale prices of commercial fuels — power, light and lubricants — rose by 264 per cent.
In many cities the price of firewood has nearly doubled in the past six years.
The demand for firewood now far outstrips supply.
Populous Uttar Pradesh, for instance, produced only 18 million cu.m.
By 2000 the demand will be 63 million cu.m.
Experts know little about how people are coping, but research in the past couple of years shows that for the majority of India's people the cooking energy crisis is already here.
In hills and plains, women and children spend hours travelling long distances to collect fuel.
In Dwing, a village in the high Garhwal Himalayas of Uttar Pradesh, women walk at least 10 kilometres three out of four days, for an average of seven hours per day, to bring back about 25 kg of wood with each headload.
Even rich villages have their energy-poor.
In Navli, a prosperous village close to the famous cooperative Amul Dairy in Gujarat, irrigation, cash crop farming and animal husbandry have made several families very rich.
But with firewood supplies dwindling, and prices of imported firewood rising farmers with large numbers of cattle have set up biogas plants and large landowners have started collecting their crop residues for fuel.
So even though more cow dung and crop-residues are available, people who have no land face increasing hardships.
They are now totally dependent on the landlords.
As one poor women in the village laments: ‘There isn't enough money for food, so where is the question of buying firewood?
We sometimes uproot small plants from around fences.
When we are caught, we are fined.
We have lost our livelihood and, it seems, our lives too.’
To what extent these isolated scenes of rural India add up to a true picture of the situation across the country is difficult to say.
Studies of India's energy economy are rare, and knowledge of trends even rarer.
But it can be assumed that many millions of poor rural women are caught in a vicious cycle: they eat food to get human energy, and then spend all this energy in producing food and collecting the energy needed to cook it.
There is little else left in their lives.
We know even less about supplies of cooking energy in urban India, especially in small towns.
Nearly threequarters of firewood and about half of the dung in urban India is purchased.
A substantial part of this firewood is brought in from the villages to be sold in the cities, although nobody really knows how much.
Thousands of people carry firewood on their heads to Ranchi every day from nearby villages.
All the three daytime trains from Dhronachalam to Kurnool in Andhra Pradesh bring with them a garland of firewood bundles strung outside carriage windows.
In Kurnool, these trains are known as ‘Firewood Specials’.
The Indian Institute of Science in Bangalore has shown that the city draws in nearly half a million tonnes of firewood every year.
Most of it comes on diesel trucks.
Considering that most woodstoves have an efficiency of only 5–10 per cent, for every 100 calories of energy provided by firewood for cooking, 25 calories are spent in the form of imported petroleum to transport this firewood to the city.
Although the government has been pushing liquid petroleum gas (LPG) in metropolitan cities, its supply remains restricted to the upper middle class and the demand far outstrips the supply.
In towns, kerosene is the main fuel for cooking.
It is now almost certain that more people in Indian cities will become dependent on kerosene for cooking in the near future.
Bombay's population, 1 per cent of the national population, burns one-tenth of the kerosene consumed in the country.
In 1981 the government had to resort to crash purchases of kerosene to meet shortages.
In fact, the erratic supplies of kerosene and LPG make it impossible for many middle-class families to rely on one source of energy.
In Calcutta, where the electricity supply is erratic, it can take a month to replace an exhausted LPG cylinder.
Because the supply of kerosene is not assured, many families turn to a fourth alternative: coal.
But as new houses generally do not have chimneys, the use of ‘angithis’(coal stoves) means a lot of smoke.
Many landlords in Calcutta, for example, make prospective tenants promise not to burn coal.
And few families can afford all four forms of cooker.
There is still no study that describes what families at different levels of earning spend on cooking energy, and how this changes over time.
In cities, poor families spend a much larger proportion on energy-often as much as 12–15 per cent of their income.
For a relatively prosperous family, spending on cooking probably drops to less than 5 per cent of the annual income.
Considering that poor families ought to spend about 80–90 per cent of their income on food, rising fuel prices mean that they must be eating less.
For an already malnourished population, this is unfortunate.
Reports from Bangladesh, Nepal and Pakistan show that some rural families may be spending a quarter of their incomes on fuel.
The shortage of cooking energy not only causes problems with nutrition, but also spreads disease.
The Food and Agriculture Organisation's document Agriculture.
Toward 2000 , points out that with the production of fuelwood expected to fall short by 40 per cent, ‘many poor people will not be able to cook their food adequately.
This can have serious nutritional and health consequences.
The digestibility of food will decrease, and also the incidence of parasites ingested with insufficiently cooked meat will rise.
There are reports of this happening already.’
The already-widespread incidence of scabies in India can certainly be attributed to inadequate supplies of water and fuel.
If people cannot heat water in winter, they will not wash.
The result: scabies.
So how are the poor trying to meet the energy crunch?
Who, for example, uses firewood?
There is now definite evidence that villagers are trying to meet their energy needs by substituting one resource for another — agricultural wastes for firewood, for example.
Contrary to popular belief, recent studies reveal that wood (especially firewood in the shape of logs rather than small twigs and branches) has become so scarce that in many villages only the rich can afford to buy it.
The bulk of firewood burned today is in twigs and branches.
The poor rarely fell trees: they mainly lop off small branches, twigs, roots and dead wood.
Threat of market forces
In Pura, a village in Kamataka, Professor Amulva Reddy and his colleagues from the Indian Institute of Science found that 96 per cent of the wood that poor families burned was in the form of twigs.
The rest was small branches.
In contrast, rich households, which get wood from their own land, depend on logs.
They consume nearly one-fifth of the village's firewood.
Thus Reddy concludes that gathered firewood, upon which three-quarters of the people of Pura depend, does not contribute to deforestation.
There may even be a male-female dichotomy on the issue.
Among the poor, it is women and children who collect firewood, and they seldom cut down trees.
The men, who are interested in cash, are more liable to go for the big wood.
It is the commercialisation of fuel that poses the greatest threat to India's forests.
In the cities, even traditionally non-commercial fuels are going on the market.
The same trend happens in the rural areas, although at a slower pace.
And it is the relatively rich, in small towns and on the fringes of big cities, who create this demand.
The headloaders of Ranchi and the ‘firewood specials’ of Kurnool are responses to this.
In the process, the landless poor, whose numbers grow every day, try to earn a pittance.
The pressure on trees differs between regions.
Families in the hills not only consume 25 per cent more energy than those on the plains, they also consume more firewood.
In desert and hilly regions, where agricultural production is low, people obtain two-thirds of their energy from firewood.
In the plains, its contribution drops to 37 per cent, and that of crop residues goes up to 31 per cent .
Thus firewood is the most important source of energy in desert areas, where vegetation is sparse.
The situation is ecologically disastrous.
The rising number of landless and marginal farmers poses a serious challenge.
In 1977, 24 million households, with a total population of 114 million, each had less than 0.4 hectares of land.
With firewood declining, these people will turn more to cow dung, and become more dependent on landowners.
Any trend toward the commercialisation of fuels such as dung and plant residues, or the introduction of technology such as biogas plants to allow land-owning families to exploit these resources themselves, will inevitably hit the landless poor.
Certainly they could easily find themselves short of energy amid plenty.
While much has been written about the concentration of land and cattle-holdings, there is no information about who owns trees.
A study from a village in Bangladesh shows that 16 per cent of its families owned 55 per cent of the cropped land, and 46 per cent of the cattle.
They owned 80 per cent of the trees, and took a keen interest in protecting them.
The old feudal relationship, in which a landlord took care of his agricultural labourers, is rapidly disappearing under the onslaught of the cash economy.
Many new farmers leave the village poor to fend for themselves.
Thus, even if biomass energy increased, the poorest villagers may find that in periods when employment is scarce, there is no livelihood better than to collect some wood and sell it.
The environment is of no concern to people who have to scrounge around for plant waste by the roadside for their own stoves.
In Gujarat, two industrial consultants recently investigated why the process developed by the Cotton Technology Research Laboratory in Bombay to make boards from cotton stalks had not been adopted, although wood was expensive.
They visited three tribal villages where cotton stalks are a major crop residue: Goral, Kanpur and Choriwad, They found that, when wood became expensive, the poor villagers relied on cotton stalks as fuel.
A big farmer admitted that he had been selling cotton stalks to agricultural labourers, a new trend in the region.
Dr B. S. Pathak, of the Punjab Agricultural University, has studied the potential of agricultural wastes in a village in the district of Ludhiana.
Bhundri is a relatively rich village, where several farms have tractors, and all the farmers practise green revolution agriculture.
Although the village is rich, cooking accounts for 98 per cent of the energy its householders consume.
They burn nearly three-quarters of their animal wastes as fuel.
Pathak's calculations yield an amazing result.
After the village has met all its needs for fodder, the energy potential of the remaining crop wastes and animal wastes is enough to fuel the village (for cooking, pumping water, making fertilisers) and still leave a surplus.
But will the increased availability of energy in the village really mean more energy for the very poor?
There is no evidence to believe that this would be so.
Even in fuel-rich Bhundri, three families have to collect plants to burn as fuel.
If a government in the Third World wants to meet the energy needs of its people without destroying the environment or creating human misery, it has to adopt an integrated national policy on energy for cooking.
To date, rural planners have virtually ignored the need for cooking energy.
The few attempts to increase supplies have been marked only by ad hoc efforts based on technology, with biogas plants, solar cookers or fuelwood plantations promoted as universal solutions.
The pattern of the supply and demand for cooking energy is extremely complex.
People live in different ecological regions, different types of settlements, and have different levels of income.
Attempts to introduce new cooking-energy technologies will have to be far more systematic.
Each source of energy or technology has its own economic, social and ecological niche, and it is only in that niche that it can prosper.
The ever popular blanket solutions, such as biogas plants for all and sundry, will not work.
Identifying these niches can bring surprises.
Solar cookers, for instance, instead of becoming the answer to the needs of poor villagers and thus easing the pressure of firewood, could become a tool for the middle classes.
There, they would reduce the need for oil products such as kerosene and petroleum gas.
Not only can the middle classes afford solar cookers, they are also the people that the rising price of petroleum products hits the most.
They may, therefore, be more keen to save energy than the fuel-gathering poor.
A government supermarket in New Delhi has been selling 10 solar cookers every day for the past few months for about £20 each.
Shops in Gujarat have already sold more than 7000.
Middle-class families get their investment back in two to three years if they cook half their lunch every day in the cooker.
A national policy on cooking energy also has to take into account the increasing interaction between the energy needs of the urban and rural areas.
It must also make full use of all sources of energy.
India has launched many social forestry programmes with the professed intention of meeting community needs such as firewood for cooking.
But in reality, none of these programmes is helping to increase the production of firewood.
The increase supply goes to those who can pay — the paper industry and the urban consumer.
To make it profitable to grow wood, the state of Gujarat, where thousands of farmers have turned over good irrigated land to tree farming, has even proposed to build generating stations fuelled with wood.
But if this were to happen, only the rich would benefit.
Thus, a second green revolution may be in the offing hereby big energy production increases, but the energy-poor still starve.
Gerald Leach, of the International Institute for Environment and Development in London, points out that, on a global basis, there is no real shortage of oil products for basic human needs.
But each country will have to look at its own resources and solutions.
India, at least, despite its large population, is not short of resources — wood, biogas, animal waste and plants.
Cooking energy is clearly one of the biggest human needs, second only to food.
The problem in meeting this need is not lack of resources, technologies or knowledge, but of political will and organisation.
It is a case of huge inequalities, between and within nations, and of starvation amid plenty.
The neglected science of UFOs
The study of UFOs has tended to attract cranks rather than scientists, for good reasons.
But behind the more bizarre, outlandish aspects of ufology lie some phenomena worthy of study
Jenny Randles and Peter Warrington
THREE years ago James Oberg won the New Scientist /Cutty Sark competition for his essay on unidentified flying objects.
His entry, ‘The failure of the science of ufology’, attacked the very existence of such a subject (New Scientist , vol 84, p 102).
But was that the end of the story?
Is there indeed no science to be found in the study of the phenomena of UFOs?
The first person in Britain to receive a grant for a scientific study of the UFO phenomenon is a sociologist, Shirley Melver of York University.
She took her doctorate in the study of the UFO movement itself, and has worked with several British researchers on what has turned out to be an illuminating project.
Her social questionnaires have delved into the motivations of those individuals involved with the subject, and she has tried to discover their opinions, social status, and political and religious affiliations.
The UFO community works principally through belief, not only in the existence of inexplicable UFOs, but also, usually, in some quite bizarre theory of their origin, often that they are a form of alien technology.
Ufologists include a cross-section of the population spanning pseudo-religious fanatics to reasonably careful researchers.
Indeed it is surprising that more studies have not been conducted in a field that, whatever else it may be, is surely one of the world's most remarkable systems of belief.
These social-science studies have shown that the average lifetime of a ufologist is about two years, after which the individual faces a crisis point.
He, or she, finds that the reality of the subject is not what he desired it to be and that he cannot even prove its basic tenets.
This relegates the whole subject to one of belief, of having faith in a non-provable hypothesis.
Indeed it is possible that many people recognise subconsciously that the hypothesis is not merely unprovable, but false; certainly many drift away from an active interest in the subject.
The bulk of those who remain interested in UFOs seem less likely to have been motivated by personal experience and are more willing to undergo the reappraisal needed to rationalise their approach.
The first symptom of such a change is to accept that all past data collected on UFOs are, in scientific terms, largely useless.
This fact is reflected in the falling number of reports collected by the British UFO Research Association.
A switch of emphasis, backed up by education, internal accreditisation and a definition of standards, has led the association away from superficial reports on all observations of UFOs to more detailed case-files on selected events.
In this way researchers are able to search for direct comparisons between reports and to isolate categories of phenomena.
It turns out that there is no single mythical ‘UFO phenomenon’; instead there is a collection of phenomena that are probably independent and which may well require several different mechanisms to explain them all.
Such phenomena are not manifestations of alien technology; rather, they are phenomena that occur naturally here on Earth.
Of course many pitfalls may lie in wait at this point of the research.
But it is possible, with caution, to isolate categories of UFO with general characteristics.
An example of one category of UFO, which some researchers have pinpointed, is of objects with an ovoid shape from 1 to 3 metres in diameter, which rotate on a vertical axis, close to the ground, and which appear to emit a wide range of electromagnetic radiation.
Perhaps what is most important is that the nature of such identifiable UFO categories, and the conditions under which they might be observed, are predictable, after careful analysis of the data.
Scientific searches, with appropriate instrumentation, are now able to prove once and for all that these UFOs do exist, and can provide information about their nature.
To distinguish such phenomena from more dubious data, we propose that they should be renamed ‘UAPs’, for unidentified atmospheric phenomena, as this seems to be an appropriate and adequate description.
What is lacking at this stage is for some imaginative research laboratory or university department to contact serious UFO researchers and design an experimental study for these UAPs.
In the US, Harley Rutledge, head of the physics department at Southeast Missouri State University, has conducted a, pilot study, with some encouraging results.
His researchers made excellent observations on 178 separate UAPs which Rutledge has published in Project Identification (Prentice Hall, 1981).
Once there are more data available, and the phenomena are established as real, the way is open for theorising about the nature of UAPs.
But there has already been some progress in this direction.
Michael Persinger, associate professor of psychology at Laurentian University in Ontario, has proposed that some UAPs are a consequence of the piezo-electric effect.
In essence he is arguing that strain in certain types of underground rock can generate an electric signal, which in turn can ionise a column of air above the rock.
The ionised column would move through the atmosphere as the source of strain moved underground.
And the ionised air can glow, taking on a shape, according to Persinger, similar to that popularly ascribed to many UFOs that fall into the category of UAPs.
Brian Brady at the US Bureau of Mines in Colorado has put the effect described by Persinger to the test.
He subjected quantities of quartz crystal to pressures similar to those occurring in active fault zones in the Earth's crust, and he found that the piezo-electric effect did induce visible ionisation of the surrounding air, just as Persinger predicted.
Persinger has suggested a large number of consequences should his theory indeed be correct.
For example, sightings of UAPs should be concentrated around active fault zones; there should be more in hilly terrain; reservoirs with their attendant stresses on the rock should be focal points for the effect; and the passage of masses of air, such as cold fronts, should release any strain that may have built up.
Persinger's hypothesis thus contains what has long been demanded of ufology: a theory capable either of validation or falsification.
Neither Persinger nor Brady is a ufologist, but certain UFO researchers have come to recognise the importance of their work and set about verifying it.
Paul Devereux, a British researcher into ‘Earth mysteries’, has recently published the results of his preliminary study (Earth Liggts, Turnstone, 1982).
He attempts to show that there is a significant correlation between active fault zones in Britain and areas where UFOs are most often sighted.
One area that has since 1972 been recognised as a region of many UFO sightings is in the Pennine foothills surrounding Leeds and Manchester, an area that also has a high concentration of active faults.
Local inhabitants and police forces talk of a luminous aerial phenomenon, known as the ‘mystery helicopter’ because of its low-level manoeuvrability.
(Surprisingly, Devereux found that this was the only area of active faults that did not have a marked number of UFO reports, but this seems to be a result of his patchy methods of obtaining data.)
In research completed this year, one of us (Randles) has shown that the ‘mystery helicopter’ is a typical UAP and has verified in the field a substantial number of Persinger's postulates.
For example, the study shows a correlation between levels of sighting and the thickness of quartz-bearing rock; that the most active faults, such as the Craven fracture, tend to produce the most spectacular UFO concentrations in local folklore; that there is a direct association between the lights and the presence of reservoirs; and clear indications that the UAP entails atmospheric ionisation.
There are even suggestions that Persinger's idea that weather systems can trigger UAPs might be realistic.
This research will be published in The Pennine UFO Mystery (Granada) this spring.
It is interesting that Rutledge's study of a hill area in Missouri appears also to illustrate several of Persinger's predicted features.
And is it merely coincidence that the two completed studies in the field both revolve around hilly terrain, just as Persinger suggested?
We believe that these preliminary studies strongly indicate that here, at last, is a valid theory for some UFO phenomena, and that what we have called UAPs can now be tested scientifically.
While this search for a physical basis to the UFO phenomenon has been continuing, there has been parallel research into another aspect.
This category is much more controversial and inherently implausible, as it contains the alleged abductions of humans on board a UFO.
The abductors are typically described as ‘alien beings’ and the UFO as a ‘spaceship’.
Serious UFO researchers have come to recognise that these stories are essentially subjective.
Randles, for example, found that while for observations of UAPs the average number of witnesses per sighting was about 2.6, this number fell dramatically for abductions to an average of only 1.3.
And the more bizarre the alleged abduction, the closer this figure tended towards 1.0, or total subjectivity.
Persinger has suggested that these reports might be hallucinations instilled into the witnesses by the effect of ionising radiation in close proximity.
The work of some UFO investigators has also shown apparent comparisons between the physiological effects of close contact with UFOs and temporal lobe epilepsy.
This might support Persinger's hypothesis, as might the fact that the only recent abduction reported in the Pennine area occurred on the Craven fault.
Meanwhile Alvin Lawson, professor of English at California State University, and his colleague, William McCall, a medical hypnotist, have endeavoured to prove whether the details of memories about abduction can be explained purely in terms of the psychology of the percipient.
This would be the case if indeed the events were involuntary hallucinations.
In their initial work, Lawson and McCall put imaginative individuals, screened for lack of UFO knowledge or interest, into a state of controlled hypnosis.
The subjects were then asked to hallucinate a UFO abduction, and the researchers compared the results with memories of allegedly real abductions.
They found marked points of similarity.
Latest tests seem to indicate a 100 per cent correlation between certain modes of abduction imagery and the way the subject was born.
If born by natural means, the subject's entry into the UFO will never be imagined as by way of a bright explosion of light; if born by surgical means, the entry will never be by transport along a tube or tunnel.
Lawson views these methods of entry into the UFO as repressed memories of sudden forced emergence into the world at birth, or of slow travel along the birth canal in the normal way.
Some psychologists still dispute the experiments of Lawson and McCall.
They argue that there is no independent proof that an individual is capable of remembering the birth process.
But, it remains possible that the imagery is a construct based upon that person's memory (as later told to him) of his process of birth.
If this is true then there may be a loophole for the theory; a case where an individual, for some reason or another, such as being abandoned at birth, never discovers how he was born, nor has opportunity to absorb such information unconsciously while a young child.
We have not intended in this article to prove any specific origin for UFO phenomena, or to appeal to the scientific community for greater respect.
But the value of UFO research to science does seem clear.
It is a cross disciplinary topic, offering data in fields as diverse as the psychology of perception, hallucinations, sociology of belief, atmospheric physics, geophysics and several others.
That would appear to make it worthwhile for science to be a little more lenient with the serious UFO researchers and their data.
REVIEW
Successful selection of the sexes
The theory of sex allocation by Eric Charnov,Princeton UP, pp 335, £29.80, pbk £9.65 
Paul Harvey
CHARLES DARWIN in an uncharacteristically generous donation to scientists of later generations, left an unsolved problem.
It was that of sex allocation: what resources should an individual put into male and female reproductive functions either directly or by determining the sex of its offspring?
Darwin seemed near a solution in the first edition of The Descent of Man and Selection in Relation to Sex , but by the second edition he had decided that it was a problem best left ‘for the future’.
R. A. Fisher started to solve the problem in 1930 with the straightforward observation that each of us gets about one-half of our genes from our mother and the other half from our father.
That trivial fact means that, in diploid organisms (those with two sets of chromosomes), both sexes contribute equally to each generation.
Furthermore, if males are in short supply in one generation, they will be selectively favoured by contributing disproportionately to the next generation.
Under many circumstances, the evolutionarily stable allocation to male and female reproductive functions should be about the same.
However, the sex allocation theory that Eric Charnov has developed in his embracing monograph has further implications.
Take two examples.
Females of several parasitic species of wasp sting weevil larvae, beside which they lay a single egg.
If the females release stored sperm, the egg becomes fertilised and develops as a female, otherwise it becomes a male.
Given two populations of hosts, one containing equal numbers of 1.0 and 1.4 mm larvae and the other containing 1.4 and 1.8 mm larvae, in each population more female wasps develop from the larger hosts and more males from the smaller.
This means that adult female wasps are determining the sex of their offspring in response to environmental variation — in this case, changes in host size.
This is because females reared on larger hosts are able to lay more eggs, but males do not gain by being larger.
Apparently far removed from parasitic wasps, individuals of some species of shrimp from temperate and arctic waters undergo sex reversal.
After starting life as males they turn into females, while other shrimps in the same populations spend their whole lives as females.
The proportions of individuals with these alternative life styles differ between populations, so that in some areas of the world all individuals change sex.
The shrimps can live for several years and the average mortality rate in adults within a population is a good predictor of the proportion of individuals within a population which will change sex.
When the life expectancies of the shrimps are short then most of those which start life as males may not survive long enough to become females.
Under such conditions natural selection may favour some individuals occupying the all-female life style.
As is the case with the parasitic wasp, it seems that sex allocation is  occurring in response to environmental variation.
The beauty of Charnov's book is that it uses one simple theoretical technique, hat of the evolutionary stable strategy, to tackle apparently disparate problems in sex allocation theory.
 Furthermore , the equilibrium allocation often reduces to the so-called Shaw-Mohler form, that selection favours mutants which alter life histories so that the per cent gain in fitness through one sex function exceeds the per cent loss through the other sex function.
Within this framework, Charnov deals with sex ratios in dioecious species (those having separate sexes), with the order and timing of sex change in sequential hermaphrodites, with the equilibrium allocation of resources for simultaneous hermaphrodites, with conditions favouring the transition between dioecy and hermaphroditism, and with the selective forces likely to alter the allocation to male versus female function (such as local mate and local resource competition).
But Charnov's feet are firmly on the ground.
He never strays far from elegant applications of the theory to field and laboratory studies, many of them his own.
In pursuit of relevant material, he has worked with or analysed data from parasitic and trap-nesting wasps, shrimps, fishes, barnacles, limpets and plants.
As he develops his theme, he concurrently reviews a wide literature and continually suggests plant and animal groups which will provide tests of alternative hypotheses.
There are numerous cross-references in the book where apparently different problems reduce to the same theoretical form.
My only worry about the book is that Chapters 2 and 3 may deter some readers.
Much of the relevant theory is developed in these early chapters, but not with sufficient care.
Parts are telegraphic, and clarity is sometimes sacrificed for brevity, as with Charnov's treatment of the graphical approach to sex allocation theory in Chapter 3.
And, although I agree with the author that the Shaw-Mohler equation is characterised by ‘its utter simplicity’, it seems a little brutal to derive it in a page of text by introducing 11 variables, when the equation itself can be reduced to three.
Nevertheless, such criticisms are minor compared with the achievements of this book, It is the first book to deal comprehensively with sex allocation theory, and it will surely remain a classic for years to come.
Mind and body in battle
Pain and its conquest by H. B. Gibson,Peter Owen, pp 223, £10.95 
Pat Wall
DR GIBSON is a psychologist who has written on hypnotism and on Hans Eysenck.
It is therefore not surprising that he should here stress the psychological aspects of pain and its control rather than the nuts and bolts of nociceptors, unmyelinated afferents, spinothalamic tracts and those splendid phrases designed to send medical students back to sleep in the belief that they now understand pain mechanisms.
Psychology has recently gained the respectability it should always have had with respect to pain, for two completely irrelevant reasons.
In the good old days of rampant dualism, the mind was rarely mentioned in polite society.
But in the 1960s the gate control theory of pain showed that pain provoking messages proceeding toward the head were the result of interactions between inhibitory and excitatory effects from the periphery which mixed in spinal mechanism.
However, it was also shown that this gate mechanism was controlled by impulses descending from the brain.
Suddenly a mechanism was provided by which the brain (which may or may not be considered in some way related to the mind) could intrude on the elementary processes of message reception and transmission.
Phenomena such as suggestion, attitude, state of mind etc were promptly given a concrete target on which they could operate.
It will be seen that the presence of a receiving target explains nothing but it does nudge two previously separate areas of discourse, the mind and the body, into a common sphere.
Therapies such as cognitive training and coping strategies descended from the air of witchcraft to something solid if jelly-like — the substantia gelatinosa of the spinal cord.
An even more irrelevant discovery exaggerated process.
One aspect of the gate control operates by use of endogenous opiates of which there are three chemically-defined families, the enkephalins, the dynorphins and the endorphins.
One of the best-known facts of the Western world is that the placebo response operates by release of internally-generated opiates.
The inability to confirm this well-known fact has not spoilt the sudden acceptance of the placebo as something with at least a false concrete explanation rather than being some form of gothic magic about which it is better not to speak.
Pain and its Conquest concentrates on perception cognition and emotion, and the ways of manipulating these by verbal and intellectual means rather than concentrating on the more traditional methods of control by cutting, by blocking or the more recent manipulating of existing control systems by chemical or electrical stimulation.
Unfortunately, I could not find either a clear description of what these psychotherapies amount to nor a critical account of the scientific trials to which some of them have been subjected.
Nowhere is this more apparent than in the chapter, ‘Women's pains’.
This subject is a minefield as dangerous for feminists as for chauvinists.
A small number of women, having scrupulously learnt relaxation, self-hypnosis, breath control and their mantra, have the experience of a painfree childbirth.
Another small number of women who have never heard of Lamaze, Velvovski or NW3 have the same experience.
Some women who come from exactly the same culture with the same intent go through absolute hell.
To make it worse, they feel guilty about it; they think they are failures to themselves, traitors to their sex and threats to their babies.
They are wrong.
It is no help to the sufferer or to a solution of the mind-body problem to propose that mind and body are engaged in battle from which the mind should always emerge as victorious.
The search for artificial intelligence
Computers that think by Margaret Hyde Enslow, pp 126, $8.95, pbk $4.95 
Margaret Boden
THIS is a clearly written, but extremely superficial, introduction to the field of artificial intelligence (AI).
Although readers will gain hardly any understanding of how ‘intelligent’ programs work, they will get a glimpse of the aims and current achievements of AI, and of the attendant ethical and social problems.
A good feature of Market Hyde's book, in comparison with other highly popular treatments of such matters, is its reiteration that certain problems which may appear to be fairly simple are in fact extremely difficult.
For instance, enabling a robot to recognise a wide variety of objects in different positions and lighting-conditions is currently beyond the state of the art, as is building a robot or desk-computer that will understand many different sentences, on different topics and spoken by different speakers.
Our own powers of visual perception and understanding language are both apparently effortless and introspectively obscure — which leads people to underestimate the difficulty of simulating these rich information-processing capacities in a computer.
Most of the criticisms one could make concern errors of omission rather than of commission.
A brief discussion of some programs written to understand language, including some that ferret out the ‘gist’ of a short passage and are able to answer questions about it, gives a sense both of the difficulties and of the promise of these types of approach.
A program knowing something about people's typical behaviour in restaurants is able to infer (without needing to be explicitly told) that if John asked for the bill and then left, he probably paid the bill before leaving.
Hyde mentions a program that can automatically provide precis of news stories, but does not point out that it can attempt to do this only for a restricted range of stories.
Much as the ‘restaurant-program’ has to be told about conventional behaviour in restaurants, so the ‘newspaper-reader’has to be told about road-accidents, earthquakes, hijackings, and the like.
It can provide a precis only where the topic is something that it knows about, so that it has some sense of what conceptual relationships to expect in the story.
There are many other examples where, readers may assume that much more can be done than is in fact the case.
Hyde's account, then, will whet the appetite rather than satisfy it (the ‘Suggested reading’ gives a useful list of more detailed, yet still introductory, books).
Computers That Think raises some socially important and intellectually fascinating questions about the relation of man and machine, and its intelligibility will prompt discussion on these important matters.
It is aimed at the general reader who knows nothing whatever about AI or related fields, and can be recommended at that level.
Life in the eyrie
Golden eagle years by Mike Tomkies Heinemann, pp 202, £9.95 
Stephen Mills
WHEN contemplating the profundities of nature, men have often found it difficult to say much of substance.
Mike Tomkies responds to the golden eagle with a smattering of science, a touch of religion and quantities of romance.
His book is not the authoritative eight year study promised by the publishers.
It is a slightly adolescent, indulgent account of a love affair — adolescent because it is redolent of a wide-eyed naivety out of place in a middle-aged man: indulgent because at times he hints that the eagles, with names like Atalanta and Melanion, may be reciprocating his feelings.
The book partakes of the American ‘Trapper and Mountain Man’ tradition: tough living, long hard treks, hardly a woman from cover to cover, and only the inevitable dog for company.
Next to survival, Tomkies presents photography as the knottiest task known to man.
Most of the illustrations are atrocious.
Nevertheless, there is some inspiration to be garnered from this book.
It speaks confidently of the existence of a wilderness in Britain which, like the wolf, many of us may have regarded as extinct.
Furthermore, anyone who has spent days and nights cramped into hides being rained on, only to have every twinge of discomfort dispelled instantly by the appearance of a bird or animal, will recognise the authenticity of Tomkies's experiences watching eagles.
His most interesting observations describe the unusual rearing of two chicks in one eyrie.
He attributes this success to the strong bond that existed between the parents: a plentiful food supply; the friendly interrelation of the chicks themselves, apparently because they were of opposite sexes; and, not least, the shape and size of the nest which gave them space to keep out of each other 's way.
His support of the official scientific view that eagles are no threat to the sheep farmer is also worth having.
In 520 hours of observation, he saw only two lambs being brought to the nest that might have been killed by eagles.
Out of 105 items of prey he examined, only 7 were pieces of lamb compared with 3 entire fox bodies and 25 rabbits.
Unfortunately these revelations do not stretch to fill the book.
still, locating 27 golden eagle eyries across 750 sq.km is no mean feat, especially for a man observed with vertigo and arthritic knees.
An open framework of holes
Hydrothermal chemistry of zeolites by R. M. Barrer,Academic, pp 360, £31 
John Emsley
BY TINKERING with the complex atomic frameworks of minerals called zeolites, chemists have developed catalysts that can turn low-grade fuels into petrol and useful raw materials.
Zeolites are naturally occurring minerals based, like most other minerals, on polymeric silicates in which the basic sub-unit is the silicate SiO4 group with its central silicon atom surrounded by four covalently-bonded oxygen atoms.
These silicate groups come together by sharing oxygen atoms to produce a variety of structures.
In zeolites this framework of silicates is such as to produce large cavities connected by open channels within the crystal.
It is these holes within the lattice that are the focus of interest, for they are large enough to accommodate small molecules.
The best known use of zeolites has been as dehydrating agents — the so called molecular sieves — which can effectively filter out and hold on to water molecules thereby removing them from other liquids.
But not only water molecules will fit into these cavities.
There is a growing interest in other ‘guest’ molecules that can be absorbed by the ‘host’zeolite.
The chemical transformations that can then occur are quite remarkable, making zeolites some of the most unusual catalysts known.
Improved gasoline yields of up to 25 per cent have been achieved using them.
Even more exciting is their ability to convert methanol, CH 3 OH, into high-grade petrol.
Not only methanol, but also other simple organic substances such as esters, ketones and acids can be converted to hydrocarbon fuels by zeolites.
Intensive development by industry is already producing results in this area.
This book is a companion to Professor Barrer's 1978 volume on Zeolites and Clay Minerals as Sorbents and Molecular Sieves (Academic), and whereas the earlier work dealt with the uses of these interesting substances, this new monograph deals chiefly with the ways in which zeolites can be made synthetically using hydrothermal  processes .
The general principles behind the method and the chemical reactions are explained clearly and concisely.
Within the open framework of zeolites, water and other small molecules, and even the counter cations, have an uncanny mobility.
For this reason, zeolites display some features in common with such diverse systems as ion exchange resins, semiconductors, and aqueous solutions of salts.
The chemistry behind the formation of zeolites is still not clearly understood as Barrer shows, but he goes on to elucidate the physical processes of nucleation and crystal growth.
The author then surveys the current state of the art of zeolite synthesis and transformation, and shows how it is possible to ring the changes among the component atoms of zeolites — the silicon and oxygen parts of the polymeric framework and the counterbalancing metal ions can all be changed for other elements while still preserving the topology that is the characteristic feature of a zeolite.
Even non-silicon zeolites have been made by researchers at Union Carbide in the US.
Zeolite chemistry has made remarkable strides forward in the past few years.
Their study is at the interface of inorganic chemistry and geochemistry.
The investment of industrial research in this area will undoubtedly continue to uncover further surprises.
Professor Barrer's timely book has the merit of being comprehensive yet readable, and beautifully produced.
Plug-in to publishing
International journal of micrographics and video technology edited by John Teague,Pergamon, quarterly, £27.50 pa 
Peter Thomas
SINCE the 1850s, when microfilming became a practical possibility, enthusiasts for this medium have said that it would eventually replace the printed book.
In recent years, video technologists, have made similar forecasts for their new publishing medium.
But all these rather extravagant claims have had to be made via the old-fashioned printed page.
England's first printer, William Caxton, by contrast, advertised the effectiveness of his products in the 15th century by having notices for display outside his Westminster premises produced by the then new technology of printing.
He could have written them by hand but this would have defeated their objective.
It is refreshing, therefore, to find this new journal devoted to micrographics and electronic information transfer is available as a microfiche at the same time as the printed version.
This is in line with the publishing policy of Pergamon and was the case with Micropublishing and Current Periodicals , a former Pergamon product which, with Microdoc , the official journal of the former Micro film Association of Great Britain (MAGB), has been incorporated into the journal under review.
MAGB has, in fact, been resurrected as the Microform Association of Great Britain and, unlike its predecessor, wisely allowed a commercial publisher to produce its journal.
The inaugural issue has, however, every appearance of being Microdoc with a new cover and a slightly larger format.
There are no articles on video technology, although a handful of book reviews perhaps indicate a determination to cover it in future.
Indeed, the publisher seems to have recognised these shortcomings of the first issue, and claims that the brief of the journal is being broadened.
I hope that the new journal, which purports to be international in content, will soon leave behind the rather parochial views of the former MAGB journal.
Unfortunately, of the seven articles in the first issue, six are the work of English practitioners in micrographics.
The news and events columns also have a decidedly British bias.
So now you have a ZX Spectrum
Tim Hartnell
COMPUTERS often conjure up images of whirling tapes on giant machines, or of bespectacled precocious kids wrestling with incomprehensible maths.
Three books on Clive Sinclair's £125 colour computer, the ZX Spectrum, go a long way to dispelling both impressions.
It seems, according to the authors of the books, that computers — especially the spectrum — are fun .
Not just the fun of zapping Space Invaders, or defending the Earth from noxious aliens, but the fun of challenging the computer to brain puzzlers.
The three books which give this impression of relentless fun are The ZX Spectrum and how to get the most out of it (hardly a winner of the snappy title award) by Ian Sinclair (Granada, pp 144, £5.95), and Easy programming for the ZX spectrum and Computer puzzles for spectrum and ZX81 by Ian Stewart and Robin Jones (shiva, pp 144, £5.95 and pp 64, £2.50).
The ZX Spectrum and Easy Programming attack the same problem area — what the hell do you do once you have unpacked your computer, tried to understand the manual, and realise it is written by people who seem to have forgotten that most of their readers will be neophytes?
The ground covered by both books is, in the early stages, fairly similar.
They begin by explaining how the spectrum keyboard works.
And such an explanation is needed, believe me, scarcely a key is free of its overlay of jargon — RND, STEP and NOT share keys with obscure wiggly brackets, slanty lines and arrows pointing every which way.
And an elaborate ritual of key  presses , in a strict order, is needed to get a key to yield the result you demand.
After this the paths taken by the books change.
Sinclair tends to race ahead, in a fairly flat, matter-of-fact way, covering his ground in a confident, but somewhat un-inspired manner.
Little suggests Sinclair is aware that the reader is being lead on a path of real discovery, with genuine wonders to uncover.
The air of general ‘unexcitement’ lifts, however, in the chapter which, to me, is the best in the book, ‘Roll your own’.
‘For sheer joy, however, nothing beats devising your own programs…’ he says, and this is not hyperbole.
He gives good, solid information in this chapter, suggesting that he felt on more solid ground when discussing this topic.
‘Roll your own’ more than compensates for the lifelessness of other parts of the book.
Stewart and Jones have produced something extremely rare — a computer instruction manual written with verve, life and humour.
Most books in the beginners'-instruction manual genre are flat and factual, with writing that is grammatically correct, but with little awareness that the final product is intended for living human beings.
Stewart and Jones fairly crackle with life.
My only solid criticism of the book is that the programs are typeset, rather than— as in Sinclair's book — being dumped directly from the computer to the ZX printer.
The third book,Computer Puzzles for Spectrum and ZX81 (the ZX81, by the way, is the £50 black-and-white predecessor to the Spectrum) is a light book, redolent with Jones/ Stewart humour.
It gives a collection of puzzles with odd names (‘Tower of Hanoi with pancakes’, ‘Rooks rampant’ and ‘Several times knightly’, to mention a few) which will entertain when you are tired of the ‘sheer joy’of trying to write your own programs.
If you are new to the spectrum, and want your information presented in a fairly straight manner, then the Ian Sinclair book is for you.
The Stewart/Jones approach will appeal if you like your learning leavened.
Once you have learnt it all,Computer Puzzles will give you something to run whenever one of your friends makes that irritating remark: ‘It's very nice…but what can you do with it?’
How fares science over the cornflakes?
EVEN if we ignore BBC Breakfast time's unsupportable decision to support a diurnal astrologer, the verdict must be: not too well.
Take Monday last week.
Two items of note.
The briefer was Selina Scott questioning Lord Soper, in fine nick on his 80th birthday, about nuclear power.
Splendid.
But as Soper quickly twigged, what Selina actually meant by her repeated mention of nuclear power was nuclear weapons.
Next, a story lifted from the Daily Mail about Professor Jerrold Petrofsky's work in Dayton, Ohio, and the hope it gave to the paralysed PC Philip Olds.
There were no less than four components — Selina's introduction, a filmed report, an interview with journalist Andrew McEwen, and another interview with Breakfast Time's resident medic, Richard Smith.
Yet only he of the British Medical Journal actually explained what Petrofsky was trying to do — stimulating muscles electrically in their natural walking sequence.
Why, then include waffle (Selina : ‘Paralysed people are able to walk again…
’Smith: ‘No, that hasn't been done yet…
’Selina : ‘But it is a miracle…’) to confuse the story line?
Tuesday saw the launch of TV-am's Good morning Britain and its first shot at wildlife.
A fun item, it seemed, with a policeman vouchsafing that he had chased a puma in his panda car.
But there was worse to come, with Angela Rippon (the outdoor girl who wishes to be known these days as an incisive reporter) giving free, uncritical publicity to somebody called Di Francis who has written a book about mysterious, leopard-sized felines roaming Britain.
How could she be sure this was a genuine UK species of big cat, Ms Rippon asked?
Because they had large paw marks, came the answer.
End of incisive questioning.
Wednesday's Breakfast Time brought another science story which, notwithstanding a clutch of talking heads that included Des Wilson of CLEAR, left viewers more confused than before.
It concerned the toxic effects of atmospheric lead and was characterised by a series of comments like ‘It's claimed that even low levels of lead can cause brain damage’, ‘It's been difficult to get conclusive evidence’, ‘There's a whole lot of evidence’, ‘Yes but there is conflicting evidence’, all delivered without any one of the four speakers actually providing figures to explain what the concern and disagreement was all about.
Even Anna Ford managed to get the UK's position vis-àvis the rest of Europe the wrong way around.
Who on earth is briefing these people?
Wednesday was an ominous day, with Claire Rayner, armchair psychologist, joining Russell Grant, armchair astrologer, on the couch.
Her topic was jealousy which she attributed to parents bringing up children to think they are unlovable.
‘They're constantly telling them not to do this and not to do that,’ she opined, curiously, at this most un-authoritarian time in our history.
I have an awful suspicion that morning TV here could soon lurch towards its American counterpart, with deep daily deliberations about you and your psyche/milkman/rocking horse/ puma/postman.
So to Thursday, and the oddest event of the week.
‘Now come on, Richard,’ Frank Bough began, ‘a lot of people confuse a stroke with a heart attack.
What really is the difference?’
After which the animated Dr smith talked at length and cogently — about strokes.
Not a single word on heart attacks, strange.
Not a promising start, then.
And for the stories coming up next, as they say, I understand that Good Morning Britain is hoping to better its big cat tale by reporting on wild parakeets in Maidstone, and cats that eat indoor plants throughout the country.
Wake up Mr Attenborough.
FORUM
Solomon's temple and excavations in Byzantium
Martin Harrison records a remarkable archaeological discovery in Istanbul
A LARGE and sumptuous Byzantine church, recently discovered in Istanbul, seems to have been modelled on biblical descriptions of the temple of Solomon at Jerusalem.
The temple had been built in the 10th century BC as an expression of the Kingship of Solomon in all his glory.
It was a building of extraordinary splendour and lengthy descriptions (I Kings , chapters 6 and 7, and II Chronicles , chapters 3 and 4; compare Ezekiel , chapters 40–43) read like an architect's specifications for one of the Wonders of the World.
The temple was destroyed by Nebuchadnezzar in the 6th century BC rebuilt, and finally destroyed again by the Romans in AD 70.
But its fame survived, and Solomon and his temple became for the Middle Ages symbols of divine kingship and royal (and indeed heavenly) opulence.
The Byzantine church in question was dedicated to St Polyeuktos, an obscure Early Christian martyr (who is perhaps only remembered nowadays as the subject of a tragedy by Pierre Corneill).
Until 1960 nothing was known of it except a handful of historical references and a poem of 76 hexameter-lines in praise of the church's founder, Anicia Juliana.The poem, which had been carved in letters 11 centimetres high on the walls of the church itself, was copied in a manuscript of the 10th century and is preserved in full in the Palatine Anthology , a medieval collection of ancient epigrams.
In the spring of 1960 municipal workers bulldozing near Istanbul's city hall churned up several marble blocks of architectural sculpture.
(Istanbul, you will remember was formerly Constantinople and before that Byzantium.)
Two of the blocks together preserved a handful or words from the poem (promptly recognised by Professor Ihor Sevcenko of Harvard University) and all of them elaborately carved.
Anicia Juliana was a princess of enormous wealth and distinction.
She was born about AD 460, daughter and granddaughter of Roman and Byzantine emperors, whose family had been prominent in Roman politics for over 700 years.
She built the church as an annexe to her palace in 524–527, in the reign of Justin I (518–527), and she died in about 528, soon after the accession of Justin's nephew Justinian (527–565).
A team drawn mainly from the University of Newcastle upon Tyne, directed jointly by the late Dr Nezih Firatli and myself, excavated in Istanbul from 1964 to 1969 for Dumbarton Oaks (Harvard University's centre for Byzantine research) and the
Archaeological Museum of Istanbul.
In our annual reports in Dumbarton Oaks Papers we have shown something of the extraordinary nature of the church and its decoration and shed much new light on the period immediately before Justinian.
A bizarre by-product has been the recognition of various richly decorated fragments of the church in places as far afield as Barcelona, Venice, Aquileia, and even Vienna, presumably carried off to the West as loot after 1204, by members of the Fourth Crusade who evidently had an eye for exotic sculpture.
(The full account of the excavations is to be published next year by Princeton University Press.)
Our excavation of the foundations showed that the church had been a large one, just under 52 metres (168 feet) square.
Nothing of the walls or vaulting remained intact, but we found the substructures to be choked with debris fallen from above, including several more pieces of the poem and various richly carved  capitals , cornices, and piers.
All were of the highest technical calibre and all displayed an extraordinary range of exuberant and exotic motifs, For a few years, until Justinian effectively eclipsed it by his construction of the church of St Sophia in 532–537, st Polyeuktos was evidently the largest and most sumptuous church in Istanbul (Constantinople).
The church had been carefully laid out and constructed, but the basic unit of measurement had eluded us until December 1982, when Michael Vickers of the Ashmolean Museum at Oxford, a former member of the excavation-team, suggested that it might be the cubit, and, specifically, the long cubit.
Now the cubit (traditionally the length of a man's forearm from the elbow to clenched fist) is the principal unit of linear measurement in the Bible , and was used too in Egypt and Mesopotamia.
It was incorporated into the later Greek and Roman systems, whose basic unit was the foot.
There were, moreover, two kinds of unit, the standard measure of six handbreadths and the longer (or royal) cubit of seven.
The common unit measured 0.445 m and the longer cubit about 0.518 m.
Ezekiel states that the unit for his visionary temple was ‘the long cubit which was one cubit and a hand's breadth,’ and moreover that the overall dimensions of the temple were 100 cubits square.
The church of St Polyeuktos was 51.45 m long and 51.90m. broad, which, with some allowance for error or subsidence, may be regarded as precisely 100 cubits square.
The hypothesis that St Polyeuktos was deliberately modelled on descriptions of the temple is reinforced by the poem's explicit claim that Anicia Juliana had ‘by her church surpassed the wisdom of Solomon’.
Moreover, the decorative features of the temple (carvings of palmtrees, capitals like lilies, capitals festooned with network, pomegranates, and open flowers) are all prominent in the repertory of St Polyeuktos, although they do not seem to have been current in contemporary Byzantine sculpture.
It seems likely, too, that several other distinctive features of the church will eventually be explained by reference to the temple.
Why did Anicia Juliana attempt to recreate Solomon's temple?
She was an aristocrat and woman of royal blood, who had seen the throne pass in 518 not to her son (who had married the Emperor Anastasius's daughter), but to an uneducated provincial, Justin, the illiterate soldier-son of an Illyrian peasant.
Her palace-church, begun a few years later, was an imperial and dynastic protest and a declaration of her own family's higher qualifications for the throne, as the proud sentences of the poem inscribed within it make abundantly clear.
That it should have been modelled on the Temple of Solomon may seem at first sight presumptuous, but it was an age that relished allusion, and Solomon, son of David, was of royal descent, anointed by Zadok the priest, and the king par excellence .
There was a sequel.
Justin died in 527 and was succeeded by his nephew Justinian.
In 532 Justinian began the construction on a breath-taking scale of the imperial church of Saint Sophia.
This was to be half as large again as St Polyeuktos and was by contrast restrained in its decoration.
St Sophia still survives and is generally accepted as one of the great buildings of antiquity.
It can now be seen as a deliberate political reaction to the earlier building, and it is even recorded that on its completion in 537 Justinian  promised God that he himself had ‘vanquished Solomon.’
Had Anicia Juliana been alive at the time (she died about 528), she would not have been amused.
Somewhere someone wants to hear from you
What will the Third World gain from Communications Year?
SOMEWHERE, a telephone rings twice.
‘Hello?’
‘Did you know it was World Communications year 1983?’
‘Hello?
Hello?’
‘I said ‘It's World…
’.’‘Hello, is anybody there?’
‘World Communications…’
Click!
Brrrrrr!
World Communications Year (WCY) began in January, The United Nations, whose brainchild the year is, has largely failed to communicate that WCY is happening at all, let alone why it is needed.
The year's purpose is to accelerate the development and provision of national and international communications.
Inundated by the raging debate on whether we get umpteen more telly channels via satellite or cable, you may well say ‘We have quite enough information about everything, thank you.’
Fair point.
In the meantime, try making a telephone call from one African country to another; you will quite likely be routed via London and Paris.
Post a letter to another country a few hundred miles along the West African coast: it will be hand-sorted in a sorting office at the back of st Paul's cathedral in London.
Try, if you are a farmer in a Third World town, to buy a stamp to send an order for urgent spare parts: you may be told the post office has run out of stamps.
Imagine what would happen if ‘Disgusted of Tunbridge Wells’ couldn't get her first-class mauve at the local sub-PO.
There is a pitifully simple need for the basic post and telegraph equipment in undeveloped countries like post offices, postal vehicles, telex, cables and telephone exchanges, radio stations and even stamps.
Coordinators of the WCY, at the Geneva-based International Telecommunications Union (ITU), see the year as ‘an opportunity for a quantum leap in the development of a complete world communications network, which will leave no one isolated from his local, national or international community.’
The words are likely to be bolder than the action.
Governments of developing countries give only low budgets to developing communications.
Western countries for their part have been slow to respond to appeals for a WCY fund.
Private finance is unlikely to be attracted to areas where people have little money to spend.
The only sizeable donations to WCY so far have come from the US ($1.4 million) and West Germany ($1.3 million).
Britain is not giving a penny, not even a penny black!
The British government says that it finances nine projects, including a recently opened satellite station in Nepal, and that it sees no necessity for a separate fund.
Less than 2 per cent of all overseas aid is going to improve communications.
If developing countries tap existing sources for money to improve communications, then there may be less cash for other projects.
So the developing countries are caught in a cleft stick.
Mohamed Mili, ITU secretary general until the end of 1982, thinks there are two reasons why the West should help.
Western manufacturers will need to find new markets in the Third World, he says.
When the West wants to move into these markets adequate postal and telecommunications systems will be needed.
The biggest communications revolution in the Third World has been radio.
One WCY project that should get under way concerns appropriate technology for rural radio broadcasting.
Another project, partly financed by the West Germans, will be a feasibility study into spreading telecommunications into remote areas.
The most appropriate technology for many people will be one that helps a country to organise a postal system so that stamps are available, to bring radio within everyone's reach and that holds out the possibility of early telephone links.
Silver lining?
DEPRESSION brought on by the effect of overhead power cables is in the news again.
Several victims have appeared on TV complaining that their lives are ruined through having to live in the shadow of the pylons.
Through some unexplained process, magnetic fields produced by the electric currents flowing in the cables seem to induce, say the depressives, the darkest feelings of gloom and despondency.
Medical experts dismiss the link with the cables, claiming ‘it's all in the mind’.
But how would they explain the recent experience of one of our hack's friend.
His wife has been suffering from severe depression, serious enough for her to be treated as an outpatient at the local hospital, for some 18 months.
A few months ago, the couple moved out of town to a more rural environment.
To be precise, a former tied cottage, which was cheap enough to be within their means for two reasons — it is remote, and it has a power pylon growing in its back garden.
Since their move, the wife has felt a burden lifted from her shoulders, and has been restored to her former carefree self.
Ah ha, you say — that's just because she lives in the country now.
So why, then, does her depression return whenever she ventures away-from home for more than a few hours?
It surely seems worth investigating the possibility that whatever it is about power lines that flips a normal brain into depression may flip a depressed brain back to normality.
Grave accusations face Lucy finders
Jeremy Cherfas on an anthropological row that is spreading from Ethiopia
EARLY MAN may not have been the competitive, scheming, naked aggressor we once thought he was, but those who seek his remains certainly are.
The latest in a long history of skirmishes in the palaeontological world has blown up into what one particularly bad press release describes as ‘one of the nastiest personal and professional feuds in all of science’.
The story is Gordian in its complexity, but no Alexander seems available to cut through the tangle of claims, counter-claims, and downright lies.
At issue are the marvellously rich fossil beds of Ethiopia and who should be allowed into them.
Humanity's birth probably lies preserved somewhere in those beds, but last October the government of Ethiopia announced a total ban on all foreign expeditions (New Scientist , 2 December 1982, p 552).
The ban will last until a special committee under the minister for science and technology has drawn up a new set of rules to control the activities of foreign research workers.
In itself this is a justifiable decision.
Ethiopia does not yet have a strong scientific community, and it would be criminal if foreign researchers were to plunder the material without assisting in the development of their host's own research capabilities.
But the personalities of the fossil hunters involved have ensured that this protective move by the Ethiopians has developed into an acrimonious tussle.
There are many factions, many accusations.
It seems that there are two main sides.
One is personified by Don Johanson, who put the Ethiopian fossil beds on the map with his fabulous discoveries of Lucy and her ilk.
With Johanson, who recently moved to California to be director of his own Institute of Human Origins, are Tim White and Desmond Clark, at the University of California at Berkeley.
The other side seems to be led by Jon Kalb, a geologist at the University of Texas, who was a member of Johanson's early expeditions but left shortly after the big discoveries because of what Kalb calls ‘disputes…over scientific and management issues’.
Caught in the middle are the Ethiopians.
The ban itself, while it seems to be justified, appears to be the culmination of an orchestrated plan by a few Ethiopian students.
The students, who were being trained by Kalb and others in the US, allege that the other expeditions had stolen fossils from Ethiopia, had failed to provide training or facilities for Ethiopians, and had made light of Ethiopian culture and customs.
Clark and White, whose expedition was kicked out of the country last autumn, say that there is no justification to these claims, Johanson goes further and blames ‘a campaign by three or four people who would like to sort of smear our reputation, to do whatever they can’.
Chief among these, of course, is Kalb.
He has been accused of being an agent of the CIA, and Ethiopian security gave him 48 hours to leave the country in August 1978, but no one has found any evidence to confirm these rumours, ‘I think it's very unlikely that Ethiopian security would expel somebody on the basis of baseless rumours,’ White says.
‘If in their judgement he was a CIA man, that's good enough for me.’
While deprecating such tactics as not being in the spirit of scientific inquiry, nevertheless Johanson and others do quickly get around to innuendos about Kalb's sources of finance.
One such was the Forge Foundation.
‘Who's ever heard of that,’ Johanson is fond of saying.
In fact the Forge Foundation seems to be a respectable body, chaired at the time Kalb got money by a past president of the American Association for the Advancement of Science.
In September 1972 Kalb applied to the Forge Foundation for funds, and in his application described the geology of the Hadar region of Ethiopia.
He sent a copy of the application to Johanson.
A 1982 paper by Johanson, Maurice Taieb and Yves Coppens in the American Journal of Physical Anthropology , which is about the hominid fossils of the Hadar, includes a description of the geology of the region that matches, virtually word for word, Kalb's grant application.
Indeed, Johanson's other writings about his work in Ethiopia are another source of offence to Kalb and the Ethiopians.
‘Many Ethiopians are…especially angry at some of the things Johanson wrote in his book Lucy ’ says Sleshi Tebedge, one of the Ethiopian students who was at Texas with Kalb.
The former dean of the faculty of science at Addis Ababa University, Tewolde B. G. Egziabher, adds that in the book Johanson ‘makes remarks about Ethiopian politics and culture and about the behaviour of officials in government — bribes and ignorance and so forth.
He should refrain from making comments on subjects he knows little about.’
This is an interesting remark, because the British edition of Lucy differs from the American in key passages that deal with Kalb and officialdom.
These differences include the original step, for a work of avowed non-fiction, of changing words within quotation marks.
In the British edition a minister to whom Johanson spoke wonders if an ‘official…acted improperly in any way’ in giving Kalb a research permit.
In the US edition he wonders if ‘this man…has been bribed or has used improper influence in any way’.
Quite apart from the doubts it casts on the multitude of extensive verbatim passages in Johanson's engaging account, this and other changes make one wonder whether legal evidence has become a consideration in reporting scientific expeditions.
Another episode that angers the Ethiopians is that of the human knee.
After finding a fossil knee, Johanson needed a modern knee for comparison.
Despite some misgivings, he persuaded Tom Gray to accompany him on a wander to a nearby burial ground, Lying on top of a heap of bones, ‘almost asking to be taken, was a femur.
Tom took it.
We looked around.
There was no one in sight.
Tom put the bone in his shirt and carried it back to camp’.
That's the story according to Lucy .
But on 17 January, 1983, days after the story of the ban and recriminations had been published in an article in Science , Johanson told a class at Stanford University a different story.
‘I really did want a femur’, he said.
‘There was this graveyard.
I talked to some of the people around there because I didn't want to get into trouble.
They said it was an old grave, nobody knows who's it is.
There were bones all over the place.
We went out there and we looked at the bone, we compared the bone and we returned that bone.’
Which to believe?
Tim White casts doubts on Kalb's ability to discharge his undertakings to care for the material he had collected.
One example is the Bodo skull, which created a stir last year when White described cut marks around it that were  consistent with the owner of the skull having been scalped.
‘Clark and I looked at the thing for five minutes and we said ‘Wow’’, White told New Scientist .
‘What are all there cut marks?
And that was before the skull had been cleaned.
Kalb had it for years and never saw the marks.’
So the accusations fly.
The ban has allowed Johanson to embroil himself in controversy, something he relishes, and the controversy has confirmed that there is much more to palaeo-anthropology than old bones.
But the real effects are hard to judge.
Of course, the fossil hunters will lose all the bones that will erode from the hillsides with no one to see them re-emerge into daylight.
But that has been happening for hundreds of years.
White says that there are several Ethiopian graduate students working for higher degrees; they will not now be able to work with Ethiopian material, he says, and this will be detrimental to them and the development of Ethiopian palaeontology.
He also points out that the expedition led by himself and Clark had assembled ‘the best people, worldwide, and the top people can't afford to stand around for a couple of years waiting for research to happen’.
They will go off to other projects, he fears, and the Ethiopians, in common with the rest of us who want to understand our origins, will be the losers.
Long live science education!
Eric Deeson is dismayed by a report on school science
‘REAL TEACHERS’ I define as those working in a busy school, facing unimagined shortages in all kinds of resources.
The sort who bore you at cocktail parties.
The people least likely to be able to find £24–95 to buy the first set of reports on science teaching from the Assessment Performance Unit (APU) of the Department of Education and science*, the latest volume of which has just been published.
Not that many real teachers have heard of the APU.
That said, the lengthy process of surveying the science performance of 11-, 13- and 15-year-olds, undertaken by the APU in 1980, surely involved real teachers.
Perhaps there were some among the good number, nominated by the local science advisers, who administered the practical tests and marked the papers.
It is possible, too, that one or two of the people overseeing the survey may occasionally have talked to real teachers about the project's objectives and methods.
Possible.
I can be sure that real teachers would have avoided a number of APU's blunders.
They would not allow ‘battery’ as a correct name for the symbol in Figure 1.
They would allow, however, a ‘lamp’ as a correct name for the symbol in Figure 2.
A real teacher is unlikely to use an instruction like this, for 11-year-olds: ‘Find three ways in which you can tell from the drawings (of spider and crane fly) that they are the same as each other and three ways in which they are different.’
Certainly he or she would exclude illustrations less than adequate for use with children, but not economise on full stops in practical worksheets.
I could go on exposing APU's lack of imagination.
Real teachers with real kids have to take care with written communication.
Vocabulary, use of complex sentence structures and passive voice, word and sentence lengths — all such aspects of language are also aspects of science teaching and, surely therefore, of testing.
In that the APU science surveys involved almost 40 000 guinea-pigs, the examples I give are not nit-picking.
With the certainly massive costs of the exercise (just how high they were I have not discovered) it is a pity to feel a little uncertain about the validity of the work.
The validity of the APU science outcomes, however, must be examined in a much wider context than that of the language of assessment alone.
That context must include the aims of science education in Britain vis à vis the aims of the APU.
It is clear that the APU agonised greatly on just what to assess under the umbrella word ‘science’— and how to assess it.
The APU's brief includes ‘to seek to identify the incidence of under achievement’ and ‘to identify significant differences of achievement related to the circumstances in which children learn’.
In other words, what are the areas of weakness in science teaching, and why?
Turn then, to the indexes of the books, to find keywords related to those objectives.
Oh, no indexes.
The ‘Contents’, then, for the standard ‘summary of conclusions’?
None.
The preface of each of the three books, obviously an APU plug-in module, reveals the secret.
‘The authors invite discussion on the interpretation of the survey results, but at this stage do not themselves draw conclusions from the results.
We hope that those to whom this report is addressed — educationalists, parents, and those concerned with the provision of resources centrally and locally [but not real teachers?]— will consider how far the standards of  performance revealed, are acceptable…
. It would be unwise to draw firm conclusions on the strength of the results of a single survey.’
Well, what kind of fool would I be, in a piece of this length, to summarise the results in any meaningful fashion?
They provide backing for such shattering conclusions as the following: s fly.
The ban has allowed Johanson to embroil himself in controversy, something he relishes, and the controversy has confirmed that there is much more to palaeo-anthropology than old bones.
But the real effects are hard to judge.
Of course, the fossil hunters will lose all the bones that will erode from the hillsides with no one to see them re-emerge into daylight.
But that has been happening for hundreds of years.
White says that there are several Ethiopian graduate students working for higher degrees; they will not now be able to work with Ethiopian material, he says, and this will be detrimental to them and the development of Ethiopian palaeontology.
He also points out that the expedition led by himself and Clark had assembled ‘the best people, worldwide, and the top people can't afford to stand around for a couple of years waiting for research to happen’.
They will go off to other projects, he fears, and the Ethiopians, in common with the rest of us who want to understand our origins, will be the losers.
Long live science education!
Eric Deeson is dismayed by a report on school science
‘REAL TEACHERS’ I define as those working in a busy school, facing unimagined shortages in all kinds of resources.
The sort who bore you at cocktail parties.
The people least likely to be able to find £24–95 to buy the first set of reports on science teaching from the Assessment Performance Unit (APU) of the Department of Education and science*, the latest volume of which has just been published.
Not that many real teachers have heard of the APU.
That said, the lengthy process of surveying the science performance of 11-, 13- and 15-year-olds, undertaken by the APU in 1980, surely involved real teachers.
Perhaps there were some among the good number, nominated by the local science advisers, who administered the practical tests and marked the papers.
It is possible, too, that one or two of the people overseeing the survey may occasionally have talked to real teachers about the project's objectives and methods.
Possible.
I can be sure that real teachers would have avoided a number of APU's blunders.
They would not allow ‘battery’ as a correct name for the symbol in Figure 1.
They would allow, however, a ‘lamp’ as a correct name for the symbol in Figure 2.
A real teacher is unlikely to use an instruction like this, for 11-year-olds: ‘Find three ways in which you can tell from the drawings (of spider and crane fly) that they are the same as each other and three ways in which they are different.’
Certainly he or she would exclude illustrations less than adequate for use with children, but not economise on full stops in practical worksheets.
I could go on exposing APU's lack of imagination.
Real teachers with real kids have to take care with written communication.
Vocabulary, use of complex sentence structures and passive voice, word and sentence lengths — all such aspects of language are also aspects of science teaching and, surely therefore, of testing.
In that the APU science surveys involved almost 40 000 guinea-pigs, the examples I give are not nit-picking.
With the certainly massive costs of the exercise (just how high they were I have not discovered) it is a pity to feel a little uncertain about the validity of the work.
The validity of the APU science outcomes, however, must be examined in a much wider context than that of the language of assessment alone.
That context must include the aims of science education in Britain vis à vis the aims of the APU.
It is clear that the APU agonised greatly on just what to assess under the umbrella word ‘science’— and how to assess it.
The APU's brief includes ‘to seek to identify the incidence of under achievement’ and ‘to identify significant differences of achievement related to the circumstances in which children learn’.
In other words, what are the areas of weakness in science teaching, and why?
Turn then, to the indexes of the books, to find keywords related to those objectives.
Oh, no indexes.
The ‘Contents’, then, for the standard ‘summary of conclusions’?
None.
The preface of each of the three books, obviously an APU plug-in module, reveals the secret.
‘The authors invite discussion on the interpretation of the survey results, but at this stage do not themselves draw conclusions from the results.
We hope that those to whom this report is addressed — educationalists, parents, and those concerned with the provision of resources centrally and locally [but not real teachers?]— will consider how far the standards of  performance revealed, are acceptable…
. It would be unwise to draw firm conclusions on the strength of the results of a single survey.’
Well, what kind of fool would I be, in a piece of this length, to summarise the results in any meaningful fashion?
They provide backing for such shattering conclusions as the following:
* Older pupils do better at given questions than do younger ones.
* Some pupils study more science than others.
* Independent schools have better resources than state schools.
* Boys and girls achieve similarly.
* Southern pupils do a lot better than Northern ones.
* Deprivation correlates with poor performance.
Glancing back through what I have written so far, I detect more than a note of cynicism.
Not that I mean to be cynical, but I do teach in an inner-city school (where only Advanced Level pupils have textbooks — and they share — and where practical work involves half-a-dozen to a bunsen).
What the APU science teams have assessed is actually a fairly forward-looking kind of school science, but it is still of little relevance or interest to very many youngsters in Britain.
That saddens me.
A frank and friendly hand
Tam Dalyell on political gestures
CONSTITUENTS and non-politicians tend to ask members of parliament an inordinate number of questions about their relations with each other.
I suppose it is an easily understood curiosity about the behaviour of those in the public eye.
What do you think of so-and-so?
Is he really like that?
How do you get on with him?
Collectively politicians tend to be pretty awful.
I am in no doubt about the dreadful impression that the broadcasting of Prime Minister's Question Time has created.
We portray ourselves as a rabble, and certainly are no example to the fourth form in a school.
Shouting (euphemistically called ‘atmosphere’) is part of the British system of politicking; indeed, in 1945, a conscious decision was made that it should remain so.
The Chamber of the House of Commons was damaged by bombs during the Second World War and when deciding whether it should be rebuilt as it was originally, or along the lines of the Houses of Parliament in Ottawa and elsewhere in the Commonwealth (’ one representative: one desk’), Winston Churchill and Clement Attlee, with other senior politicians, plumped for the old ways — and the old ways were those of adversarial politics.
The benches seat 400 MPs at the most.
On a big occasion 600 or so are crammed in.
The crush can generate ‘pressure’ on ministers, and affect the elusive ‘mood of the House’that MPs like to interpret as the will of the nation.
But apart from the ‘big’ occasion, Question Time and set-piece debates often descend into ya-boo situations.
Individually, members of parliament are much less unattractive than they are collectively.
Our relations are more adult and friendly than those of many academic staff rooms that I have seen.
Real enemies tend to be confined (where they exist at all) to colleagues in one's own party.
I suppose this is natural because of potential rivalry for office, a feeling generalised with people of another political party.
British politicians tend to treat one another in a studiedly off-hand way.
When I was a member of the European  Assembly , we were forever shaking hands with our European colleagues of all nationalities — and it was expected.
British politicians seldom shake hands, as becomes a less formal society.
Chairmen of Select Committees of the House of Commons normally remain in their places when Permanent Secretaries or other distinguished witnesses are brought before their committees.
I had a strange sensation when, on an autumnal Friday afternoon, I turned up at Old Admiralty Building, to have a viva voce on my written evidence to the Falklands Inquiry.
The surroundings were wholly out of keeping with the importance of the people there and the nature of their task.
I suppose what I was asked and what I said in reply will be subject to the ‘30 year rule’— and heaven knows what any archivist will make of it all in the year 2012!
He will probably judge that it was a freak of history.
I was one of the few ‘non-official’ witnesses at the inquiry into what I trust is the last colonial war that Britain will ever fight.
As I entered the committee room from the standard uncarpeted passage, I was given a friendly and businesslike handshake by the chairman, Lord Franks, who had courteously got out of his chair to greet his witness — an unfailing politeness that I gather he extended to every other witness.
I was nonplussed.
It was a bit different from the sort of behaviour that, as I say, I have become accustomed to.
What to do?
Well, I could not simply shake the  chairman by the hand so warmly  proffered .
I had butterflies in my stomach enough and I had to do something, so I grabbed the nearest paw, which belonged to Merlyn Rees.
I should mention that Merlyn and I have been parliamentary colleagues and friends for nearly 20 years, since he was elected by the same people of south Leeds who had sent Hugh Gaitskell to the House of Commons.
I realised I had never ever shaken his hand before, MPs do not do that sort of thing.
‘Pressing flesh’, as Lyndon Johnson once put it, was foreign to me and to Merlyn.
We both understood that we were in an extraordinary situation.
So did Harold Watkinson, the next on the circuit, and all the others.
Being examined by half a dozen people, half of whom one has known extremely well, is what Margaret Mead, the anthropologist, would have termed a ‘bizarre group situation’.
Still, the absence of handshakes does not mean there is no physical contact among politicians.
They have developed the pleasant habit of touching each other on the shoulder in time of trouble, as a sort of physical sympathy.
Of course, physical contact is not the only evidence of camaraderie.
There is, and it is very important, a joking relationship, not unlike that in the armed forces and elsewhere.
It releases tension and we need it.
Members of Parliament are human after all.
Most of us, though, have learnt to beware the double handshake: hand clasped and hand on arm, all at once, It was a beguiling technique perfected 50 years ago by Adolf Hitler when he gained the chancellorship of Germany.
It has become an ingratiatory sign.
Clearly, handshaking is a symbol of declared friendship and is intended to put one at one's ease.
But what, I ask myself, are its social and biological origins?
What is the significance of its absence in the behaviour of the British political animal?
Handshaking would make a splendid topic for research if the necessary funds could be found.
Come to think of it, so would golden handshaking, and surely that is topical!
Shame on you Sir Keith Joseph for your negative and unkind attitudes to the social sciences.
European space master
Who will next direct ESA?
THE MAN responsible for Britain's contribution to the Concorde programme is this country's candidate for the top job at the European space Agency (ESA), which becomes vacant in a year's time.
The Concorde post, which observers have unkindly suggested should disqualify the incumbent from any positions of responsibility in the future, was held between 1966 and 1970 by Sir James Hamilton, who holds down today a key position within the bureaucracy of the Department of Education and science.
Sir James, who is due to retire shortly, could take over from May 1984 the task of director general of ESA, the organisation that coordinates the space activities of 11 West European nations.
The advantages of this job include a lucrative salary, a nice office in Paris and unlimited  opportunities to watch the agency's Ariane rocket take off (or, as happens more often, crash to the ground) from Guyana one of the less pleasant parts of South America.
But all may not go Sir James's way.
For one thing, Erik Quistgaard, the present incumbent, does not want to go.
The Dane, though shy and retiring and lacking a sense of humour, has knitted together a unified policy for the agency, which spends every year some £400 million of European taxpayers' money.
The odd lapse with Ariane apart, the agency is seen as being technically as advanced as National Aeronautics and Space Administration in many key areas of space technology.
Quistgaard, who has bought a plush house in the south of France, is fighting to stay on after his four-year term runs out next year.
In his favour is the attitude of the wily French, who control the strings of most aspects of Europe's space policy.
France would like its own ‘Mr Space’, Hubert Curien of the French space agency CNES, to take over the reigns of ESA when he retires in a couple of years.
Keeping Quistgaard in position until then would help this strategy.
Also acting against Britain's interests is that the previous director general before Quistgaard hailed from these isles.
This was Roy Gibson, a smoothie from the old school of diplomacy, whose chief attribute was that he spoke several European languages.
On the grounds that Britain had a good stab at the job last time round, observers feel that a German or Frenchman should get first refusal if Quisigaard can be eased out.
LETTERS
Surprising statements
I was most surprised to note the comments of the MoD spokesman in the story ‘Scientists fight for full survey of A-test deaths’(This Week, 27 January, p 219).
I was stationed on Christmas Island for the British Megaton Trials during 1957–59 and was present for three H-bomb tests.
I was responsible for the nursing services, Royal Air Force Hospital, Christmas Island, providing a service for all Her Majesty's Forces, civilian scientific officers, Fijian Army detachments and the Gilbertese natives.
Not until the third bomb (the one that exploded at too low an altitude) were we were issued with anti-flash suits and goggles.
At no time were we issued with radiation monitors , yet we were only 24 miles from grounds zero.
 A. Johnson Darlington.
 Co.
 Durham 
Radiation survey
Your item on surveys of personnel at the British nuclear weapons tests (This Week 27 January, p 219) is seriously misleading and in at least one respect factually incorrect.
The information about the use of control groups and the healthy worker effect was known to your reporter before he spoke to me — it is common knowledge.
Contrary to your account, there has never been a disagreement between the National Radiological Protection Board and the Ministry of Defence about this or about the general form of possible surveys.
The impression you gave that I provided your reporter with new information following the meeting is totally false.
I categorically deny the two other statements attributed to me in quotation marks: particularly that which implies that I think the doses must have been higher than those reported by the MoD.
This is a question on which I do not vet have a view.
Indeed I am not aware that MoD has yet reported any doses.
The existence of ill effects has not yet been established and only when, or if, it is will the question of causation be relevant.
 J. A. Reissland National Radiological Protection Board Didcot, Oxon 
Breast milk
Your report on the Marketing of ‘infant formula’ milks gave an incomplete picture (This Week, 20 January, p 143).
The 1981 WHO international code of marketing of breast-milk substitutes is not intended to curb the use of these products; its aim is clearly set down as follows: ‘to contribute to the provision of safe and adequate nutrition for infants by the protection and promotion of breast-feeding, and by ensuring the proper use of breast-milk substitutes, when these are necessary, on the basis of adequate information and through appropriate marketing and distribution’.
Also, it is not a regulation involving bans and prohibitions, it is a recommendation to member states to implement the aims and principles in a way appropriate to their national circumstances.
In the UK, a report commissioned by the Office of Population Censuses and Surveys of the Department of Health and Social Security issued in May 1982 and entitled Infant Feeding 1980 shows that, the initiation and maintenance of breast-feeding have increased significantly since 1975.
It is the UK government's view that the provisions contained in the draft FMF code of practice, which was drawn up in full consultation with DHSS and MAFF, and the DHSS circular to professional people working in child care, together fulfil its undertaking to implement the aims and principles of the WHO code.
 Heather Paine, Secretary, Infant and Dietetic Foods Section, Food Manufacturer's Federation, London WC2 
Fowl stones
Regarding the article ‘Magnetism and the standing stones’(Forum, 13 January, p 105), it seems clear to us that such stone circles were of great practical importance to their constructors.
Stone-age man would have noticed that birds navigating by means of the magnetic properties of the ley lines together with the visual cues thereon, became disorientated at certain points (multiple ley-line intersections).
This phenomenon they used to their advantage by constructing net traps at such points which caught the confused fowl as they fluttered down to Earth.
The stones that we see today are therefore the remains of the supports that once held the nets in position.
 L. Gomulski M. Rowland London School of Hygiene and Tropical Medicines London WC1 
In the soil
In our article ‘The secret life of the soil’(Monitor, 2 December 1982 p 564) we commented that the annual input of carbon into a particular soil under wheat was remarkably low, considering the size of the soil microbial biomass.
Gordon Lines suggests that we might be underestimating the carbon input by omitting carbon-fixation by algae and photosynthetic bacteria (Letters, 23 December, 1982, p 857).
These organisms are indeed active in our site — they have been found to contribute about 25 kilograms of nitrogen per hectare per year to this wheat crop.
However, the figure we gave for the annual input of carbon into the soil (1.2 tonnes of carbon per hectare per year)include the carbon contributed by algae and photosynthetic bacteria.
This input was calculated from the increased specific activity of carbon found in the soil after the bomb tests.
These tests increased the quantity of carbon-14 in the atmosphere and hence in all photosynthetic material.
Thus, as this material decomposed, a pulse of carbon-14 entered the soil organic matter, causing in apparent decrease in the radiocarbon age of the soil organic matter.
Measurement of the relative abundance of carbon-14 in both pre- and post-bomb soil samples and in the atmosphere gives us an estimate of the amount of carbon entering the soil each year as a result of photosynthesis by both higher plants and microorganisms.
 Phil Brookes Rothamsted Experimental Station Harpenden 
Pills take the biscuit
I could not swallow pills until I realised that it was a psychological problem (’ Sticky pills’) Monitor, 13 January, p 88).
The mind does not expect a swallow until after a chew so now I chew a small piece of biscuit and then pop in the Paracetamol and swallow without difficulty.
 G. H. Chase Welwyn Garden City 
ARIADNE
IT OCCURS to me that it might be as well to quote the time related charges or TRC that British Telecom should apply in making up bills for work, following last week's item.
There can be no secret about them, for British Telecom says in its instructions, ‘The customer may be told the hourly charge rate’, though whether he will be told if he does not ask is another matter.
Besides, the instructions also say, ‘The preparation of estimates giving manhours for a job should be avoided’, which hardly appears obliging or informative.
It seems to me that anyone having a job done should take careful note of the hours worked, or spent, on it and how many men are employed, or, at least, on the spot.
Normally, the rates are £19.50 for the first halt hour and for each additional quarter of an hour or part of it, £4.50, For weekday overtime the rates go up to £23.80 and £5.45, for Saturday overtime, £24.70 and £5.65, Sunday overtime, £31.70 and £7.15 and for Bank holiday overtime, £37.00 and £8.25.
If a job starts in normal hours and runs into overtime, that time should be charged at the quarter hour rate.
That means that the first half hour rate does not, or should not, apply.
Even if a job spreads over several days, the first half hour rate should be charged on the first day and not on the others.
It is some time since I have had any work done by British Telecom, so I do not remember whether hills are presented in detail.
It would be a good idea to ask for details if they are not supplied.
IN THE past 70 years or so, according to my far from faultless memory, there has been a reversal of the cowboys and Indians convention.
I remember small boys all wanting to be cowboys and the role of Indians having to be forced on the smaller ones.
Nowadays, nobility is on the side of those who used to be called Redmen, hardly surprising to anyone who has read any of the dreadful history of the spread of Europeans across the West.
What richness of tribal tradition and history was lost in the process is a depressing thought, But something has been saved from extinction.
A story from New York's Columbia University says that it has, preserved in its library, 10 000 pages of Tsimshian history, legend and mythology.
The Tsimshians are an Alaskan tribe.
Early in this century, a half-Tsimshian called William Benyon (he would have been called a ‘half-breed’ in the contemporary books of my childhood), interviewed all the tribal elders he could find and wrote their stories down.
He sent them to a famous anthropologist at the university, who gave them to the library.
Now, an Indian community in Alaska has started to print the material.
Two paperbacks of 40 folk tales have appeared and are local bestsellers.
Two more books are planned and there is enough material for five more.
The manuscripts from which the books have been compiled are written in English and in Beynon's own phoneticised version of the Tsimshian language.
To someone such as I, who had the vague but tenacious idea that Indians communicated in pictures only, a fragile method, it is pleasant to see that one scholar of native American languages calls the manuscripts ‘the largest corpus of texts’ of them and ‘a remarkable resource’.
A LETTER reproves me for singling out rotten spelling in other places, notably The Guardian , and goes on to point out that this magazine is not immune.
Sometimes the sound of breaking glass is distressing in this office as another hurled stone goes through from inside.
It is amazing how often you (well I) can be caught out on the very point you are trying to make.
For example, the first issue appearing after I poked fun at The Guardian for spelling septic as ‘sceptic’ had an article that spelt aseptic as ‘ asceptic ’.
Down came another few panes in the glasshouse.
It is probably the result of dealing so much with science.
Another rap came in the post for a wrong spelling of Marshal as in Marshal of the Royal Air Force.
It appeared as ‘marshall’.
Baffling, this, because it was right on the copy.
There is, as anyone in the racket knows, a kind of trap between the printer and the writer that will box things up if possible, in spite of the best efforts on both sides.
While I am about it, I had better apologise on behalf of a contributor, who was castigated by post for not looking up the meaning of a phrase that was, to him, mysterious.
It was ‘a-taunto’.
It would have been easy to track down, as a somewhat acidulous correspondent explained during a few remarks on the shortcomings of journalists.
Guilty as charged.
THERE has been some correspondence going on, it seems, in the American journal,Business Week about the savings to be made by discouraging smoking at work, William L. Weis, who is associate professor of accounting at Seattle University, lists them.
‘Here's richness!’, in the words of Wackford Squeers.
There is nothing to be gained by translating dollars into pounds in this story any more than doing it in a bank, so the money is untouched.
Weis says that each year and per smoker, over $350 can be saved.
But that is the beginning.
If you do not only frown on smoking but hire only non-smokers from now on you can, he maintains, save $5000 a year per smoker in the long run.
The savings come from less absenteeism, lower insurance costs, more productivity, fewer deaths (Weis calls this ‘much lower rates of worker mortality’), not so much deterioration in furniture, carpets and so on, including office machines, less maintenance and less spent on air-conditioning and heating.
I think there must be a period for a start when the office or elsewhere is a bit on the nervous and inefficient side as smokers are deprived, but he does not mention this.
Daedalus
LAST WEEK, Daedalus presented a scheme for making cars blow a foamy exhaust.
He is now extending this technology to human beings.
Our lungs are always moist, and exude a special surfactant to aid their expansion.
So he reasons that a foam blown with this natural surfactant could be effortlessly breathed.
Foam-breathing would have many uses, beginning with the use of oxygenated foam for instant well-being.
Without clumsy pipes and masks, it would be delightful to blow a big mass of oxygen foam from the DREADCO dispenser, and bury one's face in it.
(The natural surfactant, being isotonic with body fluids, will not sting the eyes like soap foam.)
Similarly, the inhalation of anaesthetics, bronchial sprays, tobacco smoke and so on could become a simple matter.
In particular, foam-breathing could make smoking a less anti-social habit, and more economical to boot .
A pipe or cigarette burns all the time, and just wastes smoke when the user is not drawing on it.
The DREADCO autopipe will store up its smoke as a long-lasting foam, to be inhaled at pleasure.
The user would breathe out in big bubbles and these could be caught in a ‘bubble tray’, preventing suffering for non-smokers nearby.
But Daedalus wonders what breathable foam would be like as a total environment.
Rather sensuous, he concludes.
You could not see or hear very far through it, but it would be quite a supportive, cocooning medium — foams can be very viscous.
It would be warm, insulating, and cleansing as well, forming a private and delightful world.
DREADCO's proposed ‘Public Foam Baths’ should provide the  traditional Turkish bath with strong competition.
In more serious vein, Daedalus suggests using breathable foam to ventilate coal mines.
Its ability to trap dust, the ease with which stale and fresh foam can be kept separate without mutual diffusion, and the barriers it offers to the spread of flame or explosion, are all points in its favour.