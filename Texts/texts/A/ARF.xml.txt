

Antibiotics and medicines
Microbes against microbes
It is widely believed that penicillin, a substance obtained from moulds of the family called Penicillium , was discovered by Sir Alexander Fleming at St. Mary's Hospital in London.
However, the antibacterial properties of some Penicillium moulds were observed several times from the 1870s onwards, and Lord Lister treated a patient with a preparation of Penicillium before Fleming was born.
When microbes were first cultivated and investigated, John Burdon Sanderson (1828–1905), later Regius Professor of Medicine in Oxford, observed that bacteria did not grow readily in the presence of certain Penicillium moulds.
Lister was then at the height of his struggle against infection in surgical operations and took up this observation in experiments with bacterial cultures.
He found that growth did not occur in cultures infected with the mould Penicillium glaucum .
The inference was obvious, and in a letter to his brother, a distinguished mycologist, Lister proposed to try using the mould for treating patients.
No report of the treatment appears to have been published at the time, but evidence has come to light that he did indeed treat at least one patient, a young nurse with a persistent abscess resulting from injuries received in a street accident.
She lived for many years, and preserved a record that she had been treated with Penicillium .
It is unlikely that the crude material did much good, and not surprising that no more was said about it at the time.
Simple application of a culture or scrapings of a mould to an exposed wound was an unsatisfactory business, and some sort of concentration of an active principle was needed.
An Italian, Bartolomeo Gosio, in 1896, described the extraction of a crystalline substance from culture filtrates of a Penicillium : the substance was later shown to be a compound called mycophenolic acid, with interesting biological properties but no valuable antibacterial ones.
Investigators in 1897 in Lyons, in 1908 in Vienna, repeatedly showed that various bacteria failed to grow or appeared to be  destroyed in the vicinity of Penicillium moulds, but the practical application of this fact was elusive.
The word ‘antibiose’ appeared in a paper by the French physician Jean-Paul Vuillemin in 1889.
The allied word ‘antibiotic, reached the English language when the botanist Marshall Hall used it 10 years later.
There is nothing surprising about antibiosis.
All living organisms are continually in competition with other species and other members of their own species in order to obtain their needs.
The smallest organisms are no exception, and any mechanism by which some individuals can dominate others has value for survival.
An organism able to check the growth of a competing species is fortunate and better equipped to survive, so we should expect that many living organisms are successful exponents of chemical warfare.
They include various moulds and some bacteria, especially those of the species at first called Bacillus pyocyaneus and later Pseudomonas pyocanea .
In 1899, Rudolph Emmerich (1852–1914), professor of hygiene at the University of Munich, produced a preparation named Pyocyanase from appropriate cultures, which controlled some bacterial infections when it was injected into animals.
It was marketed for a number of years and was the subject of numerous clinical reports before its use declined.
It may never have been genuinely effective, or it may have failed because the organism lost its antibiotic properties when it had been grown for years in artificial cultures, or because its commercial manufacture was inadequately supervised.
It is said that the final preparations owed their antibacterial activity to the phenol which they contained as a preservative.
Another enemy of bacteria was described in 1915 by F. W. Twort (see chapter 8).
He observed an agent, invisible with the microscopes available at the time, which could be propagated like bacteria in cultures and which dissolved bacteria in cultures which were infected with it.
This was his third notable discovery, and, like its predecessors, he did not pursue his observations, which were extended and given wider prominence by Felix Hubert d'Herelle (1873–1949).
He called it bacteriophage; later it was found to exist in many forms; or rather there were many bacteriophages, each associated with the bacteria of particular species.
Indeed, the specificity of bacteriophages made them useful in identifying particular strains of bacteria, and the procedure called ‘phage typing’ was used for tracing the organism responsible for the spread of an infection in a community.
The phage could be identified and acted as a kind of label, so that bacteria from a single source could be distinguished from others of different origin.
Bacteriophages appeared to be harmless to man, and seemed to be promising therapeutic agents of revolutionary importance.
But the results obtained by pioneer workers were not confirmed, when properly controlled experiments in infected animals failed to achieve any  success.
Much later, bacteriophages were found to transfer genetic information, from one bacterium to another, so they became immensely important tools for geneticists and have played a fundamental role in understanding the functions of deoxyribonucleic acid (see Chapter 11).
Fleming
By 1920 those searching for better defences against microbial infection had had many setbacks.
Apart from quinine for malaria and arsenicals for syphilis and sleeping sickness, chemotherapy was unpromising, usually because the ‘chemical’ did as much damage to the patient as to the microbe.
The obscure world of warfare between microbial species had suggested some promising substances, but was even less successful than chemotherapy.
The pyocyanases and the penicillia did not appear to harm patients, but they were too difficult to extract and too unstable to be useful.
Undoubtedly the natural defences of the human body held out the greatest promise of further success, and undoubtedly, in England if not in the world, Sir Almroth Wright was the leading expert in devising ways of stimulating such defences.
After leaving the British Army Medical Services, frustrated by the opposition of professional soldiers, he had created a research laboratory and clinic at St. Mary's Hospital where his theories were developed and his own authority was not to be questioned.
He was elected a Fellow of the Royal Society, and had powerful support from politicians and writers.
He and his ideas were portrayed on the London stage by G. B. Shaw in his play,The Doctor's Dilemma .
Wright's combination of autocracy, determination to advance and understand medical science, love of logic and new words, contempt for women, and occasional humility make him one of the most fascinating characters in the history of therapeutic progress.
He was supported by a band of younger doctors, of whom Leonard Colebrook and Alexander Fleming were outstanding characters in the search to cure infectious diseases.
Each of them achieved success by discovering the sort of drugs which Wright dismissed as impossible or useless.
The collaboration between Colebrook and Fleming in the earliest trials of Salvarsan in this country, and Colebrook's work in establishing Prontosil and sulphanilamide have already been mentioned (Chapters 3 and 8).
However Fleming has another place in this story.
In 1921 he discovered a substance which he named lysozyme.
The discovery was strictly in the tradition of Wright's philosophy of seeking natural defences against infection, though Wright may have grieved because it was made by chance and was not the fruit of logical reasoning.
Whatever its origin, this discovery had much importance in the future of penicillin.
As will appear later, it probably contributed more than Fleming's own later observations  on the mould Penicillium .
It was, in fact, a double discovery, both of a new microbe and of an agent which destroyed it.
Fleming's account, communicated to the Royal Society in 1922 by Wright, began:
In this communication I wish to draw attention to a substance present in the tissues and secretions of the body, which is capable of rapidly dissolving certain bacteria.
As this substance has properties akin to those of ferments I have called it a ‘Lysozyme’, and shall refer to it by this name throughout the communication.
The lysozyme was first noticed during some investigations made on a patient suffering from acute coryza….
Fleming went on to describe how the nasal secretions of the patient (himself, in fact) were cultured, and how a round microbe or coccus first grew and then was destroyed where it came close to the nasal secretion.
He named the coccus Micrococcus lysodeikticus and used it as a test for identifying the destructive or lysing agent.
(‘Lysodeikticus’ is derived from Greek and means ‘an indicator of lysis’.
The name was devised by Almroth Wright, who had a great love for such verbal inventions.)
In the first experiment nasal mucus from the patient, with coryza, was shaken up with five times its volume of normal salt solution, and the mixture was centrifuged.
A drop of the clear supernatant fluid was placed on an agar plate, which had previously been thickly planted with M. lysodeikticus , and the plate was incubated at 37°C. for 24 hours, when it showed a copious growth of the coccus, except in the region where the nasal mucus had been placed.
Here there was complete inhibition of growth, and this inhibition extended for a distance of about 1 cm. beyond the limits of the mucus.
This striking result led to further investigations, and it was noticed that one drop of the diluted nasal mucus added to 1 c.c. of a thick suspension of the cocci caused their complete disappearance in a few minutes at 37°C.
These two preliminary experiments clearly demonstrate the very powerful inhibitory and lytic action which the nasal mucus has upon the M. lysodeikticus .
It will be shown later  than this power is shared by most of the tissues and secretions of the human body, by the tissues of other animals, by vegetable tissues, and, to a very marked degree, by egg white.
At first sight this was a very promising substance indeed.
It came from human tissues, and so could reasonably be expected to be harmless to them, unlike the synthetic antibacterial substances such as arsenicals and flavines which were the best known at the time.
However, the promise did not hold.
Lysozyme appeared to be effective only against more or less harmless micro-organisms, and indeed no organism was found more sensitive than the curious M. lysodeikticus .
The microbes which caused dangerous diseases were unaffected by it.
Indeed, it appeared to be a necessary property of any microbe capable of invading animal tissues that it was resistant to the action of lysozyme.
So there was no place in therapeutics for lysozyme, but it had a more fundamental value: it showed  that substances did exist which were lethal to some microbes and harmless to human tissues.
What sort of a substance was it?
Fleming had called it a ferment, or enzyme, but that did not take matters very far, and gave no hint of what it might ferment, or of what substance it attacked in susceptible microbes.
Fleming made no progress in purifying lysozyme.
The isolation of specific active substances from living cells is an intricate and laborious business, requiring the skills of a chemist more than those of a medical doctor.
This was the time at which Harington was still grappling with the improved purification of thyroxine (see Chapter 5).
Loewi and Dale were far from identifying acetyl choline convincingly (see Chapter 6), and isolation of the vitamins was straining the abilities of many chemical laboratories in the western world.
The medical school of St Mary's Hospital, like the other London medical schools, was constitutionally part of the University of London, but was in fact academically isolated, and such research as might be undertaken had no facility for difficult chemical investigations.
Fleming continued to experiment as a bacteriologist with his material, but he had no advanced training in chemistry, and his environment did not throw chemically expert colleagues in his way.
Nor, had he sought to recruit a biochemist, was there any laboratory space available for his work.
It was only in the 1930s, in Oxford, that lysozyme was isolated and crystallized, and its exact mode of action determined, as described later in this chapter.
History was destined to repeat itself.
A few years later Fleming made another unpremeditated observation, this time on a mould of the genus Penicillium , and again failed, for lack of chemical support to develop it.
Again the work was completed in Oxford, and was carried through by the leadership of a man who made no mistakes in seeking chemical collaboration or in letting matters drop for lack of it.
His name was Howard Walter Florey.
Florey
.
H. W. Florey (later Lord Florey, P.R.S.)(1898–1968) was the Australian born son of an Oxfordshire shoemaker who had emigrated to Adelaide in 1885.
The son came to England for the first time in 1922 as a Rhodes scholar.
At Oxford he worked under and received support particularly from Sir Charles Sherrington, whose immense skill and wisdom influenced him greatly.
Florey found more interest in studies of the circulation than in Sherrington's own field, the nervous system, and presently moved to Cambridge with a studentship in pathology.
A brief visit to the USA in 1926 was followed by a research fellowship at the London Hospital, where he established a long lasting friendship with Paul  Fildes (see Chapter 8).
Unlike Fleming, Florey found the atmosphere of a London teaching hospital uncongenial and the conflicts between clinicians and research workers discouraging.
Cambridge was easily accessible, and he returned there to begin his major research activities.
He acquired a lasting scientific interest in mucus, possibly augmented by digestive problems of his own.
Very little was known about mucus at the time.
As a secretion of all the internal lining membranes of the body, it was important both for lubrication and protection against bacterial invaders.
Lysozyme, recently described by Fleming, evidently had some bearing on the protective function.
Florey, with a fellow Australian N. E. Goldsworthy, and with some help from Fleming in acquiring the technique of assaying lysozyme in samples of mucus, investigated the lysozyme content of samples of gastric secretion from various sources.
The result was disappointing.
No correlation was found between lysozyme content and resistance to bacterial infection.
In the course of this work, Florey and Goldsworthy made an incidental observation that some normal intestinal bacteria inhibited the growth of the test organism used in the lysozyme assays.
It was another example of the often described, but at that time seldom remembered, phenomenon of bacterial competition, and may have contributed to Florey's later decision to pursue other examples of antibiosis.
Meanwhile, his interest in lysozyme persisted.
He sought collaboration from various colleagues, including Marjory Stephenson (see Chapter 8) in the nearby Department of Biochemistry, but made little progress before his departure from Cambridge to fill successively the chairs of pathology at Sheffield in 1932 and Oxford in 1935.
It would be misleading to imply that mucus and lysozyme were Florey's only interest.
At the time when he became a professor, his reputation probably depended largely on his studies of the capillary circulation and of the blood cells concerned with defence against bacterial invasion.
He also studied spermicidal substances, in conjunction with H. M. Carleton, a histologist with whom he had made friends in Oxford.
The work provided the foundation for the vaginal use of gels containing organic mercurial compounds as aids to contraception.
It was an important study in selective toxicity, because it required the discovery of substances which brought spermatozoa to a standstill without damaging the tissues of the vaginal wall.
Later Florey collaborated with Paul Fildes in an experimental study of the use of curare to relieve the  intractable muscular spasms which occur in filly developed infection with tetanus or lockjaw.
As curare was only just emerging from obscurity (see Chapter 6), this was a very prompt seizure of a new opportunity for therapy.
Characteristically, the curare was obtained from the one source where the material obtained might be properly characterized, the laboratory of Henry Dale.
Perhaps the most important element in Florey's brief occupation of the Sheffield chair was that it brought him into close contact with Edward Mellanby (see Chapter 7).
Mellanby was professor of pharmacology when Florey was appointed.
They were colleagues for a year, during which time Mellanby no doubt formed a very definite appraisal of Florey's abilities.
Mellanby left Sheffield to succeed Sir Walter Fletcher in the powerful position of Secretary of the Medical Research Council.
Two years later, when the chair of pathology at Oxford became vacant by the untimely death of its incumbent, Mellanby was nominated as one of the electors responsible for finding a successor.
It is said that, at the crucial meeting of the appointments board, Mellanby's arrival was seriously delayed by a late train.
The board had decided on another candidate, an orthodox pathologist with predominantly clinical and descriptive interests and not an experimentalist.
Mellanby arrived in time to be heard, and succeeded in changing the decision so that Florey was appointed.
Without the resources of the Oxford department in the following three years, Florey would probably not have been able to bring penicillin to clinical fruition.
‘It is interesting to reflect that the course of the history of medicine — and, indeed, of the history of mankind — hung briefly on the timekeeping of the Great Western Railway’.
Florey continued his interest in lysozyme and furthered it both by collaboration with the professor of organic chemistry, Sir Robert Robinson (1886–1975) and by recruiting an enthusiastic and skilful biochemist E. B. (later Sir Ernst) Chain (1906–1979).
Chain was the son of a Russo-German industrial chemist and himself a Ph.D.
in chemistry of the Friedrich-Wilhelm University in Berlin.
He had worked on the optical specificity of certain enzymes (one may remember that problems of optical activity first drew Pasteur from chemical to biological problems) but was also devoted to music and became the music critic of a Berlin evening paper.
He nearly adopted music as a profession, but left Germany during the Nazi persecutions because of his Russian and Jewish ancestry.
He found an opportunity to work in the biochemistry laboratory at Cambridge, and then came to Florey.
He completed some work on snake venoms and, turned to lysozyme.
E. A. H. Roberts, and later E. P. (later Sir Edward) Abraham, both students of Robinson's, succeeded in purifying and crystallizing lysozyme, while Chain collaborated in showing that it was indeed an enzyme, as Fleming had suggested, and that it decomposed an essential constituent of the cell wall of those organisms which were sensitive to its effect.
These discoveries would not be very difficult to make nowadays, but with no more than the techniques of the time, each was a great achievement.
So the lysozyme story was completed.
It did not produce any direct advance in therapeutics, but it remained as evidence that powerful antibacterial agents were not incompatible with living human  tissues, and that chemical methods of investigation were essential for solving biological problems.
In principle, the techniques were now established by which other antibacterial substances could be nailed down.
A new tool for bacteriologists
In 1929, while Florey was working in Cambridge, Fleming published a paper with the title ‘On the antibacterial action of cultures of a Penicillium with special reference to their use in the isolation of B. Influenzae ’.
It reported work done in the previous year, arising, like Fleming's earlier discovery of  lysozyme , from a chance observation.
Later research has shown that some of the statements in that paper do not agree with records made at the time in the laboratory notebooks of some of the people concerned.
Also, it has proved very difficult to reproduce the events which led to Fleming's famous observation, and it is clear that many versions of the story which were published 15 or more years later, after penicillin became famous, drew on faded but vivacious memories and are more or less imaginary.
At the time, Fleming's observation of a contaminated culture plate aroused little interest in his colleagues.
It looked like another  lysozyme , and, after 6 years with little progress, that subject may have become tedious.
Fleming's colleagues most concerned were Ronald Hare (1899–1986), a St. Mary's graduate with a scholarship to do bacteriological research, F. Ridley, an ophthalmologist working on lysozyme, S. R. Craddock, another research scholar working under Fleming's direction on staphylococcal variants, and C.J. La Touche, a mycologist investigating the role of fungi in precipitating asthmatic attacks and the development of vaccines against them.
Hare's account of the events has been published, and many obscure points in the history of the discovery have been investigated subsequently.
Professor Hare, as he later became, was an eminent bacteriologist and had worked in the laboratories where the discovery was made, so his account is preferable to some of those written by imaginative authors with no scientific training.
Fleming made his famous observation late in the summer of 1928, when he called in at his laboratory during his summer holiday.
During his absence, Craddock was using the room, as the amount of space available in the department was very limited.
Among the numerous culture plates awaiting inspection or disposal, Fleming noticed one unusual one, contaminated by a mould around which the staphylococci appeared to have been lysed (dissolved).
Fleming set up a culture of the mould, and preserved the plate by fixing it in formalin vapour.
Then, having shown the plate to various not very excited colleagues, he resumed his holiday.
The first entry in Fleming's notebook about the mould is dated ‘Oct.30. '28.’
It describes an experiment, the first of many, to see what  organisms were inhibited by the mould.
This approach was followed for some months, so that an impressive list was produced of sensitive organisms, including many important pathogens.
To simplify the experiments, Fleming set Ridley and Craddock to grow the mould and make extracts of the culture medium on which the mould had grown.
Whatever inhibitory material was present appeared only after the mould had grown for several days, so there was an obvious advantage in having a stock of the active principle ready for bacteriological experiments.
Ridley had taken a course in biochemistry, and so was probably the person best equipped to pursue the matter, which turned out to be very difficult.
The mould juice was filtered, concentrated by evaporation to a ‘sticky mass’, and the proteins (derived from the original broth on which the mould was grown) were precipitated with alcohol, an orthodox procedure for their removal.
Unexpectedly it was found that almost all the inhibitory substance passed into the alcohol.
This was important, because it showed that it was not a protein, and so clearly differed from lysozyme.
From this point on, progress was limited because of the great instability of the inhibitory substance.
Craddock's notebook shows that he found the substance soluble in acetone, but this fact, like various other details of Ridley and Craddock's work, was not reported in Fleming's paper.
Fleming was no chemist and appears not to have been interested in pursuing the chemical problem.
He was, as a bacteriologist, interested in the microbiological aspects, and as an enthusiast for technical methods, in the use of Penicillium extracts to make selective culture media (i.e. media in which a required organisms will grow readily while unwanted contaminants fail either through lack of an essential nutrient or because something is present which stops them).
This aspect was emphasized by the title of his paper on Penicillium .
Requests for samples of his mould soon came from several laboratories, including the pathology laboratory at Oxford.
Fleming sought help in identifying the mould from the mycologist La Touche, who worked in the same building and who thought that of the many species of Penicillium , it was most like Penicillium rubrum .
This diagnosis was later upset, but it was of no great importance, because the mould which contaminated Fleming's plate was almost unique even within its species (P. notatum ) in producing inhibitory material on an appreciable scale.
The only other mould found to have equal activity was one kept in culture by La Touche, with which Fleming's mould appeared to be identical.
Hare had noticed that the windows of Fleming's laboratory were rarely opened and indeed were almost inaccessible across laboratory benches stacked with glassware.
It must be admitted that the famous mould may well have strayed upstairs from the cultures on the floor below, and is perhaps to be included in the long list of profitable discoveries which arose from a lapse in maintaining the highest standards of laboratory practice.
The therapeutic possibilities of the inhibitory substance appear to have received little attention from Fleming.
He showed that it was harmless to white blood cells, which are a principal defence against invading microbes, and he and Craddock administered enough to animals to discover that it was remarkably innocuous.
Craddock had a chronically infected nasal antrum, and Fleming and he tried instilling some mould filtrate into it, with no obvious benefit.
Another member of the laboratory staff received treatment for a conjunctivitis caused by pneumococci, with a successful result.
Ridley, as an ophthalmologist, might well have followed up this observation with more studies of eye infections, but the opportunity seems not to have been pursued.
A recently qualified medical student from St. Mary's, C. G. Paine, who had been taught by Fleming and who had gone to work in the Royal Infirmary at Sheffield, obtained a sample of the mould from his former teacher and carried out some clinical experiments with it.
The notes of some of the patients treated have been rescued, and appear to be the oldest surviving records of the clinical use of the material.
When Florey came to the chair of pathology at Sheffield a year or two later, Paine mentioned the matter to him but aroused no obvious interest.
However, Paine's observations were duly recognized when Florey and his colleagues published their substantial text on antibiotics in 1949.
In his paper, in 1929, Fleming mentioned the possible use of penicillin as an antiseptic in surgical dressings, but the matter was taken no further.
Fleming went on using mould extracts in selective media, and published once more on the subject before 1942.
He had abundant other work with which to occupy himself.
Craddock left to take up an appointment at the Wellcome Research Laboratories, and Ridley went to join the staff at Moorfields Eye Hospital.
Trials and apathy in diverse places
In contrast to the unpremeditated way in which Fleming was taking up chance observations, various scientists were making methodical studies of microbes of all kinds.
Notably, at the London School of Hygiene, a couple of miles from St Mary's Hospital, Harold Raistrick (1890–1971) was examining the biochemistry of moulds and other fungi.
Like so many biochemists of the time, Raistrick had worked in Hopkins's laboratory, using chemical methods to study the living cells of micro-organisms.
After 9 years in which he applied microbial biochemistry to industrial manufacturing problems, he returned, in 1929, to academic work as professor of biochemistry at the London School of Hygiene, where he continued to identify the chemical constituents of fungi and discover their functions.
Fleming's paper on an antibacterial substance from a Penicillium mould was a natural starting point for a branch of Raistrick's research.
He  obtained a sample of the mould from Fleming, and discovered that it had been incorrectly identified.
After proper consultation and correction of the error, Raistrick set out to isolate active substances from Fleming's mould.
He made an immediate advance by growing the mould on a medium consisting only of simple salts and glucose, instead of the broth which Fleming had used.
This meant that any extraction procedure was much cleaner and more satisfactory: the mould might provide some tiresome debris, but at least the medium did not add the viscous remains of stale meat soup.
Fleming's paper had given no details of Craddock's work, and indeed was misleading about it.
Communication between Raistrick and Fleming appears to have been minimal.
Unknowingly Raistrick followed the same path as the St. Mary's workers and came to the same conclusion: the instability of the antibacterial substance did not make further attempts worth while.
Raistrick's prime interest was in the biochemistry of moulds, and he was not particularly aiming to isolate antibacterial agents from them.
A full-scale attack on the evanescent substance would have diverted many resources from other problems equally as or more important, and Raistrick had no reason for making such upheaval.
He did not rate his findings on the antibacterial substance worthy of a full paper, and included them in a publication which dealt with several substances derived from Penicillia .
Ten years later, when penicillin had been established as an effective drug, Raistrick gave fresh attention to the therapeutic possibilities of antibiotics.
He achieved notable if modest successes by contributing to the discovery of Patulin, which achieved a transient reputation for curing the common cold, and Griseofulvin, which was developed commercially and is used for the treatment of fungal infections of the skin.
One or two other workers made attempts at isolating the antibacterial substance from Penicillium during the 1930s.
One, Lewis Holt, actually worked in Fleming's laboratory, and took the purification a stage farther than any of the previous workers, but he did not publish his results and again what was achieved at St. Mary's had to be rediscovered by later workers.
A systematic search for the agents produced by microbes was also being made in New York, at the Rockefeller Institute for Medical Research, by René Dubos and his colleagues.
Their rationale and objectives were somewhat different.
Dubos started from the assumption that all organic matter added to the soil eventually undergoes decomposition through the agency of micro-organisms.
It followed that somewhere in the world there were soil micro-organisms with enzymes capable of attacking any substance which occurred in living tissues, and, given such enzymes, that one might use them, for instance, to destroy bacteria lethal to man.
This was neither the basic approach of Raistrick to fungal metabolism, nor quite  the same concept as that of antibiosis, but it led to a similar outcome, the possible discovery of a microbial agent which could destroy the microbes that caused disease.
The search prospered moderately.
Dubos published two papers in 1939 describing the extraction from a soil bacillus of a substance, active against some pathogenic micro-organisms, which cured mice infected with pneumococci upon injection.
It was named tyrothricin and was later shown to contain two polypeptide components, which were named gramicidin and tyrocidine.
Its potential use was limited because it was not absorbed from the gut and so was ineffective if given by mouth, and because tyrocidine, in concentrations liable to occur during therapeutic use, damaged or destroyed red blood cells.
However, though not much of an advance on existing antiseptics, it is still included in some antiseptic lozenges for sore throats.
Tyrothricin can reasonably be regarded as the first antibiotic to be established as a therapeutic substance.
Like the sulphonamides, it showed that bacteria could be attacked in vivo by single substances of external origin, and, like lysozyme, that such substances could be obtained from living organisms.
But it took time to develop interest.
Without the encouragement of interested colleagues, some scientists showed little initiative in applying their knowledge of antibiotic substances to practical ends.
One notes S. A. Waksman (1888–1973), who worked at the Agricultural Experimental Station of the State University of New Jersey.
He pursued the antimicrobial properties of soil organisms, particularly actinomycetes, which had been known since the 1920s to produce inhibitory substances.
He had been studying soil fungi since 1916, and wrote a survey of the known inhibitors in 1940, but his effective contribution to medicine came after the very modest success of tyrocidin and the very great success of penicillin.
Dubos had been a pupil of Waksman, and together they tried to organize a round table discussion at the meetings of the Society of American Bacteriologists in Saint Louis during Christmas 1940, on the subject of the production of antibacterial substances by micro-organisms.
The subject attracted no interest, and they failed to secure enough participants for the proposed 2-hour discussion.
English bacteriologists and microbiologists have little reason to claim that they were more perceptive than their American contemporaries, but there was one exception.
In a laboratory in Oxford the purification of penicillin had progressed far enough to be reported in The Lancet in August 1940.
This was 4 months before the St. Louis meeting mentioned above, so the publication evidently did not stimulate much excitement in the United States.
It was, however, a preliminary report, made before clinical trials had taken place.
To appreciate the progress that was being made, we must  return to the career of Howard Florey, whom we left newly appointed to the chair of pathology in Oxford and continuing, among other objectives, to study Fleming's lysozyme.
Breaking Through
Florey had wide interests but was determined to achieve results and not to dissipate his energies.
His resources were grievously limited.
His laboratories were housed in an excellent building, provided by the generosity of Sir William Dunn's Trustees on the advice of Sir Walter Fletcher (see Chapter 4), but the morale of the staff was low.
Florey's predecessor, Georges Dreyer (1873–1934) developed a vaccine against tuberculosis.
The press published premature and optimistic reports, while trials of the vaccine showed that it was ineffective.
Dreyer was unfairly discredited, and appears to have lost heart for further work.
The story was no doubt well known to Florey and may have contributed to his own dealings with the press.
There were no endowments to finance the upkeep of the building and the work inside it.
A university steeped in classical, historical, and literary traditions was not unfriendly to science but had little awareness of the growing cost of high level scientific research, and even, perhaps, in some quarters reservations about its importance.
Staff appropriate to Florey's aims had to be recruited and grants to pay them obtained from outside bodies.
The Medical Research Council were helpful up to a point, but even Mellanby rapidly found Florey's demands tiresome and support from that quarter dwindled.
When it failed, the Rockefeller Foundation contributed generously.
With the funds available, Florey collaborated with Chain, whose work on lysozyme, already mentioned, led naturally to a study of a wider range of antibacterial agents.
The mould Penicillium looked interesting, and was available: research workers in the department had been using it, just as Fleming was doing, to prevent the growth of unwanted organisms in bacterial cultures.
Other antibiotics described in published research papers were considered.
Eventually three were chosen for the first investigation — the products of Bacillus subtilis, Pseudomonas pyocyanea , and Penicillium notatum .
Both Florey and Chain later emphasized that their study was directed to a better understanding of antibiotic action and not specifically to finding a therapeutic substance.
Penicillin was an unpromising candidate for therapeutic use because of its instability and reputed inactivation by blood, but this did not reduce its scientific interest.
Chain began working in the summer of 1938 on penicillin and pyocyanase, though by January 1939, when an application for funds was made to the Medical Research Council, penicillin and ‘actinomycetin’, an antibiotic which Waksman was studying, were  mentioned.
Evidently some of the progress made by Waksman attracted Florey's and Chain's attention.
Sharpening the focus on penicillin appears to have been a gradual process.
Various stories lend drama to the ‘decision’ to concentrate on penicillin.
A paper from the Dunn School in 1941 described three antibacterial substances from Ps. pyocyanea .
Moulds do not usually grow fast, and conditions had to be found in which large quantities of Penicillium notatum could be produced as quickly as they were wanted.
The solution to this problem was helped by N. G. Heatley, a young biochemist also from Hopkins's laboratory in Cambridge, who had been prevented by the outbreak of war from going to work in the Carlsberg laboratories in Copenhagen.
His engineering skills and technical ingenuity were invaluable.
Methods of extracting the active substance from the Penicillium cultures had to be found.
Raistrick's work had been published and provided a valuable starting point.
A rapid method of assaying samples was essential in order to discover which extracts were giving the best yields, and the sooner a stable crude preparation was obtained which could act as a standard, the better.
Extractions were achieved without appreciable loss of activity (but not without discomfort) by working at temperatures below 5°C.
Freeze drying was valuable.
This was a technique which had evolved during the 1930s and would hardly have been practical either for Craddock at St Mary's in 1929 or, perhaps, even for Raistrick in 1931.
Florey's team produced material which stopped bacterial growth at the remarkable dilution of two parts per million.
Moreover, it was not harmful when it was injected into mice.
Later, it became clear that this material, despite its potency, contained only about 1 per cent of pure penicillin and that it was almost entirely composed of material which was not penicillin.
Florey and Abraham wrote
It must be considered extremely fortunate that the first preparations of the sodium salt of penicillin, which although of great antibacterial activity contained over 99 per cent of impurities, showed so little toxicity.
If even one of the many impurities had been highly toxic, as it might well have been, the non-toxicity of penicillin might have been completely masked, with unpredictable effects on subsequent work.
By the time these results had been achieved, World War 11 had passed from the uneasy calm of its first winter into the violence of the European devastation of 1940.
On 25th May, while the German army raced ruthlessly across Belgium and the inhabitants of England watched their skies for the first signs of airborne invasion, the scientists in the Oxford Pathology Department performed a crucial experiment.
Chain and Heatley injected streptococci into mice and then treated some of the mice with penicillin.
Later Chain went home.
Heatley stayed until 3.30 a.m., when all of the untreated mice had died.
The treated mice were alive.
When Chain came in on Sunday morning and saw the result, he is said to have danced.
His colleagues ‘all recognized that this was a momentous occasion.
What they said is not recorded, but memory has supplied subsequent writers with various versions.
One might suppose that Heatley said very little, that Chain was excited, and that Florey's reported comment ‘it looks quite promising’ would be entirely in character'.
One wonders how the scene compared with that in Domagk's laboratory several years earlier, when the mice treated with Prontosil were alive and the controls had all died (see Chapter 8).
Penicillin arrives
In the experiment of 25th May 1940, the treatment of four mice with penicillin required a substantial fraction of all the material so far extracted.
A man weighs about as much as 3000 mice, and might need a bigger dose on the same scale.
If penicillin was going to be tried in man, how on earth was enough going to be made?
Chain had overcome the problems which had defeated every previous experimenter with penicillin, but only on a small scale.
One cannot suddenly scale up a laboratory procedure by a thousandfold.
Outside help was essential, but war-torn British industry was stretched to breaking capacity and the survival of a handful of mice was too thin a basis for disrupting existing essential activities to pursue what may well have appeared to be an academic will-o'-the-wisp.
Somehow enough material had to be made to establish the worth of penicillin in man.
Somehow, it was made.
By making do and searching for essential materials — in a war-torn country — a production unit was created in the University Pathology laboratory and enough crude penicillin was extracted for further essential laboratory experiments and to treat several patients in the Radcliffe Infirmary half a mile away.
The results were impressive, but marred by the death of at least one patient because there was insufficient material to continue treatment.
In August 1941 a second paper appeared from Florey's group, now with clinical collaborators.
By then Florey and Heatley had gone to America to seek aid from a richer country not yet involved in war.
The difficulties which they met were formidable, and as much political as scientific.
Florey had been supported by the Rockefeller Foundation and received guidance where to look.
A. N. Richards (1876–1966) had worked in England with Florey and was now a scientific power in America and a source of valuable information.
Of the many contacts explored, the most fruitful early collaboration came from the United States Department of Agriculture's North Regional Research Laboratory at Peoria, Illinois, where there was much experience of culturing micro-organisms.
Here  Heatley stayed for some months, working with A.J. Moyer, a first-rate investigator of fermentation processes but also an anti-British isolationist, in the development of deep fermentation (instead of surface culture).
This process had already been invaluable to industry and proved to be so for penicillin.
It was here that it was discovered that ‘corn steep liquor’, the material left over after extracting starch from maize, was a valuable nutrient for Penicillium notatum .
When Heatley went to Peoria, culture methods were yielding 2 U ml&sup/minus1;; with these changes and new mutants of the mould, yields up to 900 U ml&sup/minus1; were obtained.
Meanwhile Florey was, as he called it, ‘carpetbagging’ around American pharmaceutical businesses with varying success.
In the end, several firms undertook penicillin production on a massive scale, but hardly any ever came to Florey himself for the clinical trials which he was desperate to extend.
The first patient to receive commercially produced penicillin in America was treated on the 14th March 1942.
By August 1943 material was available at $200 per million units, and a year later, just before the invasion of Europe on 6th June, the price was $35.
In 1950 it had dropped to 50 cents per million units.
Although the American achievement in obtaining high yields of penicillin from mould cultures was crucial to the practical introduction of penicillin on a worldwide scale, manufacture by chemical synthesis was naturally an attractive alternative.
First the chemical identity of penicillin had to be established: second, a method of making it had to be found.
It was soon apparent that more than one penicillin existed.
There was Florey's original material, which became known as Penicillin-I or Penicillin-F (for Florey); Penicillin-II or Penicillin-G (because G came after F) from the Squibb Laboratories; Penicillin-III or Penicillin-X from the laboratories at Peoria; and Penicillin-IV or Penicillin-K from the Abbot Laboratories.
The central nucleus of all these penicillins was the same, but the exact structure was established only after much controversy.
Its identification was an early success of X-ray crystallography.
Synthesis was achieved only after some years, and only by methods which did not justify expansion to an industrial scale.
It is interesting to compare this fact with the ridicule to which some experts were exposed for developing fermentation methods of producing penicillin —‘obviously to be a flop’.
Hereafter the penicillins were studied in countless laboratories, academic and commercial, and discoveries were made which enabled them to be better understood and used as the foundation for many new drugs.
Inevitably, when penicillin was widely used, the least sensitive microbes proliferated and others were able to adapt by developing penicillin-splitting enzymes.
Organisms resistant to penicillin, particularly staphylococci, became a major problem by about 1960, especially in hospitals, and accelerated the search for alternative antibiotics and for  modifications of penicillin which were resistant to the bacterial penicillinases.
The discovery, in 1945 by Brotzu in Sardinia, of antibiotic activity in a species of Cephalosporium recovered from the sea near a sewage outfall was brought to Florey's attention by a former British public health officer and led to work at Oxford and elsewhere on this and similar organisms.
Of the several active substances which were isolated, the cephalosporins have become particularly valuable.
The synthesis of penicillin on a commercial scale proved  intractable , but enzymic and chemical modification of penicillins led to semi-synthetic substances, based particularly on economic ways of generating the nucleus, 6-aminopenicillanic acid, by fermentation.
Chain, exasperated by the British failure to provide him with adequate research facilities, migrated to Rome, but was retained as a consultant by Beecham's at a time when the firm was rapidly developing its research facilities.
He had much influence on the Beecham team who isolated 6-aminopenicillanic acid.
From a therapeutic aspect, penicillin was marvellous because it cured many dangerous bacterial infections, but it was tiresome because it was inactive by mouth (it was destroyed by the acidity of the stomach contents), it acted for a very short time (it was rapidly excreted by the kidneys) and so was of little value unless given by injection at intervals of not longer than 3 hours, and because, after a time, the normal processes of evolution led to the appearance of resistant strains of the microbes which had previously been sensitive to penicillin.
All of these problems were more or less overcome by ingenious chemical manipulation, so that a very wide range of semi-synthetic penicillins have become available.
Resistance may be expected to develop in turn to these variants.
Publicity
As Fleming shared a Nobel Prize for the discovery of penicillin with Chain and Florey in 1945, one may reasonably ask what he was doing during the critical years 1938 to 1942.
The matter has been handled in meticulous detail both by Hare and Macfarlane, and only the most salient points can be noted here.
Fleming continued to work with penicillin as an aid to the isolation of bacteria in cultures all through the 1930s.
When the sulphonamides came on the clinical scene, he gave much attention to them.
In a letter to the British Medical Journal in 1938 on the treatment of pneumonia he stated that sulphapyridine was active against pneumococci only when helped by leucocytes, and (true to the tradition of Almroth Wright) its action was improved if anti-pneumococcal serum was administered at the same time.
He also recommended the use of vaccines to stimulate immunity to the pneumococci, but made no reference to the  penicillin, a little of which, presumably, was in his reach while he wrote the letter.
The first (1940) paper from the Oxford workers attracted his attention.
He arranged by telephone to visit Florey at the Oxford laboratory and did so on 2nd September.
He appears to have been pleased that someone was fostering the substance which so interested him, and went away with a sample of Oxford material, which was more potent than any he had himself prepared.
After this he began mentioning penicillin at the end of lectures on sulphonamides.
The 1941 paper from Oxford led to some comments in the press, which included reference to Fleming and to Oxford, but Fleming's first substantial clinical observation with penicillin appears to have occurred in August 1942, when a patient, an employee of Fleming's brother's optical firm, was failing to respond to treatment for meningitis in St Mary's Hospital.
Fleming succeeded in isolating a streptococcus from the cerebrospinal fluid of the patient, showed that it was sensitive to penicillin, and obtained a supply from Florey, because he himself had none of adequate potency.
When intramuscular injections of penicillin failed to cure the patient, and after consulting Florey, Fleming took the heroic measure of injecting penicillin directly into the cerebrospinal fluid, where the streptococci still lurked.
The treatment succeeded and the patient recovered rapidly.
By arrangement with Fleming, the case was included in results of clinical trials published by the Oxford workers in March 1943, and Fleming published a more detailed account in October 1943.
Each thanked the other in the two publications.
Before the patient left St Mary's Hospital, a leading article headed ‘Penicillium’ appeared in The Times and a few days later a letter was published from Sir Almroth Wright claiming Fleming as the discoverer of penicillin.
This, of course, caught the attention of many journalists, and St Mary's did not fail to provide them with information.
Another letter in The Times , from Sir Robert Robinson, drew attention to Florey's work and set enquirers off on a new tack to Oxford, but their journeys turned out to be unrewarding.
Florey, for reasons already mentioned and for others, had no wish to deal with the press.
The reporters were sent away empty handed, while Florey told his staff to give no information whatsoever to journalists.
For St Mary's his actions were a godsend.
This was before the days of the National Health Service.
The voluntary hospitals, of which St Mary's was one, depended on charity for their income, and were often desperately impoverished.
Any success that could be claimed to the credit of St Mary's Hospital improved its chances of acquiring much needed donations.
The Dean, Lord Moran (1882–1977), had close connections with Lord Beaverbrook (1879–1964), already a benefactor and, more important, proprietor of the Daily Express newspaper.
The story of Fleming's discovery was a superb one and gained delightful embellishments  as it dwindled in truthfulness.
Fleming himself, to his credit, was at first distressed by the publicity and wrote accordingly to Florey.
But the publicity machine had come into operation and nothing would stop it.
Later, Fleming evidently came thoroughly to enjoy the fame which was thrust upon him, and to travel across the world to receive prizes and honours of many kinds.
Most people believe what they are told most often, and the myth has become unshakeable.
A few people, very few, had a healthy scepticism.
J. Brunel, professor of mycology in Montreal in 1944, alerted by a popular article on the wonderful new drug, looked briefly at Fleming's original publication on Penicillium , and at other publications, and wrote an article very property drawing attention to some of the literature which Fleming had omitted to quote.
Florey himself, in a lecture given in 1945, made a similar review, which was amplified in the great book on antibiotics written by the Oxford group in 1949.
But the myth was more entertaining when dull but inescapable facts were omitted.
Some of Fleming's biographers have been writers without medical or scientific training.
They have tried to make a personal and human drama out of what was, in fact, a sequence of astonishing scientific events.
Some of these events are still not well understood; although Hare and Macfarlane have done much to bring the most important medical discovery of this century into proper perspective.
Fleming discovered the important strain of the mould later identified as Penicillium notatum .
He coined the word ‘penicillin'.
But he did not isolate or identify the substance, and for 12 years or so con fined his work to the use of crude extracts in selective culture media.
It may seem sad, or even tragic, that so much credit has gone to Fleming and so little to Florey and his team at Oxford.
All the early supplies of penicillin which came to the public were manufactured in America, and, in America at least, it was natural to assume that penicillin was an American discovery.
If the trumpets of Britain had not been blown loud and long from St Mary's, a different myth would have grown giving all the credit to America.
There was plenty of substance for such an idea.
Without the work at Peoria and in many American industrial laboratories, many more months or years would have passed before penicillin became readily available.
From another angle, one may note that the receipt of publicity, as Florey knew well, is an astonishing waste of time which can be spent on more worthy scientific activities.
While Fleming travelled the world receiving plaudits, Florey was continuing to direct ‘the best school of experimental pathology in the world’ and pursuing the discovery of more antibiotics.
He also became President of the Royal Society, so that for 5 years he led its activities in nurturing British science and ripening its fruits.
He received a life peerage and the Order of Merit; headed an Oxford College with distinction, and promoted the birth of the Australian National  University at Canberra.
It was not a bad set of compensations for unawarded praise.
Streptomycin and onwards
The next antibiotic to be discovered, streptomycin, was of great value because it attacked microbes which were insensitive to penicillin, especially those which caused tuberculosis.
Its discovery was the result of prolonged studies of the microbes which exist in soil and survive by breaking down the remains of plants and animals, and by competition with each other.
This was the real world of antibiosis, which occupied much of the life of S. A. Waksman.
The scavenging activities of soil microbes are of great importance to human welfare, but Waksman's studies were not orientated to medical applications.
Waksman was born in the Ukraine, the son of a small trader in a small town, and suffered the difficulties common to the Jewish community in that environment.
He has written a memorable account of his spiritually rich but socially oppressed childhood, his struggles for education, and his emigration to the United States in 1913.
In America he made good.
He obtained a Ph.D.
in biochemistry at the University of California and spent his working life at the Agriculture Experimental Station of the State University of New Jersey, where he gave strength to the science of soil microbiology.
His studies inevitably included competition between microbes living free in the soil.
The organisms which were his special interest, the actinomycetes or ray fungi, were particularly vigorous in producing substances which inhibit the growth of other microbes.
Waksman is said to have been shown a culture of tubercle bacilli which had been killed by a fungus in 1932, but he was not tempted to pursue the implications of this observation.
The general lack of interest in antibiosis at this time was no doubt discouraging, but it did not prevent his former pupil Dubos from bringing tyrothricin to clinical trial.
Waksman records that the great American pharmaceutical firm of Merck established a fellowship in his department in 1938 for the study of industrial fermentation processes, and made grants to him from 1939 onwards for research into antibiotics.
In 1942 his son, then a medical student, urged Waksman senior to isolate strains of Actinomyces active against human tubercle bacilli, but he replied that the time had not come yet.
However, in 1944 a paper appeared describing the properties of streptomycin, a substance obtained from a kind of Actinomyces recently reclassified and named Streptomyces .
The short report included a table showing the concentration of streptomycin which stopped the growth of various organisms.
Tubercle bacilli are included in this table, in a single line, without  information about the strain used and whether it was virulent or not.
The paper is often quoted as the original report of a major discovery, but it does not look like it.
It is difficult to believe that the authors saw the implication of their findings for human medicine.
The report, or news of it, attracted the attention of W. H. Feldman and H. C. Hinshaw, who were studying drugs for the treatment of tuberculosis at the Mayo Clinic in Rochester, Minnesota.
They made contact with Waksman and with Merck, and obtained supplies of the drug for trials in infected guinea pigs, and, when these were successful, in man.
Once clinical investigations began, events moved fast.
Economical methods of manufacture were devised at Merck, while clinical trials were organized by the Committee on Chemotherapeutics of the USA National Research Council, and the drug was distributed without charge to selected institutions.
By the beginning of 1947 the drug began to be available commercially.
The cost, like that of penicillin, was reduced about seventyfold between 1946 and 1950 by improvements in large scale production.
Streptomycin is more stable than penicillin and so it was easier to isolate and manufacture.
It is also more toxic, and from an early stage a further disadvantage gradually became apparent: tubercle bacilli become resistant to it remarkably quickly.
Later other drugs were discovered which mitigated this handicap.
Without them the useful life of streptomycin might have been confined to a few years.
But it was the first drug generally recognized as life saving in tuberculosis.
Miliary tuberculosis (tuberculous septicaemia) and tuberculous meningitis, hitherto consistently fatal conditions, yielded to it.
It is not surprising that a Nobel prize was awarded in 1952 to Waksman, though there are many reasons why other contributors were also worthy of honour.
The successes of penicillin and streptomycin naturally led to a search for further antibiotics.
The resources of many pharmaceutical firms were applied to the search for new moulds and other micro-organisms.
Innumerable materials were screened for antibacterial activity, and, incidentally, for any other kind of activity which screens (see Chapter 6) might detect.
Active principles were purified and identified chemically, and, when good fortune attended the search, developed into therapeutically useful agents.
Duplication of discovery was not surprising.
One agent, polymyxin,(later found to comprise a family of closely related substances) was reported independently from three separate laboratories in Britain and America in 1947.
The material originated from a widely distributed soil organism and was active against various bacteria, some of which at that time still awaited effective therapy.
The polymyxins had various limitations, but they were followed by the tetracyclines, chloramphenicol, and many other antibiotics.
Some were more active than  any predecessor against some particular organism, and some had special merits in use, such as working when given by mouth, or acting for a longer period than usual.
Some were active against strains of organisms which had become resistant to older antibiotics.
But the pathway to discovery was established and the scale on which resources were expended to make these discoveries represents a fantastic extravagance when it is compared with the few thousands of pounds available to Florey and his colleagues, and even with the subsequent development of the original penicillins in the United States.
Although it was more economical to use living organisms to produce penicillin, and also streptomycin, there was no fundamental reason why antibiotics should be regarded differently from drugs made in a laboratory or industrial plant by chemical processes.
Chloramphenicol was the first antibiotic to be prepared synthetically on a large scale, and no difference has been recognized between the therapeutic properties of material made by microbes and by man.
No mystique need surround antibiotics because of their biological origin.
Now there are remedies for most bacterial infections.
Viruses are more difficult, and are discussed in the next chapter.
However, it remains to be seen how completely the principle of antibiosis, or chemical warfare between species, has been exploited, and whether the capacity of microbes to adapt to their environment will outstrip the capacity of man to find means of destroying not only those which are his enemies but also those which are his friends and which he unwittingly eliminates by the overzealous distribution of his new agents.
Towards the conquest of infectious diseases
Malaria: discovery in the laboratory
Long before the sulphonamides were used as medicines, quinine was known to be a specific drug against malaria.
It did not prevent infection; it only checked the later multiplication of the parasite after infection had taken place.
Nearly all the world's quinine came from Java, and, if Java fell into enemy hands (as it did in 1942), supplies would virtually cease.
Chemists had attempted to synthesize quinine for the previous hundred years (see Chapter 2) but all they had achieved was to discover the extreme complexity of the problem.
In the 1930s, with the threat of war and the knowledge that it might be fought in territories infested with malaria, the need for additional remedies was evident.
Little was known in English-speaking countries about the new synthetic drugs (see Chapter 8) discovered in Germany in the 1920s and 1930s.
In these circumstances military disaster from the commonest of all causes, sick troops, was a serious possibility, and a number of scientists gave urgent thought to finding better drugs to control, and preferably prevent the disease.
The causal parasite, a one-celled organism which thrived in red blood cells and was named Plasmodium malariae , was first seen under a microscope in 1880 by the French physician Alphonse Laveran (1845–1922) while he was serving in Algeria.
Improved microscopic methods and new synthetic staining materials from the German chemical industry made it possible to see the parasite in films of blood from malarial patients.
Within a few years four species of Plasmodium had been recognized, responsible for clinically distinct variants of malaria.
Now over a hundred are known, mostly infecting species other than man.
Malaria was known to be associated with marshes: it was often called marsh fever, but the connection was not understood until certain mosquitoes were recognized as carriers of the disease and as alternative hosts of plasmodia.
Stage by stage, the whole complex life cycle of the parasite was worked out.
Many points were still obscure in the 1930s, notably how relapses could occur in subjects long after they had left malarial regions and remained healthy for months with no sign of parasites in their blood.
The period between the bite of an infected mosquito and the first attack of fever was also puzzling.
Again no parasites could be found in the blood, but they appeared later, even if a course of quinine had been given in the meantime.
So a drug which acted during this phase, a ‘true causal prophylactic’, was exactly what was wanted, but how was it to be found?
Several workers suggested that there must be a tissue phase, in which the Plasmodium went to ground, but it was a long time before objects, evidently forms of the parasite, were recognized in microscopic sections of the spleen and liver of infected domestic fowl, monkeys and finally man.
Very soon after Prontosil and sulphanilamide became available they were shown to be active against malaria.
Their activity created some initial enthusiasm, but was found to be poor compared with quinine.
Unexpectedly, when sulphanilamide was tried in bird malaria (see Chapter 8), at that time the standard procedure for discovering new antimalarial agents, it did not work.
This raised questions about the methods of testing.
The support of a British parasitologist Warrington Yorke (1883–1943), at the Liverpool Institute of Tropical Medicine, who foresaw the wartime problems well in advance, was most important to a programme of research into antimalarial drugs developed at the Imperial Chemical Industries Research Laboratories at Manchester.
Much of the work centred on the complex biology of the malaria parasite and on improvements in the methods of testing potential antimalarial drugs.
Up to five stages in the life cycle could be identified, each of which might respond to a different agent.
As a result of this work it could be declared that ‘All the drugs now used against malaria were found by using experimental laboratory infections: the design of the tests employed to find them, or to uncover their particular attributes and imperfections, was based on knowledge of the life cycle’.
Application of the principle of competitive antagonism (see Chapter 8) to the discovery of new drugs required some knowledge of the essential metabolic pathways in the infecting organism.
This was particularly difficult for malaria, because the parasites could not be grown in vitro , and so were not easily available.
There was no obvious starting point for experiments designed to discover the details of its biochemistry.
All that could be done was to work by analogy.
Knowledge that plasmodia were vulnerable to sulphonamides was useful, particularly when they were shown to be protected, like bacteria, by p -aminobenzoic acid.
Chemically, the antimalarial drug Atebrin or mepacrine had some resemblance to riboflavin.
Experiments with bacteria suggested that mepacrine competed with riboflavin, i.e. that mepacrine was a false building block which  blocked the place belonging to riboflavin.
It was an attractive idea, but it led nowhere.
Progress came instead from testing a long sequence of compounds leading from the most potent sulphonamides to pyrimidines, a family of moderately complex organic compounds some of which are constituents of nucleic acids (Chapter II), and later to guanidines.
A sequence of antimalarial drugs of increasing power were produced, culminating in the drug ‘Paludrine’, alias proguanil or chloroguanide, which became publicly known in 1945.
It was rated very highly as a causal prophylactic.
For suppressing attacks, especially those due to Plasmodium falciparum , it was rather slow in action and inferior to mepacrine.
Furthermore, after many years of use, strains of resistant Plasmodium emerged, and, like nearly all antimicrobial agents, its power began to wane.
But the main objective at the time, a true causal prophylactic, had been achieved.
This work depended on intimate collaboration between laboratory chemists, laboratory parasitologists, and clinicians expert in the disease in question.
It was greatly fortified by an army research unit based in the United Kingdom, and by a unit established in Australia where antimalarials were systematically evaluated in controlled clinical trials in army volunteers.
This unit provided the necessary information which allowed the most effective system of dosage with mepacrine and Paludrine to be established.
No doubt the availability of a population of soldiers willing to volunteer for such trials was an incidental benefit of the conditions of war: no such opportunities are normally available for evaluating and learning quickly and accurately how to use new drugs.
Malaria: discovery by committee
Perhaps the best known of all recent antimalarial drugs is chloroquine.
As antimalarial drugs were desperately needed during the war, it is startling to realize that chloroquine was first synthesized several years before the war and recognized at that time as having antimalarial activity.
A delightfully frank account of its development shows some of the less scientific problems of discovery.
In 1934, H. Andersag, a chemist at the Bayer Laboratories in Elberfeld, prepared a compound which was first known as Resochin.
It might be described as a simplified mepacrine, although it belonged to a substantially different chemical class.
For 10 years few people knew anything about it.
Some limited laboratory and clinical tests undertaken at Bayer led to the belief that it was slightly too toxic to be acceptable.
A closely related substance, which was given the name Sontochin, was also laid aside.
Under cartel agreements, both the Winthrop Chemical Company in the United  States and, later, the French firm of Specia (Société Parisienne d'Expansion Chimique, the pharmaceutical branch of the great chemical company, Rhone-Poulenc) were informed about Resochin and Sontochin.
By this time, 1940, the German army had overrun France, and in Europe the normal assessment of new drugs was made subordinate to military needs.
In the USA, the need for research into antimalarial drugs had naturally been foreseen.
A program on the synthesis of new antimalarial drugs was initiated at the National Institutes of Health in 1939 and formed the basis of a war program organized by the Committee on Medical Research of the Office of Scientific Research and Development, National Research Council.
The program involved scientists from the universities and industry, private individuals, the US Army, the Navy and the Public Health Service, and included liaison with Great Britain and Australia.
It was coordinated by a group of conferences, subcommittees, and, from November 1943, by the Board for the Co-ordination of Malarial Studies.
The overall search for new antimalarial agents involved the screening of some 16,000 compounds, most of them for both suppressive and prophylactic activity against several avian malarias, plus a thorough study of the toxicology and pharmacology of many of the preparations in lower animals.
Finally the appraisal was undertaken of some 80 compounds against the malarias of man.
A great deal of useful information was assembled.
Some people will regard such a massive exercise in organization with awe.
To others it may seem like a recipe for disaster rather than for successful research.
It seems that the machinery did not work very well in discovering chloroquine.
Under cartel agreements, the identity and properties both of Sontochin and of Resochin had been disclosed to the Winthrop Chemical Company.
The reports created sufficient interest for Sontochin to be synthesized and tested by the American company, and it was found to be active against malaria in canaries.
Resochin was not pursued at that time, but both compounds were duly registered for purposes of patenting.
The information very properly reached the files of the survey for antimalarial compounds under the Survey Number SN-183 and was available to various conferences, committees, and subcommittees on the Co-ordination of Malarial Studies.
History does not record what the members of these committees thought about it, or whether they had time to read their papers.
Meanwhile, P. Decourt, a French clinical consultant to Specia, took samples of the drug to Tunisia for human trials.
There he was helped by Jean Schneider, later a professor in the medical faculty at Paris.
Schneider's trials were interrupted by the Allied invasion of North Africa in November 1942, and after the capture of Tunis, Schneider turned over his promising results and his remaining samples of Sontochin to the US Army.
In due course some of the drug reached the United States.
Its chemical composition was determined at the Rockefeller Institute in New York and found to be identical with the material synthesized at the Winthrop laboratories 3 years earlier.
According to Coatney, this discovery ‘created havoc bordering on hysteria.
We had ‘dropped the ball’ and in doing so had lost valuable time in the search for a reliable synthetic antimalarial'.
Naturally the lapse had to be covered up.
The compound was given a new number and the biological data declared secret.
Further trials on Sontochin, now SN-6911, con firmed its considerable effectiveness, and also generated several ideas which resulted in the synthesis of a compound which was named SN-7618.
It was made, but it was also found to be known already and to have been patented in the USA, along with Sontochin, by Winthrop.
It was, in fact, a different salt of the same base as the original Bayer Resochin, and after much comparison with other related compounds it became established and was recognized formally in February 1946 under the name chloroquine.
It had been synthesized and first tested in animals about 12 years earlier, and rejected, or ignored, twice.
It has become the drug of choice for the American armed forces and for the World Health Organization, and has survived against the threat of resistant strains for a surprisingly long time.
Since this time much progress has been made in understanding the biology of plasmodia and new antimalarial drugs have been discovered.
Primaquine, chemically in the same family as the pre-war German drug pamaquin, emerged as the most notable success of the great US wartime project.
Daraprim (pyrimethamine), a very different substance, evolved some years later from research of more general significance, to which we shall return in the next chapter.
There are also more recent drugs and a radically different approach, based on advances immunology, is leading towards the development of vaccines.
Much has been done to control mosquitoes too, but they, like the malaria parasites, have adapted to survive in the face of new enemies.
The great hope of eradicating malaria has faded: new battles must be fought and new weapons devised if even the present level of control is to be maintained.
Tuberculosis
For another widespread disease the biochemical approach, and particularly the idea of competitive antagonism, proved to be more rewarding.
Every disease presents its own peculiar problems which fascinate and challenge investigators, but tuberculosis has more than the usual range of difficulties.
Before Koch, the cause of tuberculosis was unknown, but was suspected to be hereditary.
After the tubercle bacillus was identified, accurate  diagnosis of tuberculosis, of the lungs and of other organs, became possible.
Controversy continued for some time about the identity or otherwise of human and bovine tuberculosis, until the infecting organisms were shown clearly to belong to different species of the large genus Mycobacteria, most of which are harmless to man.
Mycobacterium tuberculosis and Mycobacterium bovis both grow slowly and require complicated rich media, including substances of unknown or uncertain chemical composition.
They have waxy cell walls which perhaps protect them against many antibacterial substances.
Furthermore, immune responses to tubercle bacilli are extraordinarily complicated.
Koch's attempt to promote immunity with extracts of the organism (tuberculins) were not crowned with therapeutic success.
A tuberculin remains as a useful diagnostic agent for detecting the state of immunity to tuberculosis, and so giving evidence of the presence, or past presence, of the disease.
Tissues respond to the presence of tubercle bacilli by forming a fibrous wall round the organisms and encasing them in the small nodules called tubercles.
Sometimes the control is effective; sometimes damage continues within the enclosed areas and great destruction of tissues occurs, with cavities and haemorrhages.
The fibrous tissues round the infected area impedes access of antituberculous substances.
So the tubercle bacillus is a particularly difficult target for chemical attack.
In the medical climate of the 1920s, when the possibility of chemotherapy was looked on so unfavourably, mycobacteria were among the least promising organisms to choose for such treatment.
A comprehensive review written in America in 1932 concluded that, of the many substances which had been tried, more or less empirically, against tuberculosis, none was effective.
One of the authors summarized the position in the words: ‘Since 1922 we have come to recognise more and more that chemotherapy in the sense in which Ehrlich introduced the term, is more of a dream than a reality’.
In England Almroth Wright was expressing similar views.
Happily, such pessimism was dispelled a decade later, when the study of bacterial chemistry began to bear fruit.
For anyone studying the biochemistry of microbes, mycobacteria must have offered a mixture of attraction and discouragement.
The genus was sufficiently unlike other bacteria to arouse curiosity.
The disease both of man and cattle was enormously important, but working with the human tuberculosis organism carried considerable risk of contracting an often incurable and sometimes fatal infection.
There was therefore good reason for using related but innocuous species and accepting the chance of missing key properties which made the virulent organisms dangerous.
The slow growth of the bacteria did not help.
Experiments which take weeks are tiresome to arrange, more likely to go wrong, and less fun to do than those which given an answer at once, or within a day or so.
Also, the slow course  of the disease implied that any drug would have to be given for a long time in order to be effective and so would have to be particularly harmless to patients.
After Domagk's discovery of Prontosil (see Chapter 8), its active principle, sulphanilamide, was tried against tuberculosis.
In large doses it was effective against experimental infections in animals, and some related compounds called sulphones were better.
But their value in human tuberculosis was slight.
They were more beneficial in a disease caused by another Mycobacterium , leprosy.
Useful results were achieved by studying the chemical needs of Mycobacteria.
In Duke University, in North Carolina, F. Bernheim studied the effect of various substances on tubercle bacilli.
He worked with the bovine strain, but confirmed his positive findings with virulent human organisms.
He was not primarily a bacteriologist, and instead of using the standard criterion of survival of the organism, growth in culture, he measured the uptake of oxygen by the cultivated organisms over short periods and so obtained results more quickly.
Among numerous negative results he found some quite simple compounds, aldehydes and fatty acids, which stimulated oxygen uptake.
Benzoic acid doubled it and salicylic acid increased it five-fold.
The closely related p -aminobenzoic acid (PABA) had just become famous because of the work of Fildes and Woods.
Bernheim tried it, but it had no effect.
Another close relative, acetylsalicylic acid, i.e. aspirin, was active only if it was broken down to release salicylic acid.
Bernheim's results suggested that he had found some substances which were good for tubercle bacilli, and, by applying the principle of competitive antagonism, he sought closely related compounds which would also be taken up by them but would block the pathway of the stimulants.
He had slight success with tri-iodobenzoic acid, but it was J. Lehmann, in Sweden, who found that, among some fifty or so compounds tested,p -aminosalicylic acid, commonly known as PAS, prevented the growth of tubercle bacilli.
The compound was tried clinically, and proved to be of considerable benefit to a number of patients, but Swedish physicians were somewhat sceptical.
The reduction of fever is an early sign of improvement in tuberculosis.
The aminosalicylate reduced the fever, but as salicylates are known to do this it was thought that the effect might be non-specific.
Indeed, as gradually became clear, PAS alone is not a powerful drug against tuberculosis.
But it was found to be valuable in conjunction with the newly-discovered antibiotic streptomycin (see Chapter 9).
The appearance of PAS on the clinical scene coincided with the introduction of streptomycin in the United Kingdom.
Very small amounts were available, quite insufficient to treat all the patients who might benefit.
The opportunity was taken to devise comparative trials, in which some patients were treated with streptomycin and others served as controls.
In  the earliest of these trials, as also in the USA, the rapid development of resistance was observed.
A further trial was promptly conducted in which streptomycin was compared with PAS and with the combination of both drugs.
The results were unequivocal, that streptomycin was better than PAS, but that the addition of PAS to streptomycin virtually prevented the appearance of resistant strains.
So the value of PAS was established, and streptomycin was saved from the loss of efficacy which would otherwise soon have rendered it useless.
With the idea of competitive antagonism as a guide and the success of PAS as an encouragement, many other compounds were investigated in many laboratories.
A French study showed that nicotinamide, a member of the B-complex of vitamins that prevents the disease pellagra in man (see Chapter 13), had some activity against the development of leprosy in rodents.
As leprosy and tuberculosis are caused by related organisms, nicotinamide was tested against tubercle bacilli.
It was found to be active but only in concentrations too high to be clinically acceptable.
This discovery was apparently overlooked in the United States, and was made again 3 years later during the screening of large series of compounds.
In Germany, Domagk and his colleagues investigated the potential of sulphonamides, gradually moving towards compounds which had no connection with his original antistreptococcal drug Prontosil.
From such work and from studies on the biochemistry of tubercle bacilli, on substances which prevented their growth, and on potential therapeutic agents, extensive research, especially in the USA, led to the substance named isoniazid which was discovered almost simultaneously in the laboratories of E. R. Squibb and of Hoffmann-La Roche and publicized in 1952.
It has remained the most effective and least toxic drug against tuberculosis.
Like malaria, tuberculosis has been contained but not eliminated.
Several more drugs have been discovered, though their activity is limited by their toxicity.
Resistance is a major problem, particularly in countries where the supply of drugs is limited and their use is ill-controlled and haphazard.
In such conditions, where drug combinations are not used for an adequate length of time, resistant strains have every chance of profiting from the destruction of their more sensitive relatives, and establishing a reservoir of  intractable organisms.
The patient, rendered incurable, is then particularly liable to travel in search of treatment to better equipped countries, and there to disseminate the resistant organisms which he carries.
Investigating and controlling the spread of tuberculosis socially is as difficult as understanding the body's internal defences against the disease.
So the need for new antituberculous drugs grows, and the older remedies become less valuable.
New synthetic chemicals and new antibiotics have been discovered and brought into use, but at present(1990) it does not seem likely that tuberculosis will be eradicated simply by the discovery of effective drugs.
The behaviour of mycobacteria and of humans is too complex.
However the pessimism of the 1920s about chemotherapy is an awful warning about the hazards of prediction!
At the frontiers of life: viruses
After the great innovative period of bacteriology had achieved its ends, there remained a number of diseases, evidently infectious, for which no causative organisms could be found.
They included familiar childhood fevers — measles, chicken pox, and mumps — and some much more dangerous conditions, including smallpox and rabies, as well as various diseases of animals, including the distemper of dogs and the foot-and-mouth disease of cattle.
Similar infections were also observed in plants.
A paper by the Russian scientist D. Ivanovsky, published in 1892 and often regarded as the beginning of the science of virology, describes how a disease of tobacco plants can be transmitted by the sap after it has passed through a filter capable of retaining bacteria and other particles.
Whatever made the sap infectious was not visible with the conventional microscope.
Loeffler showed another filter-passing material to be the cause of foot-and-mouth disease in cattle.
These agents were given the old familiar name for obscure virulent materials, virus, and presented considerable difficulties because they could be detected only by infecting susceptible species and observing whether disease resulted.
As many of the viruses, including those of man, attacked only a single species of host, investigation was a problem.
Animal viruses became easier to study when methods of growing them were devised.
For a decade, fertile hen's eggs provided the most suitable medium.
Later cultures of, usually embryonic, animal cells were used.
The presence of virus could be recognized by microscopic changes in the infected cells, and means of assay were devised to detect the presence, and preferably the amount, of virus present.
Advances followed the development of the electron microscope.
Virus particles placed in the beam of electrons cast shadows which could then be photographed enabling them to be seen.
Until then it was difficult to decide the status of these invisible materials.
I remember, about 1946 or 1947, a somewhat heated debate among microbiologists about the nature of life and whether viruses were alive or not.
As usual, ideas associated with ‘life’ generated much emotion, especially in those who were not anxious to define their words accurately.
The debate had no practical importance, nor did it influence the direction and methods of further research.
Organic chemists had been troubled and had had to overcome the same semantic problems a century earlier (see Chapter 2).
As common virus diseases produced good immunity the prospects for  inventing vaccines seemed encouraging; indeed the whole process of vaccination began with smallpox.
But there were no obvious ways of producing attenuated strains of virus until a means of cultivation was established.
The greatest progress during the 1930s was made in investigations, sponsored by the Rockefeller Foundation in West Africa and in South America, of the tropical disease called yellow fever.
By selective cultivation of strains of the virus causing yellow fever a vaccine was produced shortly before World War II.
It made an immense difference to military operations in Africa, stimulated research for other virus vaccines, and led to the award, in 1951, of a Nobel prize to the medical scientist Max Theiler (1899–1972).
The investigations in the 1930s also gave one of the earliest hints of a new kind of cellular defence mechanism against viruses.
Quite simply, when monkeys had been infected with one strain of yellow fever virus, they became transiently less easy to infect with another strain.
Their resistance developed too rapidly and disappeared long before ordinary immune reactions could appear.
Some other cellular event was involved, but its nature remained obscure and unexplained for another 30 years.
After World War II, progress was made towards understanding the nature of viruses, the mechanisms by which viral infections were rendered harmless, and discovering suitable virus strains from which vaccines could be made.
Early in the 1950s both killed and attenuated living vaccines became available against poliomyelitis and the disease was almost eliminated from those parts of the world where mass immunization campaigns were undertaken.
However deaths are still recorded from this disease and children are crippled by it.
But the problem of control of poliomyelitis is now one of social organization and, until new strains and new viruses appear, not principally one of medical discovery.
Similarly the control of rubella is complex and important, because rubella in pregnancy is a cause of congenital defects.
Effective vaccines prevent such hazards, but only if a social organization ensures that all potential mothers are vaccinated in good time.
The interference between one kind of virus and another was investigated more fully late in the 1950s by an outstanding research worker, Alick Isaacs (1921–1967), at the National Institute for Medical Research.
He exposed cells in culture to influenza virus, showed that they were resistant to infection with certain other viruses, and isolated from his cultures a protein which conferred the same resistance on fresh cells.
Once again progress had been made by identifying a kind of messenger or transmitter substance.
Isaacs named the substance interferon, and for some years vigorous efforts were made to develop it into a practical therapeutic agent.
But it soon became evident that there were many kinds of interferon, all produced when cells were exposed to particular viruses but  varying in their exact nature according to the cells which produced them and the species of animal from which the cells originated.
As the interferons were specific for their species, it was essential to prepare interferon from human cells for the treatment of humans.
To multiply human cells in tissue culture on the scale necessary presented considerable difficulties, but enough material has been made for a variety of clinical trials against many different viral diseases and certain cancers.
Here too, the difficulties are formidable, with much disappointment and rare success.
Both research and the public have suffered greatly from premature publicity which has provoked excited demands for the material.
In the absence of supplies of the curative substance and of any prospect of making it within months or years, such publicity is a tragic source of false hope and disillusion, and would be better avoided.
However, advances in recombinant DNA technology have helped and interferon is now available for certain licensed uses.
The alternative approach to treating an infectious disease, by means of chemotherapy, made little progress until viruses could be grown and studied in cultures outside living organisms.
In some early post-war work on tuberculosis, compounds under investigation were screened for antiviral activity, and some active compounds were founds.
The observation was pursued and many compounds were examined for activity against viruses in culture, and in infected animals.
One derivative, later named methisazone, attracted interest because it was shown in clinical trials in Madras, in 1963, to prevent people exposed to smallpox during an epidemic from developing the disease, even though it did not hasten recovery once the disease had developed.
Many other substances were screened for antiviral activity and a few drugs with limited clinical application were found.
Progress, as always, in the practical discovery of new drugs depended on basic advances in understanding the chemical identity of the living system.
Gradually it was established that each of the many kinds of virus consisted of a core of a nucleic acid, either ribonucleic acid (RNA) or deoxyribonucleic acid (DNA)(see Chapter II), with a protein coat.
At the same time, during the 1950s and 1960s, great advances were made in determining the molecular structures of RNA and DNA, and in recognizing their functions in controlling the activities of living cells, including the power to reproduce themselves and to become immune to infecting organisms.
Advances in virology became inseparably linked with the new science of molecular biology, and the discovery of antiviral drugs began to have a deeper and stronger foundation.
A drug named idoxuridine, synthesized as a possible agent against cancer, proved to be effective in treating eye infections with a herpes virus.
It was closely related to a naturally occurring substance.
Its  activity depended on its being sufficiently similar to be taken up by the chemical processes of the virus but sufficiently different to be useless to the virus and to jam its works.
Once again advantage was being taken of the false building block principle which had been discovered for sulphanilamide (see Chapter 8).
The differences between virus nucleic acids and those of the hosts which they infect are very subtle.
Thus it is critically important that an antiviral agent does not become incorporated into the host's nucleic acids, or those works too could be jammed, with devastating consequences.
The newer antiherpes agent, acyclovir, is of great interest, because it acts in virally-infected cells, but only to a negligible extent in healthy human cells.
Thus it has an unusual and invaluable safety factor among its properties.
It remains to be seen whether vaccines or chemotherapy will play a greater part in controlling the human immunodeficiency virus.
What is quite clear is that any success will rest on the basic sciences of virology and molecular biology, and that, without research into obscure aspects of these subjects the direct hunt for new cures would be no better than shooting in the dark with unfamiliar weapons at an undefined target.
The new look in science
In surveying the discovery of penicillin, we moved from one domain of science to another.
Fleming, a classical, conventional scientist, saw comprehensible objects and made obvious inferences about the things he saw.
You and I might have done the same if we had been there, though we would have had none of the technical skill and detailed knowledge of Fleming.
On the other hand, Chain and Florey were armed with apparatus which means little or nothing to the layman.
When he arrived at Florey's laboratory, Chain was delighted to see a Sohxlet apparatus in a cupboard, but caused consternation by saying ‘I shall want six of those’.
Yes, but what is a Sohxlet apparatus, and why isn't one enough?
Would we be wiser if we were told?
And Chain isolated substances which could be recognized as novel and peculiar only with a considerable knowledge of chemistry.
One feels a certain loss of romance.
The antibiotic mould supposedly drifting in on the wind becomes prosaic when its magic is revealed only by tedious operations in a laboratory or factory.
What would have happened if penicillin had not been discovered, or if years of patient research had failed to explain why sulphonamides acted only on a limited selection of microbes?
Would the idea of drugs useful against germs once again have faded into obscurity?
Would many firms in the pharmaceutical industry have expended large resources in the pursuit of moulds which might produce useful drugs?
Would streptomycin have become available if the example of penicillin had not given impetus to its  investigation?
And if there had been no synthetic drugs to control the resistant strains, would the decline of streptomycin have been taken to prove that antibiotics were a waste of time because organisms adapted to them too easily?
However, the medical advances were made, and so were many other scientific discoveries, impelled by the necessities of war.
The obvious achievements — radar, jet propulsion, guided missiles, and the atomic bomb which brought the war to a sudden and unexpectedly early end at a price only less horrible than the continuation of war — depended on much basic research in physics and chemistry, particularly in the fields of radioactivity and nuclear energy, and of electronics.
The same kind of basic research continued after the war and provided the groundwork for endless discoveries which could be applied to peaceful ends.
The material amenities of life increased, at least in Western society, and prosperity came to many who had never known it before.
Public appreciation of science was high, and funds for research became available on a previously unheard-of scale.
So there was plenty of enthusiasm, and plenty of opportunity.
Leadership in science, which had moved from France to Germany in the late nineteenth century and from Germany to Great Britain early in the twentieth, now went to the United States, where immense resources had been developed during the war and were ready to be applied to more beneficial ends.
The expansion of American medical research, much of the finest quality, attracted European doctors who aspired to a scientific career, and they did well to spend a year or two in an American laboratory, or even to emigrate there altogether.
The National Institutes of Health of the United States Public Health Service were extended far beyond the size of any comparable European centre.
Laboratories and institutes established by charitable foundations became bigger: the Rockefeller Institute in New York was renamed the Rockefeller University in 1977 to reflect the scale of its research and education.
Industry, especially chemical and pharmaceutical, was no less involved in the great expansion, and the opportunities for research were on an unprecedented scale.
Expansion was not confined to the USA.
In Europe the ravages of war had to be made good and then came the enlargement of universities, government institutes, and industrial establishments.
The British Medical Research Council expenditure increased twenty-fold between 1948 and 1971.
The Wellcome Trust, set up by the will of Sir Henry Wellcome to devote the profits of the Burroughs Wellcome businesses to medical and veterinary research, became a major sponsor, second in Britain only to the Medical Research Council itself, and with notable influence elsewhere in the world.
The growth of the trust owed much to its first chairman, Sir Henry Dale (see Chapter 4).
By the time of Wellcome's death in 1936, Dale was long established as Director of the National Institute of Medical Research, and soon afterwards (1940- 1945) became President of the Royal Society and a principal scientific advisor of government during the war.
Both in these positions and as Chairman of the Wellcome Trust for 22 years, he had great influence on the development of medical research during and after the war.
Other trusts based on the profits of industry gave increasing support to medical research, and the pharmaceutical industry, rapidly becoming international in its outlook and activities, promoted its own laboratories directed towards the discovery of new drugs.
Public hopes for medical science, coupled with increasing prosperity, encouraged the formation of charities which collected funds for research, largely from individual donations and legacies.
Cancer research had a long tradition of support from private contributions, but new charities devoted to particular diseases, such as arthritis and rheumatism, leukaemia, and muscular dystrophy, were founded and became a great source of strength to workers whose interests had or might have application to the desired objectives.
The style of discovery changed after World War II.
The lone worker and thinker became a rarity.
There was more team work, and the teams were larger.
Their members were more specialized: a growing proportion of them had no medical background.
The range of sciences on which they drew was greater.
The significance of many particular facts or operations could be perceived only with some background knowledge, which the uninitiated would have little wish or reason to acquire.
Reports of original work, headed often by the names of many joint authors, became too full of jargon to be understood even by trained scientists who were not working in the particular field.
This situation persists today, though strong movements towards interdisciplinary research help to avoid total fragmentation of scientific understanding.
In such a climate, it is ambitious to attempt to explain scientific problems in simple terms.
But the gap between amateur and expert must be bridged if society is not to be split between two cultures.
It can be done, though it involves going into a little detail from time to time about points of central importance, and it needs simplifications which trouble an author's respect for exact truth and may appal an unsympathetic expert.
In spite of specialization, the general outline of the discovery of many recent drugs is remarkably similar and indeed has been said to follow a text-book pattern.
To avoid too many technicalities, we will confine the story to a small number of topics: cancer, high blood pressure, and mental disorders will serve to illustrate the ways in which problems have been solved.
Cancer
The Background
Cancer probably evokes more fears and grievously false hopes than most diseases.
The causes of cancer are still obscure, but it is not always necessary to know the cause of a disease in order to cure it or even to prevent it.
Salvarsan and later the sulphonamides could hardly have been invented without the bacteriological advances made between 1880 and 1910, and bacterial test systems were essential for isolating pure penicillin from mould juice.
On the other hand, Jenner introduced vaccination when he neither knew nor had any means of knowing anything about viruses.
Snow associated the occurrence of cholera with the source of the victim's water supply 20 years or so before bacteria were identified as causing the disease.
Lime juice was recognized (though not widely established) as preventive for scurvy, and cod liver oil for rickets long before specific nutritional deficiencies began to be understood or vitamins were discovered.
So seeking ‘the cause’ of cancer is not the only route to finding drugs which will relieve or cure it.
Research directed towards preventing and curing cancer repeatedly illustrates the dilemma.
Should one seek the causes, eliminate them and so prevent the disease?
Should one seek drugs which will stop the disease, and, if so, what strategy should guide the search?
Or should one take a middle road, trying to understand what goes wrong and then deciding whether it is easier to prevent or to cure?
As we shall see, the real advances have come not from research specifically directed towards cancer, but from discoveries made in quite different fields, as wide ranging as electrical discharges in gases, heredity in banana flies, analysis of the spermatozoa of salmon, and the development of instruments of chemical warfare.
It is unlikely that anyone thought of any of these possibilities when, in 1801, a society was formed to investigate the nature and cure of cancer.
The society appointed a medical committee, which outlined the essential problems in a series of simple questions.
They asked:
1.
What are the diagnostic signs?
2.
Are there any characteristic changes in a tissue which precede the growth of cancer?
3.
Is a cancer a degenerative change which arises from some other disease?
4.
Is cancer inherited?
5.
Is cancer contagious?
6.
Is cancer associated with other diseases?
7.
Is it a localized condition or the sign of a generalized bodily disorder?
8.
Is it produced by an unfavourable climate or environment?
9.
Is cancer associated with a particular temperament?
10.
Does it occur in ‘brute creatures’?
11.
Are there exempt periods of life?
12.
Is it ever susceptible of natural cure?
Several books and treatises were written by members of the committee in their attempt to answer these questions.
An enormous amount of information has been gathered since.
It shows that no simple answer can be given to any of these questions, and that the questions, though reasonable, are themselves over-simplified.
Cancer is not one disease but many, and the answers are unlikely to be the same for all of them.
Many people have also asked ‘Can any substance be given to a patient with cancer to stop the growth and dissolve the cancer?’
And many a quack has traded on the anguish of cancer sufferers and the credulity of their friends.
Laws have been made to check such deceits, but sometimes remedies have been honestly although misguidedly trusted until experience gradually showed their worthlessness.
It is difficult to test a potential cure when a disease is ill-defined.
Cancers of all kinds are now recognized as the uncontrolled multiplication of a particular cell type, either localized in simple tumours or invading surrounding tissues and spreading via the blood stream to create secondary growths in distant organs.
Recognizing the cellular origin of cancers was a natural development from the cell theory of bodily structure and was established by the great labours of the nineteenth-century descriptive pathologists.
Virchow himself, the founding father of the subject, at first regarded cancers as arising from formless material which would later develop into cancer cells.
This was the time when theories of the spontaneous generation of living cells were receiving hard treatment from Pasteur, and Virchow came to assent without doubts that cancer cells had their origin in other cells.
There are many problems for seekers after cures for cancer.
Advances in  pathology brought accurate descriptions of the different kinds of new growth and allowed some sort of classification, but gave little help in suggesting remedies.
The most obvious treatment was to cut out the growth.
When anaesthesia and antisepsis were both well established, surgery became a bearable procedure.
But even surgery was helpless when there were widespread and multiple secondary deposits.
Epidemiological studies sometimes threw light on preventable causes of cancer.
In 1761 J. Hill associated cancer of the nasal passages with the immoderate use of snuff.
In 1775 Percival Pott recognized that scrotal cancers rarely occurred except in chimney-sweeps, an observation which has become famous as one of the earliest records of an industrial cancer.
But doctors who had a taste for epidemiology tended to study diseases which spread rapidly and killed more quickly, such as cholera and typhoid fever.
New industrial processes occasionally led to the discovery of new causes of cancer, such as the ‘paraffin cancer’ of workers in the Scottish shalefield and the ‘mulespinner's cancer’of Lancashire cotton operatives.
Once it was recognised that any kind of cancer had an identifiable cause, it was natural to try and determine the exact chemical identity of the substances responsible (the ‘carcinogens’).
Little progress could be made until these cancers could be reproduced by experiments in animals.
How else, short of applying it to humans, could one test whether a particular extract contained the carcinogenic material?
Success in this field was elusive until in 1915, Yamagiwa and Ichikawa produced tumours by painting coal tar on the ears of rabbits.
Other means of detecting carcinogens followed, but the chemical problems of isolating minute amounts of active material from large quantities of tar were also formidable.
Advances in physical and chemical methods enabled Kennaway and Hieger in 1930 at the Chester Beatty Institute in London to isolate a substance with the chemical name 1:2:5:6-dibenzanthracene, ‘the first known pure chemical compound manifesting pronounced carcinogenic properties.
Many more carcinogens have been identified since then.
Some are mainly of laboratory interest but others are clearly related to substances in more or less widespread use.
Epidemiologists have incriminated substances and circumstances, and identified potentially carcinogenic material, such as tobacco smoke and tobacco tar, showing how a substantial burden of cancer could be prevented by avoiding exposure to the sources of carcinogens.
But it has taken many years for such discoveries to be accepted and acted upon, especially when they conflict with public convenience and related commercial interests, as the sad story of tobacco promotion and consumption shows.
A young American doctor named Peyton Rous turned to laboratory work because he was not fit enough for the stress of medical practice.
In 1911, when he was working at the Rockefeller Institute in New York, he described the transmission of a malignant new growth by means of a cell-free filtrate.
The tumour came from a hen, and the material transmitted caused tumours in other fowl, so it had no obvious importance to human medicine.
The microbes known at the time did not pass through filters, so the nature of the material was obscure.
The paper did not cause much excitement and Rous turned to other subjects.
Forty years later, when viruses were better known and several people had attributed viral origins to some tumours and perhaps leukaemia, the paper was rediscovered.
In 1966 Peyton Rous was duly honoured with a Nobel prize.
But the possible role of antiviral drugs in the treatment of such cancers remains unknown.
the beginning of radiotherapy
There is no reason to suppose that either Wilhelm Roentgen (1845–1923) or Pierre Curie (1859–1906) had any thought of discovering a treatment for cancer when they first encountered X-rays and radium.
Roentgen was experimenting with electrical discharges in evacuated tubes when he observed the emission of rays which made nearby materials fluoresce, i.e. emit light when the rays fell upon them.
His article in the Transactions of the Würzburg Physical Medical Society was promptly reported in England and America and, as many scientists had been working in the field, was widely taken up.
The X-rays were quickly (and accidentally) found to penetrate living tissue and leave shadows of the less penetrable denser parts, allowing X-ray pictures to be made of the skeleton.
Later, and also accidentally, they were found to damage and destroy living tissues, so they were applied as a kind of cautery to ulcerating cancerous growths as well as to other conditions such as inflammations and tuberculosis.
Antoine Becquerel (1852–1908) observed that similar rays are given off by uranium.
Soon afterwards radium, a considerably more powerful emitter of such rays, was discovered by Pierre and Marie Curie (1867–1934).
Much work was needed to prepare enough radium to treat patients, but once it was made, it was a more convenient source of radiation than the apparatus, extremely primitive by modern standards, which produced X-rays from electric discharges.
X-rays were greeted with uncritical enthusiasm.
It was soon shown that the waters of many spas emitted radiations.
Their supposed merits in restoring health were promptly attributed, without evidence, to the new magic.
Commercial interests promoted the dispensing of radioactive solutions for therapeutic purposes, and some members of the medical profession supported their use.
According to an abstract of the time, ‘Half a pint a day six days a week for six weeks for patients suffering from rheumatic gout and similar affections was advised by the late Sir F. Treves.
Two such courses generally effect a cure’.
Methods of clinical investigation were in their infancy, and it was open to any distinguished consultant to adopt a new treatment, profess himself satisfied by its results and enhance his reputation and his practice accordingly.
Methods for measuring the amount or intensity of radiation had not been developed, and the doses to which different patients were exposed probably varied from the imperceptible to the lethal.
Deaths from overexposure would not have occurred until years later and so caused no immediate alarm.
The early use of X-rays and radium for the treatment of cancer was very much a matter of trial and error.
Experiments on the biological effects of radiation were similarly hampered by the problems of measuring the intensity of radiation and the proportion of it absorbed by living tissues.
A unit of radiation dosage, the ‘roentgen’, was not defined until 1928, and it took time for it to be universally accepted.
Basic questions about how X-rays affect living cells could hardly be answered, or even investigated with any precision until the doses absorbed could be measured.
None the less, various biological effects of X-rays were noted and explored.
Just as drugs were often used, even when their properties were poorly understood, to investigate physiological processes which they evidently modified, so X-rays were found to be a valuable tool in certain fields of study.
Cell division, and the processes by which the characteristics of parent cells are reproduced in their offspring, was one such field.
At the beginning of the twentieth century, two approaches converged.
One was the study of inheritance by direct observation of specific properties of parents and offspring.
Mendel's work had been rediscovered and repeated.
The other was the search in living tissues for the carriers or agents which determined these properties, i.e. the genes responsible for producing them in successive generations.
The discovery that suitable doses of X-rays sometimes cause a mutation, that is, a change in the property produced by a specific gene, was a valuable tool in relating the observed features of heredity to the cellular changes which control them.
In the hands of the American zoologists Jacques Loeb (1859–1924), T. H. Morgan (1866–1945), and H.J. Muller (1890–1967) from the early 1900s onwards, the study of mutations induced by the radiations emitted by radium led to major advances in the science of genetics.
Morgan received a Nobel prize in 1933, and Muller in 1946.
It was shown that the effects of irradiation are greatest on dividing cells.
The ovaries and testes are particularly sensitive, and sterilization (sometimes therapeutically desirable) is easily produced by a beam of X-rays of sufficient intensity.
As a cancer consists of cells dividing uncontrolledly, there were good prospects of finding a dose of radiation which would stop the cancer cells without damaging healthy cells.
Some tumours are indeed radio-sensitive, and some progress was made in  therapy with x-rays and also with radium, which could be inserted into a tumour so that its effect was concentrated.
When cancers did respond, radiotherapy was particularly useful in dealing with secondary growths which were too widespread for surgical relief.
But most cancers failed to respond at all to the largest doses which were tolerated by healthy tissues.
At the same time, people began to discover that irradiation not only arrests the growth of some cancers, but can have the opposite effect and generate new cancers in tissues which received excessive exposure.
Early workers with X-rays, who were exposed to what by modern standards are horrifying doses, developed cancers at an alarming rate.
Some girls, who worked in a factory where luminous radioactive paint was applied to the dials of watches, developed necrosis of the jaw and fatal anaemia.
Their tissues showed changes due to cancerous destruction, and contained substantial amounts of radioactive material, evidently absorbed because of the girls' practice of licking the tips of their paint brushes to achieve a finer point.
Other varieties of cancer associated with radiation were discovered.
All too slowly, reasons were established for treating X-rays and radioactive materials with considerable caution and for initiating proper control over the use of all sources of radiation.
The interactions of X-rays with living tissues were studied in very few laboratories, perhaps because physicists working with the new rays were not usually well informed about the biological problems which might be worth approaching, and biologists lacked the background and training in physics necessary to use X-rays in their work.
Not until after the development and use of atom bombs did ‘radio-biology’ become a widely recognized science and its contribution to cancer research properly appreciated.
Cancer research was moving forward on other fronts too.
Hormones and cancer
At about the time when Becquerel was working on the radiation from uranium, G. T. Beatson, a surgeon in Glasgow, observed that the inoperable breast cancers of three patients underwent regression after he had removed their ovaries.
He experimented on the effects of removing the ovaries of rabbits, and speculated extensively, but lacked too many important facts to make much sense of his discoveries.
Other surgeons and radiotherapists obtained benefit for some patients when they were sterilized by irradiation.
However, the advantages of either treatment were too limited and too infrequent for them to be widely adopted.
We should remember that very little was known at that time about the ways in which the ovaries influence distant organs.
The extensive studies on removal and transplantation of the ovaries by Knauer in Vienna (see Chapter 5) appeared in 1900 and the more general concept of hormones or  blood-borne chemical messengers was elaborated for the first time by Starling in his Croonian lectures a decade after Beatson's observations (see Chapter 5).
It was hardly possible to understand the effects of removing the ovaries until ovarian hormones had been purified and shown to produce effects comparable to those seen at puberty.
The isolation and chemical identification of several sex hormones in the late 1920s and the 1930s had many practical consequences.
Direct evidence was obtained that certain ovarian hormones, the oestrogens, were responsible for the growth of the breasts, both in humans and other mammals.
In mice, in particular circumstances, the growth was uncontrolled and resembled cancer.
But it was a far cry to advance from recognizing that some breast cancers diminished when deprived of oestrogens to achieving an effective cure of a common and usually fatal condition.
Investigation of the physiology of the male prostate yielded more immediate progress.
This organ has received much attention from surgeons, who are confronted with the problems which arise when the prostate enlarges late in life and obstructs the urinary channel which passes through it.
In the 1930s the Chicago surgeon, C. A. Huggins, made extensive studies of the prostate gland of humans and of dogs.
He observed that the tumours of the prostate which arise spontaneously in aged dogs and are sometimes but not usually cancerous, got smaller after the dogs were castrated.
He achieved the same result by administering female sex hormones, which indirectly cause the testes to become inactive.
Huggins and his colleagues showed that, either removal of the testes or treatment with hormones benefited the majority of patients with carcinoma of the prostate.
The cancer was not eliminated, but its growth ceased, and for many years could be prevented from spreading to distant tissues as long as treatment with hormones continued.
The synthetic oestrogen, stilboestrol (see Chapter 5), was as effective as naturally occurring oestrogens.
The treatment was investigated in a co-operative study involving many surgeons: by 1950 some 1800 cases had been reported, leaving little doubt that treatment had been found which at least delayed the progress of an otherwise intractable cancer.
Huggins shared a Nobel prize in 1966 with Peyton Rous.
As so often happens, the passage of time showed an increasing number of disadvantages of the treatment, including a greater frequency of heart disease and strokes in men receiving oestrogens.
Subtler methods of modifying endocrine balance continued to be explored.
Control of cancer of the breast was to prove more difficult.
The activity of cells in the breast is influenced by oestrogens and progestogens (cf. Chapter 5) and by androgens from the adrenal glands.
Some tumours grow if oestrogens are present, and others are checked by their administration.
Such differences in the behaviour of different cancers of the same organ does not make it easy to identify the right hormones for treatment.
As late  as 1975, an authoritative source stated, ‘The first cardinal principle’(in treating cancer of the breast)‘is that hormonal therapy should be reserved for patients for whom surgical treatment or radiotherapy has been considered and deemed no longer of value’.
One advance, still perhaps not fully evaluated, arises from the principle of competitive antagonism and the discovery that certain compounds compete with oestrogens and block the tissue receptors on which the oestrogen acts.
The drug tamoxifen, first described in the late 1960s, has some value as a palliative in patients with oestrogen-dependent tumours.
In spite of many attempts to extend the use of hormones to the treatment of other cancers, it appears that their important effects are on the organs which they normally control.
Hormones of the adrenal cortex influence the behaviour of lymphocytes, the white blood cells involved in the development of immunity: the adrenal hormones, and synthetic related substances have been found useful in the control of those leukaemias which are, in effect, tumours of lymphocytes.
Hormones modify the cells which may become cancerous, rendering them less, or more, likely to do so, but the hormones do not act primarily on the processes which turn any quiescent cell into one that divides without control.
The effects of hormones may themselves take a very long time to appear.
About 1970 a number of young adult women were found to have a rare cancer of the vagina: the appearance of several cases close together prompted enquiry about possible causes.
It was discovered that the mothers of all the patients had taken the drug diethylstilboestrol during the first 3 months of their pregnancies.
The connection has been amply confirmed and leaves no doubt that indirect exposure of the fetus to abnormal amounts of oestrogen is a potential cause of cancer.
The discovery of an effect with such a long latent period was no mean feat of epidemiology.
Swords into ploughshares: war gases and the arrest of cancer
In 1938, just before Huggins reported on the treatment of prostatic cancer, Goodman and Gilman's celebrated textbook of pharmacology made its first appearance.
It is interesting to note that no section of the book was devoted to cancer and the word cancer did not even appear in the index.
Such was the state of worthwhile knowledge at that time.
It is interesting that Gilman and Goodman themselves were the first to discover an effective anticancer drug.
Many valuable drugs have been recognized first as poisons.
Atropine from deadly nightshade, eserine from the ordeal bean of old Calabar, the alkaloids from the arrow poison curare all yielded useful medicines when their properties were studied carefully and the right dose was used for  beneficial instead of destructive ends.
Other noxious substances may be very good drugs too if they are understood and properly used.
The first effective anticancer drug was discovered in this way.
Its story is all the more piquant, because the starting point, the harmful substance, was one almost universally regarded as an exceptionally evil human ‘achievement’.
The volatile oily liquid beta-chloro-beta-ethyl sulphide was first synthesized in 1854, and in 1887 it was reported to produce blisters if it touched the skin.
It was called mustard gas and was used at Ypres in 1917, when it caused many thousands of casualties.
Chlorine was used at the same time, and one may suppose that confusion arose in many minds about their separate effects.
Research was essential to identify the ill-effects attributable to each substance and to devise means of protecting against them and of overcoming them.
By 1919, mustard gas was known to injure not only the skin but also the bone marrow, preventing the formation of white blood cells and other essential elements of the blood.
But the war was over, and the pressure to investigate chemical warfare agents disappeared.
Mustard gas was disagreeable and hazardous to work with.
Chemists maintained a sporadic interest in related compounds, including ‘nitrogen mustard’, synthesized in 1935, in which a nitrogen atom replaces the sulphur.
The outbreak of a new war made defence against chemical warfare agents once again an urgent problem.
In Britain, and later in the United States, government agencies arranged to supplement the activity of arsenals by sponsoring work in university laboratories.
An academic approach to these problem, not usually studied in university laboratories, proved fruitful, both in advancing basic ideas and in identifying new drugs.
Most of them did not escape from wartime secrecy and were not properly developed until the war was over.
At Yale, under a contract between the University and the Office of Scientific Research and Development, Goodman and Gilman supplemented our understanding of mustard gas by exploring the properties of the nitrogen mustards.
Like mustard gas, the nitrogen mustards caused blisters when they came into contact with skin, and they damaged many other tissues when they were absorbed or injected into the circulating blood.
The most vulnerable cells were those which the body renews most frequently; especially the white blood cells, including the lymphocytes.
Working with another scientist, Thomas Dougherty, who was particularly interested in tumours of white cells in mice, Goodman and Gilman used a nitrogen mustard to treat a mouse with a lymphoma, a large solid lymph cell tumour.
The tumour shrank dramatically, in a way which had not been seen before.
But the shrinkage did not last, and further courses of treatment were less effective.
Finally the mouse died, but its life had been extended.
More experiments on more lymphoma-bearing mice followed, and the doses likely to achieve the best effect were assessed with great care.
A surgical colleague, G. E. Linskog, agreed to try the treatment in human patients.
It was a hazardous undertaking: everyone thought of the nitrogen mustards as dangerous compounds which could destroy vital cells in many organs.
One of Linskog's patients had a lymphatic tumour which had become resistant to radiotherapy; situated in the jaw, it was making eating and breathing difficult.
The drug, called ‘compound X’ for reasons of wartime secrecy, was given in doses which Gilman later described as ‘a most fortunate guess’.
In 2 days some benefit was detectable: in 4 days it was obvious.
Later, the patient was in severe, but expected, danger from a depletion of his own healthy white blood cells.
But the ‘guessed’ dose had been well chosen, and the bone marrow, which makes the white cells, recovered.
The tumour had shrunk, and the patient was, temporarily, rescued from his miserable state.
However, the tumour was not entirely destroyed, and it too recovered.
They saw for the first time what was to become a regular and tragic sequence of events: a dramatic response to the first treatment, a lesser one to a second, and in the end delayed death from a condition which had become as resistant to drugs as it was to radiation therapy.
Nevertheless, no drug had previously achieved such success against any cancer-like proliferation of cells.
It was enough to warrant an investigation of related compounds and a closer exploration of how they worked.
Several laboratories and clinics were involved, in Salt Lake City, in Portland, Oregon, and in Chicago, where an independent study of another nitrogen mustard gave results like those found in Yale.
Under wartime agreements for the exchange of secret information, the news reached England, and investigations were pursued, particularly at the Chester Beatty Institute in London.
When publication was permitted, the principal findings were summarized by Gilman and Philips.
Nitrogen mustards in suitable doses damage only cells and tissues which normally exhibit relatively high rates of proliferation and growth.
They stop the process known as mitosis, in which the chromatin of the nucleus is divided into precisely matching portions for each daughter cell.
After larger doses, chromosomes are seen to break and cell nuclei to fragment.
Once again there was an association between action against cancer and changes in chromatin.
Indeed, the changes were very like the effects of irradiation with X- or ultra-violet rays, but this time they were being produced by a chemical instead of a physical agent.
At that time, the inhibition of enzymes was a particular focus of interest as a mechanism of action for drugs, and so nitrogen mustards were tested for such properties, without very striking results.
A certain formal similarity of the compounds to acetylcholine (see Chapter 4) was explored  but this too led nowhere.
One of their chemical properties which attracted attention was their ability to alkylate other molecules, i.e. attach a simple organic radicle such as CH 3 to them.
Such an addition could readily cause (and explain) big changes in the biological properties of the alkylated compound.
At the Chester Beatty Institute, it was suggested that nitrogen mustards might alkylate two adjacent molecules at once and so link them together.
If the molecules were some part of the chromosomes, this might account for the many nuclear changes which had been observed.
Several lines of research developed.
The most obvious was to seek better compounds than the original nitrogen mustards, and numerous alkylating agents emerged during the following 30 years.
They were active against leukaemias of various kinds and against some related solid tumours.
These new compounds were often specific for a particular kind of leukaemia, and sometimes they were so effective that remissions appeared to be permanent.
But for other cancers they were of little use.
A more fundamental approach was to investigate the reactions between nitrogen mustards and the chromatin which filled the cell nucleus and which they were suspected of alkylating.
The time was ripe for such an approach, because progress in chemistry was just beginning to make possible the effective study of very large molecules such as those that formed the main constituents of chromatin.
First whisperings of DNA
The cell nucleus, so prominent in stained microscopical sections of tissues, often attracted chemical investigation but presented many difficulties.
The first serious attempt was made as early as 1869 by a young Swiss doctor, Johannes Friedrich Miescher (1844–1894), whose uncle was Wilhelm His (1831–1904), a most unusual anatomist who maintained the forward-looking proposition ‘La solution finale du problème du développement tissulaire se trouve dans la chimie’(The final solution of the problem of development of organs is to be found in chemistry).
Inspired by his uncle, Miescher went, at the age of 25, to Tübingen as the first pupil of Felix Hoppe-Seyler (1825–1895), the young professor of the then new science of physiological chemistry.
Miescher studied lymphocytes, which consist of large nuclei and little else.
He obtained these cells from an unattractive source, the pus on discarded surgical dressings, which had the merit, in pre-chemotherapy days, of being very readily available.
He achieved the very considerable feat of isolating a material, demonstrating its purity and getting an analysis of the elements present.
He named it ‘nuclein’, and noted that it was rich in phosphorus.
Later, after his return to his native city of Basle, he obtained similar material from other cells, mostly the spermatozoa (again cells containing little else except nuclei) of salmon  caught in the Rhine outside the window of his laboratory.
From salmon sperm he also isolated a protein, named protamine, and observed that nuclein was closely associated with proteins if it was not actually a protein itself.
In the next 30 years considerable progress was made in purifying and crystallizing proteins.
As crystallization occurs only when a substantial fraction of the molecules present are alike in size, composition, and shape, this achievement implied that the protein crystallized had a definite molecular structure.
Attempts to determine their molecular weight suggested that proteins were behaving as though they were substances with a fixed and definite composition and, probably, structure.
Analysis of purified proteins, notably by Gowland Hopkins (see Chapter 7), also showed that the variations apparent in crude preparations disappeared with purification.
But the molecular weights were enormous, implying molecules which contained thousands of atoms, much too complicated for any details of their structure to be worked out.
With an instinct for what was later called the ‘Art of the Soluble’, most biochemists confined themselves to more manageable topics.
It was fashionable at the time to study the colloidal state, a condition in which small molecules are associated in loose, somewhat indefinite aggregates.
Ostwald in Germany and Bancroft in the United States, who held dominant positions in the world of physical chemistry, especially as editors of the principal journals, were influential in promoting such ideas.
The idea extended from chemistry into biology, so that‘protoplasm’ was envisaged, not as a giant molecule such as Ehrlich suggested, but as a colloidal system of indefinite composition.
The notion was sufficiently vague to be easy to understand and difficult to disprove.
At the other end of the scientific spectrum, organic chemists were reluctant to extend their studies beyond compounds consisting of small molecules with not more than perhaps 50 or 100 atoms.
Their closely defined concepts of the structure of such molecules had brought enormous advances in knowledge, but extending these rigid ideas to larger molecules was not easy.
Even Emil Fischer, in propounding the idea that proteins were built up by a standard linkage (-CO-NH-) between different amino acids, apparently did not envisage molecules containing more than 30 or so such units, corresponding to no more than 300 atoms which is much too small.
What were needed, and gradually emerged between 1900 and 1940, were technical methods for investigating large molecules.
Even such an elementary requirement as the accurate control of acidity and the alkalinity was difficult until, in about 1912, Sørensen devised the scale of measurement known as pH, and pioneered the use of solutions which ‘buffered’ changes of pH.
The crystallization of enzymes, the invention of the electrical method called electrophoresis which separates molecules  according to their size and their electric charge, the development of very high speed centrifuges in which the larger proteins are separated from smaller ones as they spin, and later the application of X-ray crystallography to large molecules have all contributed to progress.
None of these methods seemed at the time to have any relevance to therapeutics, and the scientists who developed them would have found it very difficult to persuade the distributors of funds for medical research to support them, but without them the practical advances which came later would have been impossible.
Tedious though this point may be, it is particularly in need of emphasis today, when the value of research is so often judged only by expected and short-term practical applications.
The main constituents of chromatin were known as ‘nucleins’.
An early paper (1909) by McCollum, of vitamin fame (see Chapter 7), describes nucleins as combinations of protein and nucleic acids, the latter having a high content of phosphorus in combination with certain organic molecules, known as purines and pyrimidines, and with a sugar.
This description was entirely correct, but it took nearly 50 years to work out exactly how the different parts fitted together.
In New York Phoebus Levene (1869–1940) produced a definite theory of their structure, based on units which contained one each of the four bases adenine and guanine (purines) and cytidine and uridine (pyrimidines).
For a long time, too long in fact, this theory held the field, until improved analytical methods showed that various samples of nucleic acid did not have the exact constant proportions of the different bases required by Levene's tetra-structure.
The sugar was identified as either ribose or deoxyribose: for a time it was believed that plant nucleic acids always contained ribose and animal nucleic acids deoxyribose.
This belief was dispelled in the 1940s when advances in technique showed that both kinds of nucleic acid were present in all cells, and that the deoxyribonucleic acid (DNA) was relatively stable while the ribonucleic acid (RNA) was being continually synthesized and decomposed.
The spiral structure of DNA and RNA molecules, the ‘double helix’, was not proposed until late in the 1950s.
None of this had any direct relevance to the discovery of drugs, and one may assume that many pharmacologists did not follow these developments.
Students of cancer had more reason to be interested in chromatin and its role in cell division, but chemical approaches to cancer were predominantly concerned with molecules which could be identified at the time, i.e. with molecular weights under 1000.
Purines and pyrimidines, ribose and deoxyribose were all well in this range, and we shall discuss the essential role they play.
But, with that unpredictability which makes biology such a fascinating science, it was some biochemists interested in nutrition who laid foundations for the next major advance in the treatment of cancer.
Converging discoveries
By the 1940s, physiological chemistry had become biochemistry and biochemistry was a flourishing science which spread into almost every aspect of animal, plant, and microbial life.
The processes which keep alive a microbe, a spinach plant, and a human turned out to have more in common than might have been expected.
Ideas spread quickly from one field to another.
Scientists noticed discoveries, apparently irrelevant to their work, which contained an inspiration for solving some current problems of their own.
Here we can mention only a few events which led to major therapeutic developments, and pass by much else which gave the clues and spurs for progress.
In Chapter 7, we saw how several nutritional factors were detected — Will's principle, found in yeast extracts and active against a tropical anaemia; a similar material to that which prevented anaemia in monkeys; the substance derived from spinach which was necessary for the growth of various microbes; and substances from yeast and from liver also needed by microbes.
Gradually it became clear that all these factors were chemically identical, and the single name, folic acid, was coined.
The exact structure of folic acid was established in 1946.
It had three parts; the amino acid glutamic acid, the nitrogenous base pteridine, and a substance we have met previously,p- aminobenzoic acid (PABA), which linked the two other components together.
PABA is essential for those microbes which are attacked by sulphonamides (see Chapter 8) and the discovery of folic acid threw fresh light on the way sulphonamides worked.
PABA, glutamic acid, and a source of pteridine, are the building blocks from which the microbe constructs its own folic acid.
We have already seen that a sulphonamide acts as a false building block; it fits into the construction but is the wrong shape for farther blocks to be added.
Now the identity of the further blocks was known, and it was evident that sulphonamides prevented folic acid from being put together.
Theoretically, the sulphonamide block could be by-passed if ready-made folic acid were available, but in practice microbes which make their own folic acid are unable to take it up from outside.
Most organisms, ranging from other microbes to man, can absorb folic acid and rely on it to provide their needs, and so they are not affected by sulphonamides.
Folic acid itself is of great interest to anyone concerned with the formation of red and white blood cells, and with the abnormal and excessive formation of white cells in leukaemia.
Was folic acid necessary for abnormal proliferation?
Might proliferation occur because the cells in question lacked the essential material and got out of control?
This point was rapidly settled when folic acid was shown not to check but to accelerate the development of certain leukaemias.
This discovery suggested that an  analogue of folic acid would block its use and prevent the multiplication of blood cells, just as an analogue of PABA prevented the multiplication of microbes which used PABA.
Such an analogue might block the normal use of folic acid and cause intractable and fatal anaemia, so it would be a hazardous substance to try.
But also it might have a greater effect on leukaemic cells, which divide more frequently, probably use more folic acid, and are thus more vulnerable to a competitive antagonist.
If this was the case, the proliferation of cells in leukaemia might be brought under control.
Analogues were made, in particular by the group at the Lederle laboratories which had identified the structure of folic acid.
The substance aminopterin, made by replacing an -OH group by an -NH 2 group on the pteridine part of folic acid, was a milestone in the history of chemotherapy.
With it, the paediatrician S. A. Farber and his colleagues in Boston obtained striking results in the treatment of acute leukaemia in children.
Apparent recovery took place, though it was only temporary: it was followed by a fresh proliferation of leukaemic cells which no longer responded to treatment.
Nevertheless, a considerable advance had been made.
Aminopterin had disadvantages, and the normal process of making and testing a series of closely related compounds led to a better drug, amethopterin, which differed by a single additional substituent but proved to be one of the most effective drugs for the treatment of blood cancers.
At the time there was little understanding of the role of folic acid in the normal working of the body.
Observations on microbes appeared ‘further to relate [folic acid]with nucleic acid metabolism and to emphasize the probability of a role for this vitamin in cellular proliferation.’
Much had yet to be done in the study of nucleic acid chemistry.
A search with many facets
In 1940, no one knew how the components of nucleic acids fitted together, but there was no doubt that they included certain pyrimidines (cytosine, thymine and uracil) and purines (adenine and guanine).
Very little was known about the origin of the pyrimidines and purines.
Since the amount of nuclear material increases as cells grow and divide, new pyrimidines and purines had to come from somewhere.
Food was unlikely to provide exactly the right nucleic acids ready-made, and it was more likely that they were being built up from their components.
So it was time to attend to the synthetic pathways, about which very little was known.
As folic acid was evidently important in some way for the formation of new cells, it was natural to seek a role for it in the synthesis of pyrimidines and purines.
The advantages of using microbes for the early stages of such studies were well known and their biochemistry provided a convenient starting  point for several investigators, especially in America.
Among them was G. H. Hitchings, who had worked at Harvard on the quantitative estimation of purines and on the purification of the anti-anaemia principle in liver, and at Western Reserve on studies which led later to the discovery of folic acid.
In 1942 he came to the Research Laboratories which Burroughs Wellcome had established at Tuckahoe on the outskirts of New York.
There he embarked on a study of nucleic acid synthesis with the twin objectives of seeking fundamental knowledge about the roles of pyrimidine and purine bases in growth, and of discovering new chemotherapeutic agents.
As parasitic tissues generally depend for survival on a more rapid synthesis of nucleic acid than the tissues on which they prey, anything which stopped the synthesis of nucleic acids had a chance of harming parasites more than their hosts.
On the basis of its dietary habits and its particular synthetic capacities, Hitchings and his colleagues chose to work with a milk-fermenting organism,Lactobacillus casei .
Even in such a simple organism as L. casei , the interactions turned out to be very complex, far beyond those of a single enzyme system and full of ‘inviting pitfalls for unwary investigators’.
Their search led, by the middle of the 1940s, to a compound, 2:6-diaminopurine, which had effects in mammals and chicks ‘about what one would expect of a substance which interferes with nucleic acid metabolism in some way’.
It prolonged the life of mice with leukaemia, and it produced dramatic remissions in some leukaemia patients.
But it made the patients very sick, and the remissions did not last.
The leukaemias resisted further treatments and were eventually fatal.
Hitchings and his colleagues, most notably Gertrude Elion, continued to.
investigate purines and pyrimidines, by no means confining their attention to the treatment of cancer.
In other hands (see Chapter 10), investigations based on the pyrimidines led to the antimalarial drug chloroguanide.
Chloroguanide was not itself a pyrimidine, but it was sufficiently close for it to be tested in L. casei , where it showed interesting effects, resembling some of Hitchings' compounds.
Turning the argument round, Hitchings suggested to colleagues in the Wellcome Tropical Medicine Laboratories in London that they might test some of the compounds being made in New York against experimental malarial infections.
The results were immediately encouraging.
After much transatlantic exchange of information, the synthesis and study of more than 300 compounds, and collaboration with physicians in many parts of Africa and Asia, the drug christened ‘Daraprim’ and later known as pyrimethamine emerged in 1952 as an antimalarial of considerable importance.
This most productive diversion was followed by further work on anticancer drugs.
In 1951, another purine, 6-mercaptopurine (6-MP), was found which caused remissions in some leukaemias.
It was tolerated well  enough to become a useful drug, but it had a very brief period of action; 6-MP is attacked by the enzyme xanthine oxidase, a normal constituent of the human body (and of widespread occurrence elsewhere) and is converted to a substance, thio-uric acid, which is not active against tumours.
Moreover, the leukaemia cells of patients treated with 6-MP adapted to it, so that the disease became resistant to further treatment.
But these limitations contained the seeds of fresh advances.
Drugs which are rapidly inactivated have advantages, because the risk of overdosage is minimized and there are no cumulative effects.
But they are also inconvenient, because frequent doses must be given to maintain a continuous effect.
So a search began for ways of overcoming the difficulty.
One way was to synthesize compounds which had all the useful properties of 6-MP but were not attacked by xanthine oxidase: this was achieved with the synthesis of a substance later named azathioprine.
The second way was to find a compound which would compete for or block the inactivating enzyme.
This way needed no search: the substance later known as allopurinol had already been synthesized by Hitchings and his colleagues, and it inhibited the enzyme xanthine oxidase (which converts xanthine to uric acid and mercaptopurine to thio-uric acid).
As allopurinol did not inhibit the growth of L. casei nor interfere with the growth of experimental tumours, nor did it appear to have any other properties which made it unsuitable, it received further investigation in man.
Another possibility, at that time very speculative, was to see whether allopurinol would prevent uric acid from being formed from xanthine in man.
If it did, it might be valuable in patients with gout, when abnormal deposits of uric acid are responsible for the development of intensely painful joints.
Whether preventing the formation of uric acid would be beneficial, or whether the accumulation of unconverted xanthine would do more harm than good was open to question, and only to be settled by cautious clinical trial.
In fact, fears were unfounded and the hoped-for benefit was achieved.
Allopurinol has withstood substantial trials, and remains a standard drug for the treatment of gout.
The use of 6-MP for the treatment of leukaemia had an unexpected consequence.
Early trials of the new drug took place at a time when the transplantation of kidneys and other organs was being vigorously investigated.
The principal obstacle to transplantation lay in the subtle differences between the tissues of one individual and another, differences which provoked immune reactions between the recipient and the transplanted organ.
Such reactions are the normal response to any foreign material and an essential protection against invasive microbes.
The importance of immune reactions in preventing successful organ grafting was shown conclusively when a kidney was transplanted from one identical twin to another and was not rejected.
(Identical twins do not differ  genetically, so their tissues are immunologically indistinguishable and there is no stimulus to an immune reaction.)
The principal problem for would-be organ grafters was therefore that of overcoming normal immune reactions to alien tissues.
Robert Schwartz, a young physician working under William Dameshek, the chief of haematology at the New England Medical Centre, was assigned the task of solving this problem.
His success depended, as so often happens in research, on entirely fortuitous events, of the kind which sometimes contribute as much as careful planning to the attainment of desired objectives.
In Schwartz's words:
The concept that formed the basis of this search was that immunologically competent cells were stimulated to proliferate on contact with antigen.
At that time, this was a relatively novel idea without much basis in fact.
Nevertheless, it seemed reasonable that chemotherapeutic agents known to block the proliferation of cells might also be immunosuppressive.
We were then using two agents for the treatment of leukaemia: methotrexate and 6-mercaptopurine (6-MP).
It was therefore decided to test their effects on the immune responses of rabbits.
Now for the lucky part.
Since neither drug was available commercially, I wrote to the Lederle Laboratories and to the Burroughs Wellcome Company for a supply of methotrexate and 6-MP, respectively.
I never received an answer from Lederle.
By contrast Burroughs Wellcome sent me a generous supply of6-MP along with some easy-to-follow directions for its administration.
(believe the directions were written by Trudy Elion.
The experiments in rabbits were begun and within a month it was apparent that 6-MP was a potent suppressor of the immune response.
Subsequently, a sample of methotrexate was finally obtained and tested in the same manner in the rabbit.
It was found to be without effect.
Later metabolic studies of methotrexate revealed that it is virtually without effect in the rabbit because of a metabolic peculiarity.
In retrospect, it is highly likely that if Lederle had responded to my letter and Burroughs Wellcome had not, the whole idea of immunosuppressive chemical therapy would have been dropped as an interesting, but unsubstantiated, speculation.
So a lucky accident provided a means of overcoming the outstanding barrier to organ transplantation.
An English surgeon,(Sir) Roy Calne, then in Boston, investigated the use of a derivative of 6-MP, azathioprine, and after repeated experiments showed that it prevented rejection of kidney grafts in dogs.
In the next few years many clinical experiments established the effective use of drugs to suppress immune responses.
The obvious hazard, that immunosuppression would render patients vulnerable to all the infections against which immune mechanisms normally work, was found, somewhat surprisingly, not to be a major problem.
The longer-acting drug azathioprine was more satisfactory than 6-MP, and the adrenal cortical steroids also contributed to the prevention of graft rejection and to establishing organ transplantation as a regular therapeutic practice.
The reasoning which led to the discovery of the antimalarial pyrimethamine was applied equally fruitfully 15 years later, to the drug trimethoprim, which was as specific for certain bacteria as pyrimethamine was for malaria parasites.
All the drugs mentioned represent an astonishing range of achievements.
History is still being made with antiviral agents from the same laboratories.
All this arose from the wise and fortunate decision to study the biosynthesis of nucleic acids.
As Hitchings himself has pointed out, ‘we were uncommitted with respect to specific disease targets, but we were bound to follow wherever our thoughts and antimetabolites led us’.
At the end of 1988, Hitchings and Elion and Sir James Black (see Chapter 12) shared a Nobel prize for ‘discoveries of important principles of drug treatment’.
Progress in cancer research
Would-be developers of anti-cancer drugs have continued to seek competitive antagonists which might block one or another stage in the synthesis of pyrimidines and purines.
At the same time, great advances have been made in finding out how best to use the many drugs now available.
The margin between doses which destroy only malignant cells and those which damage healthy cells is very small, and the cure of a cancer depends on removing or killing all the malignant cells which elude the body's own control.
Many years of research in many places have been devoted to working out the best ways of using surgery, radiation, and drugs to treat each kind of solid tumour and of using radiation and drugs for those disseminated cancers, such as the leukaemias, in which no central growth can be removed.
Often, more can be achieved by a combination of surgery, radiation, and drugs, or by combinations of drugs than can be done by any single means.
Among the very many antimetabolites which have been investigated, only a small number have shown the combination of properties necessary to be therapeutically useful.
More or less empirical screening is very unreliable for showing drugs active against cancers, but more re fined methods have evolved.
Several useful agents have been found in unexpected places.
They include antibiotics produced by fungi (dactinomycin, daunorubicin), alkaloids derived from some plants of the Vinca species (vinblastine, vincristine), synthetic organic compounds containing platinum (cisplatin), the antiviral agent interferon (see Chapter 10), and even a vaccine made from an unfamiliar bacterium,Corynebacterium parvum .
The activity of corticosteroids (see Chapter 5) against lymphocytes has offered a means of controlling lymphocyte tumours.
A variety of other agents have shown specific, useful activities, with a fairly limited range of application.
Often their mode of action provides fresh  problems and, at least potentially, new insights into the processes which lead to the growth of cancers.
Overall, the search for ‘a’ cure for cancer has resolved itself into a large number of separate questions, many of which have still to be solved.
It is no disparagement of the successes which have been achieved to say that cancer remains, largely, unconquered.
For many patients with cancer, the prospect of long-term survival without recurrence is much more uncertain than it is, say, for infections, such as tuberculosis or cholera.
Neither the researches funded by charities specifically directed towards cancer nor the great drives sponsored by governments and planned by committees have been a fruitful source of new treatments.
Research into cancer has been well funded.
As early as 1913, when the British Medical Research Committee (later Council) was established (see Chapter 4), cancer was the major topic to which it did not direct attention, because a charitable find, the Imperial Cancer Research Fund, was already making substantial provision.
As has been recorded in this chapter, the principal anti-cancer drugs have been discovered either as a by-product of military research financed by government or by research in the pharmaceutical industry, much of which had its roots in research not primarily concerned with cancer.
The laboratories supported by the various cancer research agencies have, of course, made many valuable discoveries.
Spectacular scientific advances have come from them just as they have from other institutions.
But the problems of curing cancer have not been solved.
At present, more can be achieved by avoiding exposure to recognized carcinogens than by relying on the discovery of new remedies.
Such prevention is in the province of every citizen and every politician, and it is sad that the political appeal of ‘getting cancer licked’ can divert extensive resources to activities of doubtful value.
Conferences, committees, grandiose planning of operations divorced from day-to-day contact with laboratories and clinics, and the blind screening of endless substances have not been notably efficacious.
We described, at the beginning of this chapter, a society set up in 1801 to investigate the nature and cure of cancer.
Much was written but no cures were found.
In 1971 the United States legislature passed a National Cancer Act, requiring the Director of the National Cancer Institute to produce a five year plan of his intentions.
By 1973 a plan had been created from a basic structure set up with the aid of a ‘systems management specialist’.
Administrators of the institute and some 250 cancer specialists met in groups at a retreat in Virginia between October 1971 and March 1972, to list every conceivable way of approaching cancer research.
With all the possibilities set out in great detail, action could be taken, but the results are not striking.
Sixteen years later, it was claimed that ‘nobody in biomedical research wanted the War  on Cancer’.
This exercise in planning research from outside has done little good to patients with cancer, and the politicians have given place to others.
Apart from the dollars spent, one may wonder at the concealed costs of taking so many consultants away from their patients and research workers from their laboratories and clinics.
The limited range of drugs which are effective against cancer have been discovered by uninterrupted research in laboratories, often on subjects which have had little very obvious relevance to cancer, but a lot to do with the chemistry of living cells.
That field is in no way exhausted.
Cause unknown
Internal medicine
When the cause of an illness is unknown, the search for a cure (in the strict sense of the word) is inseparable from the search for a cause.
But the progress of a disease can be mitigated and the disability and suffering of patients can be relieved without finding a cure.
Diseases of the heart and blood vessels, asthma and other allergies, gastric and duodenal ulcers, and kinds of arthritis all fall into this category.
They are not the result of any known lack of food or hormones, and no microbes have been proved to cause them.
Nor does knowledge of contributing causes give an easy way out.
The familiar enemies — cigarette smoking, too much alcohol, too much fat and sugar, and lack of physical exercise — do no good to health, but the cure by a frugal and temperate life is unattractive.
Most people prefer to enjoy themselves and forget the cost until it is too late.
Preventing or curing disease by a change in lifestyle raises problems to do with education and politics that are somewhat beyond our scope.
In most common diseases of western society, we know more or less what has gone wrong, even if we do not know why it has gone wrong.
Also we often know of drugs which will reverse some of the changes; drugs which will steady an irregular heartbeat, drugs which will lower a high blood pressure, and so on.
And if we do not have the right drugs for a particular adjustment, research on orthodox lines will often find one.
So numerous drugs have become available, but the adjustments they achieve are sometimes disappointing.
The body is full of compensatory mechanisms, and corrective treatments which are adopted for apparently sound reasons have often turned out to do more harm than good.
Blood pressure
Reasoning about diseases of the heart and blood vessels began to have a sound basis when, in the seventeenth century, William Harvey established that blood circulates from the heart, through arteries to the minute  capillary vessels in every organ, and back by the veins to the heart.
Surgeons, and anyone concerned with the seriously wounded, knew that blood was under considerable pressure in the arteries, because it spurted powerfully if an artery was severed, but the arterial pressure was not measured until Stephen Hales (1677–1761), ‘Rector of Farringdon, Hampshire, and Minister of Teddington, Middlesex, undertook a fearsome experiment while exsanguinating a horse.
Time passed and more humane, non-invasive methods of measuring blood pressure were devised.
The familiar instrument in common clinical use depends on measuring the pressure which checks the flow of blood in an artery, and was introduced at the end of the nineteenth century.
Other instruments were invented which recorded the actions of the heart and the flow in the vessels, and it became possible to investigate how the whole system was regulated throughout all the different activities of life.
Clinical research showed how far the human circulation behaved like that of other animals, and how it changed as diseases advanced.
Without this progress, understanding the existing drugs and inventing new ones would have been impossible.
The circulation depends on having enough blood in the system to fill the vessels, on the small arteries acting as taps which can be adjusted to send the blood where it is needed, and on the heart beating hard enough to push the blood through the resistance given by the taps.
The system is regulated by the controlling, involuntary or autonomic nerves (chapter 4), by hormones, and by the centres in the brain which co-ordinate all these component parts.
A defect in any of them can disturb the balance of the whole system, and the use of the right drug to restore balance had evident possibilities, if the right drugs could be discovered or invented.
The causes of high blood pressure, or hypertension, and of clotting, or thrombosis, are still obscure, in spite of the mountains of evidence accumulated about the mechanisms by which the blood pressure may be raised or the blood may clot.
Plenty of drugs lower the blood pressure, and several prevent clotting, and all look as though they should be useful treatments.
However, it is not quite so simple.
In the nineteenth century the name ‘essential hypertension’ was invented, meaning that in some patients a rise in blood pressure is a protective mechanism, essential in order to overcome narrowing of the arteries and force blood through them to reach vital organs.
The high blood pressure was, in this view, essential for the survival of the patient, and, if it were so, drugs which reduced the blood pressure were more likely to do harm than good.
On the other hand, many patients with high blood pressure ultimately had strokes, apparently because their vessels burst under the excessive pressure, or they died because their hearts failed in the continuous task of driving blood through their constricted arteries.
Controversy about essential hypertension has  waxed and waned for a century, and what is orthodox today may change with time.
And what can the cure-seekers do about a disease which is so difficult to understand?
Between 1945 and 1956, many research findings identified other factors which affected the blood pressure.
They included the amount of salt in the body, the activity of the brain, the sympathetic nerves, and the adrenal glands, and the role of the kidneys in secreting a hormone-like substance which would indirectly raise the blood pressure.
Low-salt diets and sedative drugs contributed to the methods of treatment.
These and many other factors are of great importance to practising physicians, but to do justice to them and to the controversies which they provoked is beyond the purpose of this book.
We shall focus on the search for drugs which lower blood pressure, while noting that they do not cure, that their role is essentially palliative, and that their use is not always appropriate.
Before 1940, few such drugs were available.
Most acted directly on the blood vessels.
Those which caused a fall in pressure by weakening the heart appeared unsuitable, and some of those which, like nitrates (see chapter 2), cause all vessels to dilate extensively were beneficial only in special circumstances.
More effective drugs had their origin in the basic research on chemical transmission of nerve impulses described in chapter 4.
Transmitters and mediators
The transmitter substances which we described in chapters 4 and 6 provided a valuable basis from which to start searching for new drugs.
Dale and his colleagues in the 1930s showed that acetylcholine, in addition to its other properties, was a local hormone relaying messages at autonomic ganglia, that is at critical points in the nerve pathways which control the heart and blood vessels, and at the sites where nerves activate voluntary muscles.
The first drugs which could be relied on to reduce the dangerously high arterial pressure which precedes strokes and heart failure were substances which blocked the actions of acetylcholine at these ganglia, and so prevented the passage of nervous messages which put up the blood pressure.
A series of synthetic compounds, with a long pedigree going back to the work of Crum Brown and Fraser in the 1860s (see chapter 2), were produced simultaneously by R. B. Barlow and H. R. Ing in the Pharmacology Laboratory at Oxford and by W. D. M. (later Sir William) Paton and Eleanor Zaimis at the National Institute for Medical Research.
Some of them are potent ganglion blocking agents and were introduced into clinical medicine, but they had grave disadvantages.
Drugs of this sort interfere with the moment-to-moment control of blood pressure.
All is well as long as the subject is lying down, but when he stands up, the  reflexes which normally make arteries all over the body contract to meet the new hydrostatic conditions no longer operate effectively, and a sharp and dangerous fall of blood pressure follows.
If the dose is adjusted carefully, and changes of posture are made slowly, it is possible to get about, and so the compounds are not unusable.
When they were given to patients with high blood pressure, the immediate results were encouraging.
During the 1950s, several such compounds were introduced, and they were used extensively.
But the search for better ganglion-blocking drugs was unfruitful.
All the drugs weakened the fine control of blood pressure, so that patients were liable to faint if they stood up too suddenly.
Control of other organs was also impaired, and led to difficulties in focusing the eyes, to abdominal distension when the muscles of the gut failed, and to impotence.
They were not drugs which made patients happy.
More selective agents were sought, although this was theoretically unpromising.
If the receptors for acetylcholine were all the same, agents which blocked any of them were expected to block all of them.
However, detailed analysis of the ways in which receptors are blocked revealed many unforeseen complications.
New substances were synthesized which acted rather like the ganglion-blockers and lowered blood pressure, but showed distinct and important differences.
More selective compounds did emerge, and some of them continue to play an important role.
Acetylcholine, adrenaline, and other hormones with both general and local effects, were originally discovered (see chapters 4 and 5) by examining extracts of tissues of the body for substances which showed physiological effects.
Many scientists were interested in other tissue extracts, several of which were known to affect blood vessels but were not identified until after 1945.
It was often difficult to guess which ones had important physiological roles and which were by-products or artefacts formed when tissues were damaged during extraction.
The pursuit of their properties was intellectually exciting but something of a gamble if the aim was to discover a drug for a specific purpose.
For example, a substance which lowered the blood pressure was first discovered in 1934 in extracts of the prostate gland and in semen.
It was called prostaglandin, but in time was found to be a mixture of many related substances with very complex chemical and biological properties.
In the 1960s the chemical structure of one of these substances and subsequently of many other members of the family were established.
More people became interested and the field expanded rapidly once the exact composition of the prostaglandins was known.
They seemed to have many roles, in reproduction, in blood vessels, in certain enzyme systems, and in the activity of nerves.
An unexpected but intriguing discovery was that aspirin and related pain-relieving drugs stop the formation of some prostaglandins.
This discovery gave fresh impetus to research aimed at developing new  drugs which, like aspirin, would relieve pain and control inflammation, and also it provided a new basis for testing candidate compounds.
It became clear that prostaglandins have a prominent role in tissue inflammation, as well as in such diverse functions as blood clotting and contraction of the uterus.
Thus the original study spread into wider fields.
The original observation that an extract containing prostaglandins lowered blood pressure was a good reason for further investigation, but did not mean that it would lead to an agent for treating high blood pressure.
Indian snake-root
It is perhaps surprising that plant tissues contain substances which affect animals, but plants have always been a useful source of drugs, and indigenous remedies from all parts of the world were studied when research interests expanded after 1945.
Most of them proved disappointing because no activity could be demonstrated, but one Indian medicine proved to be important.
Rauwolfia serpentina , or snake-root, is a climbing shrub long used by the inhabitants of India and neighbouring countries as a sedative, and for other medicinal purposes.
During the 1930s several alkaloids were prepared from the plant and investigated, but their properties did not correspond to the sedative and hypotensive properties of the crude drug.
Another alkaloid, named reserpine, was isolated in 1952 in the Ciba laboratories in Basle.
It fascinated pharmacologists, mainly because it displaced stores of adrenaline-like transmitter substances both from the brain and from other tissues (see chapter 13).
Among the consequences was a fall in blood pressure, particularly when the drug was given to patients with a high pressure.
Reserpine became the focus of further clinical studies.
Its sedative effects were valued, but sometimes progressed to pathological depression with suicidal tendencies, so its use was limited.
Rauwolfia is often quoted as an example by those who think that more attention should be paid to indigenous plant remedies.
However, one must remember that the number of plants reputed to relieve one condition or another is enormous, and that most of them have not stood up to critical investigation.
Substantial sums have been spent in the deliberate search for medicinal plants, and they have seldom been rewarded.
It must be remembered, too, that plants which contain medicinally active substances often do not contain them all the time in all their parts.
Substances may accumulate and disappear according to the functions which they serve and the stages in the plant's life cycle.
Cultivating such plants on a sufficient scale for worldwide needs may be difficult in primitive surroundings where the plant grows naturally and impossible elsewhere.
Aesthetic and  romantic ideas of the beneficent properties of ‘natural’ remedies do not always stand up to the realities of practical life.
Receptor for adrenaline
Although the nerve pathways from the brain to the blood vessels and heart use acetylcholine as their transmitter at ganglia, they end in terminals which release an adrenaline-like substance, so a possible way of controlling blood pressure is to block the action of this substance.
No suitable drugs for this purpose were known before 1950, and the exact identity of the transmitter itself presented difficulties.
It had been established as a close relative of adrenaline, named noradrenaline, late in the 1940s.
But a rather elaborate hypothesis emerged, particularly popular in the USA, which involved excitatory and inhibitory ‘Sympathins’ which were thought to combine with the transmitter to produce the active mediators (see chapter 4).
This theory dampened interest in new evidence and new interpretations.
In 1948 Raymond Ahlquist, then at the University of Georgia, made careful measurements of the effects of adrenaline and closely related compounds on several functions of the sympathetic nerves.
His work suggested that there were two kinds of receptor for adrenaline and adrenaline-like substances.
His conclusions were far reaching and, although the experimental evidence was sound, it was not thought to be sufficiently convincing to challenge the ideas about sympathin.
As Ahlquist wrote later, ‘The original paper was rejected by the Journal of Pharmacology and Experimental Therapeutics , was loser in the Abel Award competition, and finally was published in the American Journal of Physiology due to my personal friendship with a great physiologist, W. F. Hamilton’.
Little attention was paid to it, and 10 years passed before the existence, let alone the exact functions of these receptors, non-committally named alpha and beta, was recognized.
In common with many other groups, researchers at the Eli Lilly Laboratories in Indianapolis were ringing the changes on the structure of adrenaline, with the initial objective of developing a compound which, like adrenaline, would relax the bronchial muscle and so be valuable in treating asthma.
A good compound would not have the unwanted actions of adrenaline on the heart and blood pressure, and would go on acting for longer.
One drug with these properties, isoprenaline, was already well known.
Among the substances produced at Eli Lilly, some not only relaxed the airways but, unexpectedly, made the tissue less sensitive to adrenaline.
It appeared that these substances not only stimulated the adrenaline receptor but remained attached to it and blocked it.
A blocker could be useful in several ways, and a compound (dichlorisoprenaline) was  developed accordingly.
As it turned out, it blocked just those actions of adrenaline which Ahlquist had grouped with the beta receptors, and it had no appreciable effect on the alpha receptors.
Unfortunately it could not be used clinically.
However, this discovery greatly strengthened the hypothesis that there were alpha and beta receptors, and the idea at least became widely accepted.
Among the actions which Ahlquist had attributed to beta receptors was the stimulation of the rate and force of the heartbeat.
It was known that stimulation caused the heart to increase its oxygen consumption.
J. W. (later Sir James) Black, who was at that time an academic pharmacologist in Glasgow, had the idea that blocking the action of adrenaline on the heart might reduce its need for oxygen and so be beneficial in angina pectoris (a condition in which pain arises because the oxygen supply to heart muscle is insufficient).
When Black moved to the Imperial Chemical Industries Pharmaceutical Laboratories near Manchester he began a 4-year search for suitable compounds.
Eventually a compound was identified which met the specification.
Named Nethalide or pronethalol, it was the first effective clinical beta-blocking agent.
Pronethalol had only just come into clinical use when it was found to produce tumours in mice.
As this suggested that it might also be a cause of cancer in man, it was promptly withdrawn, to be succeeded by a more acceptable agent, propranolol.
Many other beta-blockers were subsequently developed by different companies, because the market was very large.
Clinical evidence began to accumulate, suggesting that the new drugs had a wider range of useful activities than had been predicted from experiments in animals.
They lowered blood pressure in patients with hypertension, prevented irregularities of the heartbeat which might be caused by adrenaline, reduced mortality after coronary thrombosis, and, perhaps most importantly of all, they revealed the complexity of the factors which control cardiac activity in man, and the difficulties of predicting the effects drugs will have without first carrying out extensive and detailed experiments, both in the laboratory and in the clinic.
Histamine, another active substance first extracted from tissues (see chapter 4) is not involved in the treatment of high blood pressure, but the study of receptors has been extremely fruitful in exploring its properties and discovering other drugs.
Substances that blocked the actions of histamine were discovered from the late 1930s onwards, and by the end of the 1940s were well known as ‘antihistamines’.
They were useful for treating allergic disorders and also as sedatives and remedies for motion sickness.
However, these antihistamines did not block all the actions of histamine, and, in particular, they did not affect its ability to stimulate the stomach to secrete acid.
When substances were discovered which did block these actions a second histamine receptor was postulated and the  search began for clinically acceptable drugs.
Black, by this time at the laboratories of Smith, Kline, and French, led a team which achieved results no less interesting than the discovery of beta-blockers, and of equal practical importance.
Their work culminated in the drug Tagamet or cimetidine, soon widely adopted as the most effective remedy yet discovered for gastric overacidity and gastric and duodenal ulcers.
For his achievements in the design and discovery of drugs, Sir James Black was to share a Nobel prize with Doctors Hitchings and Elion (see chapter II) in 1988.
Salt and water drugs
After Ahlquist made his first observations on the alpha and beta receptors, and before they had any practical development, another series of drugs appeared which, somewhat unexpectedly, contributed to the treatment of hypertension.
They were discovered in a search for diuretics, i.e. drugs which increase the volume of urine, and were not the first diuretics to have additional valuable properties.
Withering's interest in digitalis was aroused primarily because it promoted a flow of urine and relieved swollen, dropsical tissues of their load of water (see chapter I).
But here the main action of digitalis is on the heart, and the removal of excess water is a consequence of improving the circulation of blood and the transport of water.
Other diuretics have been known for a long time, especially arsenical compounds of mercury.
Early in the twentieth century, when the success of Ehrlich's organic compounds had been recognized, organic mercurial compounds were tested as treatments for syphilis.
The rationale was simple: if arsenic could be made into a better drug by incorporating it into an organic compound, why not mercury?
Although the results were not striking, organic mercurial drugs began to be widely used.
Clinical measurements were becoming popular about this time, and many interesting things were being discovered as a result of this more quantitative approach.
A. Vogl wrote a charming account of how, as a young doctor on the wards of a Vienna hospital, he discovered that patients passed very large volumes of urine after they had received injections of one of the new organic mercurial compounds.
He described how difficult it was to interest his seniors in this useful discovery.
However, it did eventually become well known, and for 20 years organic mercurials were the most potent diuretics in clinical use.
However, they were effective only when injected, and something better was desirable.
In 1957 a better diuretic was found, but only after a logical but circuitous investigation, described in detail by K. H. Beyer of Merck, Sharpe, and Dohme.
On the way his team investigated an undesirable property of  some sulphonamides, which were liable to crystallize in the kidneys and cause serious damage in consequence; the enzymes inhibited by sulphonamides and by compounds containing mercury; and the normal working of the kidney.
Luckily they chose experimental animals which happened to include a species sensitive to one of the new agents under trial.
If rats, traditionally used for studies on urine flow, had not been replaced by dogs, just because larger animals were needed, the new drug, chlorothiazide, would have been missed, since its activity in rats is insignificant.
Chlorothiazide is the forerunner of a large class of similar drugs, which have become known as the thiazide diuretics.
They provide an effective way of eliminating excess water and salt, and are very safe when properly used.
Once the research costs had been met, they were not particularly expensive.
Organic mercurials were completely displaced.
Heart failure is common in patients with high blood pressure, and so these patients were often given thiazides.
It soon became evident that the thiazides had an antihypertensive effect of their own and that they augmented the effect of most other antihypertensive drugs.
The later thiazides have comparable activities, and have come to be a mainstay of therapy in mild hypertension, and important contributors in more severe conditions.
Like the beta-blocking drugs which came into clinical use later, their effects were not predicted but were undoubtedly useful.
So the circuitous route to the new diuretics had a final twist: the drugs were not only diuretics but antihypertensives as well.
Evaluation
The drugs introduced between 1950 and 1965 came to dominate the treatment of hypertension.
Before 1950 there were no generally recommended drugs to lower the blood pressure.
Twenty years later at least four major families of drugs were widely used, as well as a considerable number of supporting agents which were believed to help some patients in particular circumstances.
What was achieved by the great expansion of research which produced these drugs and the clinical innovation which adopted them so freely?
There is no doubt that these potent drugs caused many problems.
Once it became possible to lower a patient's blood pressure substantially, it was not merely of academic interest to know whether the raised blood pressure was really ‘essential’, that is necessary to maintain a sufficient flow of blood through narrowed arteries to vital organs, and, if it was, whether modest treatment (to ward off the obvious hazards of strokes or heart failure) could be tolerated.
It became important to distinguish a raised blood pressure caused by an unknown progressive disease from one associated with anxiety, stress, and fear, particularly fear of medical treatment and its  implications (‘white coat hypertension’).
And above all, hard facts were needed about all the consequences of any of the regimes of treatment which could be adopted.
If the use of a drug seemed appropriate, what dose should be used, and for how long should it be continued?
Although there is no fundamental objection to life-long medication — many diabetics rely on daily injections of insulin with no prospect of stopping — no drug is without hazard, and the longer the treatment continues, the stronger the case should be for it.
All this made evaluation the new drugs very difficult.
It had to take place over a long period, in the face of a prodigious number of uncontrolled variables which were likely to confuse the outcome.
For patients with severe hypertension and an expectation of life of months or at most a year or two, the benefits of lowering the blood pressure were soon seen.
Clinical trials in which comparable patients received either one kind of treatment or another confirmed this belief.
But when studies were extended to the less seriously ill, uncertainty prevailed.
Patients lived for many years, and some died from causes unrelated to their blood pressure.
The effect of the drugs on their length of life was very difficult to judge, and small differences could be attributed to many incidental causes, such as differences in smoking, dietary habits, the amount of exercise they took, or to changes in all these habits over the years.
Not least among the ‘incidental’ factors was the probability that a particular treatment might be so disagreeable that it was abandoned, or not used often enough.
‘Compliance’ received increasing attention, and the phrase ‘quality of life’began to appear.
Therapeutic trials were undertaken to investigate as many of these factors as was feasible, and necessarily involved many patients and many doctors, nurses, secretaries, and controllers.
Some doctors became rather sceptical, and some began to protest that the multiplication of therapeutic trials was diverting resources away from more basic research.
However, valiant attempts were made to conduct massive trials in which as much information as possible could be included.
The results, obtained at considerable cost, were full of interesting facts but they were not always very conclusive.
Beliefs which had become established almost as folk-law, such as the universally harmful effects of too much salt, had less support than might have been expected.
But the practical necessities of treating patients remained, so the majority of physicians continued to use as many of the available remedies as they thought necessary, relying on their personal experience, the opinions of colleagues, and the reports of such trials as they had time to study.
Most, although certainly not all, of the remedies of 1840 were innocuous, and most had certainly not been tested in any formal way.
Those of today have always had some evaluation, but seldom enough to cover all the circumstances in which they may be used, and they include many of such  potency that their misuse can have dire consequences.
Thus although much has been achieved, it would be a mistake to believe that most of the problems have been solved.
Hypertension is but one among many diseases, and progress has been made similarly in developing new drugs for regulating or adapting other parts of the body: drugs to strengthen the heart, to promote formation of blood, to help blood to clot or to prevent blood from clotting, to aid respiration, to increase the flow of urine, or selectively to increase or to diminish the amount of some selected component, to prevent conception or to promote fertility, drugs to stimulate the production of hormones or to block their actions, drugs to influence some particular aspect of the metabolism, and so on.
To describe all these discoveries is beyond our scope.
Taking a less detailed view, the patterns of discovery do not differ greatly.
New knowledge of the basic physiology and biochemistry of the body provides new ideas for developing drugs.
Sometimes chance discovery directs research onto new and profitable lines.
Often there are discoveries which lead nowhere and do not attract much, or indeed any attention.
Some may be seen 20 or more years later to have been seminal but were ignored because they did not fit into the theories current at the time.
Many are forgotten, buried in old scientific journals or the archives of individual pharmaceutical companies.
Attempts to rescue and re-evaluate them are apt to be less rewarding than making a fresh start.
Drugs which act on the brain are comparable in many ways to any other drugs.
Some of them modify mental as well as bodily functions and have effects beyond the repertoire of conventional laboratory experiments in pharmacology.
They have provided remedies for the treatment of some kinds of insanity, and some of them alter conscious experience in ways which are of great philosophical interest.
They are discussed in the next chapter.
Drugs and the mind
Poppy or mandragora
The earliest human records contain evidence of the use of substances which alter mood or behaviour.
At least four have been in use for so long that we have no idea when they were discovered.
Alcohol, opium, cannabis, and tobacco have been known for centuries and the history of each fills many books.
These drugs are still widely used, and for many people one or more of them is a regular part of everyday life.
None of them is harmless, and all can present problems when they are abused.
Strong social pressures often support or repudiate their use, and sometimes the pressures lead to control or prohibition by governments.
Alcohol is the most widespread drug in use and was probably the first to be discovered.
Written records attributed to the Hittites of Asia Minor of 1500BC contain references to wine, and its use is familiar from Homeric legends onwards.
Opium was probably known in Roman if not in Greek times, and was used to promote sleep as well as to relieve pain.
Cannabis comes from hemp, which was among the first plants to be domesticated, especially in parts of South-East Asia, where it is a valuable source of fibre for making rope and twine.
The plant,Cannabis indica , yields a resin known by various names including marihuana and hashish.
Its use is recorded by the Greeks and Romans, and by the Chinese.
One can only guess how these drugs were originally recognized, though it is easy enough to imagine how the fermented juice of squashed grapes began to be enjoyed.
The first use of tobacco is also unrecorded, but the plant was known to American Indians and was brought to Europe in 1558 by Spanish explorers.
The practice of smoking the prepared leaves of the plant was popularized in England by Sir Walter Raleigh (1552–1618).
It is widely agreed that such psychoactive plants or preparations from them were much used in religious ceremonies, where their effects were taken as evidence for religious reality; visions of Paradise which could be reached only by the faithful.
At the festivals of Dionysus, or Bacchus, wine was central to the proceedings.
The experience of a mind-moving drug  offered, and still offers, an agreeable escape from the monotony of life.
Medicinal properties, whether real or supposed, were gradually attributed to these substances.
But the ill-effects, especially those that developed slowly, took much longer to be identified.
Cirrhosis of the liver was recognized in the eighteenth century as a consequence of too much drinking.
Lung cancer was not seen as a sequel to smoking until the middle of the twentieth.
Dependence on each of these drugs was also recognized rather slowly and perhaps reluctantly.
Even in the late nineteenth century opium could be purchased readily in some pharmacies in England.
Explorers of distant countries found other plants which produced curious mental effects.
They included the soothing mandragora, the energizing coca leaves (see Chapter 6), and the givers of disordered visions, the Mexican cactus Peyote and certain mushrooms of the Amanita and Psilocybe families.
On the other hand, a lot of folk-lore about plants was investigated to no avail.
An understanding of the substances which produced these curious effects came with the advance of chemistry in the eighteenth and nineteenth centuries.
Distillation liberated the spirits from fermented grains and fruit juices, and in time ethyl alcohol was purified.
Lavoisier established that carbon, hydrogen, and oxygen were the sole constituent elements of this alcohol, and his successors determined its exact structure as CH 3 .
CH 2 OH.
Much was learnt, and much remains to be learnt, about the innumerable other constituents which give particular qualities to particular beers, wines, and spirits.
But identifying the principal active ingredient of alcoholic drinks was a vital step forward in that it allowed the quantity of intoxicant to be measured accurately, always the first step in any proper study of drugs and their actions.
Doctors and philosophers were beginning serious studies, first of the effects of the crude mood-and-mind drugs, and later of purer principles.
In 1883 the German physician Emil Kraepelin (1856–1926), who was very influential in psychiatric circles, suggested that studying the intoxicating effects of hashish might aid the understanding of other kinds of mental disorder.
The active principles of cannabis were not purified until well into the twentieth century, but one of Kraeplin's pupils was among those who made early studies of mescaline, isolated from the Mexican Peyote cactus in 1896.
The chemical structure of mescaline was established in 1918 and was found to be closely related to that of adrenaline, which leads to some interesting speculations.
The drug is still occasionally used experimentally by scientists, psychiatrists, and philosophers, as well as by dilettante drug takers.
New chemicals synthesized by man were found sometimes to have effects on the mind.
The effects ranged from the hilarity and confusion produced by laughing gas (nitrous oxide in less than anaesthetic doses) to a  simple diminution of the sense of pain by fever-reducing drugs of the coal-tar dyestuffs industry (see Chapter 2).
The origin of these substances did not suggest that they would have magical or mystical properties, and so began to dispel ideas that psychotropic drugs had any metaphysical significance.
William James, in his study Varieties of Religious Experience , discussed the effects on consciousness of alcohol and of anaesthetics, including nitrous oxide, without distinguishing sharply between ‘naturally occurring’ and man-made substances.
Pharmacologists also adopted a down-to-earth approach.
Buchheim, professor at Dorpat in the 1860s, is said to have rated the botanical characteristics of drug-containing plants as no more important to medicine than the case in which a surgeon carried his scalpels was to surgery.
But exclusion of the mystical did not advance knowledge very far.
The human brain was very inaccessible to any sort of experimental investigation.
Little progress was made in this field before the 1950s, but in the 1940s a particularly notable drug came to light unexpectedly.
Once again ergot (see Chapters 4 and 6) was involved.
One day in April 1943 Albert Hoffmann, a chemist who was working at Sandoz on the development of ergot alkaloids, felt unwell and went home early, where for some hours he experienced a variety of disordered visions.
He guessed that these effects might be due to intoxication by one of the compounds he was working with, and confirmed his idea by deliberate experiment.
The substance was identified and named lysergic acid diethylamide (in German, Lysergische Säure-Diäthylamid, or LSD).
It became one of the best known ‘psychotogenic’ drugs.
Like its predecessors, it attracted attention from many sources, and in the liberal or liberated social climate of the post-war years it probably created more problems than it solved.
Some of its pharmacological properties are of great interest to scientists trying to understand how the brain works.
Problems of insanity
In spite of the interest which Kraepelin and others had taken in them, strange mental states produced by drugs did not help much towards understanding the causes of or finding treatments for insanity.
The classical approach, through post-mortem examinations, also gave little benefit.
Indeed, the search for anatomical abnormalities seemed to create a division between conditions, such as haemorrhage into the brain or a cerebral tumour, where an organic cause of disease was obvious, and conditions where a patient was all too evidently suffering from a mental disturbance, but for which no physical basis could be found.
Attempts to classify mental disorders and give them names ran into many difficulties.
No two patients were quite alike and objective criteria  were scanty.
Some ‘patients’ were simply of very low intelligence or ‘feeble minded’.
Some, often but not necessarily in early adult life, behaved peculiarly and described visions; they were said to have dementia praecox or, in more recent language, schizophrenia.
Some had excessive swings of mood, and were either excessively energetic or elated, or, more often, inert and plagued by beliefs of their own worthlessness and guilt; the manic-depressive psychosis.
Some had delusions of persecution or of grandeur.
Some gradually lost their memory and all their skills as they aged, and were classified as suffering from senile dementia.
Alzheimer described a similar condition beginning in middle life.
Most of these patients died for reasons unrelated to their strange behaviour, and such microscopic abnormalities as might be found in the brain seemed too obscure to account for the disturbance of the mind.
The doctrine that mental disease did not have a physical cause became widely established, so much so that a study published in 1915 which reported definite changes in the left cerebral hemispheres of schizophrenic patients was largely ignored until it was rediscovered 70 years later.
However, the borderline between those disorders which were classified as physical and those which were seemingly mental began to shift as knowledge advanced.
One mental condition after another turned out to have a physical basis and, sometimes, to be alleviated when the physical defect was corrected.
The apathy of patients with myxoedema was associated with failure of the thyroid gland and was overcome by treatment with the whole gland or one of its active principles (see Chapter 5).
The ‘feeble minded’ children labelled cretins also suffered from thyroid deficiency, or, usually, from a deficiency of the iodine which is necessary for the gland to function effectively.
They could be cured if they were treated in time with iodine, whole gland, or pure hormone.
Once the spirochaete which caused syphilis had been identified and Wassermann had invented the diagnostic reaction which perpetuates his name, the condition called general paralysis of the insane was recognized to be the result of a long-lasting infection.
Means of relief were sought, and it was found that fever, produced artificially or by deliberate infection with malaria, produced remissions.
Effective anti-syphilitic drugs, the arsenicals and later penicillin, made prevention possible, though they could not effect a cure if damage to the brain had gone too far.
Another form of mental disorder, pellagra, was associated clinically with diarrhoea and dermatitis.
It occurred mainly in communities with poor diets and was eventually identified as a deficiency disease which could be promptly and completely cured by supplying adequate food.
Later the missing dietary ingredient was identified as nicotinic acid.
Each advance transferred one more kind of ‘mental’ disorder to the category ‘physical’.
But until about 1950, the hard core of insanity, especially the schizophrenic and the manic-depressive psychoses, appeared to have no physical basis.
The special nature of their illness resulted in patients being shunned socially and isolated in special institutions.
As there was no effective treatment, the asylums were more custodial than therapeutic and did not usually cater for investigation and research.
The great change which followed can be attributed partly to changes in social beliefs and attitudes in the 1950s and 1960s, and partly to the success of three strands of investigation, which began more or less independently but soon converged.
In university laboratories and research institutes, studies of nerve cells, and particularly of the transmission of impulses from one nerve to another, developed widely from the 1920s onward (see Chapter 4).
The transmission at sites outside the brain by acetylcholine or by noradrenaline was established unequivocally (see Chapters 6 and 12) and later it was established that both these substances were present at many sites inside the brain and spinal cord.
Whether they functioned as transmitters was difficult to prove: the technical problems of access to particular sites inside the skull, located in the middle of the dense networks of nerve cells and fibres which make up the brain, are still far from being completely solved.
But the idea that this is how messages would pass from one nerve cell to another presented no difficulty.
It implied that there would be ways of modifying it, just as peripheral transmission at ganglia could be blocked by methonium compounds and transmission at certain nerve endings by beta-blockers (see Chapter 12).
For those working in industrial pharmaceutical laboratories, the technical problems of designing drugs to act on the ‘mind’ were formidable.
There were no good models in animals of human mental disorders, and no obvious way of devising them.
If a new substance produced unusual behaviour in a mouse or a rat, it was worth further study, but this approach required skilful observation and took time.
Batteries of tests were devised, and very large numbers of compounds produced by innovative chemists were studied.
Like most screening operations, the yield was poor and the significance of the positive findings was limited.
Occasionally, very occasionally, an outstanding discovery rewarded this speculative labour.
In hospitals a number of new drugs were being used.
These drugs were intended to have specific effects and on the whole it was hoped that they would have as few other effects as possible.
But sometimes unexpected things happened.
Alert clinicians noticed surprising events and related them (not always correctly) to some new drug which was being used.
The general ethos in western Europe and America favoured the publication of any novel findings, often far in advance of facts being properly established.
So ideas passed rapidly from one institution to another and promising  discoveries stimulated the development of new advances in many different quarters, sometimes with remarkably fruitful results.
The devious paths to tranquillizers
The traditional sedatives, laudanum, mandragora, bromide, paraldehyde, chloral, barbiturates, all had disadvantages and were gradually displaced.
The antihistamines, which became well known late in the 1940s (see Chapter 12), turned out to have several properties which would not have been predicted from what was known about histamine.
They reduced nausea and prevented vomiting, and many of them made people sleepy.
Antihistamines became popular remedies for motion sickness, and a search, only marginally successful, began for effective compounds which did not cause drowsiness.
Their sedative action naturally raised the possibility that histamine was a neurotransmitter.
Little evidence supported this theory, and there was rather more reason to think that antihistamines might be blocking noradrenaline receptors.
As the antihistamines were developed from early attempts to find adrenaline blockers, this was not entirely surprising.
One of the most powerful antihistamines, Phenergan (promethazine) was developed in the laboratories of the French firm Rhone-Poulenc.
Many related compounds were made in the same laboratories and were investigated in more or less detail according to the promise they showed.
The French psychiatrist Pierre Deniker, records that a substance closely related to promethazine and later known as chlorpromazine was synthesized in 1950 and ‘would have remained on the shelves had the surgeon and physiologist Henri Laborit not asked the manufacturer for a drug with central effects stronger than those of promethazine’.
Laborit was investigating the potential of controlled hypothermia, that is, chilling patients during surgical operations so that they would be less reactive to any disturbance, and the sedative properties of promethazine helped to achieve the effects he sought.
Several other groups, including some psychiatrists, began to investigate the drug chlorpromazine about the same time.
Deniker lists fourteen publications in French journals between February and October 1952.
It emerged that, in conscious and especially in excited or agitated patients, the drug produced a remarkable state of inactivity or indifference.
Some authorities maintained that it was the first time a single drug had been shown to be useful in controlling psychotic patients.
At the very least it was more selective than various predecessors which by that time had fallen into disrepute.
Further investigation showed that it had a large number of actions: so large that the trade name Largactil was coined.
The basic chemical structure common to promethazine and chlorpromazine provided a good basis from which to begin the search for  compounds which were better than chlorpromazine, and in the next few years many came into clinical use.
At about the same time, the alkaloid reserpine, extracted from the Indian plant Rauwolfia serpentina , was attracting interest for the treatment of high blood pressure (see Chapter 12).
It had been used in India to control over-excitement and mania.
As was soon discovered, it acts rather like chlorpromazine, but it is slower to take effect.
Patients sedated by reserpine are liable to become depressed and have suicidal urges, and repeated large doses of the drug produce tremor and rigidity resembling Parkinson's disease, so its clinical usefulness is limited.
But the discovery that it depleted the brain of certain transmitters made it a valuable tool in investigating brain mechanisms.
Quite by chance, and while he was working on a different problem, an Australian psychiatrist, J. F. Cade, discovered that, in guinea pigs, lithium salts made the brain less excitable.
He tried using lithium salts to quieten manic patients.
As lithium salts were not amenable to being patented, they did not attract the attention of the drug industry: also they had a bad reputation for their toxic effects, and so Cade's findings were neglected for a long time.
It was nearly 20 years before Cade's discovery was reinvestigated and found to be a useful treatment for maniacal patients.
It is not known how lithium salts work.
They are mentioned here to illustrate that lines of thought and research do not always converge.
A chance finding, outside the mainstream of scientific research, can sometimes be very valuable, but it is often difficult to see its potential.
Curare and its effects have been mentioned previously (see Chapter 6).
Psychiatrists envisaged that curare might be useful in relieving muscular tension and so diminish the feedback from over active muscles which perpetuates a sense of anxiety in tense patients.
Curare is inactive when taken into the body by mouth (which is why it is a good arrow poison for hunting game: any poison in the meat of the paralysed animal is not absorbed and does no harm to the eater).
So curare itself was unsuitable, but a substance named mephenesin achieved the desired relaxation, by acting on the spinal cord rather than on the junction between nerve and muscle.
Mephenesin was not a good drug: its effects were too short lived, and it had other unwanted effects.
A derivative, meprobamate, appeared in 1953.
Under the trade names Miltown and Equanil, it was widely advertised, especially in the United States, and became very generally known.
Perhaps, more than any other drug, it promoted to the general public ideas about new ‘tranquillizers’, and did more to establish the questionable notion that anxiety could be banished with pills.
So there were a large number of new drugs, all purporting to quieten disturbed patients, and very little means by which to evaluate them property.
In practice the phenothiazines and lithium proved to be of great  importance in managing schizophrenia and mania, respectively, and in helping to restore many patients to everyday life.
The others were more difficult to assess.
How, indeed, were mental states to be measured, and how was a mental state to be judged to be lessened or heightened if it could not be measured, even crudely?
How were clinical trials, so convincing for antituberculous drugs, to be brought into the sensitive area of subjective experience?
Could a course of treatment be judged without reference to the accompanying activities of the doctors who arranged it?
Could one, indeed, evaluate the effects of the doctors themselves, and, if not, what was the good of having them?
The new drugs were widely acclaimed, as so many other medical and surgical procedures had been.
Critical examination by the most reliable of tests and measurements, usually showed that they had little if any action greater than that of placebos, or that their effects on performance were deleterious rather than beneficial.
But were the tests sensitive or relevant enough not to miss therapeutically important benefits?
The evaluation of drugs had become more complex.
Relief of depression
Whatever benefits were conferred by the phenothiazines, they gave little help to patients who were suffering from excessive mood swings or who had entered into long periods of helpless depression.
The most effective treatment before 1960 for severe and disabling depression was electro-convulsion therapy.
This practice had a curiously devious origin, in a supposed antagonism between epilepsy and schizophrenia.
It was inferred, by what seems now a rather wild speculation, that artificially produced fits might arrest the progress of schizophrenia.
The idea was tested by using drugs which produced convulsions.
In some schizophrenic patients, particularly those who were unresponsive to human approaches and showed other features of depression, the treatment appeared to work.
When electrical stimulation was used instead of drugs, and was properly managed, regulation of the ‘dose’ was easier.
The improved treatment was investigated for patients whose only disorder was severe depression, and found to give much benefit.
The occurrence of convulsions carried risks of bone fractures and of other injuries, but ingenious psychiatrists encouraged the development of standardized preparations of curare which could be used clinically to prevent the muscular component of the electrically-induced seizures.
‘Modified E.C.T.’ became an established and very valuable practice by which countless depressed patients were restored to health.
Until the late 1950s it was practically the only effective remedy for a most distressing disorder.
The first effective antidepressants evolved from discoveries in a quite different field.
When the new antituberculous drug isoniazid (see Chapter 10) was used, there was a striking improvement in the well-being of the patients.
Their appetites improved; they became cheerful and they gained weight remarkably quickly.
Another product of the same line of research, Marsilid or iproniazid, had similar effects.
Initially there appeared to be little to choose between them, but careful comparative trials showed that Marsilid made more contribution than isoniazid to the improvements in appetite and the weight gain.
However, Marsilid also had more unwanted effects than its companion drug, and some patients experienced psychotic episodes.
The interest of psychiatrists was aroused, and so was that of biochemists.
The chemical structures of isoniazid and Marsilid were, somewhat distantly, related to that of several of the amines known to be present in living tissues.
These amines are metabolized by an enzyme now named monoamine oxidase.
Some of the amines which are decomposed by monoamine oxidase occur in the brain and are thought to function as neurotransmitters.
When it was shown that both isoniazid and Marsilid inhibited the activity of monoamine oxidase and that Marsilid was considerably more potent, the possible implications aroused a great deal of interest.
Did Marsilid act on the enzyme in the brain and protect a transmitter amine from premature destruction?
If the amine was essential to nervous processes which made people alert and responsive, it could explain the more energetic behaviour of tuberculous patients and also the abnormal excitement which they sometimes showed.
Marsilid was tried as a treatment for depressed patients, and, given over a period of weeks rather than days, but it had disadvantages as well as advantages.
The next step was to devise more potent inhibitors of amine oxidase in the laboratory.
This was a relatively straightforward exercise, because the chemical structures which served as the starting point were simple and the enzyme, which was easy to prepare, provided a much simpler test system than experiments involving whole animals.
Of course, such potent compounds had still to be assessed in animals, before they could be used in patients.
The most promising compounds were selected and studied in many laboratories, and in the next few years a substantial number of monoamine oxidase inhibitors went into clinical trials, and some into widespread clinical use.
Opinions about the value of the new drugs varied, as they had about tranquillizers.
The more scientifically rigorous the clinical trials, the more some observers judged that the trial itself had created an environment unfavourable to the effectiveness of the drug.
Others commented that the subjective experience of patients was outside the range of what could be recorded and judged objectively.
Apart from these difficulties it soon  became only too obvious that the drugs could be unexpectedly toxic.
Jaundice associated with liver failure appeared without warning and was sometimes fatal.
Also, it was discovered that monoamine oxidase removed certain amines from the blood stream — amines derived from food, chemically related to adrenaline, and thus liable to raise the blood pressure.
If patients being treated with monoamine oxidase inhibitors ate quantities of cheese or other foods rich in these amines they were prone to attacks of high blood pressure, sometimes sufficient to precipitate strokes or heart failure.
Fortunately another quite unrelated series of compounds was found to alleviate depression.
The discovery arose from the investigation of substances related to chlorpromazine.
They were all expected to have similar properties, but, prudently, in some clinics the new substances were given to patients with conditions other than those in which chlorpromazine and its allies were usually effective.
So it was that R. Kuhn, in Switzerland, administered compounds which had been prepared in the laboratories of J. R. Geigy S. A. to patients who were withdrawn, inactive, and depressed.
He observed that they improved.
According to Kuhn, ‘…thoroughness was not the only reason for doing this.
There was also our conviction that it must be possible to find a drug effective in endogenous depression.
This conviction arose from the literature study as well as from the great deal of experience we had acquired in the shock treatment of these depressions’.
The faith of the psychiatrist in whatever remedies he uses is an important contribution to, and perhaps sometimes the main reason for its effectiveness or its reputation, but this drug, later named Tofranil or imipramine, was found to be effective in many other clinics and came to be used on a wide scale.
It was the first of a series of compounds which are known as the ‘tricyclic antidepressants’, because their chemical structure contains three rings and distinguishes them from the monoamine oxidase inhibitors.
Both the monoamine oxidase inhibitors and the tricyclics were discovered empirically, but they aroused great hopes that the chemical disturbances in the brains of depressed people might at last be understood.
Monoamine oxidase inhibitors would prevent the inactivation of noradrenaline and other amines thought to act as neurotransmitters: might they be making good a lack of one of these amines in the tissues?
Quite quickly it was discovered that the tricyclics prevented the re-uptake of amines liberated at nerve endings, so they too were capable of increasing local concentrations of amines.
It was easy to imagine depression as a condition in which the stores of certain amines became exhausted: then the monoamine oxidase inhibitors would prevent destruction of noradrenaline and conserve what was available, while the tricyclics prevented losses from the stores.
Alas, it was not nearly so simple, and many more complex problems remained to be solved.
But it  was now clear that depression had a biochemical basis, even if its original causes lay in heredity and in the experiences of life.
Rescued from the remnants: a new range of tranquillizers
The search continued for drugs which would relieve anxiety, although in the absence of good models, approaches were bound to be somewhat speculative, and good luck also played its part.
One can enjoy its contribution to the story of Librium or chlordiazepoxide, the first of the benzodiazepines.
A development programme was undertaken by chemists at the Roche laboratories in New Jersey during the 1950s.
With commercial considerations about patenting strongly in mind, they pursued unfamiliar compounds, not related to the barbiturates or other sedatives or tranquillizers then known.
The wide range of existing tranquillizers had no common chemical features by which they could be identified, so this approach had some merit, particularly in inspiring chemists and setting them free to pursue interesting chemical problems with no biological constraints.
To pick out compounds which might be potential drugs, a number of animal experiments were adopted, including the assessment of muscular relaxation and reduction of aggressive behaviour.
The experiments gave positive results with meprobamate, at that time the most popular agent against anxiety in use in the USA.
One of the chemists concerned, Leo H. Sternbach, has described what happened.
He chose as his novel substances the class of compounds on which he had worked 20 years earlier when he was a Ph.D.
student at the University of Cracow, Poland.
The compounds had not led, as he had then hoped, to new dyestuffs, and it appeared that no one had yet investigated their biological properties.
At Roche he made some new compounds of the same class, but they were no more rewarding.
The chemical problems were interesting, but the biological tests were all negative, and there were more urgent jobs to be done.
The programme was therefore abandoned.
In April 1957, when what remained of the work was being cleared up, some specimens which had been laid by to crystallize were found to have done so, and so they were sent for pharmacological investigation.
it was supposed that, like their predecessors, they would be inactive and so would not waste much of the tester's time.
Sternbach promised that no more of the series would be sent.
However, one last compound was active, more so than meprobamate in quietening mice, preventing electrically-induced convulsions, relaxing muscles, and reducing aggressive behaviour in monkeys.
The compound did not make animals sleep and very large doses could be given without causing death.
So it received a full pharmacological and toxicological  examination.
No faults were found, and, as it behaved well in early clinical trials, it was duly marketed, under the name Librium.
It was an astonishing success, in terms of the extent to which it was used, the absence of immediately obvious ill-effects, and the financial returns on its production.
As usual it was the forerunner of a series of related drugs, and we may suppose Sternbach was allowed to withdraw his promise not to burden the pharmacologists.
The benzodiazepines rapidly became very popular.
All the problems of evaluation remained, but the people who took them felt better, and the doctors who prescribed them were relieved to find a means by which unhappy patients could be helped.
Depressed and anxious patients who sought refuge from their troubles by taking an overdose remained unconscious for a time but did not die of respiratory failure or asphyxiation, as happened only too readily after an overdose of barbiturate.
The subtler aspects of their effects on behaviour were widely investigated but remained extremely difficult to evaluate.
A decade passed before there was any general awareness that it is more difficult to stop taking benzodiazepines than to start, and that weaning dependent patients from their drugs could be a painful process.
Brain mechanisms and drugs
In spite of the continuing scepticism and regardless of the clinical faults of the new drugs, many attempts were made to find out how and where in the brain they worked.
Progress was easier because many new techniques were available.
By the 1950s and 1960s, delicate equipment for reaching and investigating single nerve cells could be built with new materials.
Specialized apparatus, which formerly had been made for specific purposes in the laboratory where it was required, could be obtained from manufacturers of scientific instruments, saving much time and labour.
Novel methods of analysis made it possible to do chemical separations in minutes instead of days or weeks.
Physical methods of estimating substances, for instance by measuring the absorption or emission of light at specific wavelengths, all increased the power, speed, and sensitivity of investigations.
Automatic equipment meant that many of the relatively routine tasks could be done more quickly and more accurately.
Technically, the methods which Dale and his colleagues used had become  archaic , as Dale (who lived to the age of 93 in full intellectual vigour) well knew.
However, in principle, they were unchanged.
Messages were passed from one cell to another by chemical messengers, and many drugs imitated, obstructed, or prolonged the activity of the messengers.
The problem was to identify the messengers and find out what messages each one carried.
A few of the salient discoveries are shown in table 13.1.
The transmitter, gamma-amino butyric acid, often referred to as GABA, first discovered from studies of inhibitory factors in the spinal cord, was found to be basic to the actions of the benzodiazepines.
Another, 5-hydroxytryptamine or serotonin, presents some tantalizing questions.
Its actions are blocked by the hallucinogen LSD.
Does this mean that our mental images depend on this amine in some way?
Are the disordered visions we call hallucinations a result of blocking serotonin?
What experiments could be done to find out?
The first transmitters discovered, acetylcholine and noradrenaline, are still being investigated.
A precursor of noradrenaline, named dopamine, has attracted a lot of attention since it is involved in the actions of the phenothiazines, in Parkinson's disease, and quite probably in schizophrenia.
So basic research and the discovery of new drugs for mental disorder are almost inseparable.
The academic scientist who seeks and identifies a new chemical messenger is providing his industrial colleagues with the basis for a whole new range of drugs, and the industrial pharmacologist who screens a range of new chemical entities and finds one which alters the behaviour of the brain is offering a new tool for his academic brethren.
It is all a very long way from the days of the preposterous proposition, when the American Society for Pharmacology and Experimental Therapeutics forbade its members to accept jobs in the pharmaceutical industry (see Chapter 6).
New light on old drugs
None of these newly-discovered substances explained the effects of one of the oldest of all the drugs used to relieve anxiety and pain, morphine.
Most of the potent drugs obtained from plants are known to act on specific physiological systems.
Indeed, the very specificity of their actions has provided a crucial tool in understanding these systems, as Langley showed with nicotine (see Chapter 4).
But morphine!
Morphine relieves fear and dismisses pain.
It has some effects, not obviously related, on coughing (for which it is a useful suppressant) and on the bowels (where it causes inconvenient constipation).
It creates a sense of well-being so attractive that few can resist using it if they have been exposed to it too often.
Can it be related to a system with a biological purpose?
However disagreeable pain may be, it is essential because it draws attention to bodily damage.
Pain is usually allied to behaviour which will protect injured parts and provide better conditions for local recovery.
Many thinkers have been troubled by the problems implicit in the occurrence of pain and suffering.
But biologically, pain can be seen to have survival value, and the benefit of a mechanism which suppresses pain and cancels an important warning mechanism, is not immediately obvious.
But pain often persists after all steps have been taken to relieve the cause, and practical investigators looked for drugs which gave the benefits of morphine without causing addiction or other inconvenient effects.
Codeine, which occurs with morphine in opium, relieves pain, but more feebly, and rarely causes dependence.
Heroin, derived from morphine by a modest chemical change, is more potent and more strongly addictive than morphine itself.
Many compounds, more or less related to morphine, have been prepared and tested, and a substantial list of alternative drugs provides possible substitutes with merits for particular purposes.
Chemically, they differ considerably from morphine, but they can usually be seen to correspond to part of the morphine molecule, and are thus envisaged as acting on the same receptors.
Advances in understanding other receptors and in devising methods for isolating them gave a more fundamental approach to the morphine problem.
In 1973 experiments were reported which described the isolation of portions of tissue containing something which combined specifically with morphine and other potent analgesics.
Plainly these were opiate receptors: but what were they there for?
It went against all biological sense to suggest that the receptors and the elaborate physiological adaptations which they set in motion had no purpose, or had evolved in response to taking opium.
There must be a naturally occurring substance which acts on the receptors, and, if so, it was likely that it was made and, when appropriate, let loose close to the opiate receptors, especially in the brain.
It might be any sort of compound, but a lot of evidence was accumulating that peptides, i.e. compounds containing a chain or ring of amino acids, frequently occurred in specific parts of the brain and had specific functions as local or systemic hormones.
Search for a peptide was rewarded by the discovery of a compound containing five amino acids, which combined powerfully with the opiate receptor and had all the necessary properties for it to be recognized as a new transmitter substance.
It was named enkephalin and its discovery was a major advance in the search for new analgesics.
Later opium-like activity was found in a group of larger peptides, named endorphins, and of which enkephalin was shown to be a key fragment.
The developments which followed are too recent and perhaps too elaborate to belong in this essentially historical account of the discovery of drugs.
The fact that a transmitter substance has been found does not mean that a new drug has been discovered.
Indeed, transmitters, by their very nature, are seldom suitable as therapeutic agents.
It is essential that a transmitter can be inactivated as soon as it has conveyed its message; if it were not so, the system would be clogged or would receive needless repetitions of the same message.
A drug, on the other hand, must be stable enough to reach its target, and there it must last long enough to achieve the  desired effect.
Acetylcholine was identified as a transmitter in the 1920s and 1930s, and what was known of its biology and chemistry guided the search for new drugs in the 1940s and 1950s.
So much greater was the pace of science in the 1970s, that, at a very crude estimate, what took 20 years for acetylcholine took 5 for the much less tractible opiate receptor and enkephalin.
At the time of writing we have yet to see what new drugs will come from this foundation.
What we now know as a result of studies on the enkephalin-endorphin system has brought a new understanding of pain and of bodily responses to injury.
Endorphins are released in response to severely painful stimuli.
They over-ride the normal protective mechanisms associated with pain.
Their survival value is clear: when severe injuries first happen it may be more important to get away at all costs than to stop and attend to them.
The experience of soldiers in battle is well documented, and there are many accounts of other circumstances in which horrible wounds are accepted with numbness but not pain.
It is also interesting to note that endorphins are released when acupuncture is practised and perhaps make a significant contribution to the therapeutic effects which may be achieved.
Body and mind
The discoveries made in the last 30 years about the action of drugs on the brain are important medically and philosophically.
It is beyond the scope of this book, and its author, to pursue the philosophical implications.
But one may note the steady accumulation of evidence that all kinds of mental disorder have a physical basis, and that biochemical adjustment brought about by drugs often provides more effective help to a disturbed person than any other process.
This is not to say that methods of biochemical adjustment are sufficient in themselves, or that a psychiatrist, however biochemically oriented, can neglect the pastoral aspects of caring for his patients.
It also seems inescapable that, however much conscious experience depends on the orderly biochemical working of the body, consciousness is itself outside the ordinary material concepts of matter and energy.
The disturbances of consciousness that are produced by drugs are profoundly interesting, and they may help us to understand its nature.
Or they may be no more than symptoms of a chemical fault in the consciousness-generator, and of no greater significance than that.