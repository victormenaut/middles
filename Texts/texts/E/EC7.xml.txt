

Editorials
Early nutrition and diabetes mellitus
Nutrition during fetal life and infancy may be crucial to the development of diabetes mellitus
—The pancreatic β cell mass in humans develops rapidly during gestation and infancy, increasing more than 130-fold between the 12th intrauterine week and the fifth postnatal month.
In rats the number of cells increases rapidly in the four to six days before birth, and the proliferative compartment — the proportion of β cells able to replicate — is thought to fall from 10% during fetal life to 3% in young adulthood.
These observations suggest that the peak β cell mass may be determined early in life, even during gestation, and the factors that influence it are likely to be important in the development of diabetes.
Nutrition is the main determinant of the growth of β cells.
The factors that influence the size of the proliferative compartment are less clear, though in rats there are genetic differences.
Hyperglycaemia during late pregnancy leads to hyperplasia of β cells in the neonate, and malnutrition in growing rats leads to a permanent reduction of the a cell mass.
Human infants who are small for dates — a marker for poor intrauterine nutrition — have fewer β cells.
Freinkel likened the environment of later gestation to a culture medium and coined the expression ‘fuel mediated teratogenesis’ for the longer range metabolic disturbance of middle life which he foresaw might result from the excess or deficiency of certain ‘culture’nutrients essential for normal fetal growth.
Two recent reports have focused on the part that early nutrition may play in the later development of diabetes.
In the first report Hales and Barker suggest that the factors determining early growth also influence the β cell mass in adulthood.
They hypothesise that impaired glucose tolerance and possibly type II diabetes may both result from poor nutrition early in life interacting adversely with abundant nutrition later on.
Obesity in later years leads to insulin resistance, and the functional β cell mass, programmed in leaner times, may then be unable to meet the rising demand for insulin.
Hales and Barker cite two convincing lines of evidence.
Studies of men in their 60s whose birth records were still available showed that low birth weight and low weight at 12 months were associated with glucose intolerance later in life.
The degree of glucose intolerance for any given birth weight was influenced independently by body mass index in adulthood.
Men with a low body mass index in later life were relatively protected against the susceptibility to glucose intolerance stemming from their low birth weights, while 17% of those of low birth weight but with a high body mass index later in life were frankly diabetic.
The studies have been extended to show the same inverse relation between birth weight and glucose tolerance in young men aged 18–25.
A report from Oxford in this issue confirms an inverse relation between glucose tolerance in later life and birth weight (p 302) but was unable to account for the marked impairment of β cell function in the type II diabetic subjects by low birth weight alone.
The authors conclude that additional genetic or environmental factors are likely to be necessary for the development of type II diabetes, consistent with the very high concordance rate for type II diabetes observed in monozygotic twins.
Insulin is packaged inside β cells as the precursor proinsulin, which is cleaved on secretion into C peptide and insulin.
Small amounts of proinsulin and the fragment 32–33 split proinsulin are also released in health.
Serum concentrations of both are raised in patients with type II diabetes, reflecting most probably a shift in the relation between demand for insulin and the capacity to produce it.
Whether the increased release of the precursor in type II diabetes is due primarily to a low β cell mass or to insulin resistance is unclear, but the serum concentration of 32–33 split proinsulin in the men reported on by Hales and Barker correlated inversely with their body weight at 12 months.
The second report suggests that the autoimmune damage to islet cells responsible for type I (insulin dependent) diabetes may also have a nutritional basis which operates early in life — but a totally different one.
Though the clinical presentation of type I diabetes peaks around puberty and sometimes occurs much later, highly sensitive assays for islet cell antibodies have suggested that everyone who develops type I diabetes is seropositive by the age of 5 years.
The implication is that the fuse for type I diabetes is lit early in life but may burn faster in some than in others.
Some years ago Western Samoans were found never to develop type I diabetes in their own environment but to do so when brought up in New Zealand.
Exposure to cows' milk was the suspected trigger.
An association between bottle feeding and type I diabetes has also been found in Finland.
Laboratory rodents that spontaneously develop autoimmune type I diabetes did so at a much lower frequency when fed a synthetic chow free of cows' milk protein, and recently a peptide antigen called p 69 was identified on rat insulinoma cells which cross reacts immunologically with a similar sequence present in bovine, but not human or rat, albumin.
Antibodies to bovine serum albumin were present in all patients with type I diabetes of new onset but in only 2.5% of  controls.
Antibodies to the relevant peptide sequence in the bovine serum albumin also identified the p 69 antigen from islets on immunoblots.
Karjalainen and colleagues have hypothesised that one route to type I diabetes is through molecular mimicry between the islet antigen p 69 and bovine serum albumin in cows' milk.
Early sensitisation to bovine serum albumin through bottle feeding in infancy leaves memory T cells which destroy β cells expressing p 69.
The p 69 antigen is inducible by interferon γ released intermittently during childhood infections, so that the process of destruction of β cells is protracted, variable, and uncertain.
Only a subset of the population — those with a genetic make up that was able to present the critical sequence of bovine serum albumin to the immune system — would be susceptible to the mimicry.
It therefore seems conceivable that susceptibility to both type I and type II diabetes is determined during gestation or infancy in response to nutrition, and research should respond with a new focus on early events.
But the similarity between the two of an early influence of nutrition may not stop there.
Diabetes results when the insulin reserve no longer meets demand.
If the stress on β cells that leads to type II diabetes is a progressively increasing demand (insulin resistance), the stress that leads to type I diabetes is arguably a progressively diminishing reserve (insulitis).
In either case the outcome is likely to be influenced by the peak β cell mass.
Perhaps the genetic linkage that has recently been described between type I and type II diabetes is a determinant of the β cell proliferative compartment and its response to early nutrition.
Improving medical education
Educators need to develop an open mind and a willingness to share
Stella Lowry's analysis of the problems affecting medical education (which ends this week, p 000) holds for countries other than Britain.
For example, we in the Netherlands are also struggling with medical curriculums overloaded with factual information, often of little clinical relevance, which risk turning our students into passive consumers, their creativity and curiosity stifled.
We assume that competent doctors emerge at the end of an obstacle course of traditional examinations based on facts.
Little place exists in many of our curriculums for other important opportunities for learning, such as use of simulated patients and early clinical contact, or for developing skills in self directed learning and communication.
As in Britain, changes in health care are only haphazardly incorporated into the educational programme.
If we all agree that change is required then why is it so difficult to implement?
Two impediments come to mind.
The first is the attitude of teachers.
Typically, tradition weighs heavily on us: curriculums are organised and taught in the way that we have always done it.
We have all gone through the same system (which seems not to have harmed us), and it is difficult to accept that current students should be taught differently.
Interestingly, this attitude contrasts starkly with how people conduct their clinical practice or academic research.
Here, a highly rational approach is the norm.
In clinical practice we try to keep up with the scientific literature and adapt our actions accordingly.
In academic research we submit our findings to rigorous peer review.
Regrettably, this attitude does not extend to our educational activities.
The reward system in our universities is the second impediment to change.
Just as examinations define students' academic success, so the academic success of university staff is defined by excellence outside education: higher status is mainly attained through outstanding research or excellence in clinical work rather than educational achievements.
Spending too much time on education may actually endanger one's career as less time is available for more effective ways of achieving success.
As long as this biased reward system persists, motivating teaching staff to improve the training of medical students will be difficult.
Starting from scratch has a certain attraction but is hardly an option in countries, such as Britain, which have long established medical schools.
So how could change be achieved in existing medical schools?
In her article Stella Lowry provides several examples.
Firstly, we need to convince our colleagues that problems exist and that there are better ways of doing things.
As well as persuasion, however, some external pressure, both from within and from outside schools, is needed to produce change.
Some central control is required over medical education to ensure that rational decisions are being taken and that the quality of education is monitored.
Individual departments in most medical schools have nearly unrestricted autonomy as far as their teaching is concerned.
We can therefore hardly expect change from individual departments: they lack an appreciation of the curriculum as a whole and are inherently inclined to defend their own interests.
Outside pressure is another indispensable force to achieve change.
In Britain institutions like the General Medical Council and the King's Fund could provide it yet they apparently lack the power to enforce recommendations.
On  the other hand, a string of national bodies seems undesirable and perhaps even unnecessary.
In 1991 the Dutch Ministry of Education initiated an educational review of all medical schools (carried out by the universities themselves).
The reviewing committee, on which all schools were represented, was highly critical of the quality of education provided by several medical schools.
What will happen if schools fail to comply with the recommendations remains to be seen — so far introduction of reviews has resulted in substantial voluntary initiatives for change in all Dutch medical schools.
Compared with other training programmes, medical education finds itself in relatively fortunate circumstances.
Over recent decades many changes have taken place, considerable experience has accumulated, journals specifically for medical education have been published, and conferences devoted to medical education have been held.
Courses and workshops on the topic are widely available.
Much of what is needed to tackle the problems in medical education is already available — as Lowry's series has made clear.
We now know much more about designing curriculums and about methods of selecting, teaching, and assessing students than before.
To progress, however, we need teachers and schools to become more conversant with the changes.
In education we are overly inclined to rely on our own tradition and intuition and to overstate the uniqueness of our particular circumstances (think of the thousands of teachers with their own stock of test questions in their drawer).
An open mind and a willingness to share are essential if we wish to tackle the current problems affecting medical education.
Stella Lowry's series should help.
Pre-emptive analgesia
Local anaesthesia given before general anaesthesia may reduce the severity of postoperative pain
Might analgesia given before a painful stimulus somehow prevent or reduce the pain experienced later?
Recent advances in our understanding of pain provide the background for this phenomenon of pre-emptive analgesia.
The nervous system does not modulate all pain in a fixed or ‘hardwired’ manner.
It responds to some stimuli by dynamic modification or ‘plasticity’; and once induced, this neuroplasticity may sustain and magnify the experience of pain.
Experiments on decerebrate rats have shown that noxious stimulation may generate reflex hyperexcitability in the dorsal horn of the spinal cord.
This central sensitisation prolongs and increases sensitivity to noxious stimuli over an expanded receptive field (hyperalgesia) and results in pain from previously innocuous stimuli (allodynia).
Repetition of the noxious stimulus evokes a progressively escalating response in the cord, which further magnifies the pain — a phenomenon termed ‘wind up.’
In animals much smaller doses of morphine will prevent sensitisation of the nervous system to pain than are necessary to suppress it, indicating that pre-emptive analgesia might be worth while.
Allodynia, hyperalgesia, and reflex hyperexcitability — presumably all caused by sensitisation of the nervous system — also occur in surgical patients, suggesting a potential for pre-emptive analgesia in humans.
Central sensitisation and wind up depend on the activity of N -methyl-D-aspartic acid (NMDA) receptors in the dorsal horn.
Antagonism at this receptor can prevent and even abolish these changes, suggesting that antagonists have a place in preventing and treating this pathological pain.
The only NMDA antagonist clinically available is the anaesthetic drug ketamine, but more useful agents with fewer undesirable effects on higher function are awaited with interest.
Peripheral sensitisation may also occur.
Injury may sensitise nociceptors, causing hyperalgesia at the site of injury and in surrounding non-traumatised tissue.
The mechanisms include the activity of chemical mediators from damaged tissue such as leukotrienes, bradykinin, histamine, and metabolites of arachidonic and sympathetic activity.
In addition a recently identified group of pain afferents (usually functionally dormant and called ‘sleeping nociceptors’) has been shown to be activated by inflammation and may contribute to peripheral sensitisation to pain after injury.
Agents able to interrupt these two mechanisms should be able to bring about preemptive analgesia.
Pre-emptive analgesia has, indeed, been said to have been shown to occur in several clinical studies.
Both premedication with opioids and local anaesthetic block before incision delayed the request for analgesia after orthopaedic surgery when used individually — and, more impressively, in combination.
Various non-steroidal anti-inflammatory drugs given before surgery have been shown to have analgesic effects.
Tverskoy et al reported that patients treated by infiltration of a local anaesthetic and then given general anaesthetic for herniorrhaphy experienced less pain, and for shorter duration, than patients who received general anaesthetic alone.
Spinal blockade produced intermediate results.
Pre-emptive analgesia may be relevant to the management of chronic pain; a Danish study showed a reduction of phantom limb pain for up to one year when ischaemic pain was treated effectively with epidural analgesia before amputation.
McQuay pointed out that though such studies show clinical benefit from analgesic interventions before surgery the mechanism might not be pre-emptive analgesia because the study designs did not compare identical analgesic interventions after the surgical stimulus.
Studies designed to compare identical analgesic interventions before and after injury have now been published.
Pre-emptive local anaesthetic field block for inguinal herniorrhaphy resulted in reduced pain scores and a delay in requests for analgesia during the six hours studied by Ejlersen et al , but similar work detected no pre-emptive effect over a longer period.
Katz et al found that patients given epidural fentanyl shortly before thoracotomy reported less pain and used less supplementary analgesic afterwards, while others found no equivalent effect of epidural bupivacaine and morphine before major abdominal surgery.
These conflicting findings probably arise in part from differences in the effectiveness and time course of the afferent blockade of nociceptors by the different interventions.
Furthermore, the sensitising effect of extensive nociceptive stimulation from surgery may prove much more difficult to block than the limited chemical or thermal stimuli used in  animal models of pain.
Nor do we know how long afferent blockade must be continued during and after surgery to ensure that neuronal plasticity is prevented and not simply delayed.
These considerations are important now that modern clinical anaesthesia uses low concentrations of volatile anaesthetics which abolish consciousness but may still allow sensitisation of the cord unless nociceptive input is otherwise reduced — a concern voiced 80 years ago by Crile.
Perhaps general anaesthesia should be combined with pre-emptive local and regional anaesthetic blocks more often.
As is so often the case, more work needs to be done.
Some encouraging laboratory and clinical studies suggest that pre-emptive analgesia does reduce pain after surgery, but the optimum choices of agents and timing required for a clinically useful effect remain to be established.
The underlying mechanisms may also be relevant to some chronic neuropathic pain states.
Selective decontamination of the gut
Does not affect survival in intensive care units
Nosocomial infections are commonest in intensive care units, where prevalences of 18–36% have been reported.
Rates of colonisation with potentially pathogenic micro-organisms are even higher, particularly in ventilated patients, and may exceed 80% in those staying in the intensive care unit for five or more days.
Potentially pathogenic micro-organisms are usually derived from the gastrointestinal tract and are mostly Gram negative bacilli, such as Enterobacteriacae and Pseudomonas spp, but they also include yeasts, especially Candida spp.
Patients requiring intensive care are at greater risk of nosocomial infection not only because their illness is severe but also because many therapeutic interventions actively promote colonisation or disable host defences.
Various forms of instrumentation, including ventilation, inhibit the usual means of clearing organisms from normally sterile epithelial surfaces.
Importantly, prophylaxis against stress ulcers with H 2 antagonists and antacids has been implicated in abnormal bacterial overgrowth in the stomach.
Similarly, as the gut requires luminal nutritional support to prevent mucosal atrophy and subsequent bacterial translocation the use of parenteral rather than enteral nutrition may also increase the likelihood of infection.
Vascular access may increase the risk of infection but cannulas are not usually colonised by organisms originating in the gut.
In the past decade attention has turned towards selective decontamination of the gut in an attempt to reduce these nosocomial infections.
Various combinations of topical and non-absorbable antimicrobial agents have been used to reduce relative numbers of Gram negative bacilli and yeasts cultured from faeces and the oropharynx while maintaining normal anaerobic flora.
Most regimens have included non-absorbable antibacterial and antifungal agents administered into the gastrointestinal tract by nasogastric tube as well as a topical preparation to the nasopharynx and hypopharynx.
A variable period of intravenous antimicrobial prophylaxis (usually with cefotaxime) has also been used.
Selective decontamination of the gut was first performed in immunocompromised patients outside the intensive care unit and resulted in significant reductions in the rates of colonisation and infection.
The first studies of patients in intensive care units began with investigations of multiply injured patients in the Netherlands, and these showed significantly fewer patients colonised with potentially pathogenic micro-organisms, particularly of the upper respiratory tract.
Fewer infections occurred but without any effect on survival.
Two recent prospective, double blind randomised trials have confirmed the absence of any improvement in overall mortality in the populations studied in intensive care units.
An earlier prospective study using a post hoc analysis, however, showed that selective decontamination of the gut was associated with a significant fall in mortality when patients with acute trauma were considered separately.
While use of mortality as the sole criterion of therapeutic efficacy in intensive care units is open to debate, these studies have all failed to show any cost benefit; in one, selective decontamination of the gut doubled the total cost of antimicrobial drugs.
Fears of the emergence of drug resistance in colonising bacteria in patients receiving selective decontamination of the gut have not been realised.
The lack of clearly defined benefit from selective decontamination of the gut in a heterogeneous population of patients led to a European consensus conference on the topic.
On the basis of published work (including the two recent large studies) the conference did not recommend the use of selective decontamination of the gut in any particular group of patients and, unsurprisingly, went on to suggest that further prospective controlled multicentre studies of sufficient statistical power should be done.
In our view, colonisation with potentially pathogenic micro-organisms can best be prevented by emphasising standard microbiological good practice.
Poor hand hygiene by medical staff is particularly refractory to change and should be subject to constant observation and correction.
Other simple measures include the avoidance of H 2 antagonists and antacids, regular changes of vascular access, and the use of enteral nutrition whenever possible.
Obtaining regular and appropriate specimens for culture from potential sites  of infection remains vital, as does avoiding unnecessary prescription of antibiotics unless there are clinical signs of infection.
Until there is good evidence that attempts to modify the ecology of the gastrointestinal tract are beneficial, attention to accepted standards and the further development of a multidisciplinary approach to infection in intensive care units are likely to reap greater rewards.
The language of health
A clinical language underlies the NHS information strategy
The launch of the NHS information management and technology strategy in December may not have been high on the agenda of most practising doctors.
The strategy's objective is to achieve a patient record that will be accessible wherever a patient is treated and to build on that record an entire clinical information system, so its success depends on the support of doctors.
The medical profession is supporting one of the main foundations of the strategy — the clinical terms project — which in the longer term may fundamentally change the way in which doctors work.
Central to the overall strategy is the ability to communicate information about individual patients and their care throughout the NHS.
Ultimately each citizen will have a unique NHS number, and nationally linked population registers will ensure both that information needs to be entered only once and that it is available to any clinician caring for the patient.
Electronic messages will replace many current paper transactions, and there will be a national standard for the structure and content of such messages.
A prerequisite for such a standard is a shared language, a list of common terms capable of being coded and thus transmitted electronically.
In the NHS this will be a thesaurus of those clinical terms that doctors and other health professionals currently use in their medical records.
The clinical terms project was started last year to develop a set of terms comprehensive enough to cover anything that a clinician might need to write in a patient's record.
Once this thesaurus has been devised it will be mapped on to a set of codes, which will allow the information to be communicated electronically throughout the NHS.
On the back of information collected for patient care will come aggregated information that can be used for resource management, budgeting, audit, and research on outcomes.
The codes that will be used are the Read codes, a computerised thesaurus of health care terms which have already been adopted as the standard clinical coding system for general practice and will be the standard throughout the NHS by 1 April 1994 (the deadline for the clinical terms project).
Thus when NHS wide networking is introduced it will be able to use the Read codes for communicating clinical information throughout the NHS.
The two year, £2.7m clinical terms project, which is supported by the Joint Consultants Committee, is being coordinated by the NHS Centre for Coding and Classification.
Most of the work is being done by 40 specialist working groups representing specialty associations and the relevant college or faculty committees.
Their task is to define and record all those terms that clinicians use in their medical records and to ensure that the appropriate Read codes are attached to each term.
Thus they have to include not only terms that are covered by existing classification systems such as ICD9 (diagnoses) and OPCS4 (Office of Population Censuses and Surveys classification of surgical operations and procedures) but also the many others not so classified — for example, clinical, social, and family history; symptoms and signs; diagnostic and laboratory procedures; operative and non-operative procedures; and drugs and appliances.
The groups will list all the terms used, define preferred terms and synonyms, arrange them in hierarchies according to their degree of specificity, and code the terms.
For example, a preferred term may be ‘dyspnoea,’ with ‘shortness of breath’and ‘breathlessness’as synonyms.
A hierarchy of preferred terms and their Read codes might look as follows:
The working groups also have to identify abbreviations used within their specialty.
Does MI, for example, stand for mitral incompetence or myocardial infarct?
The technical details, however, matter little to the user.
What is important is that the Read codes will cover any information in a patient record and that clinicians can go on using the words they like —‘breathlessness,’ for example, when taking a patient's history — though they will have to be more disciplined about abbreviations.
The Read codes will be applied automatically by the software running the clinical information system.
Once the clinical terms project is complete the NHS Centre for Coding and Classification will be responsible for keeping the thesaurus up to date, and the drug database will be updated monthly.
Doctors have not always welcomed the establishment of computer systems in hospitals — computers have often proved difficult to use, and the information has been of more use to  managers than to clinicians.
The technology available within the next five to 10 years — optical disk storage, text recognition, voice recognition, image processing, and graphical interfaces — should allow doctors more easily to capture and use clinical information electronically.
Also, the philosophy underlying the NHS's information strategy is that clinical information comes first.
Nevertheless, the process of building and using electronic records will require time, cooperation, money — and confidence about confidentiality.
It will alter the way in which doctors, nurses, and other professionals work (not least in making them rely more on each other 's information).
Often the most expensive element in implementing any computer project is the day to day disruption of user departments and the initial and continuing cost of training.
Unless patient care is seen to benefit, the investment in the clinical terms project and other elements in the information strategy will be wasted.
Prion diseases
Depend on transmissible and sometimes hereditable agents
That transmissible spongiform encephalopathies may be called prion diseases indicates the growing acceptance of the prion theory, which requires new concepts in biology.
There are three human prion diseases and four main prion diseases of animals.
The human diseases are kuru, seen only in the eastern highlands of Papua New Guinea and transmitted by ritual cannibalism, and two rare but worldwide diseases — Creutzfeldt-Jakob disease, usually sporadic, and Gerstmann-Straussler-Scheinker disease, usually inherited.
The animal prion diseases are scrapie, affecting sheep and goats and prevalent in most sheep rearing countries (although not Australasia or Japan); transmissible mink encephalopathy, occurring in rare outbreaks in captive bred animals on mink farms, mainly in North America; chronic wasting disease of captive mule deer and elk, seen in North America; and bovine spongiform encephalopathy, currently a major epidemic confined almost entirely to the cattle of the British Isles.
Diseases similar to bovine spongiform encephalopathy have recently been reported in several species of domestic and zoo animals.
All these are degenerative diseases of the central nervous system.
They have long incubation periods, often measured in years, but once manifested the disease usually progresses swiftly, without remission and uninfluenced by treatment, to death within a few months.
(Gerstmann-Straussler-Scheinker disease in its slower progression is an exception to this.)
The pathological features are confined to the central nervous system and include neuronal loss, astrocytic gliosis, and spongiform change.
There is no inflammatory reaction, which is consistent with the lack of any humoral or cellular reaction in the blood.
All the diseases transmit, including familial cases of Creutzfeldt-Jakob disease and Gerstmann-Straussler-Scheinker disease, most surely by the injection of brain tissue.
The intracerebral route results in the shortest incubation, which nevertheless may be measured in years.
The transmissible agent has characteristics unique to this group of diseases, being unusually small and displaying considerable resistance to physical and chemical methods of disinfection.
These features have suggested that the agent may not contain nucleic acid, which has prompted the name prion (proteinaceous infectious particle).
Normal prion protein, described as PrPc, is a constituent of the surface of the neuronal cell.
PrPSc, from scrapie brain, differs in being larger and less soluble and resisting protease digestion.
PrPSc is probably located within neuronal processes in cytoplasmic vesicles.
In association with mutations, now discovered in Gerstmann-Straussler-Scheinker disease and Creutzfeldt-Jakob disease (p 000), PrPc may change into PrPSc, which could itself be the transmissible agent, causing further conversion of PrPc to PrPSc.
One difficulty in the prion theory is the existence of a species barrier found in experiments attempting transmission to a different animal species.
Transmission often succeeds only after a long incubation period, which decreases substantially after serial passaging.
This species barrier has recently been investigated by using transgeneic mice expressing the gene for hamster PrP.
Prions ‘adapted’ to either hamster or mouse were inoculated into hamsters, normal mice, or transgeneic mice carrying the hamster PrP transgene.
The great reduction in incubation times with appropriate transgeneic lines shows how prion adaptation can alter the species barrier in transmission.
Some strains of mice with hamster PrP transgenes, when inoculated with hamster prions show incubation periods as short as 75 days rather than the 500 or more days in non-transgeneic controls.
The novel biological behaviour of the prion is gaining acceptance, but the traditional idea of a small virus (virino) controlled by nucleic acid is not yet abandoned and is a preferred explanation of the existence of strains of experimental scrapie.
Elaborate analysis of the data has tried to unite these discrepant theories.
The correspondence columns in the weekly scientific and medical journals are seldom without comment on this fascinating group of diseases and their strange causative agent.
PAPERS
Use of tumour marker immunoreactivity to identify primary site of metastatic cancer
Abstract
Objectives —
To determine whether variations in the expression of tumour related antigens can predict the origin of tumours.
Design —
Immunohistological study of tumour marker expression in primary adenocarcinomas and respective metastatic deposits.
Antibodies to the following tumour markers were used: polymorphic epithelial mucin (NCRC-11 and SM3), carcinoembryonic antigen, carcinoembryonic antigen with non-specific antigen cospecificity, CA125, CA19.9, prostate specific antigens, and thyroglobulin.
Setting —
Histopathology department of teaching hospital.
Subjects —
100 pathology sections of metastatic adenocarcinoma and their related primary tumours.
Main outcome measures —
Concordance of reactivity between primary and metastatic tumours.
Reactivity profiles of tumour sites.
Results —
The correct primary site of origin was predicted in 70% (33/47) of tumours in men and 54% (27/43) tumours in women with antibodies SM3, 288, CA19.9, CA125, and PSA (men only).
Specificities ranged from 68% for breast tumour to 98% for prostate tumour.
Conclusion —
Use of tumour markers in patients presenting with metastatic adenocarcinoma of unknown origin can help localise the probable primary sites and reduce the need for extensive and expensive imaging techniques.
Introduction
Metastasis of unknown origin is defined as a metastatic tumour, the primary tumour of which remains occult despite taking a clinical history, physical examination, chest radiography, analysis of blood and urine samples, and histological and electron microscopic evaluation.
It is a common phenomenon, accounting for 5–10% of all cancers.
The primary site becomes apparent in 20% of patients during their lifetime and 75% are found at necropsy.
About 75% of occult primary tumours are below the diaphragm, predominantly in the pancreas, colon, stomach, and liver.
The lung is the most common site above the diaphragm, accounting for 15–20% of cases.
Patients presenting with metastasis of unknown origin have a mean life expectancy of only four months so most diagnostic methods occupy a large proportion of the patient's remaining life and identification of the primary site only rarely influences the choice of treatment.
Nevertheless, many patients receive extensive and expensive investigations, perhaps more for clinical interest than to benefit the patient.
Some patients with metastasis of unknown origin do have responsive tumours.
Investigations should therefore aim at identifying patients with tumours that might respond to systemic treatment (either chemotherapy or some form of endocrine manipulation).
Any diagnostic system that is quicker and cheaper than the present system would be of use.
Certain tumour markers such as thyroglobulin and prostate specific antigen can provide sensitive and specific diagnostic information about the primary site of metastatic thyroid and prostate tumours.
Many studies have examined the diagnostic potential of immunohistochemistry, but they have generally failed to show the clear definitions found with prostate specific antigen or thyroglobulin.
Combinations of such antibodies may offer a more accurate system for identification of tumour type.
We examined the immunoreactivity of a large range of tumour marker antisera in a series of adenocarcinomas and their respective metastases to determine whether patterns of reactivity could help identify the primary sites of metastases and to assess the clinical value of this system as a routine method of investigation.
The cases used in this study were selected to include a range of primary sites and were not true cases of metastasis of unknown origin.
Methods
We searched the computer records of the histopathology department for 1987 to 1991 to identify patients who had had adenocarcinoma or metastatic neoplasm diagnosed.
A consecutive series of 1100 patients was identified.
We selected 100 patients in this series who had both a known primary site and synchronous or appropriate non-synchronous metastatic disease.
Patients were selected consecutively on the basis of primary site of tumour.
The numbers of tumours at each site were predetermined according to the approximate frequency of presentation at that primary site.
Sites chosen included colon, small intestine, stomach, pancreas, salivary gland, oesophagus, breast, lung, kidney, bladder, endometrium, ovary, fallopian tube, and prostate.
The histological sections of each lesion were reviewed to select tissue blocks containing representative and adequate volumes of tumour.
In all cases a diagnostic primary tumour block was also reacted with the antibodies.
Twelve sections were cut from each formalin fixed paraffin wax embedded block at a thickness of 3 µm.
The tissue sections were stained by the avidin-biotin complex immunocytochemical method, with diaminobenzidine as the chromogen and copper sulphate for end product enhancement.
Table I shows the primary antisera used.
Each section was examined through a microscope and scored by a single observer (without knowledge of tissue type or site of origin) from zero to four depending on the number of cells reacting.
A score of 0 represented no reactivity, 1 represented strong staining in up to 1% of cells, 2 strong staining in <30%, 3 staining in <60%, and 4 staining in up to 100%.
For  the purposes of the discriminate analysis tissues were classified as showing no reactivity versus any reactivity.
Reactivity to thyroglobulin and the prostatic antigens was not included in the discriminate analysis, as these markers seemed highly sensitive and specific for their respective tumours and therefore would not contribute to the analysis.
We used discriminate analysis for the remaining results, with the primary diagnosis group as the dependent variable and entering the scores for antibody markers stepwise.
The discriminant functions obtained were used to predict the site of the primary tumour in the samples and the results compared with the actual primary diagnosis for each patient.
Tumours (except thyroid and prostate) were grouped according to their anatomical relation and treatability: breast; lung; gut (including colon, oesophagus, stomach, and small intestine); female genital tract (including ovarian, fallopian tube, and endometrium); and others (including pancreatic, renal, bladder, and salivary gland).
Results
The intraobserver variability of the scoring method was assessed by repeat scoring of 46 samples.
The score was different in nine cases, but the difference was no more than one.
The results were then compared by a Wilcoxon signed rank test for match pairs; significance was 0.2, which is satisfactory.
Overall there was no significant difference between the reactivities of primary and secondary tumours for any of the antibodies.
Some of the antibodies, NCRC-11 and SM3 (against polymorphic epithelial mucin), 198 and 228 (against carcinoembryonic antigen), and PSAP and PSA (against prostate specific antigen), gave comparable results and in discriminate analysis knowledge of reactivity of both antibodies in each of these pairs did not provide appreciable additional information.
The number of antibodies required in the panel was therefore rationalised.
The optimum panel for investigation of men comprised PSA, CA19.9, 228, SM3, and CA125 and predicted the primary site for the common types of tumours found in men with an accuracy of 70% (table II).
In women this panel of antibodies (without PSA) gave a level of discrimination between the common groups of tumours of 58% (table III).
The sensitivity and specificity of the antibody panel for each tumour group were determined from tables II and III.
Tumour sites correctly predicted into group X were classified as true positive results; those incorrectly predicted into group X as false positive results; those incorrectly not predicted into group X as false negative results; and those correctly not predicted into group X as true negative results (table IV).
Discussion
We have shown that knowledge of immunohistological reactivity with a panel of six antibodies to tumour markers can predict the primary site of origin correctly in 70% of tumours in men and 58% of tumours in women with specificities ranging from 68% for breast tumours to over 90% for tumours in the gut, lung, prostate, and thyroid.
This system should not be judged solely on its ability to diagnose the occult primary site correctly (sensitivity) but also on its potential to exclude other sites.
In patients who could potentially benefit from treatment of advanced disease (those with breast, gynaecological, prostate, or thyroid tumours) the specificity was at least 68% and would be of clinical value.
The tests would enable identification (with varying certainty) of patients who might respond to treatment and increase their survival.
The results of the antibody tests were interpreted without knowledge of metastatic site or other clinical information and are considerably better than results of morphological studies using routine sections, in which only 27% of sites were identified correctly on morphology alone and 46% with knowledge of the metastatic site.
Electron microscopy may improve identification but it is not widely available, is expensive, and is limited by the need for specially fixed tissues when generally only formalin fixed tissues are available.
Although formalin fixed tissue can be used or transferred into glutaraldehyde, the loss in quality of the sample precludes identification of subtle features.
Ultrastructural evidence of neuroendocrine differentiation may be shown but is not widely used to discriminate primary site of origin.
With the exception of computed tomography most radiological investigations cannot identify the primary tumour in metastatic disease of unknown origin.
Gorich et al found the primary site by computed tomography in 58% of 31 patients with metastatic disease of unknown origin.
Among the remaining patients, computed tomography was helpful in 19%, but unhelpful or wrong in 23%.
Serological studies (for the markers α fetoprotein, β human chorionic gonadotrophin and carcinoembryonic antigen) are generally of little use  because of their lack of specificity and are generally used to monitor patients with tumours of known primary site — for example, CA125 in ovarian cancer.
Knowledge of the immunohistological profile of a metastatic tumour can be used to determine which patients should receive additional investigations.
Interpretation of the metastatic spread of the lesion, symptoms, and history; careful physical examination, computed tomography; mammography; immunoscintigraphy of likely primary sites; and relevant serum assays may also be helpful, but these tests are often expensive.
Such investigations could be used more effectively if guidance about the tumour site was available.
For example selective computed tomography could be performed instead of whole body scans, which are extremely expensive.
Investigative mastectomy could be considered for women with normal mammograms who present with axillary nodal disease when antibody reactivity supports a primary tumour in the breast.
The reproducibility of the immunohistological results was good.
A highly sensitive immunohistochemical technique was used (avidin-biotin complex) and it is unlikely that any improvement on the methodology would be worth while.
choice of antibodies
The value of each antibody as a member of a panel should be considered critically.
Many studies have shown that the antibodies PSA and PSAP have over 90% sensitivity for prostatic adenocarcinomas.
We found sensitivities of 84% and 74% for PSAP and PSA respectively.
Another study found that poorly differentiated solid carcinomas showed only weak staining and in our small sample a poorly differentiated tumour would significantly decrease the apparent sensitivity.
Since metastases of unknown origins are usually poorly differentiated the sensitivity of testing with these antibodies would also be reduced.
Although we could not determine the sensitivity of thyroglobulin, the specificity of about 100% agrees with previous results.
The expression of ovarian tumours of the antigen CA125 is dependent on whether the tumour is serous or mucinous.
Serous ovarian tumours are generally consistent and strong expressors of the antigen whereas mucinous tumours may show no or only weak staining.
Our antibody panel is therefore useful in identifying serous ovarian tumours but would not identify mucinous ovarian tumours correctly.
Further assessment of this problem was not possible because of the small number of cases but knowledge of histological type could further assist in determining the sensitivity of this method.
Endometrial reactions with the antibody CA125 have been reported to be 84% sensitive in frozen sections.
We used paraffin sections which may account for the 50% sensitivity that we found.
Binding of the antibody SM3 showed a similar pattern to that with NCRC-11.
These two antibodies recognise epitopes on the core protein of the same high molecular weight glycoprotein (sometimes called epithelial membrane antigen and recently called polymorphic epithelial mucin), which is normally expressed by exocrine gland cells and a wide range of adenocarcinomas.
SM3 had a greater specificity for breast and lung tumours than NCRC-11.
The coding sequence on the mucin core protein recognised by SM3 is relatively long.
It has been suggested that extensive exposure of the core protein occurs more commonly in breast cancer than in other cancers, which would give SM3 some specificity for breast cancer.
NCRC-11 has a smaller coding region and it is therefore more likely to be expressed in other cancers.
Our results support this hypothesis.
Reactions with carcinoembryonic antigen antibodies such as 228 are variable and not highly specific, although in our series most gastrointestinal tumours (stomach, colon, small intestine) scored highly with 228.
Pancreatic tumours, however, generally showed weak reactivity.
These results are similar to those of Heyderman et al , who found that 20 out of 22 primary pancreatic tumours focally or weakly stained for carcinoembryonic antigen.
future prospects
Other antibodies with site specificity will probably be produced or recognised in the future.
Such antisera could improve the ability of a panel to identify primary tumour site.
It may also be possible to extend the diagnostic discrimination using cytokeratin subtype classification, neuroendocrine status, or serological antibody titres.
For example, the new antibodies to progastricsin and DD9-E7 could increase specificity of diagnosis of intra-abdominal adenocarcinoma (colon, stomach, small intestine, pancreas).
The enzyme progastricsin, is present in 30–40% of gastric adenocarcinomas and is thought to be useful in differentiating between colonic and gastric adenocarcinomas.
Gastric carcinoma is very common in patients presenting with metastasis of unknown origin, although at present the antibody's clinical usefulness is questionable as the disease has a poor prognosis.
Antibody to DD9-E7 has been reported to have 100% sensitivity for adenocarcinomas of the exocrine pancreas.
Further work is needed to establish whether it should be included in an antibody panel.
In conclusion our results show the potential value of immunoreactivity of tumour markers in assisting identification of the site of the primary tumour in patients with metastasis of unknown origin.
It is an inexpensive, simple procedure which could be performed as part of the diagnostic histopathological process and could direct or reduce the need for subsequent imaging procedures.
If used routinely with data derived from a prospective study, a probability rating for primary site could be determined during confirmation of metastatic adenocarcinoma.
Who's afraid of informed consent?
Abstract
Objective —
To test the assumption that patients will become unduly anxious if they are given detailed information about the risks of surgery in an attempt to obtain fully informed consent.
Design —
Preoperative anxiety assessed before and after patients were randomly allocated an information sheet containing either simple or detailed descriptions of possible postoperative complications.
Setting —
Four surgical wards at two Sheffield hospitals.
Subjects —
96 men undergoing elective inguinal hernia repair under general anaesthesia.
Main outcome measure—
Change in anxiety level observed after receiving information about potential complications.
Results —
Detailed information did not increase patient anxiety (mean Spielberger score at baseline 33.7 (95% confidence interval 31.3 to 36.2), after information 34.8 (32.1 to 37.5); p=0.20, paired t test).
A simple explanation of the facts provided a statistically significant degree of reassurance (mean score at baseline 34.6 (31.5 to 37.6), after information 32.3 (29.8 to 34.9); p=0.012), although this small effect is likely to be clinically important only in those whose baseline anxiety was high (r=0.27, p=0.05).
Conclusions —
In men undergoing elective inguinal hernia repair a very detailed account of what might go wrong does not increase patient anxiety significantly and has the advantage of allowing patients a fully informed choice before they consent to surgery, thus reducing the potential for subsequent litigation.
Introduction
The NHS Management Executive's recent guidance on obtaining consent from patients is a pertinent reminder of the importance with which the government views our legal requirement to obtain fully informed consent from patients undergoing treatment.
In the unhappy event of litigation, a signed consent form may be disregarded by the courts unless it can be shown that the patient was ‘given sufficient information, in a way they can understand, about the proposed treatment.’
Sadly, the standards of consent actually achieved on the ward often fall short of those expected by lawyers, perhaps because the task of obtaining consent is left to more junior medical staff, who are themselves ignorant of many of the potential pitfalls that might face the patient.
It has been estimated that every year about 300 000 patients in the United Kingdom experience some form of harm as a result of being admitted to hospital, and if claims for medical negligence are to be minimised it is vitally important that doctors ensure that the patient has carefully considered the potential risks of any procedure as well as its likely benefits.
One solution is to adopt the North American practice of providing patients with a comprehensive list of postoperative complications, but to most British doctors the prospect of burdening patients with ‘unwanted’ information about what might go wrong is deemed to be both unhelpful and unkind.
In view of this dichotomy of opinion it is surprising that there is little, if any, objective evidence to support or refute the rather paternalistic British view that allowing patients to make a fully informed decision about their treatment would generate an unnecessary and harmful degree of anxiety.
The aim of this study was to find out who is really afraid of fully informed consent: British patients or their doctors?
Subjects and methods
Ninety six male patients admitted to four surgical wards for elective repair of inguinal hernias under general anaesthesia were interviewed in hospital on the day before surgery and asked to complete two self evaluation questionnaires: a screen for pre-existing anxiety or depressive states using the hospital anxiety and depression scale (HADS), in which patients were asked to score answers based on how they generally felt over the few weeks before admission, and an assessment of their current state of anxiety (Spielberger STAI-X1).
The Spielberger anxiety scale consists of twenty statements that gauge how respondents feel ‘right now , at this moment’ and has been widely evaluated in healthy American adults and in non-psychiatric hospital inpatients.
Subjects chose from one of four graded responses to each statement, generating a total score between 20 (low anxiety) and 80 (very high anxiety).
After this baseline assessment was obtained patients were randomly allocated one of two typed information sheets which contained a simple description of what a hernia is, why surgery was necessary, and what the operation entailed.
The difference between the two information sheets was that one provided a rather sketchy outline of possible postoperative complications (derived from a survey of what 10 house officers actually told hernia patients when they obtained consent), and the other contained a more comprehensive list (boxes).
To prevent patients on the same ward comparing the contents of different fact sheets (and thereby contaminating the data), randomisation depended on the ward and week of admission: forms used on a given ward were randomly alternated each week.
To standardise the manner in which information was presented by the investigator, patients were simply left to digest the written information for one hour, but they were given the opportunity to  clarify anything which they did not understand before their state of anxiety was reassessed by a second Spielberger questionnaire.
In addition to the in hospital assessment, we also wanted to know what the patients thought about the amount of information they were given, and to do this we administered a telephone questionnaire consisting of six questions about their inpatient experiences, one of which read ‘Was the amount of information you received before your operation too much, about right, or too little?’
statistical analysis
The significance of changes in anxiety noted was analysed by Student's paired t tests, and data from the telephone questionnaire were compared by a two tailed Fisher's exact test.
The relation between an individual's baseline anxiety and the change in anxiety observed after receiving information was examined by using scatter plots and by calculating the Pearson correlation coefficient as suggested by Bland and Altman (change in anxiety v average of first and second Spielberger scores).
We estimated that a change of five points in the Spielberger score might be clinically significant; to detect this with 95% power (assuming a standard deviation of 6) the required sample size was calculated to be 40–50 patients in each group.
Patients were simply told that we were aware that emotions could influence how they reacted to illness and were asked to participate in a survey investigating their response to hospital admission for minor surgery.
They were not aware that they were taking part in a randomised comparison of two different information sheets as this would have invalidated the study, which received ethical approval from the Royal Hallamshire Hospital ethical committee.
Results
Table I describes the general characteristics of the two groups studied.
Ninety six patients were randomised, with roughly equal numbers receiving each of the two information sheets.
The patients were well matched for age and preadmission state of anxiety and depression; the proportion of patients whose score on the hospital anxiety and depression scale was 10 or greater (a level that indicates clinically significant anxiety or depression states) was equal in each study group.
The change in anxiety invoked by reading about the potential complications of surgery is shown in table II.
There was no change in anxiety in the group who had received detailed information (p=0.20), whereas patients who received a rather superficial explanation of the risks were significantly less anxious afterwards (p=0.012), particularly if they had scored highly on the baseline anxiety assessment (fig 1; r=0.27, p=0.05).
There was no evidence to suggest that anxious patients who had been given detailed information  became more distressed afterwards (fig 2; r=0.18, p=0.23).
We were able to contact 72% (69/96) of patients after discharge from hospital.
Nearly one quarter (8/33) of those who had received the more comprehensive list of complications thought that they had been given ‘too much’ information, compared with just 6% (2/36) of those who had been given a simple explanation (p=0.04, Fisher's exact test): anxiety scores did not differ significantly between patients who thought the amount of information given was too much and those who thought it was ‘about right’(data not shown).
Only two patients thought that they had not been told enough, even though one of them had been given the very detailed sheet.
All 96 patients consented to surgery.
Discussion
The rate at which compensation claims are being lodged against medical practitioners may be escalating faster in the United Kingdom than in North America, and there are fears that if this trend continues unchecked the cost of litigation may ultimately damage the quality of healthcare by eroding already restrained budgets.
The defence societies constantly warn that most complaints are provoked by doctors failing to communicate adequately, so there is an argument for adopting the ‘defensive’ practice of our American colleagues when consent for treatment is sought: but do our patients have the stomach for an American approach?
In an attempt to answer this simple question we used a self administered questionnaire (Spielberger STAI-X1) designed to provide an objective index of anxiety at any given moment.
All of the findings we report are based on the assumption that this questionnaire can accurately and reproducibly detect a change in anxiety, even when the same questionnaire is administered twice with just one hour between each assessment.
In response to this concern Spielberger retested 197 students one hour after they had watched a stressful film depicting gory accidents and concluded that the questionnaire was indeed sensitive to acute changes in anxiety.
Our second assumption was that the information given to the patients was digested and understood.
There is evidence that at times of stress many patients do not absorb verbal information and that a better quality of informed consent can be obtained by combining oral and written information as we did.
To heighten comprehension, our information was presented using personal pronouns in deliberately short sentences that explained or avoided technical terms; awareness could be further enhanced by issuing the information sheets (customised for specific operations) during the initial outpatient consultation, which would give patients more time to assimilate the facts.
Our results suggest that it is wrong to assume that patients will become unduly anxious if they are warned about most of the potential risks of surgical treatment, at least as far as inguinal herniorrhaphy and general anaesthesia are concerned.
Whether or not the same applies to patients with cancer or those admitted for more complex surgery remains to be seen, but even major operations share many of the ‘frightening’ general risks associated with inguinal hernia repair.
Patients are entitled to receive accurate information about their treatment and the risks we ask them to take; they also have a right to withhold consent from such treatment if they feel unhappy about accepting these risks.
A full explanation of the facts allows them to make a fully informed decision about their surgery; this might reduce the number of cases of litigation arising from misunderstandings about the purpose and nature of any planned treatment.
Against this one has to balance the fact that a simple explanation of the common problems encountered seems to (statistically) reassure the patient, particularly the very anxious individual, although the overall effect was very small and probably clinically insignificant.
What is certain is that as the relationship between doctors and their patients becomes less paternalistic, so must the manner in which we seek to obtain their consent for treatment.
Simple information sheet
Complications of inguinal hernia repair
1
1 Pain and discomfort in the first few weeks after surgery.
You will be supplied with painkillers to help with this.
2
2 Recurrence of your hernia 
3
3 Problems with the anaesthetic .
Fortunately these are rare.
You will be seen by an anaesthetist before your operation.
He/she will decide on your fitness to receive the anaesthetic.
Detailed information sheet
Complications of inguinal hernia repair
1
1 Pain and discomfort in the first few weeks after surgery.
You will be supplied with painkillers to help with this.
It is common for some bruising to occur around the wound, base of the penis and testicles.
A serious wound infection occurs in 1 in every 100 patients (3 in 100 if the operation is for a recurrent hernia) and other wound problems such as a deep blood clot (haematoma ) or separation of the skin and underlying tissues can also occur.
Although wound discomfort is usually fairly short lived,nerve injury during the operation occurs after somewhere between 1 in 100 and 1 in 10 hernia operations and this can lead to more persistent or even permanent pain, discomfort or numbness over the groin, the base of the penis, and the upper part of the thigh.
2
2 A Recurrence of your hernia .
The chances of this happening for a single hernia (one side) vary from 1% to 7%, that is 1–7 patients in every hundred.
For a double hernia (both sides) the risk is 2–4%.
For a recurrent (re-do) hernia the chances are even higher (somewhere between a 1 in 20 and a 1 in 3 chance of future trouble).
3
3 Problems with the anaesthetic .
Fortunately these are rare.
You will be seen by an anaesthetist before your operation.
He/she will decide on your fitness to receive the anaesthetic.
Chest problems such as pneumonia and disorders of the heart rhythm and blood pressure are the most common serious problems associated with receiving an anaesthetic.
4
4 Temporary difficulty with passing urine after surgery occurs in about one third of hernia patients.
In some cases, this needs to be relieved by placing a drain (catheter) in the bladder for a few days.
Insertion of a catheter can cause injury to the passageway between the bladder and the penis.
5
5 Permanent damage to a testicle (either loss or permanent shrinkage) can occur in about 3 of every 200 patients undergoing a hernia repair.
In addition, the tube(s) carrying sperm from the testicle(s) to the penis might accidentally be cut, which could cause sterility .
6
6 Occasionally,injury to the intestine or other abdominal organs occurs.
This may require repair or removal of the damaged part.
7
7 Injury to the blood supply of the leg (major artery and vein), which if severe may result in heavy bleeding, blood clot formation or permanent leg swelling with possible skin ulceration .
In addition there are certain other complications which may occur after any operation.
These include deep vein thrombosis (a blood clot in the leg which may cause swelling, pain, and
pulmonary embolus , a blood clot on the lung producing breathing difficulty and possibly death).
Allergic reactions can occur to surgical dressings, cleansing agents, and antibiotics.
Inherited prion disease (PrP lysine 200) in Britain: two case reports
Abstract
Objective —
To identify cases of inherited prion diseases in Britain and to assess their phenotypic features.
Design —
Screening study of patients suspected clinically to have Creutzfeldt-Jakob disease and other neurodegenerative diseases by prion protein gene analysis.
Setting —
Biochemical research department.
Subjects —
Patients suspected to have Creutzfeldt-Jakob disease and other neurodegenerative diseases.
Results
Two patients with symptoms characteristic of sporadic Creutzfeldt-Jakob disease were found to have inherited prion protein disease (PrP lysine 200), with a mutation at codon 200 of the prion protein gene.
Both were homozygous at codon 129 of the gene.
One patient was a man aged 58 of British descent while the other was of Libyan Jewish origin.
Conclusion —
Two foci of inherited prion disease are known, among Libyan Jews and in Slovakia.
A separate British focus of the disease may also exist.
Heterozygosity at codon 129 may lead to reduced penetrance of the mutation.
Introduction
The human transmissible spongiform encephalopathies have been traditionally classified as Creutzfeldt-Jakob disease, Gerstmann-Sträussler syndrome, and kuru.
Although these disorders are transmissible, 15% of cases of Creutzfeldt-Jakob disease are familial and Gerstmann-Sträussler syndrome is usually familial.
Studies of genetic linkage have shown that familial Creutzfeldt-Jakob disease and Gerstmann-Sträussler syndrome are autosomal dominant conditions, and several mutations in the prion protein gene on chromosome 20p have now been identified in both conditions.
DNA diagnosis has shown that these conditions have a larger phenotypic range than previously realised.
They form part of a range of diseases now more logically termed inherited prion diseases, and a new nomenclature has been proposed.
A 100-fold excess incidence of Creutzfeldt-Jakob disease among Libyan Jews was previously attributed to their eating lightly cooked sheep's brain and eyeballs.
Both this cluster of disease and another cluster in Slovakia are now known to be genetic in origin and associated with a missense mutation at codon 200 of the prion protein gene causing substitution of lysine in place of glutamate at residue 200 of the prion protein (inherited prion disease (PrP lysine 200)).
In contrast to the other inherited prion diseases, this variant presents clinically like classic sporadic Creutzfeldt-Jakob disease, with a rapidly progressive dementia and myoclonus; pyramidal, cerebellar, or extrapyramidal signs; periodic complexes of 1–2 cycles/second in an electroencephalogram; and a short duration of disease (less than 12 months).
Histological examination uniformly shows the classic features of spongiform encephalopathies: spongiform change, astrocytic proliferation, and neuronal loss.
The relative phenotypic homogeneity of this disease may, however, be the result of selection bias, and now that a DNA marker is available more variability may become apparent, as is seen in the other inherited prion diseases.
Homozygotes for the mutation at codon 200 do not seem to differ clinically from heterozygotes, which indicates that inherited prion disease (PrP lysine 200) is a fully dominant disorder.
While screening patients suspected of having Creutzfeldt-Jakob disease and other presenile dementias for mutations in the prion protein gene we identified a British patient with inherited prion disease (PrP lysine 200), which suggests a further focus of this disorder.
Methods
DNA was extracted from peripheral blood with standard techniques.
The coding sequence of the prion protein gene was amplified by the polymerase chain reaction with synthetic oligonucleotide primers flanking the open reading frame.
Products of the chain reaction were fractionated by size in agarose gels to detect the presence of insertions or deletions.
The products were also immobilised on nylon membranes, and the presence of known point mutations or polymorphisms was assessed by sequential hybridisation with allele specific oligonucleotides labelled with phosphorus-32 as described previously.
Case reports
A 58 year old man was well until May 1989, when he noticed pain in the front of both shins radiating into the feet.
He became lethargic with poor concentration and intermittent unsteadiness.
He then developed a right homonymous inferior quadrantanopia.
Results of computed tomography and magnetic resonance imaging were normal.
He deteriorated and became agitated, intermittently confused, and unsteady with jerky movements.
On examination in August he was demented and ataxic with generalised myoclonus.
Routine blood investigations gave normal results; computed tomography showed mild generalised atrophy; electroencephalography showed irregular slow activity and occasional triphasic sharp transients; and cerebrospinal fluid was normal.
His dementia advanced rapidly, with further impairment of vision, and the myoclonus became more prominent.
He died in September 1989.
Histological examination of the brain (Professor L W Duchen) showed the characteristic changes of Creutzfeldt-Jakob disease: patchy spongiform changes in the cerebral hemispheres, particularly the occipital cortex, where there was considerable loss of nerve cells and astrocytosis; spongiform change in the basal ganglia and brain stem; and widespread fine vacuolations in the molecular layer of the cerebellar cortex with loss of Purkinje cells.
The patient's father had presented in 1976 at the age of 69 with rapidly progressive dementia associated with ataxia, myoclonus, and pseudoperiodic complexes on  electroencephalography .
He died three months after the onset of symptoms.
This man and his parents originated from the south of England.
He father died aged 72 from malignancy, and his mother died aged 99.
There was no history of neurological disease in preceding generations, nor any known Libyan Jewish or central European ancestry.
We also investigated a British patient of Libyan Jewish ancestry who presented with symptoms characteristic of Creutzfeldt-Jakob disease.
Results of histological examination of the brain were diagnostic of the disease.
Both patients described were heterozygous for the missense mutation at codon 200 of the prion protein gene.
No other pathogenic mutation (insertions or missense mutations at codons 102, 117, 178, 198, and 217) was present.
Both patients were homozygous for methionine at codon 129.
Discussion
We have identified a British family and a further patient of Libyan Jewish ancestry with inherited prion disease (PrP lysine 200).
The clinical presentation of those affected and the course of the disease were characteristic of sporadic Creutzfeldt-Jakob disease; the other inherited prion diseases so far described generally present as an illness similar to Gerstmann-Sträussler syndrome with a much longer duration or as atypical dementia.
The patient reported on in detail was of British origin with no evidence of either Libyan Jewish or central European ancestry, suggesting a separate, British focus of this disease.
Whether these three foci have a common origin or arise from different mutational events is unknown.
Interestingly, both patients reported on were homozygous for methionine at codon 129.
Homozygosity for either allele of this common polymorphism is associated with earlier onset of inherited disease and predisposes the person to sporadic Creutzfeldt-Jakob disease.
Some people from both the Libyan Jewish and Slovakian foci of inherited prion disease have been found to carry the mutation at codon 200 and yet remain unaffected at ages similar to or greater than the upper age at onset in most affected relatives.Such incomplete penetrance has not been reported in other types of inherited prion disease.
These carriers of non-penetrant or late onset genes may be heterozygous at codon 129 since heterozygosity at codon 129 might be expected to delay or protect against the onset of clinical disease.
Whether heterozygosity is protective could have an important bearing on genetic counselling in this disease now that presymptomatic detection of this and other mutations in the prion protein gene is possible.
Association of low birth weight with β cell function in the adult first degree relatives of non-insulin dependent diabetic subjects
Abstract
Objective —
To examine the relation between birth weight and β cell function in the first degree relatives of non-insulin dependent diabetic subjects.
Design —
Cross sectional study of 101 adults of known birth weight from 47 families which had at least one member with non-insulin dependent diabetes.
Subjects —
101 white adults aged mean 43 (SD 7) years.
Setting —
Oxfordshire, England.
Main outcome measures —
Glucose tolerance was measured by continuous infusion glucose tolerance test.
β cell function and insulin sensitivity calculated from the fasting plasma glucose and insulin concentrations with homeostasis model assessment.
β cell function was standardised to allow for the confounding effects of age and obesity.
Results —
Twenty seven subjects had non-insulin dependent diabetes, 32 had impaired glucose tolerance, and 42 were normoglycaemic.
Birth weight correlated with the β cell function of the complete cohort (r s =0.29, p=0.005), the non-insulin dependent diabetic subjects (r s =0.50, p=0.023), and the non-diabetic subjects (r s =0.29, p=0.013).
The non-insulin dependent diabetic (n=27) and the non-diabetic (n=74) subjects had similar mean (interquartile range) centile birth weight 50% (19%–91%), and 53% (30%–75%) respectively.
Non-insulin dependent diabetic subjects had significantly lower β function than the non-diabetic subjects: 69% (48%–83%)v 97% (86%–120%), p<0.001.
Conclusions —
The cause of the association between low birth weight and reduced β cell function in adult life is uncertain.
Impaired β cell function in non-insulin dependent diabetic subjects was not accounted for by low birth weight, and genetic or environmental factors are likely to be necessary for development of diabetes.
Introduction
Reduced growth in fetal life and infancy has been linked with an increased risk of developing impaired glucose tolerance in adult life.
Increased prevalence of hypertension and death rates from cardiovascular disease have also been reported in subjects with low birth weights.
The mechanisms which link low fetal and infant growth rates with disease in adult life are not defined.
Controversy exists about the relative importance of pancreatic β cell dysfunction and impaired insulin sensitivity in the genesis of impaired glucose tolerance and non-insulin dependent diabetes.
The relation of reduced growth in early life with subsequent β cell function and insulin sensitivity has not been examined.
One study has shown that subjects with lower weight at 1 year have higher plasma concentrations of 32–33 split proinsulin in adult life.
Intact proinsulin and 32–33 split proinsulin constitute a higher percentage of the total insulin and insulin precursor molecules in the plasma of fasting subjects with non-insulin dependent diabetes but this is of uncertain pathophysiological significance.
Non-insulin dependent diabetes has a familial distribution, with an increased prevalence of the disorder in the first degree relatives of affected subjects.
Diabetic subjects and their first degree relatives form a suitable population in which to examine the relation between birth weight and the development of impaired glucose tolerance and non-insulin dependent diabetes.
We studied 101 family members of 47 non-insulin dependent diabetic subjects to determine the relation of birth weight with β cell function and insulin sensitivity in adult life.
Subjects and methods
The protocol was approved by the central Oxford research and ethics committee, and informed consent was obtained from all participants.
We studied nuclear families in which at least one member had non-insulin dependent diabetes and in which both parents and their children were available for study.
Twenty one families were ascertained through a non-insulin dependent diabetic proband with both parents alive, and 29 families were ascertained through an older proband with non-insulin dependent diabetes and living spouse and children.
Siblings of diabetic probands with living parents together with the children of older probands form the subjects in this study.
Parents of the subjects had a glucose tolerance test (n=48) or had fasting plasma glucose and glycated haemoglobin concentrations measured (n=52).
The mothers were asked about the birth weight and gestational age of their children.
Three mothers did not know the children's birth weights; these mothers had one, two, and four children.
These children were excluded from the study, leaving 101 members of 47 families for study.
Birth weights had been recorded in pounds (2.2 lb=1 kg) and were converted to the nearest gram.
Gestational age was assessed as the last completed week of pregnancy.
The obstetric and neonatal charts were available for 29 members of the cohort.
The correlation coefficient between the reported birth weights and the birth weights recorded in these charts was r s =0.83 (p<0.001).
The mean age of subjects was 43 (SD 7) years.
Twenty six of the 101 subjects were known to have non-insulin dependent diabetes, and non-insulin dependent diabetes was newly diagnosed in one subject by the investigations of this study.
Seven of the 26 subjects known to have non-insulin dependent diabetes were receiving insulin, 13 were taking sulphonylureas, and six were taking a specific diet.
Body mass index was calculated as weight (kg) /(height (m)).
Blood pressure was measured with a COPAL UA251 electronic automatic auscultatory blood pressure reading machine (Surgleon Ltd, Brighouse, West Yorkshire).
A random zero sphygmomanometer with a large cuff was used for patients with an arm circumference greater than 33 cm.
None of the subjects had atrial fibrillation.
The readings were taken on the right arm of the seated subject after a minimum of 10 minutes' rest.
Three readings were obtained and the mean of the last two was recorded as the blood pressure.
Birth weight was expressed in centiles derived from the standards of Tanner and Thomson.
These standards give the distribution of birth weight in a standard population taking into account the length of gestation, sex, whether the child was firstborn, and maternal height.
The distribution was used to determine the appropriate centile group for each subject.
For example, subjects in the 50th centile group had a birth weight lying between the 49th and 50th centiles after the above factors had been taken into account.
Actual birth weights are also quoted.
The subjects had a continuous infusion glucose tolerance test.
Glucose was continuously infused at a rate of 5 mg/kg ideal weight/min for 60 minutes.
Ideal weight was determined from the Metropolitan Life Insurance tables for a medium frame.
Achieved plasma glucose and insulin concentrations were determined as the mean of the 50, 55, and 60 minute samples.
Six subjects did not consent to a glucose tolerance test and tolerance was determined from fasting plasma glucose and insulin concentrations.
Non-insulin dependent diabetes was defined according to the World Health Organisation fasting criteria.
Impaired glucose tolerance was defined as a fasting or achieved plasma glucose concentration more than 2 SD above the mean concentration of a non-diabetic population matched for age and weight.
The reproducibility, sensitivity, and specificity of the continuous infusion glucose tolerance test have been reported.
We measured plasma glucose concentration with a hexokinase method using a centrifugal analyser.
Plasma insulin concentration was measured in duplicate by radioimmunoassay with a charcoal absorption step to separate bound from free insulin; Novo Human MC Insulin was used as the standard (Novo Research Laboratories, Bagsvaerd, Denmark) and Wellcome RD 10 guinea pig antiporcine insulin antiserum (Wellcome Research Laboratories, Beckenham, Kent) and insulin labelled with iodine-125 (Amersham International, Amersham, Buckinghamshire) as tracer.
Between assay coefficient of variation for duplicates was 12.9% at 8 mU/l (n=89) and 9.9% at 28 mU/l (n=16).
Intra-assay coefficient of variation was <10% in the range encountered in this study.
statistical analyses
The fasting plasma glucose and insulin concentrations were interpreted by homeostasis model assessment to assess β cell function and insulin sensitivity.
This method uses a mathematical model of the body's glucose and insulin interactions as a frame of reference.
The major feedback loops are stimulation of insulin secretion by glucose and reduction of hepatic glucose output and increase in uptake of glucose into muscles by insulin.
Different degrees of insulin resistance and impaired β cell function can be introduced into the model, and for each combination the homeostatic fasting plasma glucose and insulin results achieved by the feedback loops are calculated.
Each patient's fasting plasma glucose and insulin measurements can be interpreted by the model to predict the β cell function and insulin sensitivity that are likely to have given those measurements.
The seven diabetic subjects receiving insulin were excluded from the correlation analyses with these variables.
β cell function and insulin sensitivity are expressed as centile groups defined relative to a non-diabetic population aged below 35 years and weighing less than 115% of ideal weight.
β cell function and insulin sensitivity measured by homeostatic model assessment have been shown to correlate with measures obtained by hyperglycaemic clamp and euglycaemic clamp.
To allow for the confounding effects of age and obesity on β cell function we calculated the standardised residual β cell function with respect to the regression of β cell function with age and obesity in a population of 104 non-diabetic people (age 21–76 years, percentage of ideal weight 86%-158%).
This is termed standardised β cell function.
Variables are expressed as mean (SD) or as median and interquartile range.
Groups were compared with the Mann-Whitney U test.
Correlations between variables were examined with Spearman's rank correlation coefficients.
Results
Of the 101 subjects, 27 had non-insulin dependent diabetes, 32 had impaired glucose tolerance, and 42 were normoglycaemic (table).
No significant differences were found in birth weight between the non-insulin dependent diabetic subjects, those with impaired glucose tolerance, and the normoglycaemic subjects.
There was no significant difference between the birth weight of diabetic subjects not receiving insulin (3.39+-(0.58) kg, n=20) and the birth weight of those with impaired glucose tolerance and with normoglycaemia.
The diabetic subjects not receiving insulin had significantly lower β cell function (median 69%) than the subjects with impaired glucose tolerance (median 96%, p<0.001) and the subjects with normoglycaemia (median 98%, p<0.001).
Centile group for birth weight was correlated with the standardised β cell function of the complete cohort (r s =0.29, p=0.005)(fig 1).
The correlation was significant in both non-insulin dependent diabetic subjects (r s =0.50, p=0.023) and the non-diabetic subjects (r s =0.29, p=0.013) when these groups were considered separately.
The correlation was significant in the 29 subjects whose birth weights were validated from the obstetric and neonatal charts (r s =0.43, p=0.019).
Analysis of birth weight in kilograms rather than by centiles did not affect these correlations, the absolute value for the whole cohort correlating with the standardised β cell function (r s =0.28 (p=0.007).
No significant correlation was found between centile group for birth weight and insulin sensitivity (fig 2), body mass index, fasting plasma glucose concentration, or blood pressure.
These findings were unchanged when the non-insulin dependent diabetic subjects were excluded from the analyses.
The possible influence of maternal hyperglycaemia was assessed by analysing separately the 55 subjects who had a normoglycaemic mother and the 46 subjects who had a mother with non-insulin dependent diabetes  or impaired glucose tolerance.
The correlation coefficient between centile group for birth weight and standardised β cell function for the offspring of the normoglycaemic mothers was r s =42 (p=0.015).
The correlation did not reach significance in the offspring of the hyperglycaemic mothers.
When the offspring of the normoglycaemic mothers were considered separately, there was no significant difference in birth weight between the 22 offspring who were normoglycaemic, the 11 who had impaired glucose tolerance, and the 22 who developed diabetes (3.44 (0.40), 3.39 (0.47), and 3.39 (0.63) kg, respectively).
When the offspring of the hyperglycaemic mothers were considered separately, there was no significant difference in birth weight between the 20 offspring who were normoglycaemic, the 21 who had impaired glucose tolerance, and the five who developed diabetes (3.59 (0.49), 3.47 (0.40), 3.74 (0.54) kg respectively).
Discussion
We found that birth weight in first degree relatives of non-insulin dependent diabetic subjects correlated with the β cell function at mean age 43 years.
This is compatible with the hypothesis that prenatal nutrition affects subsequent pancreatic function.
Gestational age, birth order, sex, and maternal height all affect birth weight.
The birthweight standards of Tanner and Thomson describe weight for gestation.
Boys and girls are considered separately, as are firstborn and later children.
Adjustment scales are available for maternal height.
Birthweight data are expressed according to centile groups from these standards.
We gave centile group for birthweight data to avoid confounding from gestational age, birth order, sex, and maternal height.
When birth weights are standardised for these variables the social class gradient disappears.
Analysis of absolute birth weight in kilograms did not affect the reported relations.
We asked mothers the birth weights of their children and validated the reports of a subset from the obstetric and neonatal charts.
The close correlation between the data obtained from these two sources suggests that recall error is unlikely to be a confounding factor.
This conclusion is supported by the significant correlation observed between birth weight and β cell function in the subjects with validated birthweight data.
Although interobserver error and the different weighing devices used to weigh infants might have caused variability in the data, the association between birth weight and adult β cell function was significant at the 1% level.
The association therefore seems to be robust.
explaining the association
The mechanisms which link low birth weight with reduced β cell function in later life are unknown.
Much of the development of the islets of Langerhans occurs in utero and β cell mass increases more than 130-fold between the 12th intrauterine week and the fifth postnatal month.
Infants who are small for dates have fewer β cells, and non-insulin dependent diabetes is associated with a moderate reduction of β cells.
Two hypotheses need to be considered.
The first is that of Hales et al,who suggested that nutritional factors determining fetal and infant growth influence the size of vascularity of the adult pancreatic β cells.
Impaired glucose tolerance could then develop in adult life, especially when accompanied by the development of impaired insulin sensitivity from obesity, physical inactivity, or aging.
An alternative hypothesis is that lower birth weight results from the phenotypic expression of a genetic β cell defect associated with reduced fetal insulin secretion and reduced anabolic activity in utero.
Mutations in the glucokinase gene in subjects with maturity onset diabetes of the young are associated with impaired β cell function but affected members of one pedigree who had a missense mutation in the glucokinase gene had normal birth weights (R C L Page et al , unpublished data).
Thus no evidence to support this alternative hypothesis is available.
The association between birth weight and β cell function was not significant in the offspring of mothers with hyperglycaemia, possibly because of the confounding effect of maternal hyperglycaemia during pregnancy.
The possibility that non-insulin dependent diabetes in the mother impairs fetal growth thus seems unlikely to account for the association between low birth weight and reduced β cell function.
The non-insulin dependent diabetic subjects had similar birth weight to subjects with normoglycaemia or impaired glucose tolerance.
No significant differences were seen between these three groups when the offspring of hyperglycaemic and normoglycaemic mothers were considered separately.
The non-insulin dependent diabetic offspring had a considerably reduced β cell function, even though 13 of these subjects were taking sulphonylureas, which increase β cell function about twofold.
No information was available on placental size or other indicators of in utero nutrition, and subnormal prenatal nutrition of those who subsequently became diabetic cannot be excluded.
Our results pertain to a sample of 101 subjects, in many of whom the birth weight was obtained by maternal recall.
Nevertheless, the lack of association between reduced birth weight and the subsequent development of diabetes suggests that defects of β cell function, in addition to that which may be induced by malnutrition in utero, are probably required for the development of non-insulin dependent diabetes.
In contrast to a previous report, we found no significant inverse relations between birth weight and blood pressure.
The absence of this association might be due to the smaller number of subjects in our study.
Retarded intrauterine growth has been proposed as the link between hypertension and diabetes, but our data provide no evidence to support this hypothesis.
In conclusion, low birth weight in first degree relatives of non-insulin dependent diabetic subjects was associated with reduced β cell function at mean age 43 years.
Impaired nutrition in utero may play a part in reducing adult β cell function.
However, additional genetic or environmental factors leading to more severely impaired β cell function are likely to be necessary for the development of non-insulin dependent diabetes.
Effect of using safer blood products on prevalence of HIV infection in haemophilic Canadians
Concentrates of clotting factors VIII and IX transmitted HIV to many haemophilic patients during the early 1980s.
In Canada all blood products are distributed by the Canadian Red Cross Blood Transfusion Service.
Products that had been heat treated to inactivate HIV were introduced in July 1985 and all untreated products were recalled.
This study was carried out to determine the number of haemophilic patients seropositive for HIV antibodies and the mortality from HIV infection and to confirm that young children were not being exposed to the virus.
Methods and results
The data were obtained from the Canadian Hemophilia Registry.
This was updated to include data collected up to December 1991 and the results of testing patients for HIV antibodies.
Deaths due to HIV infection have been recorded prospectively since 1988.
Deaths occurring before 1988 were collected retrospectively and were validated by reports from the Federal Centre for AIDS.
Haemophilia was graded as severe if the patient's concentration of coagulation factor was <0.01 of the normal value, moderate if it was 0.01–0.05, or mild if it was >0.05.
At the end of the survey the number of registered haemophilic patients was 1818, and 1584 were tested for HIV antibodies.
Untested patients were either inaccessible or unwilling to be tested but all were alive.
Altogether 617 (97%) of the 634 patients with severe haemophilia, 330 (95%) of the 349 with moderate haemophilia, and 637 (76%) of the 835 with mild haemophilia were tested.
A total of 484 (31%) were positive for HIV antibodies.
The prevalence increased with the severity of haemophilia and was higher in patients with factor VIII deficiency.
Among those with factor VIII deficiency the proportions with HIV antibodies were 323/534 (60%), 74/208 (36%), and 57/539 (11%) for those with severe, moderate, and mild haemophilia respectively.
Among those with factor IX deficiency the proportions with HIV antibodies were 19/83 (23%), 10/122 (8%), and 1/98 (1%) respectively.
The highest prevalence (82%) was in those with severe factor VIII deficiency who were over 10 years old.
The table shows the prevalence of HIV antibodies according to age.
No children aged 0–4 were seropositive; this zero prevalence was significantly lower than the prevalence of 4.8% in the next age group (p=0.029, Fisher's exact test, one tailed).
None of the 120 children aged under 6 who were tested were seropositive but the true prevalence could be as high as 2.5% (the upper limit of the 95% confidence interval).
The number of haemophilic patients dying due to infection with HIV for each year from 1980 to 1991 was 1, 0, 0, 1, 0, 1, 4, 8, 14, 20, 24, and 35.
The total number of people infected with HIV has therefore been 592 (108 dead and 484 alive).
Comment
The very low prevalence of seropositivity for HIV antibodies in children aged under 6 is encouraging since these children will have received only blood products that had been treated to inactivate HIV.
A previous survey, similar in methodology to ours, used data collected in the United Kingdom up to August 1985, before virally inactivated concentrates were introduced.
Fifteen percent of those aged under 5, 22% of those aged 5–9, and 41% of those aged 10 and over were seropositive compared with 0%, 5%, and 37% in this study.
The relative risk of being seropositive in the British study compared with age peers in our study is infinite for 0–4 year olds, 4.6 for 5–9 year olds, and only 1.1 for subjects aged 10 or over.
These relative risks are significantly different (p<0.0001, Mantel-Haenszel test of homogeneity) among the three age groups, indicating that the protective effect of viral inactivation is greater in the younger age groups.
Time of presentation, time of operation, and unnecessary appendicectomy
The correct diagnosis of acute appendicitis depends on clinical acumen and experience.
Our aim in this study was to establish whether the rate of unnecessary operations and the rate of complicated appendicitis among patients undergoing surgery for suspected acute appendicitis were related to the time of presentation to hospital and the delay between presentation and surgery.
Patients, methods, and results
We reviewed the case notes of 578 of the 587 patients who underwent emergency surgery for suspected appendicitis between 1 January 1986 and 31 December 1990.
The time of presentation (from computer generated accident and emergency sheets), time of operation (from the anaesthetic record), delay to surgery (calculated from the above), and final diagnosis (based on independent histopathological examination) were recorded.
An unnecessary operation was deemed to be one that was performed without pathological evidence of surgically remediable disease.
Complicated appendicitis was defined as appendicitis with histopathological evidence of perforation or gangrenous change.
Altogether 347 patients had uncomplicated appendicitis, 73 had complicated appendicitis, 14 had other surgical disease requiring operation, and 144 had an unnecessary operation.
There was no significant relation between the time from presentation to operation and the proportions of patients with complicated appendicitis and of unnecessary operations, although 39% of operations performed within two hours of presentation were unnecessary.
Patients who presented between midnight and 6 am had a higher rate of unnecessary operations (30/83, 36%) than those who presented at other times (χ 2 , p<0.05): 21/118 (18%) presenting between 6 am and noon, 50/192 (26%) presenting between noon and 6 pm, and 43/185 (23%) presenting between 6 pm and midnight.
The rate of unnecessary operations in patients who presented between midnight and 6 am was highest in those who underwent surgery within three hours (18/39, 46%)(table).
Patients who were operated on between midnight and 6 am also had an increased rate of unnecessary operations (39/125, 31%).
There was no relation between the rate of complicated appendicitis and time of presentation (six (7%) patients presenting between midnight and 6 am had complicated appendicitis, 13 (11%) presenting between 6 am and noon, 33 (17%) presenting between noon and 6 pm, and 21 (11%) presenting between 6 pm and midnight) or time of operation.
Comment
Our study reinforces the report of the National Confidential Enquiry into Perioperative Deaths, which emphasised the dangers of inexperienced surgeons making major clinical decisions at night without advice from more senior staff.
The difficulty in deciding when to operate for suspected acute appendicitis is balancing waiting for firmer clinical signs against possibly increasing the risk of perforation of the appendix and gangrene.
Our study shows an increased proportion of unnecessary operations among patients presenting in the early hours but no relation between the proportion of complicated appendicitis and time of presentation.
The proportion of unnecessary operations decreased with increasing time between presentation and operation with no increase in the proportion of complicated appendicitis.
At night, when faced with a choice between an unnecessary operation and repeated clinical review with the possibility of a perforated appendix later, junior doctors seem to prefer an uninflamed appendix as the lesser of two evils.
This may be due to eagerness to get to bed or to various other factors including lack of sleep, worry about contacting more senior surgical staff, lack of proper training or control by senior staff, and pressure not to leave matters that may interrupt the next day's elective list.
In conclusion, the decision to operate for suspected acute appendicitis should not be made hastily in the small hours of the morning.
Unless the diagnosis is clear the patient should be placed under active clinical review and the advice of more senior colleagues sought.
GENERAL PRACTICE
General practitioners in partnership with management: an organisational model for debate
The role of general practitioners is changing and expanding.
Doctors have more control over the treatment received by their patients but remain largely unaccountable to the public and management.
This article proposes an organisational model for integrating primary and secondary care which retains the advantages of fundholding while giving management control over overall strategy.
It proposes that general practitioners control funds for all primary and secondary care.
Secondary care will be contracted through a joint team of managers and an elected general practice executive committee.
A new health care purchasing authority will contract for primary services with individual practices or primary care provider units.
General practitioners will have local contracts reflecting their desire to provide an expanded range of services and the needs of the community.
Can general practitioners exchange the illusion of clinical freedom for the reality of effective power?
The introduction of the internal market into the NHS has implications for the roles of and relationships between doctors and managers.
General practitioners have gained influence over the care their patients receive through the fundholding scheme and through their influence on health authority purchasers.
These and other factors (box) are changing the role of general practitioners and an opportunity exists to expand the function of primary care.
If general practitioners are to be effective in this expanded role an organisational framework is needed to integrate primary care into the wider health service.
Integrating primary care into the contracting framework of the health service will have advantages for patients, doctors, and managers but general practitioners could see it as a threat to independence rather than an end to isolation.
A partnership needs to be established between doctors and management with both controlling resources so that they are interdependent.
Presenting problems
Historically general practice has been largely independent of the rest of the health service, but this independence is now restricting its influence over the remodelling of the health service into a purchaser and provider system.
The general practitioners contract concentrates on the structure of care rather than on its process or outcome.
Family health services authorities therefore have no effective managerial influence over general practitioners, resulting in a bureaucratic relationship concerned with regulation rather than a partnership devoted to improving patient care.
The national contract also makes it difficult to tackle variation in the quality of primary care so that populations with the greatest need too often receive the worst quality care.
Overall the present arrangements are messy and are causing tension, fragmentation, and confusion between general practitioners' roles in purchasing and provision.
Management's need for accountability is not satisfied and doctors are uncertain about the balance between their clinical and managerial roles.
The relationship between general practitioners and district health authorities needs to be explicitly recognised as one of mutual dependence rather than competition.
Goodwill can permit effective cooperation for purchasing of secondary care but goodwill is ephemeral when difficult decisions have to be made.
Accountability
General practitioners are accountable to their patients, their peers, and family health services authorities for performance against their contract.
The expanding role of general practitioners, along with the 1990 contract, the establishment of family health services authorities, and the introduction of medical audit have increased accountability, but general practitioners have been demotivated by the imposition of a contract that increased their administrative burden without clear evidence of clinical benefit.
Nevertheless, society will no longer accept that a self governing profession can be unaccountable for its exercise of power and its use of resources.
Increased accountability is being demanded of all public services.
Self regulation through medical audit, postgraduate education, and possibly professional reaccreditation are only a partial answer because they give no input to consumer or management.
Cooperation between general practitioners and district health authorities requires mutual accountability.
The authority should be accountable to general practitioners for its purchasing performance and general practitioners should be accountable for the purchasing plans they advocate.
Neither the authority nor general practitioners can be efficient purchasers in isolation — they need each other 's skills and experience.
Fundholding only a partial solution
Early experience with the fundholding scheme has shown that general practitioners can be effective purchasers of care.
Their success has resulted from:
Redefining and reinforcing their relationship with consultants
Finding spare provider capacity and moving appropriate volumes of work to those areas
Combining direct knowledge of the needs of patients and of the capabilities of providers
Using negotiating skills, developed in the consulting room, to make providers address quality issues which general practitioners have previously been unable to influence.
Any new model must preserve these very real advantages.
None the less continued expansion of fundholding will lead to excessive management costs, difficulties of coordination in contracting between growing numbers of purchasers, and lack of effectiveness.
The quality of primary care teams varies greatly and the success in motivated practices who have opted for fundholding cannot be extrapolated too far.
Similarly, general practitioners are unlikely to have the management resources to contract for the full range of services required by a local population.
Expansion of fundholding would not allow for representation of other professional and lay groups in the purchasing process, and would be difficult for family health services authorities to monitor and manage.
In short universal fundholding would give too much power to general practitioners and deny effective management of the health service.
A new partnership
We propose a model for organisation of health services that defines a different relationship between general practitioners and NHS management (figure).
The model is an extension of those discussed by Foster.
The principles behind the model are firstly, that management's objective is to commission or provide effective, efficient services to meet the needs of the community it serves within finite resources.
Secondly, management does not have all the knowledge required to determine how to meet its objective.
Thirdly, management should be accountable to the population and to central government for its performance.
Fourthly, general practitioners are the most logical agent of the patients' demands.
Fifthly, general practitioners should be accountable to both patients and management for the process and outcome of the care they provide.
Sixthly, general practitioners need to keep their independent contractor status to maintain the trust between doctor and patient, and, finally, family doctors must accept a reconciliation between their long term relationship with the individual patient and the needs of the wider community.
The model requires a new integrated health care purchasing authority with integrated budgets, separation of purchasing and provision in primary care, local contracting with general practice, establishment of a general practice executive committee, and purchasing of secondary care by a joint team representing general practitioners and management, each controlling resources.
How the model will work
Funds will flow through primary care to secondary care.
General practices will control funds for all health care except tertiary care and contingencies and will contract for secondary care services through a partnership between management and the general practice executive committee.
The budgets for primary and secondary care will need to be integrated to permit appropriate transfer of resources.
This change would open up a new potential for managers and doctors to invest in shared programmes.
Such integration is even more important when money is limited.
It seems likely that in the next few years funding will be increased minimally and competition will also grow.
Shifting funds to primary care under the existing system will create some new opportunities, but only if general practitioners succeed in relating to a new managed system.
Our model will also allow practices to contract for new services to meet local needs.
general practice executive committee
This elected committee will have some similarities to the local medical committee and could evolve from it.
A committee of 10–12 doctors, each representing a constituency of 20–30000, should be sufficient to service the committee's obligations.
It would need management resources, and some members would have to reduce their commitment to general medical services.
As with fundholding the committees' responsibilities would include collection and analysis of information, assessment of needs, service specification, negotiation and monitoring of contracts, all of which would be carried out in partnership with the purchasing authority.
Central funding of the committee will release resources currently dedicated to managing fundholding.
health care purchasing authority
The authority, formed by merging the commissioning functions of the family health services authority and the district health authority, will contract with primary care for defined services — general medical, community nursing, chiropody, family planning, etc.
The authority will assess the community's health needs and reflect national and regional priorities.
The authority will be able to direct resources to meet its own priorities for service development.
Control of prescribing budgets will be important for effective operation of our model.
The authority, in agreement with individual practices, will be able to transfer resources from and to prescribing.
This ability is a major incentive within fundholding.
Primary care contracts will be monitored by the purchasing authority and could include medical audit  and reaccreditation in the future.
The authority will need to involve local consultants and general practitioners from outside the district in audit and reaccreditation.
primary care provider unit
This unit or trust will be formed from the provider arms of the current community unit and family health services authority.
The unit will contract for community services with the purchasing authority or general practice executive committee team or with individual practices or the private sector.
Some competition for the provision of primary care and community services will therefore be introduced.
primary health care teams
General practitioners and primary health care teams will negotiate a contract with the purchaser and provide services under the contract.
Not all practices will want to contract for an expanded range of services and local circumstances will also affect contracting decisions.
The purchaser may contract with the primary care provider unit instead of primary care teams.
Primary care teams will manage their own budget for staff, prescribing, general medical services, etc, and be accountable to the purchaser for their performance.
The model envisages that a regional management tier will have an important role in strategy development, monitoring, and accountability.
Consequences of the model
The model will give general practitioners the enhanced influence, powers, and responsibilities of fundholders without the administrative burden.
They will have a flexible local contract focusing on the needs of their patients.
Doctors elected to the general practice executive committee will have additional purchasing responsibilities.
Flexible contracting will increase accountability to management and make management sensitive to the needs of patients.
Integration of primary and secondary care is central to an internal market driven by primary care and should encourage a needs led rather than a service dominated approach.
Under our model contracting may cause difficulties with dispensing, deputising, partnership agreements, profitability, and investment in premises.
Arbitration will be needed to prevent exploitation by the purchasing authority.
The national contract has had many successes and there is a danger these could be threatened by fragmentation.
The model requires that general practitioners and managers develop new skills particularly in contracting.
The evidence that contracting is an efficient mechanism in the NHS is still limited.
General practitioners will be concerned that purchasing pressures will disturb the doctor-patient relationship, and doctors' perception of their role as the patient's friend and ally.
Conclusions
Our model is one possible means of enhancing the benefits of the NHS reforms while minimising some of the problems of fragmentation.
The model gives a clear role to general practitioners, reduces their administrative burden, and will stimulate the development of primary care services.
A strong contracting framework will be coordinated right across the NHS, balancing the increased responsibilities and power of general practitioners and their accountability for the outcome of the care they provide.
Factors affecting general practitioners' role
External forces:
Devolution of care
Consumerism
Professional accountability
Community care
General management
Internal pressures:
Vocational training
1990 contract
Fundholding
Medical audit
Role uncertainty
The Future of FHSAs
FHSAs and prescribing This is the fifth and final article in a series of articles on the future of family health services authorities
Prescribing by general practitioners cost the NHS £2.3 billion in 1991 — the biggest single cost after staffing — and the drug bill is now rising at 11% a year.
Family health services authorities and their professional advisers are charged with the challenging task of ‘improving the quality and cost effectiveness of prescribing,’ but any consideration of prescribing costs requires an understanding of how they are affected by factors outside the family health services authority's control.
These include price regulation by the government; differential pricing between hospitals and the community; the use of generic and branded products; and the prescription charge, which conceals from the general public the true cost of medicines.
Containing costs
In most developed countries the pharmaceutical industry is an important part of the economy and its products contribute directly to health gain.
Governments, which are purchasers, are faced with the dilemma of safeguarding the benefits while containing the price of drugs.
The ability to develop new drugs is now greater than most countries' ability to pay for them without rationing or screening systems — for example, France controls individual prices and Germany has initiated a reference system which pays a basic price for all drugs in the same category.
In Great Britain the government's control system is the prescription pricing regulation scheme, a voluntary agreement between the industry and the government that agrees profitability on NHS business.
A measure of the scheme's effectiveness is that the United Kingdom has the fifth highest drug prices in Europe (about where we should expect to be).
The industry recognises the pressures to contain costs and knows that it must concentrate on developing clearly better products, work towards European standardisation of prices, and  accept the generic market in return for an extended patent period.
FHSAs have an important role in improving the standards of prescribing and dispensing
Hospitals are given large discounts on drugs to encourage consultants to use and endorse them.
Such discounts can mean the price is many times lower for the branded drug than for the generic drug and consultants may be unaware of the price in the community.
The good business outcome of this policy for the pharmaceutical industry is evident in a recent survey in which four out of five general practitioners claimed to follow the hospital prescription on patient discharge.
Drugs are expensive in primary care, not normally because of the unit cost, but because many patients take them for many years.
Thus hospital recommendations, based on discounted prices, can result in high cost commitments for primary care.
Generic substitution is common in hospitals, but only two out of five prescriptions are written generically in primary care.
The percentage of generic prescribing could be increased if legislation allowed the prescriber to ‘tick the box’ for the generic equivalent or, as in North America, the pharmacist could, with proper safeguards, offer the generic drug as an option.
An incentive in the United Kingdom could be to reduce the prescription charge by, say, 50p if the patient selected the generic option.
Most European countries have a copayment system for medicines, but in the United Kingdom patients are unaware of drug costs and only 22% pay prescription charges.
Ways of informing them would be to put the price on the pharmacist's label and make financial need the only basis for exemption from prescription charges: more patients would pay the charges (which could have an annual ceiling) but the unit payment could be reduced.
Improving prescribing
None the less real improvements could be made in prescribing, and fundholders have shown savings.
Drugs are a science based industry's problem solving approach to health care and should be seen in that context.
Prescribing is one possible treatment option; others include counselling, educating patients on self limiting illnesses, and changes in lifestyle to improve health.
Better definition of expected health gain, treatment goals, and outcome measures for drug treatment would reduce unnecessary prescribing; provide safer treatment; and ensure that drugs are used appropriately.
Family health services authorities have a key role in helping general practitioners to achieve these outcomes.
All family health services authorities are funded equally to purchase professional advice on prescribing, but evaluation of the success of medical advisers has been impeded by a variety of changes that have affected prescribing.
These include specialist drugs, such as erythropoietin and growth hormone, being moved from hospital to primary care, mostly because hospitals are cash limited and primary care budgets are not.
Health promotion clinics are diagnosing and treating disease — sometimes with drugs.
Finally, doctors planning to become fundholders may not have worked assiduously to control prescribing in the knowledge that their budgets will be based on historical costs.
The outcome of these changes is that the drug bill is rising faster than it has for some years and above the rate of inflation.
Three models of good practice have emerged.
In the first, medical advisers with a reasonable workload have developed good relationships with practices and are now well placed to advise on prescribing.
In the second, medical advisers have acted as diagnosticians to determine the needs and concerns of each practice and to identify those where prescribing is an issue; pharmaceutical advisers then visit and offer help.
In the third, medical advisers have developed a management role in the family health services authority, addressed wider health strategy, and planned practice development; pharmaceutical advisers have led in all aspects of prescribing, involving the medical adviser only when the issue is whether to prescribe rather than what to prescribe.
The NHS Management Executive has now created a prescribing team, one of whose first actions has been to require that prescribing is a priority for medical advisers.
This has required some family health services authorities to reconsider wider roles, to focus medical advice on prescribing, and to agree targeted savings.
Prescribing analysis and cost data are a computer record of all general practitioner prescribing and provide an excellent research base to investigate changes in prescribing, trends, and the health gain and cost implications.
As data are available on individual drugs and the doctor ordering them, professional advisers can use them to inform their visits to apparent high and low cost prescribers and to make recommendations for change.
Key ways in which they have worked to lower costs are in reducing the prescribing rate (which is often high in poorer areas); increasing generic prescribing by informing people of the savings, addressing concerns, and, in the west midlands, offering laboratory analysis if patients believe there to be a difference in symptom control; and providing draft formularies and guidance on their management.
‘Underprescribers’ may be simply prudent prescribers but may also not be informed on the latest thinking on the benefits of drug treatment.
They can be helped to improve the quality of their prescribing by drug treatment protocols, formularies including newer drugs, and targeted drug information.
Prescribing at the interface
Professional advisers can help general practitioners to determine their requirements for prescribing at the primary and secondary care interface and ensure that purchasers include these criteria in contracts.
These requirements include the development, jointly with hospital consultants, of drug treatment protocols for consistency of clinical management, specific policies — for example, on the use of antibiotics — and shared care  protocols for new drugs they are asked to prescribe.
Professional advisers who are members of drug and therapeutic committees can ensure that primary care concerns are heard and addressed and that they are informed of any changes in hospital prescribing that affect them.
A development of this will be to agree appropriate drug treatment when patients are in hospital to ensure we do not recreate the difference in drug policies shown between United States acute care and veterans hospitals.
Problems in prescribing at the interface present a strong case for commissioning agencies that would consider drug purchasing across both care sectors.
Meanwhile professional advisers, both directly and through their managers, address changes that affect prescribing in primary care with regional health authorities, purchasers, and providers; among these changes will be better information systems between secondary and primary care so that patients being discharged into the community have their medicines available and that ‘at risk’ patients are identified: pharmaceutical services must follow the patient.
Evaluation of the cost effectiveness of drug treatment is in its infancy, and health economics can inform the debate.
General practitioners need such information in a more relevant form, related to current patient needs and gains.
Family health services authority advisers are well placed to develop this research area, to evaluate drug use, and to facilitate local work by general practitioners on targeted areas.
Prescribing in general practice
All non-fundholding practices have indicative prescribing amounts set and monitored by professional advisers.
The amounts are primarily derived from historical practice data, with new weightings for age and sex and a formula that includes an ‘uplift factor.’
The system to date has lost credibility among general practitioners since the uplift factors proved inaccurate and the predicted outturns erratic.
The latest development is that each region has a prescribing budget for all prescribers, which will require development in a meaningful way with prescribing norms.
Practice specific work includes analysis of prescribing and visits to understand the reasons for apparent over- and under-prescribing.
Prescribing analysis and cost data offer valuable insights into practice indicators of prescribing that are worthy of further investigation (box).
Regional drug information centres inform professional advisers on new drugs and their likely cost implications.
They also provide unbiased information on how new products compare with the range, give cost comparison charts, and draft shared care protocols for development and agreement with consultants and general practitioners.
Practice visits have resulted in identifying training needs, the need for (and writing of) policies to improve the quality of prescribing, and the development of drug use analysis, including all of the cost implications.
Will budgets be cash limited?
Fundholders already have cash limited budgets.
In the west midlands 26 fundholders made a combined saving of over £1m on their drug bill: the ability to retain the savings for practice development seems to have provided a strong incentive.
Early assessments indicate that fundholding has been a success in enabling practices to manage their budgets and develop patient services in the way it chooses.
If confirmed, these outcomes are likely to make fundholding the norm provided that the Treasury continues to allow health ministers this method of resource management.
Since the general election the move to fundholding has been dramatic and the suggestion that cash limiting will apply to all practitioners will fuel this trend.
It is, of course, too early to judge whether fundholding has improved the quality of prescribing, and research on this is urgently needed.
More practices might consider a prescribing contract alone if they were allowed to retain a percentage of the savings.
These could be monitored against referral rates if each family health services authority had a minimum contract dataset (all of the necessary contract data) for all patients.
Another management system could be to calculate the modest savings achievable by practices or locally based groups of practices and to pay this sum to those who achieve the target.
Finally, treatment protocols could each be delivered as an item of service — a logical step from payment for health promotion clinics which diagnose disease.
All would have to allow agreed improved prescribing costs to be added.
Local incentive schemes are the most likely way of getting general practitioners to change prescribing habits by ensuring that they see the benefits retained in local health care.
Until then, talk of cash limited budgets will only add to general practitioners' sense of being required to make too many changes too quickly.
Will expensive specialist prescribing require health rationing?
Health economists regularly forecast rationing of expensive drugs: an easy target since their costs — and the patients receiving them — are readily identifiable.
‘Shared care’ high cost drugs are, however, a very small part of the primary care drug bill — less than 1% in the west midlands in 1991.
All high cost drugs are already rationed in hospitals through drug and therapeutics committees and clinical pharmacy services.
Best practice screening before a drug is used includes:
Appraisal of current prescribing practice and identification of the likely benefits, and of the risk in not introducing the product
An estimate of the cost to the hospital and identification, if appropriate, of authorised prescribers
A review period and reassessment of the benefits.
Such screening ensures appropriate use of expensive medicines and is a model of the way in which any NHS development should be evaluated before being implemented.
Purchasers will seek such systems from providers when setting contracts.
Family health services authority professional advisers will be keen to see  that the system is not bypassed by hospital consultants who, having had a request to use a product turned down, ask general practitioners to initiate the prescription.
When consultants ask general practitioners to share the care — that is, to prescribe specialist products — they accept an obligation to inform: shared care protocols should explain the rationale of treatment, cost, side effects, and the aspects of care for which the hospital consultant will remain responsible.
Many shared care products are high cost.
Fundholders, if not reimbursed for their use, may insist that drugs be included in the hospital price.
This will result in a two tier system, where patients will be treated (by non-fundholders) or not.
The logical way forward is for purchasers to agree the number of patients they will pay for and for the region to ensure that this provision is adequate.
The cost will then follow the patient.
Further rationing of high cost drugs should be resisted until the costs of other developments are equally well known, debated among peer groups, and evaluated in use.
Of more urgent concern is the uncontrolled way in which new drugs, formulations, and presentations (not of individual high cost but likely to be used for large numbers of patients) are introduced, without assessment of health gain or cost, into primary care prescribing by consultants' recommendations, patient pressure, general practitioners' individual decisions.
Such assessments should be nationally obtained from research units and available to all prescribers.
Consultants and general practitioners need clearer explanations that a resource can be used only once, and higher expenditure on prescribing in primary care means loss of development money for the NHS.
General practitioners need assurance that control of expenditure will result in the savings being retained in local health care.
Incentive schemes (previously described) with agreed local benefits, such as the provision of more health visitors, are most likely to reassure general practitioners on this point.
The development of purchasers must include a requirement that providers examine the appropriateness of all prescribing (including the price differential of products in secondary and primary care) and that discharge and outpatient recommendations are for a therapeutic group, rather than specific products.
While professional advisers can, and do, work towards ‘once only’ savings such as changes in the prescribing of generic drugs, the real control needed is the introduction of new products only after assessment of the health gain and financial consequences.
On the other hand, a harder look should be taken at the range of prescribable products of doubtful value, such as, peripheral and central vasodilators, cough mixtures, baby creams, mild analgesics, and shampoos, and the value of others — for example , vaccination for foreign travel — should be reassessed.
The products alone cost many millions, to which the cost of professionals' time should be added.
General practitioners can be supported in refusing requests for these products in two ways: by the extension of the limited list (planned for June 1993) and by a structured patient education campaign to inform patients that the doctor cannot prescribe all medicines and that some illnesses are self limiting.
Prescribing and dispensing standards
Professional audit, established in medical practice and proposed for pharmacists, is invaluable for prescribing analysis and offers the opportunity to set treatment goals, measure success in achieving them, and re-evaluate the process.
Practice indicators from prescribing analysis and cost data can illumine audit and highlight discussion areas (box).
Further research is needed to understand the reasons why doctors prescribe as they do, and the cultural needs of the society in which the doctor works, including issues of deprivation and doctor and patient expectation, must be addressed before any judgment of excessive prescribing is made.
The legal mechanism for determining that judgment comprises a committee of three doctors, appointed by the family health services authority (with specific criteria for their selection).
A judgment of excessive prescribing can result in an amount being deducted from the doctor's remuneration.
This procedure is seen by most family health services authorities as a last resort, after practices deemed to be prescribing inappropriately have been offered information and help to lower their prescribing rates and costs.
Some practitioners, especially singlehanded ones, may benefit from training initiatives for doctors to reduce ‘sympathetic prescribing’ under pressure from patients.
Pharmacists' dispensing standards are tested by the family health services authority and by the Royal Pharmaceutical Society of Great Britain, whose mandatory code of ethics includes standards of practice for dispensing.
Disciplinary action is taken against any pharmacist who fails to comply and the royal society's inspectors, in their role as enforcers of both the Medicines Act and the profession's code of standards, visit community pharmacists regularly.
Collaboration between the royal society and family health services authorities would be a sensible way forward in improving dispensing standards.
Future roles for community pharmacists
Community pharmacy, an underused resource, will change with the NHS reforms and become better integrated into the prescribing process to ensure optimum pharmaceutical care.
In hospitals pharmacists already advise prescribers, through drug information and clinical pharmacy services, and encourage cost effectiveness and patient safety in drug usage.
In primary care prescribers rightly expect a safe and accurate dispensing service, but they have lost the regular advisory service and are most often given drug information by drug company representatives.
Occasional visits from medical and pharmaceutical advisers need to be supplemented by a readily available and local source of advice and information.
One option would be for the family health services authority to employ community pharmacists on a sessional basis to visit local practices.
The authority's professional advisers could target an area of concern, brief community pharmacists on the issues, and use their practice visits to inform general practitioners.
Such training could be funded by the postgraduate training allowance.
More effective use could be made of the pharmacy's patient medication records — for example, to analyse a practice's prescribing patterns and make recommendations for change.
Patients whose ability to take  medicines is a critical issue could be encouraged to use the same community pharmacy on each occasion.
The pharmacist could be informed of the risk and would be well placed to help the prescribers achieve their therapeutic objectives (for example, by offering compliance aids, visiting the home, or checking usage of the product) and to inform them of any problems.
Medicines do not come without risks, and patients are harmed by them through no fault of the drug or the prescriber.
Pharmacists should lead in actively encouraging patients to report side effects, or lack of treatment success, and either resolve the problem or inform the prescriber.
Fundholding strengthens the case for pharmacists working in health centres.
In addition to dispensing, community pharmacists could offer the same range of services as their hospital counterparts: they could screen and recommend new products to prescribers, analyse prescribing patterns, and ensure safe and appropriate drug therapy since they would have access to patients' notes.
Family health services authorities and consumers will, however, wish to ensure the viability of local pharmacies, with their convenience of access, the savings pharmacists make to the NHS by responding to common ailments, and new services such as needle exchange programmes for drug misusers.
Their future would best be secured by implementing the repeat dispensing system, recommended in a recent Department of Health report, and developing a contract that pays for services other than dispensing — for example, health promotion — where the pharmacist can offer opportunistic advice without the need for identification or referral.
A reduction in the number of single handed pharmacies is likely, as is the development of specialist pharmaceutical services (such as parenteral nutrition) previously available only in hospitals.
Joint treatment protocols should be extended to the community pharmacy wherever possible so that local practices know what the pharmacist will sell.
Such protocols will be essential with the extension of the limited list — indeed, fundholders may find reimbursing pharmacists, working to a protocol, cheaper than writing prescriptions.
Conclusion
The quality of prescribing can be improved by the activities of family health services authority professional advisers.
Some outcomes, such as reducing unnecessary prescribing, will result in savings which could be maximised if family health services authorities were empowered either to make fundholding the norm or to offer incentives to all general practitioners.
Certain quality developments will have little or no cost saving effect but will improve patient safety — for example, the preferential use, wherever possible, of well tried drugs with a long safety record.
Others, such as the use of newer drugs when these are appropriate to the patient's needs, will cost more.
The future roles of medical and pharmaceutical advisers are unclear.
Purchasers will need more advice on prescribing; in a contract setting this will include the definition of health gain from drugs, secondary care agreement of joint treatment protocols, systems to ensure appropriate prescribing at the primary care and secondary care interface, and definition of the standards and range of pharmaceutical services.
These professional advisers will need statistical and analytical skills as well as expertise in drug therapy.
The family health services authority's role of advising general practitioners, both on improving their prescribing and on how to ensure value for money, will remain and they will be required to show the effectiveness of their interventions.
A golden opportunity and the enthusiasm of professional advisers would be lost if cost reduction was required to dominate without full analysis of the health gain to be achieved from improved (and sometimes costlier) drug treatment.
Increasing links between family health services authori-ties and postgraduate education and academic units are important and enable commissioning input to training and research agendas.
Drugs will continue to have a key role in preventing and treating disease and in ameliorating symptoms.
These health gains keep people independent, employed, and out of hospital, but their cost effectiveness will need to be continually evaluated alongside other options.
Some indicators of prescribing in a practice
How actively is a disease — for example, asthma — being treated?
How do practices with specific expertise — for example, teaching practices and those where doctors have hospital sessions — compare with others?
How do fundholders and non-fundholding general practitioners differ?
How do consultation and prescribing rates relate to measures of deprivation and practice population compared with similar practices?
What are the priority training areas and how can they be met?
Which doctors are most or least likely to use new products?
Which outdated drugs are still used?
In which therapeutic areas would a protocol help?
How effective is the intervention of family health services authority professional advisers measured by reanalysis of prescribing analysis and cost data?
Some indicators useful for audit of prescribing in general practice
Treatment consensus among partners and consistency of prescribing
High cost areas where drug information can help with comparative costs
The need for a repeat prescribing system; a list of drugs preferred by the practice and practice policies — for example, on prescribing antibiotics and benzodiazepines
Comparison of practice prescribing with the family health services authority average
Summary
Drug costs are rising worldwide and price controls are set by governments
The United Kingdom has a unique database of prescribing from which practice indicators and audit of prescribing can be derived
FHSAs are funded to provide professional advice to prescribers
Most fundholders have achieved savings on their drug bills; other incentive schemes are needed
Research is needed to measure prescribing outcomes and health gain before new drugs and formulations are used
There are prescribing interface issues between primary and secondary care which may best be resolved by the development of purchasers
Community pharmacists have a developing role to play in improving prescribing
Education & Debate
Opening the black box: an encounter in the corridors of health services research
Abstract
Health services research has become more prominent as a result of the NHS reforms.
Both providers and purchasers want to know exactly where the money is spent and how it could be used more effectively.
How best to obtain information about health services is the subject of much debate within and between disciplines engaged in such research.
Because of their training doctors are often sceptical of anything other than formal clinical trials and research which produces statistical data.
Some sociologists argue that another way to find out what is actually happening in the NHS is to observe people at work and talk to them.
This article debates these differing views of research methods.
For effective research both quantitative and qualitative approaches need to be used.
This paper presents a dialogue between two conflicting voices from health services research.
It is presented primarily to inform and stimulate debate and it therefore adopts a style which is unusual in this journal.
The polarisation of views, inherent in the structure of a dialogue, may oversimplify complex issues at the heart of the debate, but we hope that it highlights several important conflicts which remain unresolved.
The setting for the dialogue is the corridor outside the office of the director of a large and successful health services research unit.
The director (who has an impressive record of quantitative research) meets a recently appointed sociologist…
sociologist : I'm glad I've caught you.
It's about this research proposal you've just turned down — what do you mean, ‘It's not proper health services research?’
director : Well, you were going to look at only two hospitals.
What sort of a sample is that?
Why don't you take up my earlier suggestion of doing a randomised controlled trial?
soc : Because it won't tell you what you need to know.
My project was a reasonable attempt to find out what's really going on in those two hospitals.
dir : I'm sorry, but we have to convince the medical research establishment that we can deliver high quality work not these small scale, unquantifiable studies of yours.
Clinicians often see health services research as the soft option and easy to carry out.
We need to win their respect.
soc : And how, exactly, are you going to do that?
dir : We've got to undertake good, credible, scientific research.
Science is respected and understood by clinicians (after all it's the foundation of medicine).
soc : Do you mean science in general or a particular image of ‘hard’ science like economics with all its equations.
To my mind, what I do as a medical sociologist is just as scientific.
dir : You're entitled to your view naturally, but clinicians won't understand what you do.
The model of science they know is an experimental one — the randomised controlled trial used to test drugs and surgical procedures.
We can test health services in exactly the same way.
A fraction of current health services research in the United Kingdom consists of randomised trials; we need many more — you know the sort of thing, classic trials like Mather's work in the late 1960s which compared the treatment of myocardial infarction at home and in the hospital coronary care unit.
There was a higher mortality after a month in the group treated in hospital.
A year later there was still a significant advantage for the patients who went home.
soc : Hang on a minute.
Wasn't that the trial where only about a quarter of the patients were actually randomised?
It's hardly a celebration of the experimental method.
It was fraught with problems.
‘Methodological pluralism is vital in an applied subject like health services research’
dir : Yes, but the study was repeated by another team.
The second time the researchers randomised most of the patients and they showed no significant difference in mortality in the home and hospital groups at six weeks.
From these studies we've developed criteria to identify who needs to go to a coronary care unit and who doesn't.
Who applies the results of trials?
soc : But does anyone actually use those criteria?
dir : I don't know.
I'm just a researcher — not a cardiologist.
It's not my job to implement research.
All I do is produce basic knowledge.
soc : As far as I can see, your contribution to basic knowledge is well and truly ignored.
Not just in coronary care — there are other examples.
Numerous trials have evaluated the various procedures performed during pregnancy and labour (Iain Chalmers has even gone to the trouble of collating them) but very few of these ideas have changed obstetric practice.
dir : I can't help it if some clinicians are cussed.
Anyway, you can't dismiss the experimental method just because some irrational people choose not to put the findings into practice.
Randomised trials have enormous potential for improving health policy — at a much higher level than individual specialties like coronary care or obstetrics.
Take something as fundamental as the NHS and Community Care Act — we could have tested whether general practitioner  fundholding was better than health care purchasing by districts.
We should have done something like the RAND health insurance experiment.
soc : The what?
dir : The huge project in the United States which randomised people to different health insurance schemes to look at the consequences, including the impact on their health.
That's the kind of work we should be getting into here.
soc : I'm sorry, but I still have real problems with this picture of the experiment as an ideal.
This is a modern health services research unit but you hold an antiquated view of science.
It only seems to include the experimental model drawn from the natural sciences.
I'm not even convinced that the natural sciences actually work like that and I'm not sure you have any right to assert that the randomised controlled trial is the best method.
It has its limitations.
Alternatives to experiments
dir : I think you're just against experiments.
soc : Not entirely, but your ‘one best method’ argument reminds me of a very old debate in sociology about positivism…
dir : Do you have to talk in ‘isms’?
If you could put it in plain English I might be able to understand.
soc : Let me draw an analogy, then.
The different methods employed by social scientists are like the different views of the surgeon and the epidemiologist.
Surgeons learn through direct experience of individual cases — through what they see, hear, and feel at their fingertips.
In contrast the epidemiologist views the surgeon's patients at the aggregate level as clusters of variables.
Have you got that?
dir : Yes, but I've never given much credence to anecdotal evidence from surgeons.
Go on.
soc : Well, between those two extremes there is a whole range of theoretical perspectives and research methods to choose from, both qualitative and quantitative.
What I want, returning to my analogy, is for the surgeon's view to be given a place in the scheme of research alongside the epidemiologist's.
Methodological pluralism is vital in an applied subject like health services research.
Even the Medical Research Council recognises that health services research ‘is typically multidisciplinary, bringing together as appropriate expertise in biological and clinical science, epidemiology, statistics, economics and the social sciences.’
If you only use experiments you're using a very limited tool box.
dir : I wasn't arguing just for randomised controlled trials — but we do need hard facts like those which experiments provide.
soc : Yes, but you judge all facts using hard science as your gold standard.
The point is that some things in health services can't easily be looked at with quantitative methods alone.
Qualitative methods could help by looking at health care organisation and delivery — at the processes of care.
Surgeons learn through what they feel at their fingertips, but epidemiologists view patients as clusters of variables
What is meant by process?
dir : But process is simply what health services do to patients.
We're interested in the product of health care, the outcome, the results of intervention.
If the patient dies it's a bad outcome and I know there's something wrong with the process.
End of story.
‘Process is simply what health services do to patients.
We're interested in the product of health care, the outcome’.
soc : That's oversimplifying the situation.
We need a wider definition of process.
It's more than just what happens to individual patients.
It's also about organisations and the people within them — not just the patient who dies, but the doctors, nurses, auxiliaries, planners, administrators, clerks, and porters, and the noisy, chaotic interaction between them and the structure that surrounds them.
There is a black box marked process and we haven't even begun to open it.
dir : So what exactly would you do?
soc : Well, for a start, I would open up our full methodological tool box and start using techniques other than randomised trials and models of research borrowed from epidemiology.
Perhaps health services researchers could begin to use some of the qualitative techniques available.
dir : Aha!
I knew it.
You want us to conform to your orthodoxy…
soc : No, mine isn't the only approach.
All I'm asking is that you begin to take these methods seriously and consider them alongside your own quantitative skills.
After all, market researchers in the no nonsense world of retailing and commerce often use qualitative and quantitative methods together.
dir : What exactly are these qualitative methods you're offering?
soc : Well, what about observational studies, for a start?
dir : But we do lots of those.
We've done lots of comparative work, case-control studies…
soc : Oh dear!
We're not even talking the same language here.
I didn't mean case-control studies.
I meant observation.
You know, being there, looking, and listening.
I was thinking of ethnography, which means you have to immerse yourself in the situation and talk to the people involved like an anthropologist would.
That's just one example of an approach which gets away from counting events and controlling for extraneous variables.
It's about trying to understand what is going on, almost through the eyes of the participants themselves.
dir : Sounds like an excuse to loaf around doing nothing in particular to me.
What can ethnography tell us about the big issues?
For instance, I bet it can't help us solve the problem of waiting lists?
Can your precious ethnography tell us anything which would be of practical use about managing these queues?
Waiting lists can't be seen as bus queues
Value of ethnography
soc : Only that they're not queues.
Isn't that worth knowing?
dir : What pretentious, counterintuitive rubbish.
We might not know how best to manage waiting lists, but we don't need sociologists to complicate the basics by telling us they're not queues.
They're great long queues of people waiting to go into hospital.
soc : No, they're not.
By saying they're like bus queues, you've made lots of assumptions.
If you really want to understand a waiting list you need to get in there are find out how it is organised and managed.
The best way of doing this is to study the people who actively assemble and maintain the waiting lists.
Then you see that waiting lists seldom resemble anything like the formal queue which operations researchers are so fond of modelling.
dir : I'm still puzzled about how you got this idea.
soc : By studying one district in detail using the ethnographic methods I described.
By observing how a list is managed I found out that although lists are kept chronologically, patients seldom come off the list in that order.
The office staff and the surgeons used the list as a pool of work they would dip into — indeed a surgeon might deliberately choose a recent addition to the list over someone who had waited far longer on the grounds of greater urgency…
dir : And quite right too.
soc :…or simply because they remembered the patient.
There were all sorts of other processes that worked against the idea of a simple queue which managers needed to know about.
dir : I take your point, but what about wider, international debates?
What about explaining variations in the rates of common surgical procedures like cholecystectomy and hysterectomy between regions and countries.
Quantitative work by people like McPherson, Wennberg, and so on can tell us about that variation.
soc : And I suppose you'd like more of the same so you can go on pinpointing variation and replicate the studies which have been done to show the same thing in different places, or maybe to include a few more explanatory variables in your statistical model?
dir : Well, yes…
soc : But clinical variation raises other questions which need to be answered.
What we really need to do now is start uncovering how those rates are generated by the actions of individual clinicians.
Take something like Wennberg's concept of the surgical signature, used to describe the different profile of surgical work performed by different surgeons.
What we need to know is how those ‘signatures’ get written.
And this gets us back to looking at process.
We need to know the sequence of events which take place before the patterns of surgical variation are produced.
dir : So what do you think your approach can offer?
soc : For one thing, it could tell us more about how variation is constructed.
Mick Bloor's qualitative work on adenotonsillectomy is a perfect example of the kind of study I'm talking about.
He carried out an observational study of ear, nose, and throat outpatient clinics and showed that there were systematic variations in patient assessment routines among consultants, rooted in differences between the specialists in their informal decision making rules.
If you combine such work with quantitative data you can begin to explain how variation occurs.
Outsider's view of sociology
dir : Your programme for looking at process is all very well, but this is exactly what your lot, medical sociologists, have ignored.
Medical sociology has long since given up looking at process — it's too busy experiencing illness and waffling on about doctor-patient interaction.
soc : Perhaps, but part of the reason lies in the culture of health services research.
In the United Kingdom it's driven by medicine and there aren't many posts for social scientists.
You only have to look at what gets funded and who evaluates the proposals.
There's very little room for the qualitative work I've been talking about: it it is there it tends to get tacked on to an existing project when the sociologist is brought in to provide expertise on survey design or interviewing or to use a standard measure of patient ‘quality of life.’
dir : You can't blame me for your failure to secure funding.
Anyway isn't the Medical Research Council canvassing medical sociologists for grant applications?
‘Waiting lists seldom resemble anything like the formal queue’.
soc : Yes, but they mostly seem to have people like you assessing the proposals.
It's no good having people who know nothing about qualitative research applying their yardsticks of experimental science to all types of research.
dir : Well then, I certainly can't argue your case for you.
I only know about my approach.
soc : But you could back my project?
dir : The decision's made.
But I'll tell you what we'll do.
Come back to me in a few weeks with another research proposal.
After today's discussion I should be a bit better at understanding what you're driving at!
soc : That's something, I suppose.
dir : Could I make one last suggestion?
Your research proposal wasn't very user friendly.
You could do worse than take a leaf out of the health economists' book.
When I started out, nobody had heard of health economics; now every provider unit in the health service wants one.
People seem to want health economists, up to a point, and even epidemiologists because they boast a set of tools to offer managers and doctors for opening what you called the black box.
The economists didn't get to this position by hanging back and wingeing from the sidelines.
If, as you claim, medical sociology, and your ethnographic methods, can really open up this realm of process and tell us what is going on in the ‘black box’ then you've got to be more entrepreneurial.
Change your name to Pandora while you're at it, people might be less inclined to be dismissive!
Authors have rights too
Without publication research can be of little value.
When researchers approach publication there is ample published guidance for them on what their obligations are, and there are well known style guides within each scientific discipline including, in medicine, the Vancouver style.
This article gives a series of anonymous examples to suggest that the impact of similar guides for editors has been patchy and to make some suggestions for better communication.
The Vancouver style, ‘Uniform requirements for manuscripts submitted to biomedical journals,’ sets down only the obligations of authors.
The wide acceptance of this style guide, and similar ones in other disciplines, suggests that it fills a need.
So far there does not seem to be an equally well known guide on the responsibility of editors to authors and to referees.
Below, I illustrate some of the problems authors experience that could be avoided by editors following guidelines.
The examples do not identify the article or journal concerned, but each example has happened to me or my coauthors during submissions to what are generally regarded as quality journals.
Most of the examples are from Britain but European and the American journals also figure.
The order of the points in the article corresponds to the progress of an article from submission to eventual publication not to perceived seriousness.
What if two papers with similar content arrive?
There may seem to be no problem for an editor under these circumstances: each paper is assessed on its merits and published accordingly.
I submitted an article which caused disagreement between referees, and after a third opinion was sought it was rejected.
A few months later the journal published an article covering similar ground.
The published paper was more extensive and a much better article, but an author does not have to be paranoid to wonder what went on.
Perhaps editors need to bear in mind what authors may think when this sort of thing happens and keep them better informed.
What if the editor is also an author?
If there are few good journals in a specialty, editors may not be able to publish during tenure unless some mechanism can be found to allow for this eventuality.
I submitted an article to the journal of which one of my coauthors was editor.
The rules of the organisation which owned the journal outlined a procedure to be followed that used a guest editor.
However, this procedure was not explicit to the readership, and only by adding an acknowledgement to the article could we make clear that the article had not been accepted just because the editor was an author.
Banning the editor from publication in the journal seems extreme if there are few alternative outlets.
Logically, the editor's research team would also have to be banned, which would probably discourage potential editors even more.
Whatever the procedure for dealing with the problem the journal should make it explicit.
How long should the author wait?
When they acknowledge receipt of an article journals sometimes state how long authors should expect to wait before receiving a decision, although few make this information more widely available.
I waited two years for the first substantive response to one article despite reminder letters to the editor.
(It was then rejected, which added insult to the injury, although it was then accepted by another journal).
Another journal has taken a year to respond on more than one occasion.
Journals usually blame slow referees, but if they have not replied within three months are they likely to reply at all?
It is no real answer to say that authors could withdraw the article and resubmit elsewhere, as the chosen journal may be the most appropriate one.
Journals which publish the date of receipt and final revision under articles at least let the prospective author estimate the likely delay.
What happens when the referees report?
If the opinions of the referees agree there is no real problem, but sometimes they do not, and even when they do agree the editor's decision may not appear to agree with the opinions.
It is hard to give an example without reprinting the whole correspondence, but we have had articles rejected when our reading of the referees' reports was that the article merited publishing.
To be fair we have also been offered the chance of revising articles which attracted substantial justifiable criticism.
Of course the editor must retain the right to decide on what fits into the journal and what does not, but the high esteem in which refereed journals are held is surely based on the assumption that the referees' reports will be the main feature in the editor's decision.
A further worrying issue here is the place of confidential reports, for the editor's eyes only, which most journals use.
What is the role of these?
If the referees' confidential comments disagree with their comments to the author then they are denying the authors useful feedback; if both sets of comments agree should the editor not have to justify why they have been overruled?
What does the editor do about aggressive referees?
Because persuading people to be unpaid referees is difficult it could be argued that editors have to pass the comments on.
In one of my papers I used an abbreviation in a non-standard way, partly because my printer did not produce mathematical symbols.
The referee assumed that I was ignorant of the difference between the two concepts and launched into a torrent of abuse.
Such aggression could be very disturbing to young workers submitting their first paper, although experienced researchers are used to it and it seems to be something which most people are prepared to put up with.
Editors could return the comments to the referee for rewriting, obtain a report from a fresh referee, or suppress the report and tell the authors why.
How should feedback be given?
Some journals give clear feedback and ask for a list of changes if the paper is resubmitted, but this is not true of all.
I once had to have the gnomic response of one respected editor of a major journal interpreted for me by a senior colleague.
No one expects the editors to commit themselves before receiving a submitted paper, but some indication of the degree of pleasure with which a resubmission would be received would be welcome.
Clarity costs nothing.
What happens when the paper is resubmitted?
Most journals send the referees' reports to the authors, and authors try to take them into account, assuming they are true.
Even if all of the points have been met there can still be problems when the paper is resubmitted.
I revised a relatively brief article in line with the referees' comments only to receive a new set of comments which raised points that could have been made at the first submission.
Sometimes this problem seems to arise because the paper has been submitted to new referees but the typeface of referees' comments suggests that this is not always true.
Journal policy seems to vary.
Some editors decide whether the first set of comments have been met and send for fresh reports only for major revisions, whereas others seem to obtain fresh referees' reports routinely.
What happens when the editor changes?
This should not be too much of a problem, but sometimes delays mean that it can be months before the feedback arrives.
I was encouraged to resubmit a substantially revised article to a journal.
Although the article was resubmitted during the same editorship, by the time the referee's report arrived the editor had changed and the new incumbent had a different perception of the needs of the journal.
I have even managed to persist so long that the final work on an article was dealt with by the third editor, but that owed something to my delays as well.
Some journals expect outgoing editors to retain responsibility for work in progress when they leave.
This also encourages them to chase up the referees.
What happens in proof?
Everyone accepts that journals have a house style about how to spell, and how to write abbreviations, but some articles come back with major changes.
One article which had been revised and resubmitted appeared in proof partly returned to its original form and partly left in the resubmitted form.
Within the constraints of proof changes I could not disentangle it.
The most extreme changes in an article which I have experienced involved alterations to the title and summary and major changes within the article itself, including making the most important tables into text.
I should have complained about the first case, but I was inexperienced then.
In the second case the changes were reversed with the comment that nobody had ever objected before.
Most authors have been baffled after the leisurely progress of their article through the system to find that they have to return the proofs in such a hurry.
Their bafflement is increased when they find such major changes made.
What is the point of sending the article to learned referees if it is subsequently going to be altered without warning?
Do referees have rights too?
The important role of the referees in improving the quality of published science is often overlooked.
For many journals the referee receives a typescript in the  post, sends comments off, and receives no other feedback than to see the article appearing in print later.
Some journals routinely give the referee feedback, usually on the editorial decision and often including a copy of the other referee's report.
Producing a good report, especially on a very technical paper, can take many hours, and editors do not seem to appreciate how rewarding referees would find the knowledge that their comments were taken note of and that the other referees agreed with them.
A further concern is that some journals do not transmit the referees' comments to the authors; this wastes the referees' time and fails to appreciate that they want to improve published articles not just act as gatekeepers.
Final comments
The practice of editors varies substantially, and these points are intended to suggest that some simple changes could improve the ways in which they communicate about the process and their decisions.
I would not want anyone to think that all my interactions with editors and referees have been unrewarding, many of my papers have been improved substantially as a result of the feedback I have received.
Medical Education
Making change happen
This is the last in a series of nine articles examining the problems in medical education and their possible solutions
The problems that have been identified in British medical education are not unique, and many of the proposed solutions have already been implemented elsewhere.
Although new medical schools like McMaster in Canada and Maastricht in the Netherlands have had considerable success (in terms of staff and student satisfaction) with courses based on self directed, problem based learning, these models may be dismissed as difficult to implement in an existing course.
One example of how major curriculum reform can be introduced into an established and traditional medical course is the recent experience at Harvard.
Harvard's new pathway
Harvard has a reputation as the premier medical school in North America, and the fact that it has chosen to introduce sweeping changes in its course is likely to make other schools take stock of what it is doing.
I asked the dean, Daniel Tosteson, why such a successful school had decided to revolutionise its course.
Like many recent reforms in medical education the changes had started with the dean's concern at the effects of the traditional course on the students in his faculty.
He knew from interviews with students at entry and graduation that many were demoralised by the course.
He did not think that they were adequately prepared for their roles as modern doctors.
In particular he thought that competence in computer literacy and manipulating information technology, which would help them to be ‘lifelong learners,’ were neglected.
He was also concerned that the traditional course overemphasised factual knowledge and paid too little attention to the attitudes that modern doctors need to develop towards their patients, their colleagues, and their work.
seeds of curriculum reform
The traditional medical course at Harvard was a postgraduate entry, four year one with the first two years spent studying the basic sciences and the second two devoted to clinical subjects.
The main teaching method was the traditional large lecture.
In 1979 the school hosted a ‘symposium on medical education,’ which sowed the seeds of curriculum reform in the minds of many of the staff.
By 1982 the dean was proposing introducing a ‘demonstration project’ which motivated students could enter (with no specific academic prerequisites) at the end of their second college year.
The course would run for seven years, at the end of which graduates would enter the second year of residency programmes.
Within the course half the time would be allocated to a compulsory core curriculum and half to self directed learning.
Basic and clinical sciences would be interwoven during the course, but with the clinical sciences predominating in the final three years.
A report on these ideas appeared in the medical school newsletter and was picked up by the Boston Globe and the New York Times .
The school soon found itself inundated with applications from college students around the country wanting to enrol on this innovative course.
In response to this enthusiasm Tosteson set up a planning group to design an acceptable curriculum for an experimental track within the school.
A major departure from his original vision was the rejection of a seven year course — but other concepts were accepted.
The ‘new pathway’ was to emphasise basic concepts rather than facts, topics were to be integrated, and clinical contact was to be introduced early.
Initially there was considerable opposition from members of the faculty who feared that the proposals would undermine their own positions.
Hence it was decided that the pathway should be set up as a small demonstration project only and be fully evaluated before its concepts were more widely introduced into the school.
Guarantees of outside funding from sources including the Josiah Macy Jr Foundation, American Medical International, and Hewlett-Packard also smoothed the introduction of the scheme, which was not seen to present any financial threat to the traditional course.
In the new pathway the formal lecture time was reduced to 60% of the total available, the remaining time to be used by students to pursue topics that interested them.
Most of the teaching was offered in small tutorial groups with close association between staff and students.
Formal departmental boundaries were lost, and clinical teachers were involved from the beginning of the course.
Each student on the parallel track was given a personal computer to use for electronic mail communication with tutors and other students and for access to bibliographic information.
All students were also allocated to a librarian at the library of medicine who would help with the self directed parts of the course.
Medical courses are traditionally lecture based.
This can be changed if there is adequate funding and an enthusiastic dean
evolution of new system
In 1985 all new students were invited to volunteer to study on the parallel track.
Twenty four were randomly selected from the 70 who volunteered.
These students were allocated to the ‘Oliver Wendell Holmes Society’ and formed the first group of Harvard students to study under the new system.
In 1986, 38 students were enrolled on to the parallel track, but during the next academic year something unexpected happened.
Although the original intention had been to formally assess the new curriculum before deciding to extend it to the rest of the school, various forces came into play to ensure that by 1987 the entire 160 strong intake was studying the new pathway course.
A major influence was undoubtedly the personality of the dean himself, but the essential catalysts were the decision by the department of anatomy that it could no longer continue to operate two separate curricula — one for the traditional course and one for the parallel track — and the decision by several of the charitable funders of the new pathway that future grants would be available only if the scheme was adopted throughout the school.
The atmosphere within the school was by then receptive to change.
The special arrangements that had been made for the new pathway students had caused resentment among other students, who felt that they were being treated like second class citizens, and enthusiasm from staff members who had been involved in the parallel track had reassured other faculty members.
Dr Myra Ramos, the associate dean of educational services, thinks that the sudden explosion of the new pathway would have been impossible if Tosteson had been too cautious in his original plans.
She believes that any attempt to negotiate an acceptable package for the whole school from the start would have resulted in ‘minimal change at the margins only.’
The apparent safeguards inherent in a small pilot project enabled very ambitious changes to be accepted and meant that when the whole school converted to the new programme the change was indeed radical.
One disadvantage of the departure from the planned scheme was, of course, the loss of the opportunity to compare the new pathway students with their colleagues continuing on a traditional course.
The new system ran as a parallel track for only two years, and all of the students were volunteers.
What evaluation was possible suggests that the new scheme works well.
The new pathway students were not identified by tutors in the clinical clerkships, and unreported data collected by Dr Gordon Moore, who coordinated the introduction of the scheme, suggest that new pathway students tended to be assessed as rather better than those who had come through the traditional route.
Certainly the first cohort of new pathway students did well in the national board examinations after graduation — but this was a self selected group, who might have done well anyway.
An interesting natural experiment arose when the entire school moved over to the new pathway course in 1987.
Students due to enter the school that year had already been asked to volunteer for the parallel track, so two cohorts existed — those who had expressed a preference for the new approach and those who had not.
The design of the first year curriculum included mainly a problem based approach, but one course retained a traditional lecture based format.
The students' performance on the problem based and lecture courses were not found to correlate with their preference for type of course, and those who had not volunteered for the new pathway did as well as those who had, even on the problem based sections of the new curriculum.
Although harder data on the effectiveness of the new approach are not available, there is a feeling at Harvard that staff and students are happier in the new atmosphere.
As Dr Ramos told me, ‘There comes a point where faith and conviction are more important than hard data.’
Must change be all or nothing?
Harvard could implement sweeping changes in its medical curriculum because it had a forceful dean and access to large grants to fund a very ambitious project.
During my researches for this series I have met many people who, though agreeing with the theory behind the reforms of British medical education proposed by the General Medical Council and other bodies, do not think that reforms can be implemented on a wide scale.
Although schools like St Bartholomew's in London have succeeded in introducing innovative curricula, this is often attributed to the personal skills of the dean and local enthusiasm rather than to anything more generalisable.
Can change be introduced in ways that most medical schools would find acceptable?
Dr Colin Coles, an educational psychologist from Southampton, is a firm believer in change through evolution rather than revolution.
He cautions against assuming that the only ways to implement effective reform are to start from scratch (as with McMaster's course, utilising problem based learning in small groups) or to adopt wholesale change as at Harvard.
He suggests that the end product of medical education should resemble ‘a well stocked library capable of updating and cross referencing’ and emphasises the importance of ‘elaborated learning,’in which students find that what they learn in various parts of the course ‘fit together’into a useful, coordinated whole that they can continue to use long after the relevant examination is over.
Although adopting an integrated problem based course may be one way of achieving elaboration, Dr Coles believes that such radical approaches are not essential.
At Southampton dramatic effects on students' ability to elaborate have been achieved by changing the timing of their examinations.At Southampton the students sit a traditional 2nd MB examination, which tests their knowledge of basic sciences.
But unlike most schools which set the 2nd MB at the end of the second year of the course, before the students start their clinical studies, Southampton has moved the exam to the end of the third (first clinical) year.
The students find that the basic sciences ‘make sense’ when they come to revise them in the light of some clinical experience — as one student stated recently: ‘It's not so much revision as vision.’
Making change happen
The GMC has announced that our system of medical education must change.
There is a wide consensus among medical educators and students about the need for change and the direction it should take, and there are plenty of examples from Britain and elsewhere that change is possible and can be effective.
But how can we ensure that action results from all of the recent rhetoric?
The enthusiasm of staff and students in places like McMaster confirms that techniques like problem based and self directed learning can make medical education an enjoyable experience without loss of quality in the end product.
The sweeping changes that have occurred recently at Harvard and the new basic sciences curriculum at St Bartholomew's Hospital, London, prove that change can be implemented in long established traditional medical schools if there is adequate funding and an enthusiastic dean.
The researches into medical education going on at places like Southampton and Dundee confirm that smaller adjustments to medical courses can have useful effects on how students learn.
Changes in the provision of health care and increasing awareness of the demoralising effects of our traditional system on the students going through it are driving changes, and we may be poised on the brink of a steep acceleration in the number of schools willing to make radical changes in their courses.
But we must ensure that changes are implemented quickly and on the scale needed to address the current problems.
The ultimate responsibility for reforms in medical education rests with the education committee of the GMC.
Although the committee is to be congratulated for its lead on the need for change, this will be worthless unless it is willing to ensure implementation of those changes.
The GMC does not have a good track record in ensuring that change happens.
This is partly because the council has limited means of enforcing its recommendations, short of the draconian removal of recognition from an entire course.
If, however, the council is serious about the need for reform it must be willing to find innovative ways of enforcing its recommendations.
Although the few schools that have introduced changes seem to be enthusiastic about them, wider implementation will require sticks as well as the nebulous carrots of increased staff and student satisfaction.
influence of medical students and young doctors
The GMC may have its hands tied in terms of the disciplinary action that it can take itself, but it is in a position to collect information that could be used by other interested bodies.
Mr Richard Wakeford, senior research associate at the University of Cambridge School of Clinical Medicine, has already conducted a series of surveys into educational practices at British medical schools for the council, but the results have not been made public (R Wakeford, personal communication).
Dr Chris McManus, from St Mary's Hospital Medical School, London, suggests that the GMC should routinely collect information from medical students about all aspects of their courses.
This should not be a formal response during the education committee's infrequent assessment visits to a school but should be a regular, in depth assessment of the type of teaching and general experience provided on each course.
The GMC is in touch with all final year medical students and house officers when they apply for provisional and full registration, and it would be a simple administrative matter to require applicants for registration to complete an anonymous questionnaire about their educational experiences.
This information could be used as the basis of a ‘good school’ or ‘good house job’guide, allowing students themselves to influence the educational experience by voting with their feet against poor courses.
Ultimately the strongest driving force for change must be the students and young doctors themselves.
Individually, medical students and young doctors have little power, but collectively they can be more influential.
The falling numbers of applicants to study medicine may force schools to think again about the courses they provide.
Recent changes in primary and secondary education in Britain, with increasing emphasis on project work and self direction, may encourage school leavers to seek out courses that continue these approaches.
Organisations like the GMC and the BMA should provide students with the information on which to base such choices.
They must be empowered to demand excellence in the courses that they attend and realise that their education is not a favour to them but a means of preparing them to be the sort of doctors that we want in the future.
London after Tomlinson
Primary care development zones
This is the final article in our series looking at the issues highlighted by the Tomlinson report into London's health care and medical research and education
Most commentators on the Tomlinson report have agreed with its emphasis on improving primary and community care.
The three elements of such a strategy are a remedial  programme to bring the general level of primary care up to national standards, a programme to provide such services to people with non-standard needs such as ethnic minorities and the homeless, and the development of an expanded model of primary care.
No one model will be appropriate across all of London.
The process should start with an audit of existing resources and services within each community, together with an analysis of needs.
From this would develop a local programme with specific plans for investment in premises, staffing, training, and management.
New contractual mechanisms may be needed to attract practitioners, improve their premises, secure out of hours services, and provide medical cover for community nursing beds.
There should also be incentives for closer working between primary and secondary services.
No developments on the scale needed for London have been carried out within primary care within the lifetime of the NHS — but their success will be critical to the calibre of health services for Londoners into the next century.
The Tomlinson report's description of the inadequacy of primary and community health services in London commands widespread agreement.
On most measures of quality, primary care in the capital compares poorly with that in the rest of Britain.
This comparison holds true even when inner London is compared with other English inner cities.
Although providing good quality primary care is difficult in urban areas across the United Kingdom, the depth of London's problems — and their persistence — do argue for special treatment.
This will be needed even more urgently if the government acts on the Tomlinson recommendations for the capital's hospitals and closes large numbers of acute beds over five to 10 years.
Could Tomlinson inspired ‘development zones’ for primary care provide a fast track for improvement?
How might they work?
This paper outlines a strategic approach for developing primary and community health services in London.
It sketches ways in which a development zone for primary care could be organised to improve services in the capital.
Any effective approach needs to build on the wealth of innovative pilot projects and experiments in primary and community health services.
In the 12 years since the Acheson report much has been learnt about how to provide improved primary care in Britain's inner cities.
However, this has often depended on individual special projects — and on the highly committed innovators who tend to run them.
If things are to change in London we will need to move from the piecemeal experimentation of the past decade to a sustained programme of development.
This will require leadership and generous resourcing if it is to produce results.
Doing different things in a different way: a strategy for development
Any development programme for primary care must pursue three objectives simultaneously: to remedy deficits in the existing pattern of primary and community health services, to provide non-standard services for non-standard groups, and to expand the model of primary care.
a remedial programme
The remedial programme should aim to make up the deficit in primary and community health services in the capital, to bring them into line with national standards.
Investment in the 46% of general practitioners' premises which the Tomlinson report identified as substandard will be needed.
So will improvements in the quality and quantity of conventional primary and community health services currently available to Londoners.
non-standard services
A service development programme is needed to provide non-standard services to groups for whom the traditional model of primary care, based on serving a family of fixed abode, is inappropriate.
These groups of Londoners are very diverse.
They consist of highly mobile young people and families, commuters, and tourists, as well as disadvantaged groups such as refugees.
They also include some people from ethnic minorities, homeless and rootless people, homeless families, and substance misusers.
The small scale of primary and community health services give them the potential for meeting such diverse needs flexibly, in ways that institutions cannot.
There are a wide variety of project based experiments to draw on when devising a pattern of services geared to the needs of marginalised groups: they include ‘sick bay’ services for homeless and rootless people; services provided by salaried general practitioners or community nurses for families in bed and breakfast accommodation; interpretation and advocacy for people from ethnic minorities; and outreach teams for substance misusers and street and hostel dwellers with mental health problems.
The particular needs of London's mobile residents, commuters, and tourists have been less well explored, but possible areas of ways of meeting them include an expanded role for primary health care in accident and emergency departments and north American style ‘ambulatory care centres,’ where a range of walk in services, including specialist clinics and diagnostic facilities, are available.
an expanded model for primary care
The aim of a programme to expand primary care would be to provide in the community services currently provided in hospitals where this is appropriate and cost effective.
To achieve this a very wide range of mechanisms will be needed.
These include shared care agreements and collaboration over protocols  between general practitioners and consultants for diagnosing and treating common conditions; new roles for community nurses, to encourage innovative forms of specialist and generalist practice; ‘hospital at home’ and other high intensity home care schemes, including terminal care; developments in community based specialist working such as paediatric home care and mental health and learning disabilities teams; community hospitals and nursing beds; and the move of some specialist referral clinics from hospital outpatient departments into primary health care settings — if possible, with general practitioners and community nurses collaborating with their hospital based colleagues in patient management.
Scope of the development programme
To be effective in fulfilling these strategic objectives investments must provide demonstrable improvements in primary and community health services for Londoners.
To do this the scale and scope of the development programme will need to go well beyond traditional means of spreading good practice within the NHS.
It must also amount to more than simple investments in bricks and mortar and extend beyond conventional methods of professional development for primary care practitioners.
In the development zone primary care arrangements cannot simply be left to the normal mechanism of allowing general practitioners to decide, within limits, what services they will provide.
Authorities will need to analyse the services that need to be provided and ensure that they are in place.
In doing this family health services authorities, community health services, and local authorities will have to achieve true partnerships as well as involving local people in service design and monitoring.
London neighbourhoods are very different.
No one model of primary and community health services will be appropriate across the whole city.
If changes are to command public support, Londoners must play an active part in shaping their local service mix to meet needs which they have helped identify.
At the same time the managerial capacities of family health services authorities and community units — both trusts and those managed by their health authorities — will need to be strengthened.
A common approach cannot be assumed: most district and regional managers have spent their careers in the acute sector, and have little understanding of the interlocking network of roles, relationships, and agencies that constitute primary care.
Primary care services for the homeless need to extend beyond special projects and become part of routine provision
A process for development
service audit
Family health services authorities, district health authorities, community health services, and local authorities within the development zone should join forces with local providers to conduct an urgent analysis of existing services in their particular patch, their staffing, and the capital stock available for primary and community health services.
This ‘mapping’ exercise would aim to identify strengths and weaknesses in services and existing links between primary and secondary health care and between the NHS and local authority social services.
It could pinpoint areas for improvement.
Providers and service users should take part in these assessments.
a development plan
This analysis, together with information about the health status and needs of the population served, would form the basis of a local development plan — probably based on family health services authority areas.
Development plans would need to show that they can meet all three of the strategic objectives — for remedial action, non-standard care, and expanded care.
They should also be able to show how each authority intends to cooperate with each other and with private and voluntary organisations to develop joint or complementary approaches to service delivery.
To develop plans successfully agencies will need to work closely with local providers and community representatives.
Stimulating their enthusiasm and creativity will be essential to the success of the programme.
Local plans will need to support their service development strategy with detailed plans for investments in premises; in staffing and training; in the organisational development of practices and community services (‘teambuilding’); and in improved management.
Mechanisms for change
Various new mechanisms will be needed if ‘zoning’ is to enable family health services authorities, district health authorities, community health services, and local authorities to make swift, concerted improvements in the primary care services available to Londoners (see box).
attracting and retaining more high quality practitioners
Existing contractual arrangements are inadequate as a means both of attracting sufficient high calibre practitioners to work in London and of rewarding them for providing an appropriate range of services.
In fact the present system of capitation payments and deprivation allowances is an incentive for London general practitioners to maintain a large list and do relatively little with it.
The fact that many do much more than this is no tribute to the perversities of the system.
Within the development zone new incentives need to be devised both to attract high calibre general practitioners and other primary health care workers to the inner city and to encourage them to provide the right kind of services.
In the case of general practitioners it may be necessary for family health services authorities to take on delegated authority from the Medical Practices Committee for recruiting general practitioners and approving average list sizes.
There is also a case for new forms of contracts and variations on traditional partnership arrangements, including salaried posts, job sharing, part time working, job rotations, and time limited, renewable commitments to a practice.
Possibilities for a wider range of incentives linked to service development include:
Remuneration packages with payments linked to the achievement of agreed service delivery targets for deprived or underserved populations; for services which fulfil the objectives of The Health of the Nation or Caring for People ; or for ‘shared care’ and other arrangements which reduce dependence on hospital services
Innovative options for out of hours coverage with appropriate payments
Incentive payments for providing medical cover to local community care centres or nursing bed units
The use of health promotion funds to encourage opportunistic health promotion activities according to agreed criteria; the setting up of ‘at risk’ registers; and the establishment of an information base for practice list needs assessment.
exit arrangements
It may be useful for family health services authorities within the zone to take on responsibility for arranging early retirement packages, where these could be shown to be in the interests of the service.
improving premises
Cost rent schemes which have worked well in other parts of the country have largely failed in London.
New mechanisms are needed — along with new money.
These might include:
Additional London weighting for cost rent schemes
FHSA part ownership schemes
The separation of ownership of premises from general practitioner pension arrangements
Work with the London boroughs on expediting planning procedures for primary health care premises
A centre of expertise in the design of primary health care premises.
relationships between primary and secondary services
The gulf between primary and secondary health care is greater in London than elsewhere.
In any development plan ways of encouraging collaboration between primary health care practitioners — both doctors and nurses — and their hospital based colleagues should be actively pursued.
Possible means of doing this might include:
Incentives for hospital and practice teams who collaborate to manage patients with long term conditions to agreed standards and criteria
Incentives for siting specialty referral clinics in primary health care premises.
This should be done in a way that will encourage primary care practitioners and their hospital based colleagues to collaborate on patient management.
training and staff development
Delivering improved primary care to Londoners will depend on the skills of primary health care practitioners from a range of disciplines and on their ability to work together.
Ensuring that these capacities relate to the health needs of particular practice populations could involve:
Support for postgraduate and further education being linked to personal development plans for individual practitioners and other staff which reflect local service development priorities
Management development, team building, and organisational development plans could be developed by practices in the light of local service priorities, and approved and funded by the family health services authorities.
new organisational arrangements
Many smaller and singlehanded practices in London provide good quality and highly valued care.
They will, however, find it difficult to provide a wider range of services.
Consortium arrangements and other ways of linking such practices with each other, with community health services, with social services, and with larger practices with an extended range of facilities will need to be developed.
Conclusion
A concerted development programme for London's primary and community health services is badly needed, but developing and implementing it will be demanding.
Nothing on a similar scale has been attempted within primary care over the lifetime of the National Health Service.
Its success will be critical to the calibre of the health services available to Londoners in the next century.
As such, it should be treated as an investment in the infrastructure of the capital and appropriately resourced with both money and the equally important human currency of ideas, creativity, and enthusiasm.
The programme will have succeeded if, in 15 years' time, primary health care in the capital has lost its status as the national laggard; the quality of the services it offers matches or exceeds that enjoyed in the rest of England; and London has become a place where aspiring primary health care practitioners in all disciplines aim to work.
Developing primary and community care: a strategy
Remedy existing deficits
Provide non-standard services
Expand the concept of primary care
Mechanisms
Attract and retain good GPs
Make early retirement easier
Improve premises
Strengthen links between primary and secondary services
Train and develop staff
Offer new organisational arrangements
LETTERS
Alternative allergy and the GMC
Editor ,— There is scarcely an assertion in Richard Smith's editorial about the General Medical Council (GMC) with which I would not take issue.
I will restrict myself, however, to dealing with the main thrust of the editorial.
Smith asserts that ‘the GMC was founded to protect the public against quacks.’
I disagree.
It was founded to enable the public to identify qualified medical practitioners.
It was given no powers in relation to those who are not so qualified, nor did the Medical Act 1858 prohibit the practice of medicine without registration.
Many qualified members of the profession now practise, or refer patients to others who practise, treatments whose scientific validity is considered by some other doctors to be questionable.
Acupuncture and homoeopathy are only two examples of many.
The GMC's powers over the registration — and hence the livelihoods — of doctors are already extensive.
The exercise of these powers is triggered by complaints or referrals on specific matters, and the procedures are judicial.
Parliament has not given the GMC the powers of an investigation bureau to assess the scientific validity of new treatments before allowing doctors to use them.
That has never been seen as a constituent of self regulation, and I doubt whether any government would be willing to divert so many responsibilities already assigned to other existing bodies (for example, the Medical Research Council and the Committee on Safety of Medicines)— better qualified to carry them out — and concentrate them in the GMC alone under the sole control of the profession.
Nor is it self evident that the profession could reasonably be expected to fund such a massive activity out of its own pocket.
Possibly Smith does not seek this, but only that the GMC should carry out such investigations in relation to particular treatments that it mistrusts.
If this is the argument it neglects the fact that statutory bodies are given very specific powers.
Once given those powers they must be seen to exercise them, and to exercise them impartially rather than idiosyncratically.
It follows, I believe, that if the GMC was given responsibility in this area it would have to exercise it comprehensively, in an enormous number of areas of both conventional and unorthodox practice.
It would not be allowed to pick and choose for long.
Smith's editorial talks about treatments that are risky.
Few medical procedures carry no risk of any kind, and it seems to me that it would be impossible for one body to assume responsibility for measuring risks and assessing treatments throughout the whole of medical practice.
Specifically, it is not the role of the GMC to decide medical controversies.
The council does, however, bring a disciplinary case against a doctor who, having decided to practice a particular form of medicine or to carry out a particular procedure, does so in a way that can be shown to have been irresponsible, or unnecessarily hazardous to one or more patients, because the doctor has failed to exercise a proper standard of professional care; the council also brings a disciplinary case when a doctor makes outrageous and false claims regarding the efficacy of a particular form of treatment.
One final point.
Smith suggests that doctors may be able to make swifter judgments than a lay jury on the weight and validity of scientific arguments.
As the BMA's own study of alternative therapy showed, life is not as simple as that.
The report concluded, among other things, that ‘many of the conditions which lead patients to consult practitioners of alternative medicine are ill defined, and either chronic on the one hand, or with a high rate of natural recovery on the other.
These considerations make it difficult either to design a trial, or to interpret the findings.’
Editor ,— Richard Smith is wrong.
The foundation of the General Medical Council (GMC) in 1858 (actually ‘the General Council of Medical Education and Registration’) did not outlaw ‘quackery.’
The GMC was given the responsibility, among others, to see that doctors are properly qualified.
But the GMC has not been given the power to set out which treatments are ‘scientifically validated’ and therefore permissible and those that are not and therefore forbidden.
This would be too akin to the power of the pope backed by the inquisition in the seventeenth century, or to Stalin's power backed by the KGB over soviet scientists in the twentieth century, to be acceptable.
As orthodox doctors we are rightly dubious about alternative medicine and unqualified allopathists, but importing political correctness into a vocation that is not wholly scientific is loathsome.
Ostensibly the medical profession is self regulated.
In truth, the profession in Britain is in thrall to a near monopoly employer (the NHS) in tandem with a regulatory quango (the GMC) and  litigious ‘consumers’ egged on by citizens' charters.
It would not take much to turn fiercely independent professionals into demoralised, tame civil servants looking over their shoulders rather than at patients.
Unfortunately, by its campaigns of recent years the BMA has rendered itself virtually impotent in its defence of the profession against those who would shackle it.
Editor ,— A B Kay attacks clinical ecology (environmental medicine to British doctors) and the neutralisation technique without checking his facts.
He ignores the evidence from the 1920s onwards that asthma, migraine, rhinitis, the irritable bowel syndrome, etc respond to the detection and avoidance of triggers; many conventional treatments have no better provenance.
Ivory tower allergists discount reactions to food unless an IgE mechanism has been proved, but denying them or attributing them to hypochondriasis is a sign not of scientific superiority but of a head in the sand mentality.
Neutralisation is used by over 2000 doctors in the United States.
It entails a testing session to find the end point (the first dilution of the extract that does not cause the wheal to increase in the 10 minutes after intradermal injection) followed by prophylactic use of that dilution.
Without experience, Kay states this technique, citing imaginary dangers and ignoring risks of alternative treatments such as desensitisation and steroids.
As an immunologist I dislike not understanding the mechanism (which logic suggests is immunological), but we use the technique regularly and it works.
Until they improve and can manage without it, patients find that with neutralisation they stay well, living a less restricted lifestyle and eating a wider diet than without it.
Blatant bias in reporting the literature is inexcusable.
The neutralisation technique has been validated by double blind randomised trials, including food trials showing its effectiveness in preventing symptoms.Studies that failed to show effects evaluated the provocation of symptoms by food extracts (not part of the standard technique); that cited by Kay was also faulty in many respects and gave a wrong definition of the end point.
Maberly and I reported results in inpatients with asthma and are doing an outpatient double blind randomised trial of neutralisation.
In a questionnaire follow up of mainly polysymptomatic patients (median duration nine years, 70% response) the number of severe and frequent symptoms had reduced from five to one per patient more than six months after inpatient investigation and 38% said that they were well or almost well.
We plan to test the overall management strategy in a randomised referral trial (for which ethical approval has been granted), with pairs of patients identified by others randomised between this and any other treatment; if patients warrant admission, distance need not limit
Editor ,— A B Kay's article and Richard Smith's editorial seek to use Peter Mumby's appearance before the professional conduct committee of the  General Medical Council (GMC) to attack the validity of clinical ecology.
The articles amount to premature judgment of an issue that has yet to be subjected to valid peer review.
Given the choice, we submit that trial by an appropriately constituted GMC would be far preferable to trial by such a kangaroo court.
We find much of concern in the current vituperative condemnation of clinical ecology.
The first shot in this battle was fired when a copy of a draft of the Royal College of Physicians' report Allergy: Conventional and Alternative Concepts was produced in a case in the High Court.
The report was compiled by Kay with the help of Caroline Richmond, a journalist and the founder of the Campaign Against Health Fraud, now called HealthWatch; it was Richmond who handed the draft report over to the court, against the college's wishes.
When we obtained a copy of this draft in December 1991 we were concerned at its inadequacies and apparently wilful distortions and submitted a detailed critique to the college.
 In response to this and other criticisms the report was withdrawn and rewritten, this time with the help of M Lessof, and was published in a moderated form three months later.
By this time, however, the draft had already served its purpose in the court case.
We have discussed the ethical and scientific difficulties and potential shortcomings of consensus statements.
We consider that the Royal College of Physicians was guilty of scientific misconduct in publishing its report; our critique has been published.
It is hard to avoid the suspicion that Kay's and Smith's articles are intended to reinforce the erroneous claim that there is no scientific basis for clinical ecology.
Our critique and the references we offer in substantiation, though not definitive, discredit this claim.
Neither the college's report nor Kay's and Smith's articles amount to anything like a valid review of clinical ecology — still less does the use in court, against the college's wishes, of a draft report that was subsequently withdrawn as being unsatisfactory.
No such authoritative review of clinical ecology can occur without the active participation of proponents of the approach.
We propose that the GMC's remit should include censure of those members of the medical profession who commit scientific misconduct by distorting published evidence in reviews and consensus statements.
We have described nine readily identifiable techniques by which an author can do this, as exemplified in the Royal College of Physicians' report.
If such a proposal was adopted by the GMC Kay and his committee might find themselves in the dock.
Until such a time, the way remains open for doctors to vilify colleagues publicly with impunity and to mount ill founded and unscientific attacks on approaches to care with which they do not agree.
Such behaviour is a disservice to patients and the profession.
Editor ,— The fact that A B Kay continues to refuse to accept the validity of the Miller technique will surprise none of us who use it.
Now that good double blind studies have proved its worth — which Kay chooses to ignore — the technique is becoming increasingly available under the NHS, and it can be only a matter of time before his conversion is assured.
Richard Smith's editorial seems merely to echo Kay's views; both articles include a reference to Jewett et al 's report, which was discredited as flawed soon after it was published.
I wish to correct just one major inaccuracy in Kay's article.
On the last page he states that ‘The United States Department of Health and Human Services specifically excludes provocation-neutralisation…from reimbursement under Medicare.’
The reference given is dated 1983, since when many developments have taken place, not least that American otorhinolaryngologists have adopted the Miller technique as their treatment of choice for allergic perennial rhinitis.
In a telephone call after I read Kay's article Medicare in Baltimore confirmed that it does cover such treatment in full.
Editor ,— A B Kay's article on alternative allergy and Richard Smith's editorial use misleading arguments to discredit clinical ecology.
In the United States allergy has been a specialty for decades.
The American Academy of Environmental Medicine, with hundreds of doctor members from different specialties, has rigorous board examinations.
Both the American National Council Against Health Fraud and the British Health-Watch have attacked clinical ecologists, but some American critics have been sued under antitrust laws.
No such protection exists in Britain: we rely on the good sense and impartiality of our professional bodies
Over 3000 American doctors, including members of the American Academy of Otolaryngology, practise provocation-neutralisation as first line treatment.
Twenty million patients have been thus treated, with no deaths.
Assertions of danger are false; this treatment is safer than many prescribed drugs and unrelated to desensitisation, in which increasing doses can provoke anaphylaxis.
Even the recent report by the Royal College of Physicians, which was coprepared by Kay, accepts that conventional treatment of allergy leaves patients dissatisfied because of inefficacy or side effects.
Using unsafe desensitisation, conventional allergists and general practitioners have caused 26 patients to die since 1957.
Kay mistakenly calls provocation-neutralisation unscientific.
Science should explain the observed, not deny the unexplained.
A study by Jewett (an orthopaedic specialist)et al was criticised as flawed (J B Miller, symposium of the American Academy of Environmental Medicine, Jacksonville, Florida, October 1991).
Miller's provocation-neutralisation technique is standardised, not random; injections are intradermal, not subcutaneous; and measuring the skin response to various items precludes blind testing.
I am glad that Kay accepts the appeal of the ideal of environmental triggering: it is certainly true.
Most human illness, including 85% of cancers, results from the environment acting on genes.
Dietary effects on heart disease, cancer, and diabetes are established.
I applaud the impartial stance of the General Medical Council, mirrored in the ‘Alaska law,’ which states: ‘the Board may not base a finding of professional incompetence solely on the basis that a licensee's practice is unconventional or experimental, in the absence of demonstrable physical harm to the patient.’
This should be implemented in Britain soon.
Additionally, members of complaints committees should declare interests and defendants need the right to peer representation and to object to committee members with antipathetic interests.
Editor ,— A B Kay's article shows the feebleness of the General Medical Council (GMC) when dealing with controversial therapies.
Perhaps the GMC and the royal colleges should ‘ensure that procedures which are potentially harmful have been validated by careful placebo controlled clinical trials.’
Richard Smith's suggestion is that the GMC should ‘investigate treatments offered by doctors that may be risky and whose value has not been scientifically proved.’
Unfortunately, this advice cannot be put into practice.
Any treatment may be potentially harmful or risky.
Even if an ineffective treatment does not in itself cause damage it may harm patients by raising false expectations or by deflecting them from a better treatment, so this criterion would leave virtually all unproved treatment open to investigation.
The proportion of conventional medical treatment that is unproved is large: more than half the forms of care offered in pregnancy and childbirth were judged to have ‘unknown effects which require further evaluation’(31%) or ‘should be abandoned in the light of available evidence’(21%).
There is no reason to suppose that care in other branches of medicine has been more thoroughly validated, so Smith is setting the GMC an impossibly large task.
The alternative strategy is to inform patients whether a given method of diagnosis or treatment has been properly tested for efficacy so that they can make an informed choice.
This task is being undertaken by HealthWatch, a registered charity.
The committee (which includes experts in the design of clinical trials) has agreed minimum guidelines by which efficacy can be proved.
In response to a request from a member we ask a named practitioner (medical or alternative) if he or she has evidence of efficacy that meets these criteria and, if not, if he or she is obtaining such evidence.
The onus of producing the proof lies with the practitioner, not with HealthWatch: we merely inform our members if such proof exists.
If the public (and opinion formers among scientific journalists) have reliable information about the evidence of efficacy for methods of diagnosis and treatment then the public need not be deceived by quacks and sincere practitioners will have an incentive to validate their methods by appropriate clinical trials.
We hope that many practitioners will be willing to support us in this effort.
Editor ,— A B Kay notes the lack of any validation of the diagnostic methods and treatments used by some practitioners of clinical ecology and the possibility of dangerous adverse reactions.
He does not devote space to what may be the most disturbing aspect of all — namely, the failure appropriately to diagnose conditions, which inevitably leads to the denial of appropriate treatment and the reinforcement of maladaptive behaviours.
I and many of my colleagues who work in general hospital psychiatry often see patients who have spent years, and considerable sums of money, seeing alternative allergy practitioners for little benefit.
Such patients are often suffering from various psychological disorders, in particular depression, anxiety (with or without hyperventilation), or somatisation disorder.
Formal studies confirm that most patients who have been labelled as having ‘twentieth century disease’ or ‘environmental illness’fulfil criteria for psychiatric disorders.
The tragedy is that many of these disorders are easily diagnosed; all that is required is to take an adequate history and perform a mental state examination, procedures that are cheap and free from side effects.
Once diagnosed, many of these disorders are easily treated.
Failure to diagnose them denies patients simple and effective treatment.
On the other hand, providing a false diagnosis adds to patients' disability, reinforces maladaptive behaviour, and ensures that what might have been a brief illness becomes refractory to treatment.
Furthermore, some of the techniques used by clinical ecologists, which centre on avoiding environmental stimuli, can worsen psychological distress and physical disability.
The cure may be worse than the disease.
Such practices are costly to the patient, and not only in terms of money.
In a well publicised case a patient recently committed suicide while under the care of a clinical ecologist.
The government white paper The Health of the Nation identifies the need to reduce suicide rates as a key goal for public health.
Improving medical recognition of depressive disorders, especially when they present, as most do, with somatic symptoms, is one way.
Addressing the public stigma of mental illness, which permits the unscrupulous to collude with vulnerable patients, is another.
Kay's article also suggests, however, that it is now time to consider regulating the conduct of doctors who repeatedly fail to maintain adequate professional standards.
Editor ,— A B Kay's account of the General Medical Council's recent hearing on the case of Dr Keith Mumby raises many important issues.
There are many clinical situations in which some form of food sensitivity should be included in the differential diagnosis, but to entertain only food sensitivity as a diagnostic possibility is surely unreasonable.
Dr Mumby stated that he diagnosed food or environmental allergy in more than 99% of his patients.
He does not consider it necessary to examine the patients who consult him, and he seemed unaware that he might be failing to detect serious conditions, symptoms of which a patient might erroneously have associated with diet.
When clinical ecologists see patients with many symptoms, incongruity and inconsistency between their symptoms and clinical signs, and no laboratory evidence of disease they may diagnose environmental illness, food allergy, chronic fatigue syndrome, hypersensitivity to candida, or hypoglycaemia.
The conventional view is that some polysymptomatic patients have a psychologically based disability.These patients are extremely suggestible.
In a study of 50 such patients in the United States 15 developed new symptoms and some acquired additional ‘sensitivities’ during two years of treatment of their environmental illness by clinical ecologists.
If the disability is psychologically based diagnostic systems based on the use of multiple and unvalidated skin tests may reinforce the delusion.
In order that satisfactory treatments can be developed, proper studies need to be carried out on those subjects who have psychologically based reactions to foods, however manifested.
These may be the result of suggestion, but adverse conditioning is an entirely plausible further mechanism.
Editor ,— A B Kay deserves support in his attempt to persuade the General Medical Council (GMC) to provide far more effective protection for members of the public in relation to doctors who publicise treatments of unproved efficacy.
My experiences suggest that an increasing number of doctors are becoming involved in the promotion of dubious treatments, either by acting as medical advisers to companies or through their association with clinics providing unorthodox treatments.
Last year I thought it necessary to criticise several doctors for such behaviour.
In one case the doctor's name appeared in a promotional brochure as medical adviser to a company marketing an electrical device that was claimed successfully to treat a range of conditions including migraine, arthritis, insomnia, and depression.
These claims were purely anecdotal, and none had been verified by independent clinical trials.
According to the brochure, this device was available — at a cost of £155 plus ‘consultation fee’— from several named medical practitioners, including the allergist named by Kay.
I am also aware of another practitioner who is planning to set up a clinic with a treatment based on an electronic system in which ‘free electrons are pumped into the body by the billions’— a claim that may sound impressive to members of the lay public.
According to this clinic's publicity material, the results have been outstanding in a range of conditions including AIDS, cancer, heart disease, and even quadriplegia.
Once again there is no evidence from independent clinical trials to back up the hype.
The 1968 Medicines Act gives the public perfectly adequate protection from false advertising claims made by companies that manufacture products classified as medicines.
Unfortunately, through gullible journalists and limitations of the act, grossly exaggerated therapeutic claims can be made for ‘natural’ health supplements, herbal remedies, electrical devices, allergy treatments, etc, few of which are ever supported by objective scientific evidence.
Obviously the GMC cannot investigate the efficacy of every controversial treatment brought to its attention.
What it must now do is issue some clear guidelines on the manner in which doctors involve themselves — directly or indirectly — in promoting unproved remedies to the general public.
Editor ,— I was heartened by the stance taken by Richard Smith and A B Kay concerning controversial treatments and the General Medical Council (GMC).
As a psychiatrist I sometimes explain to people the differences between my profession and that of psychology.
There is a confusion in the public mind between the two, even among professionals.
I believe that the long training that doctors undergo enables psychiatrists to diagnose and prescribe better than those without this training.
Although there is logic behind this statement, it often provokes argument.
It suits some members of the multidisciplinary mental health team, including some doctors, to underplay the importance of these skills.
In the United States there has been a longstanding debate over prescribing rights for psychologists.
I have approached the GMC three times about professional boundaries, but it has been unable to help.
The first approach concerned a stress management clinic advertising a consultant psychologist.
The psychologist in question was not an NHS consultant, but I thought that the public might infer this.
The Advertising Standards Authority upheld my complaint and ruled that the advertisements should be amended to clarify the matter.
I approached the GMC again about ayurvedic medicine, which is allied to transcendental meditation.
This concerned pulse diagnosis by doctors and herbal prescriptions to prolong life.
The third referral concerned a chiropractor, a graduate of a European college, who styled himself doctor.
His advertisements claimed that spinal misalignment caused various illnesses.
His promotional leaflets referred to his routine practice of obtaining x ray films, running diagnostic tests, and prescribing treatment.
The GMC could not act because he had not specifically stated that he was a registered medical practitioner.
Any patient seeing this man would have to check his claims to be a doctor themselves.
The public has to distinguish between highly qualified professionals like psychiatrists and psychologists at one end of the range and, at the other end of the range, discriminate between self styled doctors untrained in diagnosis and registered medical practitioners.
Should the general public be left alone to make their own decisions, when presented with unproven techniques?
I am well aware of the GMC's circumscribed functions in maintaining a register, and regulating the practice, of medically qualified doctors.
Despite this the government needs to give some thought to the practices of doctors not on the medical register.
Editor ,— A B Kay's article on alternative allergy underlines concerns I have about unproved treatment for ‘allergy.’
People with such symptoms are often at their wits' end to get help and are convinced that their symptoms are caused by organic illness.
Many of them have been failed by conventional medicine or have rejected it.
They find their way to alternative allergists because they read articles in newspapers and magazines that are written by naive journalists or planted by efficient public relations experts.
In the course of a journalistic investigation I have met people who have spent £12000 on treatment by clinical ecologists and have remortgaged their homes — usually at the therapist's suggestion — to raise the money.
Few of them improve, and even fewer recover, many behave like members of cults, obeying their doctor without question, paying huge sums of money, and becoming estranged from their families.
The Royal College of Physicians and similar organisations overseas have studied alternative allergy and found it wanting in scientific credibility and clinical usefulness.
As a result clinical ecologists are shifting their focus away from allergy and towards toxicology, telling patients that they are being poisoned by minute doses of everyday substances or even by domestic electricity.
The diagnosis of multiple allergies or environmental illness is being replaced by that of multiple chemical sensitivities.
At Guy's Hospital the poisons unit has had to set up a psychiatric liaison service to help such patients.
The long term answer does not lie in proving or disproving the validity of alternative allergy tests.
Instead, doctors must educate the profession and the public that inchoate multiple symptoms of psychological origin are not a sign of weak will or malingering and are curable at little or no expense if doctor and patient collaborate in treatment.
Until that happens, all patients deserve the protection of the GMC, which was founded to protect the public from quacks.
Academic medicine
Editor ,— Richard Smith's editorial on academic medicine touched off an air of discontent within me.
Women, because of their role as mothers and wives, have diverse careers which are often very dissimilar to those of men.
In 1963 I studied physiology and biochemistry.
In 1966 I graduated and started work as a research assistant.
In 1967 I married and had my first child.
My only choice was to leave or to continue working (there was no maternity leave).
I left.
I had two more children and taught higher national diploma courses in the evenings at the local technical college.
In 1974 I began a part time PhD in biochemistry and electron microscopy.
As I earned only enough to pay for my childminder my father paid my train fares.
I obtained my PhD in 1978 and started full time work on ‘soft money.’
My first marriage was coming to an end, but my husband would not leave until I had a permanent job (so that I could support his children).
I started lecturing at a college of higher education in 1978 but returned to research and soft money in 1980 as soon as my husband had left.
In 1982 (as a single parent) I started medicine.
I did not get a grant for my preclinical years so I worked half time in research for two years.
I married my second husband in 1986.
I qualified in 1987, and we moved to Newcastle in 1988 (his career move).
To get experience in obstetrics and gynaecology for vocational training I had to come back to London.
My second marriage collapsed in 1991 at the beginning of my last year of vocational training — and I still had dependants.
I was accredited in general practice last June and now work in a Medical Research Council epidemiology unit, combining clinical research with 13 hours a week in general practice.
I earn £28000 a year, and I have a one year contract.
My career since 1982 has been remarkable for the number of men who have harboured exactly those prejudices that Smith speaks of — that is, that you can't do science and medicine and have children.
I have, and where has it got me?
I have a poor salary, no job security, and scant recognition of my skills.
As Smith points out, my PhD — and incidentally, my maturity — is regarded as a threat, while much is made of my ‘limited clinical experience.’
I think doctors have little regard for skill; in medical school they actually teach that you should do anything: ‘observe once, try once, and then be an expert.’
I had a rigorous scientific training and a haphazard vocational training, and they were very, very different.
Recently I have spoken to three senior academic clinicians and they have told me that I will be snapped up.
But when?
I have around 15 more good years ahead of me, but I fail to see plenty of room at the top for women like me.
Editor ,— Unfortunately, many of those who would have benefited from attending the conference organised by the Royal College of Physicians for physicians wishing to pursue a career in academic medicine will have been unable to attend because of NHS commitments.
As a young physician dedicated to an academic career, I think that several points may explain the paucity of first class researchers currently attaining senior posts.
Firstly, many junior doctors have little understanding of what medical research is all about.
As undergraduates they are often exposed to uninspired lecturing from academics, and subsequently many struggle to assimilate the minutiae of medicine in the (false) belief that this will ensure an easy passage through the membership examination.
Consequently many young doctors fail to appreciate the difference between the tedious memorising of large amounts of academic data and the excitement of novel thought and experiment that is the true reward of an academic career.
Medical schools fail their students if they fail to nurture their minds and instead take the easier option of merely imparting factual information.
Secondly, the profession needs to grapple with the problem of substandard training in research.
The royal colleges take great care in inspecting clinical posts and remove recognition from those that fail to provide adequate experience and education.
A similar procedure should be applied to all research posts.
It is all too easy for a department to obtain research money (for example, from the pharmaceutical industry) and then to employ a young doctor to perform substandard research.
Young physicians entering their first research post and hoping for a higher degree are vulnerable and naive.
They require careful guidance and training by senior academic physicians to reach their full potential.
Young physicians considering a research based career should seek out those people in senior posts who have a real desire to see fresh minds flourish in academic medicine.
It is better to train with such a person in a first rate department even if at first sight the research project is not quite what you wish to study.
Editor ,— I was interested and depressed, but not surprised, to read Richard Smith's editorial highlighting exactly why we have problems in attracting adequate candidates into academic surgery.
The assumption of those who decide where research money should go seems to be that surgeons do not need to participate in research; they should be content to operate somewhere in the depths of the hospital and speak when spoken to.
Anyone who needs an operation will wish to be operated on by a competently trained surgeon; the necessary skills need to be honed over time.
Patients will also hope that the surgeon has good judgment, is open minded, and is interested in progress.
This can be achieved only if it is recognised that research is essential in surgical practice and should be encouraged but, equally, that the person concerned must learn to operate.
Another point that Smith highlights is the obsession of the current research councils with molecular biology, the assumption being that all research on other topics is inconsequential.
This approach to surgical research is again unacceptable, ignoring as it does much excellent research that is responsible for real improvements in patients' care.
The suggestion that academic surgeons should spend years acquiring skills in molecular biology is nonsense.
This type of work should be done by scientists working in collaboration with surgeons in departments of surgery, which is the model used in my department in Leicester.
Surgeons should know about the potential of this subject and be prepared to participate in projects that will improve the health of their patients.
No qualified surgeon can be expected to do an occasional experiment in molecular biology in the laboratory any more than a molecular biologist can be expected to perform an occasional operation.
Working together is surely the answer.
Lastly, many scientists believe that an MD is a waste of time while a PhD is what everyone should do; most of these people are out of touch with the real world.
In Leicester, as I expect occurs elsewhere, the MD is a registered degree and is supervised.
The person doing it does have scientific training, and the MD is more difficult than a PhD in that the supervisor does not take part in the examination.
It is also time to recognise that a PhD is not acceptable to most appointment committees in academic medicine whereas an MD is, and this is why doctors want to do MDs rather than PhDs.
The answer to the problem is surely to make sure that all MDs are supervised, registered, and properly conducted.
Editor ,— With regard to academic medicine, surely it is not the time spent in research that is important but that the desired aim of awakening in the young doctor an appreciation of what science has to offer is achieved.
In the surgical specialties the problem of allocating time to research is particularly acute given the long apprenticeship necessary to learn technical skills.
With this in mind a new model of training in surgical science has been established at University College London, organised jointly by the departments of surgery and of anatomy and developmental biology.
The course is aimed at trainees from all surgical specialties.
A third of the course will be taught and will provide an overview of the ‘new biology,’ with the aim of improving the level of scientific appreciation in surgery.
The remainder of the course will be a research project done at the bench.
Projects are offered in a wide range of science laboratories in the university and medical school.
The Association of Professors of Surgery has advised that every surgical trainee should undertake a period of full time research training, but it must be borne in mind that most surgeons will not subsequently perform laboratory research.
This course offers an MSc in surgical science, and those with a primary motivation towards an academic career will be able to proceed to PhD registration.
It is hoped that this type of programme will answer many of the criticisms of ill conceived and piecemeal research and provide a model for surgical training in the future.
Colleges' concern
Edito r,— C J McCullough rightly draws attention to the part that the royal colleges might play in a reassessment of the present system of delivering health care.
It will come as no surprise to learn that colleges have serious concerns about the current problems —‘overspent,’‘underfunded’ hospitals indicating a flaw in either the underlying principles of health care or their implementation.
These concerns have been expressed to the secretary of state, the chief medical officer, and the chief executive of the NHS collectively and independently, and the colleges have indicated their willingness — indeed, their wish — to work with the administration to address both the immediate issues (as a matter of urgency) and long term issues.
As to the conflict between consultants' ethical and contractual obligations, it is surely the case that because of the vulnerability of patients, and to maintain patients' trust, doctors must always put ethical considerations first.
How that responsibility is best discharged can be decided only by the person concerned.
Self monitoring of blood glucose
Editor ,— Robert Tattersall asks, ‘Should people with non-insulin dependent diabetes mellitus monitor their blood glucose concentrations?’
Although perhaps a case can be made for self monitoring by patients treated with insulin, there is no evidence to justify this expensive and uncomfortable practice for most people with non-insulin treated diabetes.
It is true that home blood testing provides more accurate information than that available from urine tests, especially in patients with an abnormal renal threshold, and that it also provides information about everyday fluctuations.
These advantages cannot, however, be considered to be worth while unless they can be shown to lead to better glycaemic control or a reduction of long term complications of diabetes, or both.
Several studies of self monitoring in non-insulin dependent diabetes have now been carried out, but no difference has been found in glycaemic control between those who monitor their blood glucose concentrations and those who do not.
I have just completed a randomised study of 24 patients receiving oral hypoglycaemic agents, in which I compared the glycaemic control (as indicated by monthly assay of fructosamine) of a group allocated to self monitoring of blood glucose and a similar group who tested their urine.
There was no significant difference in glycaemic control between the two groups during the six month trial.
Despite the discomfort of frequent finger pricking there is a degree of fascination associated with blood letting, and research suggests that most patients prefer blood testing to urine testing.
But every unnecessary home blood test wastes 26p of scarce NHS resources (compared with 4p for a urine testing strip), and if each of Britain's 500000 non-insulin dependent diabetic patients carries out several tests a week the cost implications are enormous.
As a basis for adjustments to treatment results of self monitoring have now been superseded by the glycated haemoglobin concentration or results of fructosamine assays.
Therefore, if self monitoring of blood glucose concentrations does not influence either treatment or glycaemic control its value is limited in non-insulin treated diabetes.
A policy on home monitoring for this large group of patients should recognise that self monitoring is no longer the principal means of assessing glycaemic control but is, rather, a tool that can offer reassurance or warn of problems during the intervals between measurements of longer term control.
Editor ,— Lesley V Campbell and colleagues and Robert Tattersall raise doubts about the usefulness of blood glucose monitoring strips in diabetes mellitus.
We are also concerned about the reliance placed on these tests but in a different context.
We have seen three cases of hyperosmolar hyperglycaemic deterioration of diabetes (two purely non-ketotic and one with a degree of ketoacidosis) and observed a discrepancy between the readings obtained with blood glucose strips (Ames strip plus a digital meter in case 1, BM-Test-1–44 strips in cases 2 and 3) and the laboratory glucose measurements.
Case 1 — A man aged 84, not known to be diabetic, presented with confusion, cough, and anorexia.
On examination he was dehydrated with a rapid pulse and slight tachypnoea.
Glucose estimation by digital meter was 15.5 mmol/l, but the laboratory measurement of 53 mmol/l suggested non-ketotic hyperosmolar hyperglycaemia.
The patient died of thromboembolic complications.
Case 2 — A woman of 85 with diabetes controlled by diet presented to the accident and emergency department and gave a history of loss of independence over two weeks and a fall.
Her grazes were dressed, and a blood glucose concentration of 10 mmol/l was recorded with a BM strip.
Examination otherwise was unremarkable.
She was admitted for mobilisation, but tests requested the next morning on samples taken on the evening of admission showed a serum glucose concentration of 56.1 mmol/l.
The patient died of thromboembolic complications.
Case 3 — An insulin dependent diabetic woman aged 74 gave a history of nausea for one week and poor diabetic control.
A district nurse checked her blood glucose concentration with BM strips at home; it varied between 17 and 44 mmol/l.
The concentration obtained with a BM strip in the accident and emergency department was 17 mmol/l, but the laboratory measurement was 82 mmol/l.
She had some ketoacidosis and responded to conventional treatment.
Non-ketotic hyperosmolar hyperglycaemia is uncommon and easily missed.
It tends to present in elderly people, who may not be known to be diabetic.
There is frequently a vague history, and they can appear surprisingly well, without the obvious dehydration and air hunger of younger ketoacidotic patients.
Diagnosis can be delayed if too much reliance is placed on a blood glucose strip.
These test strips should be used only for monitoring and not for making executive decisions.
The paradoxically low reading in hyperosmolar states despite good technique is highlighted in the datasheet supplied with the BM-Test-1–44 (though not mentioned in the Ames sheet) but is not generally recognised or taught.
Its cause is not known (personal communication, Boehringer Mannheim UK (Diagnostics and Biomedicals), 1992), though the strips use a glucose oxidase reaction different from the hexokinase reaction of laboratory machines.
Paget's disease of bone
Editor ,— Roger Smith suggests that Paget's disease might be due to infection with a viral agent early in life.
Although this might well be the case, other explanations need to be considered.
Familial clustering is well recognised in Paget's disease, with evidence of HLA linkage in some families and a greatly increased prevalence of the disease in first degree relatives of patients.
The unusual geographical distribution is equally compatible with a genetic component.
Paget's disease, while most common in western Europeans, also occurs frequently in their descendants in Australia and South Africa, where it is rare in the indigenous population.
What could the mechanism of genetic Paget's disease be?
Some parallels can be drawn with certain hereditary tumour syndromes such as multiple endocrine neoplasia.
Both are characterised by a focal or multifocal pattern of distribution, abnormal cellular proliferation, and a genetic component.
The hereditary tumour syndromes are thought to result from an inherited mutation in one allele of a tumour suppresser gene and an acquired mutation in the other allele.
Almost 20 years have elapsed since Rebel first noted ‘virus-like’ particles in pagetic osteoclasts, but the identity of these structures remains unclear and they are not specific to Paget's disease.
Immunohistochemical and in situ hybridisation studies have yielded conflicting results, since at different times evidence has been presented to suggest that antigens or nucleic acids from measles virus, respiratory syncytial virus, or canine distemper virus might be present in pagetic tissue or cultured cells but no virus has been isolated from affected tissue.
Several groups have now used the polymerase chain reaction to try to recover paramyxovirus sequences from pagetic bone.
Colleagues and I found no evidence of measles virus, canine distemper virus, respiratory syncytial virus, or related paramyxoviruses in RNA extracted from pagetic tissue, and M Birch et al recently reported similar findings.
Though canine distemper virus transcripts (and in one case measles virus also) have been isolated from pagetic tissue, these data must be interpreted with caution in view of the possibility of external contamination, since the same group had previously worked with probes to both viruses during earlier in situ hybridisation studies.
Finally, D Roodman et al recently reported finding measles virus transcripts in cells derived from cultured pagetic bone.
These contradictory data could perhaps be explained by different viruses having a role in different geographical areas.
The powerful molecular techniques now available should soon result in great advances in our understanding of Paget's disease.
An important immediate issue is to confirm whether paramyxovirus sequences can consistently be isolated from pagetic tissue and, if so, to determine whether their presence is disease specific.
Editor ,— Roger Smith underestimates the contribution that biochemical markers of bone resorption can make to the diagnosis and monitoring of Paget's disease.
Though urinary hydroxyproline and alkaline phosphatase are useful markers of bone resorption and synthesis, respectively, they are rather non-specific.
Though no good new assays exist to supplement assays of alkaline phosphatase to assess bone formation, more specific markers are becoming available for bone resorption.
Pyridinoline (also known as hydroxylysyl pyridinoline) and deoxypyrolidine (also known as lysyl-proline) are not further metabolised, thus providing a better index of resorption than hydroxyproline, which also has the disadvantage that it is found in skin as well as bone.
Pyridinoline and deoxypyrolidine are found in collagens I, II, III, and IX, so both are found in extracellular matrix collagen crosslinks, while deoxypyrolidine is more common than pyridinoline in type I bone collagen crosslinks: the ratio of pyridinoline:deoxypyrolidine is 3.5:1 in bone collagen as opposed to 10:1 in other collagens. –9 Released as a result of bone degradation, these markers can be measured either singly or together (to derive a pyridinoline:deoxypyrolidine ratio) by high performance liquid chromatography with fluorescene detection in 24 hour urine specimens and correlate well with rates of bone resorption.
Getting it right
Editor ,— Helen Zeitlin is wrong in claiming that my article about her reinstatement was unjust and incorrect.
She has misinterpreted an indirect quote from evidence given on behalf of the health authority as a statement of fact by me.
She knows that I am well aware that the 20 complaints referred to in that evidence were ‘unsubstantiated and had not even materialised,’ since I have covered her case in detail since the beginning.
In the paragraph of which she complains I was briefly putting each side's case as outlined to the inquiry.
Surely she is not suggesting that only her side of the case should have been put.
Part time senior registrar training
Editor ,— J E Morrell and A J Roberts warn of the difficulties of part time senior registrar training.
These are well illustrated by my own case.
Working full time, I completed my general professional training, gained the MRCP, and undertook research.
When I first applied for part time training in September 1984 I was interviewed within two weeks of the birth of my first child.
There was only one post for part time senior registrar training in general medicine in the whole country, and I was not successful.
The next year only one post was available, and again I failed.
My research post had been extended by my working part time, but in 1986 funding ran out.
I had an MD and had had several articles published, and I was totally demoralised, feeling better qualified than some colleagues in full time senior registrar posts.
Fortunately, the postgraduate dean organised a part time medical registrar post.
In 1987 my application was successful, although there was only one post.
I understand that the next year three posts were available.
Manpower approval was granted in January 1987.
The educational programme was submitted, but the college did not visit until October.
Its report was sent to my supervisors in February 1988, and after a few minor changes the college's final approval was received in May.
Wessex region would not recognise me as a senior registrar until the college's approval had been received.
I had two manpower extensions.
The senior registrar contract arrived dated May 1988, and a six month battle ensued to get it backdated to January 1987.
I was not a pioneer of part time senior registrar training in Wessex: several people were already in post.
Success in part time senior registrar training requires tremendous personal commitment, a sympathetic supervisor, and a helpful postgraduate dean.
I was fortunate, yet I can recall that during my earliest discussions there was considerable concern about how a consultant appointment committee might view part time training.
In my case, I am pleased to say, it was regarded in the same light as full time training.
As Morrell and Roberts say, the experience is an invaluable education for the battles in the NHS as a consultant.
Editor ,— Graham Thornicroft and Geraldine Strathdee discuss their experience of sharing a consultant post.
We have job shared for two years in several senior house officer posts in different specialties as part of our own scheme for vocational training for general practice.
We have found it to be the ideal way of combining pursuit of a career in medicine with bringing up a family.
There is considerable difficulty in getting shortlisted when job sharing, and consequently we have found that job applications need meticulous planning.
We submit our CVs with a joint covering letter explaining about job sharing, our reasons for choosing it, and how we would apply it to the advertised post.
Most consultants have never experienced job sharing and have preconceived worries about its possible ramifications.
We therefore believe that it is important to meet as many as possible, if not all, of the consultants before shortlisting, preferably together for a show of unity.
Before the interview it is important to discuss the duties of the post with the present incumbents, paying particular attention to rotas and the timetabling of commitments such as ward rounds, on take days, and postgraduate meetings.
It is then possible to decide how to split the hours of the job optimally while still maintaining as much continuity as possible.
We have always been interviewed simultaneously, which can be advantageous: over the years we have worked out quite a double act.
Questioning invariably centres on our domestic arrangements rather than our abilities: we both have young children and share a nanny.
For holidays we fall in with the wishes of particular consultants.
It is generally mutually convenient if we take our holidays together as a block (it also enables us to give the nanny time off).
Finally, interviewers are often hesitant to broach the question of one partner wishing to resign, so at interview we raise the issue and offer reassurance that should it ever occur the remaining partner would either also resign or take on the post full time.
Like Thornicroft and Strathdee, we emphasise the importance of trust and respect between the partners.
We believe that our strength comes from our friendship and having similar priorities in life.
Job sharing is not for the faint hearted: it demands complete commitment.
To work effectively it needs the right partners and considerable organisation and communication.
It is still a novel concept, and potential job sharers should be aware that they will be breaking new ground and that their  performance may have considerable influence on the future of job sharing in medicine.
Editor ,— We are two female general  practitioners working as equal partners in a job share.
We share the considerable advantages of this arrangement with our patients and our practice.
As mothers and doctors we benefit from being able to continue our medical careers while devoting ourselves to our families; our patients have access to female doctors sympathetic to the experience of raising a young family; and our practice is enriched by our contributions on the broadest range of issues from the clinical to the practical.
The importance attached to maintaining a job share position in our practice is such that one of us was appointed only weeks before going on maternity leave.
The remaining job sharer intended to provide locum cover for her absent partner in order to provide continuity of care to patients and ensure the minimum of disruption to the practice.
Through its ruling in paragraph 49.7 of the red book, however, the Department of Health attaches a financial penalty to such a logical and mutually beneficial course of action.
It states that during periods of confinement the locum costs arising will not be reimbursed if the locum is a member of the practice.
In her editorial Vivienne Van Someren suggests that arrangements for job sharers are often an afterthought.
Our current predicament leads us to doubt whether any thought was given to job sharers when this restrictive and unhelpful legislation was drafted.
The disadvantages this brings to us, our patients, and our practice are many.
Instead of enjoying her leave one of us has been forced to spend days on the phone in search of locums while the other is deprived of the option of completing extra surgeries in her own practice with her own patients.
The patients in turn are faced with a cocktail of locums, who, despite our best efforts, have been primarily male.
Finally, our practice has expended valuable energy and resources in trying to negotiate, without success, a more sympathetic interpretation of this ruling from the family health services authority.
The matter now rests with our local medical committee.
Our daily experiences lead us to believe that the benefits of job sharing in general practice should be extended beyond the 1% of principals mentioned by Van Someren.
A frank and focused reassessment of, for example, the financing of locum cover during maternity leave would be a positive first step towards normalising the position of job sharers in general practice.
Editor ,— Stress levels are known to be high in women trying to balance their career in medicine with domestic commitments.
For overseas women the problem is compounded by struggling to achieve some status in the adopted country and meeting the domestic commitments peculiar to their cultural background.
The regulations state that to work part time one must be looking after small children or caring for disabled relatives, but there are many more reasons why women would want to work part time.
Other responsibilities exist, especially in an ethnic setting, like caring for elderly though not necessarily ill relatives, taking care of dependents, and managing a full household.
It is rare for an overseas couple to find jobs in the same area — most travel to obtain a job wherever offered.
The question commonly asked at interviews, ‘What specialty are you interested in?’ becomes largely irrelevant.
The choice is clear — you take the job that is at the status you require (never mind the specialty) wherever it is offered, or take a job below your grade in the area where your spouse works.
No marriage can survive over long distances in the long term, especially if all the effort culminates in the eventual failure to obtain that elusive consultancy.
The process of applying for part time jobs is long drawn out and tedious.
Of the many drawbacks the most ludicrous is that applications can be made only once a year at a certain time.
The processing of applications takes four to six months, or more, so that missing the deadline or failing to be appointed means wasting an entire year.
The appointment committee is hurriedly and randomly selected.
No effort is made to choose a panel who are committed to further part time training, and rarely are women doctors put on the interview panel.
Few if any members are apprised in any detail about the background of the candidate, rules and regulations about appointment, or — most importantly — the eligibility criteria.
These criteria need proper definition: although in an open competition one may fail to get the job because of another superior candidate, in this situation (where there may be no competition from peers) the shortlisted candidate may still be rejected — not for performing badly at the interview, but on technical grounds by poorly informed committee members.
Once appointed at a grade lower than one should be one has to face up to colleagues who are uncertain about the role and the duties of the candidate.
Expecting part timers to perform full time duties is difficult to dislodge, and the temptation to use them as ‘fillers’ for odd jobs remains.
The drop in salary for part time work is perfectly logical and acceptable, though not widely appreciated by colleagues.
What is incomprehensible, however, is the loss of status that goes with part time work.
Much thought is required to smooth the path if this scheme hopes to meet with success.
Editor ,— The BMJ is to be congratulated on highlighting the difficulty doctors have when they seek to train and work in the hospital service on a less than full time basis — a reasonable aspiration when you realise that the average working week for people other than doctors is 37.5 hours yet for doctors half time can be in excess of 40 hours.
Now that 45% of those qualifying are women we can no longer ignore the needs of those reluctant to work over 72 hours a week.
Because of the low status of part time training and the realisation that it makes the period between registration and achieving a consultant post even longer, the proportion of doctors training part time has dropped as the proportion of women graduates has increased.
What none of us know is whether this drop indicates that doctors are leaving medicine altogether.
What we do know from Allen's recent survey of part time working in general practice is that many women working in general practice would have preferred hospital practice, particularly paediatrics, obstetrics and gynaecology, and general medicine, if they could have trained in these specialties part time.
Could it be that there are many doctors not working because even in general practice part time opportunities are sparse?
The Medical Women's Federation has been pressing the Department of Health to introduce more flexible arrangements to encourage less than full time training.
Correspondence on this issue in the BMJ would be helpful in clarifying whether doctors are giving up medicine altogether because of the lack of opportunity to train and work over shorter hours.
Editor ,— I was astonished to read that 11% of female registrars work part time and that the aim is to quadruple this number over five years.
This figure must apply only to England and Wales, since the PM(79)3 and EL(91)5 schemes do not yet exist in Scotland.
I understand that the Scottish Home and Health Department has set up a working party to consider this issue, but as yet no recommendations have been made.
At present those wishing to work part time in Scotland must job share, which is dependent on finding a suitable sharer in the right location.
Editor ,— In her editorial on part time working and job sharing Vivienne Van Someren gives a useful list of sources of information.
For the past seven years I have run a job share register on behalf of the British Paediatric Association.
Paediatricians at any grade are welcome to contact me for names of suitable job sharers or simply for general advice if they already have a colleague with whom they wish to share.
Editor ,— Those of us who have trained part time owe our careers to the senior registrar (PM(79)3) scheme.
This, however, must be looked at with regard to aspects of employment law.
The scheme has stringent criteria for domestic commitments.
Marriage is not considered a sufficient commitment.
Pregnancy is acceptable, but should a woman lose her baby she will lose her right to apply for such a post.
These posts take longer to arrange than a full term pregnancy: a cot death could therefore also deprive a mother of her domestic commitment before her job has finally been arranged.
The time is long overdue to free part time training from such draconian requirements.
Many of life's experiences, whether as parent, carer, musician, or even rugby international, can add to a person's contribution to medicine.
Editor ,— As a female consultant and a member of the Joint Working Party on Flexible Training, recently convened by the Department of Health, I was delighted to see the editorial and supporting articles dealing with part time (now called flexible) training.
The Joint Working Party has felt very strongly that doctors may wish to spend only part of the training period working flexibly and that flexible training opportunities must be tailored to trainees' needs.
I must correct some points of detail in the article.
The quotas of manpower approvals are not determined by the Central Manpower Committee but rather by the request of individual specialties to the Joint Planning Advisory Committee at the time of the specialty review.
These reviews are usually held triennially (and under certain circumstances more frequently) and the flexible training topslice adjusted in the light of demand within the specialty.
The information on obtaining funding for a part time senior registrar post given by J E Morrell and A J Roberts will soon be superseded.
From 1 April 1993 all the costs of part time posts (at all grades) will be held by regional postgraduate deans.
Although funding has been a problem for some flexible trainees in the past, these new arrangements should improve this aspect of the arrangements considerably.
The Joint Working Party on Flexible Training has been meeting to consider in detail the arrangements for part time training at senior registrar level and the need for a formal scheme for other grades.
Its report, which is expected early this year and will be widely available, makes several recommendations which if accepted will improve the transition from full time to flexible working.
One recommendation has already been implemented: the agreement by the BMJ and the Lancet to include a separate heading in the classified advertisement for part time posts.
Architecture of cancer
Editor ,— Although there are inherent difficulties in condensing such a complex subject as the metalloproteinases to a form that is concise and comprehensive, two aspects require further emphasis.
The first point is the question of the cellular source of the metalloproteinases.
An increasing body of evidence suggests that the desmoplastic stroma in the vicinity of the tumour epithelial cells is responsible for the synthesis of these enzymes and not the tumour cells themselves as Jonathan Waxman and Harpreet Wasan's editorial implies.
Poulsom et al have shown augmented signals for the messenger RNA of 72 kDa gelatinase and tissue inhibitor of metalloproteinase 2 in the stroma in an in situ hybridisation study of colorectal tumours.
Basset et al have identified a metalloproteinase gene for stromelysin 3 which at the level of messenger RNA is localised to the stroma.
Collagenases are products of fibroblasts and are up regulated in tumour stromal cells.
Studies performed in my institution on 39 colorectal carcinomas showed a stromal localisation of stromelysin and gelatinase.
Their inhibitor, tissue inhibitor of metalloproteinase 1, was also found in the stroma but had a predominant endothelial distribution (N C Gallegos et al personal communication).
Although the concept of tumour cells producing degradative enzymes is appealing, particularly in the light of Liotta's three step theory of invasion, it is now becoming clear that production and regulation of metalloproteinases in health is a delicate host derived balance.
Biological response modifiers such as cytokines and growth factors released in peritumoral tissues, perhaps by the neoplastic cells themselves, may well be implicated in their activation.
Cell-matrix interactions may also play a part through signal transduction mechanisms.
Inhibition of metalloproteinases, therefore, may not itself break the autocrine loops of proliferation and destruction that are created in pathological conditions such as cancer.
Secondly, much of the evidence presented in the editorial (and this letter) is based on hypotheses derived from models of invasion and metastasis that may bear little relation to the function of metalloproteinases in vivo.
Further investigations are urgently required if the ‘futuristic technologies’ are to bear any fruit.
Avoiding exposure to HIV and hepatitis
Editor ,— The guidelines of the joint working party of the Hospital Infection Society and the Surgical Infection Study Group are valuable in detailing the precautions that surgical staff should take to prevent transmission of hepatitis B and C viruses and HIV.
Yet the advice to surgeons about ways in which transmission of these viruses might be avoided during operative procedures is deficient in that it fails to mention techniques of monitoring any breaches in the integrity of the barrier between the patient and surgeon.
Several studies have shown that gloves are perforated in 12–25% of procedures, although at least one report has suggested that the failure rate of gloves is as high as 52%.
More importantly, surgeons are aware that such a perforation has occurred in only 15–50% of cases.
The knowledge that the barrier between the patient and surgeon has remained intact throughout the procedure is arguably the best reassurance for surgeons and theatre nurses regarding protection.
We believe that the development and evaluation of devices to measure this is the most practical and appropriate way of implementing the recommendation of a working party of the Royal College of Pathologists that further research should evaluate measures aimed at preventing blood contact between patients and health care workers.
Reports have shown that even with simple technology surgeons can be warned of breaches in the barrier, with low false positive and false negative rates.
We are evaluating a more sophisticated electronic device which allows the entire theatre team at risk to be monitored with minimal inconvenience.
Early results have shown that the device has a high sensitivity and specificity.
We believe that the joint working party's recommendations should include the routine use of such a device for people caring for patients who are known to be positive for HIV or hepatitis B virus and for high risk patients.
It could be argued that such a system is valuable in all high risk operations: it provides reassurance not only for the surgical teams but also for patients who are operated on by a surgeon in whom seroconversion subsequently occurs.
Editor ,— It is recommended that health care workers in all departments should protect the mucous membranes of their eyes from blood splashes to avoid exposure to HIV and hepatitis.
In Britain surgeons and theatre staff rarely wear eye protection unless they wear glasses for their eyesight or are treating high risk patients.
It is increasingly common for practitioners other than surgeons, such as general practitioners and dermatologists, to perform surgical procedures under local anaesthesia.
I have assessed the risk of eye contamination during outpatient surgical procedures performed under local anaesthesia.
Over six months I recorded blood spots on the front of a single pair of eye protection glasses (Surgikos).
I wore these while excising small skin lesions (for example, pigmented naevi).
Blood spots were detected after 37 of 168 procedures.
They varied in number from one to 24 (mean five) spots per procedure.
Occasionally, blood contamination seemed to be related to use of a unipolar diathermy.
In 148 of the 168 procedures I recorded whether I used diathermy.
I performed 39 procedures without diathermy, and contamination occurred in four.
Contamination occurred in 26 of the 109 cases in which I used diathermy.
Only a minority of the blood spots on the glasses would have entered my eyes (the glasses were fairly large, at 16.5×5 cm), but my experience suggests that the eyes are at risk of contamination even in minor surgical procedures carried out under local anaesthesia, especially if diathermy is used.
Minor procedures are often carried out by junior surgical trainees and, increasingly, by general practitioners and dermatologists and in accident and emergency departments.
It seems advisable for practitioners  who do not normally wear glasses to use simple eye protection glasses for routine cases.
These are usually available or can be bought for less than £5 from opticians.
In high risk cases more elaborate protection is indicated.
Editor ,— The guidelines on precautions regarding transmission of HIV and hepatitis B virus during invasive procedures and on managing exposure to blood or body fluids contain several inaccuracies.
Firstly, the authors suggest that hepatitis B virus can be transmitted through blood contamination of intact skin, although there is no evidence for this.
Secondly, giving a second full course of vaccine without  determining whether the person being vaccinated is an infectious carrier would mean that the person could potentially transmit infection for at least six months before being identified.
Furthermore, if the suggestion to test for hepatitis B e antigen alone is followed people who are either positive for hepatitis B core antibody and therefore likely to be immune or positive for hepatitis B surface antigen but negative for hepatitis B e antigen would be revaccinated inappropriately.
The statement that ‘HIV is less transmissible than hepatitis B virus, requiring hollow needles and larger volumes of blood,’ is misleading.
Although the risk of transmission of HIV is greater with a hollow needle, at least one case of transmission associated with an injury with a solid needle has been reported.
More importantly, the degree of risk is related to the amount of virus in the inoculum, which in turn is related not only to the volume of blood but also to the concentration of virus in it.
Indeed, the concentration of HIV has been found to be up to 1000 times greater in symptomatic than asymptomatic patients.
We are worried that the statement that ‘mucous membranes are an important defence against HIV’ may deter surgeons from taking appropriate measures to protect exposed mucous membranes.
Althouth the risk from this sort of exposure seems to be less than that from percutaneous exposure, there are documented cases of occupational acquisition of HIV through mucous membranes.
In the section of the article entitled ‘Managing inoculation incidents in theatre’ the authors seem to discourage surgeons from reporting ‘minor sharps injuries, without bleeding,’or injuries involving a patient not deemed to be at high risk.
All sharps injuries should be reported through official channels and advice and treatment given.
Surgeons should not be burdened with the responsibility of assessing their own degree of risk.
The authors state that a baseline blood sample may be requested from someone who sustains a needlestick injury, whereas a baseline blood sample should always be taken after occupational exposure.
As virologists, we believe that the article shows a lack of understanding of the terminology and epidemiology of hepatitis B virus and HIV.
It would have been helpful if the report's compilers had included a clinical virologist.
Irish vote against abortion
Editor ,— Alan Murdoch's report on the Irish referendum on abortion was inadvertently misleading.
The pro-choice forces in the republic advised voters to vote ‘yes’ to travel abroad for abortion, ‘yes’to receive information about abortion services (both of which they did in large majorities), and ‘no’on the ‘substantive’issue because the preceding judgment in the Supreme Court was in fact more liberal: it permits abortion in Ireland if the woman threatens suicide.
The voters voted ‘no’ for this reason.
That this was essentially as liberal a vote as the wording permitted, for legal abortion at home, is borne out by a national opinion survey carried out before the election for the Irish Sunday Press .
This found that 7% of Irish voters wanted abortion to be legal under all circumstances and another 57% wanted it to be legal under certain circumstances.
Only 31% wanted it to be illegal in all circumstances, and 5% were undecided.
Interestingly, among women aged under 35 only 20% wanted to see abortion remain illegal under all circumstances.
So future trends are clear.
Tomlinson report
Editor ,— I agree with J D Swales's contention that the Tomlinson report will damage postgraduate education if it results in weakening of the vital links between the special health authority hospitals and teaching in the postgraduate research institutes.
Swales should not  conclude , however, that the report will redress perceived inequities in the balance of research and teaching resources between London and the rest of Britain.
There are wider implications: what is happening in London today is likely to happen in the rest of Britain tomorrow.
The consequences for clinical research across Britain may be grave.
The core role of the special health authorities and their institutes is clinical research, and their  educational function stems from this.
The cost of the clinical consequences of their research is currently met by central funding, their research itself being paid for by the Medical Research Council, charities, and the pharmaceutical industry.
In the future the special health authorities will have to raise funds by selling beds on the open market.
Purchasers may buy clinical care but will not want to pay the extra costs attributable to research.
While this problem is acute in London, researchers elsewhere will face similar problems as market forces compel hospitals to reduce costs as much as possible.
Vital research may be squeezed out.
It is wrong to suggest that London's research based hospitals fear the market.
They welcome the opportunity to compete and are confident that they can prosper.
It is vital, however, that they are able to compete on equal terms, and to achieve this there will need to be funding for the extra costs of clinical research.
If Britain is to maintain its tradition of excellent clinical research adequate support must be provided for the clinical costs of research.
As I have argued previously, this should be through a national market for research, which would be open to research hospitals all over Britain.
Such a mechanism could enhance our national ability to compete with other world class research communities.
The internal market is bringing about profound changes in the NHS.
The entire medical research community should unite to make sure that the changes do not damage our ability to carry out world class clinical research that benefits the physical and economic health of the nation.
Indeed, we should ensure that our ability is enhanced.
To see the Tomlinson report as a question of London versus the rest would be a mistake and a missed opportunity.
Editor ,— The widely held view that there is an overprovision of acute medical services in inner London—9 is not shared by orthopaedic surgeons working in the capital, who are unable to provide a satisfactory service for their patients with the resources currently at their disposal.
In January last year details of the workload and the resources available to meet that workload were collected by the British Orthopaedic Association directly from consultant orthopaedic and trauma surgeons working in the 19 general hospitals in the 12 health districts in inner London.
These were compared with similar figures derived previously from the orthopaedic departments of 17 district hospitals randomly situated throughout England.
The equivalent of 48.9 maximum part time consultants worked in the inner London hospitals, sharing 53 orthopaedic trainees (1.08 per consultant); this compared with 30.5 maximum part time consultants sharing 22 career trainees, outside London.
In addition, however, outside London there were 11 dedicated orthopaedic staff who were not in training grades.
When these are included with the trainees the ratio becomes 1 consultant to 1.08 assistants.
Thus the ratio of consultants to orthopaedic assistants is the same in inner London and outside London.
The annual outpatient workloads were also similar, and, assuming a similar case mix of new patients, it might be expected that a similar volume of inpatient work would be generated.
In fact, there were 30–9650 discharges and deaths in inner London compared with 26–9365 in the provincial sample in the year under review, but because there were fewer consultant surgeons in the provinces each team treated an average of 864.4 inpatients compared with 626.8 in London.
The London surgeons, however, had only 938 beds regularly available (an average of 19.2 per team) compared with 988 (32.4 per team) outside London, but they treated 32.7 patients per bed compared with the 26.7 treated by their colleagues outside London (49% and 42%, respectively, were elective admissions).
Although the consultants in London seemed to use their beds more effectively, 1912 patients (an average of 39.1 per consultant) had been waiting over a year for admission, which implies a lack of resources.
There is no way of knowing accurately the population served by the hospitals in inner London, and patients seek treatment in inner London for various reasons.
To the resident population of inner London must be added the one million commuters estimated to travel into the city each day as well as visitors and the increasing numbers of homeless people.
They have no choice when requiring emergency care.
Clearly, the orthopaedic resources in inner London are inadequate to meet current needs.
Whatever the future pattern of health care in London, it must make adequate provision for the demands likely to be made in the immediate future.
The only reliable guide to that is the demand at present.
Editor ,— Sir Bernard Tomlinson's report on medical care in London seems to assume that many of the demands for care made on teaching hospitals in inner London could be satisfied by general practitioners and thus the need for acute beds in London would fall.
–9 There is no evidence to support this assumption.
In the past year 13% of practices in the area served by Lambeth, Lewisham and Southwark Family Health Services Authority have kept detailed records of their consultations and referrals to hospital outpatient departments.
The data collected were analysed by the department of general practice at the United Medical and Dental Schools of Guys and St Thomas's Hospitals.
The practices concerned had 129000 registered patients and carried out 413–9000 consultations, which led to 17121 referrals to a named hospital in one year.
For these practices the overall consultation rate was 3.2 per patient per year, which is not dissimilar from the national average.
The rate of referral to hospital was 4.2 per 100 consultations or 13.3 per 100 registered patients, which is similar to the results reported by Wilkin and Smith in Manchester and by Bradlow et al in Oxfordshire.
In a study supported by the King's Fund a further, larger, sample of general practitioners recorded the problems they encountered in arranging acute admissions to hospital.
Over seven weeks 493 acute admissions to hospital were recorded by 111 general practitioners.
By extrapolation it is estimated that, over one year, there were 16 acute admissions to hospital from the practices per 1000 registered population, a figure identical with that in the third national morbidity survey.
Although the sample of doctors studied in these surveys was not random, neither were the samples studied in Manchester, Oxfordshire, or the national study.
Within the limits of the surveys described, evidence suggests that general practitioners in inner London are little different in their referral behaviour from those outside London.
Improving doctors' premises, which is essential, will undoubtedly lead to better care and promote the development of primary care teams but may not influence the doctors' referral behaviour and the need for acute beds in London.
Editor ,— Stanley Dische highlights the relative underprovision of radiotherapists (clinical oncologists) and medical oncologists by comparing London and south east England with Paris and the Ile de France.
I support his view that the service provided in the Thames regions should not be reduced.
I cannot, however, accept his statement that ‘when allowance is made for university posts and the commitment to research there is no indication that London and the south east are better provided for than the United Kingdom.’
The table shows the imbalance when the West Midlands is used for comparison.
Clinical oncologists give most of the chemotherapy outside the Thames regions, and this is a considerable burden.
The underprovision of clinical and medical oncologists remote from the south east of England is real, and the disparity cannot be passed off as being due to university and research commitments.
Furthermore, the days when London was the focus of excellence in research are long gone.
It is time that these facts were addressed.
Looking through a bubble
Editor ,— In their photographic report of a patient with a bubble of gas trapped within his cupped optic disc Lumina P Lanigan and colleagues ask, ‘If the optic disc represents the blind spot in the visual field, why was this patient aware of such bubble sight?’
There are no photoreceptors at the head of the optic nerve, and hence this area forms the blind spot.
The gas trapped within the cupped optic disc will adopt the shape of maximum volume and least surface area and will thus present a spherical anterior surface, which will protrude into the posterior vitreous face.
This interface will function optically as a convex mirror, and light incident on it — which normally would not be perceived because it would fall on the blind spot, will be reflected back into the eye.
This light will interact with other incident light through the optical phenomenon of interference, and this will degrade the quality of the retinal image around the optic disc, which the patient perceived ‘as looking through a bubble.’
The politics of poverty and health
Dear Virginia ,— Before Christmas last (22 October), you were reported in Hansard , during a debate on The Health of the Nation , as saying: ‘I have degrees from Essex University and the London School of Economics, I have worked for the Child Poverty Action Group, and have lived with the  defeatist talk that we are hearing from the hon Gentleman [Mr David Blunkett].’
Mr Blunkett had been reviewing some of the scientific evidence about the connection between deprivation and ill health or premature death, and immediately before your intervention had referred to children in social class 5 being six times as likely to be burnt or knocked down in accidents as those in social class 1.
‘Those who live in overcrowded conditions in slums or high-rise flats, or are forced to suffer the congestion and fumes of the inner city, are clearly in a less advantageous position than those in social class 1…
No one needs to be a genius to know that living in squalid conditions worsens health.’
Your intervention clearly implicates myself in the charge you make of ‘defeatist talk’ about the scientific connection between material deprivation and premature death.
I taught at the London School of Economics, I was head of the department at the University of Essex in which you were an undergraduate, and was in fact your personal tutor.
Moreover, I was chairman of the Child Poverty Action Group at the time when you were commissioned to do research and prepare a pamphlet on ‘Families with low income in London.’
I was also coauthor of the Black report on ‘Inequalities of health’ and continue to play a part in debates on that subject.
You were employed at the Child Poverty Action Group on the basis of a generous grant from the Noel Buxton Trust and the City Parochial Foundation.
Your 1971 report gives a sensitive account of the difficulties of these poor families and gives precise evidence of the inadequacy of their incomes.
Indeed, your report contains a section on health which shows that ‘sickness was a notable phenomenon among these families,’ and also that many of the families failed to use a variety of health service facilities because they ‘could not afford’the charges.
From your speech in parliament and from a wide variety of other speeches I understand that you no longer agree with the evidence you accepted in 1971.
What is indisputable is that as an undergraduate and then as a research worker for Child Poverty Action Group, far from regarding such evidence as ‘defeatist talk’ you not only accepted it but added to it.
In the published version of your parliamentary intervention you admit that ‘there is an association between health and all the factors that he [David Blunkett]has mentioned’ but go on to claim that health variations are being examined as part of The Health of the Nation strategy.
This was not only vague.
The all important relationship between material deprivation and ill health was not discussed in your speech.
Your statement misrepresented the educational influences upon you in your early career and sought to excuse your failure to deal with the established links between poverty and ill health.