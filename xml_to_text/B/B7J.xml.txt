

Leading question
THE DAYS of lead in petrol seem to be numbered.
This is not because of any sudden blinding scientific revelation proving that lead — added to petrol to make cars' engines run more smoothly — dissolves children's brains.
If anything recent research suggests that lead isn't as horrid in its effects as the extremists in the anti-lead movement claim.
Any research on something as complex as intelligence or the biological effects of very low levels of a substance is bound to be difficult, not least because so many factors are involved.
Does the lead cause the lower ‘IQ’?
Or are those with lower IQs more likely to be exposed to lead because of social factors?
Indeed, how you measure something as sensitive as intelligence poses problems.
The very people who are campaigning against lead in petrol might normally be associated with moves to stamp out ‘elitist’ IQ tests.
Correlations between behaviour and exposure are open to all manner of interpretation.
It would, for example, be possible to link odd religious cults with the absence of lead in petrol.
(California eliminated lead from petrol before anywhere else — as an anti-pollution measure — and that state gives rise to more fringe cults than any other.)
No one would place much credence on such a suggestion, but are equally batty notions finding favour with the anti-lead movement?
Having said that, we do know that large amounts of lead are harmful.
No one knows for sure when the levels become safe.
That being so, why not eliminate lead from petrol?
At one time it seemed that the best approach to the problem would be to reduce the level of lead in petrol, but not to eliminate it altogether.
That would have reduced exposure; but it is so small a step from cutting the level to removing it altogether that perhaps that is now a wiser move given the shift in public opinion.
There are other factors that recommend elimination, not least being the fact that everyone else is moving in the same direction; so if British car makers want to sell their vehicles abroad, as surely they must, they must make car engines that run without lead.
And taking lead out of petrol would immediately mean that workers in oil refineries would no longer be exposed to the substance.
The company that makes the lead additives that are trickled into our petrol has another answer to the problem.
It believes that every vehicle should have a sophisticated exhaust that traps the lead and prevents it from reaching the atmosphere.
Such a solution does not bear a close scrutiny.
It would work, but why adopt something that complicates an already complex technology?
It would be uncharitable to suggest that the lead makers prefer this line because it not only keeps them in business, but shifts the immediate cost to the motorist and gives the motor components business a chance to make more money.
Of course, the motorist will pay for lead-free petrol in the long run.
That is how it should be.
Indeed, that is what all pollution control is about — people paying to live in a cleaner environment.
If, as seems likely, there is considerable public support for ridding petrol of its lead burden, then why not act?
There are times when public opinion isn't the best way to decide a technical issue, but in this case the harm done would be minimal.
The benefits might be small, too, but the costs are hardly staggering.
Research counsel
A BATTLE royal over who is to fill the current vacuum of leadership in European science planning is now on the cards.
The major combatants will be the Council of Europe and the European Economic Community, The EEC's commissioner for industry, Etienne Davignon, has been trying to sort out the EEC's scientific programmes.
He wants to hammer out a way of relating its rather unexciting research sponsorship to the need to foster collaborative research on new ideas in European industry.
One of the major aims of the shake-up is to de-centralise research — to develop programmes at local centres of expertise.
The EEC does offer grants to academics for research on approved projects; but so far it has been unable to help with the major problems of the academic researchers, such as shortage of jobs, lack of mobility of researchers and declining funds for research.
These problems were highlighted in a report issued by the EEC itself, from a survey carried out by the European Science Foundation.
Reports from the OECD and NATO's science committee have come to similar conclusions, but so far no one has quite got it together to act on a Europe wide scale.
Now it looks as though the Council of Europe might step in and establish a small network of centres of excellence for postgraduate research and training.
The scheme could prove convenient for the European Science Foundation, which has a hitherto peripatetic post-graduate training programme in brain and behaviour research.
The ESF wants to find a home and a new sponsor for this activity.
And the ESF, just down the road from the Council of Europe's building in Strasbourg, may well be in on the planning, particularly in areas in which the Council of Europe does not yet have its own contacts.
Small centres of excellence are a good idea; and bringing together a group of experts in a subject could produce some interesting research.
But what about the undergraduate students back home who also need stimulation by brilliant people?
And what happens when one generation of  whiz-kids runs out of steam and needs to be replaced?
The Council of Europe also needs to be sure that it can avoid the stagnation, bureaucratisation and expense that have often — but not always — characterised international ventures.
The Council may also try to draw up a science policy for Europe, if it is serious about this it will have to soil its hands a little more with the sharp end of applied research.
THIS WEEK
Military fears prompt American trade ban
THE US is blocking the sale of satellite equipment to China.
It seems American officials fear that the technology could be diverted to military purposes.
China wants to buy, from America, a $12 million ground station that can receive pictures of Earth from the US's Landsat-4 remote-sensing craft.
Chuan-Shan Wang, a top Chinese space official, told New Scientist that his country reached agreement on the sale with NASA.
But other parts of the US government stepped in.
Wang, the chief engineer at China's space science and technology centre in Peking, said the delay is because the US believes the hardware could be used for military purposes.
According to Wang, the American government is particularly concerned about selling tracking equipment and computers for recording data from the spacecraft.
Under guidelines drawn up by the US government last August, a company called Systems and Applied Sciences Corporation was due to supply the equipment.
China has ambitious plans in space technology — and it has shown it can launch nuclear warheads.
With its own rockets China has launched 12 satellites into low orbits above the Earth.
Within the next year, a new more powerful launcher may take up a craft that will hover 36000 km above the Equator.
China's satellite launchers are based on vehicles that can carry warheads.
The FB-1, or Long March-3, the country's latest launcher, is derived from the CSS-X-4 intercontinental missile which has a range of 11 000 km.
Rocket tests are carried out at a missile centre at Shuan-ch'eng-tsu or at a nuclear test range in Lop Nor.
For its missiles to be effective, China would require a source of data about possible targets.
These could be in the US, USSR or India.
Such data can be obtained not only from military reconnaissance satellites, of which China launched three between 1975 and 1978, but also from the latest civilian satellites.
China may also need satellite pictures to watch for troop movements on borders.
Landsat-4 obtains data with two sensors.
The  multispectral scanner provides pictures of the ground with a resolution of 80 metres.
The more sensitive thematic mapper provides pictures in which objects just 30 m wide can be picked out.
The outer space committee of the United Nations believes that remote-sensing satellites with a resolution of 25 m could be militarily useful.
The argument about the thematic mapper data from Landsat-4 is, to some extent, academic.
Hardware on board the craft transmitting data from the mapper has recently suffered a fault, leaving the low-resolution data the only kind available to ordinary ground stations.
The US will, however, be able to pick up thematic-mapper information with a ground station at White Sands, New Mexico, to which data will be routed via the US's new tracking and data relay satellites.
The space shuttle launched the first of these last week (see below).
But future Landsat craft can be expected to carry sensors at least as sensitive as the thematic mapper.
Moreover, France plans in 1985 to launch a remote-sensing vehicle called Spot that will provide pictures with a resolution of just 10 m.
China says it wants to ensure its receiving equipment can pick up signals from Spot, which will transmit at a similar frequency to the thematic mapper.
The row over Landsat equipment comes on top of a dispute over a ground station that China has set up in Peking, with American help, for receiving data from US and Japanese meteorological satellites.
An American company called P & P Industries provided the hardware.
But Washington did not permit the export of software that would provide high-quality processing of the raw data.
Again, the Pentagon's fears that the computers could be used by the military defeated the Commerce Department, which sees the sale of advanced technology as crucial to improved Sino-American relations.
The banned software was the ‘sources’ code from which the machine's internal language is derived.
Instead China got an ‘object’ code which could not be converted for military tasks.
NASA nudges satellite into orbit
Engineers at NASA still have no idea why the launch of the space shuttle Challenger's first payload went wrong last week.
During a near-faultless flight by the shuttle itself, a rocket failure left a $100 million tracking and data relay satellite (TDRS) tumbling in an orbit far short of its proper position, 36 000 kilometres above Brazil.
Controllers regained contact with the satellite after three anxious hours, and discovered that it appeared to be in full working order.
Engineers hope to nudge the satellite into a good approximation of its planned position by firing its own small thrusters.
‘We have come through a very critical emergency and come out in good shape,’ aid NASA's satellite programme director, Robert Adler.
The failure happened as the US
Air Force's Inertial Upper Stage rocket was lifting the satellite to geostationary orbit.
Instead, it put the spacecraft into an elongated orbit carrying it between 21 600 and 34 200 kilometres above the Earth.
It is not the first time that NASA has had trouble with the upper stage.
The rocket had a minor problem during its first launch last October.
During that venture the spacecraft suffered a brief radio blackout.
NASA later traced this to a faulty switch.
The loss of communication did not affect the mission.
The latest setback could scramble the shuttle's schedule in two ways.
First, it could hold up Challenger's next attempt to launch a relay satellite, in August.
Second, the European Spacelab, which the shuttle should launch in September, will need the relay satellites to be in place to carry out some of its work.
Radiation experts row over lethal dose
RADIOLOGISTS are in sharp disagreement over the effects on the British population of a nuclear attack.
Heat has entered the debate because the Medical Research Council (MRC) has submitted secret advice to the Home Office which claims that deaths after an attack may be lower than almost any published estimate — and certainly lower than those predicted by the National Radiological Protection Board (NRPB), which has the statutory responsibility to advise the government on radiation hazards.
At the root of the argument is an assessment of the lethal dose (LD 50 ) during a bomb attack — that is the amount of radiation which will cause 50 per cent of the population to die within 60 days.
The MRC's Protection Against Ionising Radiation Committee has reported to a Home Office working party its assessment that the LD 50 for humans is a surface exposure to the body of 600 rads.
This is the  equivalent of a 450 rad dose to the bone marrow.
The NRPB's estimate of the LD 50 , published in 1979, is a bone marrow dose of 350 rads — more than 20 per cent less.
The Royal Commission on Environmental Protection in 1976 came up with an even lower figure of 250 rads.
The point is more than arcane.
John Martin, the chairman of the Home Office working party, says ‘a striking feature of the dose-response curve is its steepness.
A dose of 20 per cent less than the LD 50 will kill few and a dose of 20 per cent more will kill over 90 per cent’.
He predicts that, while 50 per cent of people would die from a dose of 600 rads, only 5 per cent would die after a dose of 400 rads.
The MRC's figures are way out of line with those produced in the US.
There the National Council on Radiation Protection and Measurement believes that a 600 rads surface dose would kill 90 per cent of the population, rather than 50 per cent.
But the MRC's figures may now be used as a basis for new — and presumably much lower — estimates from the Home Office of the likely number of deaths from a nuclear attack on Britain.
As a result of the MRC's calculations Martin claims, in an article in the spring issue of the Journal of the Society for Radiological Protection , that ‘300 rads average bone marrow dose is unlikely to kill more than a small percentage of those exposed’.
The NRPB figures suggest that this ‘small percentage’ may be some 30–40 per cent of the population.
A new assessment of the radiological effects of nuclear war published by a working party of the British Institute of Radiology suggests that, even assuming that the MRC's new guess of the LD 50 is correct, most of Britain's population would stand little chance of surviving a nuclear attack.
The working party postulated a 200-megaton attack on Britain involving low-level explosions.
This is the official Home Office scenario.
It assumed (again, as the Home Office does) that the fallout from  the explosions would be distributed evenly across England and Wales.
Over the following fortnight, during which the Home Office recommends that people cocoon themselves in some form of shelter, the dose of radiation For each individual not in a shelter would be 450 rems.
‘Clearly only people with adequate shelter would survive,’ it says.
After 14 days, says the Home Office, people should emerge from their shelters.
What will they find?
The working party is clear.
‘Doses would remain large for a very long time…
The dose commitment on emerging from the shelter after two weeks would be no less than 1700 rads and the daily dose at that time would be 46 rads.
It would evidently be impossible to resume normal living conditions for a very long time after fallout of the assumed density.’
Most of the fallout would remain in the environment.
Weather would ‘redistribute rather than remove the activity’ and ‘ingestion of the longer-lived isotopes from crops grown on contaminated land would be an additional hazard’.
Soviets star-gaze with world's largest telescope
The SOVIET UNION has launched a new space observatory, which carries the largest telescope now in orbit.
The satellite, called Astron, is intended to study ultraviolet radiation and X-rays from celestial objects.
Astron, weighing 3½ tonnes, is in a highly elliptical orbit which takes it from a height of 2000 km up to 200 000 km, half way to the Moon.
It takes four days to complete one orbit of Earth.
Astron's main instrument is an ultraviolet telescope developed jointly with the French.
It has a main mirror 0.8 metres in diameter.
This is almost twice the size of the only other ultraviolet telescope now in orbit, the International Ultraviolet Explorer, a joint American-European-British satellite.
Like IUE, the Astron telescope does not take photographs of objects.
It is designed solely to study their spectra.
In a typical three-hour exposure, one of its two photoelectric spectrometers can produce detailed spectra of stars as faint as the human eye can see.
Alternatively the other detector can take a lower-resolution spectrum of objects up to a 10 000 times fainter.
Astron also carries a Russian X-ray detector, identical to one now flying on the manned Salyut 7 space station.
It will investigate the shorter-wavelength radiation from the objects observed by the ultraviolet telescope.
The telescopes will investigate particularly hot objects.
In our Galaxy, these include young massive stars, newly-formed pulsars (like the famous Crab Pulsar in the Crab Nebula), and streams of gas in double-star systems where matter is falling from one star onto a compact star — a neutron star or black hole.
Astron will also observe the very distant and powerful quasars.
The Russian-French observatory, is part of a wider programme of space collaboration, most dramatically shown by the flight, aboard a Russian rocket, of a French cosmonaut last summer.
Russian spacecraft now regularly carry French detectors for picking up bursts of gamma rays from still-unidentified sources.
The Soviet probes to Venus and Halley's comet, Vega I and 2, will drop French balloons into Venus's atmosphere.
Future joint space observatories include the first large gamma ray observatory in 1985 and a cooled telescope for studying very short radio waves in 1987.
In these telescopes, the Russians depend on Western electronic technology for the very sophisticated instruments needed.
But there is a payback.
The Soviet Union is offering time on the Salyut 7 X-ray telescopes not only to France, but also to Holland, West Germany and the European Space Agency.
Europe refuels British energy funds
A RANGE of British energy projects will receive more cash from Brussels, following a new agreement on budget refunds.
The European Commission has granted £231 million under a new regulation.
The aim is security of energy supplies, a reduction in Europe's dependence on oil and more rational use of energy in general.
The infusion of European cash will help Britain raise expenditure on such projects as the Drax coal-fired power station in Yorkshire, for which 53 per cent of the funding will now come from Brussels.
The council of ministers agreed in June 1980 that the community should try to meet about three-quarters of electricity demand from solid fuel and nuclear power.
So advanced gas-cooled reactors are given support.
Funds go to the Heysham station in Lancashire, Torness in Scotland, Hartlepool and Dungeness.
The Dinorwic pumped storage system, which allows power supplies to be stored by pumping water up hill in the mountains of North Wales, gets nearly £7 million.
The cross-channel electricity link between France and Britain gets a similar amount.
Personal computers face registrar's rule
SCIENTISTS, doctors, lawyers, accountants, journalists, newsagents — indeed anyone who stores the names and addresses of business contacts on a personal computer or word processor — could find themselves committing a criminal offence if government plans for data protection, presented to the House of Commons this week, becomes law.
The Data Protection Bill, which has already gone through the House of Lords, proposes that every business computer-user who holds information on living individuals should register.
A registrar will then have the power to de-register users if he is satisfied that an infringement of one of eight data protection principles has occurred.
If a user continues to operate the computer after being struck off the list he will be guilty of a criminal offence and liable to an unlimited fine.
Appeals against deregistration will be time consuming.
Lawyers are worried about the rights to compensation that those who appear on computers will have if they can prove that they suffered damage by wrong information being stored about them.
At its most absurd it might mean that companies could be sued for sending letters to the wrong address.
The bill also breaches the confidentiality enjoyed by many professions — notably lawyers, doctors and journalists — who do not usually have to give up their files to the police.
At the same time the bill gives sensitive police and government computer files a blanket exemption.
This is ironic.
As one lawyer who is lobbying against many of the bill's provisions told New Scientist : ‘The very early aims of data protection laws were to protect the individual, and this particular bill was put forward by this government to protect business interests.
And yet it appears to frustrate business and fails to protect the individual,’
The bill is also under attack for being unworkable.
The registrar will have a staff of about 20, but will have to look after a register of perhaps hundreds of thousands of computers.
By contrast, the body responsible for registering and monitoring information collected by credit reference agencies has a register of about 130 000 entries, deals with about 20 000 enquiries a year, and has a full-time staff of more than 70.
A committee set up by the accountancy profession believes that the data protection registrar will have to cope with 10 times the volume of work, with less than half the staff.
‘If the essential functions of ensuring compliance and dealing with complaints are neglected, the register and legislation will fall rapidly into disrepute,’ the Consultative Committee of Accountancy Bodies told MPs in a briefing document.
Whitehall strangles the cable revolution
Barry Fox
MARGARET THATCHER's drive to bring the information revolution to Britain is juddering to a halt.
After her veto of the Alvey committee's plans to use government money to back a new era of computer research (last issue, p 3), ministers have now postponed publication of their White Paper on cabling Britain because two government departments cannot agree on how it should be paid for.
At the heart of the row is the question of whether pay-TV should be introduced to generate immediate cash to finance the cabling network.
In mid-March the Home Office was all set to go ahead with a White Paper based on last year's policy report on cabling by Lord Hunt.
This report said that there should be no pay-TV programmes.
The draft White Paper also limited the number of cheap imported entertainment programmes.
But the cable operators told the government that they would not invest in cable unless they could have pay-TV as a sweetener.
The Department of Industry (DoI) backs their call because it cannot afford to subsidise the new cable network.
But the BBC, ITV and the film industry say that pay-TV would wreck their own operations.
The Home Office and the DoI are now trying to decide whether to overturn Hunt, offend the BBC and ITV and give Britain an unlimited menu of pop programming — or stick to Hunt's ideals and risk stifling the British cable network at birth.
Ministers have already decided that they will have to give cable operators a free choice on the technology they use, provided it meets the basic requirements already laid down by the DoI and endorsed last month by the Eden Committee.
The government knows that, if it tries to dictate, the cable operators will blame the government for any commercial failure which cable suffers.
Seat belt statistics undenied
COMPULSORY seat-belts have yet to have any noticeable effect on road accident statistics in Britain, despite many exaggerated press reports.
Experts agree that it is far too soon to tell how many lives the belt law has saved.
Since the beginning of February, all Britain's car drivers and front seat passengers, with some minor exceptions, have had to wear seat-belts.
The Department of Transport estimates that before belts were compulsory, only about a third of people in the front seats of cars wore them.
The AA says that since the law about 85 to 95 per cent of people are wearing seat-belts.
At the beginning of March, a social services minister said that hospitals were reporting fewer car accident victims as a result of the law.
In the British Medical Journal a Bristol hospital claimed that 24 car drivers were admitted after accidents in February, 18 less than in the same month in 1982.
The same hospital said that road deaths had fallen from three in February 1982 to nil in February this year.
And The Times reported a shortage in kidneys for transplants because fewer people are dying on the roads-The figures for accidents in Greater London tell a different story.
These are the first police accident figures to be released.
In February 1982 there were 3223 casualties, of which 31 were fatal.
In February 1983 there were about 3200 casualties, of which more than 33 were fatal.
Because the statisticians have not finished working on the February figures, some 900 casualties have not yet been classified as slight, serious, or even dead, so this figure will certainly rise.
One of the expected effects of seat belts was to reduce the number of serious and fatal accidents.
The number of serious and fatal casualties to car occupants fell from 11 per cent in February 1982 to 9 per cent in February 1983.
But this is not so impressive as it appears.
The proportion of fatal and serious casualties to pedestrians fell, from 24 per cent to 22 per cent.
New angle on APT tilt
BRITISH RAIL is thinking of fitting a new tilt mechanism to the much-troubled advanced passenger train (APT).
According to a report in this month's Modem Railways an all-electric tilt will replace the present hydraulic system.
British Rail says that this is just one of the options being considered.
There have been no problems with the hydraulic tilt, which jacks up the carriage bodies as the train rounds a bend.
The tilt problems so far have all been traced to the electric control systems.
The prototype APT will resume its trial runs from London to Glasgow ‘in the near future’.
A British Rail spokesman was unwilling to give a precise date.
Science in Scotland
SCOTLAND will have its own science reference library by the end of the 1980s.
It will be housed inside a £15 million building in Edinburgh and should be ready by 1987.
The new building will be an  annexe to the existing National Library of Scotland.
The Scottish Science Reference Library will have a staff of 32 to give rapid access to the library's own collection of books and to computerised databases all over the world.
Academics hope that the new reference library will fill many of the gaping holes in the national library's science collection.
Even though it is a copyright library and receives three copies of all books published in Britain, many overseas books and journals have been overlooked in the past.
Defence chiefs juggle figures on bomb tests
BRITISH defence chiefs have criticised a survey which shows that servicemen stationed in the South Pacific during the atom bomb tests in the 1950s have abnormally high incidences of radiation-linked cancers.
They say the survey is inaccurate because it is based on incorrect figures that the Prime Minister gave to parliament this year.
The survey, conducted by Dr Alice Stewart of the University of Birmingham, establishes that, out of 330 servicemen, 27 have suffered from cancers of the blood or lymphatic systems.
This is about 10 more, she says, than would have been expected From the whole 8000 servicemen who, she says, took part in the South Pacific tests between 1957 and 1958.
The figure of 8000 is based on a statement by the Prime Minister in February 1983 that about 12 000 British servicemen and about 1500 civilians served during the whole of the South Pacific and Australian tests, which ran from 1952 to 1958.
However, the Ministry of Defence (MoD) has told New Scientist that these figures are likely to be underestimates, and so the survey should be based on a population size that is ‘nearer 12 000’.
The survey is the result of ex-servicemen, who had served in the South Pacific tests, and their relatives contacting the BBC television programme Nationwide .
The 330 replies showed that 22 servicemen had died of reticuloendothelia system neoplasms (cancers), and another five dead men had a history of such diseases although they were not the primary cause of death.
Out of a population of 8000 ‘normal’ men, 17.2 would be expected to die of such cancers.
If the MoD's estimate of a population of 12 000 is used, then the expected number increases to 25.8.
The survey also came up with 10 reported cases of cataracts, which can also be caused by radiation exposure.
The condition is, however, almost unknown among healthy men of the same age as those in the survey.
This is a ‘strong indication that some of those involved (in the sample of 330) had received radiation greatly in excess of a safe dose,’ according to a letter in The Lancet from a group of doctors who support the call for an independent inquiry into the atom bomb tests.
Meanwhile, the MoD has yet to decide who will conduct its official survey on mortality rates.
The Medical Research Council and National Radiological Protection Board are both contenders.
ARC's genetic research goes commercial
THE AGRICULTURAL Research Council is about to dive in at the deep end of commercial research by launching the Agricultural Genetics Company.
Its partners will be Ultramar, an oil company, Advent Capital, the city financiers, and another public body, the British Technology Group.
The plan is to do for the food industry what the Medical Research Council's Cell tech offshoot is doing for genetic engineering in medicine.
Several prominent firms engaged in genetic manipulation for the agricultural and food industries have been excluded from participation in the venture.
Dr Tom Walker, the head of BP Nutrition, says that BP had been kept aware of developments but had decided not to take part.
Walker, a former employee of the ARC, said the council's research was of a high standard but said ‘as a ratepayer one would be worried that such standards of excellence would be properly managed by the ARC.’
A spokesman for ICI, Britain's giant chemical conglomerate which is active in many fields of genetic engineering, told New Scientist that it had not been approached.
The new company will encompass long-term research already under way in the ARC's laboratories.
Examples include developing nitrogen fixation in plants and manipulating the bacteria which produce additives for animal feed and antibiotics to increase their yield.
But there will be pressure on the company to produce ‘quick fixes’ for traditional industries that have fallen on hard times.
At an ARC symposium last week, convened to mark the ARC's decision to rename itself the Agricultural and Food Research Council, delegates called for action to save the British malting industry which is hit by falling demand for Scotch whisky.
Delegates called for the ARC to conduct urgent genetic research to find new uses for the products of the malt and barley industries.
Sloppy clean-up
THE fourth anniversary of the accident at the Three Mile Island nuclear reactor in the US passes, the crippled nuclear plant is once again the centre of controversy.
This time the issue is the safety of the clean-up of the plant.
During the past fortnight engineers working on the site have charged, in affidavits, that the efforts to remove damaged uranium fuel from the reactor are sloppy.
‘The present mentality on the island emphasises short cuts, expedience and disdain for professional standard,’ said Edwin Gishel, engineering director for site operations in an affidavit sent last week to his employer, the General Public Utilities Corporation.
And Richard Parks, an engineer with the Bechtel Corporation, which built the plant and is the prime contractor for the clean-up, claimed that ‘the operation is disorganised and at times irresponsible.
There is a serious lack of coordination between Bechtel, GPU, the subcontractor and the federal agencies involved here.’
Bechtel has since suspended Parks.
One point of contention is GPU's plan to use a crane inside the reactor building to lift the 170 tonne steel top off the reactor and then lift out the 40 000 uranium fuel elements in the  stricken reactor.
Parks and Gischel say that the crane may have been damaged in the original accident.
GPU and Bechtel counter that tests have shown no sign of damage to the crane, and that all procedures were safe.
Making waves on the 36 bus
NEXT YEAR London will get its first radio-controlled buses.
But instead of hearing their controllers, drivers on the 36 bus route could find themselves permanently tuned into Johnny Halliday, or similar Muzak, being pumped out by continental radio stations.
The problem stems from the 1979 World Administrative Radio Conference, which was held in Geneva.
The Home Office, which conducted the British side of negotiations, agreed to shift mobile radio users, such as London Transport, off a group of VHF frequencies.
To reduce problems for existing users of these frequencies the Home Office shrewdly negotiated a 10 year transitional period.
London Transport does not have to switch frequencies before 1990, But this massive victory for British diplomacy does have one minor drawback — the transitional period does not apply to the new users.
So next year French and Belgian radio will start broadcasting on these frequencies.
London Transport could get round this problem by increasing the power of its transmissions and blotting out foreign broadcasts.
But the maximum output is limited to 25 watts — by the Home Office.
(The police will not have similar problems because their output is not limited.
They pump out about two kilowatts.)
London Transport could switch to its new frequencies.
But the equipment is specific to a frequency and the Home Office has yet to tell bus operators what new frequencies they can use.
One suggestion is to take over frequencies currently being used by 405-line TV.
Few TVs now use this frequency but the government has yet to announce the end of 405-line TV.
Mystery of toxic-shock syndrome may be solved
NEW YORK researchers are near to pinpointing the root cause of toxic-shock syndrome — a feverish, and often fatal condition which has struck many women using particular types of tampon.
They have identified a new bacteriophage, a viral organism that infects bacteria just as viruses infect human cells, which is associated with the syndrome.
The phage, is still unnamed.
It was found in 11 out of 12 patients suffering from toxic-shock, whereas only one woman out of a sample of 18 without the syndrome was found with the phage.
The bacteriophage infects the bacterium,Staphylococcus , by taking over its cell chemistry and it is thought to cause the production of a toxic substance which is poisonous to human cells.
If this is the case then the mystery which originally shrouded toxic shock syndrome has been solved.
The symptoms are similar to those of scarlet fever and may have a similar origin in that a bacteriophage injects genetic material into a bacterium and causes the release of a substance that is very toxic to human cells.
John Zabriskie, who originally found that the blood toxin responsible for scarlet fever is made under the direction of a bacteriophage, is also a member of the team which has made the toxic-shock discovery.
There are several candidates for the toxin that might cause toxic shock syndrome.
But apparently no one else has looked for a phage that might produce such a toxin.
The new phage was found by Vincent Fischetti and Steven Schutzer, working with Zabriskie, and is reported in the latest issue of Science .
Fischetti says a phage infection and its toxin seem to be mundane; the toxin may be a mere waste product that happens to damage human cells.
‘If the mechanism holds up, we will have a better means to identify which toxin is involved,’ adds Schutzer.
Zabriskie, Fischetti and Schutzer are members of the Rockefeller University.
Toxic-shock syndrome reached a peak in 1980 but has since declined to a stable level of about 25 a month.
Death rates have also declined according to the US Centre for Disease Control.
CND denies computer smear
THE CAMPAIGN for Nuclear Disarmament (CND) has denied claims that it ‘controls’ its membership through two computers at its North London headquarters.
The attack came during the launch attended by Michael Heseltine, the defence secretary, of a booklet called Playing at Peace .
It compares the centralised approach of CND unfavourably with the West German peace movement, which does not have a permanent organisation.
CND was accused of using its computer to record the political activities of its 60 000 members, to allocate them to local groups and check on their attendance at meetings.
‘It's a traditional cry of the left, that no records should be kept on individuals, but CND have found an excuse to do it,’ Nicholas Perry, co-author of the booklet told New Scientist .
‘They are using the computer to gauge who would be suitable to attend certain meetings: they may want to exclude some of them.’
But CND says that its computers are just used for recording members — names and addresses and their subscription payments.
The personal computers — bought for £15 000, 15 months ago — are not even up to this job, said CND, and the organisation has spent the past year trying to exchange the system.
‘It's just a glorified card index system,’ said Tony Allan, computer and membership secretary.
‘It's a membership computer and that is all.’
Puppets and Vultures vomit sustain condors
HAND PUPPETS made to look like mature Californian condors are being used by biologists at the San Diego wild animal park to nurse the first two Californian condor chicks born in captivity through the early weeks of life.
Scientists are taking extraordinary care of the tiny birds.
If they die the whole campaign to save the condor by captive breeding could come under renewed attack.
The puppets are made of leather and have fibre glass feet.
They are used to feed and preen the birds.
Food is forced into the chicks by the keeper's index finger inside the book.
Bill Toone, the project leader, spent countless hours in the wild, watching how the birds behave, so that the mannerisms could be duplicated using the puppets.
He believes the subterfuge is necessary to their survival.
The chicks are eating well and gaining weight.
But officials will not rate the survival chances above 50 per cent until a month after birth.
They are being kept in incubators, normally used for premature babies.
Their diet consists of chopped two day old mice, and vulture's vomit.
The turkey and black vultures at the park are well-fed and then scared into bringing up their food to supply the chicks.
The chicks have taken Indian names after regions of their natural habitat, Sisquoc was born on 30 March and has more than doubled his weight of 201.9 grams.
Tecuya, is smaller, 165.9 g at birth on April 5, and is causing some concern.
Pieces of eggshell and membrane are being examined to study possible environmental contamination in the condor's natural food chain.
Scientists do not yet know the sex of the chicks.
Females are needed for the breeding programme.
The three condors in captivity are all males.
. only about 20 birds still exist in the wild and in-breeding is feared.
IBM chases silicon spies
IBM is still chasing spies.
Fresh from wringing an admission of guilt from multinational competitor Hitachi (New Scientist , 17 February, p 428), the firm is now accusing a small band of its former employees in Silicon Valley of stealing trade secrets used in transferring information to and from computer discs.
The accusation is likely to become a test case for one of the greyest of grey areas in Silicon Valley: can a company stop its employees from forming competitive breakaway companies using technical know-how gained on the original job when, as often as not, the ideas are in their heads rather than stolen documents or pieces of equipment.
IBM has filed suits against five of its former executives charging them with using proprietary technology, developed over 14 years at a cost of $200 million.
Cybernex, the firm the ex-IBM executives founded in October 1981, denies any wrongdoing.
Its president, William Klein, says his company had ‘cooperated with IBM by providing full details of the Cybernex process and how it was  developed ’.
It did not involve trade secrets, only publicly-available information and research by Cybernex's staff.
IBM says that the former employees held key managerial and technical positions in the thin-film development department at its San Jose plant in California.
They knew about most aspects of the technique, which involves more than 100 separate steps.
The device is used to write computer information onto discs and then read it back again.
Meanwhile, local police are clamping down on high-tech crime.
Santa Clara County, the centre of Silicon Valley, has formed a high-tech task force made up of police and prosecutors from throughout the region.
They will start work in earnest later this month.
The task force will concentrate on rooting out theft of trade secrets and high-tech components, particularly integrated circuits.
Another area of growing concern is theft from computer data banks.
The force is reported to be the largest of its kind and is expected to become the prototype for other parts of the country with high-tech industry.
Going to Town on a dose of drug imports
MALCOLM TOWN, the drug wholesaler from Harrogate, North Yorkshire who was fined £6000 last year for importing cheap drugs and undercutting National Health Service prices, is at it again.
But he is betting that the Department of Health will not prosecute him this time.
Town's drugs are often made in Britain, flown to the Far East or some other convenient staging post and then brought back on the next night — to be sold more cheaply than if they had never left Britain.
He admits that these ‘parallel imports’ could be illegal.
But he claims that business such as his has the backing of the European Community's trade laws.
And it could knock 10 per cent off the National Health Service's drugs bill by undermining price agreements between the government and the major drug companies.
Those price agreements, which virtually guarantee the firms a 25 per cent profit on the drugs, are being renegotiated this month.
Other leading drug wholesalers in Britain also surreptitiously buy cheap imports using specially-established subsidiary companies.
Town and the others bring in branded drugs which are already legally on sale in Britain.
But they sell them without an import licence — which is illegal, In practice, the licences are monopolised by the brands' parent companies, who can afford the extensive clinical trials on the drugs that are necessary for licensing.
To protect their investment in the trials, the firms do not make the results available to small would-be competitors.
In the absence of competition, the government's Pharmaceutical Price Regulation Scheme, under which civil servants and drug companies negotiate a ‘fair’ price for the NHS's drug purchases, is meant to keep the profits of the companies reasonable.
Town says the scheme does not work.
It does not set individual drug prices, but rather limits companies' overall profits to 25 per cent.
‘The companies can charge what they like for drugs, then be as inefficient as they like, and stay under the profit ceiling.
The NHS picks up the tab,’ he says.
The NHS buys nearly all prescription drugs in Britain.
A report from the Auditor-General in January said that the Department of Health had trouble assessing company efficiency and establishing ‘fair’ returns.
Similar monopolies exist in Europe, but local price fixing is often stricter than in Britain.
In recent months Town has placed orders for Septrin, a popular antibiotic made in Britain by the Wellcome Foundation, with Wellcome's Malaysian agent.
The agent in turn placed an order with Wellcome.
The cases of Septrin followed the route backwards from Britain to Malaysia and back to Town's Harrogate base.
Town says that, of Britain's 100 most prescribed drugs, he can buy 67 abroad, sell them for 20 per cent less than the NHS price, and still make anything from 3 to 300 per cent profit.
The purchasing chemist can undercut the NHS, and still make an extra profit.
The drug companies condemn the imports as unfair because they alone must foot the registration costs.
They have waged a campaign against Town.
Peter Lumsley of the Association of the British Pharmaceutical Industry says the pricing agreement gives ‘good value for money’ because it covers research costs and attracts investments by multinationals to Britain.
The Department of Health, which is charged with both minimising drug costs and promoting the home industry, has tended to agree with the big firms.
Town says a loophole designed to allow the importing of drugs not already on sale in Britain allows him to import what he likes.
And he says that the European Commission, which has been trying to break down trade barriers in pharmaceuticals since 1975 backs him.
Last May it directed member states to do away with licensing rules like Britain's, which create import monopolies.
Pips squeak in video wars
EUROPE's video war has taken a series of bizarre new twists as the European Community's new rules on imports of video recorders from Japan produce results in the market place that nobody predicted.
Thorn EMI, which imports Japanese made recorders for sale under the Ferguson name, is complaining to the British government about the new restrictions.
The company has just started to assemble video recorders, in Berlin and Newhaven in Britain, from kits of parts imported from Japan.
But Brussels has now put a ceiling of 600 000 kits a year on this operation.
So, says Ferguson, the anti-Japanese ploy in fact jeopardises the jobs of 450 West Germans and 220 Britons.
Meanwhile Grundig, one of the European manufacturers which the EEC was trying to protect with its import restrictions, has pulled the rug from under the EEC's carefully conceived plans.
In Britain Grundig has slashed the price of its European-made V2000 video recorders to less than £300 — thereby making a nonsense of the claim that dumping by Japanese firms was at the root of the crisis in the European industry.
The video war in Europe began when Philips, the Dutch firm, complained to the EEC that the Japanese were dumping video recorders in Europe at below the cost of manufacture.
The Japanese reluctantly agreed to limit the volume of exports to the EEC to 4½ million machines a year and, rather more cheerfully, agreed to put up the prices of their machines by at least £50 each.
So a basic VHS machine will now cost around £450 or £500 — the price previously asked for the poor-selling V2000 machines from Philips and Grundig.
Now that Grundig has priced its own recorders at dumping levels, however, the Japanese have been given a heaven-sent opportunity to welch on their promises to the EEC.
EEC overturns safety code for pesticides
BRITAIN'S safety arrangements for pesticides is in disarray following a ruling by the European Commission that the voluntary code, which is operated by the industry, is a breach of the EEC's rules on free trade.
The Commission's verdict threatens to sweep away two undertakings by the industry which underpin the operation office Pesticides Safety Precautions Scheme.
Members of the British Agrochemicals Association (BAA) are required to supply only pesticides cleared under the scheme and to sell only to distributors who have agreed to supply those cleared products.
The Commission says this amounts to a restrictive trade practice.
The firms say it protects farmworkers and the public from dangerous pesticides.
While the BAA calls for the EEC to relent, it has effectively put the rules governing safety into cold storage.
Last winter two pesticide distributors, Cleanacres and Roberts and Hewitt, were blacklisted for selling an imported  herbicide Curb 50W, which is used on oilseed rape.
It had not been cleared under the safety scheme.
Following the EEC ruling, such sanctions can not now be applied by the BAA.
The BAA now says that new British legislation is vital to put the code back on the right side of the law.
But Peter Walker, the agriculture minister, opposes the idea of a new law.
According to a ministry spokesman he fears that any attempt to legislate ‘would attract extreme factions who would force through legislation to the detriment of the agrochemical industry as a whole.’
He probably has in mind those who campaigned to get the herbicide 245-T banned in Britain and who have attacked the operators of the Pesticides Safety Precautions Scheme for failing to institute a ban.
Who taught the Smiths of Igbo Ukwu? i
Frank Willett
Casting and smithing in Nigeria reached a standard from the 10th century onwards that has been compared to the art of Benvenuto Cellini.
It is a mystery where the West Africans found their materials and learned their skills
1897 the Royal Navy conducted a punitive expedition against Benin (in what is now Nigeria) and brought back to Britain a large number of bronze castings which were sold to pay for the raid.
They had been found in the royal palace, where most had served as altar furnishings.
The rectangular plaques, showing battle scenes and officials in court dress, were made to decorate the wooden columns of the palace.
They were found by the expedition in a store where they served as a rather cumbersome ‘card index’ of courtly precedents.
The study of these remarkable objects began at once.
One of the very first accounts, published in 1897, was an analysis of the metal used.
Other important casting centres have since come to light in Nigeria and some hundreds of castings have been analysed.
It was hoped originally to discover the source of the metals.
This would explain more about the history of local trade and perhaps show how knowledge of bronze-casting reached West Africa.
Yet, so many variables are involved that precise sources may never be identified.
The composition of the ores varies substantially at any one site, and the method of preparing the ore affects the amounts of impurities in the metal.
Also, metal from various sources may be melted together to make new castings.
The composition of any casting is not homogeneous due to variations in the specific gravity and solidifying temperature of different elements, so one sample cannot be representative of the
Whole casting.
In addition, when a sample is analysed by different techniques the results sometimes show substantial variations, while no technique is more precise than about 5 or 10 per cent of the measurement indicated.
The oldest artistic castings so far known in Nigeria were excavated around the beginning of 1960, on behalf of the Nigerian Department of Antiquities, by Thurstan Shaw at Igbo Ukwu in the south-east.
They have been radiocarbon dated to about the 9th or 10th centuries AD and seem to have been intended for use in ceremonies associated with an important priest.
Their compositions fall into two major groups: copper, usually with no more than traces of other elements; and alloys, either tin-bronze or leaded tin-bronze.
Shaw observed that the pieces made from copper had been manufactured by smithing techniques alone — by twisting, hammering and chasing the metal.
The twisted snakes that acted as ferrules on ceremonial staffs are amongst the less elaborate objects fashioned in this way.
The alloys were cast into complicated forms.
The surfaces were usually richly decorated with patterns made from thin threads, spirals and pellets of wax often superimposed by stylised representations of crickets, mantids, spiders, birds, snakes, frogs, snails and scaly anteaters.
Some of the castings were intended to be worn as pendants, some were decorations for staffs, while others were vessels.
Many had strings of beads attached to their already encrusted surfaces.
The beads probably come from the Islamic world.
The artists had unlimited patience not only in modelling but also in casting, for some pieces were made in stages.
There is, for example, a vessel on a stand surrounded by ropework.
The body and the upper stand seem to have been made in a single casting.
The neck, the lower stand, the loose ornament on the ropework cage and then the ropework, with the exception of the lower loops, were cast separately.
The ropework was passed over the pot from above and bent to fit.
Next, the rim was attached to the body of the pot by casting-on more metal.
The two parts of the base were joined in the same way, the lower loops of the ropework being added at the same time.
These castings-on involved the whole lost-wax process, the missing parts being first modelled in position in wax, the whole enveloped in clay and metal run in to replace the wax.
One can only suppose that the smiths at Igbo Ukwu enjoyed demonstrating their virtuosity.
These smiths, towards the end of the first millennium AD, clearly knew how their metals would behave.
Molten copper oxidises in air and so does not flow well in enclosed moulds.
It has to be worked by smithing techniques.
The addition of tin and lead makes the metal flow more easily so that an alloy of copper with these elements is more suitable for casting.
Paul Craddock of the British Museum Research Laboratory has pointed out that the silver in metals used at Igbo Ukwu would almost certainly have been recovered by European and Arab smiths of the period, while the unusually low iron content suggests the copper was made by a very primitive technology.
It is thus unlikely that the metals used at Igbo Ukwu were prepared north of the Sahara.
Indeed there are West African sites, where copper was mined or refined, which date from the first millennium BC and perhaps even the second.
Marandet in Niger, 1200 kilometres due north of Igbo Ukwu, has been dated by radiocarbon to between the 6th and the 10th centuries AD.
A range of copper alloys has been found there and evidence suggests that lead was extracted from the copper by causing it to fuse with the silica and alumina in the clay crucible to form a lead-glass.
The only castings found were ingots, so this seems to have been a metal refinery.
Ife, a city to the west of the River Niger and, according to Yoruba tradition, the centre where the world was created, was occupied at the time of Igbo Ukwu.
Casting was practised here from the 13th to perhaps the mid-16th century AD, though terracotta sculpture was practised earlier.
Artistically, the Ife sculptures are remarkable for the portrait-like naturalism with which kings, queens and courtiers are represented.
The castings are mainly life-size heads.
They are thought to have been attached to wooden figures to carry a dead king's crown in ceremonies expressing the continuity of royal office.
There is also a life-size mask of similar appearance, together with some sculptures of royal figures and some staffs with human heads.
Most of these castings are of an alloy of lead zinc-brass which runs well in enclosed moulds.
Some parts of the castings are extremely thin.
A sculpture representing a king and queen was broken by the builder's labourer who found it, revealing that the metal of the faces was only about a millimetre thick.
The Ife smiths were so self-confident that they seem always to have allowed a casting to cool slowly inside the mould instead of splashing cold water over it so it could be opened and checked quickly, which is the usual modern African practice, The slow cooling allowed the metal crystals to grow.
in this case to the thickness of the face.
The sieving of 80 tonnes of earth failed to recover even a scrap of the missing face, which must have shattered into individual crystals.
Surprisingly, some of the Ife castings are of unalloyed copper and they are more successful than similar castings in leaded zinc-brass.
The average number of casting faults which had to be repaired is well over twice as high in the alloy heads as in the copper ones.
The Ife smiths must have known the only technique by which air can be largely excluded to permit copper to be cast in an enclosed mould.
After the wax has been poured out, the mould is inverted over the top of the crucible.
The two are joined together with clay and the whole unit is heated in the furnace.
This drives out a great deal of air through the porous clay of the mould producing a partial vacuum which helps to suck the metal quickly into place when the arrangement is inverted.
Max Frolich. a Swiss silver- and goldsmith, studied the technique in Cameroon in 1977.
He says that the maximum weight of casting that can be made in this way is about 6 kg.
The heaviest copper head from Ife weighs almost 7 kg so the Ife smiths seem to have been working at the limits of this technique.
No one knows whether they discovered the technique for themselves, or learnt it from others.
The seated figure found at Tada, on the River Niger 200 km north of Ife, is generally considered one of the masterpieces of Ife sculpture.
It too was cast in copper but at 18 kg it was too heavy to cast by inverting a joined mould and crucible.
It had to be cast by the unsuitable technique of melting the metal in separate crucibles.
As a result it shows evidence of a score of repairs, some of them very extensive.
Perhaps copper was the only metal available at the time.
Although the combined crucible technique works well with copper, it was not appropriate for casting the other heads since their alloys are rich in both zinc and lead which are very volatile.
Their vapours would not have been able to escape, thus causing holes in the castings.
That the metal was poured from separate crucibles is shown very clearly in one of the heads where the mould had to be topped up.
The metal cooled slightly before the additional pouring and this left a crack most of the way round the top of the head.
These two techniques of casting are regarded as distinct and having different geographical distributions.
They have been labelled the ‘Egyptian’(joined crucible) and the ‘Renaissance’ or ‘Cinquecento’(separate crucible) techniques.
These names however are misleading for the earliest castings known were made by the ‘Renaissance’ technique.
Both methods seem to have been used at Ife, depending on the metal to be cast.
According to traditions in Benin, casting was introduced there from Ife at a date estimated to be towards the end of the 14th century, about a century before the first European contact with Benin was made by sea.
Some of the castings. like the head of a Queen Mother, show that the metal was poured in from separate crucibles.
The initial pouring had partly cooled before another crucible was added, leaving a crack around the base.
The position of the crack shows also that the head was cast upside-down.
This seems to have been the usual practice in Benin in contrast to Ife.
The tops of the Ife heads, where they would be hidden by the crown, carry the marks of the sprues — the passages in the mould formed from rods of wax, through which the metal runs.
The Benin heads are represented with crowns or have the hair modelled and no traces of sprues can be seen on their tops.
Sprues can however sometimes be detected at the bottom.
The most accomplished of the Benin castings are the high relief plaques of around the 17th century.
These often have projecting parts like spears and swords supported by metal, which has been fed from the rear by fine ducts, hidden when the plaque is seen from the front.
A modern founder would probably use a centrifuge for such a complicated casting.
Graham Connah's excavations in 1964, for the Department of Antiquities, revealed that tin-bronze was available in 13th-century Benin where it was cast into ingots in open moulds before being smithed into bracelets.
When lost-wax casting came in, tin-bronze was used but it was gradually replaced by zinc-brass.
Otto Werner, formerly of the Bundesanstalt fur Materialprüfung, Berlin, published analyses in 1970 which showed that in very general terms the amount of zinc in the brass increased with time until it reached a natural maximum of about 28 per cent.
He has demonstrated in the laboratory that this is the highest obtainable by heating zinc ore with copper.
Zinc metal needs to be added to the copper to get beyond this barrier.
There is no evidence that zinc metal was ever prepared in Africa — it has to be made by condensation since it volatilises before it can be reduced from the ore.
The technique was known in Europe in classical times but was forgotten.
It had to be rediscovered in the 18th century.
Brass made from metallic zinc was patented in England in
1781 so Benin alloys exceeding 30 per cent of zinc must be later than this date.
There is plenty of documentary evidence that brass objects were imported into Benin from Europe by sea and no one doubts that this was the main source of the metal from the 16th century onwards.
In earlier periods, some metal was traded across the Sahara Desert.
In 1964 at Ma'aden Ijafen, in southern Mauretania, Theodore Monod, then of the Institut Francais d'Afrique Novre, found 2085 brass bars abandoned by a camel caravan around the 12th or 13th century.
Their composition is so far unmatched in the known casting centres of West Africa, but Paul Craddock suggests that their zinc and iron contents indicate a source in the Islamic world.
Isotope studies of the small amounts of lead in the unalloyed copper may help to identify the source, but it is only too likely that alloys will contain lead from different ore bodies and thus be unidentifiable.
Whether or not we ever find out the precise source of the metals, analyses have shown that these early casters in West Africa had a considerable technical knowledge and expertise.
The source of the expertise is still a matter for speculation.
Lost-wax casting was known in the Middle East in antiquity and seems to have diffused from there.
Bronze moulds for elaborate axes of the late Bronze Age in Britain could only have been used in the lost-wax process.
By what route the technique got into West Africa — or even whether it was independently devised there — cannot be ascertained until we have discovered more sites of the first millennium AD, and earlier in West Africa.
Metal cast by lost-wax
LOST-WAX casting is so called because the object to be cast is first modelled in wax (over a clay core if the casting is to be hollow).
The wax is enveloped in clay, baked in a fire and poured off.
Molten metal is then poured into the space left by the wax.
Provision has to be made For the wax to escape and the metal to enter.
This is done by applying wax rods at  appropriate points which form ducts in the mould when the wax has been melted out.
The core is secured in position by metal pins and if possible by joining the core and mould together.
The diagram shows how one Ife head was made.
There is a crack around most of the head in what must have been a horizontal line at the time of casting.
Keeping the gene genie in the bottle
Stephanie Yanchinski
Last week the British government announced plans to reorganise its safety watchdogs for biotechnology.
But, as genetic manipulation leaves the laboratory and enters the factory, just how safe is it?
THE HEALTH of workers in some of the new biotechnology factories could be at risk if companies do not adhere strictly to safety guidelines to contain their creations.
Dr Roger Nourish, head of the team of microbiologists within Britain's Health and Safety Executive (HSE), which inspects factories, says that ‘even in microbially low-risk processes, like the processes carried out so far — which do not involve infections or toxic hazards — allergenic risks arising from workers’ exposure to foreign proteins or polypeptides have to be considered’.
He points out that ‘industrial production can give rise to substantial aerosols, particularly at the stage of downstream processing where centrifugal separators, for example, are often used…
. Although risks from the industrial use of microorganisms should not be exaggerated, thorough risk assessment and implementation of containment and other safety precautions…are essential, whether the organisms have been genetically engineered or not’.
Nourish's ‘allergenic risks’ refer to the problems connected with keeping the entire process totally contained, from the fermenter, through the separation of the product in centrifuges, to the treatment and disposal of effluents.
Prolonged exposure, even to small amounts of genetically-engineered microbes in the air, could cause allergies in workers.
Even worse, they may develop some auto-immune disease.
Further down the line, in the spray drying or packaging units, the protein products of the microbes could cause similar problems.
Although there is scant evidence that this could happen, few people are collecting the necessary epidemiological data to assess scientifically the effect of these new materials on human health.
Some of these diseases take 20 years to appear.
The HSE says that companies that take shortcuts when building new units, refurbishing and converting facilities, especially those for high-rise work, might expose workers to infectious, allergenic or toxic hazards.
Nourish says: ‘The technical knowledge and equipment to provide adequate containment is available.
But companies not using the equipment properly nor designing safe processes could pose hazards for their workers.’
According to Dr Hugh Watson, secretary of the Confederation of British Industry's Research and Technology Committee, special problems could arise if small companies with limited experience in biotechnology introduce processes based on genetic-manipulated microorganisms.
‘We are not aware of any such companies at present,’ he says.
However, others in the industry are concerned about ‘cowboy’ companies dabbling in biotechnology for the first time and about the commercial offshoots of universities which are scaling up laboratory experiments — often on shoestring budgets.
Eighteen months ago the CBI suggested that the HSE take on a number of extra people to monitor the burgeoning biotechnology industry, but this has not been done.
The HSE warns that even established companies using high-risk processes that require high levels of containment, which are costly in time, trouble and money, may run into difficulty.
At the moment, no law requires any company or research organisation to notify the HSE of its intention to scale up to fully commercial production in the field of genetic manipulation.
Companies do so on a voluntary basis.
They also notify the government's other watchdog body the Genetic Manipulation Advisory Group.
GMAG (pronounced ‘Geemag’) and the HSE between them help to set the level of containment necessary, and give advice on how to design a safe process.
The company's obligations under the Health and Safety at Work Act ends at providing a ‘safe working environment’ as far as is ‘reasonably practicable’.
The act does not control what happens to cell cultures imported by companies operating on the fringe of the biotechnology industry — away from the watchful eyes of the HSE and GMAG.
The same voluntary notification system applies here too.
The regulations do require companies to notify the HSE of ‘dangerous  occurrences ’ involving certain dangerous pathogens.
But unfortunately,Escherichia coli , the microbe commonly used in a crippled form in genetic engineering processes, is not regarded by the HSE as a ‘dangerous pathogen’.
Leaks of genetically-engineered E. coli could legally go, unreported — however dangerous they might be.
The heyday of public concern about genetic engineering came in the mid-1970s.
Then, scientists worried that if microbes such as E. coli which naturally lives in the human gut, escaped from a laboratory carrying foreign genes, they could colonise the gut and flood the body with protein.
Biologists envisaged various ways in which such altered escapees, with which the human gut and immune system would not be familiar, could cause trouble.
The big fear was that they would pass on potentially-harmful genes to other E .
coli already in the gut.
This fear largely evaporated when it was proved that the fragile genetically-engineered microbes could not live outside their special environment inside the fermenter.
In the 1970s the United States led the world in setting up standards of risk  assessment , and establishing suitable levels of containment for laboratory buildings and equipment.
In parallel to the development of these ‘physical’ standards of containment the genetic industry followed the university lead and developed crippled microbes, which closely followed existing guidelines for ‘biological containment’.
However, now other hazards are causing increasing concern.
These genetically-engineered microbes bear foreign proteins or lipopolysaccharides which could provoke an allergic response in workers who breath them in.
Even worse, they produce proteins in large quantities which are very similar to those in our own body.
These could trigger an ‘auto-immune’ response with the immune system of the workers sending out antibodies to attack their own proteins.
Workers might also develop a resistance to certain common antibiotics, whose use is still an integral part of some processes, unless scientists can find safer substitutes.
Dr Sandy Primrose, of G.D.
Searle, told New Scientist that his company won't be using any antibiotics in its processes.
As yet there have been few large-scale studies of technicians involved in scaling up genetic engineering processes.
But the potential hazards are not imaginary.
In 1971, when ICI first scaled up its production of single cell protein (SCP) workers complained of ‘sticky’ discharging eyes and flu-like symptoms — headaches, aching limbs, shivering, and tightness in the chest.
ICI quickly installed better ventilation to control wet aerosols of ‘live’ material but there were subsequent incidents whenever the dust concentrations of the dead, dried and fragmented particles became unusually high further down the processing line.
After a four-year study of 70 men, which involved a battery of tests including an assessment of respiratory health, skin prick testing, tests for the presence of antibodies in blood, lung function tests and chest radiography, Dr R. W. Mayes, a member of the medical department, in ICI's Agricultural Division, concludes that there is ‘no evidence of allergic reaction or of deterioration of lung function related to exposure.
The results show that Pruteen can be produced and handled without adverse effects on health, provided that adequate measures are taken to prevent exposure to high concentrations to dust’.
Of the affected men exposed to the live microbe, 11 revealed antibodies against Pruteen in their blood, which in one case was detectable four years later.
Dr Roger Harrison, director of product development for Eli Lilly's subsidiary Dista Ltd in the UK, told New Scientist that after five years of experience scaling up Lilly's genetically engineered insulin ‘we have not perceived any allergic reaction in the chemical processing or packaging units.’
Around the fermenters where wet aerosols of live material could escape ‘we started from square one, and designed a system to avoid contamination of workers so we went with sealed units.’
Brian Richards, vice president of UK preclinical R & D at Searle, which recently spent £15 million designing and building a genetic engineering pilot plant in High Wycombe, near London, argues that ‘good manufacturing practice’ may suffice for biotechnology factories — as it has for other fermentation industries such as the antibiotic industry.
He adds, ‘I am perfectly confident that the organisms at Searle are being handled in a safe manner.
Recent evidence, presented by Primrose of Searle shows that genetically-engineered cells can change their character in ways not completely understood after about eight days continuous growth.
Today's ‘continuous’ culture processes are designed to go on for months without completely emptying the fermenter.
The HSE's view is that the large-scale use of genetically manufactured organisms is inherently no more dangerous than the vaccine, antibiotic or enzyme industries, where work with vats of microbes or handling large amounts of purified proteins is a daily occurrence.
Bob David, a senior HSE administrator, says ‘no one has any specific evidence that large-scale genetic engineering will be any more hazardous than the conventional biotechnology industry.
We believe that it doesn't need any special legal requirement.’
However, from the point of view of factory workers the picture is not so sanguine.
In one survey half the 500 workers contacted in a major industrial plant in the UK manufacturing penicillin reported positive allergy symptoms, and in another company manufacturing enzymes for biotechnology laboratories two out of 60 were sensitised.
The International Federation of Chemical, Energy and General Workers Unions about a year ago revealed that a study conducted for the US National Institute for Occupational Safety and Health (NIOSH) among workers in a New Jersey Plant working with the proteolytic bacterial enzyme Esperase in producing a bleach showed they had become immunologically sensitised to the enzyme, despite very low levels of exposure.
In this case air concentrations of the enzyme dust ranged from 0–002 to 1–57 micrograms/ cu.m, which the ICEF contends, is well below current occupational exposure criteria of 3–9 micrograms/cu.m.
Professor Derek Ellwood, director of the pathogenic microbe research laboratory at the Centre for Applied Microbiology Research, Porton Down, Wiltshire, says that ‘from the point of view of safety, a biotechnology factory should not be designed in the same ways as one making antibiotics’.
It is acceptable for antibiotics plants to release microbes into the air — but genetically-engineered bugs must be contained.
He adds: ‘A lot of money should be spent on redesigning filters,’ and continuous monitoring of airborne contamination and the health of workers is essential.
All this comes about at a time when the future of GMAG is under review.
An HSE document proposes that GMAG be turned into ACGM — an Advisory Committee for Genetic Manipulation under the direct responsibility of the HSE.
There are fears that, with its loss of independence, GMAG's role might be downgraded to preparing general standards of risk assessment and containment, and the major responsibility of assessing each individual project would pass to the HSE.
The report recommends that the number of representatives of public interest groups sitting on the new committee be reduced in favour of more process engineers from industry and union representatives, so the goodwill and trust of the public could also be jeopardised.
However, the HSE will continue to need advice from GMAG.
For example, viruses are a natural choice for ferrying the foreign DNA into animal cells.
Unfortunately, scientists fear that viruses, either whole or in part, may prove oncogenic — cancer causing.
Also some disquiet surrounds the production of’ second generation’vaccines using genetically engineered microbes to make fragments of viruses.
A recent five-year study by three researchers, two Cambridge research institutes involved in genetic engineering, at the Ludwig Institute for Cancer Research and the Medical Research Council's Laboratory of Molecular Biology concluded that ‘genetic manipulation experiments in the categories encountered in the Cambridge laboratories constitute no general risk to the workers involved or other staff’.
However, it adds that ‘the consequences of genetic manipulation experiments may well be slow to express themselves, and therefore some form of long-term surveillance is obviously necessary’.
The HSE's Employment Medical Advisory Service keeps a register of all research workers involved in genetic manipulation experiments, which would provide important data should an epidemiological survey be launched at any appropriate time, and all laboratories are required to inform GMAG and the HSE of their health monitoring arrangements.
However, industry is not required to do the same thing.
The HSE declares itself satisfied with the general health monitoring programmes run by the companies involved in building biotechnology factories but aside from the ICI programme New Scientist was unable to discover any others established especially to periodically review the health of workers involved in biotechnology processes.
Despite its seemingly sanguine attitude the HSE nevertheless thought it wise to set up its own small epidemiological study, part of a larger project within the HSE aimed at helping the industry to set standards for equipment and installations.
However Roger Nourish says that setting health standards would be very difficult.
‘What would we look for — elevated levels of antibodies, or enzyme changes in the blood?
What would they mean?
It's not like the problem with lead.
We do not have enough accumulated data.’
Donna Haber, of the white-collar union ASTMS, says that most of the studies so far have involved feeding genetically engineered E. coli to test subjects.
But these studies are unrealistic, she says.
The major hazards will come from aerosols containing microbes that are breathed in by workers in biotechnology factories.
The HSE has now acted on the advice of men like Nourish to launch a survey of microbiological hazards ultimately to develop standards in scale up and industrial processes.
A special van visits factories to measure the ‘leakage’ of microbes.
The objective is to draft a code of practice and collect data on the health of workers.
The HSE has a team of three specialists who oversee biotechnology companies but this forms a small part of their regular duties, which involve regularly visiting the antibiotics and vaccine manufacturers, as well as the clinical laboratories in hospitals and medical centres.
With such a small team the HSE can do little more than react to clear examples of bad manufacturing practice.
Donna Haber, from ASTMS who is also a member of an OECD expert group looking at safety in the biotechnology industry, says that the key to safety in biotechnology is planning in advance.
‘If people start with the right attitude then there will be no problem.’
But she adds that past hazards to workers making contraceptives and detergents are a warning: ‘In the past employers did not take the proper precautions.
And there is no evidence that they will act any differently now.’
Can we adjust to computer culture?
Christopher Joyce and Lois Wingrson
The expert and the inexpert met in New York last week to talk about computers and the future.
Both groups felt frustrated by their differences
NEW YORK'S Empire State Ballroom was packed for four days last week with people who knew little about computers.
They listened to, and questioned others knowledgeable in subjects such as artificial intelligence, expert systems and the effect of automation on people's lives.
The deliberations irritated both groups a little because they realised that the gap is growing between those who run computers and those who don't.
The occasion was the New York Academy of Science's conference on ‘Computer Culture’.
It began with a hint of friction when Marvin Minsky, master of artificial intelligence at Massachusetts Institute of Technology, chastised the press for sending ‘scientific ignoramuses’ to interview him.
That was after he accused Berkeley's Philosophy Professor of having ‘idiotic’ notions during a long debate on whether computers will ‘think’like people in three centuries hence.
It was also after one of only two psychologists present said that programmers and computer scientists were ‘arrogant’.
After Minsky had made his point, Charles Bennett, a specialist in algorithmic information theory at IBM, spent 40 minutes speculating on predicting the behaviour of physical systems.
There were two comments from the audience.
The first was: ‘I think you said something interesting, but I don't know what it is.’
The occasional acidic comment at the conference was, perhaps, symptomatic of a looming problem.
Delegates and speakers alike expressed concern about the West's readiness and ability to adapt to life in a ‘computer culture’.
Psychologist Donald Norman told delegates about his recurring nightmare.
Sometime in the future, he is chained to his computer and surrounded by his young captors.
They chant: ‘Jcl, grep, compile and load A-dot-out, popstack format, and code.
Dimension, declare, goto while true Execute, interpret, could-er and queue’.
(Refrain)‘Foobar, foobar, foobar’.
Norman studies how people interact with computers; he works at the University of California in San Diego.
His daytime fear is that ordinary people in the coming, computerised society ‘could be at the mercy of the technocrats’.
Computers remain mysterious to most people, the psychologist maintains, because of the ‘arrogance’ of computer scientists and programmers who understand their machines but who are indifferent about the rest of us.
On the other hand, the rest of us have yet to realise that computer literacy will soon be as essential as driving a car.
Basic concepts have still to be learned, Norman Continued.
These included knowing the difference between hardware and software, the nature of an algorithm, machine architecture, multiprocessing (a computer doing several tasks at once), the notion of net-works of computers that talk to each other , and about data bases.
He suggested the need for a new kind of designer who would create ‘interface programs’ for individuals.
The programmer writes programs to unleash the powers of the machine; the designer writes an interface for the program that fits the personal needs of tailor, musician, secretary or — dare we hope — journalist.
Eventually, each user could carry their personal interface on a pocket-sized ‘smart’ card.
Norman said that his day-dream was ‘to walk up to any computer, plug in the card and have the terminal look and act like the one at home.’
If he needed a sympathetic ear for his worries he would have probably got one from Alphonse Chapanis, director of the Communications Research Laboratory at Johns Hopkins University in Maryland.
Chapanis suggested that computers are not quite as easy to work as the glossy brochures suggest.
Most systems have languages that are too cryptic, too difficult to remember and too large, he complained.
There was no way for users to communicate their difficulties to designers and systems just did not warn the inexperienced of potentially dangerous actions.
IBM's PROF system for office workers is supposed to be for those with little or no experience of computers.
‘I got a premonition of what the system is really like as soon as I discovered that the guide is divided into modules,’ said Chapanis.
‘The manual is full of unexplained code words like: BWD½, U, OFSSMCNTL, CRON, HDL, and PUN.’
‘Ease of use’ is something that no-one studies scientifically, says Chapanis.
He wanted to set a standard that says a system is easy to use ‘if at least 90 per cent of a representative example of users can be trained to the level specified in 15 minutes or less.’
It may well take only a quarter of an hour to train a worker in the future but industry is also going to have to change how it treats that worker.
It must change if it wants to get the most out of computer technology, two other speakers said.
Seymour Melman, a professor of industrial engineering at Columbia University, predicted: ‘There will be a growing contradiction between the technology itself and previous methods of organisation.
The era of Taylorite management is at an end.’
Melman was referring to the management principles of the American engineer Frederick Winslow Taylor, pervasive in Western industry since about 1911.
Taylor spent his life touting his philosophy.
This centred on three principles: reducing work to simple tasks; giving each worker one unvarying duty; and removing all planning and quality control from the shop floor to the central office.
(Taylor once said that steel workers are like oxen, both physically' and mentally.)
By taking the ‘man’ out of manual labour, Melman reasoned, computers make these principles obsolete.
Before, the main component of idle production time was idle labour; today, given that machine down time costs seven times the rate of employing someone, the knowledge to maintain and repair machines becomes the most important skill.
Management has a choice about workers: it can pay them a pittance to control an on-off button, or minimise down time by training them to fix — ie program — the new machines.
Unfortunately, Melman said, Taylorism is built into the new technology.
Many computer-aided machines have locks to keep workers out of the innards.
‘I have viewed a number of plants where the inception of computer equipment is viewed as a way to further de-skill the worker, and thereby lower his wage,’ Melman added.
‘From the standpoint of optimising the equipment this, to my view, is crazy.’
Melman told the tale of an American car parts manufacturer where one plant elected to perpetuate Taylorism when it installed computers, and the other agreed (as a condition of collective bargaining) to train workers to program, In the first plant, workers were designated ‘operators’ and paid $12–50 an hour; when their machine malfunctions they nip the on-off switch and call in a repairman.
In the second, they are ‘journeymen machinists’ paid about $15 an hour.
Each Monday these workers maintain and program their own machines.
In the first plant, Melman said, machines are down for at least half of the time.
In the second, where worker turnover is almost nil, down time amounts to three per cent.
Harley Shaiken of the Massachusetts Institute of Technology illustrated the perils of ‘electronic Taylorism’ with an example from a study by Britain's Council for Science and Society.
A designer was using a computer to specify plans for the igniter for an aircraft engine.
A computer error moved a decimal place one unit to the right.
The machinist on the shop floor could detect but not correct the error.
It took two workers to carry the world's largest aircraft engine igniter to the designer — who said that the component agreed with the specifications, and approved it.
Melman argued that decentralising control, to allow workers to make decisions, is the only way to prevent the ‘computer illusion’ that human knowledge is no longer necessary in manufacturing.
The question whether man or machine is best fitted to have control of the on-off button will be answered one day, according to the high priesthood of artificial intelligence (AI).
Few forces can resist the unbridled optimism of a convocation of computer visionaries — certainly the unexploded Luftwaffe bomb found outside New Scientist's telex office in London could not  suppress their message this week.
The conference was assured that truly ‘intelligent’ machines would come, It was conceded that it might take a few hundred years.
However, there was little doubt that it would happen, and that this revolution will change the world.
Most consternation was reserved for the prospect that the Japanese will probably get there first.
Making computers ‘think’(not necessarily as humans do, but in a logical, inferential way so that they can do more than arithmetic) is a ‘grand vision’ for Edward Feigenbaum, one of the Prometheuses of AI, Feigenbaum is a computer scientist and senior investigator for computer heuristics (common rules of thumb for thinking) at Stanford University in California.
He predicts that computers of the future will process knowledge, not numbers, using symbolic inferences, as in the familiar syllogism: all birds can fly; budgie is a bird; then budgie can fly.
A small step has been made in that direction.
Expert systems already exist.
They are computer programs pumped full of plain old knowledge and heuristics lore from experts who lend their wisdom.
One expert system can diagnose patients using 125000 facts on internal medicine.
It has the expertise of Jack Meyers of the University of Pittsburgh packed inside it; the system recognises 3500 signs and symptoms of disease, and 500 known diseases.
Known familiarly as ‘Jack-in-the-Box’, it is soon to undergo clinical trials.
There are others.
Chess-playing systems are common.
But ‘Dendral’ is probably the most spectacular: it hypothesises organic chemical structure from analytical data.
It far exceeds human analytical behaviour in this field, says Feigenbaum.
There is a program at Stanford that helps molecular biologists plan DNA sequencing experiments; it speaks a language called GENEGLISH.
One firm, Schlumberger and Energy Concern, has a system that measures and processes the physics of rock and hydrocarbon formations during well drilling.
Expert systems are, Feigenbaum claims, at the stage of development equivalent to the bi-plane in aerospace.
They are limited to microworlds where a few simple rules of thumb reign.
Over time, however, scientists will induce enough generalisations from expert systems to generate a theory of intelligence.
This will not be a theory of human intelligence or of machine intelligence, it will be a theory of intelligent information processing, no matter whether that is realised in silicon or in tissue.
By Friday, after four days of being enthused at, confused, intrigued and occasionally feeling rather excited, the 800 delegates must have been glad to think of one computerised future that was just different rather than scary.
‘Computers will never replace executives,’ Robert Lucky reassured them.
‘Because no-one can describe what executives do.
For a similar reason, a robot is not likely to supplant your housekeeper in the near future.’
Lucky, director of communications research at Bell Labs, played prophet with Michael Dertouzis, director of MIT's laboratory for computer science.
Executives will continue to run things in the world of computer culture, because they are schooled in dealing with complexity.
‘The management of complexity is the key problem of our era,’ Lucky said, ‘and the people who will benefit from the computer revolution are those who are comfortable with complexity.
‘We will not all learn how to program.
After all, we drive to work every day without understanding the transmission.
In fact, complete ‘computer literacy’ is probably already meaningless.
More than half the programs we write at Bell Labs contain more than a million lines of code.’
Nobody totally understands that kind of computer.’
As the cost of hardware continues to drop (productivity is increasing at about 30 per cent per year in that industry) individualised computer programming and time-sharing would become expensive relics, he told the conference.
The cost of mass-market programming would then be spread over thousands of purchasers.
Computers would compete with manual labourers, but Western countries had been losing their jobs for years already (as anyone knows who buys plimsolls in the supermarket and reads the label.)
In the information industries, ‘telescabbing’ will probably exacerbate regional unemployment.
Lucky said that computer links have started a trend toward using ‘offshore word processing’ based in the Caribbean, where labour costs are less.
Databases will make professional services such as law and medicine ever more automated.
‘But your housekeeper will stay on,’ Dertouzos said, ‘because no-one knows how to teach a robot to plan.
You can teach it to pick up the broom, but how does it avoid knocking over the potted plant?’
However, the information marketplace would transform commerce.
Very soon, Dertouzos said, General Motors plants will communicate with each other by computers.
Within a decade General Motors will communicate with US Steel's computers.
This becomes a threat when the information in the marketplace is about humans, and private.
Dertouzos called for government regulation to prevent the linking of databases containing personal information without certain safeguards.
The ‘computer culture’ will aggravate the gap between West and East, where computers will be used to increase centralisation and control over individuals.
It will also widen the chasm between North and South.
The wealthy nations are going to be better able to use and organise information, whose value will be very much more closely linked to the value of goods.
Computers will reduce our energy needs, according to Dertouzos.
It's easier to carry bits than bodies.
They will also reduce our needs for mental energy, and the 21st century's cognoscenti will take up mental jogging, using programs specially designed to exercise the mind…until then we'll have to keep attending conferences on computer culture.
MONITOR
Charting the brain's memory map
ACCORDING to Plato, memory can be considered similar to a block of wax: ‘When we wish to remember anything which we have seen or heard…we hold the wax up to the perceptions and thoughts and in that material receive the impressions of them’.
Plato was not alone in believing that some kind of physical change must occur in the brain when information is stored in memory, and neuroscientists have been looking for Plato's ‘wax tablet’ without success since the beginning of this century.
Now Richard Thompson, Professor of Psychology at Stanford University, and his colleagues believe they have found it.
It was Karl Lashley, the pioneer of neuroscience who began the quest for the neural basis of memory, now known as the ‘engram’.
Lashley taught laboratory rats to find their way through a maze to a reward box.
When a rat became a competent maze-runner, Lashley removed part of its cerebral cortex and checked to see whether the animal could still find its way through the maze.
He reasoned that the primary visual cortex was the most likely place for the engram because it is the site for most higher visual functioning.
By systematically removing different areas of the cortex, Lashley hoped to localise the specific spot where the maze running engram is stored.
But he never found it.
Instead, he found an amazing resistance to forgetting.
Even with 90 per cent of their visual cortex removed, rats still remembered how to run the maze.
Lashley finally concluded that there is no such thing as a localised engram.
Although Lashley's failure led many behavioural psychologists to adopt a ‘black-box’ approach to learning (specifying input and output variables but leaving their connections a mystery), neuroscientists continued their search for the engram undeterred.
However, it is only now that Richard Thompson has uncovered what appears to be the engram for a specific memory.
This engram resides in a tiny area in the brain's cerebellum — a place many neuroscientists never thought to look.
Thompson's approach is to study simple learned behaviours in laboratory rabbits.
His goal is to specify the neural circuitry underlying these behaviours and to discover how the brain changes during learning.
Most of his research has been concerned with conditioning the ‘eyeblink’ response in rabbits.
Classical conditioning is a form of learning by association.
For example, in Pavlov's classical experiments, hungry dogs heard music when they were given food.
After several such pairings, the dogs learned to salivate to the music just as they had previously salivated to the food.
Thompson's approach is similar.
Rabbits (and humans for that matter) blink their eyes in response to an air puff directed towards the cornea.
If a tone precedes the air puff, the rabbits quickly learn to blink when they hear the tone.
Animals can learn the standard eyeblink response even with most of their cerebral cortex removed.
This meant that Thompson had to look elsewhere for the engram underlying eyeblink conditioning.
Using electrical recordings made by implanting micro-electrodes in various parts of the mid-brain and brainstem, Thompson noted that certain regions of the cerebellum become very active during eyeblink conditioning.
The cerebellum is located at the top of the brainstem below the cerebrum, and works as a sort of administrative computer regulating the rate, sequence and force of motor movements.
Thompson began to record electrical activity from deep cerebellar locations during conditioning.
He found no responsivity to the reflex blink elicited by the air puff but as the animal learned to make the conditioned eyeblink response to the tone, electrical activity was noted.
In other words, electrical activity was seen to develop in the cerebellum in connection with eyeblink conditioning.
This electrical activity predicts the occurrence of the conditioned eyeblink to the tone but it is unrelated to the reflex eyeblink that occurs in response to the air puff.
In order to verify his electrical recording findings, Thompson made lesions in the cerebellums of animals that had learned the conditioned eyeblink response, Rabbits that learned with their left eye and had lesions made to the left half of their cerebellum no longer blinked when they heard the tone but continued to blink to the puff of air.
Moreover, they could learn to make the conditioned response with both eyes, lesions to both sides of the cerebellum were necessary to abolish the conditioned response.
The amount of tissue that must be destroyed to produce these effects is very small — destruction of 2 cubic  centimetres of tissue in a region of the cerebellum known as the lateral interpositus nucleus will eliminate the conditioned response.
It is important to note that the elimination of the conditioned response is not accompanied by any motor dysfunction; the animals still blink normally to the air puff.
The effect is on memory and not on motor ability itself.
This interpretation of Thompson's findings has been further strengthened by the results of his most recent studies in which he has shown that the engram can be ‘forgotten’ and ‘retrieved’.
His technique is to microinject a small amount of bicuculline methiodine into the engram area.
This chemical is a specific antagonist of the neurotransmitter GABA, a transmitter present in high concentrations in the cerebellum.
Blocking the activity of GABA eliminates the conditioned but not the unconditioned response.
That is, the rabbit still blinks to the air puff but not to the tone.
When the action of GABA is restored (the inhibitor wears off), the conditioned response returns.
This finding not only reinforces the review that the engram site has been correctly located, it also strongly suggests that the engram is intracellular — it remains stored in the cell but can't be communicated when the neurotransmitter is inhibited.
Songbirds tune in to trimphones
WHATEVER the British public may think of Buzby, British Telecom's avian advertising mascot, some of our more natural bird species are clearly impressed.
Several wild song thrushes in different parts of Britain — and some blackbirds too — have been heard singing a new song that bears a striking resemblance to the distinctive electronic warble of British Telecom's ‘trimphones’.
The resemblance is so close that a human can easily mistake the new song for the sound of a trimphone.
Trimphones were introduced in the 1960s as an alternative to the conventional type of ‘phone, and now account for almost 6 per cent of all Britain's telephones.
Peter Slater, of Sussex University, used a sonograph to compare exactly a recording of the new song as sung by a wild song thrush with the sound of a trimphone (Animal Behaviour , vol 31, p 308).
He found the frequency, modulation rate, and the timing of the phrases to be remarkably similar in the two sounds.
It appears that birds have overheard trimphones ringing (or singing?) and have incorporated the sound into their song repertoires.
Most perching songbirds (passerine birds) have to hear their species’ songs when they are chicks in order to produce normal songs as adults.
However, many won't learn just any song they happen to hear — it has to have some resemblance to the typical species song.
Song thrushes normally have a large song repertoire, and Slater suggests that the trimphone sound has been taken up because it is sufficiently similar to the normal songs to be learned and imitated; he calls this the ‘Buzby effect’.
It is probably not a coincidence that, where the song was recorded, a trimphone is installed in a neighbouring house.
But the song might spread from one bird to another by imitation — and give British Telecom a lot of free advertising as well as confuse telephone subscribers.
Cancer gene  evaporates from normal cells
ANYONE who may have been disturbed by a recent Monitor report on the threat of cancer lurking in normal cells (New Scientist , 3 March, p 583), can sleep easy again, at least for the time being.
George Khoury and his colleagues, who recently announced in Science that mutations associated with cancer were to be found in the normal cells of a patient — and were thus probably inherited — turn out to have spoken too soon.
The mutant gene, they now confess, found its way into their cell cultures as a contaminant and there is no longer any evidence that cancer genes may be inherited (see Nature vol 302, p 476).
Strictly speaking, though, the possibility remains that heritable cancer genes may exist: no-one else has looked at normal tissues from cancer patients.
One step nearer to synthetic haemoglobin
CHEMISTS are beginning to understand Nature's subtle use of iron as an oxygen carrier.
Professor Daryl Busch and his team at the Ohio State University have mimicked the action of the body's natural oxygen carriers, haemoglobin and myoglobin, by making the first totally synthetic iron-containing molecule that reversibly binds oxygen at room temperatures (Journal of the American Chemical Society , vol 105, p 298).
Iron (chemical symbol Fe) is an abundant and fairly typical member of the transition group of metals.
One of their chemical properties is ‘variable oxidation state’— the ability to part with different numbers of electrons.
The chemistry of iron revolves around its two main oxidation states, Fe(II) and Fe(III) in which iron loses two or three electrons respectively.
In solution, Fe(II) compounds are slowly oxidised (lose an electron) by air to form Fe(III) compounds.
Iron II compounds then, are reducing agents (electron donors) and Fe(III) compounds are oxidising agents (electron acceptors).
Another property of the transition series metals is their ability to form chemical bonds where the electrons are provided entirely by the other bonding species (called ligands).
These ‘coordination complexes’ are usually highly coloured for example, the deep blue of tetrammine copper (II),[Cu(NH)].
Over the millennia, nature has learnt to capitalise on the abundance of iron and its mild reactivity to perform many important biochemical reactions, these include oxygen transport, which depends on the iron maintaining its Fe(II) oxidation state, to bioredox catalysis (for example in the production of metabolic energy) where iron rapidly undergoes reversible oxidation state changes.
In haemoglobin the iron lies within a flat circular molecule called a porphyrin.
The iron-porphyrin complex is tucked into a water-repelling (hydrophobic) pocket in the protein and hemmed in top and bottom by other complexing ligands.
Oxygen can just get into the pocket and bind to the iron but, due partly to the absence of water, can't oxidise it.
It can look but it cannot touch, the result being it can just as easily be released again.
In other words oxygen binding is reversible.
As the oxygen is bound the iron shrinks in size and buries itself further in the porphyrin.
This tiny movement is transmitted and amplified by the atoms of the protein to the three other iron-porphyrin sites on the haemoglobin molecule, which in turn, are able to bind oxygen more quickly.
This apparent collaboration between iron-porphyrin units puzzled scientists for years until Max Perutz's elegant X-ray crystallographic work revealed the movements behind the structural changes of the haemoglobin molecule during oxygenation.
Since then chemists have been trying to model haemoglobin's reversible oxygen binding.
This would provide valuable information concerning the orientation (stereochemistry) of oxygen when it binds to the iron.
Interest is not just academic for it could lead to better industrial catalysts that mildly and selectively oxygenate organic compounds — normally an energy intensive process that is quite difficult to control.
Most models to date have consisted of an iron-porphyrin complex with various surrounding bulky groups.
These attempted to recreate haemoglobin's hydrophobic pocket on one side of the iron complex.
The other side was blocked either by another ligand or a molecule of solvent.
Stable Fe(II)-oxygen complexes have been claimed but only in non-aqueous solvents like benzene or pyridine and only at sub-zero temperatures (haemoglobin works most efficiently at body temperatures and in an aqueous environment).
Meanwhile other chemists have tried to fashion totally synthetic models that do not depend on a porphyrin ligand.
There are two main reasons for this.
If such a working model of haemoglobin could be made, it would prove once and for all that it is the iron and not the porphyrin that's ultimately responsible for the properties of haemoglobin.
Secondly, a non-porphyrin ligand would be easier to chemically modify and so permit study of a greater range of ligand structural variations.
Till now though such research has been fraught with failure and misinterpretation.
Enter Daryl Busch and his team.
Busch has been trying to make totally synthetic model oxygen carriers for a decade.
Over the last six years, he's concentrated on so-called lacunar (from the Latin meaning a hollow or gap) iron-complexes. (see Figure).
These are designed with a ‘dry-cave’ of bulky hydrophobic groups on one side of the iron-complex while the other side is blocked by another ligand or solvent molecule.
So far, the general strategy resembles the porphyrin-based models.
But now the lacunar ligands greater structural versatility takes a hand.
By juggling with various permutations of bulky groups (R, R, and R in the diagram), Busch has managed to make a complex which has a good affinity for oxygen and is stable.
In fact the adduct was reasonably stable at room temperature and in solutions of up to 20 per cent water content.
As with the hydrophobic pocket of haemoglobin, Busch's lacunar ‘dry-cave’ permits oxygen to bind to but not oxidise the Fe(II).
Busch concedes that the full range of possibilities for bulky groups have yet to be explored.
A lacunar iron complex with haemoglobin's temperature and solution stability seems not far off.
The best size for runners
BIGGER is faster — but only just.
That is the conclusion of a recent survey of the maximal running speed of land mammals carried out by Theodore Garland of the University of California (Journal of Zoology , vol 199, p 157).
Garland surveyed literature for the running speeds of 107 diverse mammal species and discovered that the maximal speed tends to increase gradually with increasing body mass.
A house mouse can run at 13 km/h, larger species somewhat faster until the optimum size for -running is reached at about 120 kg.
Animals of still greater mass, the hippos and elephants, are slower.
The theoretical basis for this overall result is unclear.
The three groups for which most data are available, the carnivores, the rodents and the artiodactyls or even-toed ungulates, reveal running speeds that are independent of mass.
This is exactly the prediction made for geometrically identical animals of different size by D'Arcy Wentworth Thompson in his classic ‘On Growth and Form’ published in 1917.
The cheetah maintains its status as the world's fastest animal (110 km/h) and the prong-horn antelope of the North American plains the fastest herbivore (100 km/h) but , overall, predatory carnivores and their herbivore prey seem to run at about the same speed.
The several carnivores, such as the badger and the skunk, which are noticeably sluggish for their size, are species which either do not need speed for capturing prey or have alternative means of self-defence.
The maximal aerobic speed, that is the maximal speed that can be maintained without incurring an oxygen debt, appears generally to be about one half of the maximal running speed.
This agrees with the observation that human marathons are won at about half the speed of 100 m sprints.
But the ideal physique for the two races is visibly different; compare Alan Wells and Alberto Salazar.
New evidence for B meson decay
Physicists working on CESR, the Cornell Electron Storage Ring at Cornell University in Ithaca, New York, have found new evidence for the so-called B mesons.
These are subatomic particles that are similar to the more familiar pi-mesons, but which are made from a different combination of quarks, the fundamental building blocks of matter.
Although the same group of physicists has found good evidence for the production of B mesons at CESR before, this latest result shows for the first time the explicit decay of B mesons into less-rare, longer-lived particles (Physical Review Letters , vol 50, p 881).
The protons and neutrons of everyday matter appear to be built from two types of quark, called — up’ and ‘down’or u and d .
But short-lived particles produced in experiments at high-energy particle accelerators turn out to contain other types of quark, known as — strange’, ‘charmed’ and ‘bottom’, or s. c and b .
Particles containing the b quark (bottom particles) are the heaviest found so far, some weighing in at around 10 times the mass of the proton.
The first bottom particles to be discovered were the upsilons, which comprise a b quark bound with its opposite number, a b antiquark.
The B mesons, however, contain only one b quark (or antiquark) bound instead to a more ‘ordinary’u or d antiquark (or quark).
It turns out that the heaviest of the four upsilon particles has sufficient mass to decay radioactively into two B mesons, the b quark and antiquark splitting up to go their separate ways in the two B mesons.
CESR is the only machine that can produce reasonably large numbers of the heaviest upsilon, so its collisions between electrons and positrons provide the most promising hunting ground for B mesons.
The first indication that the fourth upsilon did indeed decay into B mesons came when the team working on the detector known as CLEO discovered energetic electrons and muons, presumably from the decays of B mesons (New Scientist , vol 87, p 776).
Now the same team has more direct evidence.
This time the researchers have looked for steps in the decay chain of a B meson, in which the b quark converts first into a c quark and then into an s quark; this means that the B meson decays into a charmed D meson, and then a strange K meson.
The K mesons live long enough to produce tracks in the CLEO detector, so the team could work back from detected K mesons to hunt for those that seemed likely to have originated from a B meson.
In such cases the spray of particles emanating from the electron-positron collision would be entirely consistent with the steps expected for the decay of a B meson (see Figure).
From the 18 possible B mesons they were able to find, the researchers have deduced a mass of 5270 MeV for the neutral B meson and 5270 MeV for the charged B — some 5.3 times as heavy as the proton.
The B mesons can now be assured of a place in the tables of known subatomic particles.
Blind mites need vitamin A to ‘see’
AT FIRST sight it's something of a puzzle how invertebrate animals without eyes measure daylength.
But the answer to this riddle is that they have a receptor, most probably in the brain, that enables light detection to bypass normal, ocular channels.
In fact, even the sighted cousins of these creatures are thought to use the brain receptor for photoperiod perception.
Exactly how this extraocular photoreception works is still unknown.
But one attractive possibility is that it is similar to the normal mechanism used in eyes, which depends on the interaction of light with substances called rhodopsins, or their close chemical relatives, the porohyropsins.
Each rhodopsin molecule is made up of the aldehyde part of the vitamin A molecule and a protein.
Obviously, if vitamin A can be shown to be necessary for photoperiod detection by an extraocular receptor, it is likely that rhodopsins are at work.
This was the rationale behind a recent experiment carried out by Veerman and his colleagues at the University of Amsterdam (Nature vol 302, p 248).
The scientists chose an eyeless mite Amblyseius potentillae for their studies.
Mites are arachnids — close relatives of spiders and scorpions — but they have a lot in common with insects.
For instance, they may show the state of arrested development called diapause, well known in insects.
In Amblyseius , diapause takes the form of a temporary blockage of reproduction and is probably a device for preventing breeding in adverse conditions.
It is induced by daylength cues.
So, if you subject young mites to short days, they enter a state of diapause in the adult state of the life cycle.
If, on the other hand, the mites are kept in long days, or in continuous darkness, no diapause supervenes.
Clearly, the eyeless mites must have a photoreceptor somewhere.
This receptor can be disabled by forcing Amblyseius (which normally devours spider mites) to go on a diet of broad bean pollen.
If the mites are exposed to short days after this prandial insult, they don't show a diapause.
The significance of this result is that broad bean pollen is completely devoid of carotenoids, and some of these chemicals are the physiological precursors of vitamin A.
What the Dutch scientists did next was to supplement the pure pollen regime with various compounds and then see whether diapause could be induced by short daylengths.
If so, it would mean that photoreception had been re-established.
As supplements they tried three carotenoids (Pcarotene, 3-hydroxyechinenone, astaxanthin) and two vitamin A derivatives (the acetate and acid).
The outcome of this dietetic juggling was that although astaxanthin and vitamin A acid were ineffective, the other three compounds were almost 100 per cent successful at enabling diapause induction.
Taking due cognisance of biochemical pathways, the authors conclude that only substances metabolically convertible to vitamin A are capable of restoring photoreception.
So, the experiments produced strong evidence of a rhodopsin-like mechanism in the mites' extraocular receptors.
What's the significance of this convergence between eyes and daylength detectors?
It's already remarkable that the eyes of every animal examined to date, vertebrate and invertebrate, use rhodopsin type photochemistry.
Ambeyseius ’ receptor is a significant non-ocular addition to the list.
And it invites the conclusion that rhodopsin-like compounds are a particularly favoured way of going about light detection in the animal world.
But it's necessary to mention that there is some evidence that different photochemical mechanisms are used by certain brain based photoreceptors in insects.
Brick-eating butterflies
BRICKS, gravel and your car windscreen could play and important part in the sex life of the Purple Emperor butterfly (Apatura iris).
Oxford researchers have found that males of this species frequently suck such objects, sometimes even wetting a dry brick with excretions and then sucking them with their proboscises.
Such behaviour has been observed in other butterflies on tropical river banks.
The researchers believe that the Purple Emperors are sucking up sodium, and possibly potassium and calcium present in the brick and gravel following the evaporation of the water in which they were brought to the surface.
But why do only males feed in this way?
It appears that the male butterflies secrete sodium in their spermatozoa capsules (spermatophores) during mating, which the female then uses to construct her eggs.
This unusual involvement of the male in the egg-building process is by no means  negligible — after mating the male's body sodium is severely depleted.
TECHNOLOGY
Sulphides: the next deep-sea Klondike
MINERALS companies and geologists are turning their attention to a newly-discovered deep-sea phenomenon which promises an important source of metals.
Deposits of polymetallic sulphides, found mainly along rift zones in the Pacific Ocean, are generating excitement now that interest in manganese nodules is waning.
Mining companies all over the world set up consortia to study ways of mining the manganese nodules on the floor of the deep oceans, but have been unwilling to proceed until the world can agree on laws to cover deep sea mining.
But according to Conrad Welling, of the US company Lockheed, the way ahead lies in exploiting polymetallic sulphides.
These deposits are not only a potential source of copper, zinc and other metals, but are also of great interest to oceanographers for the insights they offer into the formation of metals on the ocean floor.
A team of American scientists lead by Robert Ballard first discovered an active metallognic ocean floor hydrothermal system along the Galapagos ridge in 1977.
Since then, researchers have found similar deposits along the east Pacific Rise, within the Guaymas Basin, off San Diego and at several sites in the south and central Pacific.
The deposits occur as massive bodies of ore pierced by occasional hot vents of ‘black smokers’, which pour out high temperature solutions, rich in metals.
The most thoroughly surveyed site is at a depth of 2000 metres in the Galapagos Rift Valley.
Samples from different sites contain on average 38 per cent iron, 6.5 per cent manganese, 0–3 per cent aluminium and smaller amounts of other metals.
The compositions vary from deposit to deposit: some samples from the East Pacific Rise contain almost 50 per cent zinc.
The genesis of the deposits is linked to their location, generally along the central axis of ‘spreading centres’, in the language of plate tectonics, where heat flows are at a maximum.
Here, oceanic crust is created from upwelling basaltic magma at the trailing edge of’ plates’whose leading edge is being re-melted deep beneath.
The combined processes of volcanism, tectonic fracturing and hydrothermal circulation together form massive deposits of sulphides.
Seawater percolates down through fractures, becomes super-heated and leaches metal from the rocks it passes through on its way back to the sea floor.
When the metal-rich solution, ejected at temperatures of up to 350°C, mixes with cold water, it rapidly precipitates out the metals in the form of sulphides.
At first sight, these deposits are of commercial interest.
But it is important to remember that they are two to three kilometres beneath the surface of the sea, and in some cases thousands of kilometres from the shore.
And unlike with manganese nodules, the technology to extract the sulphides is not available.
Despite the difficulties, a deposit of sulphides 100 km off the Northern California and Oregon, is attracting interest from companies.
Along with deposits near Hawaii, this is the only deposit that lies within the proposed 200-mile exclusive economic zone of the US.
This legal and political advantage is balanced by the higher order of technical complexity involved in exploiting sulphide ores.
While nodules are loose deposits, lying on the sea bed, sulphides are massive deposits below the ocean floor.
Exploration alone will be difficult enough.
Although big advances in  multibeam sonar and improved positioning equipment allow detailed surveys to be made, the only way to find what is in the deposits is to drill cores.
Such a programme, which would involve drilling from a surface ship such as the Glomar Explorer, would be very expensive.
Also, there is no portable submersible rotary corer that could do the job.
An alternative to mining might be to pump the superheated brine emerging from the ‘smokers’ directly to the surface.
Each litre of brine contains between 0–6 and 6.5 grams of zinc, However no one knows if the brine is concentrated enough to tap from a small area.
Nevertheless, American companies are interested, and the Woods Hole Oceanographic Institute in the US and the French national centre for ocean exploration are systematically exploring the mid-Pacific ridge.
But many of the companies interested have a potentially redundant nodule mining technology on their hands.
A government programme to encourage the exploitation of sulphide deposits might put the results of all that expensive research back to work again — but the question is whether the sulphide story will be a replay of the long and unproductive nodule saga.
Brighter future for the humble soyabean
SUCCESS with a new product and hopes for a novel pest killer are generating excitement about one of Japan's staple foodstuffs, the soyabean.
Japanese people consume the nutritious legume mainly as tofu (bean curd), or miso , a thick brown salty paste used for flavouring.
Several years ago,miso came under fire from researchers who claimed that it caused high blood-pressure, then Japan's number-one killer.
Predictably, sales slumped.
Now to the miso producers' rescue has come tonyu — soyamilk, In fact, soyamilk is not new.
The Chinese have drunk it hot, for more than 2000 years.
But many people find it unpleasant.
Recent refinements to production techniques have made tonyu palatable, and in the past three years sales have soared.
Manufacturers have been quick to point out the drink's advantages over ordinary milk: it contains no cholesterol, has a low fat content and is high in alkali.
On the proceeds of doubled sales, one former miso manufacturer near Nagoya is building a new factory which will produce one million 200-millilitre packages a month.
The firm is introducing boil-in-the-bag soups and desserts.
Another leading firm, Kibun, has signed a technology exchange agreement with the Swedish company, Alfa Laval, which will produce tonvit plant and equipment.
Kibun says that firms from 18 countries are interested in purchasing the hardware.
On the surface, the  burgeoning popularity of tonvit would seem good news for Japanese soyabean growers.
In fact, most soyabeans used to make the foodstuff come from the US, Japan imports 4 million tonnes of US soyabeans a year.
Unable to compete, domestic farmers at one stage looked set to go out of business.
Production in 1974 was down from the immediately post-war total of 600 000 tons to just over one sixth that figure.
But then the Japanese government swung into action.
The government is promoting the crop through subsidies to farmers and through research into automated techniques for cultivating soyabean.
Another way in which Japan is promoting the soyabean is through tackling the crop's major enemy, soyabean cyst nematoda.
The eggs of this parasitic worm can wait as long as 16 years for a suitable root to grow nearby.
The root gives off a chemical which incites the worms to hatch and crawl into it.
A group at the University of Hokkaido is trying to isolate this chemical, which it calls glycinoeclopin A. So far the group has managed to obtain a tiny portion — 0.5 milligrams — of the substance and now it is trying to discover the chemical structure of the material.
Japan faces up to the software crisis
THE COMPUTER industry in Japan is trying to solve its problems over producing software by fixing up deals overseas.
Companies in Japan have arranged contracts in which people from China, Taiwan and South Korea write programs for Japanese computers.
The industry is also interested in signing up people in Brazil to write programs (Brazil boasts a large number of Japanese emigres).
Under a plan by the Japanese Software Industry Association, Chinese students will work on computer programs for Japanese manufacturers.
In return, the Chinese will receive training.
Both Fujitsu and NEC plan to open software training centres in several Chinese cities.
Fujitsu has started negotiations on a joint venture with the Chinese Science Commission of Tianjin for the development of a computer system for the Chinese language.
In another move, Computer Applications Corporation, a leading Japanese software house, has started a joint venture  with a Taiwanese firm called Systex.
And Fujitsu has started to train South Koreans to produce software.
This is done under the auspices of the Japanese firm's subsidiary, Facom Korea.
Contracts overseas are one way that Japanese firms can fight back against a chronic shortage of trained programmers.
According to one estimate, the country could be short of as many as 180 000 computer specialists by 1985.
The computer business in Japan is unusual in that most software writing is done by people who use computers, as opposed to the manufacturers of the machines.
Computer owners in Japan do not favour the trend in the West of designing general-purpose software packages.
They prefer software tailored For a particular use.
THE programs will be produced either by the user company or by a software firm under its ownership.
In the short run this approach costs more.
A company that operates computers in Japan must employ its own software organisation with high fixed labour costs.
But the long-run benefits are compelling Custom-made software is often more reliable and has fewer ‘bugs’ or faults.
Also if the people who will later run the computer are also responsible for the software, then they are more likely to fit the programming to their own needs, which can save time and money later.
In Japan, computer users create some 87 per cent of their applications programmes.
Another 7 per cent is contracted with independent software house, and computer makers provide the remaining 6 per cent.
The software subsidiaries of a large computer users are among the 40 large data-processing firms in Japan.
They include Mitsui Knowledge Industry, Sumisho Computer Service and MSK Systems — subsidiaries of the Mitsui, Sumitomo and Mitsubishi general trading companies.
Nomura Computer Systems, which is owned by the largest Japanese securities house, ranks third among the largest information service companies.
This practice is not confined to the largest companies.
Medium-size enterprises such as machine-tool makers, now riding the wave of factory automation, are compelled to establish special software subsidiaries.
One such toolmaker, Toyota Machinery Works, employs about 50 software engineers and needs 100 more.
The preference for custom software has shaped the industry in another important way.
The hardware manufacturers themselves offer not only systems software, which comprises the most basic sets of instructions that make computers operate and with which users are normally powerless to interfere.
The manufacturers also assist in developing applications software for specific jobs.
NEC is the third biggest computer manufacturer in Japan after Fujitsu and IBM Japan.
The firm employs 30 000 software specialists as part of the parent company and another 3000 in 11 software subsidiaries.
Supplementing this permanent organisation are 4000 more software engineers and programmers supplied by around 250 subcontractors.
For the most part, these contract workers work under the supervision of permanent staff, performing more labour-intensive tasks.
Among the leading computer firms, Fujitsu and Hitachi have followed the course of making machines that are ‘plug compatible’ with those of IBM, the world's biggest computer company.
In other words, the machines use the same software as the American firm's products.
But NEC has eschewed this approach.
It relies instead wholly on software of its own design.
At Fujitsu, of 36 000 employees 6000 are engaged in software design and development.
In addition Fujitsu has created an average of five new software subsidiaries annually for the past three years.
The largest, Fujitsu Facom Information Processing (FIP), ranks among the top 10 information processing firms with a turnover for the fiscal year ending March 1982 of 9500 million yen ($34.93 million).
Not all of this represents work performed for Fujitsu however, nor is FIP restricted to software activities.
It maintains its own computer centre and since last July has incorporated Fujitsu's time-sharing division.
Although Hitachi has been overtaken in the domestic computer market by NEC, it was not from lack of commitment to software development.
Hitachi has 15 subsidiaries providing software services, in addition to its large in-house data-processing contingent.
Two of the top 10 data-processing firms in Japan are numbered among these subsidiaries: Nippon Business Consultants and Hitachi Software Engineering (HSE).
With a turnover of 8000 million yen, the latter is the largest software house in the country.
HSE was founded in 1969 primarily to supply Hitachi with programmers.
The 1900-strong organisation earns 40 per cent of its sales by providing services to other firms.
Japan tries to do better in software engineering by emphasising teamwork, ‘Team members who work together are, in their collective wisdom, far more effective than individuals working alone,’ says Yukio Mizuno, associate senior vice-president at NEC.
HSE has an independent division which aims to ensure high standards in software production.
The company also encourages employee participation in this process through small groups in which workers discuss ideas.
New firms can enter the software business relatively easily ‘All you need to establish a software house these days,’ says Mizuno, ‘is a desk, a chair and four or five programmers.
It's a process of biological reproduction as explosive as a colony of amoeba.’
Given what seems to be an insatiable demand — with simultaneous booms in office and factory automation, fuelled by the development of new Japanese language processing systems — Mizuno expects a steady stream of new entrants into the software service business during the coming five years.
In 1981, turnover of software houses from software development activities was more than five times that of 1975, with annual growth rates as high as 60 per cent.
However, employment in the industry scarcely doubled to 105 891, which means that productivity rose  appreciably due, at least in part, to better quality control measures.
Both the Ministry of International Trade and Industry (MITI) and the Japan Software Industry Association have programmes to improve the training and professional competence of software systems engineers.
People trained at the Institute of Information Technology, established by MITI in 1971, return to their original companies — users, mainframers or software houses — where they help to train junior engineers and programmers.
RESEARCHERS set a date with radiocarbon
THE TRIED-AND-TESTED archaeological technique of radiocarbon dating is due for a fillip later this year.
Engineers are putting the finishing touches to a roomful of scientific equipment in Oxford which will use a new technique to measure the amount of radioactive carbon in an ancient specimen.
With the apparatus, researchers should be able to analyse an item in 15 minutes when the current technique takes days.
Moreover, as a result of the £500000 Oxford project, archaeologists will have to give up for dating only a tiny portion of their specimen, 1 milligram or less.
Conventional methods of dating objects by analysing radiocarbon, a sample of between 1 and 5 grams is normally required.
Researchers are often reluctant to provide this weight of sample, especially when it has to be cut away from a valuable fragment of, say, bone or wood.
In traditional radiocarbon dating, an important archaeological tool for 30 years, workers measure the decay of radioactive isotope carbon 14.
In any organic specimen, carbon-14 is present in tiny quantities, being swamped by the more abundant isotope, carbon-12.
The proportion when the specimen is alive is constant at around one part in 10 12 .
But after death, the amount of radiocarbon decreases at a fixed rate: it halves every 5730 years.
Measuring the radiation emitted by whatever proportion of carbon-14 is left indicates how long the specimen has been dead, and hence its age.
Workers at Oxford University's Research Laboratory for Archaeology decided to try a different tack.
Instead of measuring the proportion of radiocarbon indirectly by detecting radiation, they set on quantifying the number of carbon-14 atoms in a given specimen.
The most difficult job is to separate carbon-14 from the far more abundant carbon-12.
In the Oxford project, this is done by producing, from a specimen of graphite, carbon ions which are accelerated at very high energy past an array of magnets.
On account of their different magnetic properties, weight and velocities, the carbon-12 ions follow a slightly different course from their radioactive counterparts and can thus be separated.
A spectrometer counts the number of carbon-14 ions left after the lighter ions are separated.
The equipment for funnelling off the carbon-12 takes up two sides of a workshop the size of a church hall.
The apparatus is controlled by a console would look more at home in a nuclear power station or in the cockpit of a jumbo jet.
Edward Hall, the director of the laboratory, says that archaeologists are keen to try out the new system.
He hopes that the equipment will be used 12 hours a day once demand builds up.
The Science and Engineering Research Council, which is providing the funds for the equipment, will coordinate a programme in which researchers from all over the country' will send specimens to the unit.
The new system should provide reliable dates for objects 60000 years old; the upper limit with existing radiocarbon techniques is 40000 years.
Tests with the new system have dated remains containing carbon with an accuracy of about 3 per cent.
The Oxford workers want to reduce this to I per cent before starting a full service.
Third World turns to computers
COMPUTERS can ease the financial problems of countries in the economically troubled Third World.
That is the opinion of the United Nations Industrial Development Organisation (UNIDO) which has teamed up with Apple, a leading American maker of microcomputers, to produce a package of programs aimed at the finance ministries of developing countries.
UNIDO's computer specialists in Vienna have written the programs, sold under the name COMFAR.
The $15 000. package includes training the people who will use the programs, plus regular updating of the software.
The programs will run on an $8000 Apple III computer.
According to Werner Behrens of UNIDO, the software will standardise the way countries draw up feasibility studies for development projects funded by, for example, the World Bank or the US's Agency for International Development.
With the system, a government official in, say, Zambia or Paraguay can punch in a 19-column set of data on local tax and interest rates, together with other factors important in planning a new dam or factory.
In minutes, the computer will produce 18 columns of net and discounted cash flows presented over a set period of time.
The advantage to the institutions providing the money — assuming enough countries follow the UNIDO format — is that proposals from many nations all contain the same essential data.
Machines made by Apple are the only microcomputers that can understand PASCAL, the language that COMFAR uses.
IBM, Digital Equipment Corporation, Philips and Wang also promise faster microcomputers that will handle the new Programs.
UNIDO will keep a close eye on the software, says Behrens.
Any tinkering by users would negate the principle of a worldwide standard.
Faster transplants
A COMPUTER system introduced by Japan's Ministry of Health has cut the time taken to match a kidney donor with the most suitable recipient from several hours to three minutes.
The system's central computer at the National Hospital in Sakura City connects seven centres in towns throughout Japan.
Plans call for another seven units to be added later, depending on the available budget.
Some 37000 people in Japan have said they are willing to donate kidneys.
About 2500 of these are registered in the computer, which stores relevant data on their blood and tissue types.
In the past 10 years, the average number of kidney transplants in Japan has risen from less than one a week to about one every day.
In the new system, after a registered kidney donor has died, the hospital to which he or she has been taken contacts the nearest computer centre.
This then chooses the most suitable hospital among those in its district that can perform a kidney transplant.
Kidneys must be removed within 90 minutes of death and transplanted within 48 hours.
The chosen hospital dispatches a team of doctors to remove the organ.
At the same time, samples of blood and tissue from the donor are sent to the centre for tests that take four or five hours.
The results are fed into a terminal.
Three minutes later, the computer prints out a list of 60 names of suitable recipients, together with their relevant data.
The first 20 live closest to the hospital that is to do the transplant, the next 20 are somewhat further afield and the remainder are scattered all over the country.
Specialists then select and contact the most suitable recipient.
The system may be expanded in future to handle records on registered donors and follow-up information on recipients.
It will also become a national database for information related to kidneys.
Video upset
THE HOME video market is due for a big upset later this month.
JVC, Ferguson, Hitachi and Fisher will all launch VHS video recorders that run at half speed, to double the recording and playback time available from a standard VHS cassette.
The new machines will cost only £50 more than current single-speed VHS models and in the long-play mode give up to eight hours' playing time, instead of the normal maximum of four hours.
This move negates the last remaining advantage of the dying V2000 system developed by Philips and Grundig.
This uses a flip-over cassette which gives four hours' playing in each direction.
Last year Grundig promised to launch an ‘autoreverse’ machine, to give eight hours' continuous recording on a V2000 cassette, but it never appeared.
The half-speed VHS machines Hill also undermine efforts by the film industry to put a tax on blank video tape, like that imposed in Sweden, to compensate the industry for losses due to piracy.
It will be impractical to fix a levy that is as fair for the three million owners of normal-speed machines as it is for future owners of half-speed machines.
A half-speed recorder would effectively halve the rate of tax that consumers would pay, should a levy be introduced.
The VHS video system was launched in Japan and the US earlier than in Britain.
VHS machines across the Atlantic can record and play back at three different speeds; in two, four or six hours.
With specially thin tape, Americans can obtain eight hours from their systems.
When the VHS system was launched in Britain five years ago, a single tape speed (2.34 cm/s) was chosen to give a playing time of three hours per cassette.
This was later extended to four hours by using thinner tape.
Now the VHS manufacturers have designed a machine which can be manually switched to half speed during recording.
When the machine is playing back, the manual switch is inoperative.
Circuitry senses the recording speed and switches playback speed accordingly.
In this way it is possible to mix long-play and standard-play recordings, even during the same programme.
Picture and sound quality are inevitably degraded, especially the sound of music.
But the system is good enough for recording TV programmes for watching in the home.
Epoxy promises new line in road markings
PAINT could be on the way out as a way of marking lines on roads.
Federal highway engineers in the US are promoting a new material based on epoxy resin which is supposed to be more durable.
But already plans to use the substance have stirred up controversy.
Officials in charge of the roads in California and Texas say the material, called epoflex, is difficult to apply and may not do the job intended.
The Federal Highway Administration says it has tried out epoflex in Four states.
The trials showed the material should last up to 10 times longer than ordinary paint.
The potential savings are enormous.
Each year the US uses 110 million litres of paint to ‘stripe’ about 3 million kilometres of road at a cost of $120 million.
To promote epoflex, the administration is telling states that it will put up the cash to lay test stripes.
It will also pay to evaluate how the material is coping with weathering and wear from traffic.
The administration has spent $500 000 developing epoflex, which was invented by John Dale, an engineer at the Southwest Research Institute in San Antonio, Texas.
The exact ingredients are secret.
The material is made of liquid and solid epoxy resins, pigment, filler and tiny beads which reflect light from headlamps at night.
Unlike most epoxy systems, the material requires no hardener.
It sets best, however, when heated to 230°C.
Setting time can be less than 5 seconds, according to Dale.
He points out that as well as being more durable than paint, epoflex contains no solvents and so is non-polluting.
The Federal Highway Administration's trials have supported Dale's claims.
In
Redondo Beach in California, for instance, the material withstood a battering of 42000 cars a day for six months, while paint needed a fresh application every six months.
But not everyone agrees about the quality of epoflex.
‘Our man in Houston told me to come down and look at it [epoflex]in a hurry or it will be gone,’ said Joseph Raska, materials and test paint engineer for the Texas Department of Highways.
‘And that was after only two months.’
Don Chatto, a specialist in road marking at California's transportation laboratory, said the substance is difficult to apply.
He said that widespread application will depend on the availability of ready-mixed, preheated epoflex in 25 kg blocks.
Preheating, says Chatto, could change the characteristic of the material.
Dale says that anyone who is having problems with epoflex is not following the instructions.
Biochemists do the splits over proteins
A GROUP of biochemists at the Atomic Energy Research Establishment in Harwell has adapted the technique of electrophoresis so it can be used in industry.
The Harwell scientists, headed by Chris Lambe, have produced a machine that will separate large protein molecules from the complex soupy mix that forms the product of many biochemical reactions.
CJB Developments of Portsmouth is making the separator.
It will go on show for the first time at the Biotech ‘83 exhibition in London next month.
The new separator relies on electrophoresis: different molecules are pulled off in different directions toward positive or negative electrodes.
In electrophoresis used on a laboratory scale, the separation takes place slowly in a gel that prevents convection currents mixing up the products.
This technique normally produces materials in quantities of a few micrograms.
Engineers have recently scaled up the process to separate at a rate of a few milligrams per hour.
But it is still too slow to cope with the quantities needed for industrial-scale separation.
The Harwell separator, about 1 metre tall, comprises one tube within another.
The inner tube is negatively charged and the outer tube is made positive.
The mix is pumped gently down the inner tube, out through the bottom and up the outer tube.
Scientists can adjust the rate of flow so that positively-charged molecules drift to the inside while negatively-charged molecules travel to the outside.
The rate of movement depends on the amount the particles are charged.
The process is so effective that by the time the molecules reach the top of the outer tube, they are arranged in a series of concentric rings, each representing one type of molecule or cell.
The rings can then be split in to 30 different fractions, separated by partitions at the top of the tube.
The key to the system is that the inner tube is stationary while the outer tube rotates smoothly about 150 revs/minute.
This keeps the solution flowing smoothly and, together with keeping the solution at 2°C, stops convection currents building up.
The speed of separation — the solution only takes about 30 seconds to move through the outer tube — also prevents too much heating.
The first major use for the machine will be in separating Factor 8, needed by haemophiliacs to make their blood clot, from human blood plasma.
Tests show the Harwell system is nearly twice as efficient as conventional methods at obtaining Factor 8.
The equipment can separate abnormal from normal red blood cells.
It can also isolate different isomers of the same compound that carry different charges.
A few words with Ruby
Adrienne Zihlman and Jerrold Lowenstein
A living fossil gives the first interview in her career, and describes life as it was when she first roamed the Earth
READERS of New Scientist will be familiar with the sensational discovery two years ago of a young Australopithecus female frozen in a glacier atop Mt.
Kilimanjaro for three million years.
The co-discoverers, fossil hunters John D. Hansom and Roderick Luckey, were inspired to explore the Kilimanjaro glacier by the success of Russian palaeontologists in retrieving whole frozen mammoths from the Siberian permafrost.
Equipped with a refrigerated camper, so that specimens found in the glacier could be preserved intact until studied, Hansom and Luckey were astounded and thrilled to discover a perfectly preserved specimen of a new hominid species two metres inside the glacier.
Now named Australopithecus tanzaniensis , the specimen was a female, age about 30 (plus three million).
She was promptly dubbed ‘Ruby’, as she was found on Tuesday and reminded Hansom of the Rolling Stones' song Ruby Tuesday .
Luckey, an expert on East African folklore, was reminded of the Masai proverb, ‘Human life is short, but a ruby lasts for thousands of generations.’
Fortunately, they were thus able to agree on her name.
Ruby was flown, still frozen, to the London Institute of Cryogenic Research, where biopsies revealed that her cellular structure, even her DNA, remained remarkably intact.
Therefore, an attempt was made to restore Ruby to life by a combination of very slow thawing, cardiac resuscitation and careful monitoring of serum electrolyte balance.
As everyone now knows, this unique experiment was a success, and mankind obtained a witness of human life on Earth three million years ago.
But how to tap this priceless resource?
Ruby attempted to communicate by a combination of gestures, clicks, and  guttural sounds unlike any known language.
A team of linguists and experts in primate communication have been working intensively with her during the past year to teach her English.
Though Ruby's brain weight is only 400 grams, about a third that of a modern human's, she has proved an apt pupil and now understands and uses a vocabulary of about a thousand words.
Recently New Scientist was given the opportunity to interview Ruby, on the occasion of her first visit to the British Museum (Natural History).
Appropriately enough, we met in the Hominid Room of the Natural History museum, a light spacious rectangular chamber with a glass wall on one side that looks out on a grassy park.
In cases around the room lie the collected fragmentary treasures of human ancestry, mostly skulls, jaws and teeth with a few partial limb bones.
The most precious specimen of all, and — the oldest, sat on a high stool.
The size of a five-year old, though quite adult in appearance, she was wearing a well-tailored white cotton short-sleeved blouse, a blue denim wraparound skirt, and open-toed sandals.
Her short wavy black hair was combed neatly back from a rather narrow sloping forehead with prominent brow ridges.
The brown hairless face with its flat nose, projecting jaws and large teeth revealed in a friendly smile, is decidedly more human than apelike, though there are definite resemblances to the chimpanzee.
She has rather long arms with slightly curved fingers, short legs and broad feet.
Ruby greeted us with a brisk, ‘Good morning.
How d'you do?’
The voice was distinctive, at the same time hoarse and shrill, rather like that of the late chanteuse Edith Piaf.
We found ourselves uncharacteristically hesitant.
How do you begin an  interview with a three-million-year old fossil?
After a brief pause, we blurted out the obvious opener, ‘How does it feel to be alive again after all this time?’
‘Far out!’ she replied with gusto.
Clearly, the linguists had done their job well, though the idiom was a bit dated.
‘Much rather be alive than dead.’
‘And what's your reaction to the modern world, or at least what you've seen of it here in London?’
‘It's too much,’ she said slowly, wrinkling her sloping brow thoughtfully, as though she would elaborate further.
But then she merely repeated, ‘It's too much.’
After these preliminaries, we went to our main purpose for the interview and asked Ruby to describe for us what life was like in the African Rift Valley some 1500 generations ago.
She replied that she had lived in a small group of about 10 people: she indicated the number by holding up both hands with the fingers spread.
They wandered the  savannah during the day, looking for food, and sometimes met and socialised by the lake with other groups of hominids.
It was during one such encounter that she met her mate, Klono.
He wooed her by sharing with her a delicious baobab fruit.
From her account males did not often share their food with others, and the feeding of children was largely the mother's responsibility.
Before the rainy season.
Ruby — whose name in Australopithese was Glubu — gave birth to a son, Krono, her only child as it would turn out.
She carried him on her back for much of the next three years, until her back ached, and he was forced to fend more for himself.
We asked her to describe the other members of her group, and she told us that it was composed largely of female relatives, their mates and children.
‘There was my mother and my sister, Gruthu, and also my mother's sister Gkutu.
Mother's mate died, but Gruthu's mate, Ktholo, and Krotho, Gkutu's mate — my uncle — were also in the band.
Then there were the children, Gtudu and Krotho, my cousins, and my young brother Klogo.’
There is no English equivalent for these names as Ruby pronounced them.
We later asked one of the linguists who had worked with her whether these sounds bore any resemblance to the click languages of the African Bushman-Hottentot group and were informed that there are superficial resemblances but that Ruby's unique phonetics derive from distinct differences, presently the subject of a monograph, in the anatomy of her larynx, palate and nasal cavities from those of Homo sapiens .
We asked Ruby what kind of food they ate, and she mentioned berries, beans, nuts and roots.
She was even able to identify species in a catalogue of edible African plants available at the Museum.
It seems that her own particular favourites were a kind of winter melon, termites and caterpillars.
We noted the omission of any mention of meat and asked her particularly about this, as there have been so many debates among anthropologists in recent years as to the origins of hunting and meat-eating.
From another encylopedia, this time of African animals, she identified for us some of the small animals they occasionally caught and ate.
They included hare, guinea fowl, small (or baby) duiker, gazelle and antelope.
Elephant and large antelope bones have been found at a few African hominid sites, dated at nearly two million years.
There has been much disagreement among palaeontologists whether this indicated hunting or scavenging, but Ruby told us that she and her kind stayed as far as possible away from these large animals, for the freshly expired bodies were invariably surrounded by hyenas and big cats.
While she was identifying these predators in the encyclopedia, Ruby became noticeably paler and agitated.
She told us that the hominids were quite vulnerable to these carnivores, which in her time included the sabre-tooth cat, and were often killed and eaten.
In fact, her mate Klono had been killed and dragged off by a leopard one night when her son Krono was about a year old.
When the hominids could not avoid the predators during the day, they would usually succeed in driving off danger by shouting, jumping up and down, and throwing rocks and sticks, behaviour which, from her description, resembles that observed in groups of chimpanzees.
‘Did you use tools and weapons?’ we asked, and were not sure she would understand those terms.
But it seems that her discoverers, ‘Jack and Rod,’ as she referred to them, had probed deeply into that issue, which is, of course, one of the critical ones in human evolution, so she was well prepared.
‘Weapons, no,’ she replied.
‘As I said, we threw rocks and sticks, but were lucky if we hit anything.
From the cricket and football games Jack and Rod have taken me to, I'm amazed how you modern people can throw and kick things where you want them to go.
Tools, yes.
We used sticks to dig up roots, and gourds to carry water, and vines around our shoulders to help carry babies.
Sometimes we made shelters with leaves and branches to keep off the rain.
We broke nuts and bones with rocks, and we even fished for termites with sticks, the way chimps do.’
A clever uncle
All the things she described can in fact be done by chimpanzees.
The earliest evidence of stone tools — modified or used by hominids — does not appear in the archaeological record until 2 million years ago.
We wanted to know whether Ruby and her kind ever used another object to modify the rocks or sticks they found, to make true tools, in the human sense.
She said, ‘There was only one in my group, my uncle Krotho, who did those things.
He knew how to break one rock with another rock so they were sharp and then used them to make a point on a stick.
We thought he was a…
’ She hesitated, trying to find the word, ‘A magician,’she said triumphantly, with her beguiling smile.
We were impressed with the fluency with which she manipulated her thousand word vocabulary, though speech itself did seem to be a considerable effort for her.
She used her face and hands much more than the average Englishman, though perhaps not more than the average Italian.
As is well known, chimpanzees can be taught to communicate with sign language, though there is no evidence that they have such a language in their natural state.
We asked Ruby whether the same was true for Australopithecus tanzaniensis , whether they actually had speech or only the capacity to be taught speech.
‘Yes,’ she replied, ‘we had speech, but we didn't have as many words and names for things as you have now.
Most of the groups that met by the lake could speak to each other.
Sometimes a new one would come that spoke another kind of speech.’
Another controversy which we hoped Ruby would be able to resolve for us was the issue of whether there was one species of hominid or two living on the African  savannah three million years ago.
The fossil finds in Hadar, Ethiopia, from that time have been variously interpreted as indicating either two or a single species with extreme sexual dimorphism (size difference between males and females).
In response to our inquiry, Ruby indicated that the males of her kind were only moderately larger than the females, but that there was another type of upright hominid on the  savannah .
‘They were much bigger than we were.
We called them The Big Ones.
They didn't have speech, and they were not as smart as we were.
We laughed at them because they were so big and dumb.’
At this she burst into loud laughter that sounded rather like the hooting of a siamang and slapped her thighs with her hands.
When she had subsided, and we had recovered from our surprise at this outburst, we asked her whether the small and large hominids were strictly  savannah species or whether they spent much of their time in forests.
Anthropologists disagree over whether these early australopithecines retained a chimplike ability to climb trees, despite the evident bipedal features of their anatomy.
Ruby surprised us again by her response.
‘We and the Big Ones lived only on the  savannah .
Our ancestors were apes who left the forests, because there were too many apes and not enough food.’
‘How do you know that?’ we asked.
‘My grandmother told me.’
‘What kinds of apes lived in the forest in those days?
Were they anything like the apes that live today?
But perhaps you haven't seen the apes that live today.’
She told us that she had made several visits to the London Zoo and so was familiar with the appearance of modern apes.
According to her, there were two kinds of apes in the old days, and both looked a lot like chimps.
The big kind were bigger than the common chimpanzees at the zoo, but not as big as gorillas.
The little kind were very much like pygmy chimps,— she stumbled over the word pygmy, then quickly added, ‘You know,Pan paniscus ,’ and she flashed the same toothy grin of triumph that pronouncing ‘magician’had evoked.
Evidently, she took pleasure in surprising her tutors with new vocabulary.
‘The little chimps were our ancestors, or so my grandmother told me.
You have probably noticed how much I look like them.’
And so we had, but were too polite to comment on the truly striking resemblance.
‘Well, you certainly are clearing up a number of problems in prehistory for us.
There's another one, on which your discoverers, Hansom and Luckey strongly disagree…‘
She burst into that hooting laugh again.
‘Jack and Rod disagree about everything , and each one wants me to tell him he is right.
Half the time I don't even understand what they are fighting about.’
‘Their strongest disagreement, at least in public, is about the origin of us modern humans.
Hansom believes that your species,Australopithecus tanzaniensis , was our ancestor, and Luckey maintains that this belief is wrong and that our ancestor was another species of the genus Homo .
Do you know which is correct?’
‘How should I know?
I was frozen in a glacier for the last three million years.
If I say one of them is right, the other will be mad at me.
But,’ she paused here and then thoughtfully continued, ‘you people are a lot bigger than we were.
Maybe your ancestors were the Big Ones.’
She tried to suppress a laugh but a brief honk came through.
We asked if she was getting tired of being subjected to all these questions, and she said that she had a few more minutes before she had to go and meet Jack and Rod for lunch.
We said we would like to ask her about males and females, and it was evident that her interest picked up.
‘A current hypothesis on the origin of bipedalism…’ we began, but she interrupted, ‘Please keep it simple.
Remember my 400 gram brain.’
We tried again.
‘Do you know Dr Aaron Killjoy?’
‘Jack's friend,’ she replied at once.
‘The one who thinks everything started with sex.’
‘Right.
Killjoy explains bipedalism — that is, walking on two legs — as a way of life that left the hands free for other things.
He proposes that males developed bipedalism so that they could go out and bring back food for the females.
Females, then, could have more babies than the apes could have, because they wouldn't have to carry them around looking for food.
The females could stay in one place, taking care of the babies with their free hands, and in return for finding her and the infants a male would have his own female always available for sex.’
Ruby sighed, ‘One thing hasn't changed in three million years.
Males still think sex explains everything.
The males I knew didn't share food unless they wanted sex that minute.
But it is true, our mates worried that we would have sex with other males when they weren't there.’
We asked whether their fears were justified, but Ruby only smiled.
‘just a couple more questions.
How did you happen to wind up inside that glacier?’
‘After the rainy season, the berries high on the mountain were really yummy.
One day my son Krono and I were there, too busy eating to watch for trouble, and a big bird came down and took him away.’
She flipped through the encyclopedia and pointed to a monkey-eating eagle.
‘The bird's mate came down for me, and I jumped into a crack in the ice.
Next thing.
I woke up in hospital here.’
‘Are you impressed with our modern civilization, with all the technical progress?’
‘I love the telly and the movies, but I miss the animals, even the ones I was afraid of.
I cry whenever I go to the zoo.
It's still hard for me to cope with seeing so many people everywhere.’
‘What are your plans for the future?’
‘The BBC is doing a ten part documentary on my life,Ruby, Woman of the Pliocene .
After that, I'm going to appear with Jack on the Today show in New York, and I have an offer to star in a new Tarzan movie.’
‘You've been seen around London lately with both John D. Hansom and Roderick Luckey, and rumour has it that both men want to marry you.
Can you tell us about that?’
The little hominid smiled ruefully, and replied, ‘I adore both Jack and Rod.
I owe my life to both of them, and we're all good friends.
But I feel I'm much too young to marry and settle down now, at the start of my career.
Don't you agree?’
‘Absolutely,’ we responded, and thanked her for taking time from her busy schedule to talk with us.
Then we left the Hominid Room and its lifeless fossils and walked together out of the Museum.
Ruby straddled a child's moped and, as though mounted on a Wellsian Time Machine, skilfully manoeuvred into the heavy traffic on Cromwell Road.
CAN A BEE BEHAVE INTELLIGENTLY?
James L. Gould and Carol G. Gould
Most — though not all — of a bee's behaviour is the result of innate programming and makes no intellectual demands.
But like every other species, including the human, the bee is just as clever as it needs to be.
WHEN A foraging honey bee finds a new source of nectar or pollen, she returns to the hive to recruit help.
She performs a ritualised dance that tells the other bees the distance, direction, and quality of the food.
They ‘memorise’ the information she supplies, process it somehow, and then, compensating for crosswinds and the movement of the Sun, fly out on their own directly to the flower patch.
This behaviour looks on the surface like a complex communication system, and the participants seem to be acting at least intelligently, even rationally.
The more we learn about bees' capabilities, though, the more glaring their limitations become, and the question of what constitutes intelligence emerges as a central issue in understanding behaviour.
Largely as a result of Donald Griffin's book The Question of Animal Awareness (Rockefeller UP, 2nd ed 1981), ethologists have begun to re-examine the issue of animal intellect and to ask whether the organisms they study are, as we presume ourselves to be, something more than mere mindless circuitry.
But the mind is, by nature, a private organ.
How are we to judge from an animal's overt behaviour whether we are observing a well-oiled machine or a creature with some degree of intelligence and creativity?
Particularly with insects, whose chitinous exoskeletons make it difficult to consider them in anthropomorphic terms, how are we to discover the extent to which they might be acting intelligently?
Several lines of evidence for insect intelligence have come to the fore, but a little careful thinking, observation, and experimentation indicate that most of these criteria are untrustworthy.
One intuitively powerful argument, for instance, is that since animals regularly face problems and solve them in sensible ways, they must have some intellectual grasp of the problem.
When a honey bee, for instance, encounters a dead bee in the hive, it very properly tosses it out of the colony.
But experience tells us that adaptive behaviour most often reflects the intelligence of evolution rather than that of the animals it has so carefully programmed.
Bees recognise their dead colleagues by means of a ‘sign stimulus’— a single key feature of an object which is taken to represent the entire object.
In this case a special ‘death odour’, possibly oleic acid, releases the act of removal.
So mindless is the wiring of this sensible hygienic behaviour that a drop of oleic acid on an otherwise innocuous piece of wood or even on a live bee results in the removal of the offending object.
The sight of one bee carrying out a struggling sister or even the queen should convince us that behaviour can seem intelligent in its normal context without any need for the intellectual participation of the actors.
A second criterion frequently suggested is that the very regularity and invariability of such robot-like behaviour may be a guide to what behaviour is performed automatically and without the need for thinking.
As we all know from personal experience, intellect will often come up with two very different solutions to the same problem in two different individuals, or even in the same individual on two different occasions.
An automatic computer would come up with one ‘best’ answer.
When the 19th-century French naturalist Jean Henri-Fabre interfered with the prey-capture ritual of a cricket hunting wasp by moving its paralysed victim, he stumbled upon some of the wiring that runs the wasp's routine.
The wasp, whose behaviour appears eccentric but intelligent, invariably leaves the cricket she has caught lying on its back, its antennae just touching the tunnel entrance, while she inspects her burrow.
Each time Fabre moved it even slightly away from the entrance, the re-emerging wasp insisted on repositioning the cricket precisely, and inspecting the tunnel again.
Fabre continued this trivial alteration 40 times and the wasp, locked in a behavioural ‘do-loop’, never thought to skip an obviously pointless step in her program.
Clearly the wasp is a machine in this context, entirely inflexible in her behaviour.
The remarkable persistence of the wasp's performance serves also to remind us that most other animals have contingency plans to extricate them from such behavioural culs-de-sac .
By far the most common escape mechanism for organisms ranging from bacteria to human beings is ‘habituation’, a kind of behavioural boredom by which an animal becomes less responsive as it encounters the same stimulus repeatedly.
But habituation and other such escape strategies are not the result of any active intellect.
They are merely sophisticated programming ploys, and in the sea slug Aplysia , the neural and biochemical bases of the machinery are pretty well understood.
The mindlessness of this acquired behavioural numbness is illustrated by the contrary phenomenon of sensitisation: almost any irrelevant but novel stimulus can instantly destroy habitation's insensitivity.
Other sorts of seemingly intelligent behavioural variability, though, cannot be accounted for either by ‘noise’ in the computer or by habituation.
Honey bees, for example, show spontaneous preferences for certain colours and shapes of artificial flowers, with many-petalled purple flowers being the most attractive to the apian mind.
This display of aesthetic preference is not absolute, but probabilistic: given a choice between two colours that we know from learning experiments they can distinguish reliably — purple and blue, for example— the bees will choose their favourite, purple, only 70 per cent of the time rather than 100 per cent .
Similarly, in a conflict an animal will sometimes fight and sometimes flee.
Even in experiments in which care has been taken to factor out the role of immediate past experience, this sort of predictable variability persists.
Can the perplexing unreliability of animal behaviour be taken as evidence for something more (or perhaps less) than machinery making decisions?
Probably not.
Game theory demonstrates that it is usually most adaptive to be variable or unpredictable, so long as evolution or personal experience takes care to set the odds appropriately.
Though flowers may more often be purple than blue, it makes sense to try blue coloured objects from time to time rather than to concentrate exclusively on purple.
Even this sort of quasi-aesthetic ‘decision’ makes enough evolutionary sense that there is a good chance that it results from programming rather than intelligence; and in most carefully studied cases it is clear that variability is innate.
But though a great deal may be programmed into animals, there must surely be a limit to the complexity possible.
There must be a point beyond which no set of built-in computer-like elements can suffice to account for an animal's apparent grasp of its situation, particularly in the face of variable or unpredictable environmental contingencies.
The difficulty in drawing this intellectual line, however, is daunting.
Some of the most impressively complex examples of behaviour we see are known to be wholly innate.
The intricate knot-tying nest building of weaver birds is a case in point, but given the  undoubtedly limited intellectual ability of the performer, surely the construction of orb webs is even more impressive.
In total darkness, without prior experience, and with the location of potential anchor points for the support structure unpredictable, a mere spider sets about constructing a precise and complex network of several different kinds of threads held together with hundreds of precisely placed ‘welds’.
It automatically repairs even damage that occurs during construction.
All this is accomplished through one master program.
and several subroutines, and requires no conscious grasp of the problem.
The use of subroutines to deal with the unpredictable is especially obvious in navigation.
Honey bees, for example, regularly use the Sun as their compass, compensating for its changing azimuth as it moves from east to west.
This is a formidable task even for a human navigator, but as we have found out in the past few years, the bees' trigonometric adjustments are perfectly mindless, depending only on a memory of the Sun's azimuth relative to the bee's goal on the previous trip (or day) and an extrapolation of the Sun's current rate of azimuth movement.
The strategy is innate, though the program must include steps for measuring the relevant variables when necessary.
Bees recognise the Sun by an equally innate criterion — its low ratio of ultraviolet to visible light — so that a dim, 10 degree, triangular, highly polarised, green object against a dark background is just as acceptable as the actual, intensely bright ½ degree, circular, unpolarised white Sun which the bees see almost every day in the normal sky.
When the Sun is invisible (obscured perhaps by a cloud, a landmark, or the horizon) the bee's whole Sun-centred system is discarded in favour of a backup system — a separate navigational subroutine — based on the patterns of polarised light generated in the sky by the scattering of sunlight.
This analysis itself is composed of a primary and backup system, and uses sign stimuli and very simple processing.
When the polarisation is unavailable as well(as on overcast days, for example ), bees fall back on yet a third system, based on landmarks, and there is no reason to suppose we have exhausted the set of fail-safe plans built into bees.
The apparent complexity of the formidable navigational behaviour that many insects display is, in fact, based on the interplay of groups of subroutines which are themselves quite simple.
They depend as a rule on the same sorts of schematic stimulus-recognition systems and simple processing seen in less elaborate behaviour.
Since a staggering degree of behavioural complexity can be generated by a set of individually simple subroutines, mere complexity of behaviour cannot be in itself a trustworthy guide to intelligence.
Does learning involve intelligence?
Another commonly-accepted indication of intelligence is the way animals deal with the unpredictable contingencies of their world through learning; and it is here that our intuition tells us that we must be dealing with something very like intellect.
After all, learning suggests to most of us some degree of understanding, some conscious comprehension of the problem to be solved.
Alas, headless flies can learn to hold their legs in a particular position to avoid a shock, and even solve the problem faster than those still encumbered with brains.
Learning theory has traditionally recognised two general sorts of learning: associative learning (also known as classical or Pavlovian conditioning) and trial-and-error learning (also known as operant or Skinnerian conditioning).
Associative learning is the process by which an animal comes to replace an innately recognised cue — the sign stimulus — with another cue or set of cues.
It is nature's version of inductive reasoning: animals learn only cues which tend to predict the imminent arrival of something desirable, like food, and the reliability of the new cue does not need to be by any means perfect.
Trial-and-error learning involves learning to perform a novel motor behaviour, which is used to solve a problem posed by nature.
Animals discover by experimentation what works and what does not, and so experience shapes the behaviour.
This process is in many ways analogous to deductive reasoning.
To understand the role of inductive and deductive learning in the lives of animals and how these processes relate to the issue of intelligence, let us look at how they work in honey bees.
As we shall see, there is much in the organisation of bee learning that suggests the gears and wheels of an automatic pilot rather than any aware intelligence.
When a honey bee discovers a flower, for example, she sets in motion a learning sequence which seems utterly mechanical in nature.
A forager learns many things about a food source that aid her in the future, including its colour, shape, odour, location, nearby landmarks, time of nectar production, how to approach, land, enter, and reach the nectar, and so on.
Colour learning, for instance, has all the marks of associative learning: bees have an innate program which recognises flowers by their dark centres and light petals (as seen in ultraviolet light — these markings are usually invisible to our eyes).
After it has served its purpose, though, this sign stimulus is replaced by associative learning with a far more detailed picture of the flower.
Bees learn colour only in the final three seconds as they land: the colour visible to the bee before the landing sequence, the colours it sees while standing on the flower to feed and while circling the blossom before flying off, simply never register.
Experimenters can change them at will and the bee will never be fooled.
A naive bee carried to the feeder from the hive and placed on the food source will circle repeatedly after taking on a load of sugar water as if ‘studying’ the source, and yet when she returns a few minutes later she will be unable to choose the correct feeder colour.
And yet, so mechanical is this learning routine that if we interrupt such a bee while she is feeding she must take off and land again of her own accord, that landing permits her to choose the correct feeder colour on her next visit.
Similarly, bees learn landmarks after taking off: a recruit who arrived and fed at the feeder, but was transported back to the hive while feeding, returned without the slightest memory of the landmarks she must certainly have seen on her arrival.
Desirable imperfection
Other aspects of the associative component of flower learning seem equally curious.
Although a bee learns a flower's odour almost perfectly in one visit, she must make several trips to learn its colour with precision; and even then a bee never chooses the correct colour 100 per cent of the time.
It learns shape less quickly, and time of day more slowly still.
It is as though perfection, clearly possible in other contexts, is not in this case desirable.
It appears, in fact, that the speed and reliability of a bee's flower memory at least roughly corresponds to the degree of variability it is likely to encounter among flowers of the same species in nature (including variation from day to day of an individual blossom).
In fact, the rate at which a bee learns each component differs dramatically between various geographic races of honey bee, strongly implicating a genetic basis for the different learning curves.
Once a bee has learned how to recognise a particular kind of flower and when and where to find it, it is as though the information is stored in the manner of an appointment book.
As a result, changing any component of the set — the odour, say, which is learned to virtual perfection after one visit — forces the bees to relearn painstakingly all the other pieces of information at their characteristic (slower) rates even though they have not changed.
So, logical and impressive as the associate flower learning of honey bees seems, these hard-working insects appear simply to be well-programmed learning machines, attending only to the cues deemed salient by evolution (and then only in well-defined contexts and often during precise critical periods)— and then filing the information thus obtained in pre-existing arrays.
Nothing in this behaviour, wonderful as it is, suggests any true flexibility or awareness.
Nor is the situation any different when we look at the trial-and-error component of the behaviour by which bees learn to harvest flower species efficiently.
We can see that the widespread strategy of programmed learning is the means by which the genes tell their dim-witted couriers when and what to learn (how else could an insect reason it out?) and then what to do with the knowledge thus obtained.
There are, however, cases of apparently self-directed learning that may admit of another explanation.
Indeed, one of the main factors leading to the demise of classical behaviourism was the discovery that animals can learn a motor behaviour — which way to run in a maze to get some food — without the need for either associative learning or overt trial-and-error experimentation.
A rat, for instance, carried passively to each of two ‘goal boxes’ at opposite ends of a runway and shown that one contains food and the other does not will, when released, run unerringly to the box with food.
This phenomenon, which we call ‘cognitive trial-and-error’, requires a deductive process to go on inside the mind of the animal without its actually trying different behaviours.
The animal, be it the rat in its maze of a  chimpanzee gazing from a group of boxes to a clump of bananas hung just out of reach overhead, must reason out a course of action in its mind.
Here is something that seems very like intelligence, and we must ask whether it is really that, or merely another clever but mechanical programming finesse that we do not yet see.
There are among honey bees three reported examples that appear at first glance to qualify as cognitive trial-and-error.
One instance revolves around their avoidance of alfalfa (lucerne).
These flowers possess spring-loaded anthers that give honey bees a rough blow when they enter.
Although bumble bees (which evolved pollinating alfalfa) do not seem to mind, honey bees, once so treated, avoid alfalfa religiously.
Placed in the middle of a field of alfalfa, foraging bees will fly tremendous distances to find alternative sources of food.
Modern agricultural practices and the finite flight range of honey bees, however, often bring bees to a grim choice between foraging on alfalfa or starving.
In the face of potential starvation, honey bees finally begin foraging on alfalfa, but they learn to avoid being clubbed.
Some bees come to recognise tripped from untripped flowers and frequent only the former, while others learn to chew a hole in the side of the flower so as to rob untripped blossoms without ever venturing inside.
Who has analysed and solved this problem — evolution, or the bees themselves?
It may be that both cases are standard, pre-wired back-up ploys: differentiating tripped from untripped flowers could simply be a far more precise use of the associative learning program, while chewing through may be a strategy normally held in reserve for robbing flowers too small to enter.
Buzzing with anticipation
Another slightly eerie case is not easy to dismiss.
During training to an artificial food source, there comes a point at which at least some of the bees begin to ‘catch on’ that the experimenter is systematically moving the food further and further away.
The pioneer of bee research Karl von Frisch recalls (and we have observed) instances in which the trained foragers began to anticipate subsequent moves and to wait for the feeder at the presumptive new location.
This seems an impressive intellectual feat.
It is not easy to imagine anything in the behaviour of natural flowers for which evolution could conceivably have needed to program bees to anticipate regular changes in distance.
Along the same lines, we have on several occasions during experiments on bee navigation seen behaviour that appears to reflect an ability to form what experimental psychologists refer to as a ‘cognitive map’.
The classic example of this phenomenon is the ability of a rat in an eight-arm maze to explore each arm in a random order without inspecting any arm twice.
This ability to form a mental map and then formulate behaviour (perhaps by imagining various alternative scenarios) seems very like the ability of chimpanzees to imagine the solution to the hanging-banana problem by stacking the boxes in their minds before performing the behaviour for real, and of course the same process goes on in our own minds all the time.
The first hint of such an ability in bees came years ago when von Frisch discovered that bees that had flown an indirect route to a food source were nevertheless able to indicate by their famous communication dances the straight line direction to the food.
By itself, it is easy to  interpret this ability as some sort of mindless, automatic exercise in trigonometry.
Three years ago we trained foragers along a lake and tricked them into dancing to indicate to potential recruit bees in the hive that the food was in the middle of the lake.
Recruits refused to search for these food sources, even when we put a food source in a boat in the lake at the indicated spot.
At first we thought that the foragers might simply be suffering from some sort of apian hydrophobia, but when we increased the distance of the feeding station so that the dances indicated the far side of the lake, recruits turned up in great numbers.
Apparently they ‘knew’ how wide the lake was, and so were able to distinguish between sources allegedly in the lake and sources on the shore.
We see no way to account for this behaviour on the basis of either associative or trial-and-error learning.
This ability is accounted for most simply if we assume that the recruits have mental maps of the surroundings on which they somehow ‘place’ the spots indicated by the dances.
This interpretation is further reinforced by another observation.
While exploring the question of whether bees can use information about direction gathered on the flight back from the food, we transported foragers caught as they were leaving the hive for natural sources to an artificial feeder in the middle of a large car park hundreds of metres from the hive.
After being allowed to feed, the majority of foragers circled the feeder and, in many cases, departed directly for the hive, which was out of sight.
Many of the young bees, however, circled helplessly and never got home.
When the successful foragers arrived at the hive, many danced to indicate the car park.
Now for a bee to know the location of a barren car park which had certainly not been on their list of flower sites, it seems most reasonable to suppose that they were able to ‘place’ it on some sort of internal map and then work out the direction home.
That only older (and presumably more experienced) bees were successful at this task is consistent with this interpretation.
Taking these cases at face value, does the apparent ability to make and use maps provide convincing evidence of active intelligence?
And if so, why are bees so thoroughly mindless in other contexts?
The second question is easier to speculate on than the first.
Intuitively it seems reasonable to suppose that if we were designing an animal, we would ‘hard-wire as much of the behaviour as possible.
Where there is a best way of doing something, or finding out how to do something.
there seems little point in forcing an animal into the time-consuming, error-prone, and potentially fatal route of trial-and-error learning.
But where explicit programming will not serve, it seems equally reasonable to direct an organism to fall back on ‘thinking’, particularly when the solution to a problem can then, as in the case of imprinting, be wired into the system for later service.
It must be said that much of human behaviour seems to fall into this neurologically economical pattern: we work hard to master a problem, then turn the solution into a mindless, rote unit of  behaviour .
Difficult problems like learning to type, ride a bicycle, tie shoes, or knit seem almost impossible at first, but once learned become as matter-of-fact as breathing or walking.
Are humans machines too?
But whether cognitive trial-and-error qualifies as intelligence is more difficult.
On the one hand we can imagine how we might go about pre-wiring a Cartesian map, and how we could then encode the instructions by which the information to fill the map should be gathered, stored, and used.
On the other hand, there is increasing evidence that many of the intellectual feats of our own species — language acquisition, Aristotelian logic, categorisation, pattern recognition, and the like — are themselves based on pre-existing wiring and storage.
The more we learn about the brain, the more clearly we see how its specialised wiring affects what we are.
It may be that the question is one of degree: to what extent is a pocket calculator ‘intelligent’?
Does a TI-59 with its hardwired navigation module installed — a good approximation to a small part of a honey bee brain — qualify?
What about a chess-playing machine, programmed to examine the board and then ‘imagine’ thousands of possible moves and evaluate them in relation to each other?
Or is it the provision for automatic self-programming such as we see when a flower trains a bee to exploit it that is intelligence?
The more we look at the behaviour of insects, birds, mammals, and man, the more we see a continuum of complexity rather than any difference in kind that might separate the intellectual Valhalla of our species from the apparently mindless computations of insects.
We see the same biochemical processes, the same use of sign stimuli and programmed learning, identical strategies of information processing and storage, the same potential for well-defined cognitive thinking, but very different storage and sorting capacities and, most of all, very different intellectual needs imposed by each species' niche.
In short, the intelligence of insects, like that of our species, seems to be more than anything else the intelligence of evolutionary necessity.
El Chichón and Britain's weather
John Gribbin
Last spring El Chichón in Mexico produced one of the biggest volcanic eruptions of the century.
Some have predicted that it will cause a series of bad winters; but studies at the University of East Anglia give cause for optimism
THE ERUPTION last April of El Chichón, on the Yucatan peninsula of Mexico, was one of the three biggest volcanic explosions this century.
It put 16 million tonnes of material into the upper atmosphere.
Early in 1983, a consensus seemed to be emerging among theorists using computer models of the atmosphere that this material, now spreading across the northern hemisphere, would lead to a cooling of perhaps half a degree Centigrade, with the peak effect occurring in the late summer of 1983 or the winter of 1983–84.
But a detailed study of the climatic effects of major historical eruptions has now led Mick Kelly and Chris Sear, of the Climatic Research Unit in Norwich, to conclude that the peak influence of El Chichón on climate has already passed.
We can blame the volcano for our cold, wet June last year, but there is no need to fear, on this count at least, a cold wet summer in 1983.
This disagreement between the different schools of thought is more than just a storm in an academic teacup.
Soon after the eruption last year, Brian Toon, of the NASA Ames Research Center in Moffatt Field, California, was quoted as saying, ‘this is really the first time in modern meteorology that something has happened that has the potential to affect the climate.
If all those [computer]models do work, it will give us a lot more confidence working on all those other problems,’(Science News , 21 August 1982, p 121).
The unstated corollary is that if the computer models don't predict the impact of El Chichón on climate successfully, it will cast doubt on their accuracy in predicting other climatic changes — such as the ‘greenhouse effect’, the hypothetical warming effect that is due to the build-up of carbon dioxide in the atmosphere.
There is no doubt that major volcanic eruptions have affected the climate of the northern hemisphere in the past few hundred years (see ‘Do volcanoes affect the climate?’
New Scientist , vol 93 p 150).
The doubt concerns the speed with which the effects are felt, and the magnitude of those effects.
The conventional wisdom is that the biggest effects are produced after the veil of material from an eruption (called a ‘dust veil’, although suspended droplets of liquids such as sulphuric acid may be just important as solid particles) has spread around the hemisphere and is blocking the Sun's radiation more or less uniformly.
It takes several months for the dust veil to spread in this way, and then perhaps a year or two for the material to fall out of the stratosphere and for normal warming of the Earth's surface by the Sun to be restored.
The great historical eruptions seem to fit this picture — global mean temperatures in the  northern hemisphere (taken as annual means) show a significant dip in the year or two after a great eruption, like that of Krakatoa in 1883, or, on a more modest scale, Agung in Bali in 1963.
So the first question is, how much’ dust’did El Chichón put into the stratosphere?
The volcano became active on 28 March last year with a series of eruptions building up to the major explosion on 4 April.
The resulting cloud was observed by instruments on satellites and aircraft, as well as from the ground.
As it drifted westward in the prevailing high-altitude winds the cloud passed over Hawaii and, spreading northward on later circumnavigations of the globe, the southern states of the continental US.
The cloud is 20 times as large as the dust veil from the Mount St Helens eruption, and very rich in sulphur dioxide and sulphuric acid droplets produced as the sulphur dioxide reacts with water vapour.
As far as total dust veil is concerned, it seems to be roughly the same size as the veil from the Agung eruption, which has been blamed for cooling the northern hemisphere by about 0.3 °C in the mid-1960s.There is one key difference, though: El Chichón's eruption occurred in the northern hemisphere, Agung's in the south.
These figures were put in perspective by a report from Lowell Observatory in Arizona to a meeting, in Boston.
G. W. Lockwood described how the passage of the dust cloud over the observatory site on Kitt Peak (latitude 32 N) had disrupted astronomical observations.
The cloud first passed over the observatory between 10 and 15 April, and produced a pronounced dip in the measured intensity of radiation from the solar disc (Figure 1).
By chance, the cloud arrived in the middle of a series of measurements of the ‘extinction’ of Sun and star light caused by the atmosphere, and as a result the Lowell team has a very good record of day-to-day variations in the  transparency of the atmosphere.
Apart from the El Chichón cloud, the most intriguing aspect of this record is a pair of dips in January and March 1982, before El Chichón erupted, which may be related to a ‘mystery cloud’ of material in the stratosphere.
The best conjecture, backtracking the path of this cloud, is that it originated from an unobserved eruption either in Zaire in the middle of January or in the northern Pacific during the first half of January 1982.
Whatever its origin, this cloud confuses the situation slightly, and probably adds a little to any effect on climate of the much bigger eruption of El Chichón.
But don't worry too much about the massive effect of these clouds over Arizona; these are local and temporary, produced while the cloud was compact and before it spread to produce a much smaller effect over a much bigger area.
It is the comparison of the size of the cloud with the dust veils from eruptions such as Krakatoa and Agung that leads to a prediction of a cooling of the northern hemisphere by about 0.5 °C, with the biggest effect late in 1983 or in 1984.
The computer models, fed with cloud data and the assumption that the biggest climatic effect is produced when the cloud of sulphuric acid drop lets is most widespread, all come up with figures in this ball park.
Even that prediction, however, might prove difficult to test.
It happens that 1981 was the warmest year (averaging over the whole northern hemisphere) since detailed records began to be kept in 1881, about 0.6 °C above the long-term average.
Early in 1982, before El Chichón erupted, a steep decline in temperature set in.
Whatever its cause, that decline makes it harder to lay blame for any recent severe weather on El Chichón.
But the month-by-month figures (Figure 2) do show a very sharp drop in temperatures very soon after the eruption — totally disagreeing with the forecast of a greatest influence on the hemispheric environment 18 months to two years after the dust veil is blown into the stratosphere.
So Kelly and Sear have looked in more detail at the temperature changes following the handful of similar eruptions that have occurred since 1881, when those detailed temperature records begin.
Only five events qualify for inclusion in this study — four individual eruptions, and a series of three closely spaced events in 1902 which together add up to produce a large dust veil.
These eruptions were those of Krakatoa in 1881, Pelée and Soufridre in the West Indies and Santa Mana in Guatemala, all in 1902; Ksudach in Kamchatka in 1907; Novarupta in Alaska in 1912; and Bezymianni in Kamchatka in 1956.
The team at the University of East Anglia analysed the month-by-month temperature record for the northern hemisphere over the 48 months following each event.
All of the eruptions except Krakatoa happened in the northern hemisphere, and together they show a clear pattern of behaviour.
A rapid fall in average temperatures reaches a minimum two months after the eruption, followed by a slow recovery over the next two years.
By contrast, the response of the northern hemisphere temperatures to the Krakatoa eruption, in the southern hemisphere, is delayed by eight months — and a similar delay is seen in the temperature record following the Agung eruption of 1963.
The clear implication of this study is that the biggest response of northern hemisphere temperatures ‘should’ have been in June, two months after El Chichón's eruption, and that is just what the temperature record shows.
Kelly and Sear cast doubt on the theories underpinning the computer forecasts, and suggest that the biggest effect of a volcano on the weather occurs when there is still a lot of dust in the veil and the sulphuric acid droplets have also started to build up.
Immediately after the eruption, there is lots of dust and not much acid; after a few months, there is plenty of acid but little dust.
Both seem necessary to produce the greatest effect, and theorists have been misled — by the accident that Agung and Krakatoa erupted in the southern hemisphere — into thinking that the delay between eruption and northern hemisphere cooling indicates the dominant role of a widespread sulphuric acid veil.
It takes a long time for an explosion in the southern hemisphere to affect the north; an eruption in the northern hemisphere has a much quicker impact on us.
And, with hindsight, it is not too much of a surprise that the whole hemisphere can be affected before the dust veil spreads northward out of the tropics.
After all, the greatest input of heat from the Sun into the ‘weather machine’ is in the tropics, and cooling there can have the biggest impact on the workings of the whole machinery of climate and weather.
As yet, Kelly and Sear have not formally published their calculations, which are hot off the Norwich computer.
But their findings have been widely disseminated by Kelly in an interview on the BBC World Service programme Science in Action , where he stressed the significance of the new insight that a large-scale disruption of hemisphere-wide circulation mechanisms could be produced by events in the tropics.
‘The errors are coming in the computer models,’, he said.
‘not in the observations.’
We now have one of those very clear, but actually rather rare, tests of a scientific hypothesis that we all learned about at school.
The computer modellers forecast a cold period ahead, with a dip in northern-hemisphere temperatures reaching 0.5°C late this year or early in 1984.
Kelly and Sear predict that things should actually improve over the next few months as the northern hemisphere continues to recover from the 0.5°C cooling that actually happened in June last year.
All we will have to do is look out of the window to determine which hypothesis is correct, and therefore deserves elevation to the status of a theory.
FORUM
Tinker, tailor, soldier, swot
Danny Connolley wonders where intelligent inquiry ends and espionage begins
SERGEI V. IVANOV, the Russian diplomat declared persona non grata on the eve of All Fool's day was a danger to Britain because he is a purpose built hi-tech spy.
In my view, Ivanov probably did not spy, in the conventional sense, during his 18 months in Britain, simply because he managed to produce spectacular results for his employers without subterfuge.
As second secretary for science and technology, his brief was to improve the quality of Anglo-Soviet scientific relations.
He carried out this aspect of his work assiduously, spending a great deal of time obtaining detailed accounts of Soviet work of significant practical use to British academics in disciplines ranging from ergonomics to biotechnology.
Ivanov's character is tailor-made for technical espionage.
His academic background in mechanical and electrical engineering gives him a sound grasp of a broad range of scientific disciplines.
He is completely at home with the English language and our literature and humour.
People like him and he can recall verbatim quite complex conversations.
Ivanov was capable of using his considerable social skills to cultivate and subsequently exploit successfully the acquaintance of a susceptible person engaged in strategic work.
The popular image of a spy is a person who gains information, denied to his masters, in a covert and underhand manner.
If this definition is applied, the Russian assertion that ‘only the West has spies’ is substantially true.
We need spies because Soviet security is highly effective.
Western security is for all practical purposes, non-existent, at least in the view of Russian diplomats who have served in the West.
Almost all the information they gain is given freely and with the tacit or blind approval of Western governments.
There is so much valuable information on tap that the London-based Soviet mission cannot cope.
In its view, there is not the time, the manpower or even the need to spy in the conventional sense.
Ivanov and others like him work almost exclusively as ‘collectors’.
The material which Ivanov accumulated and interpreted came not from  closeted sources but from publicly available journals, technical newspapers and magazines, and house publications such as British Aerospace News .
The UK technical press in particular is considered to be a superb source of data.
One article reputedly worth its weight in gold to the soviet navy, was an account of HMS Invincible's sea trials that appeared in Electronics Weekly .
Horrendous indiscretion is not limited to the press.
Ivanov's greatest single source of strategic data was literature from conferences, trade shows and exhibitions.
most notably in electronics, computing, telecommunications, avionics and aerospace.
He could fill a car-boot after any show with bumph given to him by exhibitors, none of whom ever seemed to ponder the consequences of encouraging copycat technology.
He would conscientiously visit every stand, whether a show had 40 or 400 exhibitors.
Technical sales literature often contains important data such as circuit diagrams and explanations on how  improvements have been effected.
With all this intellectual philanthropy, a Russian intelligence gatherer needs no covert skills to extract valuable information.
Back home the data accumulated by Ivanov and his ‘back up’ man in the Czech delegation would be sorted and despatched for analysis.
For example, information on semiconductor production equipment goes to Minsk (the home of the Russian computer industry, while information on nuclear physics (incidentally, never in much demand) is sent to the Volga Nuclear Physics Centre at Dubna.
There is an embarrassing paradox in British technology, in that much of the information classified as ‘secret’ by HM Government is exceedingly trivial while much that should be secret is not.
Anyone who has had access to classified work produced by the scientific civil service is likely to endorse this view.
Almost all the key advances in defence have come from contractors.
The only way they can market their products is to produce literature detailed enough to convince the prospective buyer.
Ivanov's major interest was communication satellites, in respect of which he was constantly being pressed to come up with something new.
At one stage he even considered visiting the library of British Aerospace to gain (legitimately) information on British and American advances.
Other targets were the big British defence electronics companies — Racal, Plessey, Marconi and Ferranti.
He accumulated the equivalent of a suitcase-full of literature from each.
There is a popular belief that Russian science is unoriginal and years behind.
We gain that impression because the work the USSR reports can be up to 30 years old at its first publication.
The USSR copies the West simply because it is much cheaper and easier, not because it is inherently backward.
Socially at least, representatives of the Russian delegation in London make no secret about the type of information they want.
They are encouraged by the openness of the informational market-place to pursue blithely and openly any objective they choose, without fear of recrimination.
‘Spying’ in the accepted sense is redundant, save as a last resort.
An important part of Ivanov's job was to meet, befriend and socialise with technical, scientific and defence journalists.
People sometimes familiar with important gossip or primary sources of information.
He probably enjoyed this aspect of his work more than any other, because the pub land to a lesser extent, the steak house) was his spiritual home.
Most of his 400 roubles a month spending money went on drink.
He could drink copious amounts of beer without ill effect.
Sergei Ivanov will be sorely missed as a drinking companion by many.
No more amusing anecdotes about his brief army career.
No more tales of his young daughter Galena.
No more colourful yarns and jokes about the Soviet way of life.
There is widespread speculation that he was uncovered by Vladimir Kuzichin, a minor KGB official who defected last year.
This is quite possible since MI5 did not make a detectable or a sustained effort to keep a watchful eye on Ivanov's movements.
If anything he was able to go about his duties as if he had been given carte blanche .
This implies that MI5 felt that he was quite harmless.
In my opinion, Ivanov never had time to do any protracted spying.
He spent almost every evening drinking and most of his days routinely and painstakingly abstracting information from the Science Reference Library, the Patent Office and even the US Embassy library in Grosvenor Square.
His expulsion is probably more justified in terms of his considerable long-term potential as a spy than in terms of his current status and responsibilities.
If Ivanov was a spy, then I am sure he obtained far more strategic information by legitimate methods than he ever did by covert means.
Intensive death
Donald Gould believes that some heroic attempts to save life are misguided
RIGHT-THINKING PEOPLE have been angered and shamed by the manner in which our unimaginative leaders bundled that wretched and ill-done-by Papusoiu onto a plane at Heathrow airport bound for a cruel Romanian jail, and have voiced their disgust.
But, strangely, I have seen no protests concerning an equally callous and stupid mishandling of a human being in distress just now perpetrated in the US of A.
I refer to Dr Barney Clark, a dentist, who died in the University of Utah Medical Center at the end of March, 122 distressful days after being fitted with an artificial heart.
He was frequently referred to on radio and television, and in the papers, as the first person to have been given an artificial heart.
This was not correct.
During the heart transplant epidemic which swept the so-called developed world following Dr Christiaan Barnard's first Cape Town adventure, several crude pumps were sewn into the chests of unfortunate American citizens, all of whom promptly succumbed.
Doubtless the number of victims of this particular form of surgical homicide would have been greater but for the American Food and Drug Administration, whose officials promptly and wisely proscribed the procedure.
The FDA cannot tell American surgeons what they can and cannot do to their customers.
(Had it this power there might be a dramatic fall in the incidence of needless hysterectomies, gall bladder removals, and other operations performed in that great country for profit rather than the client's greater good.)
But the agency does have the job of approving materials and devices (as well as drugs) intended for the treatment of disease, and way back in the late 1960s it rightly concluded that none of the artificial hearts available was fit for the task for which it had been designed.
At the end of last year, the FDA was persuaded that the Utah Medical Center had evolved a plastic and aluminium ‘heart’(known as the Jarvik 7, after its designer, Dr Robert Jarvik) which stood a chance of sustaining some kind of life, and permission was given for a series of seven experiments, employing the new toy, after which the instrument's worth was to be reviewed.
So the boys in Utah went ahead.
The manoeuvre was different in kind, and even less justifiable, than a heart transplant.
With a transplant there is at least a chance that the victim will walk away from the hospital and enjoy a period of tolerable life (slim though that chance may be).
There was never even a possibility that Barney Clark would ever be more than a wretched cripple.
His future, if he had one, involved being permanently connected, by two six foot hoses, to a massive power unit weighing 375 lb.
His life would be forever hanging, literally, by a thread, except in this case the ‘thread’ would be a couple of plastic tubes.
The likely misery he faced was recognised in a lengthy legal document that he was required to sign before the deed was done.
One of the grotesque provisions it contained gave him the ‘right’(on whose authority — God Almighty's?) to terminate his own life if he found his state unbearable.
He was a very sick man before the operation, and there was clearly small prospect that he could hope to be anything else, even if the machine worked well.
The whole incident is reminiscent of the  obscenities surrounding the deaths of President Tito of Jugoslavia and General Franco of Spain.
Tito, at the age of 87, was forced to stay alive for a few extra weeks by the vigorous application of every last trick of the medical trade, including the use of a kidney machine, long after it was apparent that he had reached the end of a pretty long road.
On his deathbed General Franco was attended by 32 doctors, who, in their efforts to delay his end, employed, among other devices, a kidney machine and a respirator, and who performed at least three major abdominal operations, and administered an unknown number of gallons of blood.
By attempting to sustain life at all costs, and by refusing to admit the fact that death is a good and proper part of life, doctors are in error.
By undertaking extravagant adventures aimed at preserving lives which have clearly been called in by the Great Reaper, doctors are not serving the best interests of their clients, which is I take it, their first duty.
Doctors should not regard the death of a patient as some kind of insult to their calling, and a mark of failure.
People have to die at last, and there is nothing that anybody (even doctors) can do to alter the fact.
Most of us, I suggest, do not want ‘intensive care’ when our time is nigh.
We don't want to have every last stop pulled out on our behalves in a last, heroic effort to extend our lives for a few more days or weeks or months.
It is not the nearness of death that frightens, and corrupts the mind and soul.
It is the fear of being abandoned — of being left helpless and alone while still alive — of burdening relatives beyond endurance — of awful pain that comes when no help is at hand.
When I am called to meet my Maker face to Face, I hope my doctor helps me do it gently, instead of striving to avoid the issue.
The Midland rhynchosaurs
READERS fascinated by Mike Benton's article ‘The age of the rhynchosaur’(7 April, p 8) will be interested to learn that Warwickshire Museum, Warwick, has some splendid fossil remains of the beasts collected from local quarries.
Robert Alcorn, a young sculptor/model-maker employed by the museum under the auspices of the Manpower Services Commission, has also produced resin models of prehistoric amphibians and reptiles (including the rhyncosaur left).
In researching the anatomy and posture of the beasts, the museum's keeper of geology Tristram Besterman, was advised by specialists including the  taxidermist Arthur Hayward, who has just completed ‘Guy’, London Zoo's famous gorilla, for the Natural History Museum.
Decline of the walnut
Bill Burroughs on a cold winter that changed the style of British furniture
THE IMPACT of spells of cold weather is usually short-lived.
But for those of us who are gardeners, the bitter experience of the winter of 1981–82 has shown that extreme cold can do lasting damage.
Even so we do not expect such spells to lead to permanent changes in our lifestyle.
It is therefore interesting to discover that something as basic as fashion in furniture has been altered by a single cold winter.
I refer to the rapid decline of the use of walnut in English furniture making in the first half of the 18th century.
The Persian or English walnut (Juglans regia)is among the noblest of the hardwoods.
It is generally regarded as a native of south-east Europe and Asia Minor, Doubt surrounds the timing of its introduction to the British Isles, but the earliest record of its presence was made in 1562.
The climatic limits of the growth of mature English walnut trees appears to be defined by winter cold.
In particular, extreme frosts below about — 20 to — 25 to —y reported to cause great damage to mature trees.
Walnut displaced oak as the prized hardwood in England in the late 17th century.
The combined qualities of lightness, rich-colouring, solidity, compactness, durability, ease of working and freedom from warping made the heart-wood of the walnut a popular timber for making tables, panelling and cabinets.
The veined and variegated roots yielded beautiful veneers much prized for ornamental work.
In the 1720s the use of walnut went into sharp decline and it was replaced by mahogany.
The immediate cause of this switch was a ban on the export of walnut from the Savoie region of France — the principal source of the wood for the English industry — by the French government in 1720.
The underlying cause for this decision was the awful damage caused by the savage winter of 1709.
That winter, according to available records, may well have been the coldest of the Little Ice Age over much of northern Europe.
It hit France especially hard.
The central feature was an extraordinary cold spell for three weeks in January which destroyed crops and killed so many livestock that it precipitated one of the last great subsistence crises of French history.
The cold was so intense that it killed up to two thirds of the walnut trees in France.
While the mortality recorded in several subsequent winters was high, nothing matched the toll of 1709.
The shortage of walnut resulting from this winter combined with the heavy demand for walnut gunstocks during the War of the Spanish Succession appears to have led directly to the French ban on exports in 1720.
In their search for alternative supplies, English furniture makers turned to other parts of Europe and, more important, to the New World.
The options from the Americas were the hardier native ‘black’ walnut of the eastern United States, or mahogany from the West Indies and Honduras.
In the event, the advantages of mahogany with its large planks, resistance to rot and woodworm and its attractive appearance won the day.
In fact, mahogany had been known in England since Sir Walter Raleigh's day but it took the French ban for it to become popular.
It was assisted by Parliament passing an act in 1721 exempting timber imported from British plantations from duty.
The value of annual imports rose rapidly from £276 in 1722 to almost £80 000 at the end of the century.
By the middle of the 18th century walnut was no longer used for fashionable furniture but continued in favour in the provinces where, late in the century, pieces were made in the style of 50 years earlier.
But the walnut used was native English wood which lacks the dark markings of the Grenoble variety.
(Catalogues of the Great Exhibition of 1851 commented that although the black walnut of North America produced wood which was of a rich purple-brown and could be obtained in very large plants, it was ‘but little employed by the cabinet makers’ in Great Britain).
It is interesting to speculate what would have happened but for the winter of 1709.
Clearly the benefits of mahogany would have eventually become evident but it would probably have taken much longer.
So a single cold spell was responsible for a permanent change in the taste of English society in a way which is probably without parallel.
An Easter holiday
D. A. Allen recalls a Polynesian visit
I KEEP a mental catalogue of my personal ‘wonder of the world’.
It features such spots as the Yosemite Valley in spring, the hypostyle hall at Karnak, the Olgas of central Australia, and Blencathra on a January day.
To this list I must now add Rano Raraku.
The island on which it stands is the loneliest inhabited place on Earth.
Until the advent of Europeans, its natives knew no place closer than the Moon.
They had no name for their isle.
Rapa Nui is a modern Polynesian appellation, and the alternative Te Pito 0 Te Hanua, fancifully translated as ‘the navel of the world’ is better rendered as ‘land's end’, referring to one of the headlands.
To appreciate the remoteness of this morsel of land, one must set sail from Santiago, strike west into the great Pacific, and rely on one's navigational skills.
Most visitors, ourselves included, trust instead to LAN Chile's expertise, and arrive by one of the oldest 707s still in service.
We alighted from the aircraft steps onto the only paved surface on the island.
On the heels of fellow passengers we crossed the tarmac to a lava-strewn field where women sat crosslegged on the ground before their arrays of wooden carvings and shell  jewellery : these were the airport shops.
Beyond stood a rectangular building, the terminal, fabricated from the packing crates left over by the American military from its construction work on the runway.
And through the far door: Easter Island.
We had allowed six days to explore the island: it was scarce enough.
You will meet those who spent two, maybe three days there and left believing they had done it all.
Conversely, we have yet to meet any visitor who feels he or she stayed too long.
You do not — or should not — expect tropical nights, moonlit beaches, rhythmic dancing by maidens in grass skirts, or cocktails.
Easter Island has a temperate climate, and only two tiny beaches far from the sole settlement of Hangaroa, There is but one small hotel; our preference was for a guest house where we could meet a local family.
Rent a horse or a motor bike and explore on a few leisurely sorties.
The perimeter measures a mere 40 km, so considerable portions can be covered from base at Hangaroa.
Temples abound along the coast.
Some are heaps of stones in a number of characteristic shapes, dating back a thousand years or more.
Others present massive facades to the sea, their walls clad with smoothly worked slabs fitted irregularly but snugly together with the skill reminiscent of Inca workmanship.
Scramble over these temples (ahus)and peer into the burial cists.
In most you will find intact the bones of Easter islanders who entered their spirit world centuries past.
Some of the moai ahus — temples which once carried the famous statues — have been reconstructed.
Ahu Tahai is one such, and is conveniently near Hangaroa.
Better preserved are the moais at Anakena, beside the pleasantest beach on the island.
These moais have been lovingly restored: their two-piece red topknots and yellow bodies, carved to represent Easter Island tattoo patterns, clearly demonstrate that these were representations of real people, folk who wore their hair in a bun and stretched the lobes of their ears.
The statues are imposing: they stand tall on their ahii .
But how much more imposing must they have been when their eye sockets were equipped with staring eyes of black obsidian and white coral.
Complete from the hips upwards, the statues were naked save for a collar, probably of wood, that encircled their necks.
The ahus all stand near the coast except for one ceremonial group, almost lost in the billowing moorlands of the interior.
Worth a visit, too, is the topknot quarry, a small volcanic vent of vivid hue from which have been excavated the ruddy cylinders weighing up to tens of tons.
Did the Easter Islander really have the technology to raise such topknots onto their statues?
Certainly a must is Orongo, a ceremonial village perched on the rim of the Rano Kau volcano.
From this vantage you peer down into the crater lake, its surface green with the fresh growth of ‘totora’, a reed otherwise known only in the Andes.
At Orongo are the best of the petroglyphs.
Nearer to Hangaroa you may find a cave which wears painted motifs.
But it is to Rano Raraku that the visitor should go.
This volcanic cone, dormant for at least 3000 years, provides the prized yellow rock from which the moais were carved.
Outside and in, the rock face has been transformed into a quarry for giant busts.
They lie, as dormant as their volcano, stacked up ledge upon ledge.
With every move the visitor transfers from one ear to another, steps over the roughed out eye-socket of a sleeping figure, or dodges round a protruding nose.
Moais lie horizontally, vertically, even base over apex to make optimum use of the rock face.
The population of Easter Island could not have exceeded a few thousand, so a sizeable proportion of the men must have been employed at the quarry, carving likenesses of their deceased relatives.
Then, perhaps overnight, they downed their tools.
Civil war probably halted the work, with the result that 20th century tourists can still stumble on the stone axes where they were lain, and can study the progress of carving from the first outlines to the almost completed megalith ready to slide down from this rocky womb.
The Rano Raraku moais are taller than any of the statues which had actually been transported to and erected on ahus .
Their extra height has been gained by elongating the facial features to form a caricature.
Some statues are 20 metres tall.
On an island nearly denuded of wood, the transportation and erection of statues such as these presents a technical problem that modern man still ponders on.
Here, in splendid isolation, emerged a tribe of Polynesians who were prepared to address problems such as this, and who moreover were one of the few peoples in the world to develop a system of writing.
To stand atop the moai quarry of Rano Raraku is to glimpse a mighty neolithic civilisation.
Battle of the species
Simon Lyster sets the scene for next week's meeting in Gaborne, Botswana on endangered species
CITES must be the least known acronym in Britain.
But if you are thinking of buying little Johnnie a pet parrot for his birthday or treating yourself to an exotic fur coat or snake-skin handbag, CITES will affect your decision.
The Convention on International Trade in Endangered Species of Wild Fauna and flora, to give it its full name, is an international treaty which regulates one of the most lucrative and controversial businesses — the international wildlife trade.
Worth an incredible £1000 million a year, the trade brings substantial rewards to dealers who are permanently trying to weaken CITES controls, and anguish to wildlife conservationists who try equally fervently to add species to the protected lists.
With a pair of macaws fetching up to £10 000 and with an ounce of ground rhinoceros horn costing more than an ounce of gold in Asian medicine shops, the stakes are high.
(To clear up a myth once and for all, rhino horn is in demand not as an aphrodisiac but for its supposed fever-reducing qualities.
But consuming rhino horn will do you about as much good as chewing your finger nails; however, trying to tell that to the people who consume rhino horn is like trying to tell Ian Botham to lose weight.
You will be ignored and you might get thumped.)
The degree of protection that CITES gives to a species depends on its conservation status.
Appendix I of the convention lists species in danger of extinction.
There are about 600 of them, and they cannot be traded for commercial purposes.
Species that may become threatened with extinction are listed in Appendix II.
The several thousand species in this category can be commercially traded, but exporting countries are required to limit their trading to a level which is not detrimental to the survival of the animals.
Seventy-nine countries, including the UK, are parties to CITES.
When government delegates meet every two years to decide which species to add to or delete from the appendices, the scene is set for a battle between non-governmental conservation organisations, such as the World Wildlife Fund, and representatives of the pet industry and the fur trade, with both factions desperately trying to sell their points of view.
The future of dozens of species will be at stake, One of the most alarming agenda items for the meeting is a proposal by Zambia and Zimbabwe to transfer eastern and central African populations of leopard from Appendix I to Appendix II.
The leopard has been listed as a species in danger of extinction since CITES was concluded in Washington 10 years ago, which is why you do not, or at least should not, see leopard skin coats and hats in London's expensive fur shops.
(You may occasionally see an old skin for sale as CITES makes exceptions for specimens acquired before the convention came into force.)
Acceptance of the proposal could lead to a resurgence in international trade in leopard skin.
The problem is not so much the effect this will have on eastern and central African populations of leopard, which are relatively stable, but the disastrous impact it could have on the species elsewhere.
The distribution of leopards is wide, ranging from South Africa northwards and eastwards through Asia as far as China, and in parts of North Africa and Asia the species is in serious danger of extinction.
For the moment, endangered populations are relatively secure from poachers because listing the leopard in Appendix I has more or less dried up the market in leopard skins.
But they could be seriously jeopardised by the Zambian and Zimbabwean proposal because there is no adequate system for marking skins, and once a pelt has reached the fur markets of Frankfurt, London or New York there is no realistic way of knowing where it came from.
The recommencement of any trading would be an open invitation to poachers and smugglers throughout the leopard's range to get down to their illicit business.
In some areas any exploitation, however limited, would wipe leopards out.
Proposals from the US and Canada to remove North American populations of lynx, wolf and bobcat from Appendix II, and thereby remove all controls on international trade in these animals, could prove even more controversial.
None of these species is in good shape, and North American conservationists fear that acceptance of the proposals could mean a dramatic increase in the numbers taken by hunters and trappers.
They are particularly concerned about the bobcat which is already under intense pressure — about 100 000 are now trapped annually compared to just a few thousand two decades ago.
The removal of CITES controls could be extremely serious.
Bobcats need a range of about 60 square miles per male, and they have already been exterminated from parts of the eastern and central United States.
Canada's action is not altogether surprising in view of her dubious record on other conservation issues, but it is sad to see the proposals coming from the US.
They provide further evidence that the Reagan administration is doing its best to undermine the traditional position of the US as the leader of world conservation.
It is somewhat ironical that this position was carefully constructed by earlier Republican presidents and that CITES was primarily the brainchild of the Nixon administration.
But CITES is not just about glamorous mammals.
Trade in thousands of plants is subject to international controls, and the delegates in Botswana will be turning their attention to exotic-sounding plants, such as the saw-toothed lewisia, Panry's lemon lily and the boojum tree.
The most serious of the plant proposals is probably that from Chile to delete from Appendix I ‘dead specimens’ of a magnificent and endangered tree known as alerce or Chilean false larch.
Alerce is one of the longest lived trees in the southern hemisphere with some specimens believed to be over 4000 years old.
It also happens to have very valuable timber, and the Chilean government is anxious to profit from the dead trees that are interspersed with living ones in the few remaining areas of forest where alerce still occurs.
The proposal sounds reasonable enough, but it will encourage felling: as soon as a living tree is felled it will clearly be dead.
Exactly who will win what in Botswana is still far from clear.
If conservationists manage to save the leopard, bobcat and alerce, they may lose some of the battles that will be fought over dozens of other issues including proposals to increase protection for hair seals and whales, to decrease protection for Nile and saltwater crocodiles, and to weaken controls in the trade in ivory and sea turtles.
Whatever happens, the Botswana conference will affect the status of so many important animals and plants that it should put CITES well and truly on the map.
The last two seconds
Tam Dalyell takes a look at some new military technology
EVERY WEEK, all members of the House of Lords receive a written call, or  ‘whip’ from their party managers to attend certain meeting and to vote.
In the same package, there arrives the all-party whip, which lists a series of meetings and events, either of importance to members and their constituents, or germane to special interests.
My attention was recently caught by a note informing me that the Earl of Kimberley and the Earl of Cork and Orerry, officers of the All-Party Defence Committee, had arranged for a presentation by Contraves, the Swiss multinational company.
I knew that it made, besides such things as textiles, the remarkable Oerlikon guns and that it was part of the Oerlikon-Buhrle Group, employing some 40 000 people, mostly in Europe, but also in the US and Japan.
I have long been interested in military technology so I was determined to attend the presentation.
My particular interest was to learn about Contraves's Sea-Guard System.
The threat to warships in the 1980s and beyond lies above all in the accurately guided anti-ship missile launched beyond the range of the ship's weapons.
The problem is to defeat the missile, irrespective of its terminal velocity and trajectory.
The Sea-Guard close-in weapon system claims to be able to do this by destroying the missile using high performance, ‘kinetic energy’ ammunition.
The missile's terminal speed and angle of attack make no difference.
We were shown film of one-hit-one-kill armour-piercing ammunition, fired from a multiple cannon, able to shoot 3200 rounds a minute of 25 mm ammunition.
The gun is capable of covering a hemisphere, and can be continuously re-loaded.
Each of its four barrels is independently fed.
Particularly impressive also was the ‘Sea-Zenith’ gun, with a two-axis mount.
This can elevate from minus 15 to plus 125 degrees, with outstanding speed and accuracy.
What this means is that ships can now have some protection against guided bombs released from a great height.
Hitherto, even equipment that can calculate flight paths has been unable to cope with this threat.
Certainly at low altitude it is a difficult feat to track a small target, such as an Exocet missile, travelling at 700–800 metres per second.
Such missiles may be as little as 30 centimetres in diameter.
With Sea Wolf fore and aft, and the Sea-Guard anti-missile gun system, on port and starboard, the makers claim that a ship could have a 9 to I chance of remaining undamaged even if the missiles were pre-programmed to be ‘evasive’.
What makes me shudder.
though, is that for all the skill of the anti-missile scientists, we cannot underestimate the inventiveness of the missile makers.
Sea-Guard may or may not be a super reliable system.
It looks to my lay eye extremely impressive yet the eerie fact remains that it engages missiles when they are only 2 or 3 seconds away from hitting a ship.
The margin of error is minimal.
It takes only one missile to get through, and lives may be lost, not to mention the ship.
(A small type-23 destroyer, which a year ago could be had for £65 million is now officially priced at £90 million.)
Moreover, there is a spine-chilling fact known to those of us who witnessed the technical expertise, if not genius, of the Contraves designers.
Among their customers are Blohm and Voss.
When I saw the picture of the Meko 200 frigate go up on the screen.
I immediately twigged that the Almirante Brown was a Meko 360.
This is the ship named after the hero of the Argentine Navy in the 19th century, and it is the first of four Meko type destroyers that Buenos Aires has purchased from the Hamburg shipyard (who in turn have been supplied with Rolls-Royce engines).
The four ships represent the best that can be bought in a European shipyard.
The Argentinians are buying a new fleet that will rival any other.
Their navy wants the best and it has placed £2 billion of orders in Europe since the Falklands war.
They include six corvettes and two diesel submarines from the Germans and five fast patrol boats from Spain.
All will need to be armed.
I judged our Swiss hosts to be sincere in saying that their latest equipment would be offered on a preferential basis to NATO and other friendly countries, and that it would not find its way to Argentina.
How can they be sure?
The End Users' Certificate system, whereby arms sales are supposedly made only when the end user is known, is a farce.
There is no way of monitoring arms once they are sold, although I believe Contraves when it says that it would have to fit the latest equipment to any ship, and would not fit Argentinian ships.
Naval warfare has become ever more horrific.
Life or death has come to depend on the proper functioning or malfunctioning of super-sensitive equipment over a couple of seconds.
I would recommend anyone to read two books.
The first is Message from the Falklands , the letters and poems of Lieutenant David Tinker RN.
In a letter to Julian Salmon, Tinker writes, from HMS Glamorgan, 6
May, 1982, ‘The Argentinian air force has the latest attack aircraft and missiles, which we just do not have.
We long for nights when their aircraft cannot attack us, and at the moment we are rejoicing in a fog which is sheltering us, I wish the politicians would see sense and stop the war.
What is happening here is barbaric and totally unnecessary.
It is disgusting that two Christian and humane countries (one at least) should resort to this, all for some petty reason.’
The second book is Daniel Kon's Los Chicos de la Guerra , the Argentine conscripts' own moving accounts of their Falklands war.
‘On occasion, after two or three hours of moving accounts of bombardments, combat, mutilations and all kinds of suffering and humiliation, it was easy to forget that one was listening to a teenager, and only a few details could bring the situation back into perspective, back to the fact that a nineteen-year-old was speaking.
(For instance, one veteran listed a pair of jogging shoes left behind on the islands among his painful memories: another recalled a letter he wrote to his girlfriend from the trenches, asking her to tell me the truth, if she didn't love me any more or was going out with another boy’.)’
This Easter we have seen the groundswell of demand all over the world that the arms race be brought to a standstill.
I look forward to the day when the technological wizardry of Contraves can be concentrated in their Biomedical Technology, and Space Technology, Divisions.
Dragon slaying
John H. Parkinson offers some thoughts for St. George's day
DRAGONS, like unicorns, have always been elusive features.
So before as a gallant young man you decide to go dragon slaying, on 23 April, just pause to think about what you might be chasing.
Centuries of tradition have portrayed dragons as fire breathing, flying serpents.
They always seem to live somewhere in the north as typified by this quotation from the Anglo-Saxon Chronicle.
AD 793 ‘In this year, dire forewarnings came over the land of the Northumbrians, and miserably terrified the people; there were excessive whirlwinds and lightenings, and fiery dragons were seen flying in the air.’
There are many other such records: ‘A bloody cloud in likeness of fire was seen oftentimes’— AD 979.
‘The heaven appeared almost all night as if it were burning’— AD 1098.
Is all this the work of dragons?
No, it is all due to the faithful old Sun going through it usual cycle of activity and the so called dragons turn out to be early sightings of aurorae.
These dramatic spectacles are caused by charged particles, which are accelerated in solar flares, being diverted towards the poles by the Earth's magnetic field where they enter the upper atmosphere causing ionisation and producing light.
Aurorae appear as streamers or curtains, varying in colour from whitish-green to deep red, often changing minute by minute.
Aurorae have not just been mistaken for dragons.
A particularly brilliant display in January 1938 was interpreted by some people as the fulfilment of the prophecy of Our Lady of Fatima that ‘the chastisement of the world (was) at hand’.
Indeed, three months later Hitler invaded Austria.
Here, some bright spark thought Windsor Castle was on fire and called the fire brigade!
So, on St George's day stick to rescuing damsels in distress, it will be more rewarding.
With the Sun in its present state of inactivity there are unlikely to be any dragons worth chasing.
REVIEW
How scandalous is the lead scandal?
Lead versus health Edited by M. Rutter and R. R. Jones.
Wiley, pp 379, £18.50 
The lead scandal by Des Wilson,Heinemann  Educational , pp 182, £12.50, pbk, £3.95 
Hans Eysenck
BOTH these books deal with the question of whether low-level exposure to lead has important effects on behaviour and intelligence, and both come to a rather positive conclusion.
Apart from these similarities they could not be more different.
Des Wilson is not a scientist but an activist; he is indeed, as is said in the book, ‘one of Britain's most experienced and best-known campaigners on social issues’.
The Lead Scandal is manifestly a propaganda effort, as the title suggests, and his presentation of the evidence is rather one-sided, as well as being emotional and full of accusations of scientists and politicians with whom he disagrees.
It is a very effective package, paperbacked with a threatening kind of picture on the cover; it has a subtitle (’ The fight to save children from damage by lead in petrol’) which begs the question, and although it contains nothing but the truth, it certainly does not contain the whole truth.
Lead Versus Health , edited by Michael Rutter and Robin Russell Jones, is written in a much more scientific and reasonable manner, and its 15 chapters, by various experts who are well-known as researchers in this field, give as comprehensive and impartial a survey of the evidence (including new evidence) as we are likely to get from any source.
This makes the conclusion reached all the more impressive, and certainly forces one to take seriously the possibility that even low-level exposure to lead may have gravely deleterious effects on children's behaviour and intelligence.
The issues discussed are of considerable interest, For various reasons.
The most obvious of these, of course, is the practical one.
If indeed there are dangers to the health of our children in exposure to low levels of lead, and if we can reduce this exposure by banning lead additives from petrol, then something can and should be done.
For many people, this practical issue will overshadow the refinements of scientific investigation, but this would be a pity.
Epidemiology presents many interesting problems to the scientist, and the controversy that has arisen around the effects of lead in petrol on the health of children highlights many of the problems and difficulties in this field.
These problems figure much more prominently in the Rutter and Jones book, and quite rightly: Wilson takes the answers for granted, and hence is much less impressed with the difficulties and complexities of the scientific search for an answer.
Scientifically, there are essentially two questions.
The first relates to whether there is a correlation between lead levels and behaviour and intelligence in children with blood levels below 35 mg/dl.
No one doubts the toxic properties of lead above such levels, and that is not an issue in this debate.
The establishment of such a correlation is not as easy as it might seem at first, because lead is only one (and probably not one of the more important) influences on the behaviour and intelligence of children, so that the correlation would at best be low, and hence require a large number of cases to be established at an acceptable level of statistical significance.
For the same reason many other factors have to be controlled in order to rule out the possibility that the observed correlations might not be due to these other causes.
It is only the most recent work that has been of an acceptable standard in this respect, and the finding may be summarised as showing a modest correlation between the level of lead in the blood and hyperactivity in children, and between high blood levels and low intelligence, with the latter conclusion more firmly established.
Observed correlations are usually somewhat higher than correlations corrected for various artefacts, but even the corrected correlations show a relationship of the kind posited.
I don't think it is possible to disagree about the high probability that a relationship exists, and that indeed children with higher levels of lead in the blood tend to be less intelligent (and possibly more hyperactive) than children with lower blood lead levels, although the differences are quite small, amounting to some 3 or 4 points of IQ.
The existence of a correlation, of course, does not establish the existence of a causal relationship, and even when a causal relationship is suggested the correlation itself does not establish the direction of the causal relationship.
This problem has always  bedeviled much of the research on epidemiology.
The correlation between smoking the lung cancer is well known, and is usually interpreted in a causal manner: can we interpret the equally strong correlations between eating meat and cancer of the large intestine, or between sugar and breast cancer along similar causal lines?
Alternative hypotheses usually exist, and have to be considered.
It is one of the weaknesses of the Wilson book, and unfortunately also of the Rutter and Jones book, that obvious alternative hypotheses are not considered — possibly because no research has been devoted to the elucidation of the causal chain.
One obvious alternative hypothesis, reversing the causal chain, would be that nonacademic, extroverted children (an alternative description of the hyperactive, low IQ type) are more likely to go out and encounter the hazards of lead in petrol.
It does seem a pity that no one has bothered to look at the actual behaviour of the children in question in relation to such practices as might lead them to encounter greater dangers of lead pollution; the almost entire absence of psychologists among the medical and other experts engaged in this research may account for their overlooking a very obvious alternative hypothesis.
Oliver David and others demonstrated that penicillamine, a chelating agent whose main therapeutic action concerns its effect in increasing the loss of lead from the body, produced a curative effect on hyperactivity in children, comparable with that of methlyphenidate.
This provides an important argument for the lead causes-hyperactivity hypothesis.
But there are several weaknesses in the experiment, and no measures of IQ were taken, so that the causal influence of lead on IQ is not clarified in the experiment.
However, in principle this would seem to be the most promising avenue to explore to furnish us with a better understanding of causal relations.
The observed correlation of lead in the blood with IQ is slight, and the few points of IQ apparently lost through lead uptake may seem negligible.
But, because of the statistical properties of the normal curve of distribution, they do have a large effect at the extremes.
It seems a pity that investigators have relied almost entirely on traditional IQ tests, which can be affected by impulsivity and other personality factors related to hyperactivity; it is quite possible that the effects of lead on hyperactivity may be responsible for the apparent loss of IQ, even if we acknowledge a causal influence of lead on hyperactivity.
Perhaps the traditional type of IQ test in this context should be supplemented by the newly developed psychophysiological measures of intelligence involving the evoked potential of the EEG (New Scientist , vol 85, p 308) and other similar measures.
Such tests, used in a design similar to that of David employing chelating agents, would perhaps get us nearer to the point where truly causal relations could be studied.
In summary it seems that a statistical relationship between low-level exposure to lead on one hand, and low intelligence and, possibly, hyperactivity on the other, has been established, but that the causal relation is still an unresolved issue.
How this could or should affect the political decision about banning lead in petrol is not a question which I am competent to answer; it involves too many non-scientific aspects.
What is clear, I think, is that to refer to the whole debate as a ‘scandal’ is grossly to exaggerate the position, and it disregards the very great scientific problems thrown up by the apparently simple question of whether low-level lead exposure does indeed produce the alleged effects.
Guide for global eavesdroppers
International satellite television reception guidebook by S. J. Birkill,Satellite Television Technology Inc, pp 78, $40 
Barry Fox
IN THE US there's a new hobby.
You erect a radar dish several metres across in your garden, point it at a satellite in the sky and dip into the menu of television and radio programmes that are continually being bounced across the world by broadcast stations.
Since writing about this in New Scientist , I have received numerous letters from readers asking how they can do the same thing in Britain and Europe.
The problem is that, because the broadcasters do not want people to receive their signals this way, information is not openly available.
And although some data, for instance on Russian satellite transmissions, are on public record, it is often incorrect.
So satellite buffs have to learn by trial and error.
Now the doyen of backyard reception, Stephen Birkill a Briton, has written a manual to make life easier for anyone who wants to take up this new hobby.
But be warned.
This is no casual hobby for someone who dabbles in electronics and fancies watching a few extra television programmes.
The dish and electronics will cost several thousand pounds and you may have to build some of it yourself.
Some of the signals are scrambled and, depending on where you live, your aerial will be able to ‘see’ some satellites but not others.
For anyone interested in taking satellite reception seriously though, the rewards are fascinating.
Raw news coverage can be watched live, before the networks receive it and transmit edited and censored excerpts.
You will also get a fascinating peep into the other side of television.
The night shifts at some Russian TV stations amuse themselves by using their satellite links to swop pirated tapes of pop music, porn,Bugs Bunny and Bruce Lee.
The cost of computer complacency
Software reflected by Robert Baber,Elsevier, pp 192, Dfl 80 
C. A. R. Hoare
IMAGINE a branch of engineering vital to the industrial and social welfare of the developed world, and which promised yet further benefits for the future.
Engineers of this discipline are in the greatest demand, and receive the highest salaries at an early age, Imagine also that the raw material used by these engineers has been rapidly increasing in abundance and dramatically decreasing in cost over a period of 20 years.
Suppose that the quality of the raw material is such that it will reliably perform millions of operations per second for many years without wear, fatigue, fracture or other error.
Finally, imagine that the designs and products of the practising engineer are so unpredictable, so prone to delay, error and collapse, that the remark ‘Sorry sir, it was a computer programming error’ is taken as an adequate excuse for almost any misfortune, from an inflated tax claim to a delayed spacecraft or the near-triggering of a nuclear war.
Now you can give your imagination a rest.
I am describing only the current reality: the state of the art of software engineering — the art of programming the raw hardware of our increasingly cheap and reliable computers to meet the needs and aspirations of their users.
The mismatch between promise and performance in computer programming was first publicly recognised by professionals in the field at a famous conference on software engineering in 1968.
The past decade has seen immense progress in elucidating the scientific basis for a proper discipline of programming: it is now possible to prove that a computer program meets its specification, in much the same way that mathematicians and engineers know how to prove the correctness of a proposed solution to the relevant differential equations.
The present predicament of the programming profession is most clearly described in Robert Baber's new book Software Reflected : and he also describes the nature of the solution.
It is an immensely readable book, yet it treats its important subject with insight and responsibility.
It contains sound practical advice not only for computer programmers, but also for the users of their products, and for educators in secondary school and universities.
I would particularly recommend this book to the non-professional reader, including industrial managers, journalists, teachers and politicians.
In many developed countries, politicians have at last realised the promise offered by the magnificent achievements of computer hardware engineers.
But if they are to make the right decisions, they must realise that the promise will turn to ashes if a similar progress is not made by software engineers and those who educate them.
Trinity of colleges in South Kensington
Science for industry — a short history of Imperial College by A. Rupert Hall,Imperial College, pp 108, £6.75, pbk £3.50 
Jack Meadows
I WONDER whether Commonwealth students find it at all odd to attend an institution called ‘Imperial College’.
If so, they can always comfort themselves with the thought that its establishment coincided with the beginnings of imperial decline.
In Parkinson's Law , C. Northcote Parkinson confidently dates the initial step on the downward path of Empire to the general election of 1906.
The Imperial College of Science and Technology was officially incorporated in 1907.
Rupert Hall's short history of the college guides us through the years leading up to this event, then on through the 20th century to recent times.
It provides a useful introduction to a unique institution.
Imperial College arose from the unification of three main entities — the Royal College of Chemistry, the School of Mines and the City and Guilds Institute.
Each of these had its own independent origin, development and supporters.
The feature they came to have in common was occupancy of land in South Kensington purchased with the profits from the 1851 Exhibition at the Crystal Palace.
Prince Albert, who was much involved in the exhibition, felt strongly that the British neglected technical education.
In comparison with his native
Germany, they had no focus for advanced training in science and technology.
This focus might be provided at South Kensington.
During the latter part of the 19th century the Royal College of Chemistry (subsequently retitled the Royal College of Science) and the Royal School of Mines moved to the site from their previous buildings in the West End and the City and Guilds Institute was built there.
Alongside these teaching institutions developed the great museums which the Victorians — more progressive than many of their descendants — saw as another type of educational establishment.
Watching over this assemblage was the Science and Art Department.
that fascinating 19th-century creation — a government department concerned solely with scientific and technical training.
Professor Hall somewhat misleadingly refers to the ‘very meagre resources’ of the department.
In fact, the Treasury's unhappiness at the amount of money the department was expending proved to be an important factor in its ultimate demise.
But the department's bootstrap operation did help create science teaching in Britain.
The colleges of South Kensington were involved in this along with other groups which, unfortunately, are passed over in this account.
It is a considerable feat to have condensed 150 years of complex history into some hundred readable pages.
However, this condensation has been bought at a price: developments at Imperial College are often not placed very fully within the context of the British educational scene.
For example, shortage of technical assistance in the laboratories and lack of funds for equipment are mentioned at intervals throughout the narrative.
But a comparison with science departments at other universities — such as the Cavendish Laboratory at Cambridge — shows that Imperial College has not been too badly treated down the years.
Similarly, the stagnation in student numbers between the two world wars was true of most British universities.
At points, this inward-looking approach defies the outside reader.
‘Old rituals and traditions are cherished within each constituent College,’ we are told, ‘Boanerges’is as much loved as ever.’
Seeking enlightenment, I asked a recent graduate of the college.
The name was new to him, too.
Perhaps this simply underlines another of Rupert Hall's points.
‘The students were still — and even today remain so — far more conscious of their professional collegiate identity, than of belonging to an Imperial College.’
To an outsider visiting Imperial College, some of the departments seem so large as almost to prevent a sense of unity.
It would have been interesting to have had such contemporary problems, deriving from the college's success, treated in the same detail as the early problems, when it was still seeking the way ahead.
In those early years, we are told.
‘The ways of the South Kensington trinity of colleges were almost as mysterious as those of its counterpart, and far less harmonious.’
What would one say today?
Shifting foundations of social science
Sociobiology and the human dimension by Georg Breuer,Cambridge UP, pp 286, £22.50, pbk £8.95 
Paul Harvey
THE FOUNDATIONS of the social sciences will be reformulated to become part of biology.
That, at least, was E. 0.
Wilson s claim in Sociobiology :the New Synthesis which was published in 1975.
The response to Wilson's arguments was intense and varied.
As the dust settles, significant advances can be seen in three areas.
First, there have been attempts by social scientists to communicate with biologists.
Secondly, evolutionary biologists have tested their theories by searching for expected patterns of behaviour across different human cultures.
The third advance has been the construction of formal models for cultural evolution.
Such models are necessary for the realisation of Wilson's claim, and there have been several attempts at preliminary formulations by social scientists, archaeologists, population geneticists and from Wilson himself.
Georg Breuer's book does not mention those advances and that, I think, is because he is too concerned with the past.
Breuer is a gifted and intelligent freelance scientific writer, and in this volume he has produced one of the few substantive sociobiological works to emanate from Continental Europe.
He describes the neo-Darwinian approach taken by ethologists, concentrates on the behavioural ecology of Old World monkeys and apes in an attempt to extrapolate from animals to man, and examines the political objections to sociobiology.
This last section is the most level-headed assessment of the topic that I have read.
What Breuer writes is usually clearly argued and factually correct, but he does not refrain from making his own contribution to the field.
He argues that humans are unique in their ability ‘to identify with any conspecific and feel sympathy with him’, and that this widely ignored fact provides the necessary bridge between the disciplines.
It seems to me that he must abandon or reformulate his thesis because, as he says, ‘it is something that must be understood, as it were, by brain and heart’.
As a practising scientist, I could not allow such subjective assessments of the human condition to influence my work.
If the foundations of social science shift in the way Wilson envisaged, then Breuer's argument would have to be reformulated.
Unfortunately, the book fails at other levels.
As I said, it looks to the past and, here, I Roswas bothered only that Niko Tinbergen's place in the development of ethology is almost totally ignored.
But what of developments since Wilson's sociobiology?
Recently there has been a distinct shift from comparing humans with other primates, to comparing one human culture with another; attempts by Mildred Dickemann, John Hartung and Alexander to do this are not mentioned.
Also omitted are assessments or even mention of the studies of cultural evolution made since Richard Dawkins's discussion of the memo, the scathing attacks by Richard Lewontin of the scientific method used in sociobiology, and of social scientists' reactions to Wilson's claims.
To have missed these, by chance or design, means that this book has to some extent failed in its major aims which were ‘to give a balanced account of the main ideas and achievements of sociobiology and the main criticisms levelled against this new discipline’.
Insight into intense beams
An introduction to the physics of charged particle beams by R. B. Miller,Plenum, pp 351, $45 
Artificial particle beams in space plasma studies edited by Bjorn Grandal,Plenum, pp 704, $85 
John Lawson
CHARGED particle beams have a wide range of applications today, from modern television tubes to giant particle accelerators.
Although accelerators of electrons were used early in this century in pioneering studies of the nature of matter, the precise discipline of electron optics was not developed until the 1930s.
The context then was the electron microscope, which demanded accurately controlled sources of electrons, and lenses with well-defined focal properties.
During the Second World War, and in the decade that followed, the development of microwave generators required an understanding of more intense beams, where the ‘space-charge’ forces arising from the mutual interaction of the electrons played an essential part in determining their behaviour.
For many years now builders of particle accelerators have also studied particle beams.
These two books are concerned with two very different but topical recent developments.
R. B. Miller takes as a starting point modern pulsed power technology which, although originating in the UK, has been developed on a large scale in the US.
This technology allows us to produce particle beams with enormous power (up to a million amps at a few million volts) but very short duration, typically one ten-millionth of a second.
The generation and behaviour of these beams, explored during the past 10 years, and a survey of possible applications form the subject of the book.
The main incentive for developing these intense beams is the hope of achieving inertial — confinement fusion.
Particle beams promise substantially higher efficiency than do lasers, but focusing presents severe problems.
By analysing simple situations, with essential features in common, we can gain insight into the behaviour of these complicated beams.
But it is in developing a coherent conceptual framework for such discussion that the book is least successful.
More physical discussion of simpler examples and of experimental results, and less detailed mathematical analysis of particular problems (sometimes of dubious relevance), would have made the book more readable and more useful.
Nevertheless, it contains much of value and of topical interest, and an extensive bibliography.
The second volume is the proceedings of a NATO conference held in 1981.
By ejecting beams from rockets and satellites we can explore the local plasma environment, and study how electron beams interact with it.
Radiation in the optical range and at radio frequencies can be detected either locally or at Earth stations.
These studies help us to understand the coupling between magnetosphere and ionosphere, and complex natural phenomena such as the aurora.
This is very much a book for specialists.
It gives a good up-to-date perspective but in such a rapidly advancing field will soon become dated.
Science for the benefit of all
Partial progress by David Albany & Joseph Schwartz,Pluto, pp 224, £495 
Herman
IT NEVER struck me until I was in the sixth form that the activity pursued by scientists had any direct link with the everyday world.
But after listening to Lord Ritchie Calder speaking about Pugwash, the committee of scientists to prevent the spread of nuclear weapons, and Steven Rose condemning the use of CS gas in Northern Ireland, I could never again retreat into the comforting vision of the scientist as an impartial observer.
Further experiences as a journalist have led me to appreciate the real power of the vested interest, the industrial lobby, the vast nationalised undertaking, and last, but not least, the status quo .
So I can sympathise with those protesters outside the gate who say that new scientific knowledge must be applied for the benefit of all and not just those who commission and control it.
And I admire and sincerely respect those who take the time and trouble to challenge the interpretation that the powers-that-be put on the fruits of scientific research.
Partial Progress re-examines some of these interpretations.
The most convincing example is that of the Davy lamp (New Scientist , 10 February, p 363).
Most of us have been taught to see the Davy lamp as a scientific advance in that it saved the lives of miners because it would burn without causing explosions in a methane-rich atmosphere.
In fact, Albany and Schwartz tell us, the Davy lamp enabled the managers of the mines to extend operations into seams with dangerous atmospheres, so when accidents did occur, the chances of being killed were far higher, This example sets the tone of the remainder of the book, which discusses more topical issues in science and how they are manipulated to serve one vested interest or another.
Many of the fashionable topics arc here: IQ, ‘sex role and gender research’, the ‘image’ of the scientific worker, the implications of microelectronics for workers.
Some interesting issues that need a far wider airing are also raised — the close relationship between the development of electronics and computers and the needs of the military, for example.
A strange omission is the politics of the environment: one of the few areas, I would have thought, where a lobby is likely to bring about change.
What of scientists themselves — whose help can often make or break successful protests against serious abuses of science.
They have as wide a range of political opinions as any other professionally-defined group, with, one would like to think, some extra tinge of willingness to examine new ideas.
But how much sympathy will they give to a platform whose rules are ‘Never trust a scientific report’ and ‘Never trust a scientist’?
In providing a popular account of the ‘socialist’ view of science, Albany and Schwartz have been almost wholly destructive, and compounded the crime by failing to build convincing alternative views of the relationship between science and society.
The power of scientists and their masters may sometimes be sinister, but it is not going to be effectively redistributed through an ill considered and superficial programme like the one outlined in Partial Progress .
Paradise previewed by Channel 4
HITHERTO there seems to have been an assumption in the minds of programmers as festive holidays loom that, for the most part, audiences' minds are on vacation, too.
Time now to put out the stuff from the back of the shelves, holding back the normal fare until everyone is back on the treadmill again.
Reviewing during these television troughs is not easy.
There are signs that Channel 4 has given this matter some thought.
This is not, of course, for reviewers' sakes but because its audience has a high proportion of AB viewers, the kind of people who tell you they don't watch much television and who, annoyingly, are mainly telling the truth.
Having wooed an impressive proportion of these, having gained confidence from scrutinising its viewing figures, and having enjoyed, thanks partly to the contortions at TV-am, a respite from its role as the medic's whipping boy, Channel 4 appears resolved to becoming the network with a difference, not least in its approach to holiday periods.
Signs of this were evident at Christmas and, happily, at Easter, too, Not only did Channel 4 go out in peak time with Granada's king Lear on Easter Monday but also had the bright idea of showing us on that day, in Are you having any fun? archive material demonstrating how the British had determinedly convinced themselves they were enjoying themselves as long ago as 1896 and as lately as 1964.
It worked well.
It also gave us a taste of its international coproduction In search of paradise, starting it on Easter Monday, continuing it on the Tuesday, and on the Friday.
The full 13 parts are to be shown later this year but only the very-hard-to-please will jib at the prospect of seeing these three programmes again.
Visually they were a delight, mixing film and paintings in a way that riveted.
But this easiness on the eye, and Michael Hordem's predictably effective narration, will not deter criticism From those who demur at the implicit assumption that man's continuing affection for gardens arises out of a folk memory of being cast out of the Garden of Eden and a consequent urge to recreate this paradise.
Did the Egyptians, for instance, whose kings, at the high point of Egyptian farming, found the time to create garden-like enclosures in which to hunt, have any such memory?
Or the men who built the ancient city of Pompeii and constructed gardens inside and out 2000 years ago?
The series, while mentioning these historical facts, appears to be ignoring the obvious questions they raise, possibly relying on the grand sweep.
And grand it is.
In the first programme, we visited Egypt, Pompeii, the Tivoli, glimpsed Central Park (are muggers seeking Adam?), and our own Kew en route to establishing that gardens were and are a universal obsession.
In the second, it was the turn of the East, China, where symbolism in gardens early achieved great subtlety, then Japan.
The Japanese, ever imitative, took their ideas from the Chinese and made them their own.
They borrowed the idea of the tea ceremony, adapting it to the tea gardens meant to separate people from everyday concerns.
Industrious Buddhist monks laid out gardens everywhere full of abstract patterns that preceded Picasso by centuries.
It was their idea to miniaturise, to reduce the scale of nature so that it could be contemplated in the sweep of an eye.
All good horticultural stuff and seasonal, too, from producer Revel Guest.
His concept in In Search of Paradise bids to be over-ambitious though beautiful and certainly a welcome oasis in an otherwise arid week.
LETTERS
LOFT did not rise from Super-SARA's ashes
Perhaps, when writing of international projects, your printing devils multiply to gremlins, elves, and hobgoblins.
In any event, those wretches played havoc with your LOFT versus Super-SARA article (This week, 24 March, p 787).
The US Department of Energy will be shocked to learn from this article that I am Britain's man on the loss of fluid test (LOFT) project, because that agency is currently providing me with a handsome salary on the understanding that I am the US Department of Energy's man on the selfsame project.
As for the comment you attributed to me, that Britain has a budding romance with pressurised water reactor, I have always been an advocate of keeping government out of the bedroom and would, therefore, never have allowed such a comment to pass From my lips.
In a more serious vein, the attribution to me of the statement that Super-SARA was a tremendous hindrance to negotiations for a LOFT consortium was a surprise to me and, I submit, to anyone who knew that the funds for Super-SARA had already been set aside.
I prefaced my response to this question with the comment that I had no knowledge of the relationship of support for these two projects.
In my ignorance of the situation, however, I conjectured that in these times of diminishing reactor safety research budgets, there might have to be a choice on the part of some countries between the two projects — but, ‘tremendous hindrance’!
Finally, 1 wish to correct the false impression given by your statement that Larry Leach (of EG & G, Idaho) is now in Britain keeping on the Sizewell inquiry for the US government.
Mr Leach is, in fact, attached by the US Nuclear Regulatory Commission (NRC) to the hydraulics section of the UKAEA, Winfrith, to help in adapting computer codes concerned with safety issues.
As a secondary responsibility, Mr Leach is keeping the NRC alerted to safety issues arising from these studies and the inquiry.
Most important, however, is the basic intent of your article of connecting the birth of the OECD LOFT project to the demise of Super-SARA.
It is clear to me that no such connection exists.
Cruise controversy
Congratulations on giving cruise missiles an extended examination, but I was disappointed by some omissions from your articles.
Even in the war-fighting role described by Mark Hewish (Countdown to the cruise, 31 March 1983, p 878), it is not credible that a 12-yard accuracy is needed to destroy bases, camps, etc with a 10-Hiroshima sized bomb.
New Scientist should not allow the first weapons with terminal guidance to be installed before noting that the accuracy is needed to destroy missiles in hardened concrete silos: in other words for a first strike.
It is another nail in the coffin of deterrence even if the first generation of cruise will be slow for such a role.
I think you should also have pointed out that cruise will make future arms control negotiations much more difficult as it is an almost ‘unverifiable’ weapon.
It is so small and mobile that it could easily be hidden, and it can carry nuclear or conventional warheads.
These two points alone are enough, I believe, to make a mockery of the British and US government's declared twin policies of strengthening deterrence and pursuing negotiations towards verifiable arms control agreements.
One of the many things which I love about New Scientist is the way you print the odd spoof article or two in the issue nearest 1 April.
It does rather spoil the fun, though, when the spoof is too obvious — the one in the 31 March issue was so obviously naive and reckless in its content that it could not possibly have fooled anybody with even a grain of sense.
Incidentally, how did you persuade Michael Heseltine to write it for you?
The Germans had their problems launching V2 rockets.
They were much more efficient than the present-day Russian or US forces.
I suggest the following War Diary for a Cruise/SS 20 launching team.
Red alert.
One or more members of team unavailable (AWOL; sick; high on pot/vodka; gone to fetch coffee/tea).
Vehicle leaves base; attacked by indigenous saboteurs.
Vehicle loses way to hitherto unvisited firing-point.
Bogged down/ditched/jammed on narrow bridge/falls through/wedged between trees.
Optical-fibre cable kinked, snarled in bushes, run over by other vehicles too short to reach control centre.
Pre-flight check reveals defects.
Messenger sent back to base for tools, instruments, parts.
Missile aimed on reciprocal course/explodes on firing.
As Denis Thatcher said in the Falklands, ‘some things never change’.
Mark Hewish makes a number of statements about the efficiency of cruise and Pershing II missiles without giving much evidence.
American reports say that the Pershing II, which is only a stretched, possibly over-stretched, Pershing I, has only once been fired successfully after a number of failures, and that over a shorter distance than will be required.
The cruise missile also has not been tested to its full distance overland, because the United States does not have the space.
They are negotiating with Canada to allow them to do it there, but it has not happened yet and the weapons are due here in six months time.
In addition 20 per cent of cruise firings fail in some way or other.
They go only a short distance, or in the wrong direction or just come straight down again.
If this happens when they are carrying nuclear warheads, it means that 1 in 5 will destroy British towns not Russian ones.
It appears that we are being conned by the Americans into accepting untested and unreliable weapons.
Lead linings
Tam Dalyell's thoughts on the need for lead in petrol (Forum, 31 March, p 908) seem to have been shaped by the glossy publications of a lead alkyl manufacturer.
Could it be that Octel's handsomely presented claim that without lead alkyls the roads of ‘most of the world would be very empty’ has had the intended effect on one of our more propaganda resistant MPs?
I hope not: but if it has, he should note that the majority of cars in the US and Japan ‘get out of the garage’ using lead-free petrol, and that documented tests have shown cars perform well on petrol containing alcohols.
Plainly it is futile to make out there is ‘still no clear road for lead’ by nailing up sign-posts provided solely by those who make lead alkyls.
Tam Dalyell is wrong to say that I have been predicting a total European ban on lead in petrol as from June this year (Forum.
31 March.
p 908).
This is not at all the case and if Tam (who is usually very accurate in his writing) read the material coming from the European Parliament he would know that this is not the case.
In fact what is proposed by Mr Ceravolo in his report to the Parliament is the setting of a timetable for the elimination of lead from petrol and it is likely that this will be on the agenda of the Council of Ministers in June and it is to be hoped that the Council will then call on the Commission to proceed to a new directive on the matter to replace the existing one which determines the 0.15 minimum level.
Tam's article consists of setting up a false target and then knocking it down.
As to his argument about an immediate ban, I would accept that entirely and that is precisely why my Committee has taken, and is likely to continue to take, the attitude that it has.
Tam Dalyell, writing on lead pollution, makes a statement which, coming from a normally well informed Labour MP, I find surprising.
He says that ‘four out of five cars would be unable to run if the lead were removed.’
This statement has been demolished so often, and so convincingly, that most readers will find further refutation tedious.
The Department of Transport report on lead in petrol in July 1979 made a similar statement.
However even with nine representatives of British industry on the working party, the report only came up with two specific problems.
They were: 1.
Wear to valve seatings, unprotected by their accustomed film of lead rich gauge.
2.
Problems caused by using fuel with a too low octane rating.
The first problem is peripheral.
The second has caused much confusion, some of it deliberate, which has plainly rubbed off on Mr Dalyell.
The British petroleum industry has claimed that it is uneconomic to produce 97 octane lead-free fuel.
And the British car industry, in the face of mounting environmental and medical evidence, has continued to develop and market high octane engines with undiminished enthusiasm.
For this reason alone the poor old British car industry is facing problems.
If as Mr Dalyell alleges, the EEC is about the push for lead-free petrol, one can expect a propaganda barrage more far reaching than Associated Octels recent £100 000 advertising campaign.
If lead-free petrol has some disastrous effect on British cars unknown to the DoT working party, rest assured that Associated Octel will be giving the editor of New Scientist the full horrid details without delay.
If they don't, one should dismiss the idea of cars unable to get out of the garage as sensational rubbish-mongering.
Weapons perspective
I was astonished to read the article entitled ‘Soviet military research powers’(This Week, 17 March, p 708) which appears to be a tame reproduction of figures given by the Pentagon as to their calculation of the Soviet defence effort.
New Scientist , of all journals, must be aware how totally unscientific the Pentagon version of these matters is.
I imagine that you would also be aware that the only reason the Pentagon produces such figures is to extract from a long suffering American tax-payer billions upon billions of extra dollars in order to pursue its own lunatic military fantasies.
BBC Video
I am writing to register our concern about your report ‘Video blackout warning’(This week, 17 March, p 705).
Your writer refers to the recent agreement between BBC Enterprises and talent unions to allow release of BBC material featuring those union members, on the BBC Video label, for sale or rental to the public, for home use.
That agreement in no way affects the work of another BBC Enterprises department, that of Education and Training Sales, which distributes a wide variety of programmes to non-paying audiences.
This covers sales to the fields of business, industry, and education and training organisations, and many of the programmes sold are in the science documentary area.
We would also like to point out that minority interest programmes will in fact be available on the BBC Home Video label if there seems likely to be enough demand.
Science in Nature
I was excited to see from their fine centre spread advert (24 March, p 820) that McDonnell Douglas have realised how much can be learnt from Nature about improving everyday mechanisms like fighter aircraft undercarriages.
The beautifully posed colour photograph, however, shows a rather elderly specimen of the Mexican Green grasshopper with broken wingtips, usually caused by misjudged landing speeds — an unfortunate oversight.
The copy writers, furthermore, omitted to mention the continuing failure of aviation technology to harness the insect's most useful feature, namely, high-velocity lift-off by instantaneous electrochemical tissue response.
Perhaps this is the reason for the bashfully truncated picture of the F/A-18 which, although admittedly showing the aircraft's refined canopy shape successfully developed from the grasshopper's eye concept, plays down the disappointing lack of progress in the other aspects mentioned.
More weather lore
The answer to Ross Ferguson's (Letters, 24 March, p 840) is as follows:Fire and Ice Some say the world will end in fire, Some say in ice.
From what I've tasted of desire I hold with those who favour fire.
But if it had to perish twice, I think I know enough of hate.
To say that for destruction ice is also great And would suffice.
Ross Ferguson should buy a house in Southern Italy up a mountain.
If the ice comes he'll be far enough South and if it all melts he'll be above the new sea level.
Either way his children will be happy to live in such an attractive place when we all work from home at the end of an optical fibre.
ARIADNE
HAVING vague recollection from reading accounts of English milords on the Grand Tour in the 18th century that there was a nourishing fake industry around the Mediterranean, I was intrigued to learn from Oxford's Research Laboratory for Archaeology and the History of Art that it is still going.
It is going, perhaps, less strongly than it might if the techniques that the laboratory uses for dating pottery, wood and other materials — though no-one has yet found a method of dating metals — were not available.
Italy, apparently, is a centre of the fakers' art, though Iran had a well organised industry until the advent of the Ayatollah's government.
There must be money in it and that may be the reason for an attempt to fool the laboratory in its work with thermoluminescence.
This is the technique which detects stored energy in the crystal lattice of minerals, caused by natural radiation.
In brief, the amount can be compared with the rate of natural radiation and so establish the date of a specimen.
The laboratory was sent an object for examination in which the energy trapped in the crystal lattice had been increased by exposing the object to radiation from a cobalt source beforehand.
That would have shown the object to be far older than it really was, if the dodge had not been detected.
The laboratory's opinion, though, is that the incident was more likely to have been an attempt to make the researchers there look a bit silly.
If you have a piece of pottery that you suspect is older or younger than it purports to be, you can have it tested by thermoluminescence for £80.
I should think it will not be long before the laboratory is turned into a commercial outfit.
TWO whole pages of advertisement in the top people's paper,The Times , extol the virtues and rewards of owning a word processor made by Olivetti.
Edward de Bono, Lord Reilly and Stirling Moss are shown with appreciative expressions and different models of the machines.
Kingsley Amis owns up.
‘From time to time my typing suffers from dyslexia,’ confesses Kingsley Amis.
But he says that he now has an Olivetti ‘spelling disk’ that holds 80 000 words and space For another 30 000.
It highlights any word misspelt or letters transcribed so he can then correct them.
After which it is something of a disappointment to see that Olivetti or the firm's advertising agents have not applied the spelling disk to the advertisement.
It says that Stirling Moss can use his word processor as a telex machine.
All it needs is, according to the copy, ‘just a small adaption’.
But I know how Olivetti must feel.
The computer that sets the type for this page altered ‘privileged’ to ‘privileged ’last week.
Privilege could mean a shelf in a lavatory, but I cannot see the word catching on.
ALTHOUGH it is not clear exactly what movements are incorporated in the thing, a Japanese ‘mechatronics’ artist has produced a robot Marilyn Monroe.
It is claimed that all the Monroe features are natural and lifelike because ‘a microcomputer-controlled air compressor regulates all her expressions’.
The driving force for the achievement was rage.
The artist, Shunichi Mizuno, became consumed with it because all his work for exhibitions was destroyed immediately afterwards.
‘Robots,’ he said, ‘gave me a means of venting my anger,’a remark whose logic baffled me until I read another ‘Logic alone cannot explain this.’
Supported by yards of philosophy, a talking robot is about to make an appearance.
Its voice will be ‘far away from the erotic quality of the ultimate android.’
One step at a time I always say.
A TRIED and true method of removing a spider from a bath is to trap the creature inside a glass and then slide a postcard over the open end while holding the glass against the side of the bath.
This works even with the quickest and most agile spiders.
It is the method I have used every time I have heard the shrieks and pounding feet indicating discovery.
Why spiders horrify some people, I do not know.
Neither do I know how the things get into baths so frequently.
I cannot, either, remember why the subject ever came up, but there is now, I am,(I hope) reliably informed that there is a spider ladder on sale.
It is made of wooden slats and string.
Instructions are to hang in between the taps and any trapped spider will climb up it and away to other parts.
I should think that a piece of string would do just as well.
IMPRESSED just this side of awe as I am by the Department of Transport and its fearless tackling of such problems as juggernaut lorries and EEC regulations, I must nevertheless confess some disquiet about a recent plan.
It is, according to report, to test electronic equipment for checking cars coming into the centre of cities.
If a motorist did enter, he would eventually get a bill.
The dodge, hardly new as an idea, is to fit a special number plate, presumably magnetic, to cars.
This would be detected by loops buried in the road at what are called key junctions and the data passed on to a computer which would issue the bills later.
Hong Kong's transport authority is seriously interested in such a scheme, and the DOT here is collaborating, with the implied idea of applying it to London.
I, for one, cannot take this seriously.
Hong Kong might be able to deal with traffic by using key junctions.
In London, I should have thought, it would be out of the question, unless traffic was channelled into a small number of routes, so making congestion worse.
That is apart from the colossal cost of fitting cars with the number plates and finding out which cars needed to be fitted, catching drivers who had removed the plates, sending out bills, dealing with drivers who said they had not driven their cars on the date in question, and many another items.
DAEDALUS
ALL existing 3-D cameras infer the third dimension indirectly (eg by parallax).
Now Daedalus announces a true distance coding camera, his ‘Discocam’(Regd.).
In the spirit of the infra-red camera whose false colour makes an image of the scene not in optical brightness but temperature, the Discocam records each element in a false colour corresponding to distance.
Its principle is simply that light travels faster than sound.
Its ‘flash’ is a pulsed laser producing a bright, sub-nanosecond burst of light.
Simultaneously with the flash, a piezoelectric plate behind the film launches a sonic pulse into the back of the film emulsion.
Light goes maybe 30 metres in the time it takes sound to travel the 0.2mm thickness of the emulsion.
An object close to the camera, with a very short out-and-return light-path from flash to film, will be imaged while the sound-pulse is still at the back of the emulsion but by the time light from an object 15 metres away has reached the film, the sound-pulse will have reached its front face.
It only remains to devise a film that will encode this experience in false colour.
Ordinary film is sensitive to pressure as well as light so DREADCO chemists are devising a film whose light-sensitivity depends on pressure.
Whereas common colour film has many separate individually dyed layers, Discofilm will have continuous gradients of dyes across its thickness.
The colour developed at any point will depend on where the sonic pressure-pulse had got to when the light arrived, i.e. on the distance of that part of the scene.
The main uses of the Discocam will be in surveying and architecture, engineering evaluation and quality-control, medical diagnosis of body-contours, and so on.
Its pictures should be artistically entrancing as well.
If the colour-code used blue for distance, like the atmosphere, they might give a 3-D effect too.