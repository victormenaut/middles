

Communication and representation within the brain
HORACE BARLOW
This chapter is about the way one part of the brain communicates with a different part of the brain.
How, for example, does my left cerebral hemisphere, which occupies the left half of my skull, talk to the right cerebral hemisphere, which is about three inches away?
I think you will agree that, if we knew about this, we would know the answers to a lot of interesting questions.
Do the messages that pass from one side of the brain to the other use symbols like the words of our ordinary language?
Is there a grammar?
Does my left brain tell the truth to my right brain, or can it lie to it?
I shall not be able to answer these questions, but hope to convey some of the ideas that neuroscientists are currently pursuing in search of answers.
Two of the things we do know about communication and representation within the brain are, first, that they are brought about by nerve cells, and, second, that the neocortex is the most interesting bit of the brain to consider since it is the part whose great expansion distinguishes the primates from other mammals, and makes humankind pre-eminent among primates.
It is a paired structure which occupies most of the cerebral hemispheres and is also called the neopallium .
Sixty years ago C. J. Herrick, the American comparative anatomist, dubbed it the ‘organ of civilisation’, and I have set myself the task of seeing how far our scientific knowledge of nerve cells might earn the neocortex this grandiose title: Would these nerve cells, as actors, be able to perform the play, ‘Civilisation’?
Figure 1 Diagram to show the size of a neuron and its components, and their ranges of variation.
Inset shows a single synapse.
The numbers at the right give an impression of the complexity of the computational system in our heads.
NERVE CELLS
Varieties
Nerve cells, or neurons, come in all sorts of shapes and sizes and perform a great variety of functions.
For example, pinching the skin excites nerve terminals there, and nerve fibres propagate this excitation from the skin to the spinal cord and brain, where the messages give rise to the sensation of pain.
Other neurons conduct impulses from the spinal cord to muscles and cause them to contract; so the pain relayed by the first neurons might cause a limb to be moved by the second set of neurons.
There are also many nerve cells within the brain that connect one part to another, and these are the ones I shall mainly talk about.
Size and number
Figure 1 shows the parts and dimensions of a much simplified neuron.
The distance of the cell body from the dendrites is extremely variable.
Within the brain it is usually only 1 mm or less, but the cell bodies of the neurons that bring information to the brain from the skin lie close to the spinal cord, so in a whale or dinosaur the dendrites could be 10,000 mm long, and this also applies to the axons of the motor fibres, which carry commands from the spinal cord telling the muscles to contract.
Cell bodies are more constant in size — from about  to  mm.
Rather complicated interactions can occur at the synapses that connect  one cell to another, so the dimensions of a synapse are also of interest.
They are of the order of  mm, and each neuron may have 10 3 to 10 5 such synapses from other neurons on its dendrites and cell body.
Figure 2 A neuron simply transmits information from one place to another in the brain, but its trigger feature determines what pattern it responds to, and its projective zone determines where news of the occurrence of this pattern is sent.
In the table at the right of Figure 1 I have given rough figures for the numbers of neurons and synapses in the human neocortex.
As you see, these are very large, and one possibly gains better intuitions from the densities at the right.
There are more than 200,000 cubic millimetres of neocortex, and every cubic millimetre contains at least 50,000 neurons with 500 million synapses; these figures may give you some idea of the complexity of the computer we have in our heads.
Information flow
Figure 2 shows what such a simplified neuron does.
Its dendrites pick up information from other neurons, and the axon and its terminals pass this on to other cells.
The cell body with its nucleus controls the growth and maintenance of the cell.
The axon transmits information by means of electrical impulses, and it is beeause these cause current to flow in the media around the cell that one can monitor the impulses, and hence the information flow, by means of a micro-electrode placed close to it.
Simply transmitting information from input to output may seem a trivial  task, but the neuron has two opportunities to be discriminating in performing it.
First, the details of the synaptic connections from other neurons on to the dendrites determine what a neuron responds to; think of them as forming a lock which is only opened by a key in the form of a particular pattern of activity in the neurons which make contact with it.
This is sometimes called the trigger feature , and I shall shortly show you examples.
The second crucial feature of neurons is the ability to relay this information to a particular destination in the rest of the brain, its projective zone .
So each neuron responds to a particular pattern of activity in the cells that connect to it, and when this pattern occurs it signals the news to a group of cells lying in another part of the brain.
A third key element of a neuron's computing power is its modifiability , and I shall consider this after giving examples of trigger feature and projective zone.
Retina
I am going to illustrate these ideas by a brief discussion of neurons in the retina of the rabbit.
I have selected them partly because I was involved in their investigation, but also because it is a relatively simple system that does happen to illustrate these two concepts rather nicely.
The vertebrate retina is an outlying part of the brain.
The light in the image formed by the lens actually passes through the neural layers of the retina (which are almost transparent) to reach the photoreceptors where it is absorbed.
The ganglion cells are the neurons which communicate with the brain by propagating impulses up their axons, while their dendrites detect patterns of excitation in the photoreceptors, to which they connect through intermediate cells.
For present purposes we need not worry about the complexity and the names of the various components in the retina if only we can answer the following question: What does a single one of these ganglion cells tell the brain about the image falling on the photoreceptors to which it connects?
It turns out that this does not have a simple answer, for there are many different kinds of ganglion cell (as anatomists have long known), and when one records from them one finds that they carry different types of message.
Let us look at some of them.
Receptive fields
Figure 3 shows responses from two of the commonest types of cell which are found in most vertebrate retinae.
The first and third columns illustrate light stimuli, the second and fourth show about one second's worth of the electrical responses from each cell; the electrical impulses appear as vertical deflections on these records.
For the top row, no stimulus was applied, but nevertheless the cells give a slow and irregular sequence of these impulses.
Now all retinal ganglion cells have, somewhere within the visual field, a region called the receptive field where light causes a change in the number of impulses, and as you would expect this region is situated within the field of view of the eye at the position where a light spot illuminates the retina underlying the ganglion cell.
Figure 3 Responses of an On-centre (left) and Off-centre (right) ganglion cell from typical mammalian retina.
The left part of each half shows the stimulus configuration which produced the pattern of impulses shown in the right part.
The periods when the light was on are shown by the bars below (from Hubel 1988: see Further Reading).
First look at the second row of the left half.
If you put a spot of light right in the centre of this cell's receptive field you get the response shown in the second column: when the spot goes on (see stimulus trace at the bottom) you get a burst of impulses, so it is called an ‘on-centre unit’.
At the right are shown responses from the other type: here the burst of impulses occurs when the spot of light goes off, so it is called an ‘off-centre unit’.
Surprisingly, if you use a large spot that covers the whole of the receptive field, you get very little response in both cases, as shown in the third row.
The reason for this becomes clear if you use an annular stimulus; you then get a response at the opposite phase to that for a central stimulus, and there is antagonism between these two regions, so when you illuminate both together there is little or no response; they cancel each other out.
It is not difficult to see what such neurons are telling the brain.
The ‘on’ type is saying that the centre of its particular region of the visual field is brighter than the rest, while the ‘off’type is saying that it is darker.
The ‘keys’ or trigger features required to ‘unlock’these two types of cell are rather simple — it is just a matter of applying a small stimulus in the right place, and giving it the correct sign, an increase for one and a decrease for the other.
Figure 4 This ganglion cell from a rabbit retina gave responses when a stationary spot was turned on (+) or off (-) anywhere within the area surrounded by O's.
The receptive field does not enable one to predict the responses to movements of a spot in the directions of the arrows; these are shown round the outside of the figure.
The trigger feature for this cell is movement upward through its receptive field (from reference 1).
Trigger features
The next trigger feature is rather more complicated, and is illustrated in Figure 4.
The centre shows a map of the receptive field of a particular ganglion cell obtained using a stationary spot.
In the convention used here, a plus sign signifies that a response was obtained at onset at that position, a minus sign that a response occurred at offset, and O means that no response was obtained there or outside that position.
So this cell signals both onset and offset of a small spot over a small region of the visual field.
But when you explore the same region of the visual field with a moving spot you get a result that you could not have predicted from the responses with stationary spots.
For an upward movement the massive response shown below is given, while for a downward movement only two impulses result, as shown at the top.
For other directions the responses are intermediate.
The message conveyed to the brain from one such cell is a bit ambiguous: it is saying either that a stationary spot is going on or off in a particular region, or that something is moving upwards in that region.
However, in a natural environment a sustained response is fairly unambiguous and must indicate  upward movement.
In the rabbit there are four types of such neuron with four different trigger features, upward, downward, forward, and backward movement (see Figure 5 above).
Since their receptive fields are scattered all over the visual field the rabbit's brain is kept well-informed about movements all around it.
Figure 5 For a sample of on-off type directionally selective ganglion cells the preferred directions of movement fall into four groups (left half), whereas for a sample of the on-type they fall into three groups (right half).
The samples came from a fairly restricted region of the visual field, so the explanation offered in Figure 6 is probably correct.
Projective zone
Quite unexpectedly, we found that there was another type of ganglion cell which we called the on-type directionally selective because, when plotting their receptive fields with a stationary spot, they only responded at onset, unlike the other type I have just illustrated which responded at both onset and offset; we still do not understand the reason for this, but it led us to discover other differences.
First, they responded to much slower movements than the other group — so slow, in fact, that they could easily detect the motion of the sun or stars through the sky.
But the most surprising difference was that their axes of preferential response were clearly not lined up with the axes of the on-off directionally selective type, and when Clyde Oyster and I analysed this in more detail we found what is shown in Figure 5.
We were completely baffled as to why there should be these differences, and in particular why the preferred directions of the on-type directionally selective ganglion cells should fall into three groups.
But I think the answer was discovered several years later.
Figure 6 According to J. J. Simpson the on-type directionally selective units signal rotations around three axes which correspond to those around which the three semi-circular canals respond to angular accelerations.
As shown in C, this could lead to the appearance of three groups (see Figure 5 from reference 3).
J. J. Simpson and his colleagues showed that the axons of the on-type directionally selective ganglion cells pass to the brain in a special pathway called the Accessory Optic Tract, and end in a nucleus that has three divisions.
He suggests that their role is to signal rotations of the animal, and to do so using a co-ordinate system that is compatible with the other main organ for signalling rotations of the head, namely the semicircular canals, which are sensitive to angular accelerations.
There are three pairs of semicircular canals, which signal rotations around three axes at right angles to each other.
Figure 6 shows a rabbit on the left, with these axes marked, two horizontal and the third vertical.
The middle diagram shows how objects would move through the visual field for pure rotations round the two horizontal axes, and the right-hand diagram shows, enlarged, the approximate region where the receptive fields shown in Figure 5 had been collected.
His hypothesis explains very nicely why we found the three groups, and he has confirmed it by showing that the preferred axes change with position in the visual field in the manner expected.
But in addition to explaining this mystery, it is a beautiful example of what can be achieved by neurons having the appropriate projective zones .
All the 1,000 or so retinal ganglion cells that are maximally excited by rotation about one particular axis, whatever their positions in the visual field, project to one of the three divisions of the nucleus of the accessory optic tract; similarly all those excited by rotations about the other two also go to their appropriate subdivisions.
These arrangements create three small zones in the brain in  each of which there will be massive activity for rotation about one particular axis.
Collecting together just the right information from scattered origins is obviously an important step in making a sensitive visual analysis of rotation relative to the environment.
Visual information from neurons in these zones supplements that provided from the three semicircular canals and is distributed in parallel with it to the part of the brain that controls our balance, the cerebellum.
Incidentally, the ability to respond visually to very slow movements fits in well, for the semi-circular canals fail to respond to slow rotations, so the visual mechanism takes over just when it is most needed, when the inertial mechanism fails.
NEOCORTEX
I hope I have given some idea of what a single neuron with its trigger feature and projective zone an accomplish, and now I must explain a bit about the neocortex, which is the stage on which neurons perform to bring about higher mental processes.
First, its origin.
Evolutionary origin
About 70 million years ago the brain of the most advanced animals had cerebral hemispheres, but they composed a third or less of the whole brain.
They were concerned almost entirely with smell, except for small patches that had inputs from other sensory modalities, probably mainly touch.
Presumably this made it possible to combine touch and smell information, though we can only guess about this.
Over the next few million years there was an enormous expansion of this non-smell part of the cerebral hemispheres — the neopallial explosion as Elliot Smith called it.
He suggested that this occurred because some of the early mammals took to the trees, and in that new environment smell became less important, while vision and neuromuscular control, and particularly the co-ordination of the two, became more important.
Similarly, hearing increased in importance both for the information it gave about the environment in general, and for communication within the species; hence the stage was also set for language to be born.
By the time our forbears were established tree-dwellers, the cerebral hemispheres had almost lost their original association with smell, and with the great expansion of the parts devoted to vision, hearing, touch and movement, you have something like the modern primate brain.
From then on the  most prominent change leading to the human brain was simply an increase in the area of the sheet of cells which forms the neocortex or neopallium.
In us, each side has an area of about one square foot, so the crinkled appearance results from the need to crumple the sheet like a piece of paper in order to accommodate it within the skull.
But though our brains are big, they are not the biggest; whale and elephant are larger and we only top the scale if you take into account overall body size — our brain is largest relative to our bodies.
Why a structure that had originally been a smell-brain should prove so useful when taken over by other senses is not clear.
One possibility is that some superior form of modifiability occurred in the smell-brain, and I shall return to this later.
I also like another idea, that because the position of an excited smell receptor is unimportant, its central processing station is adapted to make global rather than local associations.
In contrast, the position of an excited tactile, visual, or auditory receptor is all-important and the commonest patterns among them are spatial.
One of the features of the cerebral hemispheres is that they have more extensive interconnections from one part to other parts than is usual in sensory centres, and perhaps this was the feature, inherited from its origin as the smell-brain, that made it useful for other modalities as well; global pattern recognition requires taking into account large chunks of sensory information, not just localised patches.
A new creation myth?
What I have told you is a 50-year-old version of the creation myth.
In some ways it is an improvement over yet older  versions, sions,but I hope you realise that the information it encapsulates is much vaguer and less certain than the description I gave of what single cells can do.
I suspect it may soon be superseded by a very different idea derived from evolutionary theory and the knowledge molecular biology is giving us about the genetic control of brain processes.
Perhaps, for reasons we do not understand, the patterns of interconnections in the smell-brain are under a more versatile system of genetic control, and this allowed the rapid evolution of the neocortex, facilitating the neopallial explosion.
It is said that 60 per cent of the human genome codes for proteins that are only expressed in the nervous system, so the real reason that human brains are different may be because greater genetic control has allowed them to evolve more rapidly; if that is the case, taking to the trees may have freed the smell-brain, but it was its susceptibility to rapid evolution that led to the neopallial explosion.
Outline of neocortical structure
That is, or may be, how we acquired our  brain, but what is its structure?We need to have some idea what the cells are picking up from, and where they are sending information to, in order to apply those two principles I gave you earlier, the selective trigger feature, and the selective projective zone.
A converted physicist not afraid of over-simplification, Valentino Braitenberg, has proposed a scheme so simple that it needs no diagram.
As pointed out above, it is known that extensive interconnection is a characteristic of the neocortex: thus the great majority of the input to any cell comes from other parts of the neocortex itself, and similarly most of the outputs go to other parts of the neocortex.
Braitenberg says these internal connections are of two kinds:local interconnections of about 1 mm, which are largely derived from collaterals of axons leaving one region of neocortex and carrying messages elsewhere; and long-range , distant connections carried by the axons I have just mentioned.
He calculates that there are enough long-range connections for there to be two-way connections between any patch of 1 mm 2 and every other 1 mm 2 patch over the whole neocortex, which is quite impressive when you realise that the human neocortex has an area of more than 100,000 sq.
mm.
This pattern of interconnection means that all neurons in the neocortex could connect with any 1 mm 2 region through only one intermediate neuron, and likewise it could be influenced by the activity of any 1 mm 2 region through only one intermediary neuron.
Braitenberg's scheme is obviously a great over-simplification which neglects the special connections that exist between regions with related functions, but it may nonetheless point to the overall pattern through which the neocortex carries on its extensive conversations with itself.
Neocortical trigger features
After this build-up of the neocortex as the organ endowing us with superior mental functions, it is time to see what messages are actually passed along its nerve fibres.
Our knowledge of this comes very largely from David Hubel and Torsten Wiesel, who worked together for twenty years at Harvard Medical School, recording from single neurons of the visual cortex — the part of the neocortex that receives its input mainly from the eyes.
In one of their experiments they first find the region of the visual field that causes electrical activity to be recorded through an electrode placed in a particular patch of neocortex, and then they map the receptive field for a single cell, as illustrated for a retinal ganglion cell in Figure 4.
Based on the shape of this receptive field, they then search for the stimulus that gives the best  response from it, and in Figure 7 you see that one particular cell responded best to movement of a bar oriented at a particular angle, and also that it only responded when this bar moved in one direction.
It turns out that all neurons of the primary visual cortex respond best to oriented bars or edges, though they still vary greatly among themselves as to the position their receptive field occupies in the visual field, as to the direction of preferred orientation, velocity of motion, size of bar and its polarity (dark or light), and in other ways.
Figure 7 Orientational and directional selectivity in a neuron from the visual cortex.
When a white bar is moved to and fro as shown to the left, the neuron responds only when it is nearly vertical, and only for one direction of movement (from Hubel 1988: see Further Reading).
The discovery that oriented bars and edges were the trigger features for neurons in the visual cortex was enormously exciting when it was made thirty years ago, but Levick followed up their discovery and found that there are orientation selective neurons in rabbit retina as well as the directionally selective ones shown in Figure 4.
Figure 8 illustrates one of these ganglion cells.
It had a small receptive field that was somewhat elongated vertically, and on examination with elongated stimuli it became clear that it responded well to a vertical bar but not at all to a horizontal bar.
Other similar neurons respond preferentially to horizontal rather than vertical bars, and there are many such ganglion cells to be found in the part of the retina in the rabbit called the visual streak, which normally receives the image of the region of the visual field lying close to the horizon.
Figure 8 Selectivity for orientation is also found in retinal ganglion cells.
This one was recorded from the rabbit by W. R. Levick, reference 6; it had the receptive field plotted in the centre, and responded to bars at different orientations as shown by the responses round the outside of the figure.
There are of course important differences between rabbit retina and visual cortex.
The neocortex contains vastly more cells, they come with many different orientational preferences instead of just two, and also in many different sizes.
But they are not better pattern selective elements, so I think one can conclude that the orientational selectivity of cortical neurons is not what makes it the organ of civilisation.
Projective zones and non-topographic maps
If their special property is not to be found in their trigger features, might it be something about their projective zones?
My own view is that the neuron's ability to relay selective information to selected zones has greater possibilities than have yet been discovered by neurophysiologists.
Computer scientists appreciate the power of what are called ‘generalised Hough transforms’, but so far only weak hints of such operations have been found neurophysiologically.
The primary visual cortex is surrounded by many secondary visual regions that seem to deal with special qualities of the image such as colour and movement, and in theory much could be achieved by assembling in appropriate ways information about the occurrence of different trigger features.
Perhaps in the next decade the projective zone will be recognised to be a neural processing tool as powerful as the neuron's receptive field and trigger feature.
Already we have a few examples of the end-product of several stages of processing, although we do not yet understand the mechanisms.
Many years ago Gross and his colleagues found neurons at higher levels in the visual pathway in which the vigour of the response varied strongly with details of the shape of an object moved about in the visual field.
For some cells they had the strong impression that the response increased the more the object resembled a monkey's hand, while in others the trigger feature appeared to be a monkey's face or head.
This has been confirmed by others, and cells have even been found that respond preferentially to the face of a particular individual among those that regularly looked after the monkey.
Such cells were able to maintain their preference when the heads were inverted or other difficulties placed in the way of recognition, and one would much like to know about the computational principles and physiological mechanisms that performed the task.
In spite of these impressive results, progress in finding other examples of neurons with highly selective trigger features has not been as rapid as was hoped.
Most people feel there must be other principles at work to explain high level functions, and the plasticity of neurons is an obvious place to look.
MODIFIABILITY AND LEARNING
Actors have to be trained, and they have to learn their parts; similarly, neurons must somehow acquire their trigger features and projective zones.
It is easy to see that studying the growth and modifiability of neurons is a much harder task than describing them in the state you normally find them, so it is not surprising that much less is known, and all I can do here is to point out some of the interesting possibilities that are opening up.
There appear to be two types of modifiability in cortical neurons: a slow,irreversible process that occurs during early development, and a rapid,reversible one that continues to operate through life.
Rapid, reversible modification
This rapid process is responsible for what psychologists call figural after-effects, contingent after-effects, or pattern specific adaptation; Figure 9 demonstrates two forms of it.
First, look at the mark between the central pair, and note that top and bottom are the  same size and are both vertical.
Next, look at the line between the gratings on the left for about thirty seconds, then transfer your gaze to the central pair again.
They no longer look vertical, but slant in opposite directions.
Do the same for the right pair, and the central pair will look unequal in size.
There are many other simple demonstrations of similar phenomena, and the oldest of them, the after-effect of movement, was known to Aristotle.
Figure 9 Short-term effects of experience.
Gaze at the black bar between the left-hand pair of slanting gratings for about thirty seconds, then transfer your gaze to the dot between the central pair of gratings; they will appear to slant in the opposite directions.
The right pair of gratings give a corresponding after-effect for size (from Blakemore, reference 13).
At a phenomenal level, what happens here can be described by saying that it is as if your perceptual mechanisms became fatigued by some salient characteristic of the adapting stimulus — its orientation or periodicity in the case of Figure 9, or direction of movement in the case of the motion after-effect.
The popularity of this explanation gained a lot from the demonstration that neurons in sensory pathways respond selectively to such characteristics, and do indeed show a decline in their response on continued exposure.
But recently my colleagues and I have developed another theory which I think has more interesting implications.
The strengths of the theory are, first that it explains the perceptual phenomena I have just described, second that the brain has a real need for the operation it postulates, and third that it gives a role to a prominent but hitherto unexplained anatomical characteristic of the neocortex.
I will start with the prominent anatomical fact.
Figure 10 Ten years ago the famous Hungarian neuro-anatomist Janos Szentagothai drew this picture of a section of cortex about 1 mm across.
For a modern view, which is no simpler, see the review by Kevan Martin, reference 10.
Positive feed-back
Figure 10 shows what Janos Szentagothai, a famous Hungarian neuro-anatomist, conceived the neocortex to be like ten years ago.
It can be described briefly by a single word — complicated.
And the diagram is much simpler than the real neocortex, which contains 10,000 cells where only 25 are shown here.
But one simple fact emerges, namely that there are innumerable interconnections between the cells in one small region, which, of course, only reinforces what I have said several times  already, namely that the neocortex talks a lot to itself.
In what follows I shall describe one type of such interconnection, though I confess I am not by any means sure that it is the one responsible for the rapid modification process.
It is possible to find the origin of the synapses ending on cells of the type Hubel and Wiesel recorded from, and it is an amazing fact that 80 per cent or more of their excitatory input comes from other cortical cells, and less than 20 per cent from the nerve fibres coming up from the eye.
One would expect this large amount of positive feed-back to lead to instability: as soon as the input is strong enough to excite one or two neurons, one would expect these to feed back on to others and initiate an explosive chain reaction.
But suppose there is a rule which says that the effectiveness of a synapse decreases whenever it causes the post-synaptic cell to fire.
This will stabilise the network, for the amount of positive feed-back between those combinations of neighbouring cortical neurons that tend to be active together will rapidly decline.
After a time the circuit should settle down to a state in which the usual combinations of inputs to the cell are relatively ineffective, while any unusual combination can still set off a strong response.
Thus the combination of positive feed-back with the rule defined above has the making of a device for detecting unusual combinations.
The detection of novel conjunctions, or suspicious coincidences, is the essence of good detective work, so this simple mechanism might endow our actors, the nerve cells, with a grain of intelligence.
Need
Networks operating on this principle perform an operation that is likely to be extremely important for the neocortex, and it was actually the search for a mechanism that would do this that led us to the suggested modification rule: the modifiable interconnections tend to make the representative elements become uncorrelated, and thus to signal independently of each other.
It is obvious enough that a neocortex would be useless if all its neurons responded to the same or strongly similar features, so decorrelation is useful for this purpose, but it also confers another great advantage.
If the responses of a set of representative elements are statistically independent of each other, it becomes relatively easy to form reliable associations with combinations of them, whereas this is much more difficult when the responses show strong correlations.
Thus decorrelation would enormously increase the versatility of the cortex in detecting new associations.
Increased versatility of learning would confer great selective advantage and is just the kind of  change that might lead to the very rapid evolution of neocortex, so we can add this to global connectivity and greater genetic control as possible causes of the neopallial explosion.
Figure 11 Long-term effects of deprivation during the sensitive period.
The histograms show the numbers of cells controlled exclusively by the contralateral eye (1) or ipsilateral eye (7), with intermediate balance of control shown in groups 2 to 6.
Normal cats have the distribution shown at the left, cats deprived of vision in the contralateral eye during the first three months of life have the distribution shown in the middle, and cats whose eyes were misaligned as a result of surgery have the distribution shown at the right.
Experience is required for the connections from an eye to continue to control its fair share of cortical neurons, and joint experience is required for joint control (adapted from Hubel and Wiesel, reference 5 and Hubel 1988: see Further Reading).
This is all I can tell you about the rapid modification process; it has the effect of diminishing the prominence of events and combinations of events that normally occur together, giving prominence to new associations.
The slow modification process is quite different.
Slow modification
Hubel and Wiesel showed that the properties of the neurons in the visual cortex were drastically changed by restricting the visual experience of an animal, provided that these restrictions took place during a few months early in life called the sensitive period.
Figure 11 shows the result of one of their experiments.
They were interested in the way that the connections between an eye and a cortical neuron were affected by whether that eye had or had not been used, so first they measured the numbers of cells  establishing these connections in normal animals.
These numbers are given in the histogram at the left, 1 meaning that a cell could only be activated through the contralateral eye, 7 that it could only be activated through the ipsilateral eye, and intermediate numbers indicating intermediate degrees of ocular dominance; thus group 4 means that both eyes affected the neuron equally.
They then reared some animals with one eye closed throughout the sensitive period, and as you see the result was dramatic — the closed eye lost control of almost all the neurons it would normally have activated.
Carrying the experiment a stage further, they tried the effect of misaligning the eyes.
Both eyes now had the same average experience, but since they were misaligned, cells would no longer be activated simultaneously by both eyes.
The left histogram shows the result: each eye established control over roughly equal numbers of neurons, but the number connected to both was dramatically less than in normal animals.
Apparently, simultaneous activation of a neuron through both eyes is required to maintain connections to both eyes.
Similar experiments have been done by Blakemore, Hirsch and Spinelli, and others, which show that the same rule applies to other forms of selectivity.
For instance, if vertical lines and edges have not been experienced, there will be few cells responding to vertical lines and edges.
One wonders how many of one's own mental defects result from lack of the appropriate experience at the proper time!
Notice that, at a phenomenological level, the slow modification process works in the opposite direction to the fast modification process, which desensitised the system to the adapting stimulus.
In the slow process it appears that exercise of a particular type strengthens, or at least preserves, the system's response to that type of stimulus.
It is particularly interesting that this strengthening or preservation applies to the conjunction of two stimuli, as shown in the strabismus experiment: cells that respond to joint excitation of the two eyes are normally found, but are missing if joint excitation has been made very improbable by misaligning the eyes.
It has been argued that the mechanism of synaptic reinforcement at work here follows a rule that the psychologist Donald Hebb proposed forty years ago as the neuronal basis of memory: when an input pattern is successful in making a neuron fire, then the synapses that took part in making it fire are strengthened.
These modifications are relatively slow, probably requiring hours or days, and they are thought to depend heavily on growth processes.
The rule for rapid modification suggested earlier was actually anti-Hebbian, the opposite to the above since it postulated a decrease of synaptic efficacy whenever presynaptic activity successfully excited the post-synaptic neuron.
But rapid anti-Hebbian modification of the mutual interactions between the neurons at one level should work rather well if combined with slower Hebbian modification of the synapses feeding excitation from a lower level.
The fast process would ensure that each cortical neuron tended to respond to an input feature that was different from the features of other cortical neurons.
Then, since it is whether or not a cell actually responds that determines whether it undergoes the slow modification process, the slow process would make cortical neurons become permanently tuned to this uncorrelated set of features.
Thus the fast process may make a permanent contribution during the sensitive period, while its influence later would adjust the cortical feature detectors, tending to make them respond most to the unusual combinations and coincidences in their input.
CONCLUSIONS
Now I have explained all I can, you will realise that we really do not understand why the neocortex is, as Herrick called it, the organ of civilisation.
We need not doubt that the epithet is justified and I think we are on the right track in attributing its powers to nerve cells with their trigger features and projective zones, but the connecting links are missing.
Thus our next problems are to understand what principles govern the establishment and modification of the interconnections between unimaginable numbers of nerve cells, how these interconnections endow us with higher mental functions, and the cellular mechanisms that bring about these remarkable processes.
Perhaps we are just beginning to see how the brain works, but we have a long way to go.
Animal communication
PATRICK BATESON
Equipped with his ring, King Solomon is commonly supposed to have spoken with animals.
The biblical text suggests simply that he spoke of them, knowledgeable man that he was.
I suspect the misinterpretation represents the deep longing that most humans have to get inside the heads of other animals.
If anybody could do it, surely Solomon could.
Of course the fantasy of animals talking like humans is as old as human fables and is resplendent in a great chunk of the literature for children.
(Not least, Winnie the Pooh, pondering on truth in chapter 4.)
We have a wonderful capacity, some would say an over-developed capacity, to project ourselves into other beings.
If we are imaginative enough we can project ourselves inside plants and inanimate objects as well as other animals.
We wonder what it would be like to be an oak tree, a house, a mountain, even a thunder cloud.
The urge to empathise is strong, but the projection is often rewarded by understanding in the case of animals.
People who know their animals well have a strong sense of what they are going to do next from what is referred to as the animals' ‘body language’.
Certainly, pet owners and expert ethologists alike can generally tell from cats' and dogs' expressions whether they are likely to attack or escape.
We sense that their postures represent mixtures of the human emotions of fear and aggression.
It may seem reasonable, but we should be clear that the arguments used in discussions about intention, emotion, pain and language in other animals are usually extrapolations from ourselves.
We have intentions, feel pain, and tell each other things.
If we believe that humans have evolved, we are liable to assume that our subjective experiences are shared by other animals.
This evolutionary argument  appeals to continuities between humans and other animals, looked at from a human point of view.
Another utterly different approach to animal communication involves asking what the observed activities might be for.
In other words, what is the evolved function of these behaviour patterns?
This evolutionary argument asks what it is about a feature that improves the animal's chances of surviving and reproducing itself.
If we consider why communication might have evolved, we are drawn into types of arguments and speculations which are much less familiar to the lay-person.
DARWINIAN EXPLANATION
Virtually every biologist who cares to think about the subject believes that all living matter has evolved.
Existing species were not created in their present form at the beginning of life on this planet.
The modern scientific debates are about how the changes came about, not about whether or not they happened.
Chance and catastrophe are unsatisfying and inadequate as explanations when we try to understand the numerous and exquisite examples of correlations between the characters of organisms and their physical and social environments.
Such adaptations grab our attention because the characters seem so well designed for the job they perform.
Much the most coherent explanation for the evolution of such phenomena is still Charles Darwin's.
Indeed, Darwin's proposal is much better seen as a theory about the origin of adaptations than as a theory about the origin of species.
Darwin's proposed mechanism depends crucially on two starting conditions.
First, variation in a character must exist at the outset of the evolutionary process.
Second, close relatives must resemble each other with respect to such a character more than do distantly related individuals.
The steps in the process involve some individuals surviving or breeding more readily than others.
If the ones that survive or breed more easily carry a particular version of the character, the character will be more strongly represented in future generations.
If the character enabled them to survive or breed more readily, then the long-term consequence is that the character will generally bear some relation to the conditions in which it worked.
Figure 1 A reed warbler feeding a young cuckoo as if it were its own offspring (Photo: I. Wyllie).
Richard Dawkins has argued that individual organisms do not survive from one generation to the next, while on the whole their genes do.
He proposed that, therefore, Darwinian evolution is primarily about changes in the genes.
Dawkins's approach to evolution was presented in characteristically  entertaining form when he suggested that the organism is ‘…a robot vehicle blindly programmed to preserve its selfish genes’.
His approach has undoubtedly helped a lot of people to understand the complexities of biological evolution.
While Dawkins cannot be blamed for it, modern enthusiasm for the ‘enterprise society’ may explain why his parable of selfish genes has commonly been elided with the selfish intentions of individuals.
Be that as it may, the general style of thinking about evolution has been applied to the study of animal communication in ways that suggest that all activities directed by one individual towards another are manipulative.
Sometimes this view is clearly correct.
We see it in its most obvious form in the interactions between species when one species manages to control the  behaviour of another as if it were a puppet.
A striking example is the European cuckoo.
The mother cuckoo lays each egg in the nest of another species such as the reed warbler.
The egg very closely resembles the egg of the host.
The young cuckoo hatches before the reed warblers and ejects the competition from the nest.
Then the young cuckoo successfully persuades the unfortunate warbler parents to feed it, even when it is twice their size (Figure 1).
By looking like a super-offspring, the cuckoo successfully exploits the normal pattern of interaction that exists between parent and young.
Is it the case that all communication within a species should be treated as though it were part of selfish manipulation?
The conclusion seems most sensible when applied to the displays between rivals for a mate, for food or for territory.
SIGNALS IN CONFLICTS
At the moment there is vigorous theoretical argument among people who study animal signals, with some taking the extreme position that signals carry no accurate information about the state of the signaller and others arguing that the signals are extremely reliable.
Those who advocate total manipulation urge that a trustworthy mode of communication is always open to cheating.
The cheat uses the information provided by its opponent and gives nothing away about itself.
As a consequence, it is much more likely to win the resource.
And, as a result of that, it is likely to reproduce faster.
Before long, cheating will have evolved to become the dominant mode of behaviour.
It sounds convincing but, as I have already noted, most people who know a particular species well quickly develop a good intuitive sense from an animal's bodily and facial postures of whether it is likely to attack or escape.
Examples from the domestic cat and the wolf, which is the ancestor of the domestic dog, are shown in Figure 2.
Most pet owners who know either cats or dogs would readily agree with where the expressions have been placed on the two axes of likelihood of attack and likelihood of escape.
A great deal is now known about such signals in a wide range of animals, from crabs and spiders to monkeys and humans.
The theories about how the signalling behaviour is controlled are also developing fast.
As an example, take a spider in which each individual needs to find a good place in which to put its web, but good places for making webs are in short supply.
Contests over web sites consist of a series of bouts during which the spiders are increasingly  likely to attack each other if the contest persists.
After the initial location of the opponent, three levels of escalation precede an actual fight, involving easily recognised and increasingly energetic displays.
Neither party will benefit from getting hurt and in the great majority of cases the disputes are settled without serious damage on either side.
The encounter can break off at any stage in the process of escalation.
The contests are usually won by the large spider, but if the spiders are of equal size, they are usually won by the owner.
The displays are usually more energetic if the site is a particularly good one for snaring prey.
Even in these spiders, the simplest explanations for what they do requires that they assess their own fighting ability relative to that of their opponent.
They also need to assess their own needs and how much their opponent is prepared to fight.
The theoretical model, developed by Maynard Smith and Reichert to explain what happens, also requires that the behaviour of each individual at each stage of escalation indicates how serious it is about continuing.
Figure 2 Expressions given by the domestic cat and the wolf in different combinations of circumstances (from drawings by P. Leyhausen of the cat and P. Barrett of the wolf).
All this seems to contradict the expectation of the manipulation theorists.
If we can tell what the animals are about to do next, then surely so can their opponents.
It is sometimes claimed, however, that in fact we are fooling ourselves and our capacity to predict what will happen is not very good.
From a large number of quantititative studies, it is clear that escape is very well predicted by certain patterns of behaviour.
For instance, two postures  given by blue ties threatening each other at a bird table accurately predict escape about 90 per cent of the time (Figure 3).
We can see some sense in this.
If one animal suddenly turns tail, it is liable to be attacked and might get injured.
The advantage to the loser of not being misunderstood and expressing the animal equivalent of a white flag are obvious.
The winner's benefit from responding appropriately to such a signal is that it does not risk injury by escalating the conflict into a real fight when it need not have done so.
The argument is, therefore, that a form of behaviour which effectively negotiates the end of a conflict can be evolutionarily stable.
Figure 3 Three blue ties threatening each other at the bird table (Photo: Kim Taylor/Bruce Coleman Ltd).
That having been said, it is true that attack is predicted by other postures only about half as well as escape.
This has been taken as evidence for the manipulative view of animal communication seen in conflicts.
My guess is that you would draw a comparable, but equally misleading, conclusion from similar analysis of the human game of chess where cheating is not possible.
Tipping the king over in resignation tells you without fail who is the winner.
On the other hand, it can be extremely difficult to be sure who is going to win until very near the end of the game.
In a famous encounter between Robert Byrne and Bobby Fischer in 1963, Fischer seemed to have lost the game by the 21st move.
He had just moved his Queen and two grand masters, providing a commentary for spectators, declared that Byrne had a won game.
In fact, Byrne knew better and eventually resigned without making another move because he realised that he was due to be mated within four moves!
Because of the variety of possibilities at each move, the ability to predict who will win from a given move becomes less and less reliable, the longer the game has to run after that move.
Therefore, the empirical evidence suggesting that reliable signals of each actor's state are not seen in the course of animal conflicts may have been misinterpreted.
These signals may have been less predictive of the outcome because they occurred at higher frequencies at earlier stages in the conflicts.
Even so, the issue is complicated.
The crucial question for evolutionary biology is where the balance is struck between signalling real information about your state and signalling misinformation.
Consider analogies with another human game, poker.
On the one hand, if you can get away with bluff, you make a lot of money.
On the other, if you bluff against an opponent who has a really good hand you may end up very much worse off than if you had decided to throw in your bad hand before you had raised the bet too far.
So we might well expect something equivalent to negotiation, as Robert Hinde has argued.
For each individual the optimal outcome of such negotiation should represent a balance between the costs of escalating the conflict to likely injury and the benefits of winning the resource easily.
An individual that escalates without assessment is in danger of finding itself in a fight with a much stronger individual.
This is not purely a verbal argument since recently Alan Bond has shown how an equilibrium between deception and honesty might be struck in the course of evolution.
The developments in thinking about what happens in animal conflicts have some interesting parallels with economists' theorising about human bargaining.
For many years it was supposed that nothing should be revealed about the bargainer's intentions.
What the opponent observes is either an attempt at manipulation or costly delays by the other party, expressing apparent lack of interest.
However, subtle signals, known as ‘cheap talk’ are now recognised.
These signals may maintain negotiations when they might otherwise have broken down and, therefore, benefit both parties by increasing the likelihood that a transaction ultimately takes place.
This is somewhat similar to what is now recognised in animal conflict.
The evolutionary pressure for some exaggeration of fighting ability is present and many species puff themselves up in various ways, thereby making themselves look more fearsome than they really are.
Even so, honest advertisement of strength providing cues that cannot be faked may count  most in the long run.
While fake characteristics may gain short-term successes, those individuals that ignore such clues and focus on reliable sources of evidence about their opponents will eventually emerge in the course of evolution.
One example may be the male red deer which competes vigorously with other males for opportunities to mate.
Fights occur, of course, but conflicts are most often settled by bouts of roaring at each other (Figure 4).
The rate of roaring is increased by each individual as the contest proceeds until one individual gives up.
The roaring is extremely exhausting for the animals and the one that can keep it up for longest is also likely to be the strongest.
In the roaring contests, both individuals increase the rate of roaring until one seems to recognise it is outclassed and retreats.
Tim Clutton-Brock and Steve Albon played tape-recordings of red deer roars to a real stag.
Unlike the stag, the tape-recorder did not get tired and when the tape-recorder roared at high rate, the stag roared less.
It seems as though the stag has been forced into accepting that it was dealing with a much more powerful opponent.
Figure 4 A red deer stag roaring during the mating season (Photo: T. Clutton-Brock).
Figure 5 The courtship displays of the male mandarin drake in which he shows off his striking orange wing feather (from Owen: Wildfowl of Europe , by kind permission of Macmillan, London and Basingstoke).
SIGNALS IN COURTSHIP
I will turn now to a much easier, less controversial case, namely courtship before mating.
Being explicit about internal state is an obvious advantage to the signaller as well as to the receiver.
If he or she indicates in effect, ‘I'm ready to mate’, and the signal is correctly interpreted, then the arrangement is advantageous to both sides.
In the animal kingdom, we find many such examples of signals that play an important role in courtship.
The drake mandarin duck has an enormous orange flag on each wing modified from one of the wing feathers (Figure 5).
In courtship the male turns his head and points at this beautiful feather with his beak.
How did the posture and its supporting feather ever evolve?
In other ducks courting males may also preen themselves in certain phases of their displays.
Ethologists often notice that animals that are about to switch from doing one thing to doing something else, first do something quite irrelevant.
These so-called ‘displacement activities’ which often involve grooming the body for a short time, seem to occur particularly in states of conflict between, say, attacking and escaping from another individual.
When two high priority activities such as approaching and moving away are in balance, lower priority activities may be briefly observed.
So it is possible that, in the course of evolution, the preening activity of the male has been accentuated because it signals to a female that he is in a state of conflict.
Now, in the early stages of  courtship, the male is aggressive and if the female comes too close he is likely to attack her.
If the male, by his displacement activity, conveys that he is in a state of conflict between attacking the female and behaving sexually towards her, she could detect that this male is interested in her.
As a consequence she may be more likely to mate with him than with a male who is less explicit about his state.
The individual that produces the most clear-cut signal is most likely to have the most offspring.
In this way, an increasingly ritualised signal might have evolved.
It is possible that, if the signal was made even more dramatic by being supported by a set of feathers, the chances of a male getting a mate and thereby breeding might be even further enhanced.
However, combinations of characters can produce surprising outcomes in evolution as in everything else.
In many species mating preferences are acquired by a learning process known as sexual imprinting.
In my own work with Japanese quail I have found that this process may lead to a preference for a partner that is slightly novel — just a bit different but not too different from the members of the opposite sex it knew when it was young (Bateson,Mate Choice ).
If the quail have been reared with siblings, both sexes prefer to mate with first cousins.
The reasons for doing this may be that the animal maximises its chances of mating with somebody with whom it can have offspring while at the same time minimising the ill-effects of inbreeding.
At the same time, for quite different reasons, animals have evolved sensory systems that are particularly good at picking up biologically important features of the environment.
In the visual system of birds, colours and contrasting outlines are some of the features picked out and responded to strongly.
When these two separately evolved features came together, some interesting evolutionary changes became possible.
Suppose that the mating preference was asymmetrically arranged around the familiar so that first cousins with conspicuous plumage were preferred over those with dowdier plumage, then there would have been a relentless pressure for plumage to become more conspicuous.
We cannot, of course, replay a piece of history and we do not have a fossil record of behaviour.
But we can at least test the logic in computer simulations.
Of course, the pressure for change may be resisted because birds with brightly coloured or greatly elongated feathers are vulnerable to predators.
Since lots of birds have highly conspicuous plumage, the possession of such plumage would seem to carry with it some real advantages.
Figure 6 A cleaner fish unharmed inside the mouth of predator fish (Photo: Bill Wood/Bruce Coleman Ltd).
SIGNALS IN CO-OPERATION
The evolutionary explanations I have used are all couched in terms of the benefit for the individual.
The same logic can be brought to bear on the cases in which individuals co-operate.
Even though Darwinian evolution is represented as a competitive process, the outcome has often been that animals ended up working with each other.
One explanation for co-operation is that, at least in the past, the aided individuals were relatives; co-operation is like parental care and has evolved for similar reasons.
Another is that co-operating individuals jointly benefited even though they were not related; the co-operative behaviour has evolved because those who did it were more likely to survive as individuals and reproduce than those that did not.
Once again the force of this particular argument can be seen most clearly in communication between different species.
Little striped fish clean the teeth of great big predator fish.
Before they do their job, the cleaner fish do a characteristic waggling swim in front of the monster.
This inhibits the normal feeding response and the great predator  opens its mouth, allowing the little fish in (Figure 6).
When the big fish needs to eat other little fish, it signals it is switching back into normal hunting mode by jerking its jaw in a particular way.
The little fish scuttles for cover and the symbiotic arrangement is preserved.
Both parties benefit by this arrangement.
I will give some examples of signals that maintain relationships within a species from a familiar companion animal, the domestic cat.
The cat's independence has encouraged a widespread view that it is asocial and unco-operative.
However, the studies of cats living under natural conditions have revealed that, apart from an intense early family life, the females in particular may stay in groups as adults.
While living together, cats may help each other in terms of mutual defence against intruders and caring for each other 's offspring.
Of course, the benefits to the individual of co-operation change as conditions change and, in really difficult circumstances, previously existing mutually beneficial arrangements may break down.
Or if members of a group are not familiar with each other, no mutual aid may occur until they have been together for some time.
As familiarity grows, individuals come to sense each other 's reliability.
Furthermore, expectation of an indefinite number of future meetings means that deception or conflict are much less attractive options.
Once evolutionary stability of co-operative behaviour under some conditions had been reached, features that maintained and enhanced the coherence of the behaviour then evolved.
For instance, purring almost certainly signals that the cat is relaxed and contented.
Kittens first purr while suckling when they are a few days old.
Their purring probably acts like the smile of a human baby indicating to the mother that all is well.
If so, the purr helps to establish and maintain a close relationship.
Probably for similar reasons, the purr is used by adults in social and sexual contexts.
For instance, an adult female will purr while suckling her kittens and when she courts a male.
Again like the human smile, purring can be used in appeasement by a subordinate animal towards a dominant one, the implication being that it reduces the likelihood of attack.
Cats frequently rub parts of their body against objects and other animals (Figure 7).
The patches between the eyes and the ears (which are only lightly covered with fur), the lips, and chin and the tail are all richly supplied with glands producing fatty secretions.
The lips, chin and tail are primarily used in marking objects and the head patches and also the tail arc used in marking other cats.
The result of marking with the head patch may sometimes  be seen if a friendly cat on the other side of a window can be persuaded to approach and rub.
If the light is right, a broad smear, which quickly dries, may be seen where the cat has pushed its head against the glass.
Given that other cats are marked with the patch and the rubbing is reciprocated, it would seem that all the cats in a social group end up smelling alike.
If that is so, then the common odour would be an olfactory badge which might denote common membership of the club.
Figure 7 A domestic cat rubbing the hand of a human with the glands between the eye and the ear (Photo: L. Barden).
One of the most characteristic signals of a cat entering or leaving a social group is the raising of its tail.
The raised tail is a visual signal to the others (as it is to humans) that the individual is relaxed and friendly.
Such signals may be performed regularly because, like a human hand-shake, the cat maintains stable social relationships in this way and reduces the chances that it will be disrupted in its daily round by the other individuals with which it lives.
Finally, another friendly gesture is the blink.
A prolonged stare is intimidating and may cause a subordinate cat to withdraw.
Perhaps for this reason, non-aggressive cats when staring at other cats or at humans will blink, thereby signalling that the scrutiny is not hostile.
In Darwinian terms, once again, cats that did this were more likely to maintain their social relationships and thereby derive the benefits that such relationships provide than cats that did not.
In co-operating animals, the mutual benefits of working together can be greatly enhanced if information about the state of the external world can be transmitted from one individual to another.
One of the most extraordinary and well-analysed examples of such transmission is still provided by the so-called dance language of honey bees described so beautifully by Karl von Frisch.
The story is well known.
The characteristics of the waggle dance performed in the hive provide the crucial information about where the returning bee successfully foraged.
The duration of the dance circuit is strongly correlated with the distance from the hive to the food.
In a darkened hive the angle of orientation of the central segment of the dance with respect to the vertical is strongly correlated with the angle between the food source and the sun's position.
Now, it was logically possible that the cue used by the recruits following a dancer was something other than the angle of the dance — and for a while von Frisch was sharply criticised for precisely this reason.
However, an ingenious experiment by Jim Gould has provided direct support for the view that the new recruits use the angle of the central segment of the waggle dance.
While bees will orientate their dances with respect to gravity in a darkened hive, in bright light, they orientate with respect to the light.
The switch from one mechanism to the other is done by the stimulation of three light-sensitive cells between the big compound eyes on their heads.
If these are painted black, bees orientate their dances with respect to gravity even in bright light.
In the experiment, a light of adequate brightness was placed at 85° to the left of the vertical in the hive.
The first foragers to a feeding site were captured and their light-sensitive cells were painted so that when they returned to the hive they orientated their dances with respect to gravity.
Since the new recruits in the hive had not been tampered with and were stimulated by the light, they misinterpreted the dance of the returning foragers.
As a result they flew out from the hive at an angle of 85° to the right of where the food actually was.
So it seems virtually certain that the angle of the central part of the waggle dance relative to either gravity or a bright light does indeed provide the crucial information for the new recruits.
In general, it can often be difficult for us to be sure just what is going on in supposed examples of communication.
Even so, it is possible to get a long way with well-designed experiments.
Another example is provided by African vervet monkeys.
These monkeys produce alarm calls when one of their many predators approaches — thereby alerting other members of the group.
They are particularly intercsting because they produce several calls and each call is specific to a particular type of predator: a low grunt in response to eagles, a high chutter in response to snakes like pythons and a rather pure tone in response to leopards.
Simply observing vervets rush into trees when somebody gives a tonal call does not guarantee that it was the call that did it.
The other monkeys might have been responding to a visual signal or they may have seen the leopard themselves.
The importance of the calls was demonstrated nicely by Dorothy Cheney and Robert Seyfarth.
They first recorded the vervets' call and then played them through loud-speakers to free-living monkeys moving about on the ground.
When Cheney and Seyfarth played a tonal call normally given in response to leopards, the majority of the monkeys ran to a tree.
When they played a low grunt normally given in response to eagles, the majority of the monkeys looked up.
And when they played a high chutter, normally given in response to snakes, the majority of the monkeys looked down.
LEARNING ABOUT SIGNALS
Unlike the honey bees, a great deal of the vervet's signalling system is learned.
While the adults distinguish between particular predator species within a class and only call to species that are likely to give them trouble, the young vervets give leopard alarm calls in response to a wide variety of terrestrial mammals, the eagle calls in response to a great many different birds and snake alarm calls in response to long thin objects, many of which are not snakes.
Many birds and mammals may have alarm calls that are given to objects that other members of their species have indicated are frightening.
It turns out that like the vervets, birds will also learn to whom they should respond.
For instance, blackbirds will mob owls, producing a high intensity pinking call.
When a stuffed owl was presented to experienced blackbirds living in aviaries, they started mobbing the mounted bird.
If, meanwhile, another blackbird saw a species it has never seen before, it would rapidly associate this species with the mobbing calls made by its fellows.
The novel species was an Australian bird that the European blackbird was not likely to have seen before, called the noisy friar bird.
This grotesque bird is specialised for taking honey from wild bees' nests and has no feathers on its head.
The strangeness and oddity of the stuffed Australian bird were enhanced by painting its head blue.
The blackbirds that saw it quickly treated this bird  as though it were potentially dangerous and mobbed it, even when their fellows could not see the owl and so were making no noise.
In later experiments a brightly coloured plastic bottle was used and the blackbirds even learned to mob this object, although it was not so effective as a novel stuffed bird.
Evidently there are some constraints on what the blackbirds will learn to treat as enemies.
In many ways this is like our own fear of snakes.
We have a predisposition to avoid them, but this can be enormously enhanced by the alarm of others.
This experiment showed how important learning can be in interpreting a signal.
Not surprising, you might think, in animals designed by Darwinian evolution to find associations in the real world.
But it emphasised the point that the capacity to signal and the capacity to learn combine to make animal communication increasingly rich and complicated.
Not only is the predictive value of the signal enriched by learning, but the characteristics of the signal are also enriched.
Nowhere is this more obvious in the animal kingdom than in the song of birds.
This is an immense and fascinating field of research and the founder of my own laboratory, Bill Thorpe, can take most of the credit for also founding the field.
It is clear that male birds with more complicated repertoires can intimidate rivals more successfully and/or attract mates more readily.
The blackbird acquires extremely complicated songs, incorporating noises from what it hears in the environment, such as the songs and cries of other animals.
Recently birds have even incorporated the beeps of pelican crossings and the refined noise of the new-style telephone.
Many a person has been seen hastening into their house on a fine summer's day by this bit of imitation.
The ability to learn such things provides an important step in enriching the signals of animals.
It also provides a link to the last topic I want to cover.
LINKS BETWEEN ANIMALS AND HUMANS
Although my brief has been to examine animal communication, I am bound to be asked whether the Darwinian approach can add anything to understanding the connections between what animals do and what we do.
Noam Chomsky argues in his chapter that there is no evidence to support the view that human language is designed for communication (in the sense that it is the product of Darwinian evolution).
He suggests that the emergence of what he calls the ‘language faculty’ is a side-effect of the evolution of a complex brain with many specialised functions.
Others have stressed, in contrast, the continuities between humans and other animals.
To lend plausibility to their view, attempts have been made to teach apes to talk.
What can be said about the success of these attempts and the character of the debate?
To be sure, the great apes behave so intelligently and have such a rich social life that it seemed extraordinary to many people that they could not learn to speak.
An apparent breakthrough came when the Gardners taught their first chimpanzee, Washoe, the sign language used by deaf and dumb people.
Their experiments were criticised because they had not rigorously excluded unconscious cues that might have been provided by the human trainers, as in the case of the famous German horse, Clever Hans.
Then other research workers got chimpanzees to perform complicated signalling under much better controlled situations, using plastic shapes which the chimp could pick up, or images back-projected onto a screen which the chimp could press.
Some symbols denoted objects such as bananas, apples and tables.
Others denoted actions such as eating, walking and swimming.
In the kind of yuppy apartment in which they lived, the chimpanzees would signal ‘GO SINK’ and head off to the kitchen sink.
One experiment conducted by the Rumbaughs took the following form.
The chimpanzee scanned a tray of objects and went to a keyboard out of view of the tray and pressed a symbol corresponding to one of the objects.
The chimpanzee then returned to the tray of objects, and picked the object corresponding to the symbol.
Finally he brought the object to a human who was out of sight round a corner.
In the birds, the brain has evolved so that in some groups it is comparable in size and complexity to that found in primates.
Relative to its body size, the parrot has the biggest brain of all.
It has complexity of social behaviour to match.
Irene Pepperberg has spent a great deal of time training an African grey parrot which she calls Alex (Figure 8).
Parrots have an advantage over and above chimpanzees in that they can, of course, imitate human sounds.
But, contrary to popular belief, they are not at all analogous to tape recorders.
Alex has been trained to produce vocal answers to questions from a human.
For instance, Alex was shown pairs of objects that had nothing in common and asked ‘What's the same?’
Alex looked at the objects and said ‘None’.
He was then given two objects that were identical and asked ‘What's different?’.
Back came the reply ‘None’.
Now, you might think that is unremarkable and argue that he simply says ‘None’ to everything.
But when Alex is shown two objects that differ in one of three respects: colour, shape or the material of which they are made and asked ‘What's different?’,
Alex says: ‘Colour’, if they differ only in colour and: ‘Shape’, if they differ only in shape.
If they differ only in what they are made of he says: ‘Mahmah’, which is his version of ‘Matter’.
In some ways, the result of her formal experiments are less dramatic than the incidental bits of behaviour shown by Alex.
After a long session of testing, Alex became increasingly crotchety and unco-operative and, in one marvellous sequence captured on video-tape, after a tiring day at the office the parrot says: ‘I'm going to go away’.
He then waddled off and hung his head in a corner.
His behaviour is a long way from human language with all its expressive power and complex syntactic properties.
Even so, it is a great deal more than would have been credited to a bird even a few years ago.
The important conclusion is that some of the cognitive capacities needed for language evolved long before humans.
It was a necessary condition for the big leap in the ability to communicate that took place with humans, but it was not sufficient.
Figure 8 The parrot Alex taught by Irene Pepperberg to give verbal answers to spoken questions about two objects (Photo: D. Linden).
It is obvious that humans have far bigger brains than even our closest relatives and the fossil record suggests that the rate of evolution has been spectacularly fast, the brain size more than doubling in less than two million years (see e.g. Foley,Another unique Species ).
This is what one would expect in a process that feeds back positively on itself, further promoting the conditions  that got it going in the first place.
A fashionable explanation is that this rapid upward spiral is the product of Machiavellian intelligence by which individuals gain great advantage from outwitting others.
Alternatively, or in addition, the upward spiral is the product of some of the surprising consequences of co-operation.
I have already given examples of different characteristics evolving for different reasons.
When these combine they open up a new range of possibilities on which Darwinian evolution can act.
This thought may be helpful in thinking about the evolution of human language.
Capacity to learn about associations in the world is clearly of great value in a variable environment and appeared at an early stage in animal evolution.
Social life can lead to individuals genuinely working together and to signals that indicate the state of the individual.
These signals probably serve to maintain the coherence of the group to the benefit of the individual.
They can also provide valuable information about the rest of the environment.
In the most complicated animals, social life can lead to transmission of skills by copying.
The next step is to enrich the behavioural repertoire used in communication by imitating the signals of others and to associate the performance of signals with the context in which they are given.
It is not a big step from here to the symbolic use of signals.
In general, if one individual is able to make its future actions plainer than another and if it derives benefit from doing so (which does not seem implausible in a social context), then we should expect evolutionary change in the effectiveness of such signals.
All of the capacities could have evolved independently, but then obtained further impetus for change from the gradual emergence of language.
All would lead to more computing capacity and larger brains.
My response to Chomsky, then, is that he is right in part to treat the evolution of human language as an emergent property of other characteristics.
The question is whether he is wrong to argue that the capacity for language does not carry any benefit to the individual and, therefore, was not subject to further evolution.
Once the ability to create symbolic signals and rearrange them was in place, individuals that accomplished this more effectively might well have been at an advantage over those who did it less effectively in terms of all the benefits that come from co-operation.
We may eventually be able to check whether the verbal arguments for the Darwinian evolution of language can be simulated on a computer.
If and when this is achieved, the proposal would at Ieast seem plausible.
However, it will always be difficult to obtain direct evidence for such a view since the less successful members of the lineage left no descendants for us to study.
CONCLUSION
A number of themes have run through this chapter.
I began by pointing out that the idea of evolution has been used in two different ways.
One is that, because we have evolved from other animals, it makes sense to project downwards from ourselves.
The other approach is to look for the advantage to the individual of behaving in a particular way.
This second approach relies heavily on Charles Darwin's theory of evolution.
However, I argued that we should not suppose that the essentially competitive process he proposed implies a competitive outcome.
On the contrary, a great deal of communication is to do with signals that carry real information — even in conflicts — and with co-operation in which all the participants benefit by working with each other.
Another popular misconception of Darwinian evolution is that its products must be genetically determined because their inheritance depends on genes.
In fact we have seen many examples of animal communication that involve learning.
I argued that individuals can gain great advantage from their ability to refine and enrich their methods of communication by this means.
Finally, I made the point that relates to the possible links between animal and human communication.
As capacities evolved, they may have combined with others that have evolved for quite different reasons to create new characteristics that then acquired an evolutionary life of their own.
If this happened, the style of projecting our intentions and emotions into other animals, which we all find so easy and which seems to flow from a belief in evolution, will often lead us astray.
We assume continuities of communication between other animals and ourselves where there may be none.
Solomon was probably wise not to have tried to speak with animals.
Telling the truth
D H MELLOR
Few witnesses in court refuse ‘to tell the truth, the whole truth and nothing but the truth’ on the grounds that they don't know what the truth is or how to tell it.
Outside the courts, however, Pontius Pilate has been but one of many who have claimed, more or less sincerely, not to know what truth is.
I can't say I know all about it either; but I do know enough to be able to tell at least some of the truth about why and how we tell, i.e. communicate, the truth.
And to do that I do have to say something about what truth is, in order to explain why we should want it told.
This doesn't mean I have to define truth, merely produce two important truisms about it, each of which has in fact been proposed as a definition.
But for present purposes it really doesn't matter which if either of them is the right definition.
All that matters is that they're both true, which I hope you'll agree they obviously are.
My first truism is the one Aristotle used to say what it is for a statement to be true or false: ‘To say of what is, that it is not, or of what is not, that it is, is false; while to say of what is, that it is, or of what is not, that it is not, is true.’
For example, to say of what is in fact honey that it isn't honey, or of what isn't honey that it is, is false; whereas to say of what is honey that it is honey, or of what isn't that it isn't, is true.
Now whether or not that's the right definition of truth, it is at least obviously true.
And it's obviously true not only of statements, but also of beliefs, which play an absolutely crucial role, not only in telling the truth, but also in an essential preliminary to telling it: namely, finding it out.
For what finding out the truth means is getting true beliefs for ourselves; and what telling it means is giving our own true beliefs to other people — often of course(though as we shall see, by no means always) by making true statements.
Figure 1 Truth: ‘To believe or say truly is to believe or say of what is that it is…’
So I shall use Aristotle's truism in the following form, extended to cover beliefs as well as statements:to believe or say truly is to believe or say, of what is that it is, or of what is not, that it is not .
See Figure 1.
That's my first truism about truth.
The second truism is one I shall need to answer the question: why should we want to be told the truth?
Or more generally, why should we want to find it out, whether by being told it or otherwise?
Why, in other words, should we want to get true beliefs rather than false ones?
The reason is not a moral one.
True beliefs aren't generally better than false ones in any moral sense: there is usually nothing morally wrong about being mistaken in one's beliefs about matters of fact.
Sometimes there is, especially when one has to act on one's beliefs in ways that affect other people.
Thus a false belief that a man is about to set off a bomb might well be reprehensible in a soldier, who therefore shoots him, when the soldier could and should have known that the man was not about to do any such thing.
But most of our mistakes have no such moral consequences.
There's no moral virtue in the truth of most of our true beliefs.
But there is a practical one.
What is generally and inherently good about getting true beliefs is that they're useful, in the following sense:truth is that property of our beliefs which ensures that the actions they make us perform will succeed .
That's my second truism about truth.
Take the soldier who shoots a man to prevent an explosion.
What makes him do that is his belief that the man is about to explode a bomb.
If his belief is true, then his action (shooting the man) will succeed: it will prevent an explosion.
If it isn't, it won't: since there wouldn't have been an explosion anyway.
It's clear enough there how the truth of the soldier's belief makes the action it causes succeed.
But what does it mean in general for actions caused by beliefs to succeed?
To answer that, I must first say something about how beliefs cause actions.
And the first thing to be said is that, on their own, beliefs don't cause actions.
Believing that a man is about to set off a bomb won't make our soldier do anything, unless he also wants something: in this case, to prevent an explosion.
And what the soldier wants will enormously affect what this belief of his will make him do.
It's only because he wants to prevent the bomb going off that this belief of his makes him shoot.
If he too had wanted the bomb to go off, his belief wouldn't have made him shoot, it would have made him dive for cover.
So what really causes the soldier's action is not just his belief, but a combination of that belief with a certain desire.
And this is true of all actions: every action is caused by some combination of belief and desire.
Thus suppose, to take a less bloodthirsty example, that Pooh's desire for honey makes his belief that there's some in the cupboard cause him to go to the cupboard to get it.
If Pooh's belief is true, his action (going to the cupboard) will succeed: it will get him the honey he wants.
But if his belief about where the honey is is false, his action will fail: it won't get him what he wants.
In short, an action succeeds when it fulfils (i.e. achieves the object of) the desire that has combined with some belief to cause that action.
And that's what the truth of our beliefs ensures: that the actions they combine with our desires to cause will succeed in fulfilling those desires.
That in the end is why we want true beliefs rather than false ones.
We want them because truth is what makes our beliefs useful to us in this well-defined sense.
Indeed, in many cases, we do more than merely want true beliefs: we positively need them in order to survive, since our survival depends on our actions fulfilling our most basic desires, such as the desire for food and warmth.
Given then that we need and want our own beliefs to be true, the next question is: how do we get them?
How do we set about getting the true beliefs that we need if our actions are to succeed in fulfilling our desires?
Well, obviously, we get them either for ourselves, or from other people.
We get them from other people by communication; and we get them for ourselves by thinking, or by observation, or both.
Beliefs that we could get  just by thinking (such as beliefs about logic and mathematics) I'm going to ignore.
To keep things relatively simple, I'm going to stick to true beliefs that we could get by observation, like beliefs about the presence or absence of honey, even though in fact we get most of them by communication: by being told things.
How then do we get true beliefs of the sort that we could get by observation?
And how in particular do we get them by communication?
That's my main question.
But to answer it, I must make a considerable digression, to say something about how we get such beliefs by observation.
And first I must say why I need to make this digression.
I'm not making it just because observation comes before communication, although it does: since before an observable truth can be communicated, someone somewhere must get that true belief — or something from which it can be inferred — by observation.
Nor am I digressing because observation is a necessary part of communication, although again it obviously is: since communications obviously can't work if they're not observed.
For example, I obviously can't tell you anything unless and until you hear what I've said or see what I've written.
However, the real reason for starting with observation is that communication doesn't merely depend on observation in these two ways: in effect, communication itself is a kind of observation.
Being told an observable truth is, as we shall see, just one way among many of indirectly observing it.
So in order to understand how observable truths are communicated, we must first understand how they are observed: first directly, and then indirectly.
Only then will we be able to see what's so special about observing them by being told them.
How then do we get true beliefs by observation?
Well, the simplest way, when it's feasible, is by direct observation.
We just look and see, or hear, or touch or smell — or, as in Figure 2, taste.
The first thing to note about the observation that Pooh is making in Figure 2 is that it is, amongst other things, an action: something which Pooh does.
Which means, as we've already remarked, that it's caused by some combination of desire and belief: in this case, by Pooh's desire, not just for honey, but to get a true belief about whether what's in the pot is honey, and his belief that the way to get that true belief is to taste what's in the pot.
So considered as an action, Pooh's observation will succeed if this belief of his is true: that is, if tasting what's in the pot will in fact make Pooh believe it's honey if it is honey, and believe it's not if it's not.
If his tasting what's in the  pot will do that, his action will succeed: it will be a good observation.
And what will make it good is a causal link, between what he's observing (what's in the pot) and the belief he gets about it.
What sets up the causal link in this case is the fact that honey has a distinctive taste, which Pooh will recognise.
So if what's in the pot is honey, its taste will cause Pooh to believe that it's honey.
And if it isn't honey, the absence of that taste will cause Pooh to believe that it isn't honey.
So either way Pooh will make a good observation.
The belief he gets will be true, because he will have been caused to get it by the very fact (that what's in the pot is honey) which makes it true.
And that in general is what makes direct observations good.
The facts that cause the beliefs those observations yield are the very facts which make those beliefs true.
Figure 2 Direct observation: How to get a true belief (1): Look and see.
But observations needn't be direct to be good.
Instead of looking directly for something one wants to get a true belief about, one can look instead for a sign .
By ‘sign’, I should say, I mean nothing very technical.
I mean only what anyone would mean by saying that clouds mean (i.e. are a sign of) rain or, as in Figure 3, that bees mean honey.
In Figure 3, Pooh observes the presence of honey only indirectly: what he observes directly are honey bees.
And since Pooh knows what bees look like, we may assume that this observation is a good one: the belief the bees give him (namely, that they are bees) will be true.
And from that belief Pooh then derives the belief that there's honey by inferring it, via his belief that bees mean honey, i.e. that where there are bees there'll be honey.
And as for Pooh, so for us.
We make an indirect observation by first making a direct observation of a sign, and then making an inference from that to what we believe the sign signifies.
Figure 3 Indirect observation: How to get a true belief (2): Look for a sign.
For an indirect observation to be good, therefore, both parts of it must be good.
The direct observation must be good, and so must the inference.
That is, the inference must preserve the truth of its premise (that the sign is present) in its conclusion (that what the sign signifies is present).
And it will do that just in case, as a matter of fact, the sign is correlated with what we take it to signify: that is , provided that , at least in Pooh's neck of the woods, there really is honey wherever there are bees.
If that's so, then Pooh can get true beliefs about honey just as well by observing it indirectly by observing bees as he can by observing it directly.
Either way, the beliefs he gets about honey will be true, which is what matters.
We get many of our beliefs by indirect observation in just this way, either because we don't want to make a direct observation or because we can't.
We might for example want to find out if it's freezing outside without going outside to feel directly how cold it is.
So we make an indirect observation by looking through the window for signs of freezing, such as frost.
Or we might want to know how cold it is to the nearest °C, in which case we have no  choice.
We can't make that observation directly, because our feelings of cold don't enable us to discriminate temperatures that finely.
This observation is one which we have to make indirectly: by directly observing a thermometer, and inferring that the temperature is what the thermometer says it is.
In both these cases, we are essentially doing just what Pooh does when he observes honey indirectly by inferring its presence from that of the bees he observes directly.
There are of course obvious differences, but they're not really relevant.
One such difference is that whereas thermometer readings are caused by the temperatures they signify (that's what correlates them), with bees and honey it's the other way round: what correlates them is the fact, not that honey makes bees, but that bees make honey — the sign causes what it signifies.
But that's immaterial.
It doesn't matter whether a sign causes what it signifies, or is caused by it, or whether both are caused by something else (like thunder and lightning, either of which might be a sign of the other and both of which are caused by an electrical discharge).
What matters is the correlation between them, not how the correlation is produced.
Another and even more importantly irrelevant difference is that thermometer readings are linguistic : they say explicitly what they're signs of.
Every reading on a good thermometer is correlated with the temperature it names: so that, for example , the reading ‘10°C’ is correlated with that very temperature.
Whereas bees, of course, like frost, are not linguistic signs: they don't say what they're signs of.
But why should they?
You can learn to use a sign without its having to tell you what it signifies every time you use it.
Bees do not need to be labelled ‘Honey’ any more than honey pots do: all that's needed in each case is a memorably distinctive appearance.
So that difference too is irrelevant.
All we need, in order to make a good indirect observation of something, is a learnable correlation between it and something else which we can observe directly.
And that — a learnable correlation — is also the main thing we need in order to be told the truth.
Suppose for example, as in Figure 4, that Pooh, visiting Rabbit, asks him if there's honey still for tea, and Rabbit says yes, there is.
That statement of Rabbit's will be true (as our first truism about truth tells us) if and only if there really is honey still for tea.
So in order to be true, Rabbit's statement must be correlated with what in the circumstances it says it signifies (namely honey).
Otherwise the statement will be false; and so therefore will the belief, that there's honey, which Pooh gets by believing what Rabbit says.
In other words, Pooh's relation to Rabbit's statement, telling him that  there's honey, is essentially the same as his relation to the bees which he uses to observe indirectly that there's honey.
Indeed from his point of view, that of the tellee (if you'll pardon the expression), being told the truth just is finding it out by a certain kind of indirect observation.
Figure 4 Communication: How to get a true belief (3): Ask an informant.
The only difference in this case is that, instead of looking out for bees, Pooh gets Rabbit to say something ('Yes') which he hears (i.e. directly observes) and understands (i.e. takes to say, as a response to his question, that it's a sign of honey).
And from this Pooh infers that there really is honey.
But this in essence is just what Pooh did when he inferred the same belief about honey from his direct observation of bees.
In both cases what really matters is the same: that the sign he observes directly — the bees, Rabbit's saying ‘yes’— should be correlated with honey, so that the belief he infers from the sign will be true.
This for Pooh is the whole object of the exercise: getting a true belief about honey.
The fact that he gets it by being told it, as opposed to observing it for himself, is incidental.
Communication here is a means to an end (the acquisition of a true belief), not an end in itself.
And Rabbit, knowing this, could in fact have answered Pooh's question without telling him anything at all.
In other words, he needn't have told Pooh that there was honey, he could have shown him that there was — for example, by drawing his attention to the pot of honey on the sideboard.
But what then is the difference between being told the truth and being shown it, and does the difference really matter?
Since in both cases the end, getting a true belief, is the same, the difference must lie in the means; but what the difference is, and why it matters, remains to be seen.
The difference is this.
When Pooh is shown the honey, he doesn't get his belief that there's honey from Rabbit.
In fact, Rabbit needn't have that belief: he might have forgotten all about his honey until Pooh's question made him look for it.
Whereas when Rabbit tells Pooh there's honey, Pooh does get his belief from Rabbit; and specifically, from what Rabbit himself believes.
For Pooh doesn't infer the presence of honey directly from what Rabbit says: he infers it indirectly, via what (he believes) Rabbit believes.
In other words, what Pooh infers first from Rabbit's saying ‘Yes’ is that Rabbit believes there's honey.
Only then, from that, does he infer that there really is honey; and this is what really distinguishes being told the truth from finding it out in other ways.
When Pooh infers the presence of honey from the bees he sees, his observation may not be direct, but his inference is: bees, therefore honey.
The bees' beliefs about the matter (if any) don't come into it.
And when Rabbit shows Pooh the honey, again the inference is direct: a honey pot, therefore honey.
Rabbit's beliefs about the matter don't come into it.
But when Rabbit tells Pooh that there's honey, Pooh's inference is indirect: it goes via Rabbit's belief.
Pooh only believes what Rabbit says because he believes that Rabbit believes it too.
In other words, he adopts Rabbit's belief.
And that's what makes this a communication : the way the teller's belief is passed on — communicated — to the tellee.
That's the difference that matters between Pooh believing Rabbit and Pooh believing his bees.
The other differences between these different ways of acquiring true beliefs are irrelevant.
In particular, it's quite irrelevant that Rabbit tells Pooh there's honey by saying that there is, i.e. by producing a linguistic sign, whereas bees, as we've remarked, are not a linguistic sign.
But as we've seen, not being linguistic doesn't make Pooh's bees any less useful as a sign.
And just as indirect observation in general doesn't need linguistic signs, nor does the special case of communication.
Language may not only be ill-adapted to communication (as Professor Chomsky shows us in chapter 3), it's also in principle, and quite often in practice, unnecessary.
Rabbit doesn't have to use language to tell Pooh that there's honey.
He needn't say anything to do that.
He could just nod, or sigh, or do anything, in fact, which Pooh would rightly take to correlate with Rabbit's believing that there's honey.
As indeed, in Figure 5, Eeyore does when Pooh asks him if there are any thistles.
Figure 5 Non-linguistic communication.
Eeyore's sigh is not a linguistic sign.
It's like the bees: it doesn't say what it's a sign of.
But it is a sign nonetheless, and what it signifies is that Eeyore believes he's out of thistles: simply because he only sighs (when the subject's raised) when he does believe that.
And because Pooh has learned this correlation, just as he's learned that bees correlate with honey, Eeyore can tell Pooh that thistles are off simply by sighing, without using any language at all.
In short, it's not the use of language that distinguishes being told the truth from other ways of finding it out: it's the fact that when we tell people the truth, we do so by getting them to believe what we believe.
But why do we do that?
Why, for a start, do we want to be tellees, i.e. to adopt other people's beliefs?
And why, as tellers, when we want to tell people the truth, do we do so by telling them instead what we believe?
The first question is relatively easy.
The reason we want to adopt other people's beliefs is that we know that everyone wants their own beliefs to be true: because, as we've seen, truth is what makes our own beliefs useful to us in the way I described earlier, by making our actions succeed in fulfilling our desires.
We all know therefore that everyone tries to get their own beliefs by methods that will maximise their chances of being true: like Pooh getting his belief about what's in his honey pot by tasting it.
So if, for example, I believe that you've got your belief about whether there's honey by an especially good method which I can't use (because I can't get at your honey pot), then I  will naturally want to adopt your belief, in order to acquire with it its high chance of being true.
In other words, the fact that we get most of our true beliefs from other people, whom we believe are better placed than we are to get them for themselves, is just a special case of the division of labour: namely, of epistemic labour, the labour of acquiring knowledge.
That's why, when I want to be told something, the belief I want to get about it is my teller's belief.
There is really no great mystery about that.
But that doesn't answer my second question.
It doesn't explain why, when I want to tell other people the truth, I want them to believe what I believe.
Because what I really want, after all, is to give them a true belief, and I know very well that, although I want my own beliefs to be true (because that's what makes them useful), we can all make mistakes.
So I don't flatter myself that someone who gets my beliefs will automatically get true ones.
And yet, when I want to tell people the truth, what I will in fact do is try to get them to believe what I believe.
Why?
There is one very bad answer to this question, which is depressingly common and goes like this.
‘We can't really know what actually goes on in the world, like whether there really is honey: all we really know, and therefore all we can really tell other people, is what we believe goes on in the world.’
That's nonsense.
We know far more about what goes on in the world, i.e. we have far more reliably formed true beliefs about it, than we do about our own beliefs about what goes on in the world: beliefs about honey, thistles, etc.
We have very few beliefs, true or false, about what our beliefs about honey etc. are: why should we?
At any one time, therefore, most of the many beliefs that constitute our knowledge of what goes on in the world are beliefs that we don't know we have.
So it's just not true that we know less about what's going on than we know about our own beliefs about what's going on.
It's absolutely the other way round.
So that can't be why, when we want to tell people the truth about what's going on, what we actually do is try to give them our own beliefs about what's going on.
No, the real reason is this.
Telling the truth about something is an action, caused, like all actions, by a combination of desire and belief: in this case, of a desire to tell some truth and a belief about what the relevant truth is.
So suppose Rabbit wants to tell Pooh the truth about honey, and believes the relevant truth to be the proposition, P, that there is some.
But by our first truism about truth, for it to be true that there's honey is just for there to be honey.
So for Rabbit to believe that P is true is just for him to believe P, i.e. to believe that there's honey.
That's why his desire to tell Pooh the truth will in  fact make him tell Pooh what he believes, whether that is actually true or not.
This is almost right, but not quite.
Telling the truth is a little more complicated than this.
For Rabbit doesn't just want to say what's true: he wants to make Pooh believe it.
And as an experienced tellee himself, he knows that Pooh will only believe what he says if Pooh believes that he believes it too.
So Rabbit's immediate desire is to give Pooh a true belief about what he, Rabbit, believes.
So what Rabbit will tell Pooh is not necessarily what he actually believes, but what he believes he believes.
But since (Rabbit believes) Pooh will in fact believe that Rabbit believes what he says, this needn't make Rabbit say ‘I believe there's honey’: it need only make him say ‘There's honey’.
And as for Rabbit, so for the rest of us.
When we set out to tell other people the truth by saying things, what we actually do is to say not what we believe, but what we believe we believe — which, as Freud and others have taught us, isn't always the same thing.
That — I'm telling you!— is how we tell the truth.
But I fear you may not believe me: because you may well think that I've made the process seem incredibly complicated.
After all, we all know how often we tell the truth, and I'm sure it doesn't seem anything like as complicated a process as I've said it is.
Nor it does.
But it is.
The reason the process of telling the truth seems less complicated than I've said is simply that we aren't conscious of most of the mental processes I've been describing.
But one of the most persistent and pernicious myths we've inherited from Descartes is that mentality is essentially conscious, so that anything we can't introspect can't really be going on in our mind.
But we know now that that's not true: that there are many unconscious and subconscious mental processes which we can't just introspect, and that our mental life is far more complicated than we ourselves are ever aware of at the time.
So what I've said should not be incredible in principle.
And in practice, I can even offer you an introspectible piece of evidence for it, as follows.
I've said that most of the time we don't know what our own beliefs are, because we don't believe we have them.
(By which, of course, I don't mean that we dis believe that we have them: merely that we mostly have no belief either way about what beliefs we have.)
So when, for example, Pooh goes to get honey from the cupboard where he believes it is, he needn't be aware of having that belief.
He can just go, guided by that belief, which he has, but which he needn't at that instant believe he has.
But if I'm right about what it takes to tell the truth, Pooh can't tell anyone  that there's honey there without first becoming aware of having that belief.
And that's because, according to me, telling the truth means saying (or otherwise conveying) not what you believe, but what you believe you believe.
And similarly of course when you want to lie or to mislead — to give someone a false belief — what you'll say is not necessarily something you disbelieve, but rather something you believe you disbelieve.
So either way, whether you want to tell the truth or to lie, you need to have beliefs about what your relevant beliefs are.
In other words, you have to be aware of them.
And so you do.
Wanting to tell people things, sincerely or not, does demand an awareness of the beliefs (or disbeliefs) you're trying to give them: an awareness which most of the actions those beliefs combine with your desires to cause doesn't demand at all.
And this is just a fact: indeed an introspectible fact, which we can therefore all observe directly for ourselves.
So this is not something I'm even trying to tell you: it's something I'm trying to show you, by drawing your attention to it!
All I'm trying to tell you is how my account of how we tell the truth explains this fact, which apparently simpler accounts of how we tell the truth don't do.
And that fact, I believe, provides significant support for my account.
So much for telling the truth.
What about lying?
Suppose Rabbit doesn't in fact believe there's any honey left (and believes he doesn't believe that).
So when he says ‘There's honey’, he's lying, saying something he believes to be false.
But now suppose that Eeyore does the same.
Suppose he sighs because, although (he believes) he believes there are thistles left, he wants to keep them to himself.
Has he lied to Pooh, or just misled him?
He hasn't after all said anything false, because he hasn't said anything at all: all he's done is sigh.
And some people think that this matters: that when it's wrong to mislead people — which it usually, if not always, is — then it's not quite as bad if you can manage to do it without actually saying anything you believe to be false.
I think that's nonsense.
The only thing that's ever wrong with saying something you believe to be false is that you do it in order to mislead someone whom you think will believe what you say.
There is after all nothing inherently wrong with quoting fiction — with saying, for example, that Baker Street once housed a detective called Sherlock Holmes — so long as you don't mislead anyone by palming it off as a fact.
And if you did palm it off as a fact, it would be no excuse that you had done it non-linguistically: for example, by including clips from Sherlock Holmes movies in old newsreels as if they were genuine news items.
What matters about lying is giving  people false beliefs, just as giving them true ones is what matters about telling the truth.
Whether that's done by saying things or not is immaterial.
So I'd say that Eeyore too was lying, or at least doing something just as bad.
But how can you tell when other people are lying?
Well, sometimes it's easy, because you know independently, not only whether what they say is true, but whether they believe it.
Suppose for instance you see some visibly sighted person make a phone call in broad daylight, and hear them say that it's pitch dark.
You know they're lying because you can see, not only that it isn't pitch dark, but that anyone who isn't blind can see that too.
Of course it isn't always as easy as that.
And when it isn't, one maxim that's often used as a lie detector is the maxim that actions speak louder than words .
And I'd like to end by saying why that's often (though not always) true.
One might, for instance, use the maxim to infer that because Eeyore's sigh is a non-linguistic action, it's a better sign that he's out of thistles than Rabbit's words are that he has some honey.
But even if that's true, it won't be because sighs aren't words.
It will be because Eeyore isn't even trying to communicate.
For example, his sigh might not be a voluntary action at all .
It might be an involuntary reaction, which any mention of thistles always produces in Eeyore when he believes he's out of them.
And if it is, then its correlation with that belief of his won't depend on his wanting anything (other than thistles) and in particular not on his wanting to tell anyone the truth.
And this will make Pooh's inference from Eeyore's sigh to what Eeyore believes safer than his inference from Rabbit's words to what Rabbit believes: because that inference does depend on Rabbit's wanting to tell Pooh the truth, whereas, as we've remarked, he may in fact be lying.
But then, as we've also remarked, so may Eeyore be lying.
He too may be trying to mislead Pooh, by sighing deliberately when (he believes) he believes he's by no means out of thistles.
So the point of the maxim that actions speak louder than words is not that people never use non-linguistic actions to communicate (which is when they may be deliberately misleading), but that language is much less often used to do anything else.
So while you might well overhear Eeyore sighing to himself, and know therefore that he isn't trying to mislead anyone, it's much less likely (though not of course impossible) that you'll overhear Rabbit muttering ‘There's honey’ to himself.
That's why actions generally, although by no means always, do speak louder than words: because, paradoxically, they aren't meant to ‘speak’ at all, and a fortiori aren't meant to speak what's false.
That's all I have to tell you about how to tell the truth.
Or rather, about how to try to tell it: since whether any such action of yours succeeds in doing what you want (giving your tellee a true belief) will depend as we've seen on the truth of the beliefs which you also need in order to make you undertake that action.
And I don't just mean the belief that you're trying to communicate.
There's also your belief about what that belief of yours is, which is what will determine what you'll actually say.
And finally, of course, there's your belief that your tellee will believe what you say.
If all those beliefs of yours are true, your action will succeed.
You will give your tellee a true belief: you will actually tell the truth.
If they're not all true, then you'll probably fail.
But at least you'll have tried.
As I have done.
The novel as communication
DAVID LODGE
Anyone contributing a single lecture to a series like this — covering a wide spectrum of disciplines and addressed to a general audience — is bound to feel some anxiety and uncertainty about how their contribution will fit into its larger context.
Looking at the other titles I infer that mine is the only lecture on literature, and logically, perhaps, my title should be ‘Literature as communication’.
Some of what I have to say does in fact apply to literature generally, but much of it is specific to the novel, the literary form in which I am most interested, both as a literary critic and as a practising writer.
There are two possible ways of approaching this topic.
One is to take for granted that the novel is a mode of communication, and to analyse its formal features as techniques of communication; the other is to question the assumption that the novel is communication — to ask what is implied by that assumption, and what excluded.
I shall try to do a little of both.
I shall also consider the subject from two points of view: that of a critic and that of a practising novelist.
I suspect that it is assumed by most people, including those who planned this course of lectures, that language is a means of communication — that this is what it is for ; and that since literature is made out of language, it too must be a kind of communication, as defined by, for instance, the Collins English Dictionary: ‘the imparting or exchange of information, ideas, feelings’.
A common sense view of the matter would say that that definition covers the composition and reception of a novel.
The novel as communication:La Liseuse de roman by Vincent van Gogh
The classic novelists certainly seem to have thought of their activity as communication.
Henry Fielding, for example, in the eighteenth century, draws his masterpiece,Tom Jones , to its conclusion with a metaphor of social intercourse:
We are now, reader, arrived at the last stage of our journey.
As we have, therefore, travelled together through so many pages, let us behave to one another like fellow-travellers in a stage coach, who have passed several days in the company of each other: and who, notwithstanding any bickerings or little animosities which may have occurred on the road, generally make up at last , and mount for the last time into their vehicle with cheerfulness and good humour; since after this one stage, it may possibly happen to us, as it commonly happens to them, never to meet more.
The intrusive authorial voice exemplified in this passage, and generally typical of the classic novel — the voice that confides, comments, explains and sometimes scolds — the voice to which we rather casually give the name that appears on the title-page (Henry Fielding, Charles Dickens, George Eliot, or whoever) is the most obvious sign that these writers saw themselves as engaged in an act of communication with their readers.
In this kind of novel  the act of narration is modelled on a speech act in which one person tells a story to another.
George Eliot begins her novel Adam Bede thus:
With a single drop of ink for a mirror, the Egyptian sorcerer undertook to reveal to any chance comer far-reaching visions of the past.
This is what I undertake to do for you, reader.
With this drop of ink at the end of my pen, I will show you the roomy workshop of Jonathan surge, carpenter and builder in the village of Hayslope, as it appeared on the 18th of June, in the year of Our Lord, 1799.
By apostrophising the reader, the act of writing is transformed here into a kind of speaking.
Through the figure of the drop of ink, at once miraculous and homely, the act of telling is transformed into a gesture of showing.
This offer to transport us out of our own world, with all its problems, unfinished business, boredom and disappointment, into another world where we may escape these things or negotiate them vicariously, is perhaps the fundamental appeal of all narrative.
What is peculiarly novelistic about George Eliot's opening gambit is its pseudo-documentary specificity — the proper names and the date: ‘the roomy workshop of Jonathan Burge, carpenter and builder in the village of Hayslope, as it appeared on the lath of June, in the year of Our Lord, 1799’.
The novel is a form of narrative.
We can hardly begin to discuss a novel without summarising or assuming a knowledge of its story or plot; which is not to say that the story or plot is the only or even the main reason for our interest in a novel, but that this is the fundamental principle of its structure.
(These two terms, incidentally, story and plot, are sometimes used to describe two opposed types or aspects of narrative, but unfortunately they are also used as interchangeable synonyms and I shall use them as such.)
The novel therefore has a family resemblance to other narrative forms, both the purely verbal, such as the classical epic, the books of the Bible, history and biography, folk tales and ballads; and those forms which have non-verbal components, such as drama and film.
Narrative is concerned with process , that is to say, with change in a given state of affairs; or it converts problems and contradictions in human experience into process in order to understand or cope with them.
Narrative obtains and holds the interest of its audience by raising questions in their minds about the process it describes and delaying the answers to these questions.
When a question is answered in a way that is both unexpected and plausible, we have the effect known since as peripeteia or reversal.
All this applies to the novel as to every other form of narrative, whatever its medium.
Verbal narrative, as distinct from narrative which includes an element of performance and visual images, has two basic modes of representation: the report of characters' actions by a narrator, and the presentation of the characters' own speech in dialogue.
These two modes — narrator's voice and character's voices, or summary and scene, telling and showing, as they are sometimes called — are the woof and warp of all verbal narrative, from the story of Little Red Riding Hood to War and Peace .
The novel, however, exhibits particularly subtle and complex interweavings of these modes of presentation, as I shall indicate more fully later on.
Its discursive variety and complexity is one of the reasons why it imitates the social world with a verisimilitude unequalled by other literary forms.
Another reason is that pseudo-documentary specificity I mentioned earlier in connection with the opening of George Eliot's Adam Bede .
In short, the novel is characteristically a realistic form of narrative.
Early critical discussion of the novel, which acquired a distinctive generic identity in the eighteenth century, focussed on this quality: its illusion of reality.
Clara Reeve, for instance, writing in 1785, said:
The Novel gives a familiar relation of such things as pass every day before our eyes, such as may happen to our friends, or to ourselves, and the perfection of it is, to represent every scene in so easy and natural a manner, and to make them appear so probable, as to deceive us into a persuasion (at least while we are reading) that all is real, until we are affected by the joys or distresses, of the persons in the story, as if they were our own.
(The Progress of Romance )
A much later, much more sophisticated critic, Ortega y Gasset, said much the same thing:
…the novel is destined to be perceived from within itself — the same as the real world…to enjoy a novel we must feel surrounded by it on all sides…
Precisely because it is a preeminently realistic genre it is incompatible with outer reality.
In order to establish its own inner world it must dislodge and abolish the surrounding one.
('Notes on the novel', 1948)
Out of a thousand possible illustrations of this point one might cite the testimony of William Smith the nineteenth-century publisher, on his first reading of the manuscript of Charlotte Bronte's Jane Eyre .
After breakfast on Sunday morning I took the ms of Jane Eyre to my little study and began to read it.
The story quickly took me captive.
Before 12 o'clock my horse came to the door, but I couldn't put the book  down.
I scribbled 2 or 3 lines to my friend saying I was sorry circumstances had arisen to prevent my meeting him, sent the note off to my groom, and went on reading the ms.
Presently the servant came to tell me lunch was ready.
I asked him to bring me a sandwich and a glass of wine, and still went on reading Jane Eyre.
Dinner came; for me the meal was a very hasty one, and before I went to bed that night I had finished reading the manuscript.
The peculiar verisimilitude of the novel's representation of reality, and the peculiarly hypnotic spell the novel casts upon its readers, have always made it an object of some suspicion, both morally and aesthetically.
Is there not something fundamentally unnatural and unhealthy about a form of art whieh suspends the reader's awareness of his own existence in real space and time?
Is not the pleasure of the novelistic text akin to day-dreaming, wish-fulfilment fantasy?
Freud certainly thought so (see his paper on ‘Creative writers and day-dreaming’).
On such grounds it has been argued that the novel is not authentic communication, notably by the Marxist critic Walter Benjamin.
Benjamin drew a distinction between storytelling, which he saw as, in its purest form, an oral-aural transaction between a narrator and an audience physically present to each other, and the novel, which is produced in one place by a solitary silent author, and consumed in another place by a solitary silent reader.
The rise of the novel, he observed, was coincident with the decline of storytelling; and in consequence he says, in a striking phrase, ‘the communicability of experience is declining’.
The novelist has isolated himself.
The birthplace of the novel is the solitary individual, who is no longer able to express himself by giving examples of his most important concerns, is himself uncounselled and cannot counsel others.
('The Storyteller')
In recent years there have been many attacks on what is sometimes called the classic realist novel on similar grounds: that far from being a means of communication it is a means of ideological domination and repression, reproducing on the cultural level the processes of industrial capitalism, making its audience passive consumers, reconciling them to their alienated state instead of liberating them from it, by making it appear normal or natural.
(One of the most recent of such polemics is Resisting Novels: Ideology and Fiction , by Lennard J. Davis, 1987).
In fact the classic novelists were well aware of the dangerous power of their art, and took various measures to prevent or warn against its abuse.
The intrusive authorial voice itself is often used to point to the formal conventions of the novel, and thus to prevent a naive confusion of literature with life.
When Henry Fielding introduces the word ‘pages’ into his stage coach metaphor ('As we have, therefore, travelled together through so many pages') he reminds his audience that they are reading a book.
Jane Austen gives an even sharper jolt at the end of Northanger Abbey to ‘my readers, who will see in the tell-tale compression of the pages before them, that we are all hastening together to perfect felicity’.
When Trollope says in Barchester Towers , ‘But let the gentle-hearted reader be under no apprehension whatsoever.
It is not destined that Eleanor shall marry Bertie Stanhope’, he is teasing rather than indulging his audience.
Henry James did not see it that way.
Such authorial admissions that the events of the novel are invented seemed to him ‘a betrayal of a sacred office’.
James inaugurated the modern or as it is sometimes called, the ‘modernist’ novel in England, a kind of fiction which, in pursuit of a more faithful representation of reality, attenuated or eliminated altogether the authorial narrator.
Instead the action is narrated as perceived by the consciousness of a character or characters.
This can be done in various ways, most of which can be found in eighteenthand early nineteenth-century fiction, but not used so artfully or extensively.
One simple and obvious way of eliminating the authorial voice and giving a realistic effect to the novel is to make a character the narrator, as in Robinson Crusoe or Jane Eyre or David Copperfield .
But whereas those first person narrators are fairly transparent surrogates for the implied authors of those novels, the first-person narrators of modernist texts are more ambiguous, less reliable witnesses to their own experience, and are often framed by or counterpointed with other narrators — as, for example, in Henry James's The Turn of the Screw or Conrad's Heart of Darkness .
A further, characteristically modern variation on the pseudo-autobiographical or confessional novel is the interior monologue, as used in James Joyce's Ulysses , where the reader eavesdrops, as it were, on the actual thoughts and sensations of the character as he or she moves through time and space.
Here is Joyce's Leopold Bloom, considering his cat:
They call them stupid.
They understand what we say better than we understand them.
She understands all she wants to.
Vindictive too.
Cruel.
Her nature.
Curious mice never squeal.
Seem to like it.
Wonder what I look like to her.
Height of a tower?
No, she can jump me.
This kind of discourse is at the opposite pole from storytelling as defined by  Benjamin.
Compared to the classic novel, not a great deal happens in the stream-of-consciousness novel — or it happens off-stage, as it were, glanced at in memory and allusion rather than presented directly.
The minute registering of ‘the flickerings of that innermost flame which flashes its messages through the brain', to use Virginia Woolf's words, works best on ordinary experience rather than extraordinary — walking along a street, preparing a meal, knitting a stocking.
Interior monologue is particularly ill-suited to narrative purposes — even Joyce uses it only intermittently in Ulysses , in combination with other kinds of discourse, including free indirect style.
Free indirect style is a mode of narration which as it were fuses and interweaves the authorial narrator's speech and the speech of the character.
By reporting the character’ s thoughts in the third person, past tense, as in traditional narrative, but keeping to vocabulary appropriate to the character, and omitting some or all of the tags that normally introduce reported speech (like ‘he thought’, ‘she wondered’, etc.) an effect of intimate access to the character's inner self is produced, without relinquishing the task of narrating to the character entirely, as in the pseudo-autobiography or interior monologue.
This type of discourse — free indirect speech or free indirect style — is peculiar to the novel; it makes its appearance in the late eighteenth century and Jane Austen was probably the first novelist to realise its full potential.
Here for instance is her rendering of Emma Woodhouse's thoughts, having just received a most unwelcome proposal of marriage from Mr Elton whom she had supposed to be in love with her protégée, Harriet, as a result of her own matchmaking contrivances:
She had taken up the idea, she supposed, and made everything bend to it.
His manners, however, must have been unmarked, wavering, dubious, or she could not have been so misled.
So far there is a discreet element of authorial summary in this representation of the heroine's thoughts as she reviews the supposed courtship of Harriet by Mr Elton.
But in the following sentences — unfinished, fragmentary, as spontaneous as speech — we seem to be placed right inside Emma's head.
The picture!— How eager he had been about the picture!— and the charade!— and an hundred other circumstances;— how clearly they had seemed to point at Harriet.
To be sure the charade, with its ‘ready wit’— but then, the ‘soft eyes’— indeed, it suited neither; it was a jumble without taste or truth.
Who could have seen through such thick-headed nonsense?
Jane Austen uses this technique sparingly, to represent moments of inner crisis, in combination with the more traditional modes of authorial report and direct speech.
But Virginia Woolf's mature novels consist almost entirely of long passages of introspection by the characters in free indirect style, punctuated by banal conversational remarks and parenthetical reports of trivial actions.
Here is another fictional matchmaker, Mrs Ramsay, in To the Lighthouse (1927):
Foolishly, she had set them opposite each other.
That should be remedied tomorrow.
If it were fine.
they should go for a picnic.
Everything seemed possible.
everything seemed right.
Just now (but this cannot last she thought  , dissociating herself from the moment while she talked about boots) just now she had reached security; she hovered like a hawk suspended; like a flag floated in an element of joy which filled every nerve of her body fully and sweetly, not noisily, solemnly rather, for it arose, she thought, looking at them all eating there, from husband and children and friends…
Thus Mrs Ramsay at her dinner table, thinking her thoughts, ‘dissociated from the moment’, plotting a match between Lily Briscoe and William Bankes, while Lily Briscoe at the same table is thinking wistfully of quite another man.
The emergence of the stream-of-consciousness novel at the end of the nineteenth and beginning of the twentieth centuries was obviously related to a huge epistemological shift in culture at large, from locating reality in the objective world of actions and things as perceived by common sense, to locating it in the minds of individual thinking subjects, each of whom constructs their own reality, and has difficulty in matching it with the reality constructed by others.
If the modern novel is a form of communication, then paradoxically what it often communicates is the difficulty or impossibility of communication.
One of the modernist arguments for removing the intrusive authorial voice — wise, omniscient, reliable, reassuring — from the novel was that it was false to our experience that life is in fact fragmented, chaotic, incomprehensible, absurd.
The trouble with the classic realist novel, in this view, was that it was not realistic enough: truth to life was sacrificed to the observance of purely narrative conventions.
‘If a writer could…base his work upon his own feeling and not upon convention’, said Virginia Woolf, in her celebrated essay, ‘Modern fiction’, ‘there would be no plot, no comedy, no tragedy, no love interest or catastrophe in the accepted style…’.
Instead she called for a kind of fiction that would record the atoms of experience ‘as they  fall upon the mind, in the order in which they fall’, that would ‘trace the pattern, however disconnected and incoherent in appearance, which each sight or incident scores upon the consciousness’.
The modernist novel thus tends to endorse the philosophical argument known as solipsism — that the only thing I can be sure exists is myself as a thinking subject.
This lays it open to Walter Benjamin's critique even more than the classic realist novel, for it is still further removed from his concept of storytelling.
Another Marxist critic, the Hungarian Georg Lukács, attacked modernist fiction on similar grounds.
‘Man, for these writers [he said], is by nature solitary, asocial, unable to enter into relationships with other human beings.’
Unable therefore to communicate, and unable to act upon history.
And of course a familiar populist complaint about modernist fiction is that it does not communicate its meaning to the reader in a clear and comprehensible way.
It is obscure, difficult, esoteric, elitist.
The standard defence of the modernist novel is based precisely upon these qualities, on its formal complexity and difficulty: the ‘revolution of the word’ is seen as either essential to, or more important than, any political revolution.
The paradigmatic case is James Joyce.
After the psychological hyperrealism of the early chapters of Ulysses , the text is taken over by a bewildering variety of voices and discourses — parodic, travestying, colloquial, literary: newspaper headlines, oratory, women's magazines, pub talk, operatic songs, encyclopaedia articles, and so on; while the narrative level of the text is full of gaps, non sequiturs , anticlimaxes, and unsolvable enigmas, and the chronological order of events is broken down and rearranged by the operations of memory and the association of ideas in the consciousness of characters.
Reading such a text we are reminded that the world we inhabit is constructed, not given; constructed in language.
As Gabriel Josipovici has said, ‘To imagine, like the traditional novelist, that one's work is an image of the real world, to imagine that one can communicate directly to the reader what it is that one uniquely feels, that is to fall into the real solipsism, which is, to paraphrase Kierkegaard on despair, not to know that one is in a state of solipsism’(The World and the Book ).
That is, I think, a somewhat tendentious description of the classic realist novel, and, in fact, writers like E. M. Forster, D. H. Lawrence, Ernest Hemingway, Evelyn Waugh and Graham Greene have written fiction that answers to the twentieth century's sense of moral and philosophical crisis without deviating violently from the conventions of classic realism.
In the experimental fiction of our day that is sometimes called ‘post-modernist’ these conventions — such as the omniscient and intrusive authorial narrator — are retained in exaggerated and parodic forms that remind one of the metafictional jokes of Fielding, Sterne, Thackeray and Trollope (one thinks for instance of Muriel Spark and John Fowles in this respect).
In short, I am suggesting that there is more continuity than discontinuity in the development of the novel as a literary form.
The emergence of the modernist novel of consciousness is often described in terms of a shift of emphasis from ‘telling’ to ‘showing’— but showing in this context is a metaphor.
Written language cannot literally show us anything except writing.
Speech cannot show us anything except speech.
Language is not an iconic sign system, in which the signifier has a visual resemblance to the signified (as in the traffic signs for ‘falling rocks’ or ‘humped-backed bridge’), but a symbolic one in which the connection between signified and signifier is arbitrary.
The stream-of-consciousness novel only ‘shows’ us the operations of the mind by another kind of telling than straightforward authorial report.
And even those modern fictional texts, such as the novels of Samuel Beckett, that seem dedicated to demonstrating the impossibility of communicating anything to anybody about anything, do so by alluding to a paradigmatic act of storytelling, a paradise lost of communication:
Where now?
Who now?
When now?
Unquestioning.
I, say I. Unbelieving.
Questions, hypotheses, call them that.
Keep going, going on, call that going, call that on.
Can it be that one day, off it goes on, that one day I simply stayed in, in where, instead of going out, in the old way, out to spend day and night as far away as possible, it wasn't far.
Perhaps that is how it began.
[The Unnamable ]
To recapitulate: the novel tells a story, which has some kind of generalisable thematic significance, by means of a tissue of interwoven discourses.
There is the discourse of the narrator, who may be a character or an authorial persona, who, if the latter, may be covert or overt; and there are the discourses of the represented characters, as manifested in their direct speech, or what we usually call ‘dialogue’, and as manifested in the representation of their thoughts through soliloquy, reported speech, free indirect style, interior monologue and so on.
But all these discourses will also contain echoes of, allusions to, anticipations of, other discourses both spoken and written — the discourses of popular wisdom, literary tradition, cultural institutions, social classes, and so on.
It is this multivocal quality that distinguishes prose fiction from poetry, as Mikhail Bakhtin, the great Russian theorist whose work has only recently become well-known in the West, observed:
The possibility of employing on the plane of a single work discourses of various types, with all their expressive capacities intact, without reducing them to a single common denominator — this is one of the fundamental characteristics of prose.
Herein lies the profound distinction between prose style and poetic style…
For the prose artist the world is full of other people's words, among which he must orient himself, and whose speech characteristics he must be able to perceive with a very keen ear.
He must introduce them into the plane of his own discourse, but in such a way that this plane is not destroyed.
He works with a very rich palette.
But this richness and complexity of discursive texture in the novel, what Bakhtin called the novel's ‘polyphony’, offers a certain resistance to the idea of the novel as communication.
The basic model of communication is a linear sequence:
The addresser encodes a message in language and sends it to the addressee via speech or writing and the addressee decodes it.
But who is the addresser in prose fiction?
The French critic Roland Barthes quotes a passage from Balzac's story ‘Sarrasine’, in which a young sculptor falls in love with a castrato disguised as a woman.
The words of the text are as follows: ‘This was woman herself, with her sudden fears, her irrational whims, her instinctive worries, her impetuous boldness, her fussings and her delicious sensibility .’
Barthes asks:
Who is speaking thus?
Is it the hero of the story bent on remaining ignorant of the castrato hidden beneath the woman?
Is it Balzac the individual, furnished by his personal experience with a philosophy of Woman?
Is it Balzac the author professing ‘literary’ ideas on femininity?
Is it universal wisdom?
Romantic psychology?
We shall never know, for the good reason that writing is the destruction of every voice, of every point of origin.
Writing is that neutral, composite, oblique space where our subject slips away, the negative where all identity is lost, starting with the very identity of the body writing.
['The death of the author']
It is time to consider, very briefly, the assault mounted by post-structuralist literary theory on the idea of literature as communication — indeed on the idea of communication itself.
The trouble with the model of communication in which the addresser encodes a message and sends it to the addressee, who decodes it, is, as another post-structuralist theorist has pointed out, that ‘every decoding is another encoding’.
Perhaps I may be permitted to quote from Morris Zapp's lecture on ‘Textuality as striptease’ in my novel,Small World :
If you say something to me I check that I have understood your message by saying it back to you in my own words, for if I repeat your own words exactly you will doubt whether I have really understood you.
But if I use my words it follows that I have changed your meaning, however slightly…
Conversation is like playing tennis with a ball made of Krazy Putty, that keeps coming back over the net in a different shape.
Reading of course is different from conversation.
It is more passive in the sense that we can't interact with a text, we can't affect the development of the text by our own words, since the text's words are already given.
That is what perhaps encourages the quest for interpretation.
If the words are fixed once and for all, on the page, may not their meaning be fixed also?
Not so, because the same axiom, every decoding is another encoding, applies to literary criticism even more stringently than it does to ordinary spoken discourse.
In ordinary spoken discourse the endless cycle of encoding-decoding-encoding may be terminated by an action, as when for instance I say, ‘The door is open’ and you say, ‘Do you mean you would like me to shut it?’and I say, ‘If you don't mind’, and you shut the door, we may be satisfied that at a certain level my meaning has been understood.
But if the literary text says, ‘The door was open’ I cannot ask the text what it means by saying that the door was open, I can only speculate about the significance of that door — opened by what agency, leading to what discovery, mystery, goal?
In other words, the fact that the author is absent when his message is received, unavailable for interrogation, lays the message, or text, open to multiple, indeed infinite interpretation.
And this in turn undermines the concept of literary texts as communications.
If Jane Austen's Emma , for instance, is a communication, what is its message?
Hundreds of articles and chapters of books have been published, purporting to explain what that novel ‘means’, what it is ‘about’, and we can be sure that hundreds more will be published in the future.
They all differ to a greater or less extent from each other in their conclusions and emphases; indeed if they did not differ there would be no need for more than one to be published.
Does this mean that the message hasn't got across, that Jane Austen has somehow failed to communicate?
This is the perennial paradox in which literary criticism finds itself implicated: that, as Michel Foucault observed:
the commentary must say for the first time what had, nonetheless, already been said [by the original text]and must tirelessly repeat what had never been said [by other commentators].
Commentary…allows us to say something other than the text itself, but on condition that it is the text itself which is said, and in a sense completed.
['The order of discourse']
The fact that we cannot identify the author of a text simply and straightforwardly with any of the discourses which make it up, especially in the polyphonic novel-text, and the fact that literary texts resist interpretive closure, has led some modern critics to deny that literature is communication.
Rather they see it as production — the production of meaning by the text itself when activated by the reader.
Roland Barthes again:
The text is a productivity.
This does not mean that it is the product of labour (such as could be required by a technique of narration and the mastery of style) but the very theatre of a production where the producer and reader of the text meet: the text ‘works’, at each moment and from whatever side one takes it.
Even when written (fixed) it does not stop working, maintaining a process of production.
The text works what?
Language.
It deconstructs the language of communication, representation, or expression (when the individual or collective subject may have the illusion that he is imitating something or expressing himself) and reconstructs another language, voluminous, having neither bottom nor surface…
This is a forceful attack on not only the idea of literature as communication but also on the idea of communication itself.
Note that communication is described as an ‘illusion’ which literary language ‘deconstructs’.
Barthes is here influenced, no doubt, by the founder of deconstruction, Jacques Derrida, who argued that contrary to the traditional view that speech is the exemplary case of language in use, and writing an artificial substitute for speech, writing ought to be privileged because it exposes the fallacious metaphysics of presence, of the autonomy of the subject, which speech encourages.
Deconstruction marginalises the author, or seeks to do away with the author altogether, replacing him or her with what Foucault called the ‘author-fiction’, that is, a culturally and historically determined role over which the individual writer has no control.
As we see from the passage I just quoted from Barthes, the work or labour that the writer puts into composing his text is brushed aside as of no importance.
Rather it is the text that ‘works’, and the text is not something that the author creates and hands over to the reader, but that the reader produces in the act of reading it — and by writing his own text about it.
For the production-model of the literary text is a very academic one.
It has its origin in the academic institution's need to justify the endless multiplication of commentaries, from undergraduate essays to doctoral dissertations and scholarly articles.
It offers an escape from the double bind of commentary pithily summarised by Foucault, in the passage I quoted just now.
In this perspective there is no essential distinction between primary  and secondary texts, between so-called creative and critical writing.
Most writers and readers of fiction outside the academy, it must be said, still subscribe to the communication model of the literary text.
That is, they regard a novel as the creation of a particular human being, who has a particular vision of the world, which he tries to communicate to his or her readers by employing the codes of narrative and language in a particular way, and is responsible for the novel's success or failure in this regard, and deserves praise or blame accordingly.
That is the basis on which most novels, including my own, are actually written, published and received in our culture.
As a practising novelist, my instinctive reaction is to repudiate the deconstructionist position.
Barthes says the text is not ‘the product of a labour (such as could be required by a technique of narrative or a mastery of style)’.
I know empirically that a novel is the product of such labour.
(So, I believe, were Barthes's own books, if we substitute ‘argument’ for ‘narrative’in his formulation.)
But is it a labour of communication?
A major difficulty, here, is that the idea of communication is tied up with the idea of intention, and intention is a very tricky concept in literary criticism.
It is fairly easy to demonstrate that the meaning of a text cannot be constrained by reference to a writer's intentions.
Let me give a trivial but I hope interesting example from my own experience.
In Small World the middle-aged English academic Philip Swallow has a wife called Hilary and has a passionate affair with a younger woman called Joy, who reminds him of his wife when she was younger and prettier — when he first meets her, Joy is even wearing a dressing gown like one Hilary used to wear.
Reviewing the novel in the London Times , A. S. Byatt noted approvingly that this theme of identity and difference was neatly encapsulated in the names of the two women, Hilary being derived from the Latin hilaritas , or Joy.
Now I can be quite sure I had not intended this pleasing symmetry.
I called Philip's wife Hilary in a previous novel,Changing Places , because it is an androgynous name and at that stage of their marriage she was the dominant partner in the marriage, or, as the saying is, wore the trousers.
I called Joy, Joy because when Philip falls in love with her he is in pursuit of what he calls ‘intensity of experience’, an essentially Romantic quest with a capital R, and joy is a key word in Romanticism.
At the moment of consummation, Philip shouts aloud the word ‘Joy’, which is both exclamation and apostrophe.
I had no conscious awareness of the Latin root of the name Hilary until Antonia Byatt pointed it out to me.
Nonetheless the play on words is there in the text, and is appropriate.
It seems a good case of what Barthes calls the text working.
Another difficulty with the idea of the novel as an intentional act of communication  is that until the writer has completed it he doesn't know what it is that he is communicating, and perhaps doesn't know even then.
You discover what it is you have to say in the process of saying it.
However carefully and thoroughly you prepare the ground, you cannot possibly hold the whole complex totality of a novel in your head in all its detail at any one moment.
You work your way through it word by word, sentence by sentence, paragraph by paragraph, trying to hold in your head some idea of the totality to which these bits are contributing.
What you have written already and what you plan to write in the future are always open to revision, though such possible revisions will be constrained by their mutual effect on each other.
The future of a novel in the process of composition is always vague, provisional, unpredictable — if it were not so, the labour of writing it would be too tedious to bear.
When you have finished the novel it is not that you have really finished it, but that you have decided to do no more work on it.
If you sat down and made another fair copy of the manuscript, you would infallibly find yourself making new adjustments and emendations to it.
And when the novel is published and goes out of your control to modify it, it also goes out of your control to intend the meaning of it.
It is read by different readers in a bewildering variety of ways, as reviews and readers' letters attest.
Can this be described as a process of communication?
I think it can, as long as we realise the inadequacy of the simple linguistic model of communication (addresser-message-addressee) not only to literary discourse, but to any discourse.
The model only works at the level of the textbook example, the single isolated sentence.
But there are no isolated sentences in reality.
Here we must reintroduce Bahktin.
Language, according to Bakhtin, is essentially dialogic.
Everything we say or write is connected both with things which have been said or written in the past, and with things which may be said or written in response to it in the future.
The words we use come to us already imprinted with the meanings, intentions and accents of others, our speech is a tissue of citations and echoes and allusions; and every utterance we make is directed towards some real or hypothetical Other who will receive it.
‘The word in living conversation’, says Bakhtin, ‘is directly, blatantly directed towards a future answer word.
It provokes an answer, anticipates it and structures itself in the answer's direction.’
The same is true of literary discourse, in a more complicated way.
To write a novel is to manipulate several different codes at once— not simply the linguistic codes of grammar and texts, denotation and connotation, but the narrative codes of suspense, enigma, irony, comedy and causality, to name but  a few.
To write a novel is to conduct imaginary personages through imaginary space and time in a way that will be simultaneously interesting, perhaps amusing, surprising yet convincing, representative or significant in a more than merely personal, private sense.
You cannot do this without projecting the effect of what you write upon an imagined reader.
In other words, although you cannot absolutely know or control the meanings that your novel communicates to its readers, you cannot not know that you are involved in an activity of communication, otherwise you will have no criteria of relevance, logic, cohesion, success and failure, in the composition of your fictional discourse.
The generation of meaning unintended by the author, in the reading process, is dependent on a structure of intended meaning: the Hilary-Joy equivalence in Small World , for instance, is brought into play partly by the percipience of A. S. Byatt and partly by the fact that that novel is by intention full of doubles and pairs and symmetries and heavily connotative names.
Perhaps I may conclude by repeating what I have written elsewhere:
As I write, I make the same demands upon my own text as I do, in my critical capacity, on the texts of other writers.
Every part of a novel, every incident, character, word even, must make an identifiable contribution to the whole…
On the other hand (there is always another hand in these matters) I would not claim that, because I could explicate my own novel line by line, that is all it could mean, and I am well aware of the danger of inhibiting the interpretive freedom of the reader by a premature display of my own, as it were, ‘authorised’ interpretation.
A novel is in one sense a game, a game that requires at least two players, a reader as well as a writer.
The writer who seeks to control or dictate the responses of his reader outside the boundaries of the text itself, is comparable to a card-player who gets up periodically from his place, goes round the table to look at his opponent's hand, and advises him what cards to lay.
(‘Small World: an Introduction; in Write On 1985).
It might be profitable to pursue this idea further: the novel not as communication, not as production, but as play.
But that would be another lecture.
Communication without words
JONATHAN MILLER
Wittgenstein once asked what was left over after one subtracted from the sentence ‘I raise my arm’ the sentence ‘My arm goes up’.
A comparable question about communication might go something like this.
‘If I were to set aside all those communications which are expressed or expressible in words written, spoken or signed — what would be left over?’
For anyone who regards language as the canonical form of human communication, the answer would probably be ‘Not much is left over’ and the residue, such as it is, is either a redundant supplement to words — something which the telephone shows we can do without — or else a sadly impoverished alternative which we are sometimes compelled to use when circumstances make the ordinary use of words awkward or impossible.
On the other hand, for those who regard language with suspicion, especially written or printed language, on the grounds that it misleads and confuses as much as it informs and expresses, eliminating words and sentences exposes a level of communication of unsuspected richness, one in which human beings express their true meanings.
The idea is that articulate language is a barrier to rather than a medium of communication and that if only this barrier could be removed, human beings would revert to a golden age of wordless, heartfelt communication.
This attitude to non-verbal communication has been encouraged by the popularisation of right-brain left-brain studies and amongst those who sponsor the soft primitivism that I have just referred to it is widely assumed that the verbal capabilities of the left cerebral hemisphere have been over-developed by a culture which puts too much emphasis on linguistic finesse and that the expressive repertoire of  the supposedly holistic right hemisphere has been dangerously neglected as a consequence.
In fact there are those who go even further, insisting that favouring the verbal capacities of the left hemisphere not only conceals but actually deforms and disables right-sided accomplishments.
The most widely publicised example of this claim is to be found in Betty Edwards's best-selling Drawing on the Right Side of the Brain .
In this astoundingly popular and not altogether unpersuasive book, Miss Edwards sponsors a pedagogical programme designed to diminish the influence of linguistically determined ways of seeing the world.
Her argument is that by learning to overlook those parts of the world which are easily nameable we can revert to a mode of perception more favourable to successful drawing.
Here is one of her recommendations.
The left hemisphere is not well equipped to deal with empty spaces.
It can't name them, recognise them, match them with stored categories, or produce ready made symbols for them.
In fact the left brain seems to be bored with spaces.
They are therefore passed over to the right hemisphere.
To the right brain, spaces and objects, the known and the unknown, the nameable and the unnameable are all the same.
It's all interesting.
And so on.
There are some other interesting strategies recommended in the book and as someone who has always been frustrated by his inability to draw nicely I am bound to admit that the exercises suggested by Miss Edwards have brought about an unexpected improvement in my performance as a draughtsman.
Now whether this has anything to do with a conflict between right and left halves of the brain is not really the issue here.
In any case I don't intend to discuss the visual arts as an example of non-verbal communication and I only introduce the topic of drawing to illustrate the extent to which antagonism to language has infiltrated itself into at least one important department of educational theory.
There are other examples though.
Although the advertising industry is almost promiscuous in its use of verbal slogans, the creative emphasis falls more and more upon the persuasive power of imagery — slow motion shots demonstrating the lustrous lightness of newly washed hair, or the soft resilience of freshly laundered towels — in fact it would be tiresome to list the repertoire of non-verbal devices deliberately designed to by-pass a critical vigilance based upon language.
A comparable tendency is to be found in the theatre.
Inaugurated in the 1960s with the rediscovery of Artaud's manifestos in favour of the so-called Theatre of Cruelty, drama in the last quarter of the twentieth century displays  a noticeable interest in bizarre expressionistic decor, extended pantomimic gestures and sometimes a cacophony of non-verbal sounds.
In the increasingly popular idiom of so-called ‘performance arts’ actors and audiences revel in non-verbal excesses in the belief that such behaviour addresses itself directly to the human soul and that all other forms of traditional theatre are disgustingly ‘literary’.
This repudiation of language is often associated with the more romantic forms of political radicalism, the idea being that language is one of several devices by which the ruling elite manipulates cognitive structures to its own advantage, and that it is only by storming the Bastille of linguistic tradition that human beings have any hope of being restored to a state of primaeval egalitarian fellowship.
This attitude is one of the things that has given non-verbal communication such a bad name and since it already has a somewhat shaky reputation due to the fact that it has no powerful theory associated with it, its academic credibility suffers in comparison to that of formal linguistics.
In fact even if one succeeds in dissociating oneself from some of the more romantic claims that are made on its behalf it's easy to get the discouraging impression that communication without words is after all a residual topic and that once orthodox language has been subtracted all that is left is a rubbish heap of nudges, shrugs, pouts, sighs, winks and glances — or to put it another way that non-verbal communication is simply the behavioural exhaust thrown out of the rear end of an extremely high-tech linguistic machine.
And yet…is it all that easy to subtract language in the first place?
Can one really strip away the lexical component leaving behind a non-verbal residue which has nothing to do with communication in words?
The fact that one can commit words to paper without any apparent loss of intelligibility suggests that there is, in fact, a clean division between the lexical and the non-verbal component of human communication, and that the so-called kinesic variables such as facial expression, posture, and hand movements are just optional extras.
But this conclusion overlooks the fundamental distinction between the meaning of an utterance and the meaning which the utterer wishes to convey by means of that utterance.
Because although it could be argued that what an utterance means is readily recoverable by anyone who can read printed English, it is important to understand that what the speaker wishes to express is more often than not defined by the factors which get lost in the process of transcription.
The problem is that writing was not developed in the first place to preserve the meanings of talk or conversation.
It was developed originally to promulgate priestly or legislative initiatives, and since these were collective and in some sense impersonal productions, what the writer meant was to all intents and purposes recoverable from what he wrote down.
If there was any ambiguity, that is to say implications which might escape the first or indeed many subsequent readings, they were not the ones which would have made themselves more readily apparent if some form of graphic representation had preserved the tone of voice, the facial expressions or the hand movements of their author.
So that there was no incentive to develop a notation designed to represent the non-lexical parts of an utterance.
In fact, the notational shortcomings of writing only became apparent when authors tried to reproduce the talk of individuals.
Then, and perhaps only then, the difficulty of identifying speech acts becomes apparent.
The notion of speech acts was introduced by the Oxford philosopher J. L. Austin, who pointed out that in uttering this or that well-formed sentence a speaker is doing something over and above expressing its literal meaning.
He or she may be stating, describing, warning, commanding, apologising, requesting or beseeching.
In fact, according to Austin there are more than a thousand of these acts which are performable in English, and unless the hearer or reader recognises which of these is being expressed by the utterances in question he or she has missed the point.
Of course, the identity of a speech act, its illocutionary force as Austin calls it, is often made apparent by an explicit lexical indicator.
‘I warn you that I will take steps to prevent you’ or ‘I promise that I will be there on time’.
And in such cases the non-lexical cues — finger waggings, handshakes and so forth— are indeed superfluous, and the printed text preserves everything that the utterer intended to convey.
But for each of the thousand or so explicitly identifiable speech acts there are just as many for which there is neither a name nor a lexical indicator.
And in that case the only way of identifying them with any accuracy is to hear them spoken and to witness the non-verbal behaviour with which they are preceded, accompanied or followed.
A playwright will often do his best to supply this non-lexical information by telling the reader that the character shrugs, winks, or looks heavenwards as this or that phrase is uttered.
A novelist can be even more helpful by saying that the phrase in question was spoken waggishly, or grimly, or that it was snapped out as the character turned angrily on his heel.
However, the grain of this behavioural notation is unbelievably coarse and one is often surprised by the extent to which two performances of the same written utterance can differ — even when the actors in question are  apparently following the same instruction with respect to intonation, facial expression or manual gesture.
The result is that instead of trying to recover the often indeterminable illocutionary force intended by the author for this or that character, the actor finds himself inventing someone who might have wished to express this or that speech act by means of the speeches assigned to him in the text.
In which case the non-verbal concomitants of the various utterances are improvised as if for the first time, and in the best of all possible productions an unforeseeable Lear, Macbeth or Rosalind emerges in performance, and the speeches come across expressing meanings which would have been hard to foresee from reading the bare text.
The point I am labouring at such length is that there is a large and complicated repertoire of non-verbal behaviour without which it is impossible to communicate meanings through the medium of spoken words and although it is tempting to regard this non-lexical repertoire as something which can be painlessly removed without any significant loss of meaning, the experience of reconstructing talk from a medium in which the representation of this aspect of speech is so poor is a salutary reminder of its importance.
Up to this point I have concentrated on the way in which non-verbal behaviour helps us, as Austin would say, ‘to do things with words’.
I would now like to turn my attention to something which is in a sense a mirror image of what we have been considering.
How can we ‘say things with deeds’?
There is, of course, a sense in which all our actions or deeds speak louder than words, and that everything we do — or fail to do, for that matter — is open to interpretation and therefore counts as a communication.
In fact, it doesn't have to be anything properly identifiable as a deed to communicate interpretable evidence.
A blush, a hangdog posture or a limp handshape can all convey information and experts in so-called body language — horrid phrase — have compiled long lists of postures and gestures from which an observant onlooker can glean some information about the attitudes or intentions of others.
Mere ‘presence’ can speak volumes.
Someone who turns up at an occasion which is known to be an ordeal for him communicates information whether he wishes to or not.
His unexpected presence may be interpreted, rightly or wrongly, as a deed deliberately intended to express his courage or defiance.
A well-known alcoholic who unexpectedly turns up at a cocktail party may inadvertently communicate the fact that his sessions with AA have given him newfound confidence in his self-control.
But his turning up at such an occasion may be an explicit act of communication — a way of saying without words that he can now resist the blandishments of the bar and that his  friends and colleagues are to regard him as a reformed character.
It is important to distinguish, as far as one can, between behaviour which wordlessly betrays information, behaviour, that is, from which an onlooker may glean something, and non-verbal behaviour which is performed with the express purpose of communicating this or that information.
Here is another example.
Someone who manages to read in a noisy, crowded room may inadvertently communicate evidence as to his enviable powers of concentration.
But since the act of reading monopolises his attention, he is by definition ‘dead to the world’ and therefore unaware of that fact which his behaviour communicates.
In contrast I have chosen the following passage from Barnaby Rudge :
‘How do you find yourself now, my dear wife?’ said the locksmith, taking a chair near his wife (who had resumed her book), and rubbing his knees hard as he made the inquiry.
‘You're very anxious to know, an't you?’ returned Mrs Varden, with her eyes on the print.
‘You, that have not been near me all day, and wouldn't have been if I was dying!’
‘My dear Martha —’’ said Gabriel.
Mrs Varden turned over to the next page; then went back again to the bottom line over leaf to be quite sure of the last words; and then went on reading with an appearance of the deepest interest and study.
‘My dear Martha,’ said the locksmith, ‘how can you say such things, when you know you don't mean them?
If you were dying!
Why, if there was anything serious the matter with you, Martha, shouldn't I be in constant attendance upon you?’
‘Yes!’’ cried Mrs Varden, bursting into tears, ‘yes, you would.
I don't doubt it Varden.
Certainly you would.
That's as much as to tell me that you would be hovering round me like a vulture, waiting till the breath was out of my body, that you might go and marry someone else.’
Unlike a person whose actual reading betrays his powers of concentration, Mrs Varden's pretended reading prevents her from actually reading, because in order to monitor and enjoy its communicative effect it would be impossible for Mrs Varden to accomplish the deed of reading in earnest.
But not all pretended deeds have to fall short of their normal function in order to accomplish their communicative purpose.
Take the example of the burglar in Austin's famous essay on pretending — surely a classic example of saying something with deeds as opposed to doing something with words.
A burglar is inspecting a window with a view to breaking and entering, but in order to make his interest look innocent he pretends to be cleaning the windows.
As it happens, the most convincing way of pretending to clean a window is to actually do so.
The most observant reporter of saying things by means of deeds was the late Erving Goffmann, and it is to his work that I would like to dedicate the rest of this lecture.
I do so as a grateful tribute to someone who has liberated the study of non-verbal communication from the dead hand of ethological reductionism.
A central feature of Goffmann's approach to non-verbal behaviour is his assumption that it is to be visualised against the background of institutional norms which create the salient facts of social life.
Without an appreciation of these norms it is almost impossible to make sense, let alone describe, much of the conduct which characterises our mutual involvements.
According to Goffmann, what lends credibility to our concepts of personal self is the recognition of certain rules or conventions which limit the claims we can expect to be acknowledged with respect to freedom from untoward threat, interference and so forth.
We venture into public life protected not so much by the sanctions of formal law but by an unwritten charter of civil rights which assigns us both access to and independence from others with whom we come into contact.
Those who lay claim to these rights and expect to have violations recognised and remedied, know that they undertake reciprocal obligations and will be expected to provide appropriate remedies if they are guilty of infraction, even if innocently.
In our transit across public places we rely on others recognising the rules which assign us the right to proceed without being inconvenienced by impudent stares or unsolicited conversational openings.
On the other hand we also proceed on the assumption that we have some measure of personal access to others if the occasion unexpectedly requires it and vice versa.
And that if such openings ensue that there are supportive rituals which allow us to engage in them without offence and terminate them without insult.
In return for such a privilege we implicitly acknowledge that there are reciprocal obligations incumbent upon us.
What this means is that the individual in public feels obliged to broadcast an unceasing stream of non-verbal signs, intended to inform others, whether they be acquaintances or more often otherwise, of the place which he or she expects to have in the undertakings which follow.
By means of such conduct, we inform one another about the legitimacy of our presence, the innocence of our motives and our readiness to grant access or co-operation if the situation arises.
And at times or places where our actions are likely to be misinterpreted the intensity of this indicative behaviour increases.
As Goffmann points out these signs have been neglected or disparaged as  trivial items.
Or even worse they may be misdescribed as vestigial bequests from our primate ancestry — yet another example of the naive reductionism which sometimes passes as orthodox science.
Where Goffmann scores is by allocating scientific importance to the moral representation of self in everyday life.
Consider for a moment the question of legitimate presence.
In places, where anything short of purposeful warning might be misinterpreted as either suspicious loitering or aberrant vacancy, the normal person feels obliged to put on a show, which tells anyone who might be watching that orderly motives are in hand.
He or she will glance ostentatiously at his watch, as if to indicate that an expected arrival is late for an appointment and if he happens to meet the glance of a passer-by, he will more often than not look once again at his watch and cast a long-suffering glance at heaven; as if by recruiting sympathy for a familiar predicament he will pre-empt any suspicion of more suspect motives.
Such behaviour will perhaps be even more pronounced if the innocent loiterer happens to have stationed himself at places where his presence might be misinterpreted.
Washrooms and lavatories are classical locations for such conduct.
In Men's rooms, which are the only ones from which I can report personal experiences, there are elaborate rituals for avoiding the impression of suspect motives.
A concentrated stare at the white tile immediately ahead of one usually takes place when someone unknown unexpectedly occupies the stall alongside — sometimes accompanied by the onset of a tuneless and preoccupied whistle — anything to avoid creating the impression that one might be showing an untoward interest in the UG equipment of one's neighbour.
Of course such behaviour won't wash, and I use the word advisedly, if the neighbour happens to be a colleague.
For in that case, the elaborate precautions to avoid eye contact could be read as a suspicion of his motives and thereby create a second order of virtual offence.
For obvious reasons, the situation is less fraught with the risk, in the purposeful va and vient of open corridors.
Nevertheless even here an unremitting etiquette prevails.
It is an etiquette in which the participants tacitly assume that there are reciprocal obligations with respect to right of way, freedom from inquisitive glances and capricious encroachments upon privacy.
At the same the management of eye movements leaves room for the possibility of accesses which can and often do develop into what Goffmann describes as focussed encounters; episodes which are themselves introduced and terminated by rituals of greeting and farewell.
Such episodes may, of course, be confused as passing acknowledgements, but the readiness  to exchange such signals is one of the ways in which we register the normality of the passing scene and it is when we encounter consistent anomalies in the broadcast that we begin to suspect and perhaps report something odd.
In institutions such as hospitals or the BBC, where colleagues and acquaintances run the risk of passing one another many times in the same morning, the ritual resources for handling brief encounters are often over-stretched.
First and second encounters can be managed by conventional openness — a third meeting may necessitate a humorously resigned grin — a fourth can be handled by pretending to be wrapped in thought — a fifth may require some dramatised horseplay such as play-acting a Western duel.
And you've all seen and probably participated in the scene where a sequence of such meeting is brought to its climax by one partner coming right out with the movie cliché ‘We can't go on meeting like this’ or less effectively ‘Long time no see!’
All this, as Goffmann points out, presupposes three levels of normal functioning:
(a) The recognition of the fact that an individual is a potential source of alarm, inconvcnience, offence and encroachment.
(b) Recognition of the fact that each individual has both the obligation to minimise these aspects of himself AND the capacity to do so.
(c) Recognition of the need to perform remedial work if one recognisably infringes any of the norms which one intuitively regards as binding.
The point is that almost any configuration of events with which an individual is likely to be associated in public carries the risk of a worst possible meaning which might reflect unfavourably upon him, and it is a sign of intact mental functioning that one recognises this risk, without of course being incapacitated by the thought, and at the same time that one is equipped to perform repair work if and when infractions occur.
It is, I think, in the analysis of this so-called remedial work that Goffmann is at his most imaginative and productive.
One of the things that makes his account so useful — so much more than the anecdotal triviality of which he is so carelessly accused — is his ability to compare and contrast this informal repair work with the formal structures of explicit legal process.
As in law there is an orderly sequence of offence, arrest, remedy and reconciliation.
But what distinguishes these interchanges is the fact that the offender is so often the first to recognise that an infraction has occurred and usually initiates the appropriate repair work without being asked to do so.
An even more important distinction is the fact that the remedial work is  expressive rather than productive.
In other words the remedial performance is designed to restore a favourable image of the offender as opposed to offering substantial compensation to the offended.
Taking his cue from yet another of Austin's philosophical essays, the famous and often reprinted ‘A plea for excuses’, Goffmann distinguishes various forms of remedial ritual, of which the first is the so-called account .
In this, the offender re-describes his or her act so that its offensiveness may be overlooked or discounted.
It may take the form of an explicit explanation.
Someone, for example, who finds himself in the embarrassing situation of seeming to have winked at an unknown passer-by may offer the account that he has some grit in his eye — this often accompanied by a flurry of overacted eyelid-rubbing and nose-blowing.
In this way he re-establishes his image as an altogether innocent victim.
Of course, one has to be careful in this context to recognise that many of the infractions I'm referring to are not necessarily offences AGAINST others — but represent errors of performance, imperfections which reflect badly on the offender — so that one undertakes remedial work, NOT for the purpose of making amends but to re-draw the picture of oneself so that it corresponds more closely to the one which one would like to project to the world at large .
So important is this consideration, and it would be perfunctory to regard it as mere vanity, that it may motivate performances to anonymous and usually unconcerned strangers.
You only have to think of the otherwise incomprehensible behaviour of someone who hails a cab with a flailing gesture of the outstretched arm and who, having failed, then feels it necessary to provide an account of what happened by using the same hand to smooth down the hair.
Or in Goffmann's own example of the man who trips in the street, to his own and no one else's inconvenience, who then feels it necessary to retrace his steps and conscientiously examine the sidewalk — as if to establish the impression that the fault lies in the pavement and not, as might otherwise be suspected, in the nervous system of the person concerned.
The point is, that whether it's addressed personally, or all round to anyone who might be watching, whether it's verbal or mimetic, the function of an account is to correct a potentially unfavourable impression of oneself which an infraction of the unwritten rules might produce.
And the same principle applies to apology , although as Austin pointed out in his essay, the logic of apology is not the same as that of accounts.
In making an apology one accepts blame for what has happened, but at the same time one tries to convince the injured party if there happens to be one, or the world at large if not, that the error is not to be taken as representative of the real self.
Apology, in other words, is aimed at convincing anyone interested that the miscreant recognises his fault, and by that token alone, is to be regarded as someone whose typical tendency is to observe the conventions.
Such a performance may be verbal or non-verbal.
In circumstances when words are inappropriate or impractical, the apology may take the form of an elaborate pantomime of contrition.
On entering a small seminar room, where a meeting is already underway, the show may take the following complex form.
A self-uglifying expression of humility — plus an elaborate show of stealthiness which is as good as saying ‘Yes, I am late — and please pay attention to my performance of humbly not wishing to be paid attention to’, i.e. Here's me entering as unostentatiously as I know how — so you can see how much I regret my rudeness!’
A comparable version of this is the face made by someone who barges into a room unannounced expeeting to speak to a friend, only to find that this friend is engaged in an intimate professional consultation with another colleague.
Although a verbal apology would probably fit the bill, the offender may feel constrained to act the fool he expects to be accused of being.
Hence an otherwise unintelligible grimace.
Or the actor who stumbles over his words for the second time at a rehearsal.
He will often apologise by overplaying the spastic idiot everyone around must suspect him of being.
There are also, I think, concealed apologies included in the otherwise straightforward rituals of farewell.
As Goffmann points out, the end of conversational encounters carry an increased risk of creating offence — in the sense that careless or perfunctory termination may convey the misleading impression that one couldn't wait for the session to end and that as far as one was concerned the whole episode was a waste of time.
On occasions where this is felt to be a risk, preventive apologies may be issued in the form of prolonged negotiations to meet again soon.
Or anything to avoid the potentially offensive gesture of actually leaving !
This of course raises the question of the apologies and/or accounts which accompany failed farewells.
The situation I'm thinking of is this.
One's been talking with a small group of colleagues.
Because of an appointment or whatever one has to leave before the group as a whole breaks up.
Having successfully manoeuvred an inoffensive farewell, one discovers that one has left a book in the room.
Now try and visualise the risks of re-entry.
First, the offence to onself.
This is usually surmounted by merely explaining ‘Left my book’.
But since one may suspect that one'll be thought a fool for having done so, it may be necessary to overact being a fool and murmur ‘Forget my own head next’.
Perhaps this show is reinforced by miming a stumble or a mindless  struggle with the door on leaving yet again.
But the situation is complicated by the knowledge that in one's all too brief absence the space left by one's departure is already in process of closing over — new topics are in hand and one might create offence to the members of the reconstituted group by seeming to re-insert oneself.
Once again the tip-toe manoeuvre — but this time it's not quite an apology so much as an unsuccessful account.
An account which tries to convey the impression that you're not there at all.
And so forth.
Now…in my enthusiasm for  the anecdotal aspect of all this I have neglected to mention the other half of Goffmann's analysis of remedial procedure.
I am referring of course to the process of closure — that is to say the ritualised responses, whereby the injured party acknowledges and accepts the accounts or apologies, thus allowing social activity to resume its productive course.
If this so-called round is left incomplete the offender, virtual or actual, is left hanging in the air, uncertain as to his moral status in the undertakings that will follow.
These replies may seem too trivial to mention — a nod, a murmur, ‘that's OK’ or whatever, but if these signs are not provided the offender is left with the uneasy sense that his or her offence, trivial or not, is permanently entered in the criminal record.
It is, I think, one of Erving Goffmann's most lasting achievements to have made these interchanges both visible and intelligible.
And what makes his analysis so attractive is the fact that he has resolutely turned his back on the temptations to reduce what he has seen to some supposedly more fundamental principle of animal behaviour.
As far as he was concerned, what we are witnessing in these exchanges is the expression of the distinctly moral part of human nature.
In his own words,
If we examine what it is one participant is ready to see that other participants might read into a situation and what it is that will cause him to provide ritual remedies, followed by relief for these efforts, we find ourselves looking at the central moral traditions of Western culture.