

Hemispheric asymmetry in normal subjects
methods, findings and issues
The previous chapters discussed hemispheric asymmetry as revealed by brain bisection and the study of patients with unilateral cerebral lesions.
However, the split-brain findings may not apply to normal subjects, and attempts to compare the relative effects of damage to left and right sides of the brain are notoriously fraught with problems.
Chief among these is that of ensuring that left and right hemisphere damaged groups are appropriately matched in extent and type of pathology as well as in locus of lesion.
As the effects of right sided damage are likely to be less immediately troublesome than comparable damage on the left, which frequently causes some degree of aphasia, naturally occurring left hemisphere lesions may well lead the patient to seek medical advice earlier in the disease process than would equal damage at the right side of the brain.
This possibility might easily introduce a bias into the composition of left and right brain damaged groups.
In the absence of post-mortem verification of the site and size of the cerebral lesion it is difficult, on purely clinical and radiological grounds, to be certain that the two groups are evenly matched in extent or severity of damage.
With the advent of computerised axial tomography (CAT scan) this is likely to be less of a problem in the future, but in the past researchers have had to be content with less sophisticated methods.
One group of Italian workers attempted to deal with the problem of ensuring equivalent left and right hemisphere damage in their two groups of patients by assessing simple reaction time to a visually presented stimulus.
Reaction time has been found to be extended in cases of brain damage (Costa, 1962) and it may reasonably be thought that latency to respond is related to the degree of damage.
By entering reaction time data in an analysis of covariance, a statistical technique which enables the influence of one or more extraneous variables to be taken into account when assessing the effect of the principle variable of interest, De Renzi and  his colleagues (Arrigoni and De Renzi, 1964; De Renzi and  Faglioni , 1965) hoped to control for possible differences in extent of damage between left and right hemisphere groups.
A problem with this manoeuvre, however, is that certain evidence implicates the right hemisphere in control of simple reaction time (Benson and Barton, 1970; Howes and Boller, 1975; Nakamura and Taniguchi, 1977) and thus equivalent response times for left and right hemisphere groups may not in fact reflect equivalent damage at the two sides of the brain.
A second problem which besets the researcher investigating the effects of unilateral cerebral lesions is the possibility that the same functions may be organised in different ways in left and right hemispheres (Semmes, 1968).
If this is so, identically placed lesions at the two sides will not necessarily have equivalent effects, even though each intact hemisphere may be equally as capable as its fellow of subserving a given function.
Furthermore, it is usually impossible to say whether the effects of a lesion in one hemisphere, in terms of loss or impairment of a particular function, follow from the destruction of the true neural locus of that function, or instead reflect the influence of abnormal tissue on other brain areas that actually subserve the function in question.
To localise a region of dysfunction, therefore, is not to localise a function, as pointed out by Hughlings Jackson in the nineteenth century.
A final difficulty is that there are almost always generalised, as opposed to specific, effects of localised cerebral lesions.
To be sure that the locus of a given lesion is responsible for loss or impairment of a particular capacity, it is helpful to invoke the principle of doubled dissociation proposed by Teuber (1955).
If lesion A affects function X but not function Y while lesion B affects function Y but not function N, it is reasonable to assume that the effects observed are specific to the loci of lesions A and B rather than to the general effects of brain damage.
Because of the sort of problems outlined above (for a more detailed discussion the reader is referred to Mayer (1960) and Piercy (1964) it is desirable that the results of studies carried out on patients with brain damage be confirmed, and if possible extended, among normal subjects.
Within the context of hemispheric asymmetry there are several means whereby this can be achieved, and each of these will be considered in turn.
No attempt is made here to provide a comprehensive survey of the literature; the intention rather is to introduce the basic experimental techniques and to summarise some of the principal findings and theoretical issues.
Reference will be made to fuller reviews at appropriate points in the text.
TACHISTOSCOPIC VISUAL HALF-FIELD STUDIES
Directing visual input to a single hemisphere of the brain by flashing a stimulus to one side of a central fixation point was explained in the previous  chapter.
This technique can be employed with normal subjects, as well as with commissurotomised patients, although the presence of intact mid-line commissures in normals means that visual information presumably does not remain lateralised to one hemisphere as it does in split-brain patients.
Ocular dominance
The term "ocular dominance" (or"eyedness') has been used to refer to a number of different phenomena (Money, 1972).
In the present context it has usually been used to mean acuity dominance, that is, superior acuity in one eye, or sighting dominance, the tendency to use one particular eye in preference to the other during monocular viewing.
The sighting dominant eye may be, but is not necessarily, the eye having the greater acuity.
Under conditions of binocular vision the two eyes do not contribute equally to providing a stable binocular percept.
When the image presented to each eye is not the same, a state of rivalry may exist which is resolved in favour of each eye alternately (see Walker, 1978).
The eye providing the more stable percept is then, by definition, the dominant eye.
On this definition, the dominant eye may or may not be the same as the eye chosen preferentially on a monocular sighting test.
The importance of ocular dominance within the tachistoscopic laterality paradigm is twofold.
Firstly, evidence suggests that there may be a superiority of the crossed compared with the uncrossed optic pathways (Sampson, 1969; Maddess, 1975; Osaka, 1978; Hubel and Wiesel, 1959).
If this is so, and if there is a sighting or acuity difference between a subject's left and right eyes, then either the left or the right nasal pathway may be favoured accordingly.
Hence there may be a bias in recognition towards either the right or left cerebral hemisphere respectively.
Kershner and Jeng (1972) found right eye sighting dominant subjects to be more accurate than left dominant subjects on a tachistoscopic verbal task, while the reverse was the case on a non-verbal task.
This suggests some interaction between hemispheric specialisation and a functional superiority of the crossed optic pathways (see also Polich, 1978).
It is worth mentioning, however, that it is not always the nasal pathways that have been observed to be superior (Neill, Sampson and Gribben, 1971) and that naso-temporal differences have sometimes been observed for one eye but not for the other (Overton and Weiner, 1966; Markowitz and Weitzman, 1969; Beaton, 1977; 1979a).
Whatever the direction of naso-temporal differences their mere existence dictates caution in the design and interpretation of tachistoscopic laterality experiments.
It is normally assumed that because each eye projects to both hemispheres any imbalance between the two eyes is adequately controlled.
Yet if a naso-temporal difference exists for one eye but not for the other, the set-up is not balanced with respect to left and right visual fields.
Practically speaking, this may not be important except at very brief exposure durations, but it is as well to be aware of the problem.
The second reason for the importance of ocular dominance with regard to visual laterality research lies in the possibility of a relationship between ocular dominance and cerebral lateralisation.
Since some forms of eyedness are apparently under genetic control (Merrell, 1957) this is not an unreasonable suggestion.
In fact, a relationship between visual laterality effects and eye dominance has been found in some studies (Hayashi and Bryden, 1967; Zurif and Bryden, 1969; Bryden, 1973).
Attempts have been made to determine whether there is a correlation between manual preference and eye dominance, but to date the results are conflicting.
Some authors have reported that right eye sighting dominance is more common than a dominant left eye among dextrals while the association between the side of the preferred eye and preferred hand is less predictable among sinistrals (Friedlander, 1971; Porac and Coren, 1975).
Other researchers have found no significant relationship between the dominant hand and eye (Gronwall and Sampson, 1971; Coren and Kaplan, 1973; Porac and Coren, 1976; 1979b).
It is possible that a failure to distinguish between the two sexes can explain the lack of agreement.
Gur and Gur (1977) found handedness and sighting dominance to be associated for males but not females and acuity dominance with handedness for females but not males.
If there is a relationship between eyedness and handedness then there may also be a relationship between eyedness and brainedness.
If so, groups of subjects composed of individuals with opposite eye dominance may not be homogeneous with respect to cerebral laterality.
The dependent variable in tachistoscopic visual field studies is usually accuracy of recognition or recall and/or simple or discriminative reaction time.
Simple reaction time refers to a response, such as a key press, indicating merely that the stimulus has been detected, whereas discriminative reaction time refers to a response where some kind of discrimination is called for between two stimuli presented either simultaneously or successively.
For example, subjects are often required to decide whether two stimuli are the same or different and then to respond on one key for "same" matches and on a second key for "different" matches; or else to respond to instances of one kind of match and withhold responding to instances of the other kind (a go/no.go discrimination).
In the short review which follows no particular effort has been made to distinguish between the results obtained with different classes of response measure (accuracy or reaction time) as the findings, by and large, are consistent with each other .
Speed versus accuracy trade-offs, for example, have rarely been reported.
There are, however, suggestions that reaction time may be more sensitive to visual field differences than accuracy scores (White, 1972).
In this chapter (and those which follow) the terms left or right "visual field" , "hemifield" and "half-field" are used interchangeably.
Tachistoscopic studies using verbal stimuli
The upsurge of interest in tachistoscopic laterality research which has taken place during the last two decades or so can be traced in part to the split-brain investigations and in part to an experiment conducted by Mishkin and Forgays (1952).
Although these investigators were not specifically concerned with the notion of cerebral asymmetry of function, their finding that bilingual subjects recognised English words more accurately from the right of fixation but Yiddish words (which are read from right-to-left) more accurately from the left of fixation (see also Orbach, 1967) sparked off a number of experiments designed to uncover the relationship between visual field asymmetry and a range of procedural and subject variables.
A crucial distinction turned out to be whether the stimuli were presented only to one side of fixation at a time or simultaneously to both sides.
Heron (1957) found that unilaterally presented words were better recognised from the right visual field but that with bilateral presentation there was an advantage of words to the left of fixation.
He therefore suggested that:
faced with a line of print there is one tendency to fixate near the beginning of the line and another to move the eye along it from left to right.
When alphabetic material it exposed in the right field alone, the two tendencies will be acting together.
When, however, it is exposed in the left field alone, the tendency to move the eyes at the beginning of the line (presumably the dominant one) would be in conflict with the tendency to move the eyes from left to right.
(pp.146–7)
Heron was then able to explain his results by supposing that the neural traces corresponding to the tachistoscopically exposed stimuli are processed in the same way.
However, with bilateral stimulus presentation a tendency to report, rather than process, the left-most stimuli first provides an equally plausible explanation (Ayres, 1966; Dick and Mewhort, 1967; Coltheart and Arthur, 1971; Wilkins and Stewart, 1974).
Support for the scanning hypothesis of lateral differences in tachistoscopic recognition came in the form of findings which showed the direction of visual field asymmetry to be related to whether the stimuli are symmetrically shaped (Bryden, 1968) or are presented in normal or in mirror image orientation (Harcum and Filion, 1963).
An alternative to the scanning hypothesis of laterality differences in tachistoscopic recognition is that, with unilateral stimulus presentation at least, words (Terrace, 1959) and letters (Bryden, 1966) and material for which a verbal label is readily available (Wyke and Ettlinger, 1961; Bryden and Rainey, 1963) are more accurately recognised in the right visual field as a consequence of the more direct neural pathway from the right than from the left side of fixation to language areas of the left cerebral hemisphere.
This cerebral dominance hypothesis is able to explain the results of an experiment by Barton, Goodglass and Shai (1965) who presented three-letter words in a vertical orientation so as to minimise putative scanning mechanisms.
These investigators found their unilaterally presented stimuli to be more accurately recalled from the right visual field  both by American subjects viewing English words and by Israeli subjects seeing Yiddish words.
The early experiments have been reviewed by White (1969a, 1972), McKeever (1974), Pirozollo (1977) and, more recently, by Bradshaw, Nettleton and Taylor (1981a).
The latter authors argued that these early studies were marred by methodological deficiencies.
Nonetheless, Bradshaw et al.conclude on the basis of recent work on tachistoscopic word recognition that, at least with single-syllable words exposed one at a time to left or right visual hemifield, artefacts due to directional scanning contribute little if anything to hemifield asymmetry.
With non-word letter strings or multi-syllabic words the position is less clear.
Kinsbourne (1970) proposed a modification of the cerebral dominance model to explain tachistoscopic hemifield asymmetries.
He suggested that when subjects know to expect verbal stimuli, attentional mechanisms prime the left hemisphere for reception of this material and it is this attentional bias, rather than any inherent perceptual advantage, which gives rise to the right hemifield superiority in word and letter recognition typically obtained with unilateral stimulus presentation.
Kinsbourne initially based his suggestion on the result of an experiment he carried out using a square with a small gap in one of its sides.
Normally subjects were able to detect the presence of this gap equally well whether the square was presented to left or right of the fixation point.
Yet if the subjects were required to repeat the alphabet to themselves during the task this introduced a bias in gap detection favouring the right visual field.
Although there is evidence to support Kinsbourne's hypothesis (Kinsbourne, 1975a; Cohen, 1975a) it cannot account for the results of those studies in which opposite field superiorities have been obtained for verbal and non-verbal stimuli presented randomly or simultaneously to each half field of vision (Terrace, 1959; Berlucchi, Brizzolara, Marzi, Rizzolatti and Umilta, 1974; Hines, 1975; Klein, Moscovitch and Vigna, 1976; Pirozollo and Rayner, 1977).
Nor can it explain the shift from an initial RVF superiority on a visual reaction time task to a LVF superiority when a concurrent memory list of nouns is superimposed on the perceptual task (Hellige, Cox and Litvac, 1979).
One of the difficulties of traditional tachistoscopic procedures is that of relying on subjects to maintain their fixation during stimulus presentation.
McKeever and Huling (1970a) tried to get over this problem by presenting a digit at fixation point at the same time as a stimulus appeared in one or other visual field.
The aim was to ensure that subjects had been fixating correctly by requiring them to report this digit immediately prior to recalling the stimulus.
Trials on which the digit was not correctly identified were discarded from data analysis and substituted later in the series.
Using this technique these workers reported a right field advantage both with unilateral and with bilateral word presentation and attributed their results to"greater transmission fidelity and/or lesser transmission time of the shorter pathway to the left, verbal, hemisphere (McKeever and  Huling, 1971a).
Since a right visual field advantage was still found when the word in the right field was exposed 20 msecs. later than the word in the left field it was subsequently concluded that temporal factors were not importantly involved (McKeever and Huling, 1971 b).
The atypical but consistent finding of McKeever and his collaborators that a right field advantage can be obtained with both unilateral and bilateral stimulus presentation may be attributable in part to their use of very short exposure durations, and in part to their use of a digit as a "fixation forcer" .
This technique has been widely adopted by researchers in recent years.
However, it is not yet clear that the use of a fixation stimulus does not introduce as many difficulties as it seeks to eliminate.
Hines (1972), for example, using exactly the same words as McKeever and Huling (1971a) replicated the latter's finding of a right field superiority in bilateral recognition when a digit was presented at fixation but obtained a significant left field advantage without the digit.
McKeever, Suberi and Van Deventer (1972) replicated Hines's experiment but found that neither the magnitude nor direction of visual field asymmetry was affected by the presence of a central fixation digit.
A similar finding was reported by MacKavey, Curcio and Rosen (1975).
However, reversal from left to right visual field superiority was observed by Kaufer, Morais and Bertelson (1975) when they investigated the effect of presenting a Landolt's ring at fixation for subjects to report the position of a small gap in the ring prior to recalling the stimuli presented in the left and right visual fields.
It is therefore possible that in some circumstances a stimulus at fixation serves as an anchor such that processing occurs first for material appearing to the right of fixation.
Moreover, it has been suggested on the basis of experiments carried out with children that the nature of a fixation stimulus may affect visual hemifield asymmetry by inducing a bias towards either verbal or non-verbal processing, depending on the nature of the stimulus (Kershner, Thomae and Callaway, 1977; Carter and Kinsbourne, 1979).
This claim however was not substantiated in a study with adults (Hines, 1978).
Tachistoscopic studies using non-verbal stimuli
Form recognition
A vast literature now exists reporting a right visual field (RVF) superiority in recognition or recall of words and letters.
A large number of experiments have also been carried out to investigate laterality effects in tachistoscopic perception of non-verbal stimuli.
One of the earliest was that of Terrace (1959) who introduced geometric forms into a series of unilaterally presented words in an attempt to prevent the development in his subjects of an exclusively verbal "set" .
Terrace found a slight though not significant advantage for the left hemifield for these forms in contrast to a right field superiority for words.
Bryden and Rainey (1963) also failed to find a significant hemifield difference in the perception of geometric forms, as did  Lordahl, Kleinman, Levy, Massoth, Pessin, Storandt, Tucker and Vanderplas (1965) using random shapes as stimuli.
However, Gross (1972) obtained an advantage for the left visual field in recall of partially shaded grid matrices and Fontenot (1973), Dee and Hannay (1973) and Dee and Fontenot (1973) found a left field superiority in recall of random shapes.
Dot enumeration and localisation
A non-verbal, visual task of a different kind was utilised by Kimura (1966).
In this task, known to be sensitive to right hemisphere damage (Kimura, 1963a), subjects were required to report the number of dots that were presented randomly in one or other visual field.
Kimura found an advantage for the left field in this task as also when geometric forms were  substituted for the dots.
Adams (1971) found no significant asymmetry in a dot enumeration task but it is possible that the relatively long exposure duration he employed was sufficient to eliminate any potential difference between the visual fields.
The left hemifield advantage reported by Kimura (1966) for the enumeration of dots was subsequently extended to include localisation of a single dot presented in any one of 25 different spatial positions (see also Bryden, 1976).
This might help to explain McKeever and Huling's (1970b) finding that reproduction of dotted designs was more accurate for stimuli presented to the left of fixation whereas there was no asymmetry for solid line designs (Kimura and Durnford, 1974).
On the other hand there is clinical evidence that the right hemisphere is better than the left in recognition of visually degraded stimuli even when these are letters and thus verbal in nature (Faglioni, Scotti and Spinnler, 1969).
Perception of line orientation
A superiority has been found for the left field discrimination of curvature (Longden, Ellis and Iversen, 1976) and in perception of the spatial orientation of a single line (Fontenot and Benton, 1972; Sasanuma and Kobayashi, 1978).
In addition, Atkinson and Egeth (1973) found that responses were faster for the left visual field on a matching task in which subjects had to indicate whether or not two lines showed the same orientation.
These findings are unlikely to be due to some superior "tuning" for line detection in the right hemisphere.although Tei and Owen (1980) have argued that the right hemisphere is neurophysiologically more sensitive to orientation than is the left hemisphere.
The study carried out by Tei and Owen (1980) involved presentation of a grating in central vision while subjects fixated a central point.
Immediately following offset of the adapting grating a second grating (of the same spatial frequency) was presented approximately 4 degrees to the left or right of the fixation point for 100 msec.
This second grating had either the same or a different orientation as the adapting grating and the subjects' task was to indicate by means of a lever response whether the orientations were the same or different.
The results showed that there were more errors  made, and responses were slower, in the left visual field than in the right visual field.
In their analysis of error scores Tei and Owen combine data from trials in which the adaptation and test gratings were the same with data from trials on which they were different.
It is thus not possible to tell whether the significance of the laterality effect observed was due to "same" and/or "different" trials.
Inspection of Tei and Owen's Tables I and 3 reveals that the laterality effect was greater for "same" trials but it is theoretically important to know whether there was any significant interaction between stimulus type and visual hemifield.
A significant difference between the LVF and RVF on "same" trials might imply a faster rate and/or greater magnitude of adaptation in one visual hemifield.
A significant laterality effect for "different" trials would suggest broader tuning of orientation detectors in one cerebral hemisphere than in the other.
These two possibilities are not mutually exclusive.
Tei and Owen provide no breakdown of their data in terms of the angular separation between adapting and test stimuli on their "different" trials so it is net possible to see whether adaptation is effective over a greater range of orientations in the LVF compared to the RVF.
Such a finding might be seen as inconsistent with data from brain damaged patients (Warrington and Rabin, 1970; De Renzi, Faglioni and Scotti, 1971) which suggest that the right cerebral hemisphere is more accurate than the left hemisphere in judging the orientation of a line.
The finding that adaptation is more profound in the LVF than the RVF, on the other hand, would be consistent with the results of Meyer (1976), who found a stronger McCollough effect in the LVF, but would not support the findings of Beaton and Blakemore (1981) who observed no hemispheric difference in extent of adaptation or orientation selectivity in either of their two well-practised subjects.
The possibility of a left-right difference in rate of adaptation, however, remains to be explored.
The frequent finding of a left visual hemifield advantage in the perception or discrimination of line orientation may reflect an overall right hemisphere superiority for tasks which stress the spatial arrangement of elements in a stimulus display (Gross, 1972; Kimura and Durnford, 1974; Robertshaw and Sheldon, 1976; Pitblado, 1979a).
This superiority in the visuo-spatial domain has been found in some studies to extend to perception of the third dimension.
Stereopsis
Stereoscopic depth perception was studied by Durnford and Kimura (1971) by asking subjects to judge whether two rods, one presented at the point of fixation and one presented in the left or right visual field, were horizontally aligned.
With monocular viewing no field difference was found but with binocular viewing a left field superiority was obtained.
Binocular viewing of random dot stereograms also yielded higher scores for the left field in identification of the fused forms.
Durnford and Kimura  therefore concluded that the right hemisphere is specialised for the perception of depth cued by retinal disparity.
Dimond, Bures, Farrington and Brouwers (1975), using a different technique, also claimed a right hemisphere dominance for stereoscopic depth perception.
This supports certain findings from brain damaged patients (Carmon and Bechtoldt, 1969; Benton and Hécaen, 1970; Hamsher, 1978) but the issue of whether there is a hemispheric dominance for stereopsis is unresolved (Julesz, Breitmeyer and Kropfl, 1976; Danta, Hilton and O'Boyle, 1978; Pitblado, 1979b).
Facial recognition
Prosopagnosia is a rare clinical condition in which visual recognition of faces is impaired as a result of brain damage.
The few reported cases that have come to autopsy have generally shown bilateral cerebral lesions but the right sided damage has always been in the region of the occipito-temporal junction whereas the lesions on the left have not been uniformly located (Benson, Segarra and Albert, 1974; Meadows, 1974; Whiteley and Warrington, 1977).
Since prosopagnosia has been associated with right hemisphere damage on purely clinical grounds (Hécaen and Angelergues, 1962; Warrington and James, 1967; but see Cole and Perez-Cruet, 1964) it is reasonable to interpret the post-mortem findings as confirming this association.
Facial recognition has therefore been investigated with neurologically intact subjects in the expectation of finding a tachistoscopic left visual field superiority.
Reaction times to photographs of faces in a same-different task were reported to be faster for left than for right hemifield presentation by Geffen, Bradshaw and Wallace (1971), Rizzolatti, Umilta and Berlucchi (1971), Berlucchi, Brizzolara, Marzi, Rizzolatti and Umilta (1974) and St John (1981).
With accuracy of recognition as the dependent variable a left field advantage was found by Hilliard (1973), Ellis and Shepherd (1975), Jones (1979) and Leehey and Cahn (1979).
Although a superiority of the left visual field has not always been reported, this has been the common finding when the faces to be responded to were highly discriminable and/or unfamiliar (Sergent and Bindra, 1981).
When schematic drawings of faces have been used as stimuli visual hemifield asymmetry has been found to be a function of several factors, including the degree of similarity between the stimuli to be compared and the inter-stimulus interval employed (Patterson and Bradshaw, 1975).
The question of whether the recognition of faces is a specific ability (Yin, 1970; Tzvaras, Hécaen and Le Bras, 1971; Whiteley and Warrington, 1977) or is part of a more general visuo-spatial processing system is unsettled (Ellis, 1975; Hay and Young, 1983).
The typical finding of a left hemifield superiority in facial recognition is, however, consistent with other findings reviewed in this chapter which point to a relative dominance of the right hemisphere in dealing with non-verbal events in general and visuo-spatial processes in particular.
This is entirely consistent with a wealth of  clinical evidence which indicates that the integrity of the right cerebral hemisphere is more important than that of the left for carrying out visuo-spatial tasks (Milner, 1965; Newcombe, 1969; Benton, 1969a; De Renzi, Faglioni and Scotti, 1971; Taylor and Warrington, 1973; Hécaen and Albert, 1978).
Theoretical interpretations of laterality effects
It is generally assumed that in the absence of methodological artifacts visual laterality effects in normals arise either because one cerebral hemisphere is relatively inefficient at processing or retrieving the stimulus material presented and/or because one hemisphere cannot fully process the information and has to send it across the corpus callosum to the opposite hemisphere.
Transmission across the callosum takes time and necessitates crossing at least one synaptic junction, during which the information is said to undergo some degree of transformation such that it arrives at the second hemisphere in a comparatively degraded state (McKeever and Huling, 1971a; Gross, 1972; Gibson, Dimond and Gazzaniga, 1972).
Thus either the comparative inefficiency of one hemisphere in dealing with the information presented and/or a reduction in stimulus fidelity consequent upon hemispheric transfer are held to account for the advantage obtained for a particular half of the visual field.
Attempts have been made to decide between the above two explanations.
Such attempts have usually been based on the notion that the response to a stimulus presented in, say, the left visual field, should be quicker from the left hand than from the right.
Although there is evidence that both hemispheres can control movements of the upper arm (Sperry, Gazzaniga and Bogen, 1969; Van Der Staak, 1975) the extremities appear to be under exclusively contralateral control (Brinkman and Kuypers, 1972; 1973).
Thus in the former situation the stimulus is received and the response initiated by the same hemisphere (direct or uncrossed reaction).
A right hand response to a left field presentation (indirect or crossed reaction), however, would mean that the hemisphere initiating the manual response is not the hemisphere receiving the stimulus and therefore some finite interval of time is required for a nervous impulse to cross from one half of the brain to the other in order to generate a response.
Thus reaction time in this situation would be slower than when a response originates from the directly stimulated hemisphere.
Based on the argument outlined above, measures of inter-hemispheric transfer time have ranged from around 3 msec.
(Poffenberger, 1912) to approximately 30 msec.
(Filbey and Gazzaniga, 1969).
One reason for this discrepancy in estimated values undoubtedly relates to the different kinds of stimulus material and task employed in the different experiments.
Another related reason may be that it is not at all clear what it is that is transmitted during inter-hemispheric transfer.
Rather naively, it has sometimes been suggested, either explicitly or implicitly, that it is some  more or less faithful copy of the stimulus which is shunted from one side of the brain to the other.
This assumption has been most conspicuous in the context of experiments comparing manual response times with vocal reaction time.
It has been supposed that a vocal response must necessarily emanate from the left hemisphere and that a stimulus presented in the left half field of vision must therefore be transferred from the right to the left hemisphere.
If this were so one would expect measures of inter-hemispheric transmission time to remain roughly constant for the same stimuli and subjects, yet this does not appear to be the case (Bashore, 1981).
A tactic for distinguishing an effect on reaction time of a hemispheric processing inefficiency from an effect due to inter-hemispheric transfer is suggested by the application of a memory search procedure (Sternberg, 1966).
A subject is given a number of letters to hold in memory and is then presented with a probe letter.
He has to decide whether the probe letter matches one of the letters in the memory set.
It turns out that the time taken to respond increases linearly with the number of items in the memory set.
A left hemisphere advantage for matching by name (Cohen, 1972) would be expected to lead to a RVF superiority on a memory search for letter names.
If the right hemisphere is merely slower than the left on this task, then the more matches that have to be made the greater the relative right hemispheric disadvantage should be.
The difference in reaction times between RVF and LVF should thus be an increasing function of the number of items held in memory.
Conversely, if the right hemisphere cannot perform the task at all but has to send the probe stimulus to the left hemisphere for a comparison with memory items then the relative disadvantage in reaction time for the right hemisphere should be constant regardless of the size of the memory set.
This experiment has been carried out by Klatzky (1970) and Klatzky and Atkinson (1971) with results favouring the inter-hemispheric transfer interpretation.
There was also an effect due to the hand used to make the discriminative response.
A difficulty in interpreting laterality reaction time data according to a fixed anatomical model is that shorter response latencies for uncrossed as compared with crossed reactions would be expected simply on the grounds of stimulus-response (S-R) compatibility.
It is well known that responses to a stimulus presented off-centre will be faster when made by the limb on the same side of the body as the stimulus appears, that is, when stimulus and response are said to be compatible (Fitts and Seeger, 1953).
It is possible to argue that the SR compatibility effect is in some sense due to the nature of the anatomical pathways involved.
However, compatibility effects are still observed when subjects cross their arms such that the right hand responds to stimuli presented in the left field of vision and the left hand responds to right field presentations.
In such a situation it is sometimes possible using very simple stimuli to dissociate the effects of stimulus-response compatibility from those due to eye-hand connections (Berlucchi, Crea, Di Stefano and Tassinari, 1977) but the relevance of the different anatomical pathways in situations employing more complex  stimuli is doubtful.
Generally speaking, therefore, difficulties of interpretation in this area mean that very rarely does the tachistoscopic paradigm allow any firm conclusion to be drawn as to whether an observed inferiority of one half field of vision is due to time or information loss during callosal transfer and/or to less efficient processing by the contralateral hemisphere.
Nonetheless any differences in some aspect of the responses made by subjects to stimuli presented in left and right visual fields may plausibly be attributed, in the absence of more compelling alternative explanations, to differences of one kind or another between left and right cerebral hemispheres, at least where a visual field effect clearly over-rides the effect of stimulus-response compatibility factors (e.g. Anzola, Bertolini, Buchtel and Rizzolatti, 1977) and/or procedures to counterbalance the effect of the responding hand are incorporated into the experimental design.
Although this review has so far concentrated on those findings which reveal most clearly opposite visual hemifield superiorities for verbal and non-verbal (especially visuo-spatial) stimuli it is impossible for one familiar with work in this field not to be struck by the lability of the laterality effects reported (Cohen, 1982).
Failures to replicate results are common.
If a superiority of one half-field derives from some fixed advantage of the contralateral cerebral hemisphere for the stimulus material in question then comparatively minor procedural differences (e.g. Hiscock and Bergstrom, 1982) should have little or no influence on the outcome of an experiment.
As it is, the magnitude and direction of laterality effects vary not only between different subjects and different experiments but also within the same subject at different stages within an experiment (e.g. Hellige", 1976; Shefsky, Stenson and Miller, 1981).
Structural models of hemisphere specialisation which posit that perceptual asymmetries arise because the brain structures that deal with a particular class of stimuli are lateralised exclusively or predominantly to one hemisphere rather than the other cannot cope with this variability.
A possible resolution of this difficulty is offered by accounts such as those of Kinsbourne (1970, 1973, 1977) which stress dynamic as opposed to structural determinants of perceptual laterality effects.
Thus Kinsbourne's attentional model views shifts in the magnitude or direction of a visual field difference as due to changes in the relative activation of one hemisphere as compared with the other.
Such a theory predicts that an increase in advantage for a particular visual hemifield should be accompanied by an equivalent decrease in performance for the other hemifield, yet this does not appear to be the case (Hellige and Cox, 1976).
Also, the magnitude of a particular visual field difference should be the same for equivalent stimuli presented in the same experimental situation.
Hellige and Cox (1976), however, obtained a slightly larger hemifield superiority for random forms having 12 points than for forms having 16 points even though these two types of form were distributed randomly throughout a series of trials.
Taken together with the finding that an initial RVF superiority on a visual reaction time task gave  way to a LVF superiority when subjects were required to simultaneously hold in memory a list of nouns (Hellige, Cox and Litvac, 1979), this implies that dynamic shifts in attention are insufficient to explain all perceptual laterality effects.
Models of hemisphere specialisation have been critically reviewed recently by Cohen (1982).
She distinguishes between those models that treat hemisphere specialisation as absolute, according to which a given function can only be performed by a particular hemisphere, and those that regard specialisation as relative.
According to the relative specialisation models, both hemispheres can perform a given function but one is faster or more efficient than the other.
These models therefore differ in the degree to which specialisation for a particular function is thought to exist.
In addition, models differ as to the nature of the specialization which they postulate to occur for the two hemispheres.
In her review Cohen argues that there is little evidence in favour of the absolute specialisation models and points out that, as regards the nature of hemispheric specialisation, differences between the two halves of the brain have been conceptualised in terms of specialisation for different types of material, specialisation for different processes and specialisation for different stages of processing.
It was pointed out above that specialization for different types of material cannot explain the lability of many perceptual laterality effects.
Interest therefore centres on the notion that left and right cerebral hemispheres differ in the processes which they characteristically employ or in some other aspect of information processing.
Information processing and visual field asymmetry
In recent years a growing sophistication in tachistoscopic half-field investigations has derived from a conceptual and methodological framework known as information processing theory.
This term refers not to a single theory but rather to a set of assumptions underlying a particular approach to the study of perception and cognition.
The basis of this approach is the belief that the response which a subject makes is not an immediate outcome of sensory stimulation but results from a number of processes which occur over time, stimulation of the sensory receptors being only the first stage in a series of events.
Information processing theorists attempt to define these stages and the order in which they occur.
Models of human information processing have been developed by a number of theorists of this persuasion and the interested reader is referred to the original publications for further details (Broadbent, 1958; 1971; Neisser, 1967; Sperling, 1963; 1967; Atkinson and Shiffrin, 1968; Turvey, 1973).
Common to all models is the view that stimulation of sensory receptors sets up neural activity which outlasts the duration of the physical stimulus.
This persistence is referred to as brief visual (iconic) or auditory (echoic) storage and is believed to last up to about one quarter of a second (Sperling, 1960; Coltheart, Lea and Thompson, 1974).
During this time various encoding operations may be  performed upon the stored information which enables some representation of the stimulus to be held in a short term memory store, after which it either drops out or is transferred into some other more durable store.
Thus information processing models at their most simple distinguish between three distinct stages: registration, coding and retrieval.
Iconic registration
Cohen (1976) argued that visual laterality effects may be attributable to asymmetry at different stages of information processing.
She presented three rows of two letters in either the left or right field and asked subjects either for a full report of all six letters or simply to recall a particular pair of letters (partial report condition) corresponding to a single column of the display.
In the latter situation subjects were given a cue prior to the stimulus presentation (pre-cued condition) so that they knew beforehand whether to report the inner or outer column or the letters printed in a particular colour.
In another condition of the experiment a "masking" stimulus was presented 20 milliseconds (msec.) after the offset of the letter display (post-cued condition).
The reasoning behind Cohen's experiment ran as follows.
Firstly, a hemisphere difference in the rate at which information is encoded and/or read out from some sensory representation of the stimulus should be revealed by a differential effect of masking in left and right visual fields since the presumed effect of the mask is to prevent any further processing.
Secondly, a difference in the ability of the two halves of the brain to utilise advance information in selecting the required stimulus feature for further processing should result in an asymmetrical effect of pre-cueing in the partial report condition as compared with the full report condition.
Cohen's results showed that masking produced a significant decrement in the left visual field but not in the right visual field, thus implying a superiority in rate of encoding for the left hemisphere.
The effect of pre-cueing was also greater in the right field, suggesting a hemispheric difference in the efficiency of selective sampling.
The former result supports similar findings by other investigators (Oscar-Berman, Goodglass and Cherlow, 1973; Turvey, 1973; McKeever and Suberi, 1974; Ward and Ross, 1977) while the latter finding is consistent with the results of another experiment by Cohen in which she used different cues and a different task (Cohen, 1975b).
As well as the experimental conditions referred to above, Cohen (1976) employed conditions in which the cue to recall a particular column of letters was presented at various intervals after stimulus presentation.
Contrary to most published studies, in the post-cued conditions Cohen found no advantage for partial as compared with full report at any of the delay intervals used in her experiment.
This result she attributed to the very short duration of persistence of the icon, which meant that it had faded before the cue could be utilised to sample selectively.
According to calculations carried out on her data, Cohen estimated the duration of the icon to be longer in the left (57 msec.) than the right (34 msec.) visual field.
More recently, Marzi, Stefano, Tassinari and Crea (1979), also using a post-cued partial report technique but without a mask, obtained a partial report advantage which decreased with increasing intervals between stimulus presentation and cue.
This effect was symmetrical for the two visual fields, suggesting that there is no hemisphere difference in persistence of the icon.
Marzi et al.explained the discrepancy between their finding and Cohen's estimate of a longer lasting icon in the left visual field by arguing that the masking paradigm employed by Cohen does not allow measurement of icon persistence independently from encoding rate.
Better performance for one hemifield could be due either to a longer duration of icon, thus allowing more information to be encoded before the icon fades, or to a faster encoding rate, allowing more information to be encoded before the arrival of the masking stimulus.
Marzi et al.therefore saw Cohen's results as due to a confounding of these two aspects of information processing.
In counter-argument it might be suggested that the Marzi et al.finding of an equivalent partial report advantage for left and right hemifields was due to their use of relatively long delay intervals (at least 300 msec.) between stimulus presentation and partial report cue.
It is generally held that the icon has virtually faded after about quarter of a second from stimulus offset.
With the extended delay intervals used by Marzi et al., therefore, any hemispheric difference in duration of the icon will be difficult to detect using the partial report technique.
Cohen's estimate of the hemisphere difference in icon persistence was 23 msec. which is less than 10 per cent of the duration of the shortest delay interval used by Marzi et al.
Cohen's finding that masking produced a significant decrement in the left visual field but not in the right visual field is not supported by the results of Hellige and Webster (1979).
These workers presented target letters followed at very short intervals by curved or straight line masking stimuli and found a LVF superiority.
They also obtained a LVF superiority for simultaneous masking (both letters presented together but superimposed) and forward masking (mask presented prior to target letter).
Given the very short inter-stimulus intervals employed (less than 20 msec.) and the nature of the masking stimuli this suggests the possibility that the LVF superiority arose from some right hemisphere advantage in discriminating the target stimulus from the mask.
There is evidence that the right hemisphere is better than the left in making elementary sensory discriminations concerning brightness (Davidoff, 1975) colour (Davidoff 1976; 1977; Pennal, 1977; Pirot, Pulton and Sutker, 1977) and velocity (Bertolini, Anzola, Buchtel and Rizzolatti, 1978).
A right hemisphere advantage for this stage of processing is not necessarily incompatible with a left hemisphere advantage in rate of encoding.
Moscovitch, Scullion and Christie,(1976) also carried out an experiment within the framework of information processing theory.
These authors presented pairs of faces to one or other visual field and required their subjects to match the faces either to each other or to previously presented  faces.
By varying the interval between presentation of target and test stimuli Moscovitch et al.found that a left field superiority in reaction time emerged only with an inter.stimulus interval of 100 msec. or longer.
This was interpreted as indicating that at the lower inter.stimulus intervals employed (5 and 50 msec.) both hemispheres have access to a short-lived visual trace (i.e. the icon) but once the trace decays the right hemisphere has preferential access to, or operates more efficiently on, some more stable representation of the stimulus.
If this was so, Moscovitch et al.argued, then the effect of a mask which eliminated the short term trace should force the subject to utilise the more "highly processed" stable representation and thus reveal a right hemisphere advantage even with inter.stimulus intervals of less than 100 msec.
Moreover, if the permanent representation is more "highly processed" , then in a task which can only be performed by referring to this higher.level information a right hemisphere advantage should be found even with a zero inter.stimulus interval, that is, with simultaneous presentation of the two stimuli to be matched.
In order to force the subject to use higher.order processing Moscovitch et al.presented photographs and caricature pictures in a simultaneous same.different matching task.
This yielded faster response times to stimuli presented in the left visual field although simultaneous matching of photographs alone, which could be matched on the basis of lower-level processes such as feature analysis, revealed no field advantage.
Thus both predictions were confirmed.
The fact that no hemispheric difference was found with inter.stimulus intervals of less than 100 msec. in the first experiment of Moscovitch et al.was seen as indicating that the initial registration of a stimulus (the icon) is equivalent in left and right hemispheres.
This supports the findings of Marzi et al.(1979) discussed above.
That a LVF superiority in reaction time emerged at 100 msec., however, was taken by Moscovitch et al.to mean that the right hemisphere had some advantage with respect to a more stable representation of the stimulus.
They argued that hemispheric differences only emerge at later stages of processing beyond immediate registration.
Other authors have claimed that visual laterality effects occur when judgements have to be made from memory, that is, beyond the coding stage (Hardyck, Tzeng and"Wang, 1977; 1978; Kirsner, 1980; Kirsner and Brown, 1981.)
Although there are cases where a significant field difference has only been found when some form of retention interval has been imposed on the subject (e.g. Dee and Fontenot, 1973) it is unlikely that these are the only circumstances in which reliable effects occur (Schmuller, 1980).
In an experiment by Berrini, Della Salla, Spinnler, Sterzi and Vallar (1982) subjects were presented with one stimulus in central vision and a comparison stimulus in one or other visual field.
In the first condition of the experiment the laterally displaced stimulus was presented first followed by the central stimulus second.
This produced the usual visual field asymmetry.
Presenting the central stimulus first and the lateralised stimulus second produced no difference between the visual  fields.
The authors therefore saw the asymmetry as arising from the input rather then the recognition stages of processing.
Hemisphere differences in coding
The nature of stimulus coding has been studied by Posner and Mitchell (1967).
Subjects were asked to respond "same" or "different" to pairs of letters.
This could be on the basis of the shape of the letters (physical identity) or according to the name of the letters (nominal identity).
When subjects were asked to perform a physical identity (PI) match (e.g. A-A or a-a) they correctly rejected instances of nominal identity (A-a) as quickly as pairs with different names (e.g. A-b).
This suggests that physical matching was based entirely on a non-verbal mental representation of the stimuli.
Conversely, nominal identity matches such as A-a were performed more slowly than physical identity matches (A-A) suggesting a separate representation for nominal as opposed to physical matches.
These findings support the view of Paivio (1971, 1975) that verbal and non-verbal information is represented and processed in distinct but connected systems.
His research has shown that the probability of recalling items is greatest for actual objects, not quite as great for pictures, reduced again for words representing concrete objects and least of all for words representing abstract concepts.
The explanation usually offered for this phenomenon is that subjects implicitly attach a verbal label to pictures and objects and hence a verbal memory trace as well as a pictorial memory trace is established.
A word describing a "concrete" object also gives rise to a "pictorial" trace but an "abstract" word establishes only a verbal trace.
The increased probability of recall of "concrete" as compared with "abstract" words is thus due to the availability of two codes as compared with one; if one system fails, the other may succeed.
Although the existence of a pictorial code has been disputed (Pylyshyn, 1973) the dual-coding hypothesis has gained wide acceptance.
The verbal system may operate at either a semantic or acoustic level and the non-verbal system according to the kind of transformations (such as inversion, rotation, size reduction) that can be performed on visual images.
Even if a non-verbal visual form of representation is not in the form of an implicit picture or image — and there must be non-verbal representations of a non-visual kind, for how else could we recognise the sound of a car door or the smell of supper?— there is a wealth of experimental evidence (Bower, 1970; Nelson and Brooks, 1973) to support the notion of two separate coding systems, verbal and non-verbal.
(It is perhaps as well to make clear that these systems are not necessarily amenable to introspection.)
Both clinical Jones-Gotman and Milner, 1978; Whitehouse, 1981) and experimental evidence link the verbal and non-verbal codes to left and right hemispheres respectively.
Cohen (1972) presented the Posner task to the left or right visual field and found a RVF superiority for NI matches and a LVF superiority for PI matches, as did Geffen, Bradshaw and  Nettleton (1972).
These results are important in showing that even with verbal stimuli a tachistoscopic LVF advantage may be obtained when the task can be performed non-verbally.
Thus it is not the ostensible nature of the stimuli that is crucial in determining any difference between the visual fields as the kind of cognitive processing that the subject undertakes (but see Simion, Bagwara, Bisiacchi, Roncato and Umilta, 1980).
This is shown most dramatically by the results of studies in which, using exactly the same stimulus material, opposite field advantages have been obtained according to the task requirements (Klatzky, 1972; Seamon and Gazzaniga, 1973; Robertshaw and Sheldon, 1976; Niederbuhl and Springer, 1979).
That a stimulus can be processed either verbally or non.verbally helps to make sense of those otherwise anomalous findings in which verbal stimuli give rise to a LVF superiority (Gibson, Dimond and Gazzaniga, 1972; Schmit and Davis, 1974; Wilkins and Stewart, 1974; Hellige, 1976; Martin, 1978; Jonides, 1979; Niederbuhl and Springer, 1979) and non-verbal stimuli such as faces (Patterson and Bradshaw, 1975; Marzi and Berlucchi, 1977; Umilta, Brizzolara, Tabossi and Fairweather, 1978), colours (Malone and Hannay, 1978) or pictures (Wyke and Ettlinger, 1961) produce an advantage for the right visual field.
Even within the same series of experimental trials opposite field superiorities may be obtained for similar stimuli processed in different ways.
For example, Umilta, Rizzolatti, Marzi, Zamboni, Franzini, Camarda and Berlucchi (1974) required subjects to judge the orientation of a single line.
Those lines which were oriented so as to be readily named (e.g. vertical, horizontal, diagonal) gave a RVF superiority in reaction time whereas the remaining orientations favoured the left visual field.
(This may explain the results of White (1971) who presented lines only in horizontal, vertical and diagonal orientations and found a RVF superiority.)
The effect of providing subjects with a verbal label for random forms was investigated by Hannay, Dee, Burns and Masek (1981).
A left field superiority when the forms were presented alone was converted to a RVF superiority when subjects had to use a label for each form.
This implies that unwanted variance may be introduced into the data of those experiments where subjects are free to spontaneously attach their own labels to non-verbal stimuli.
A preference for using one code rather than the other could explain differences between individual subjects in the direction of hemifield asymmetry for different tasks (Kroll and Madden, 1978).
However, there is a risk of becoming circular in accounting in this way for any particular visual field difference that is observed.
What is required is independent evidence that a particular code is in fact being used.
Seamon and Gazzaniga (1973) presented subjects with two words referring to common objects (e.g. Hat-Duck).
In one condition subjects were specifically instructed to engage in verbal rehearsal of these word pairs and in a second condition they were instructed to use visual imagery to relate the two objects.
A picture was subsequently presented in one or  other visual field and the subject's task was to indicate whether or not the probe picture had previously been presented among the memory set.
It was found that, with instructions to verbally rehearse, reaction times were faster to left hemisphere probes, while under the relational imagery condition reaction times were faster to right hemisphere probes.
It was argued that in the verbal rehearsal condition subjects had to name the picture probe before a match could be performed on a verbal basis, while in the imagery condition a match could be made directly.
The statistically significant interaction between condition of retention and visual field of presentation was held to confirm the hemispheric locus of visual and verbal codes.
These findings have been replicated by Metzger and Antes (1976), though found to be statistically significant only for "same" trials,
Modes of processing
A subject's performance on an experimental task may depend not only on the way which he encodes the stimuli but also on the strategy he adopts in carrying out the task.
Information processing theorists distinguish between serial and parallel processing.
Serial processing refers to cognitive operations carried out successively whereas parallel processing is carried out simultaneously.
Attempts have been made to map these two modes of processing on to the left and right hemispheres respectively.
Cohen (1973) presented subjects with from 2 to 4 letters in a same different matching task.
On "same" trials all the letters were identical; on "different" trials at least one letter was different from the others.
She found that, for the RVF, manual reaction times for "same" trials increased with the number of letters presented but, for the LVF, reaction time was more or less constant regardless of the number of letters presented.
Since a process of comparing each letter in turn with the other letters of the stimulus set would lead to reaction time increasing with set size this result has been quoted as showing that the left hemisphere operates in a serial manner.
Conversely, the constant reaction time found with left visual field presentations has been taken to imply that the right hemisphere processes information simultaneously, that is in parallel.
However, Cohen also carried out the same experiment using non-letter characters from a typewriter and obtained no consistent effect of set size in either visual half field.
When these characters were combined with letters in a third experiment there was again an increase in reaction time with set size for the RVF but only for letters, not for the typological characters.
It thus seemed that serial processing was confined to verbal stimuli.
However, this neat conclusion is upset by the finding of White and White (1975) that even with letters as stimuli there was no significant visual field-by-set size interaction when subjects performed nominal and physical identity matches.
Furthermore, the notion that it is only the left hemisphere that operates in a serial manner is not supported by the results of Gross (1972), Niederbuhl and Springer (1979) and Polich (1980) all of whom found evidence of serial processing in both visual fields.
Although there is evidence that the left hemisphere is better at dealing with sequences of stimuli in different modalities (Carmon and Nachson, 1971; Swisher and Hirsch, 1972; Brookshire, 1975; Nachson and Carmon, 1975; Tallal and Newcombe, 1978; Sherwin and Efron, 1980; Mills and Rollman, 1980) this does not necessarily entail that the left hemisphere itself processes information sequentially.
Nor should this be confused with evidence (see Chapter 5) that the left hemisphere has a special role to play in the organisation of sequential motor behaviour.
A second distinction that has been drawn is between analytic and holistic modes of processing (see Bever, 1975), sometimes referred to as analytic versus gestalt processing.
It seems to have arisen from the report of Levy-Agresti and Sperry (1968) that in a visuo-tactile matching task the two hemispheres of split-brain patients solved the problems in characteristically different ways.
The right hemisphere seemed able to grasp the shape of a three-dimensional form as a unified whole whereas the left hemisphere concentrated in turn on each of the edges and corners of the forms.
The analytic versus holistic  dichotomy is often confused with the serial versus parallel dichotomy but the two are conceptually distinct.
The analytic versus holistic dichotomy as it applies to laterality research has been more often invoked to explain results in a post hoc fashion than it has itself been subjected to experimental scrutiny.
However, Martin (1979) predicted that if the shape of a letter was made up from smaller letters, then with instructions to respond on the basis of the overall configuration there should be a LVF advantage.
With instructions to respond on the basis of the smaller letters there should be an advantage for the RVF.
In the event, the global task (responding to the overall configuration) showed a non-significant LVF superiority and the local task (responding to constituent letters) gave a significant RVF superiority in reaction time.
Since the strategy which a subject adopts towards an experimental task is under his own control, unless otherwise constrained, any visual field asymmetry found in a particular experiment is as likely to reflect aspects of information processing as any intrinsic difference between the hemispheres for the task in question (e.g. Ross and Turkewitz, 1981).
Even with subjects' strategies constrained, it will be necessary to know how those interact with hemispheric specialisation as a function of different cognitive tasks and experimental variables if a complete account of visual hemifield asymmetries is to be achieved.
Visual field differences have been related to a host of methodological, procedural and stimulus factors.
These include the spatial or temporal intervals between the elements making up a display (Kimura, 1969; Hines and Satz, 1971), the distance of stimuli from fixation (Bryden, 1966; McKeever and Gill 1972c; Carmon and Nachson, 1973; Curcio, MacKavey and Rosen, 1974), the spatial frequency of the stimulus (Rao, Rourke and Whitman, 1981), the directional characteristics of words and letters (Harcum and Filion, 1963; Bryden, 1966; 1968; White, 1969b), the number of times a stimulus is presented (Hardyck, Tzeng and Wang, 1977; 1978; Schmuller, 1980), exposure duration (Bryden, 1965; Gill and McKeever, 1974; Beaumont and Dimond, 1975), stimulus size (Pring, 1981; Pitblado, 1979b), typeface (Bryden and Allard, 1976), complexity (Fontenot, 1973) and discriminability (Patterson and Bradshaw, 1975).
In addition to these stimulus characteristics, a large number of subject variables have been studied in relation to visual hemifield asymmetry.
Many of these are covered in the chapters which follow.
DICHOTIC LISTENING
One of the techniques now employed in many laboratories to assess differences in function between the two halves of the brain entails simultaneous presentation of competing information to the left and right ears.
Pairs of stimuli are aligned on two tracks of a magnetic tape such that the onset and offset of one stimulus coincide exactly with the onset and offset of the second stimulus.
Intensity of the two stimuli is also carefully balanced.
The tape is played over a pair of stereo headphones to the subject who hears one member of the stimulus pair at one ear and the second member of the pair at the opposite ear.
This procedure, referred to as dichotic presentation, has its origins in experiments on selective attention carried out by Broad bent (1954,1958).
However, the rapid development of interest in dichotic listening as a tool for the investigation of hemispheric asymmetry stems largely from the work of Kimura in the early sixties.
Kimura (1961a) showed that temporal lobectomy results in a significant deficit in recall of digits presented at the ear opposite the side of the surgery, but only under conditions of dichotic presentation and not when input is restricted to one ear alone.
She argued that this was consistent with the view that the auditory pathways from each ear to the contralateral cerebral cortex are more effective than the ipsilateral pathways from each ear to the same side of the brain.
Although the contralateral impairment observed with  simultaneous digit presentation to the two ears was found after both left and right sided lobectomy, the overall efficiency of recall was much higher for the right temporal group of patients.
Kimura saw this result as confirming that the left temporal lobe is more important than the right temporal lobe in the perception of spoken material.
Models of dichotic listening
The fibres from the receiving station of the inner ear, the organ of Corti synapse first at the cochlear nucleus.
From there, some fibres continue to the superior olivary body on the same side of the brain stem as the stimulated ear but the majority cross over to the olivary body on the opposite side of the brain stem.
Pathways from the two ears thus converge on the olivary body at each side (Figure 6).
From here both ipsilateral (uncrossed) and contralateral (crossed) fibres pass successively upwards to   the lateral lemniscus, inferior colliculus and medial geniculate nucleus before arriving finally at the superior gyrus of the temporal lobe.
There is now substantial clinical (Bocca, Calearo, Cassinari and Migliavacca, 1955; Oxbury and Oxbury, 1969; Celesia, 1976) and experimental (Rosenzweig, 1951; Satz, Levy and Tyson, 1970; Majkowski, Bochenek, Bochenek, Knapic-Fijalkowska and Kopec, 1971; Andreassi, De Simone, Friend and Grota, 1975; Mononen and Seitz, 1977) evidence to support the view that the crossed pathways are more important than the uncrossed pathways in transmitting auditory information.
In particular, Milner, Taylor and Sperry (1968) and Sparks and Geschwind (1968) found that split-brain patients were able to repeat digits presented to either ear alone but showed almost total absence of report of digits presented to the left ear when different digits were simultaneously presented to the right ear.
This suggests that impulses travelling along the uncrossed pathways suppress or inhibit impulses travelling to the cortex by way of uncrossed fibres, although recent work suggests that the extent of ipsilateral suppression depends upon the nature of the competing stimuli (Springer, Sidtis, Gazzaniga and Wilson, 1978).
This suppression may take place at different levels, sub-cortical as well as cortical, within the auditory system (Berlin, Lowe-Bell, Cullen, Thompson and Loovis, 1973; Berlin, 1977).
The effect of suppression, wherever it occurs, is that stimuli presented to the left ear are destined predominantly for the right hemisphere and stimuli heard at the right ear arrive mainly in the left hemisphere.
The extinction of left ear responses in the dichotic listening performance of split-brain subjects can thus be explained by the fact that material in the right hemisphere cannot reach the speaking left hemisphere unless the anterior two thirds of the callosum (Springer and Gazzaniga, 1975; Hécaen, Gosnave, Vedrenne and Szikla, 1978) and/or, in some patients, the anterior commissure,(Risse, Le Doux, Springer, Wilson and Gazzaniga, 1978) is intact.
Kimura (1961 b) presented neurosurgical patients with three pairs of digits, one member of each pair to the left ear and the other member to the right ear.
Twelve of the patients had right hemisphere speech representation as determined by the Wada sodium amytal test.
In this group of patients the mean number of items recalled from the left ear was higher than from the right ear.
In the remaining 103 patients, with presumed left hemisphere speech, mean recall was higher from the right ear.
Kimura also found that among normal right handed subjects there was a small but statistically significant advantage in recall of verbal material presented to the right ear.
Dichotic listening thus appeared to offer a comparatively simple, non-invasive technique for determining the speech dominant hemisphere in neurologically intact subjects as well as in neurosurgical patients, since the side of speech dominance shows up as an advantage for digits presented to the contralateral ear.
The right ear advantage in normals was attributed by Kimura to a combination of two factors.
First, the crossed auditory pathways inhibit the uncrossed pathways such that stimuli presented to the right ear arrive intact at the left hemisphere and stimuli presented to the left ear arrive at the right hemisphere.
Second, information is either degraded in passing from the right to the left hemisphere or else is less efficiently processed by the right half of the brain.
Following publication of Kimura's paper the dichotic listening technique was taken up enthusiastically as a means of assessing language laterality in normal subjects.
Her finding of a mean right ear advantage  (REA) in, the recall of dichotically presented material by right handers has been replicated by many investigators (see Studdert-Kennedy, 1975; Berlin and McNeill, 1976) and is now a firmly established phenomenon.
However, Kimura's interpretation of this finding did not go unchallenged.
When digits are presented in pairs to left and right ears, there is an almost universal tendency (Broadbent, 1954) for subjects to report all of the items presented to one ear before reporting those items presented to the other ear.
Inglis (1965) summarised data which showed that among individuals with memory defects only the number of items recalled from the second ear differed from the number recalled by normal control subjects, whereas recall from the initial ear was similar for both groups.
Inglis argued that his result supported an interpretation of the usual right ear effect in terms of memory rather than sensory competition.
He suggested that a tendency to report first the material entering the right ear might allow information from the left ear to decay in short term memory and thus give rise to the observed superiority of the right ear.
An order of report interpretation was considered an insufficient explanation by Bryden (1967), who continued to find a right ear advantage even when analysing only responses given from the ear reported first, but such an explanation continues to surface from time to time(e.g. Friedes, 1977).
Notwithstanding Bryden's (1967) results, it may happen that subjects primarily attend to, as opposed to recall, information presented to the right ear in the absence of constraints to do otherwise (Simon, 1967; Haydon and Spellacy, 1973; Levy and Bowers, 1974).
Perhaps that is why sounds are recognised more accurately (Hublet, Morais and Bertelson, 1977) to the right of a subject and appear louder than sounds of equal intensity heard on the subject's left (Kellar, 1978; Wexler and Halwes, 1981).
However, an attentional hypothesis cannot explain the finding of a right ear advantage when subjects are asked to attend to the input presented to the left ear (Bryden, 1969).
Furthermore, Kallman (1978) found a right ear superiority for words and a trend towards a left ear advantage for music in a target detection task in which the two types of stimuli were randomly interspersed.
An attentional model cannot account for the statistically significant ear-by-stimulus type interaction.
Finally, the theory that attention is directed to the left or right side as a consequence of asymmetrical activation of the cerebral hemispheres (Kinsbourne, 1970; 1973; 1975a) predicts that in hemispherectomised patients attention should be directed almost exclusively to the side contralateral to the intact hemisphere.
Nebes, Madden and Berg (1981) found no evidence to support this hypothesis.
This is not to argue that prior activation of one hemisphere cannot introduce a bias towards the opposite ear (Nachson, 1973; Morais and Landercy, 1977) but it does suggest that the effect of activation may be to engage the processing mechanisms of a particular hemisphere rather than upset a hemispheric balance of attention.
The possibility that a dichotic right ear superiority is due to subjects being required to give a verbal response prompted Springer (1971, 1973) to  present consonant-vowel syllables either dichotically or opposed by white noise (a mixture of all possible sound frequencies) and to use manual reaction time to a target syllable as her response measure.
In both conditions the usual asymmetry emerged suggesting that factors associated with verbal output do not determine the advantage for the right ear.
Thus although Kimura's original findings related ear asymmetry to the hemispheric side of speech production it is possible that differences between the ears reflect asymmetry between the hemispheres in speech perception rather than production.
Morais and Bertelson (1975) pointed out that the usual dichotic listening paradigm does not allow one to distinguish between an interpretation of the REA in terms of ear of stimulus presentation and an alternative explanation favouring input coming from the right side of space.
That is, one explanation sees the right ear advantage to be the result of stimulating a particular ear, the other as the result of receiving sounds from a particular side of space.
Morais and Bertelson therefore carried out an experiment in which the apparent spatial localisation of a sound source was achieved by manipulating either the time or the intensity difference of the same stimulus heard at the two ears.
By stereophonic means a situation was created such that each ear heard the same two virtually simultaneous messages but, due to a very small difference in the time of arrival of a given stimulus at the two ears, one message appeared to come from the subject's left while the other appeared to come from the right.
Thus ear of entry was eliminated as a potential source of dichotic advantage since both ears heard the same two messages.
It turned out that Morais and Bertelson obtained a significant advantage for those stimuli which appeared to come from the right side of space.
They argued that an interpretation in terms of the relative potency of crossed and uncrossed pathways could not account for this result.
Kinsbourne's (1970) explanation of perceptual asymmetries as resulting from activation of the contralateral hemisphere could, however, handle their data.
In support of the idea that ear differences in recall may have something to do with position in lateral space there is an intriguing but brief report in the literature that the magnitude of ear asymmetry can be modified by requiring subjects to wear prism lenses that displace the visual field to one side of the true position (Goldstein and Lackner, 1974).
The fact that a right ear advantage was obtained in the experiment by Morais and Bertelson does not mean that there is no difference in functional potency of crossed and uncrossed pathways, but implies that competition between the two ears is not the sole and necessary determinant of auditory laterality effects.
This was in any case already known from the fact that statistically significant ear differences in reaction time or accuracy of report have been observed even with monaural stimulus presentation (for a bibliography see Henry, 1979).
In general, it appears that the more complex the level of stimulus processing required, the more likely it is that a difference between the ears will be revealed with monaural presentation.
Few, if any, workers, would deny that a superiority for the right ear has, other things being equal, something to do with the fact that the left hemisphere is more efficient at verbal tasks generally.
Yet the nature of this "something" will vary with different stimuli, tasks and subjects.
Not all dichotic listening experiments tap the same psychological operations which may well differ in the extent of their underlying cerebral lateralisation.
Lateralised processing mechanisms may be engaged at either the acoustic, phonetic, syntactic or semantic levels of language.
At the acoustic level Kimura and Folb (1968) found the usual right ear advantage in the perception of dichotically presented backward speech, even though such sounds are totally unintelligible.
Zurif and Sait (1970) also obtained a difference between the ears in recognition of meaningless speech stimuli.
In one condition of their experiment nonsense sequences followed a structural pattern of English in so far as replacing the nonsense stems by English stems would have resulted in a grammatically correct sequence.
In the control condition this was not the case.
A superiority of the right ear was obtained in the structured but not in the unstructured condition.
This effect could not be attributed to different patterns of intonation in the two conditions (Zurif and Mendelsohn, 1972) which implies that the effect was mediated at a syntactic level.
However, Harriman and Buxton (1979) presented semantically anomalous sentences spoken either in a monotone or with appropriate intonation, and obtained a REA only in the latter condition.
One of the simplest sets of stimuli used in dichotic listening experiments consists of natural or computer generated pairs of syllables, such as /pa/ and /da/.
Shankweiler and Studdert-Kennedy (1967) used a device to generate consonant-vowel (cv) syllables from different consonants paired with the same vowel.
Pairs of syllables carefully synchronised were then presented dichotically to subjects who had to report both syllables on each trial.
A right ear advantage was found which was greater for those syllables differing in two articulatory features, voice and place, than for syllables differing in only one such feature ( "voicing" refers to vibration of the vocal chords; "place" refers to the place of articulation of the sound in the vocal tract).
Using steady state vowels, which do not convey information by means of distinctive articulatory features, no laterality effect was obtained.
Shankweiler and Studdert-Kennedy therefore concluded that the language processing system may be engaged at the level of the sound structure of language and involves an analysis-by-feature mechanism.
Thus not only can the dichotic listening paradigm be employed as a tool for investigating brain asymmetry but it can also be used to probe the nature of speech perception.
Liberman, Cooper, Shankweiler and Studdert-Kennedy (1967) argued that the perception of speech involves analysis of an acoustic message into the articulatory movements which would be required to reproduce that message, the so-called motor theory of speech perception.
Such a theory implies that decoding a speech signal by reference to its articulatory features may be what characterises, at least in part, the special capacities of  the left hemisphere (Liberman, 1974).
On the other hand Marshall (1973) considers the crucial point to be that…the phonological correlations in terms of which speech is perceived and the temporal segments of the acoustic wave which  examplify phonological sequences is not one to one and thus some decoding mechanism, unique to the left hemisphere, is required to derive the one from the other.
(p. 452)
The question of exactly what linguistic features the left hemisphere is specialised to detect has been pursued vigorously.
This issue is beyond the scope of this book and the interested reader is referred to papers by Studdert-Kennedy and Shankweiler (1970), Shankweiler (1971), Blumstein (1974), Cutting (1974), Darwin (1974), Liberman (1974), Berlin and MacNeill (1976) and Berlin (1977).
It may be noted, however, that a right ear advantage has been reported for stimuli other than speech.
This implies that the left hemisphere's specialisation is not restricted to speech sounds.
Dichotic studies with non-verbal stimuli
Papcun, Krashen, Terbeek, Remington and Harshman (1974) presented short Morse code sequences to naive and experienced Morse operators and found a significant right ear advantage in both groups of subjects.
This suggests that the meaning of the stimuli was irrelevant to the asymmetry between left and right ears.
However, longer Morse sequences yielded an advantage for the left ear, but only for the experienced operators.
It was suggested that they were able to switch to using a more "holistic" processing mode which is the preferred mode of operation of the right hemisphere.
As with other authors who have had recourse to the analytic versus holistic distinction (Bever and Chiarello, 1974; Bever, Hurtig and Handel, 1976; Ross and Turkewitz, 1976; Gates and Bradshaw, 1977a) this is a post-hoc explanation, not an experimental test of the notion that different cognitive strategies are characteristic of left and right hemispheres.
Musical stimuli have been employed in a number of dichotic listening experiments.
Kimura (1964) first reported an ear difference in the perception of dichotically presented melodies.
The same subjects who showed an advantage for the right ear with pairs of digits showed a significant superiority for the left ear when the stimuli consisted of snatches of melody which had to be identified by means of a multiple-choice response method.
This finding supports that of Milner (1962) who found that right brain damaged subjects were more impaired than patients with left sided damage on certain items of the Seashore test of musical abilities.
Subsequently Shankweiler (1966) found right temporal lobectomised patients to be inferior to left temporal patients on a dichotic melodies test.
Together with Kimura's finding this strongly implicates the right temporal lobe in certain aspects of music perception (see also Shapiro, Grossman and Gardner, 1981).
In an attempt to identify the musical dimensions which determine the  left ear effect, Gordon (1970) presented competing melodies matched for rhythm and pitch to experienced musical subjects.
In a second condition, single chords were heard at each ear.
No asymmetry was found on the melody task but a significant left ear advantage emerged for the chords.
Gordon suggested that the failure to find a left ear superiority for melodies, in contrast to Kimura's (1964) results, might have been due to differences in the rhythm and/or pitch of the stimuli employed by himself and by Kimura.
He subsequently found (Gordon, 1978a) that these two features show different laterality patterns, pitch yielding no ear difference and rhythm an advantage for the right ear.
Robinson and Solomon (1974), Natale (1977) and Gates and Bradshaw (1977a) also obtained a right ear advantage in recognition of rhythm but dichotic pitch perception has yielded contradictory results (for review see Craig, 1979a).
It is possible that the different results for dichotic recognition of melodies obtained by Kimura (1964) and Gordon (1970) were due not to stimulus differences in the two experiments but to differences in the musical experience of the subjects employed.
Bever and Chiarello (1974) and Johnson (1977) found a left ear superiority for melodies among naive listeners but a right ear advantage for musically experienced listeners.
Comparable findings were obtained in an electrophysiological study by Hirshkowitz, Earle and Paley (1978) but a significant group-by-ear interaction has not always been found (Gates and Bradshaw, 1977a; Zattore, 1979).
The potentially confounding effects of musical experience with musical aptitude were dissociated in an experiment by Gaede, Parsons and Bertera (1978).
Subjects low in musical aptitude showed larger between ear differences on tests of chord analysis than did subjects of greater aptitude but within the same aptitude level there was no effect of experience.
Gates and Bradshaw (1977b) have reviewed the literature concerning music and the cerebral hemispheres and caution against regarding one particular hemisphere as dominant for musical functions.
Each half of the brain may make its own contribution towards different aspects of musical expression or appreciation.
Other reviews on the role of the hemispheres in music are those by Wyke (1977) and Damasio and Damasio (1977).
Non-verbal tasks giving rise to left ear advantages have included discrimination or recognition of pitch (Curry, 1968; Schulhoff and Good-glass, 1969; Halperin, Nachson and Carmon, 1973; Oscar-Berman, Goodglass and Donnenfeld, 1974; Kallman and Corballis, 1975), environmental noises (Curry, 1967; Knox and Kimura, 1970; Carmon and Nachson, 1973b) and such stimuli as clicks (Murphy and Venables, 1970), sonor signals (Webster and Chaney, 1966) and square-wave patterns (Sidtis, 1980).
As with other laterality paradigms the cognitive processing undertaken by the subject rather than the nature of the stimulus per se determines which, if either, ear will be superior on a given task (Tsunoda, 1971; Nachson, 1973; Van Lancker and Fromkin, 1973; Bartholomeus, 1974; Gates and Bradshaw, 1977a).
For example, Spellacy and Blumstein (1970) presented dichotic pairs of consonant-vowel-consonant (cvc) syllables  among which were randomly interspersed either real English words for half the subjects or musical or environmental sounds produced by a human voice for the other half of the subjects.
The syllables heard at the two ears differed only in the initial consonant or only in the middle vowel.
The subjects hearing occasional words showed a right ear advantage for the vowel-varied stimuli whereas those subjects who heard non-verbal sounds exhibited a left ear superiority for the same stimuli.
As a general rule stimuli which are heard within, or from part of a linguistic context give rise to an advantage for the right ear whereas stimuli heard within a non-linguistic context are more likely to show a superiority favouring the left ear.
Bartholomeus (1974) presented dichotic pairs of melodies sung by different people repeating different letter sequences.
Using the same stimulus tapes but different subjects for each task, she found that recognition of melodies gave a significant left ear advantage, and letter sequences yielded a significant right ear advantage while voice recognition showed no difference between the two ears.
Thus opposite ear superiorities may be found when subjects are constrained to process different aspects of the same stimuli.
This implies that in the absence of specific constraints subjects are free to attend to different aspects of the stimulus.
Reliability and validity of dichotic listening asymmetry
Much of the motivation in dichotic listening research lies in identifying the hemisphere responsible for speech or other functions.
However, as with the tachistoscopic paradigm, left-right ear differences in dichotic listening scores are far more labile than one would expect if ear asymmetry is an index of some fixed structural attribute (Teng, 1981).
In one study as many as 30 per cent of subjects exhibited a change in the side of the superior ear when re-tested within a period of one month (Pizzamiglio, Pascalis and Vignati, 1974).
Even within a single testing session the magnitude or direction of asymmetry may change, perhaps due to changing strategies utilised by the subject (Perl and Haggard, 1975; Kallman and Corballis, 1975; Sidtis and Bryden, 1978).
Over a number of sessions the proportion of subjects showing a right-ear preference for verbal stimuli tends to increase due to the greater probability of change among subjects showing an initial left ear advantage (Blumstein, Goodglass and Tartter, 1975; Shankweiler and Studdert-Kennedy, 1975).
Even with adequate reliability the validity of any test instrument is not guaranteed.
One still needs to know what is being measured.
While a mean right ear advantage has been correlated with left hemisphere dominance for speech as determined by the Wada sodium amytal test (Kimura, 1961a; Tsunoda, 1975) the validity of dichotic ear asymmetry as an index of cerebral speech representation in individual subjects is questionable.
This is because in any sample of right handers it is usually found that a considerable proportion of subjects do not show the expected right ear  superiority for verbal material.
Bryden (1967) found this proportion to be approximately 15 per cent.
Even allowing for a difference in the extent of lateralisation of executive aspects of speech, revealed by the Wada test, and receptive aspects, tapped by the dichotic listening technique, this figure of IS per cent is too high to accord with the evidence from brain damaged populations.
A closer correspondence between behavioural and neuropsychological estimates of speech lateralisation is obtained by only considering ear differences that reach a specified level of statistical significance (Wexler, Halwes and Heninger, 1981) but as Satz (1977) has argued, the probability of mis-classifying a right hander with a dichotic left ear advantage as right brained for speech is of the order of 90 per cent(see Chapter 5)!
In general even if it can be shown that one particular dichotic testing procedure can lead to an accurate prediction of the side of speech representation it does not logically follow that other procedures are equally valid or even tap the same processes.
Nonetheless, the stimuli and tasks used in dichotic listening research have been almost as varied as the number of investigations undertaken with little or no attempt at proper validation.
An exception to this criticism is the work of Geffen who together with her colleagues has devised a dichotic monitoring test.
Subjects hear words in left and right ears and are required to make a manual response on detecting a specified target word in either ear.
A greater number of detections in one ear than the other is said to reflect speech dominance of the hemisphere opposite the more accurate ear.
The technique has proved reliable (Geffen and Caudrey, 1981) and has been validated against the assessment of language laterality by means of unilateral ECT (Geffen, Traub and Stierman, 1978) and, in four cases, against the Wada sodium amytal test (Wale and Geffen, 1981).
Despite the fact that dichotic listening techniques have often been adopted without proper validation, findings which show a difference in the direction and/or magnitude of ear asymmetry between groups of right and left (or non-right) handed subjects have been taken as indicating a difference in direction or magnitude of cerebral lateralisation.
Discussion of this point is deferred until Chapter 13.
TACTILE PERCEPTION
Although hemispheric specialisation of function has been studied mainly through the visual and auditory modalities, there has been some work carried out with regard to the sense of touch.
The fact that the sensory and motor functions of each hand are represented predominantly in the contralateral cerebral cortex means that information available to one hand alone is processed largely in the opposite hemisphere.
Thus the abilities of left and right hemispheres on tactile tasks can be assessed by comparing the performance of the right and left hands.
Although a tendency towards greater tactile sensitivity of the left compared with the right hand has been  reported for right handed adults (Semmes, Weinstein, Ghent and Teuber, 1960, but see also Rhodes and Schwartz, 1981) a sensitivity difference between the hands is probably not important in tasks employing suprathreshold stimulation.
Benton and his colleagues used an electromechanical device to stimulate the back of the hand.
Three points lying in a straight line were stimulated in quick succession and the subject's task was to indicate from among four alternatives the orientation of the line in which the stimuli had been presented.
More accurate perception of orientation was found for the left than for the right hand, at least among right handers (Benton, Levin and Varney, 1973; Varney and Benton, 1975; Benton, Varney and Hamsher, 1978).
Earlier Carmon and Benton (1969) and Fontenot and Benton (1971) had found that patients with lesions in the left hemisphere were impaired on this task only on the right hand whereas patients with right sided lesions were impaired on both hands.
This is the reverse pattern of results to that found for purely somatasensory defects by Semmes et al.(1960).
These findings, together with those for normal subjects, therefore suggest that the right hemisphere plays an important role in mediating tactile perception of direction.
This might explain why right brain damaged patients perform poorly in learning a tactual maze (Corkin, 1965).
Faglioni, Scotti and Spinnler (1971) found that, with vision excluded, patients with right hemisphere lesions were significantly impaired in comparison with left brain damaged patients in reproducing the position of crosses marked on a model.
Similarly, right hemisphere patients were inferior at reproducing by touch alone the angle at which two movable rods were set relative to each other(De Renzi, Faglioni and Scotti 1971).
In both these studies the results for tactual responding closely mirrored those for responding under visual guidance, which suggests that the right hemisphere plays a supra-modal role in appreciation of spatial relations generally (De Renzi and Scotti, 1969; De Renzi, Faglioni and Scotti, 1970).
On a tactual version of the Formboard Test, in which wooden forms have to be fitted into spaces of the same outline shape, patients with right posterior damage were found to be much slower than those with damage to the left hemisphere (De Renzi, Faglioni and Scotti, 1968).
With regard to neurologically intact subjects, Witelson (1974) devised a"dichotomous tactile task which revealed a left hand superiority in perceiving meaningless, three dimensional forms.
Similar findings have been reported by others (Kleineman and Cloninger, 1973; Gardner, English, Flannery, Hartnett, McCormick and Wilhemy 1977; Dodds, 1978; Klein and Rosenfield, 1980).
Thus it appears that the right hemisphere bears particular responsibility in the tactile perception of shape.
A superiority in either the perception of shape or in the perception of direction, if in fact these functions are dissociable, can account for the left hand advantage in Braille reading found for both experienced blind subjects (Hermelin & O'Connor, 1971) and blindfolded normal subjects  (Smith, Chu and Edmonston, 1977; Harriman and Castell, 1979) taught to read Braille.
These findings are particularly interesting in view of the fact that reading is a verbal process and might therefore be expected to yield a superiority for the right hand.
Oscar-Berman, Rehbein, Porfert and Goodglass (1978) obtained a right hand superiority in recognition of letters traced oil the palm of the hand but a left hand advantage in discriminating the orientation of lines.
Conceivably, the degree of difficulty in discrimination determines whether the spatial or verbal aspects of Braille dominate performance on the task and this determines the direction of asymmetry.
ELECTROPHYSIOLOGICAL STUDIES
It is impossible from purely behavioural experiments conducted with neurologically intact subjects to specify with any accuracy the locus in the brain of those neural events which intervene between presentation of a stimulus and the occurrence of some response.
Modern techniques of electroencephalography (BEG), however, hold out the promise of localising the electrical activity of the brain in so far as this can be detected at the scalp.
Although identification of left or right hemisphere activity represents a fairly gross level of localisation it is sometimes possible to be more precise as to the area of brain that is active.
In any case, electrophysiological indices of functional brain asymmetry are useful in complementing the purely behavioural data.
In order to record the brain's activity at the scalp at least two electrodes are required.
The signal that is picked up is the difference in potential between the two electrode positions.
This signal is amplified many times and used to drive a pen recorder which traces out a wave form plotting voltage against time.
Ideally speaking, one of the electrodes should be at a site where no activity occurs at all and then the amplified signal would represent the total activity at the area of interest; in practice this state of affairs is difficult to achieve since no site is entirely free from underlying neural activity.
In investigations of cerebral asymmetry, therefore, electrode leads from various positions over left and right hemispheres are often linked to a common reference site at which underlying activity is unlikely to be affected by variables manipulated in the experiment.
Provided that the reference position is suitably chosen, this means that differences in potential between the common reference and each of the corresponding left and right hemisphere sites will be equal unless there is some asymmetry in activity between left and right hemispheres.
If so"it shows up as a difference in the wave forms obtained from one or more of the left and right hemisphere leads.
It is thus crucial to choose a common reference position that avoids any initial bias in potential difference between each of the hemisphere leads and the common reference.
The electrical wave forms recorded from the scalp can be broadly classified into two types.
One type consists of event-related potentials, the  other is ongoing EEG activity (Hillyard and Woods, 1979).
Event-related potentials, as the term implies, refers to the changes brought about when a subject is presented with a particular stimulus.
When the event precipitating the change is a visual or auditory stimulus under experimental control the resulting activity is referred to as the visual or auditory evoked potential.
This broad classification of EEG activity into ongoing and event-related is purely arbitrary since, as Hillyard and Woods (1979) point out, even ongoing EEG activity might be considered event-related if only the event concerned could be specified.
By definition, event-related potentials are time-locked to some stimulus or other  specifiable event.
As these changes in electrical potential may be very small in relation to fluctuations in ongoing EEG activity the usual procedure is to use a computer to sum the potentials during the half-second or so following each presentation of the evoking stimulus so as to produce an average value.
The principle here is that if particular changes in activity bear a constant relationship to the reference event they will show up against fluctuations of the ongoing EEG which, being "random" , should cancel out to zero when averaged over successive trials by the computer.
Despite the appearance given by the EEG of probing the machinery of the brain, electroencephalography is a relatively gross technique which tells us only that a population of neural units is active rather than quiescent.
It is difficult to localise with anything but a fair degree of accuracy the spatial locus of this activity.
When it is remembered that the brain is a three dimensional structure it will be appreciated that very precise localisation of the activity picked up by surface electrodes is rarely possible.
It is also worth pointing out that EEG recording is technically difficult and fraught with potential artefacts due to muscle movement (Grabow and Elliott, 1974), eye movement (Anderson, 1977) and possible left-right differences in skull or brain mass underlying the electrodes (Rubens, 1977).
Since a decrease in the alpha component of the EEG implies an increase in the underlying cortical activity, relative suppression of the alpha rhythm over one or other side of the brain has been taken to indicate selective hemisphere involvement during different cognitive tasks.
For example, differential suppression of alpha over the two hemispheres was observed by McKee, Humphrey and McAdam (1973) during the performance of verbal and musical tasks.
Similarly, Nava, Butler and Glass (1975) found relatively greater suppression over the right hemisphere when subjects performed a face recognition task and greater suppression over the left hemisphere when subjects attempted problems of mental arithmetic.
Such task-related changes in distribution of alpha activity have been reported by others (Morgan, McDonald and MacDonald, 1971; Galin and Ornstein, 1972; Morgan, MacDonald and Hilgard, 1974; Robbins, Dale and McAdam, 1974; Galin and Ellis, 1975; Galin, Johnstone and Herron, 1978; but see Mayes and Beaumont, 1977).
A frequent methodological problem in electrophysiological experiments has been that experimenters have either failed to exercise any control  whatever over their subjects' cognitive strategies or else have relied simply on instructions to subjects to engage in a particular mental activity.
Buchsbaum and Fedio (1970), for example, reported that the visual evoked response to lateralised presentation of words and nonsense patterns differed for the two types of stimuli, most markedly over the left hemisphere.
However, they exercised no control over their subjects' processing.
Beaumont and Rugg (1978), on the other hand, required subjects to perform a go/no-go discrimination task in which subjects responded either to the sound of visually presented letters or to their shape.
A left-right asymmetry in the latency of the first positive and second negative peaks was recorded which was not attributable to lateralised stimulus presentation per se.
Ledlow, Swanson and Kinsbourne (1978) carried out a similar study in that subjects were required to perform a same-different match to visually presented letters either on a physical or a nominal basis.
The results of this experiment were consistent with the view that EEG asymmetry can reflect hemispheric processing differences as distinct from effects due to mere stimulus presentation (Willis, Wheatley and Mitchell, 1979; Shucard, Cummins, Thomas and Shucard, 1981).
Even changes in a subject's preparatory "set" may be sufficient to reveal EEG differences between left and right hemispheres.
Butler and Glass (1974) required subjects to perform various mental operations when presented with numerical information.
Prior to each trial the contingent negative variation (CNV) was recorded.
This is a shift in negative potential which occurs when subjects are presented with a stimulus signalling some imminent event to which they must respond.
Butler and Glass found the CNV to be of greater amplitude over the left hemisphere in all of twelve right handed subjects and greater over the right hemisphere in a single left hander.
In a subsequent experiment, carried out only among right handers, the warning stimulus was followed by a verbal stimulus in one condition and by pictures of faces in other conditions.
The CNV following the warning stimulus was found to be of greater magnitude over the left hemisphere in the verbal condition and greater over the right hemisphere in the picture condition.
Butler and Glass therefore concluded that the CNV asymmetry relates to differential hemispheric activation rather than to handedness.
Some aspects of EEG activity, however, have been shown to vary with manual preference (Eason, Groves, White and Oden, 1967; Provins and Cunliffe, 1972).
The finding of Butler and Glass (1974) that the magnitude of the CNV was greater over the left hemisphere prior to a verbal task and greater over the right hemisphere prior to a facial discrimination task might lead one to expect that the direction of CNV asymmetry can be predicted on the basis of selective hemispheric involvement in particular tasks.
Donchin, Kutas and McCarthy,(1977) asked subjects to perform either a "functional" match or a "structural" match between items presented tachistoscopically.
Research with split-brain patients (Levy and Trevarthen, 1976), supported by results from normal subjects (Landis, Assal and Perret, 1979), suggests  that the left hemisphere matches stimuli on a conceptual basis (for example, a picture of a knife and fork "goes with" a picture of food) while the right hemisphere matches on a structural basis (that is two pictures which look physically similar will be matched).
In the experiment which Donchin et al.carried out subjects were forewarned which match they would be required to make.
In one set of trials the type of match required was varied from trial to trial while in a second set of trials the same match was required for a fixed number of stimulus presentations.
It was found that CNV asymmetry was greater in the former condition but the direction of asymmetry did not differ for "functional" and "structural" matches.
This could mean that the same hemisphere carried out both types of match.
Certainly Levy and Trevarthen in their study with split-brain patients argued that the "wrong" hemisphere was sometimes activated in preparation for a particular task.
Alternatively, it could be that the CNV does not reflect all relevant aspects of preparatory cortical activation.
This brings out the point that it is not always an easy matter to determine the functional significance of any given electrocortical event.
While not denying the clinical value of the EEG as a non-invasive technique it is probably fair to conclude that electro-physiological research has so far not contributed anything new to our knowledge of cerebral asymmetry but rather has corroborated findings from other areas of investigation.
However, there are situations in which the EEG may disclose lateralised phenomena which, because of their very nature, may not have been suspected on other grounds.
Morgan, MacDonald and Hilgard (1974), for instance, have related hypnosis to mediation by the right hemisphere and Cohen, Rosen and Goldstein (1976) claimed to show that sexual orgasm in humans is associated with increased amplitude of the wave form over the right but not the left hemisphere.
Recent reviews of electrophysiological analyses of hemispheric asymmetry have been compiled by Anderson (1977), Donchin, Kutas and McCarthy (1977), Thatcher (1977), Levy (1978), Marsh (1978), Hillyard and Woods (1979) and Rugg (1982).
The paper by Donchin et al.is a particularly good methodological critique of research in this area.
LATERAL EYE MOVEMENTS
When someone is asked a question, it is likely that before answering he will direct his gaze away from the questioner's eyes (Argyle and Cook, 1976) particularly if the question requires some thought.
Day (1964) noted that people are fairly consistent as to the direction in which they shift their gaze to break off eye contact.
Bakan (1971) proposed that the direction of lateral eye gaze reflects activation of the hemisphere opposite the direction of eye movement, movement to the left, for example, indicating activation of the right hemisphere.
Since electrical stimulation of the exposed cortex of one hemisphere can induce a deviation in eye gaze towards the opposite side  (Penfield and Roberts, 1959) it is conceivable that naturally occurring lateral eye movements reflect, at least in some circumstances, asymmetrical activity in the two hemispheres.
It follows from this proposition that manipulating differential hemispheric activity should induce changes in direction of lateral eye gaze.
Kinsbourne (1972) and Kocel, Galin, Ornstein and Merrin (1972) attempted to differentially engage the left and right hemispheres by asking different types of questions.
The direction of a subject's first eye movement following a question was recorded and found to be related to the type of question being asked.
Verbal questions tended to elicit eye movements to the right whereas questions of a spatial nature tended to elicit movements to the left.
Similar results have been reported by many but not all authors (see Ehrlichman and Weinberger, 1978) and support, but do not prove, a hemispheric activation model of lateral eye movements.
The issue as to whether lateral eye movements are an enduring characteristic of an individual, as thought to be the case by Day (1964), or whether they reflect transient shifts in hemispheric activation, as conceived by Kinsbourne, was taken up by Gur, Gur and Harris (1975).
These workers noted that in the studies by Kinsbourne (1972) and by Kocel et al.(1972) the experimenter was seated behind the subject, eye movements being recorded by means of a video camera, while in the situation described by Day (1964) subjects sat facing the experimenter.
Gur et al.therefore carried out a study to examine the possibility that this factor was crucial in determining whether lateral eye movements vary as a function of the type of question asked.
The results of this experiment showed that among right handers, gaze direction was not related to question type when the interviewer faced the subject but was so related when the interviewer sat behind the subject.
Left handers showed a consistent direction of movement in the experimenter-in-front condition, but no systematic relationship between direction of eye movement and question-type in the experimenter-behind condition.
It was therefore concluded that gaze direction is a function both of an individual's consistent tendency to rely on a particular half of the brain and of differential hemispheric arousal in response to specific experimental situations.
In order to explain the different findings obtained according to whether the interviewer sat behind or in front of the subjects, Gur (1975) suggested that when the interviewer sits opposite the subject the latter's anxiety level is increased which leads him to reply in a characteristic mode of thought.
Hiscock (1977) therefore attempted to manipulate anxiety level experimentally and thereby observe the interaction of this variable with the presence or absence of an experimenter.
It was found that anxiety level had no effect on the consistency or direction of eye movement or on the relative extent of left-right deviations of gaze in response to verbal and spatial questions.
Nor was there any significant difference in direction of gaze for the two types of questions unless specific items were picked out which apparently reflected most clearly the verbal-spatial distinction.
If it is true that verbal questions primarily engage the left hemisphere while spatial questions tap the functions of the right hemisphere, it might be predicted that responses to such questions will be optimal when the appropriate hemisphere is activated rather than if the opposite hemisphere is aroused.
Gur et al.(1975) analysed the data collected in their experiment with a view to seeing whether more accurate responses were given to verbal questions which were followed by eye movements to the right than to verbal questions eliciting leftward eye movements.
Similarly, for spatial questions it was predicted that more correct responses would occur in association with eye movement to the left rather than the right.
By and large, these expectations were confirmed.
The direction of subjects' lateral eye movements has been correlated with EEG alpha activity, consistent left movers showing a relatively greater degree of alpha activity (Bakan and Svorad, 1969).
Relative alpha activity has also been correlated with susceptibility to hypnosis (Bakan, 1969).
It was therefore hypothesised by Morgan, McDonald and MacDonald (1971) that subjects showing a predominance of left lateral eye movements in response to verbal and spatial questions would show a greater susceptibility to hypnosis than those with predominantly right lateral eye movements.
This predication was confirmed although Gur and Gur (1977) believe that this relation holds only for right handed, left eye dominant males.
It is claimed that left lateral eye movements reflect relatively greater right than left hemisphere activation.
It is also believed that activity in the alpha band of the EEG signifies a low level of cerebral activation.
It can be predicted, then, that if left lateral eye movers are highly susceptible to hypnosis in comparison with right eye movers, highly susceptible subjects should show the opposite direction of alpha asymmetry to less susceptible subjects.
However, Morgan, MacDonald and Hilgard (1974) were unable to relate hypnotic susceptibility to lateral asymmetry of alpha despite confirming that highly hypnotisable subjects show relatively more alpha activity than those less susceptible to hypnosis.
On the other hand it is worth mentioning that the hypothesis of decreased left hemisphere activity during the hypnotic state has been supported by other workers using different response measures.
Frumkin, Ripley and Cox (1978) found a reduced mean right ear advantage on a dichotic listening task during hypnosis compared with scores obtained before and after the hypnotic session.
With a partial split-brain patient as their subject McKeever, Larrabee, Sullivan and Johnson (1981) observed that the usual difficulty of naming objects presented to the left hand was considerably reduced under hypnosis.
This was seen tentatively in terms of reduced interference by the left hemisphere in right hemisphere speech mechanisms.
Gur, Gur and Marshalek (1975) discuss findings which suggest that people who typically move their eyes in a leftward direction prefer to sit on the right side of a classroom (looking towards the front).
Although these findings were considered in the context of differential hemispheric activation, they might more parsimoniously be thought to reflect no more than  the fact that people wish to be able to look at a blackboard in the middle of the room.
Sitting on the right side of the room means that left eye movements bring the centre of the room into view whereas right eye movements do the opposite.
People might simply be responding, albeit unconsciously, in a manner consistent with their usual direction of eye movements.
Because of the potential source of artefact of such factors as the spatial layout of a research laboratory Saring and Von Carmon (1980) had their subjects lie supine in a darkened room.
It was argued that this should have maximised any lateral eye movement asymmetry.
Although analysis of initial eye movements revealed no statistically significant effect of question type on direction of eye movement, the average frequency of all lateral eye movements in response to verbal questions was greater for movements towards the right.
Gross, Franko and Lewin (1980) asked whether involuntary eye gaze would influence the cognitive processing employed by subjects.
In other words these workers examined the usual question in reverse by asking not whether direction of eye gaze would reflect differential hemispheric, but whether forced direction of eye gaze would induce asymmetrical activation and hence determine choice of processing mode.
Subjects were asked to look either to the left or to the right while choosing the odd one out from among three Hebrew words.
The odd word could be chosen according to semantic or non-semantic criteria.
For example, of the three words "watch" , "clock" and "block" the odd word in terms of meaning is "block" but "watch" is odd in terms of rhyme.
Gross et al.found that when right handers were asked to look to the left while hearing such sets of words, decisions were made on non-semantic grounds significantly more often than when subjects looked to the right.
If semantic processing is considered characteristic of the left hemisphere these findings can be taken as supporting the idea that Involuntary direction of gaze may influence asymmetrical hemispheric activation.
Although lateral eye movements appear at first sight to offer a simple and straightforward way of assessing which hemisphere is active at a given Instant, the evidence relating eye movements to hemisphere function is at present rather insubstantial.
The fact that opposite directions of movement may in some circumstances be associated with different questions, considered a priori to encourage different types of cognitive activity, is not sufficient evidence to warrant the conclusion that opposite hemispheres are being engaged.
Different questions may vary not only in terms of verbal or spatial content but also in terms of degree of interest, emotion or imagery aroused in a subject.
Directional asymmetry in eye gaze may be related as much to these or other variables as to differential hemispheric activation.
What is desirable is to have independent evidence linking eye movements directly to functional cerebral asymmetry.
Electrophysiological measures suggest themselves in this context but the problem of artefact, that is, of actual or potential eye movements producing an asymmetry in the EEG  record (Anderson, 1977), would have to be circumvented.
In the absence of such direct evidence, a study by Lefevre, Stark, Lambert and Genese (1977) is of some interest.
These researchers presented a group of subjects with a verbal dichotic listening task and noted that subjects gave more rightward than leftward eye movements as well as showing the usual right ear advantage on the dichotic task.
A second group of subjects presented with a non-verbal dichotic task yielded a left ear advantage and more eye movements towards the left than towards the right.
While this does not prove that the first group of subjects were using their left hemisphere and the second group their right hemisphere the results are at least consistent with such a supposition.
A sex difference was also noted: males made significantly more left movements than right movements overall while females showed little difference.
By contrast, Beveridge and Nicks (1976) claimed that females tended to be left movers and males tended to be right movers.
The literature on lateral eye movements has been reviewed by Ehrlichman and Weinberger (1978) and the reader should consult their paper for a thorough critique.
These authors draw attention to a number of methodological problems as well as to difficulties of interpretation and theory.
With regard to methodology two main problems stand out.
These concern, first, the validity of items chosen so as to represent one or other cognitive mode and, second, the scoring of lateral eye movements.
Ehrlichman and Weinberger criticise the emphasis that has been placed on the first eye movements occurring after a question has been asked and the consequent ignoring of movements which occur prior to or during presentation of a particular item.
Furthermore, eye movements include vertical as well as lateral deviations of gaze and the general tendency to pay little or no attention to vertical eye movements may have important implications for interpretation of the data on horizontal movements.
Finally, as Ehrlichman and Weinberger point out, differences in the distance between subject and experimenter may well account for certain of the inconsistencies in the results reported by different investigators.
The topic of interpersonal distance has a copious literature in its own right (see Argyle and Cook, 1976) and it is to be expected that any effects due to hemispheric asymmetry will interact with social and personality factors in different ways under different circumstances.
DUAL TASK EXPERIMENTS
The final method of investigating hemispheric functional asymmetry in neurologically intact subjects involves analysing the effects of requiring two tasks to be carried out simultaneously.
The notion that the cognitive processing necessary for one task can be assessed by measuring the spare capacity available for allocation to a second task is one that has proved useful in several areas of psychology (Kalsbeek and Sykes, 1967).
This idea  is based on the assumption that the overall capacity of the organism is limited, an assumption that has, as it happens, been questioned (Neisser, 1973; Allport, 1980).
The dual task technique was first exploited within laterality research by Kinsbourne and Cook (1971) who asked their subjects to balance a dowel rod with the index finger of one hand whilst simultaneously repeating letters of the alphabet.
Concurrent verbalisation was found to reduce balancing times for the right hand but not the left hand.
This was explained by arguing that the neural mechanisms underlying both motor control of the right hand and the production of speech are located within the same cerebral hemisphere and thus the two tasks compete for limited neural space or processing capacity.
In contrast, such intra-hemispheric competition does not occur when balancing is carried out by the left hand since this is controlled from the right hemisphere.
The simple task devised by Kinsbourne and Cook (1971) was subsequently taken up and modified by other investigations.
The original findings have been replicated (Hicks, 1975; Johnson and Kozma, 1977) and an interpretation in terms of intra-hemispheric competition supported by evidence of impairment on various tasks carried out by the left hand when cognitive operations supposedly mediated primarily by the right hemisphere are performed (Kinsbourne, 1973; McFarland and Ashton, 1975; 1978a; Smith, Chu and Edmonston, 1977; Dalby, 1980).
The intra-hemispheric competition model predicts that since two tasks compete with each other both should be affected by interference (Bowers, Heilman, Satz and Altman, 1978).
This has rarely been reported.
Bowers et al., for example , found that although their cognitive tasks affected manual performance the reverse was not the case.
A manual task was, however, found by Botkin, Schmaltz and Lamb (1978) to affect the number of digits that could be repeated backwards.
Fewer digits were repeated when the right rather than the left hand was used to carry out a tracking task.
Lomas and Kimura (1976) examined the effect of concurrent vocalisation on different manual tasks.
They found that speaking interfered selectively with the right hand only under certain conditions.
These conditions were, firstly, when subjects had to depress each of four Morse keys rapidly in turn with each of the four fingers of one hand and, secondly, when a whole arm movement had to be made to depress each key in turn.
Since a performance decrement for both hands, rather than a lateralised impairment, was found when a single button was pressed repetitively with one finger Lomas and Kimura suggested that "it is the rapid positioning of a limb, or parts of a limb,…which is related to the lateralised decrement produced by concurrent speaking." 
Cremer and Ashton (1981) required subjects to alternately tap with a rod two small metal targets.
A concurrent verbal task interfered with the speed and consistency of tapping by the right hand while a visuo-spatial task interfered more with left hand performance.
Reducing the size and increasing the distance apart of the targets did not remove these lateralised  effects even though greater accuracy was required in hitting the targets.
These findings were held not to support the view expressed by Lomas and Kimura.
The effect of increasing task difficulty may be confined to one hand or affect both hands.
Nicks, Provenzano and Ribstein (1975) found that as subjects rehearsed increasingly difficult lists of words a deficit on a typing.
like task showed up first on the right hand and then spread to include the left hand.
comparable results have been reported by other authors (McFarland and Ashton, 1978b; Bowers, Neilman, Satz and Altman 1978).
However, Nicks,— Bradshaw, Kinsbourne and Feigin (1978) found that concurrent verbalisation increased response times for both hands on a typing task but more so for the right hand.
The magnitude of this asymmetrical effect increased with the difficulty of the typing task.
The effect of task difficulty in terms of whether a purely lateralised effect or a bilateral effect (symmetrical or asymmetrical with respect to the two hands) is observed thus appears to depend upon the nature of the two competing tasks.
It may be helpful at this point to distinguish between two possible sources of interference between concurrent tasks.
One source is competition for the same neural mechanisms of motor (including verbal) output.
The other is competition between two tasks for attention or cognitive processing capacity (see also Lomas, 1980).
Hellige and Longstreth (1981) asked subjects to tap with either the left or right index finger.
Concurrent reading reduced the rate of tapping more for the right than for the left finger.
This effect was greater for subjects reading aloud than for silent reading and larger again for subjects who were led to expect a test on what they had read.
It was therefore concluded that lateralisation effects are mediated by both motor and cognitive aspects of the tasks.
Similar results were reported by Bowers, Neilman, Satz and Altman (1978) who observed a bilateral but asymmetrical impairment on finger tapping when subjects merely had to listen to a story knowing that they would subsequently be asked to recall its contents.
Kinsbourne (1975a) argued that "both hemispheres draw upon and often compete for a finite amount of attention invested in the organism as a whole" .
Consequently attention may be distributed asymmetrically between the two hemispheres.
The effect of this, according to Kinsbourne, is that there is a bias in responding to the side of space contralateral to the hemisphere which has the greater share of attention.
Part of Kinsbourne's evidence for this view is that on tachistoscopic tasks for which no left.right hemifield asymmetry is normally observed concurrent verbalisation can induce a left.right difference in favour of the right visual hemifield.
On a task requiring the subject to detect and respond to a small gap in one of the sides of a square Kinsbourne (1973) found concurrent verbalisation to lead to a right hemifield superiority and humming to lead-to a bias in detecting gaps in the left visual hemifield.
Other authors, however, have failed to replicate these findings (Gardner and Branski 1976; Boles, 1979).
Nonetheless there is sufficient evidence to suggest that concurrent performance of certain cognitive tasks can in some circumstances alter left-right perceptual asymmetries (Kinsbourne, 1970; 1973; Hellige, 1978; Hellige, Cox and Litvac, 1979; Allard and Bryden, 1979; Rizzolatti, Bertolini and Buchtel, 1979; Beaumont and Colley, 1980)…
The problem is that the additional task has sometimes been found to facilitate performance in the visual field opposite the supposedly activated hemisphere and in other cases has been found to impair performance.
In cases of facilitation, this is "attributable to the beneficial effect on performance of increase in arousal when this is moderate in degree" according to Kinsbourne and Hicks (1978).
When the effect of an additional task is to disrupt rather than facilitate performance then the two tasks are said to compete for the same "functional space" within the hemispheres.
As Cohen (1979) has pointed out, Kinsbourne's theory has "too much explanatory power and too little predictive power" .
It is impossible to predict whether a particular task will help or hinder performance on a second task.
Hellige and Cox (1976) found a LVF superiority in tachistoscopic recognition of random forms.
When subjects had to concurrently hold in memory two or four nouns on each trial a superiority of the RVF emerged.
This would be predicted by Kinsbourne's theory of selective activation of the left hemisphere by a verbal task.
However, a concurrent memory load of six nouns markedly reduced recognition in the right visual field resulting in a LVF superiority which would not be predicted.
The conditions under which a concurrent memory load either facilitates or impairs performance on a primary cognitive task was further investigated in a series of experiments by Hellige, Cox and Litvac (1979).
To account for their complex set of results they proposed that a concurrent task may have either general effects, that is, influence performance by both hemispheres, and/or specific effects which are restricted to one particular hemisphere.
In one of their experiments, for example, subjects had to compare tachistoscopically presented random forms with a set of forms held in memory.
This yielded a LVF superiority in reaction time.
When either 2 or 6 words had also to be held in memory then reaction times for both hemispheres improved but more so for the left hemisphere than for the right hemisphere, leading to a RVF superiority.
It was argued that these findings reflected general activation of both hemispheres combined with specific activation of the left hemisphere.
In another experiment subjects had to match visually presented upper and lower case letters according to their names (nominal identity match).
There was a RVF advantage in reaction time for this task carried out alone.
However, when subjects had to concurrently remember 2,4 or 6 words the reaction time for both hemispheres improved, but that for the right hemisphere more than that for the left hemisphere, which resulted in a LVF superiority.
The explanation offered was that the facilitating effects of general arousal in the left hemisphere were offset by the cognitive load of remembering the set of words.
The problem with Hellige's formulation is that it can be used to explain any particular pattern of results but cannot readily predict them since the nature and difficulty of both primary and concurrent tasks needs to be taken into account.
For example, the effect of holding in memory a visual pattern made up by randomly filling in half the cells of a matrix (with either 3, 4 or 5 cells per side) did not produce "general activation" in the same way as words were found to do.
Instead, the performance of both hemispheres declined equally.
Whatever the difficulties of the model proposed by Hellige et al.it has the merit of illustrating how theoretical progress might be made through sets of carefully related experiments.
Progress will inevitably be slow but the dual-task technique offers the possibility of determining something of the nature of the dynamic interaction between the two hemispheres.
Due to the preoccupation of investigators with the issue of hemispheric asymmetry this most important problem has hitherto been immune from serious experimental attack.
All the methods in current use for investigating hemispheric asymmetry of function in normal subjects have now been described.
Of the six methods, tachistoscopic half-field presentation and dichotic listening have generated the largest amount of research.
This is partly because of the preeminent roles played by the senses of vision and hearing in Man and partly due to historical reasons.
Tachistoscopic and dichotic techniques have been employed in laterality studies for about two decades while the other methods described above were devised more recently.
Electroencephalography, it is true, had its origins in the nineteenth century but only in recent years has there been an acceleration of interest in lateralised electrophysiological phenomena.
Since visual field asymmetry and dichotic ear differences have both been claimed as indices of the same phenomenon — cerebral lateralisation of language — these two measures derived from the same set of subjects ought to correlate with each other.
A significant correlation was indeed reported by Hines and Satz (1974) but other studies (Bryden, 1965; Zurif and Bryden, 1969) have yielded low and insignificant correlations.
Fennel, Bowers and Satz (1977), for example, took pains to devise a tachistoscopic analogue of their dichotic task and still failed to find a significant correlation between the two sets of scores, although there was an increasing agreement over four testing sessions between the side of the ear advantage and the superior visual half-field.
THE MEASUREMENT OF LATERALITY
There has been some discussion in the literature as to the most appropriate way of expressing the degree of lateral asymmetry which a subject shows in an experiment.
A simple expression of the difference between left and right  ears or visual fields for each subject can be misleading since the same difference in scores may be obtained by subjects who differ in their overall level of accuracy.
Consequently, the same absolute difference score can represent different relative values.
An example should make this clear.
Imagine that Smith obtains a score of 20 correct responses at the left ear and 30 correct at the right ear.
His absolute difference score is therefore 10.
If/ones obtains 30 correct responses at the left ear and 40 correct at the right ear then his absolute difference score is also lo.
But Smith's right ear score is 50 per cent higher than his left ear score, while Jones's right ear is only one-third better than his own left ear.
In order to reflect a relative difference between the ear or half fields a laterality coefficient may be computed according to the formula
where R represents the number of correct responses for the right ear/visual field and I stands for the left ear/visual field.
By this means an absolute lateral difference is converted into a ratio measure.
In the example above, Smith would have a laterality coefficient of 0.20 while/ones would have a coefficient of only 0.14 It does not matter whether the score for the left side is larger or smaller than the score on the right since the sign of the coefficient, negative or positive, indicates the direction of any lateral advantage.
It was argued by Marshall, Holmes and Caplan (1975) that the degree of brain asymmetry underlying performance on a particular task is theoretically independent of the overall level of accuracy which a subject attains on that task.
These authors discuss data presented by Harshman and Krashen (1972) which show that the absolute difference between scores for left and right ears does in fact correlate significantly with the total correct score for the two ears.
Although Marshall et al.consider that in certain circumstances one would expect laterality scores to correlate with overall accuracy scores, they favour the use of an index of laterality that is independent of accuracy in the sense that the values which the index might take within the total range of values possible is not "constrained" by any given level of accuracy.
The meaning of this should become clear in considering the following indices which Marshall et al.rejected:
1.
Absolute difference scores;(R — L) 2.
Per cent correct (POC); R/ (R. + L) 3.
Per cent error (POE); L/ (R + L,)
where R, and L refer to the per cent correct score at the right and left ear or visual hemifield respectively and R and L refer to the per cent error score at each ear or hemifield.
The absolute difference score can range from + 100 to — 100 and POC and POE can each range from 1 to 0.
However, only if total accuracy is 50  per cent, i.e. (R + L) = 100, can (R — L) take all values from + 100 to — 100.
If, for example,(R + L) = 120 or 70 then (R — L) can never equal + 100 or — 100.
Similarly, POC is constrained above 50 per cent accuracy and POE is constrained below 50 per cent accuracy.
On the other hand, the value of (R — L) /(R + L) is not constrained at or above accuracy levels of 50 per cent and the value of (R — L) /(R + L) is not constrained at or below accuracy levels of 50 per cent.
Marshall et al.therefore recommend that one or other of these coefficients (which they refer to as "f" ) be used in laterality experiments — depending on the level of accuracy achieved.
Repp (1977) has argued similarly but Richardson (1976) considers choice of the "f" index to be as arbitrary as any other.
Despite the fact that it is the property of not being constrained by overall accuracy that most concerned Marshall et al.in choosing a laterality index subsequent authors have been interested in the statistical correlation between various indices of laterality and overall accuracy.
The phi coefficient proposed by Kuhn (1973), for example, has been shown by Levy (1977c) to correlate with overall accuracy.
(The value of phi is given by the formula
where R and L right and left ear scores respectively and T = total number of trials).
Similarly Hellige, Zatkin and Wong (1981) found the absolute difference score, POC, POE, f and phi coefficient to correlate very highly with each other and with total accuracy on a dichotic listening task.
It is, however, not surprising that this is the case since the same data are being used to derive both the laterality index and the total accuracy score.
Thus the statistical significance of the correlations should not be calculated with respect to an expected value of zero (Stone, 1980).
Yet this is what has been reported in the literature (Marshall et al., 1975; Birkett, 1977).
The search for a laterality index that is not biased with respect to accuracy recently led Bryden and Sprott (1981) to propose the adoption of a new index, lamda, based on the log odds ratios (P/ (l — P); P/ (l -P) where PR and P, are the respective probabilities of a correct response at the left and right sides.
As yet, however, there are no empirical data with which to evaluate the usefulness of this index.
The nature of the laterality index one chooses is intimately bound up with the sort of theoretical question one wishes to ask (Eling, 1981).
It has been argued, for example, that laterality should be measured only on a nominal scale (Colbourn, 1978) such that only the direction and not the magnitude of any laterality effect is taken into account.
Discussion of this point will be deferred until Chapter 14.
SUMMARY
This chapter reviewed techniques devised for investigating cerebral functional asymmetry in neurologically intact subjects.
Results using these techniques are in broad agreement with those of the split-brain studies and with findings obtained from patients with unilateral cerebral lesions.
However, it is not always clear what is being measured in a given situation.
Correlations between measures of tachistoscopic hemifield and dichotic listening asymmetry, for example, are low.
Laterality effects in normals are notoriously sensitive to experimental manipulations that ought not to be influential if what is being measured is some fixed attribute of cerebral organisation.
The lability of such effects can be accommodated by information processing or dynamic models of asymmetry but not by purely structural models.
There has been some discussion in the literature as to how left-right differences in performance should be measured.
Although different laterality indices correlate positively and significantly it has been argued that the index of choice is one that is not constrained at any level of accuracy.
Language and Laterality
The first observation that the left half of the brain is intimately concerned with the functions of speech is usually attributed to Broca (1861) although an unpublished manuscript noting a correspondence between defects of language and lesions of the left hemisphere was written by Dax in 1836.
Broca's (1861) contribution (for a review of the very early literature see Benton (1964)) was to identify the third frontal convolution of the left hemisphere as the "centre" for "articulate speech" .
Broca discovered during post mortem examination of the brain of a patient who had been dysphasic that this area, now known as Broca's area, was severely damaged.
Subsequently Wernicke (1874) drew attention to defects in the comprehension of language following damage to the posterior third of the superior temporal gyrus on the left side, now referred to as Wernicke's area.
A band of fibres, the longitudinal arcuate fasciculus, runs between Broca's and Wernicke's areas.
It has been argued that whereas damage to Wernicke's area produces defects of comprehension, and damage to Broca's area defects in the production of speech, damage to the arcuate fasciculus results in the syndrome of conduction aphasia.
The patient is able to understand, but not repeat, what is said to him.
This is attributed to the disconnection of the region responsible for understanding speech from the region responsible for organising the motor programmes for speech output (Geschwind, 1970; 1974).
Other regions of the brain, both cortical and subcortical, are implicated in language behaviour.
In particular, the role of the thalamus has increasingly come under attention (see Brown, 1975; Ojemann and Mateer, 1979a, and papers in Brain and Language, Vol. 2.
Number 1,1975) in recent years.
Yet as Brown (1979) points out we still do not have coherent model of the neural bases of language.
Despite considerable individual differences in the localisation of language in the brain (Brown, 1979; Ojemann, 1979; Gur and Reivich, 1980) the preeminent role of the left hemisphere in the majority of adults is not in doubt.
This chapter reviews the evidence bearing on this aspect of the cerebral organisation of language with particular reference to handedness.
Readers interested in other aspects of  the neurology of language are referred to papers by Geschwind (1964); Lenneberg (1967); Brown,(1979a, b) and Marin, Schwartz and Saffran (1979).
Evidence concerning language lateralisation comes from a variety of sources.
Unilaterally brain-damaged patients provide the classic source of data, beginning with Broca's observations in the nineteenth century.
More recently, other techniques have been devised which allow estimates to be made as to the hemisphere responsible for speech.
Some of these techniques are for use specifically with patients having, or suspected of having, some kind of damage to the brain.
Others are used with neurologically normal subjects.
The rationale behind them, and their limitations, were discussed in Chapter 4.
All of these techniques can be used to explore the relation between handedness and hemispheric specialisation for language.
Originally it was believed that the preferred hand was a reliable indicator of the speech-dominant hemisphere.
If an individual was right-handed, then speech was thought to be controlled by the left hemisphere; if he was left-handed, then the right hemisphere was considered responsible.
We now know that this is not necessarily the case, at least for left-handers.
Yet despite the development of the newer techniques for estimating speech dominance, the precise relation which left-handedness bears to the lateralisation of language is still not clear.
The issue is as much conceptual as empirical, having to do with the definition and measurement of handedness as much as with the demonstration of a hemisphere "dominance" effect.
This chapter reviews the evidence on the issue that has accrued from the different methodologies available.
Findings obtained with brain-damaged patients are discussed first, followed by the results of studies carried out with normal subjects.
It should be appreciated that hemispheric specialisation for language is not absolute.
Executive aspects of language appear to be more clearly lateralised than receptive aspects, but even this is not the whole story.
The chapter therefore closes with a review of findings concerning the linguistic ability of the right hemisphere.
UNILATERAL CEREBRAL LESIONS
Following Broca's (1861, 1865) analyses of aphasia in right.handed patients who had sustained lesions of the left frontal lobe, Jackson (1868) drew attention to the case of a left handed patient who had become aphasic following a presumed right.sided lesion.
Gradually there arose the belief that speech is always represented in the hemisphere opposite the preferred hand.
Although there were from time to time reports of "crossed aphasia" , in which the lesion is on the same side as the preferred hand (Bramwell, 1899), these were initially regarded as no more than occasional exceptions of the "contralateral rule" .
Even the finding that disturbances of speech were as likely to result from left as from right sided brain damage in  patients who showed no, strong preference for one or other hand was not considered to compromise this general rule (Chesher, 1936).
However, evidence (Humphrey, 1951) suggesting that left handers were more variable than right handers in their hand preference for different tasks led Humphrey and Zangwill (1952) to analyse the incidence of language disorders in a small group of left handers having damage confined to one or other side of the brain.
In contrast to the view that consistent left handers would become aphasic only with right sided lesions, Humphrey and Zangwill predicted that aphasia would occur from damage to either hemisphere, This expectation was confirmed, although there was a tendency for damage to the left hemisphere to result in more severe speech disturbances.
In subsequent studies it was shown that there are more sinistral aphasics with left than right hemisphere lesions.
(Goodglass and Quadfasel, 1954; Ettlinger, Jackson and Zangwill, 1956; Hécaen and Piercy, 1956; Brown and Simenson, 1957; Russell and Espir, 1961; Hécaen and Ajuriaguerra, 1964).
This difference is in the approximate ratio of 2:1 (Piercy, 1964; Roberts, 1969).
Gloning, Gloning, Haub and Quatember (1969) compared matched groups of right and non-right handed patients on a number of verbal tests.
No difference was found between the two groups with a lesion situated in the left hemisphere, but non-right handers, as a group, were significantly impaired on every test in comparison with right handers when the lesion was on the right side.
There were some striking differences among the non-right handers with lesions of the right hemisphere, depending on whether the left or the right hand was used for writing.
A higher frequency of transient expressive dysphasia was found among those who wrote with the right compared with the left hand.
Among left handed writers defects of verbal comprehension were more frequent than among those who wrote with the right hand.
These differences may reflect the influence of parental or pedagogic pressure to write with the right hand as compared with a natural predisposition to use the left hand.
Hécaen and Sauguet (1971) compared left and right lesion groups according to strength of manual preference, patients being divided into weak, medium and strong left handers.
With right sided lesions, language defects were found only in the group of weak left handers and were virtually absent among the strongly left handed.
Since weak left handers were observed to have sinistral relatives more frequently than strong left handers, Hécaen and Sauguet inferred that"the intensity of left handedness is not directly related to bilaterality of language representation or to familial left handedness.
Indeed, the opposite is the case".
More recently, however, Hécaen, De Agostini and Monzon-Montes (1981) have confirmed that as far as most language functions are concerned, cerebral bilaterality is associated with familial sinistrality rather than strength of hand preference, Nonetheless, some language functions, such as naming of objects, appear to depend upon the left hemisphere in both familial and non-familial sinistrals.
The fact that dysphasia in non-right handers occurs after right as well as left sided lesions implies either that language is represented in both hemispheres of non-right handers and/or that such people are more likely than dextrals to show right hemisphere lateralisation of speech.
If speech is indeed represented bilaterally in non-right handers then the frequency of aphasia consequent upon unilateral cerebral lesion should be higher in this group than among right handers.
Such has been reported to be the case by some authors (Subirana, 1969; Luria, 1970) but not by others (Russell and Espir, 1961; Newcombe and Ratcliff, 1973).
As the negative findings were obtained in studies of the effects of circumscribed missile wounds of the brain it may be that the positive findings are related to diffuse cerebral damage encroaching more frequently on the language areas of the brain.
A better prognosis for recovery among sinistrals than among dextrals (Subirana, 1958; Zangwill, 1960; Luria, 1970; Hécaen and Sauguet, 1971) can also be explained by the view that language is bilaterally, though not necessarily equally, represented in the two hemispheres of left handers.
THE WADA TEST
If speech is represented bilaterally in left handers, then it should be possible for this to be demonstrated in individual left handers.
Injection of sodium amylobarbitone (a barbiturate anaesthetic agent) into the common carotid artery results in the drug being circulated through the cerebral vascular system.
It has the effect of temporarily depressing the functions of the cortex, initially of the hemisphere on the side of the injection and subsequently of the opposite hemisphere.
If a patient is requested to hold up one arm and to count aloud during injection of the drug, the arm on the side contralateral to the side of injection collapses as the drug takes effect.
Similarly, if the drug is transported to the speech dominant hemisphere the patient stops counting.
He may be mute for some minutes and have difficulty in naming objects and carrying out commands for a little while thereafter.
By injecting the drug into the carotid artery on different days it is possible to observe the effect of disruption of left and right hemispheres alternately.
This is the basis of the test for hemispheric speech representation first described by Wada (1949).
A serious limitation of the Wada technique is that the risks inherent in puncturing the carotid artery preclude its use without obvious medical justification and testing is therefore restricted to those patients who are candidates for brain surgery.
A second limitation is that the duration of the effect with standard doses is confined to only a few minutes before the drug diffuses around the circle of Willis and into the opposite hemisphere.
This severely constrains the type of testing that can be carried out.
Sometimes there is a complete loss of consciousness, particularly, some have claimed, after injection on the left side (Serafetinides, Hoare and Driver, 1961; but see Rosadini and Rossi, 1967).
This is in accord with data suggesting that  impairment of consciousness occurs more commonly following acute cerebrovascular accident to the left  hemisphere compared to the right (Albert, Silverberg, Reches, and Berman, 1976).
Rasmussen and Milner (1975) summarise data collected in their clinic over a number of years' use of the Amytal test (see Wada and Rasmussen, 1960; Branch, Milner and Rasmussen, 1964).
Considering cases where there was no evidence of early injury to the brain, which may result in a shift of hemispheric dominance for speech (see Chapter 7), the test was carried out on 140 right handers.
Of these, 134 (96 per cent) patients had speech controlled from the left half of the brain and 6 (4 per cent ) had right hemisphere speech.
Among 122 non-right handers, left and mixed handers being considered together, 86 (70 per cent) patients had speech controlled from the left hemisphere, 18 (15 per cent ) had right hemisphere speech and in 18 (15 per cent ) speech was bilaterally represented.
The figure of 4 per cent of right handers with right sided speech is almost certainly an over-estimate of the extent of right sided speech among right handers in general.
The incidence of aphasia from right sided lesions in right handers among unselected series of patients is closer to 1 per cent than to 4 per cent(Levy, 1974a).
Furthermore, Rossi and Rosadini (1967), who also used the Amytal technique, reported that only one patient out of 74 right handers, all of whom received injections on both sides, did not have exclusively left hemisphere speech dominance.
The patients studied by Rasmussen et al.were all pre-selected for Amytal testing because there was some suspicion, based on the results of psychological tests or on the extent of left handedness in the patient's family, that the patient might have shown some departure from the typical dextral pattern of left hemisphere dominance.
Such pre-selection is sufficient to explain the relatively high proportion of dextrals with right hemisphere representation of speech in Rasmussen and Milner's data.
The data for non-right handers collected by Rasmussen and his colleagues show approximately two thirds of left handers to have left sided speech while the remaining third are divided between those with speech on the right side and those with speech represented bilaterally.
Among the latter there was sometimes a qualitative difference in the effects of amytal injection into the left and right carotid arteries.
Anaesthetisation of one hemisphere produced defects in naming objects but no discernible difficulty in tasks of serial ordering such as counting, saying the days of the week or reciting the alphabet.
Depression of the opposite hemisphere had the converse effect.
Rasmussen et al.combined their data for left and mixed handers, since their previous analyses had shown little or no difference between the two groups of patients.
As more data accumulate it may turn out that there are in fact subtle differences and that these relate to the presence or degree of sinistrality in the patient's family or to the position of the hand during writing (see below).
ELECTRICAL STIMULATION OF THE EXPOSED CORTEX
The work of Foerster in mapping the human brain by electrical stimulation of the exposed cortex was developed and extended by his pupil Penfield and associates, culminating in the monograph by Penfield and Roberts (1959).
Electrical stimulation has either positive or negative effects as far as speech is concerned.
A positive effect means that application of the electrode elicits some vocalisation whereas a negative effect either disrupts ongoing speech or produces an inability to vocalise or to use words properly.
It should be noted, however, that a positive effect has never been found to produce a single word, far less a complete utterance, the usual effect being a sustained or interrupted cry.
Penfield and Roberts (1959) give the following data for those of their patients who received electrical stimulation in Broca's area and/or in inferior parietal and/or posterior temporal regions of the left hemisphere during surgery carried out for the relief of focal epilepsy.
Of 65 right handed patients who had post-operative aphasia, 54 had shown some effect of stimulation on their speech and a further 10 out of 15 right handed patients showed aphasic arrest during cortical stimulation but had no post operative aphasia.
Stimulation affected speech in 3 left handers, of whom 2 had post-operative aphasia, while another 7 left handers showed no effect of stimulation and no aphasia after surgery.
All of these 7 patients had had cerebral birth injuries which might have induced a shift of dominance to the right hemisphere.
With stimulation of corresponding regions of cortex in the right hemisphere only one out of 14 right handers showed any effect of stimulation and none showed post-operative aphasia.
Six left handers were operated on the right hemisphere of whom one was affected by stimulation and also showed aphasia post-operatively.
Penfield and Roberts concluded from their data that "the left hemisphere is usually dominant for speech regardless of the handedness of the individual with the exception of those who have cerebral injuries early in life" .
This conclusion is thus somewhat at variance with that usually encountered in the literature.
However, the relatively small number of left handers without early birth injury who were stimulated does not permit of seriously challenging the accepted view.
Moreover, as Penfield and Roberts admit, the effects of cortical stimulation are not consistent since"electrical interference in a given area is only effective about 50 per cent of the time.
It cannot be assumed, therefore, that stimulation would not have had some effect on another occasion in those patients who were stimulated but showed no interference in their speech.
UNILATERAL ELECTROCONVULSIVE THERAPY
Psychiatric treatment for depression may involve administration of electric shock to the (anaesthetised) patient's head.
Although the rationale for this  treatment is somewhat arcane, dramatic results have been claimed.
The shock is usually administered either to both sides of the head or to the side considered on a priori grounds to be non-dominant with regard to language functions.
A number of studies have indicated that, in right handers, shock to the left side of the head impairs verbal learning, memory and word finding (Zamora and Kaebling, 1965; Gottlieb and Wilson, 1965; Halliday, Davidson, Brown and Kreeger, 1968; Fleminger, Horne and Nott, 1970; Pratt and Warrington, 1972) while shock to the right side is more likely to impair non-verbal functions (Cohen, Noblin and Silverman, 1968; Berent, Cohen and Silverman, 1975; D'Elia, Lorentzson, Raotma and Widepalm, 1976; Berent, 1977).
The first attempt to assess cerebral dominance for language in a group of non-right handed patients appears to have been that of Pratt, Warrington and Halliday (1971) who tested 12 right handers and 12 so-called left handers.
The criterion for inclusion in the "left handed" group was a greater preference of skill for the left hand in any one of four specified activities.
The test which best discriminated between the effects of left and right sided electro-convulsive therapy (ECT) after two treatments to each side was naming of objects after hearing a verbal description of them given by the examiner seven minutes after shock administration.
Eleven out of the 12 right-handers achieved higher scores after shock to the right side of the head, one patient showing no left-right difference.
Among the "left" handers 8 patients obtained higher scores after right sided ECT, 2 were better after left sided shock and 2 patients showed no difference.
Re-testing of the latter patients some twenty minutes after ECT indicated right hemisphere dominance for each of them.
In a later study carried out with left-handers classified in the same way as before Warrington and Pratt (1973) calculated language to be lateralised to the left hemisphere in 26 patients, to the right hemisphere in 9 patients and uncertain or bilateral in 2 patients.
Other investigators have looked at the effects of unilateral ECT in relation to handedness.
However, even considering all studies together, the numbers of non-right handers have been too few, and the criteria for classification of hand preference too simplistic, to allow any precise conclusions as to the relative proportions of left and right hemisphere speech dominant individuals to be drawn.
The most that can be said is that the majority of individuals said to be non-right handed still show left hemisphere language representation (Annett, Hudson, and Turner, 1974; Fleminger and Bunce, 1975; Clyma, 1975).
As a non-invasive technique ECT is a potentially useful method for estimating language laterality in individuals presumed to be without gross organic brain damage.
However, differences between left and right sided treatments in individual patients may be small (Annett et al.1974) and, of course, the procedure can only be used with those psychiatric patients for whom ECT has been chosen as the treatment of choice.
Moreover, the possibility that clinical depression may be particularly associated with  impaired function of the right hemisphere (see Chapter 12) means that there may be an inherent bias towards poor performance of the right hemisphere in depressed patients.
The use of appropriate control procedures is therefore doubly important in estimating speech lateralisation in such patients.
LANGUAGE LATERALITY IN NEUROLOGICALLY INTACT SUBJECTS
Electrophysiological studies
During the past decade or so a number of investigators have used electrophysiological techniques to study hemispheric specialisation of function, usually in right handers.
Schafer (1967) reported finding a significant asymmetry in the electrical activity of the brain immediately prior to speech production.
There were characteristic variations in waveform over the left temporal region as a function of different spoken letters, but no parallel changes were recorded over the corresponding region of the right hemisphere.
The specificity of such"cortical command potentials' (Ertl and Schafer, 1967) led Schafer to suggest that they might reflect the process of selecting particular speech sounds.
Subsequently McAdam and Whitaker (1971) demonstrated that prior to the production of various test words summed negative wave potentials were of greater magnitude over the left than the right hemisphere.
However, this work was criticised by Grabow and Elliott (1974) on the grounds that tongue movements may have contaminated the EEG recordings.
Grabow and Elliott therefore carried out an experiment similar to that of McAdam and Whitaker and found that movements of the tongue to left or right induced asymmetric scalp potentials which were not observed when subjects merely had to think of a word.
Cohn (1971) presented evidence that summated auditory evoked potentials show a greater amplitude of initial output over the right hemisphere with click stimuli but higher amplitude over the left hemisphere when subjects listen to monosyllabic words.
Similar findings with nonsense syllables as stimuli were reported by Morrell and Salamy (1971) and Morrell and Huntingdon (1972).
However, differential waveforms over the two hemispheres were recorded by Wood, Goff and Day (1971) only when their syllables required a linguistic analysis.
This result was interpreted in terms of meaningfulness' by Matsumiya, Tagliasco, Lombroso and Goodglass (1972) who showed in a separate study that inter-hemispheric asymmetry was greatest when subjects had to understand each stimulus word, and minimal when they could ignore the semantic content.
Teyler, Roemer, Harrisson and Thompson (1973) recorded evoked potentials when subjects simply thought of the meaning of words which could be used either as nouns or verbs.
Significant differences were found within each hemisphere for the two forms of the same word but an overall greater magnitude of response was recorded over the left hemisphere.
The above results confirm for right handers the asymmetrical involvement of left and right hemispheres in matters of speech production and perception.
The role of left handedness in this connection has not often been investigated although in more recent studies, relating to other aspects of verbal function, the question of handedness has been raised.
These studies were discussed in Chapter 4.
Dichotic listening and visual half-field studies
Several early experiments utilising the dichotic and tachistoscopic procedures with verbal tasks have shown that, as a group, left handers exhibit reversed or attenuated ear (Satz, Achenbach, Pattishall and Fennell, 1965; Satz, Achenbach and Fennell, 1967; Curry, 1967; Knox and Boone, 1970) or visual field (Bryden, 1965; Orbach, 1967; McKeever and Gill, 1972; McKeever, Van Deventer and Suberi, 1973; Hines and Satz, 1974) asymmetry as compared with right handers.
Similar effects appear with the dual task (Hicks, Provenzano and Ribstein, 1975; Lomas and Kimura, 1976) and lateral eye movement paradigms (Hicks and Kinsbourne, 1978).
These group effects are due to the fact that within-subject laterality differences are often smaller among sinistrals than among dextrals (Curry, 1967; Curry and Rutherford, 1967; Klisz and Parsons, 1975) and sinistrals show more reversals of the "typical" dextral pattern (Curry, 1967; Curry and Rutherford, 1967; Bryden, 1975).
In the light of certain of the clinical evidence it might be expected that one factor influencing the direction or degree of perceptual asymmetry obtained in laboratory experiments among left handers would be their degree of sinistrality.
The results are conflicting.
Some authors have reported finding a greater proportion of subjects showing a left ear advantage among strongly, compared with weakly, sinistral subjects (Satz, Achenbach and Fennell, 1967; Lishman and McMeekan, 1977; Geffen and Traub, 1979) although Dee (1971) reported the reverse.
In terms of group mean scores McKeever and Van Deventer (1977b) found no effect of degree of either left or right handedness but Searleman (1980) found strong left handers to show significantly smaller phi-scores, indicating reduced asymmetry, than weak left handers.
Conversely, strong right handers showed significantly higher phi-scores than weak right handers.
One reason for the conflicting results may have to do with other uncontrolled, variables in some of these studies.
It is, for example, becoming clear that a family history of left handedness is in some way related to the cerebral organisation of functions.
THE ROLE OF FAMILIAL HANDEDNESS
Clinical studies
Hécaen and Sauguet (1971) classified brain damaged left handers according to whether or not they had one close left-handed relative.
Disturbances  of spoken language were found with lesions of the right hemisphere only among those with at least one sinistral relative.
The severity of impairment did not differ from that seen after left-sided lesions.
Among patients with damage to the left hemisphere those with left handers in their immediate family were superior on a number of written, verbal tasks.
Zangwill (1960) had earlier expressed the opinion that
just as left handers are as a rule more variable in their hand preferences, so too are they less completely lateralised at the cerebral level.
Hécaen and Sauguet, however, argued that their findings suggest that "cerebral bilaterality is present only in the familial type of left handers" .
Consistent with this view, Hécaen, De Agostini and Monzon-Montes (1981) recently reported that disorders of language follow lesions of either hemisphere more often among left handers with at least one sinistral relative.
Unlike Hécaen and Sauguet (1971), Newcombe and Ratcliffe (1973) showed familial left handers to be impaired on tests of language more than non-familial sinistrals.
They also found 5 out of 12 non-familial sinistrals to be dysphasic after right sided lesions in comparison with the absence of aphasia in 6 familial sinistrals.
Thus the findings of Newcombe and Ratcliffe do not confirm those of Hécaen and Sauguet.
Since the patients in Newcombe and Ratcliff's study sustained penetrating missile wounds of the brain whereas those of Hécaen and Sauguet suffered from naturally occurring lesions it is possible that aetiological differences account for the discrepant findings.
Dichotic listening studies
Lishman and McMeekan (1977) analysed dichotic listening data from neurologically intact subjects in terms of familial sinistrality and found, particularly for females, that among strongly left handed individuals with left handed relatives the mean laterality ratio was significantly reduced in comparison with left handers without familial sinistrality.
It was concluded that bilateral speech representation applied only to strong left handers with left handed relatives.
Since bilateral speech need not imply that speech functions are distributed equally between the hemispheres this does not necessarily conflict with the finding that the proportion of subjects showing a left ear advantage was highest among the strongly left handed.
Dee (1971) observed that left handed subjects with sinistral relatives showed, as a group, a left ear advantage while subjects without left handedness in their pedigree showed a right ear advantage on a verbal dichotic task.
Comparable findings were reported by Zurif and Bryden (1969).
However, Geffen and Traub (1979) found an increased incidence of right ear advantage on their dichotic monitoring task in left handed males with at least one sinistral relative in comparison with non-familial sinistrals.
Briggs and Nebes (1976) found no effect of familial handedness but nor did they find any effect of handedness per se.
Tachistoscopic studies
Results using the tachistoscopic paradigm and a variety of verbal tasks are as conflicting as those obtained with the dichotic technique.
Zurif and Bryden (1969) report that a group of familial sinistrals showed no significant visual field differences but non-familial sinistrals showed a strong and consistent significant right hemifield superiority on each of a number of verbal tasks.
McKeever, Van Deventer and Suberi (1973) reported left handers with a positive family history to show a RVF superiority where non-familial left handers showed no significant difference between fields.
Higgenbottam (1973) obtained comparable results in as much as the greatest RVF superiority was shown by his familial compared with non-familial sinistrals.
By contrast, McKeever, Gill and Van Deventer (1975) found minimal half-field asymmetry in a group of 5 familial left handers as did McKeever and Jackson (1979).
No asymmetry for non-familial sinistrals and a RVF superiority for familial left-handers were reported by Schmuller and Goodman (1979).
One of the reasons underlying the inconsistent results with regard to the effect of familial sinistrality might be that this factor is likely to be confounded with family size (Bradshaw, 1980).
The chance of recording a positive family history of sinistrality was found by Bishop (1980b) to increase with the number of siblings respondents said they had.
Another factor is that neither definitions of a positive family history of left handedness, nor methods of enquiry (e.g. self-report by family members versus questionnaire responses by subject) have been consistent across studies.
Familial sinistrality in dextrals
Among right handers, Hines and Satz (1971) obtained a significant tachistoscopic RVF superiority, at least at certain rates of stimulus presentation, among right handers having left handed relatives; a non-significant LVF advantage was obtained for right handers without a positive family history of sinistrality.
However, Hines and Satz (1974) did not replicate the effect of familial sinistrality.
McKeever and his co-workers obtained a significant RVF superiority only in dextrals without left handedness in the family, those with sinistral relatives showing the same pattern as left handers, that is non-significant field differences (McKeever, Gill and Van Deventer, 1975; McKeever, Van Deventer and Suberi, 1973).
Hannay and Malone (1976) found right handed females without familial sinistrality to show, for certain retention intervals, a significant RVF superiority while right handers with left handed relatives showed a slight, non-significant RVF superiority.
There is a measure of agreement from the above studies that in right handers the presence of left handedness in the family is associated with a shift in tachistoscopic asymmetry on verbal tasks away from a strong RVF superiority.
Comparable findings have been reported for a dichotic listening  task with children (Harter-Craft, 1981) and for adult dual-task performance (Hicks, 1975, but see Wolff and Cohen, 1977).
If this is seen as suggesting reduced left hemisphere language representation in those with sinistral relatives it would be consonant with the findings from brain damaged right handers indicating greater bilaterality of verbal functions (Hécaen et al., 1981) and increased recovery from aphasia (Luria, 1966; 1970; Hécaen and Sauguet, 1971) in association with familial sinistrality.
Familial handedness and non-verbal performance
Hécaen et al.(1981) reported with regard to spatial performance that deficits occurred only after right sided lesions in familial left handers.
Thus in contrast to bilateralisation of language functions in this group spatial performance is more distinctly lateralised.
However, tachistoscopic half-field studies with normal subjects suggest that for sinistrals the presence of familial left handedness reduces perceptual asymmetry for non-verbal as for verbal tasks (Gilbert, 1977; Albert and Obler, 1978) or shifts the asymmetry in the direction opposite to that for dextrals (Schmuller and Goodman, 1980).
Similar effects for both dextrals and sinistrals were noted on a lateralised tactile spatial task by Varney and Benton (1975).
Keller and Bever (1980) asked right handed subjects to categorise musical intervals presented monaurally and obtained a significant REA in non-musicians for this task and a non-significant left ear advantage among musicians.
Having left hand relatives affected this ear difference among musicians but not among non-musicians.
Musicians without sinistral relatives showed a greater and statistically significant left ear advantage compared to those with a positive family history of left handedness who showed a non-significant REA.
On balance then, familial sinistrality seems to be associated with bilateral representation of non-verbal as well as verbal functions.
INHERITANCE OF LANGUAGE LATERALISATION
The evidence reviewed above, albeit inconsistent, concerning the influence of familial sinistrality on both lateral asymmetry in perception and the effects of brain damage, suggests the possible role of genetic factors in determining speech lateralisation.
In view of the relationship between handedness and the cerebral organisation of speech recent genetic theories of handedness (reviewed in Chapter 2) do, in fact, make explicit statements regarding the genetic control of speech lateralisation.
Observations of prenatal neuro-anatomical asymmetry in language-related areas of the brain constitute indirect evidence in favour of a genetic blue-print but it is not yet certain that the anatomical asymmetry actually relates to functional asymmetry after birth.
Data on the hereditability of hand preference do  not address directly the issue of speech laterality.
What is required, therefore, is a study aimed specifically at determining the inheritance or otherwise of speech lateralisation.
Bryden (1975) used dichotic listening as an index of speech lateralisation in 49 families.
In terms of a laterality score there was a positive and significant correlation between the scores for spouses and between scores for mothers arid their children.
There was a negative correlation between the scores for siblings (p0.10).
Bryden tentatively argued that the latter correlation indicated that in terms of dichotic listening asymmetry one is not dealing with something under genetic control".
However, it is difficult to conclude anything at all from a correlation, particularly one which is barely significant.
In any event, if a negative correlation for siblings implies non-genetic control of dichotic listening asymmetry what are we to make of the positive (and significant) correlation for spouses?
What conceivable genetic mechanism could account for this?
Genetic models are often tested using twins on the basis that monozygotic (MZ) twins have identical genetic make-up whereas dizygotic (DZ) twins do not share genetic material to the same extent.
Phenomena under genetic control, therefore, are expected to show greater similarity in MZ than in DZ twins.
Springer and Searleman (1978) gave a dichotic listening test to 35 D7 and 53 MZ pairs of right handed twins.
Ho evidence was obtained to suggest a higher concordance in MZ than in DZ twins for any of several measures of laterality, including direction of ear asymmetry (regardless of magnitude) and strength of handedness.
The data therefore suggest that variation in direction and degree of dichotic listening scores is non-genetic in origin.
But, if so, the fact that twins with a left hander in their immediate family showed a significantly smaller ear asymmetry (and lower overall score) than twins without a family history of sinistrality is not readily explained, at least within traditional Mendelian models of inheritance.
DOMINANCE PROPORTIONS
The question arises as to the relative proportions of left and right handers in the general population with left sided, right sided and bilateral speech representation.
The techniques used with normal subjects give estimates that do not closely correspond to those derived from the clinical literature.
For example, of a group of normal right handers as many as 15 per cent usually fail to show a right ear advantage on a verbal dichotic test (Bryden, 1978).
If a left ear advantage, per se, were considered indicative of right-sided speech then up to this proportion of right handers would be classified on such a test as having right hemisphere speech.
This proportion is very much higher than estimates based on the effect of unilateral cerebral lesions or the Amytal test (but see Wexler, Halwes and Heninger, 1981).
Given the level of reliability of dichotic listening scores (see Chapter 4)
the lack of correspondence between the normal and the clinical literature should not be surprising.
Satz (1977) has exposed the folly on probabilistic grounds of inferring right sided speech dominance in an individual with a left-sided ear advantage.
He estimates (using parameters derived from the brain damaged population) that though the probability of left sided speech given a right ear advantage is 97 per cent, the probability of right sided speech given a left ear advantage is only 10 per cent .
Hence, in view of the dubious validity of interpreting dichotic and tachistoscopic asymmetry in terms of left and right hemisphere speech dominance, recourse must be made to estimates based on samples of brain damaged patients, but here, too, problems arise.
These are ably discussed by Levy (1974a).
Hemisphere dominance for speech can be inferred from either the presence or absence of aphasia following a unilateral cerebral lesion.
Thus a left sided lesion in association with aphasia implies (at least some degree of) left hemisphere speech control.
Similarly, the absence of aphasia following an appropriately localised right sided lesion also implies left sided speech.
Dominance proportions, then, can be inferred in at least three ways:
1.
All individuals with unilateral lesions are assessed for the presence of aphasia, or 2.
Only individuals with lesions in the so-called language areas are considered, or 3.
The relative frequency of left and right sided lesions among the total aphasic population is calculated.
A logical problem arises with all three methods.
It is that if speech can be bilaterally represented, then damage to the speech areas of one side could conceivably occur without any ensuing aphasia.
Dominance would then be ascribed incorrectly only to the non-lesioned hemisphere.
However, the amytal studies appear to rule out the force of this logical objection since in cases of bilateral speech some difficulty has been noted with injection on either side.
Indeed, that is the very reason for assuming bilateral speech in the first place.
The observation required to give empirical "flesh" to the logical"bones' of the possibility just outlined would be that of observing no speech disturbance with injection on either side.
Provided the dose of the anaesthetic is sufficiently large this does not seem to have happened.
Having dismissed the logical difficulty there is an empirical problem as far as methods 1 and 2 above are concerned.
If there is a bias in the proportions of left and right lesions entering the series of patients in the literature then this will influence the dominance proportions inferred for the normal population.
There is evidence that there is such a bias (Satz, 1979).
This is due probably to the fact that people suffering from aphasia are more likely to come to the attention of a neurologist than individuals suffering from certain kinds of right hemisphere damage which may pass unnoticed by the individual himself such that he does not seek medical attention or is not referred for neurological investigation.
Levy (1974a) suggests as a solution to the problem of bias that one should estimate dominance proportions from the relative frequency of left and right sided lesions among non-aphasic brain-damaged patients.
Using this method and the data of Goodglass and Quadfasel (1954) she estimates language laterality in left handers to be predominantly or exclusively left-sided in 60 per cent of cases and right sided in approximately 40 per cent.
These proportions are not, in fact, significantly different, statistically speaking, from the proportions based on the same series and calculated according to methods 2 and 3 above, which each give estimates of 53 per cent left hemisphere speech among left handers.
Roberts (1969) calculated from a number of different series that approximately 63 per cent of left handed aphasics had left-sided lesions.
Considering the data available Levy considers 56 per cent as a reasonable compromise estimate of the frequency of left sided speech in sinistrals.
(Her method of analysis does not, it will be noted, allow her to identify the proportion of sinistrals with bilateral speech.)
With regard to right handers, Levy quotes a personal communication from Bogen to the effect that only two cases of aphasia in association with left hemiplegia occurred in 600 consecutive cases of stroke-induced aphasia, giving an estimate of 0.33 per cent right sided speech representation in right handers.
She considers this to be a more realistic figure than other estimates which might be based on the literature since there is probably a tendency to over-report cases of crossed-aphasia (i.e. presumptive lesion and preferred hand on the same side) in dextrals because of their rarity.
Levy's computations ignore the data from the sodium amytal test which suggest that at least some proportion of left handers have speech represented bilaterally.
Satz (1979) has proposed a method for determining the acceptability or otherwise of models of speech representation in the left and right handed.
He considers three possibilities.
These are that: I. speech is entirely unilateral; 2. it is entirely bilateral; or 3. it may be unilateral in some cases and bilateral in others.
He tabulates data from 12 published studies which show the frequency of aphasia after left and right sided lesions.
The overall reported incidence of aphasia in the left handed varied from a low of 0.3 (Newcombe and Ratcliff, 1973) to a high of 0.9 (Chesher, 1936), the mean value being 0.6.
Among right handers the lowest frequency reported was 0.33 (Penfield and Roberts, 1959), the highest was 0.38 (Hécaen and Ajuriaguerra, 1964) and the mean was 0.35.
Thus the mean frequency of aphasia for left handers was almost twice as great among left handers as right handers.
Given the assumption that aphasia always occurs after damage to the speech-dominant hemisphere (which, of course, will not be the case where damage is restricted to regions outside the language areas of the brain) it is possible to estimate the expected upper limit (EUL) for the frequency of aphasia generated by a particular model of speech dominance in the population.
If the EUL is exceeded by the empirically determined proportions then the model can be rejected.
Satz considered the unilateral model  first and took as examples of left and right sided speech in right handers the values of 96 and 4 per cent respectively.
(He quotes this figure as "empirically estimated" , citing as a reference a paper presented at a conference by one R. Milner.
As these figures are identical to those given for the Amytal test by Rasmussen and B. Milner (1975) it is presumably these data to which he refers).
Assuming that of 100 brain damaged individuals 50 have left sided and 50 have right sided lesions, the expected upper limit for the frequency of aphasia will be 48 plus 2, that is, 50 per cent .
In fact, on a strictly unilateral model the exact figures used for estimating the EUL are immaterial.
Assuming L and R lesions occur with equal frequency, and that a lesion in the speech hemisphere will always produce aphasia, the EUL will always be 50 per cent.
Since the observed frequency of aphasia in right handers is well below this figure, the model of unilateral speech dominance for right handers is, according to Satz, at least viable.
The same cannot be said for left handers since the mean observed frequency is greater than 50 per cent.
The strictly unilateral model can therefore be rejected for left handers.
There remain the possibilities that all left handers have bilateral speech representation (which would give an EUL of 100 per cent) or that some left handers have bilateral speech and others have unilateral speech.
No one has suggested that all left handers have bilateral representation of speech but the distribution of speech representation in sinistrals can be estimated on the grounds of the Amytal test as 70 per cent left sided, 15 per cent right sided and 15 per cent bilateral.
On these figures the EUL of the frequency of aphasia is 35 per cent(those with left speech representation) + 7.5 per cent (those with right sided speech) + 15 per cent (those with bilateral speech) = 57.5 per cent .
According to Satz (1980) this incidence is exceeded in the majority of papers which report relative data for left handers.
He therefore suggested that a model based on a higher proportion of sinistrals with bilateral speech than 15 per cent would provide the only model not rejected by the observed incidence.
The question of exactly which left handers have speech located on one side of the brain or the other and which of them have speech represented bilaterally cannot yet be answered unequivocally.
If the conclusion of Hécaen and his colleagues (Hécaen and Sauguet, 1971; Hécaen, De Agostini and Monzon-Montes, 1981) that familial left handers have bilateral speech, is accepted there is still the problem of distinguishing between those sinistrals with speech on the left side and those with speech on the right.
The amytal data do not appear helpful in this context.
The results reported have combined data from mixed and left handers, since according to Rasmussen and Milner (1975) there is no difference between them.
According to Annett (1975) the incidence of left or right sided speech representation among sinistrals should be considered a function of the proportion of sinistrals in the population at large.
This in turn depends upon the criterion used to establish left handedness.
Her theory (discussed  in Chapter 2) postulates that the general population may be conceived as made up of two overlapping distributions (see Fig. 1, Chapter 2).
These two distributions (of differences in skill between left and right hands) consist of those individuals in whom the right shift factor biasing the left hemisphere towards subserving speech, and coincidentally favouring greater skill of the right hand, is present (RS +) and those in whom it is absent (RS).
Given a fixed overlap between these two sub-populations the criterion of sinistrality can vary.
Now, individuals with right-sided speech constitute one half of those in whom the right shift factor is absent since in the absence of this factor speech dominance is distributed between left and right hemispheres according to chance expectation.
However, the proportion of RS — individuals among left handers must be proportional to the left handers in the total population.
This is because increasing the proportion of left handers in the overall population by shifting the criterion to the right takes in a larger segment of the RS — distribution, but this segment constitutes a changing proportion of the number of individuals to the left of this criterion (i.e. the left handers).
Thus the extent of right brainedness among left handers is seen to be a function of the position of the criterion used to classify sinistrality.
HAND POSTURE
The suggestion was discussed in Chapter 2 that the manner in which a pen is held in the hand during writing may be used as an index of speech lateralisation.
This idea was put forward by Levy and Reid (1976; 1978) who employed tachistoscopic verbal and spatial tasks and found in 70 out of 73 subjects that the direction of presumed cerebral lateralisation was predicted by handedness and hand posture.
Specifically, for the verbal task, subjects had to report 3-letter nonsense syllables presented in either the left or right hemifield and, for the spatial task, they had to locate the position of a dot in a rectangle exposed within one or other visual field.
It was claimed that among subjects with a normal (non-inverted) writing posture, language and spatial functions were lateralised to the contralateral and ipsilateral hemispheres respectively.
The reverse pattern held for subjects who wrote with an inverted posture.
Support for Levy and Reid has not been unequivocal.
Volpe, Sidtis and Gazzaniga (1981) observed four left handed patients who had been given the Wada Sodium Amytal test.
Three of these patients had left hemisphere speech and wrote with their left hand in the upright position; the fourth patient wrote with a hooked posture and had right hemisphere speech.
These results are entirely contrary to those predicted by Levy and Reid's hypothesis.
Using normal subjects Beaumont and McCarthy (1981) found a dichotic right ear advantage among right handers but no asymmetry among left handers.
There was no difference in ear scores among the latter subjects between those who wrote with the hooked and upright postures.
Lawson (1978) used a face recognition task which yielded a LVF advantage for right handers and a RVF superiority for left handers.
Within each handedness group the difference between female inverters and non-inverters was in the direction opposite to that predicted by Levy and Reid but, for males, the difference was in the predicted direction.
In terms of vocal reaction time Bradshaw and Taylor (1979) found that inverted sinistrals showed a weaker RVF superiority than non-inverters.
According to Levy and Reid the latter should have shown a LVF superiority.
Levy and Reid (1978) also argued, on the grounds of their tachistoscopic data, that inverted sinistrals are less lateralised for language than are non-inverted sinistrals.
That is, the specialisation of the left hemisphere for language among inverters was assumed to be less complete than the right sided specialisation of non-inverters.
Todor (1980) predicted that this would hold true for other tasks mediated by the language hemisphere and he therefore required his subjects to carry out a sequential motor task.
He hypothesised that left handers who employed the upright posture (indicative of contralateral cerebral lateralisation of language) should perform better with the left hand than inverted sinistral writers.
He found this to be the case.
Warshal and Spirduso (1981) argued that if inverters are less lateralised for language than non-inverters then differences between the left and right hands during performance of concurrent verbal-manual tasks (see Chapter 4) should be smaller for inverters.
This prediction, too, was supported but the pattern of results shown by right handers (non-inverters) was closer to that of left inverters than to that shown by left non-inverters, which would not have been expected on Levy and Reid's hypothesis.
Since inversion of the writing hand has been hypothesised to correlate with reduced lateralisation of brain functions it would be expected that there is a relation between inversion and familial sinistrality which also appears to relate, albeit inconsistently, to reduced perceptual asymmetries.
McKeever (1979) but not Searleman (1980) reports that inversion is significantly more frequent among left handers with sinistral relatives than among non-familial left handers.
However, in the study by McKeever, hand posture per se did not discriminate between left handers on a laterally presented word recognition task although the presence or absence of a family history of left handedness did so.
Familial left handers showed a greater RVF superiority, the group-by-visual field interaction being significant (at least with unilateral trials).
On a colour naming task, by comparison, inverted writers showed a significant RVF superiority where non-inverters showed no significant difference (interaction significant), but as inverters were more often of the familial type of left hander this result might equally as well be due to familial sinistrality.
Levy and Reid's model has been evaluated by Weber and Bradshaw (1981).
These authors find empirical support to be lacking for the basic postulates of the theory which Levy and Reid derived from their original  observations.
A particular difficulty would seem to be that the proportion of left handed inverters found in the general population does not correspond to the proportion of sinistrals estimated on other grounds to have left hemisphere speech (Searleman, Tweedy and Springer, 1979) although it must be admitted that the range of estimates of both proportions has varied quite widely and there is at least some overlap.
Another difficulty is that Levy and Reid make no suggestion as to how sinistrals with bilateral speech representation might be identified.
However, in a recent reply to Weber and Bradshaw (1981) it was suggested by Levy (1982) that the earlier findings she reported with Reid may relate not so much to language (or speech) representation in general as to reading and writing — that is, visual aspects of language, in particular .
There is little or no reason to suppose that these are represented bilaterally in any or all left handers.
It is not obvious how the neural control of speech differs as between well-lateralised individuals and those with bilateral speech representation.
Although it is clear that the left hemisphere is dominant not only for speech but also for verbal memory and reasoning generally (Meyer and Yates, 1955; Meyer, 1959; Milner, 1962, 1971; Lansdell, 1968, 1969, 1973; Benton, 1968; Newcombe, 1969, 1974; Buffery, 1974) the nature of hemispheric control of speech output is still somewhat obscure.
The vocal musculature is innervated bilaterally.
That is to say, anatomic connections are present between the tongue, larynx, lips (and other structures) and the two sides of the brain (Espir and Rose, 1976).
It has therefore been suggested that the lateralisation of language to one hemisphere is to prevent inter-hemispheric competition in the control of speech.
Indeed, at one time it was believed that requiring a natural left hander to use his right hand for writing would induce speech defects, such as stuttering, as a result of coopting the left hemisphere into language functions in competition with the right hemisphere (Travis, 1931).
Although this idea of hemispheric competition is not very precise, a number of studies have been carried out to investigate speech lateralisation among stutterers.
STUTTERING
Jones (1966) carried out the Wada test with four patients who had stuttered from childhood, and found all four to have bilateral speech representation.
After surgery (for lesions in the approximate speech areas) the stammer cleared and Wada testing revealed no difficulty with speech after injection on the side ipsilateral to the surgical removal.
With the anaesthetic introduced on the opposite side, the usual speech impairment was observed.
This might be taken to imply that the surgery had prevented one side of the brain from attempting to assume control of the mechanisms for speech output.
However, other reports using the Wada technique have provided little evidence to suggest that bilateral speech production is a  significant feature of all cases of stuttering (Andrews, Quinn and Sorby, 1972; Luessonhop, Boggs, Labowit and Walle, 1973; Dorman and Porter, 1975).
Studies using the tachistoscopic (Moore, 1976), dichotic listening (Curry and Gregory, 1969; Brady and Berson, 1975; Rosenfield and Goodglass, 1980) and electroencephalographic (Moore and Lang, 1977) techniques have sometimes, but not always (Slorach and Noehr 1973; Pinsky and McAdam, 1980), suggested that a greater proportion of stutterers than controls have some language processes lateralised in the right hemisphere.
Sussman and McNeilage (1975a) argued that whereas receptive aspects of language are lateralised to the left hemisphere, production of language is not so clearly lateralised in stutterers as it is in normals.
Wood, Stump, McKeehan, Sheldo and Proctor (1980) compared patterns of regional cerebral blood flow in two cases of stuttering.
While off medication, both subjects showed high levels of blood flow in anterior regions of the brain at the right side; with stuttering controlled by haloperidol, the flow of blood was greater in the left hemisphere.
However, the situation is not simply that the right hemisphere is more implicated than usual in the production of speech.
The two patients of Wood et al.showed no stuttering, and the usual blood flow asymmetry favouring the left side, when they had to read aloud a passage of prose.
Thus it seems to be not so much the articulation of words per se that engages the right hemisphere in these patients but the spontaneous putting together of meaningful speech.
SPEECH AND MOTOR FUNCTIONS OF THE LEFT HEMISPHERE
The association between handedness and the cerebral lateralisation of language offers much scope for speculation.
It has been suggested, from an evolutionary point of view, that language may have arisen out of primitive man's use of manual gestures to communicate with his fellows (Hewes, 1973).
Since handling of tools and weapons requires precise manipulation of the fingers and thumb, a dextral bias in hand preference for wielding these implements might have predisposed our earliest ancestors towards the use of the right hand for gestural communication.
The emergence of speech might then have developed from neural systems for motor control already lateralised to the left half of the brain.
The term apraxia (or dyspraxia) refers to difficulty in carrying out purposeful movements or sequences of movements, as in the manipulation of common objects.
The disorder arises as a result of brain damage, particularly of the left parietal lobe, and for the label apraxia to be applicable, the patient's difficulties must not be due to problems in comprehending the examiner's instructions.
Central to any definition of apraxia is the idea that any paralysis or weakness of limbs is insufficient to  account for the movement disorder.
Certain broad categories of apraxia are recognised (Hécaen and Albert, 1978).
Ideomotor apraxia refers to an inability to correctly perform simple gestures such as a salute, making the sign of the cross or pretending to stir a cup of coffee.
Ideational apraxia is seen when a patient cannot carry out a complex sequence of movements, even though he is capable of carrying out each movement individually.
For example, he may strike a match perfectly well but in attempting to light a candle he may try to light the wick with the match unlit or strike the match against the candle.
Constructional apraxia is an impairment in the construction of two- or three-dimensional figures as in drawing or using matches or building blocks.
Dressing apraxia refers to difficulty in putting on clothes; the patient may manipulate them haphazardly, unable to relate them spatially to his own body, or he may be unable to put them on in the correct sequence.
The literature on apraxia is highly confusing and contradictory.
This is in part because different investigators have held different ideas as to the independence or otherwise of the different sub-types of dyspraxia or as to the essential nature of the various defects.
Some have seen apraxia as primarily a defect of execution, others have considered the problem to be one of planning or of conceptual organisation.
It is not the intention here to discuss the controversies or to review the literature.
The interested reader is referred to reviews by Geschwind (1967), Ajuriaguerra and Tissot (1969), Hécaen and Albert (1978) and, for constructional apraxia, Benton (1969) and Warrington (1969).
More recent papers concerning the distinction between ideational and ideomotor apraxia are those by Lemkuhl and Poeck (1981) and De Renzi, Faglioni and Sorgato (1982).
For present purposes it is sufficient to note that in right handers ideational apraxia occurs as a result of lesions located posteriorly in the left hemisphere.
The apraxia is always bilateral, that is, occurs for both left and right hands.
The clinical literature, then, suggests that in the execution of certain types of movement or sequences of movement the left hemisphere is implicated to a greater extent than the right hemisphere.
This view is supported by the results of experimental studies carried out with non-apraxic brain damaged patients.
Although a unilateral lesion of the left or right hemisphere may impair the accuracy or speed of unilateral movements of both the contralateral and ipsilateral arm (Wyke, 1968; Heap and Wyke, 1972; Haaland and Delaney, 1981) left sided lesions appear to produce greater deficits (Wyke, 1971a; Kimura, 1977a; Kolb and Milner, 1981a) or bilateral impairment on tasks in which only a contralateral deficit is observed after a right sided lesion (Wyke, 1967; 197 lb).
The importance of the left hemisphere for sequential movements was highlighted in a study by Kimura and Archibald (1974).
Left brain damaged patients were impaired relative to those with right side damage, not only on traditional tests of apraxia but also in imitating a sequence of meaningless manual movements.
Left lesioned patients were not impaired in copying a single hand posture nor in flexing a single finger at the middle  joint without simultaneous flexion of the other fingers.
This last task, in fact, had earlier been found to be performed better by the left hand of neurologically intact right and left handers (Kimura and Vanderwolf 1970).
Although sequencing errors may occur as a result of either left or right sided lesions (Kim, Royer, Bonstelle and Boller, 1980) it is generally held that left hemisphere damage more frequently leads to impairment.
A number of experiments carried out with normal subjects support the idea that the left hemisphere is dominant for certain aspects of movement control (Wolff, Hurwitz and Moss, 1977; Summers and Sharp, 1979; Taylor and Heilman, 1980).
What is the relevance of all this to understanding the nature of left hemisphere speech specialisation?
Speech is, of course, in its very nature a highly organised and complex sequence of sounds, but there is more to speech and language than sequential motor activity (Poeck and Huber, 1977).
The correspondence within the same hemisphere of the mechanisms underlying speech and movements of the hands would gain added significance if there were evidence to connect speech and manual activity more directly.
Such evidence is beginning to emerge.
Kimura (1973a) observed the movements which right handed people made with their hands during five minutes of conversation and during five minute periods of silent verbal and non-verbal problem solving.
Hand movements were classified into two main classes for analysis: 1.
self-touching movements and 2. free movements.
During speaking, but not in the silent conditions, free movements were made more by the right than by the left hand (see also Kimura and Humphrey, 1981).
In a second study left handers were observed in the speaking condition and while humming.
In the latter condition, free hand movements were symmetrical while in the speaking condition those sinistral subjects with a right ear advantage (on a dichotic listening test) showed the same excess of right hand activity as the majority of right handers (Kimura, 1973b).
Subjects who showed a dichotic left ear advantage tended to produce more free movements of the left hand.
Kimura argued that the lack of movement asymmetry in the humming condition showed that more than mere vocal activity was involved in producing the difference between the hands.
Since there was an association between the direction of ear difference on the dichotic listening task, and asymmetry of hand movement, she concluded that activation of the speech system in one hemisphere is associated with concomitant activation of certain other motor systems in that same hemisphere.
This, of course, assumes that the direction of dichotic ear asymmetry is a valid index of the hemisphere in which speech is represented.
Kinsbourne and Cook (1971) asked subjects to balance a dowel rod on the index finger of one hand.
The right hand was better at balancing unless the subject had to concurrently repeat the alphabet, in which case both hands performed equally well.
Lomas and Kimura (1976) repeated this experiment using different manual tasks and found that speaking interfered  selectively with the right hand only under certain conditions.
These conditions were, firstly, when subjects had to depress each of four Morse keys rapidly in turn with the four fingers of one hand and, secondly, when a whole arm movement had to be made to depress each key in turn.
Since a bilateral rather than a lateralised impairment was found when a single button was pressed repetitively with one finger, Lomas and Kimura suggested:…it is the rapid positioning of a limb, or parts of a limb,…which is related to the lateralised decrements produced by concurrent speaking.
If that is true, an important contribution of the left hemisphere to speaking may also be in the control of rapid placement…(of the articulatory musculature (p. 31).
This view is supported by the results of an experiment by Sussman (1971).
Subjects were presented with a computer controlled tone in one ear and had to match this tone through movements of the tongue which were transduced so as to produce a sound which was relayed to the other ear.
Significantly better performance was found when the target tone was presented to the left ear, and the tongue controlled the sound heard in the right ear, than in the reverse condition.
This laterality effect was also obtained when the cursor for tracking the target was attached to the jaw (Sussman and MacNeilage, 1975b) but not if the jaw was used to track lateralised visual input (MacNeilage, Sussman and Stolz, 1975) nor if it was the right hand that was used to track auditory input (Sussman 1971).
These findings suggest a close relation between self-generated auditory input and output of the speech musculature.
The act of speaking requires very precise articulation of the vocal apparatus.
At any one moment the positioning of the folds of the vocal tract is determined not only by what has just been said but by what is about to be said (Springer, 1979).
Speech thus requires very fine sequential organisation not only at a psychological level but at a physiological level also.
The results of Sussman and his colleagues suggest that the left hemisphere is particularly adept at monitoring and controlling the precise movement of the speech articulators.
The motor mechanisms of the left hemisphere as they relate to speech are further indicated by studies of non-verbal oral-facial movements (such as protrusion of the tongue or lips) in aphasic patients.
It has been shown that in performing sequences of three such movements aphasics are worse than non-aphasic left brain damaged patients who in turn are worse than patients with right brain damage.
The latter are unimpaired (Mateer and Kimura, 1977; Mateer, 1978).
Electrical stimulation of the exposed cortex in a small group of patients has been reported to disrupt production of single oral-facial movements at exactly the same electrode sites that produce speech arrest during naming of objects.
Stimulation also  disrupted sequential oral-facial movements, but not repetitive movements of the same gesture, at other sites within the classical language zone but not at control sites outside this area.
Furthermore, stimulation at sites where oral-facial movements were disrupted also  impaired the patient's ability to identify stop consonants (e.g. p, b, d) embedded in a nonsense syllable.
There was no site at which phoneme identification was impaired where there was not also a disruption of oral-facial movement, although at one site (in one patient) movement was disrupted without any impairment of phoneme identification (Ojemann and Mateer, 1979b).
The evidence reviewed above suggests that the left hemisphere bears a special responsibility for certain aspects of movement of both the hands and the vocal apparatus.
There appears to be an overlap between the neural systems engaged during vocal and manual activity.
At an anecdotal level this is not surprising.
Charles Darwin (1872) pointed out that: children learning to write often twist about their tongues as their fingers move, in a ridiculous fashion.
Could it be, as Kimura (1977b) suggests, that: brain regions considered to he important for symbolic-language processes might better be conceived as important for the production of motor sequences which happen to lend themselves readily to communication?
One line of evidence connecting manual activity and symbolic language processes concerns cases of "signing aphasia" in the deaf This refers to the deficit shown by those individuals who have learned to use their hands to communicate in sign language and subsequently sustain brain damage which impairs this ability.
Kimura (1977b) tabulates seven such cases reported in the literature and it is notable that in every case the lesion responsible could with reasonable confidence be localised to the left cerebral hemisphere.
Although it is claimed that these cases indicate an impairment in executing symbolic gestures it may in fact be the case that this aspect of their difficulty is secondary to a deficit in dealing with sequences of movements in general, the apparent linguistic defect deriving from this (Kimura, Battison and Lubert, 1976).
However, there is evidence from hearing subjects that aphasia-producing lesions of the left hemisphere are associated with defects not just of execution but of comprehension of manual symbolic gestures (Gainotti and Lemmo, 1976; Seron, Van der Kaa, Remitz and Van der Linden, 1979).
This implies that it is the appreciation of symbolic significance that is impaired.
LANGUAGE AND THE RIGHT HEMISPHERE
Despite the undoubted pre-eminence of the left hemisphere for language in the majority of right handers, it is possible that the right half of the brain can participate in certain language functions as indicated by the split-brain studies reviewed in Chapter 3.
Hughlings Jackson (1874) was of the opinion that though the left hemisphere was responsible for what he termed propositional speech the  right hemisphere could undertake "the automatic revival" of words, particularly under conditions of great emotion.
(This may be why the speech of aphasics is often peppered with expletives and stereotyped phrases.)
In line with Jackson's view it has sometimes been observed that the ability to sing may be preserved despite severe expressive aphasia (Yamadori, Osumi, Masuhara and Okubo, 1977), injection of amylobarbitone into the left carotid artery in a left speech-dominant patient (Gordon and Bogen, 1974) and even in the total absence of the left half of the brain following hemispherectomy (Gott, 1973).
This suggests at least some role for the right hemisphere in certain language functions.
With regard to written aspects of language, a distinction has again been drawn between conscious and automatic writing.
Left sided lesions may impair the former, leaving intact such well practised actions as writing one s name and address (Luria, Simernitskaya and Tybulevich, 1970; Simernitskaya, 1974).
Studies carried out with Japanese subjects suggests that the right half of the brain is preferentially involved in reading a certain type of material.
Japanese orthography is unusual in that three types of symbols — Katakana, Hirakana and Kanji — are used.
The first two are phonetic symbols standing for syllables, whereas Kanji are non-phonetic symbols, or ideograms, representing complete ideas.
Tachistoscopic studies have shown a right visual hemifield superiority in recognition of Katakana and a left hemifield advantage for Kanji (Hatta, 1976; 1977; Saganuma, Itoh, Mori and Kobayashi, 1977; Endo, Shimizu and Hori, 1978).
A dissociation between these two scripts has been observed in Japanese aphasics (Sasanuma, 1975) and in a patient with alexia and agraphia.
The latter showed severe reading and writing difficulties in Kana but Kanji presented less of a problem (Yamadori, 1975).
The conclusion from all these studies, that processing of Kanji is less dependent on the integrity of the left hemisphere than processing of Kana, is supported by electrophysiological findings (Hink, Kaga and Suzuki, 1980) and by results obtained with three patients who sustained partial commissurotomy in the course of removal of pineal gland tumours (Sugishita, Iwata, Toyokura, Yoshioka and Yamada, 1978).
However, the suggestion that experience with these two different systems of writing leads to the Japanese having a different cerebral organisation to that of Westerners (Tsunoda, 1975; Hatta and Dimond, 1980) lacks convincing experimental support.
Even in the West we use ideographic symbols in some circumstances.
When numbers are written as figures a given digit stands for a word.
When subjects are asked to judge which of two simultaneously displayed numbers is numerically the larger, irrelevant variations in the physical size of the digits influence response times when the numbers are printed in figures (e.g. 9) but not when they are printed alphabetically (nine).
This finding (Besner and Coltheart, 1979) suggests that there are two independent processing systems.
A right visual field superiority on the task when digits  are displayed was found by Katz (1980) but a LVF superiority by Besner, Grimsell and Davis (1979).
Language following hemispherectomy
A unique opportunity to study lateral specialization of function in the human brain is provided by those patients who have been treated by left or right hemispherectomy for malignant tumour or for convulsions associated with infantile hemiplegia.
In this procedure the patient loses the entire cortex of one half of the brain, though in cases of recurrent tumour the hemisphere may be removed in two or more stages.
Although there are differences in the method of removal favoured by different surgeons (Goodall, 1957), it is usual to spare as much of the thalamus, basal ganglia and hippocampal cortex as possible and for this reason Austin and Grant (1955), among others, have pointed out that the operation might be better described as hemi-decortication, reserving the term hemispherectomy for those cases in which subcortical structures are also destroyed.
Because of the association between aphasia and the left side of the brain, neurosurgeons have been understandably reluctant to remove the entire left hemisphere of adult right handers.
Consequently, there are very few cases of this type in the literature.
The first reported case (Zollinger, 1935) was of a woman who could answer "alright" in response to questions immediately after the operation but otherwise could say little more than yes, no, goodbye "," please"and a few other words.
However, beginning from the first or second post-operative day there were gradual signs of improvement until her death three weeks after surgery.
The second case, that of Crockett and Estridge (1951), survived for a period of four months after left hemispherectomy.
Immediate post-operative speech was limited to "yes' and" no "but after two weeks the patient was able to say" no, I don't want any "and" put me back to bed".
During the following two weeks his speech improved and he began to use a few more simple words, but subsequently "a block in his speech appeared" and he only said "aw-caw and" yes' and "no" .
Such limited expressive speech following left hemispherectomy was also observed in the third recorded case (French, Johnson, Brown and Van Bergen, 1955).
A more recent case of dominant hemispherectomy in a right handed adult is that reported by Smith and Burkland (1966) and Smith (1966).
The patient was a 47-year-old man at the time of operation.
Mine months previously he had had a neoplasm removed from the left hemisphere which had resulted in some post-operative speech disturbances.
Prior to hemispherectomy, however, he was speaking more or less normally.
Smith and Burkland state that "the patient spontaneously articulated words and short phrases fairly well immediately after the operation" but he could not repeat single words until the tenth post-operative week.
This patient subsequently exhibited considerable improvement in his speech capabilities (Smith, 1966, 1974; Zangwill, 1967).
As well as the four adult cases of left hemispherectomy there are two reports of left hemispherectomy carried out during early adolescence.
Hillier (1954) describes the case of a young boy who underwent total left hemispherectomy at the age of 14 years, following an operation less than one year earlier for removal of a tumour from the left parietal lobe.
The first operation left him with a "mixed" aphasia but this cleared before a reappearance of his symptoms, including "very severe aphasia" , led to the hemispherectomy.
The patient was said to be unable to speak after this operation but by the sixteenth day he was able to use words like "mother" , "father" and "nurse" .
It is reported that on discharge from hospital on the thirty-sixth postoperative day "he appeared to have perfectly normal powers of comprehension of the spoken word" and was able to refer to the medical and nursing staff by name.
At this time his vocabulary was said to show "daily improvement" .
A similar case was reported of a left hemispherectomy performed on a 10 year old girl two years after a malignancy had been removed from the left lateral ventricle.
This patient also showed speech limited initially to simple words and phrases during the early post-operative period but her auditory comprehension appears to have been good (Gott, 1973).
Interestingly, singing of familiar songs was still possible.
Although cerebral organisation in adolescence may be characterised by greater functional plasticity than is the case among adults, the picture after left hemispherectomy is essentially one of gross linguistic impoverishment in which comprehension is better preserved than expressive speech.
"The effect of right cerebral lesions on language functions
Crossed aphasia in dextrals, that is aphasia resulting from a right sided lesion, is extremely rare (Brown and Hécaen, 1976) with confirmation at autopsy of a strictly unilateral lesion reported for only four cases at the time of writing (Brust, Plank, Burke, Guobadia and Healton, 1982).
Even now cases of crossed aphasia in right handers are likely to be reported in the literature on account of their rarity (e.g. Brown and Wilson, 1973; Zangwill, 1979; Wechsler, 1976; April and Han, 1980) although there is little to suggest that there is any qualitative difference between the aphasias produced by left and right sided lesions (Carr, Jacobson and Boller, 1981).
Although frank aphasic symptoms are only rarely seen after lesions of the right hemisphere, or even after total right hemispherectomy (Damasio, Almeida and Damasio, 1975; Smith, 1974) in patients with left hemisphere specialisation for language, careful studies are now pointing to certain linguistic impairments in association with right-sided brain damage.
Eisenson (1962) was one of the first to note such effects and reported that right lesioned patients used more descriptive terms and more qualifiers than left brain damaged patients.
Marcie, Hécaen, Dubois and Angelergues (1965) noted impairment in some patients on tests of sentence production, vocabulary selection and syntactic transformation after right hemisphere  lesions.
More recently, Caramazza, Gordon, Zurif and De Luca (1976) found right brain damaged patients to be impaired relative to controls on tests requiring the answer to such questions as "who is shorter?" , given that "A is taller than B" .
Gardner, Silverman, Wapner and Zurif (1978) found right hemisphere lesions to impair appreciation of antonymic contrasts (opposites) and Winner and Gardner (1977) report that right-sided damage interfered with the ability to understand metaphors.
In general, then, recent evidence points to conceptual or linguistic difficulties of a fairly high level.
Having said this, it does not follow that there are not difficulties at a more "elementary" level of language.
In particular it seems that the ability to interpret information conveyed by prosodic aspects (i.e. intonation) of speech is impaired by right hemisphere damage (Schlanger, Schlanger and Gerstmann, 1976) as may be the ability to employ appropriate intonation oneself (Ross and Mesulam, 1979).
These observations are consistent with findings with normal subjects suggesting a role for the right hemisphere in appreciation of the prosodic factors in speech (Haggard and Parkinson, 1971; Zurif 1974; Blumstein and Cooper, 1974; Craig, 1979a; Dwyer and Rinn, 1981).
Recovery from aphasia
Whatever its normal role in language functions, there is evidence that in some cases, though not all perhaps, the right hemisphere participates in the recovery of language following aphasia.
This is shown most clearly by those instances in which a lesion of the right hemisphere has re-instated an aphasia produced earlier by left sided brain damage (Nielsen, 1946) or when amytal injection into the right carotid artery has disrupted the speech of patients previously rendered aphasic by left hemisphere damage (Kinsbourne, 1971).
Supporting evidence for the view that the right hemisphere may participate in the recovery from aphasia comes from findings obtained with the regional cerebral blood flow technique (Meyers, Sakai, Yamaguchi, Yamamoto and Shaw, 1980) and from studies of dichotic listening performance which have shown a disproportionate increase in the left ear score with recovery (Pettit and Noll, 1979), at least among certain categories of aphasic patient (Castro-Caldas and Botelho, 1980).
Studies with normal subjects
The extent of language function in the right hemisphere under normal circumstances is not easy to infer from the clinical studies.
Experiments have therefore been carried out in an effort to examine this question in subjects with intact brains.
The Moscovitch model
Moscovitch (1972; 1973) presented subjects with a set of unrelated letters which were heard through both ears.
Following this, a single probe letter  was presented to one or other visual half-field and the subject's task was to respond, using the left hand, as fast as possible to indicate whether the visually presented letter was or was not a member of the auditorily presented memory set.
The left hand was used in order, it was assumed, to engage the right hemisphere in response output.
The argument was that if the right hemisphere can store a representation of the auditory set and compare it with the visual probe letter then there should be an advantage in reaction time to letters presented in the LVF compared to the RVF.
In the event, an RVF advantage was generally observed implying, according to Moscovitch, that the letters presented to the LVF had to be transferred to the left hemisphere for processing.
However, a LVF advantage (for same"responses) was observed when the auditorily presented memory set consisted of only a single letter.
It is possible that the subject retained a single letter in the form of a visual representation of the acoustic stimulus and that he subsequently matched this representation against the visually presented probe stimulus.
The observed left field advantage may therefore reflect not a "linguistic" process but a process of matching based on purely visual features of the letters to be compared.
Hence Moscovitch (1976) extended his earlier experiment by presenting a single letter binaurally followed by a visually presented letter.
His aim was to determine whether single letters are dealt with by the right hemisphere in a visual or a phonological code.
Moscovitch argued that if the subject uses a linguistic strategy, that is compares the names of two letters, then it should be more difficult for him to discriminate between acoustically (e.g. I-Y) than visually (e.g. V-U) similar letter pairs.
This should be reflected in longer reaction times (RT) to acoustically similar letters.
Conversely, use of a matching strategy based on physical features should result in extended RTs to visually similar letters.
His results pointed to the latter strategy.
However, when the two letters to be matched were presented simultaneously, rather than successively, the pattern of results differed for the two visual fields in such a way as to suggest that the right hemisphere was still using a visually-based strategy while the left hemisphere was using an acoustically based strategy.
Forcing the subject to use an acoustic strategy, by making the task one in which he had to indicate whether the terminal phoneme of one letter's name was the same as that of another (e.g. B and G have the same terminal sound, B and M do not), still led to a RVF advantage.
Moscovitch claimed that together with his other findings this showed that the right hemisphere had little or no"linguistic abilities
On the basis of his own findings Moscovitch argued that in the normal brain the right hemisphere has little or no language.
However, he was struck by the apparent paucity of linguistic skills in the right hemisphere of normal subjects compared to that reported for  commissurotomised patients.
He also noted that the effects of a left hemisphere lesion may be more devastating in terms of its effect on language than even total left hemispherectomy (Smith, 1974).
Moscovitch therefore suggested that the  reason why the right hemisphere shows so little language ability under normal circumstances is that it suffers from inhibitory control by the left hemisphere.
In the absence of the left hemisphere, and after section of the corpus callosum, this inhibition is reduced or eliminated.
An appropriately localised unilateral lesion of the left hemisphere represents a situation intermediate between the normal state of affairs and disconnection of one hemisphere from the other by commissurotomy or hemispherectomy.
The language behaviour observed is therefore at a correspondingly intermediate level.
Moscovitch found support for his proposition in the fact that split-brain patients sometimes begin to write with the left hand what is clearly a correct response to a stimulus seen in the left visual field, but that then the left hemisphere takes over control and the response is finished incorrectly since the left half of the brain has not seen the stimulus (Levy, Mebes and Sperry, 1971).
It is possible to argue against Moscovitch on various grounds (see Selnes, 1974; Ulrich, 1978) and his theory is certainly difficult to test experimentally.
Yet the notion of inter-hemispheric inhibition is one that has been adopted by other authors to explain how language becomes lateralised to the left hemisphere (Gazzaniga, 1974).
It is known that myelinisation of the fibres of the corpus callosum is not complete until about 10 years of age (Yakovlev and Lecours, 1967).
This is roughly halfway between 5 years of age (Krashen, 1973) and puberty (Lenneberg, 1967) which have been taken to mark the end points of the process of lateralisation.
Furthermore, behavioural evidence suggests that the callosum becomes increasingly functional iii an inhibitory (Dennis, 1976) as well as a facilitatory (Galin, Johnstone, Nakell and Herron, 1979) manner throughout childhood.
The argument proposed by Moscovitch is not as far-fetched as it perhaps appears.
It has been known for some time that the majority of fibres from the left and right eyes converge upon single cells in the visual cortex of the cat and monkey (Hubel and Wiesel, 1967).
These binocular cells can be made to fire by impulses arriving by way of fibres from either eye but there is normally a bias in favour of one eye or the other, the so-called ocular dominance of the cell.
If the animal is raised with a surgically induced squint, or with one eye sutured from birth, then there is a dramatic reduction in the number of binocular cells.
Even after the eye is opened most cells can only be driven by input presented to one eye.
What happens, therefore, to the connection between the cell and the ineffective eye?
Some workers believe that a process of inhibition takes place which prevents the cell from firing in response to impulses travelling along the pathway from the ineffective eye.
Since evidence suggests that humans also possess binocular cortical neurones and that their connections with the left and right eyes are susceptible to modification, as with the cat and monkey (Aslin and Banks, 1978), it is not difficult to see the possible extrapolation from the cellular to the hemispheric level (see also Kinsbourne, 1975b).
Lexical decisions in left and right visual fields
Although Moscovitch argued that the right hemisphere showed little or no language ability, other workers have since been less dismissive.
One class of experiment which has been used to investigate this issue involves what is known as a lexical decision task.
Letter strings are presented to the subject who has to decide as quickly as possible whether the letter string constitutes a word or not.
Leiber (1976) carried out such a study and found that reaction times were equal in the left and right visual fields when the stimuli were not words, but a RVF superiority obtained when the letter-string made up a word.
She argued, therefore, that since a good proportion of the non-words actually looked like words and could be pronounced without difficulty, the RVF superiority obtained with real words was related to their semantic aspect.
(In a subsequent experiment Axelrod, Haryadi and Leiber (1977) used letter strings which were always pronounceable but the approximation of the letter clusters to real English varied such that some letter combinations occurred very commonly in English (called high frequency approximations) while others occurred much less frequently (low frequency approximations).
The findings were that RTs to high frequency approximations were responded to faster in the RVF.
This suggests that predictable letter sequences may be treated as words even in the absence of semantic information.)
An interesting finding was reported by Bradshaw, Hicks and Rose (1979).
These workers presented letter strings to the left or right visual field for different durations.
At the shortest duration (20 msecs) subjects were unable to identify any words, but lexical decisions were more accurate in the left than the right visual field.
As the exposure duration was increased to the level at which words could be positively identified a RVF superiority emerged.
The LVF advantage at the shortest duration implies that the right hemisphere may recognise genuine words when it sees them, even though it cannot necessarily identify them, which suggests that in this respect the right half of the brain is not inferior to the left.
This would be consistent with certain other findings.
Marcel and Patterson (1978) presented one word, followed by a pattern mask (see Chapter 4) such that the word could not be identified, and the mask was followed by a letter string about which subjects had to make a lexical decision.
Where the first (masked) word (e.g. bread) was semantically related to the following word (e.g. butter) reaction times in the lexical decision task were shortened.
Since the masked word could not be identified this semantic priming effect calls into question the usual explanations of masking (Turvey, 1973) and suggests instead that a mask does not necessarily interrupt visual processing but prevents the appearance of a word"in consciousness.
The important feature of Marcel and Patterson's findings for present purposes is that semantic priming affected RTs in the left and right hemifields to an equal degree.
This again suggests that the right hemisphere is not without some word recognition ability.
Deep dyslexia
The above findings are consonant with recent research conducted with patients suffering from a certain type of rare reading disability arising as a result of damage to the brain.
The syndrome of "deep dyslexia" (see Coltheart, Patterson and Marshall, 1980) is characterised by certain kinds of errors which the patient makes when unable to read aloud particular words.
In a high proportion of cases errors bear an obvious semantic relationship to the target words.
For example, asked to read aloud "gnome one patient said" pixie"(Marshall and Newcombe, 1971).
In addition, the patient is unable to read pronounceable non-words (Coltheart, 1980a).
These and related observations have been interpreted to mean that"deep dyslexics' are unable to employ a phonological code, that is, they cannot decode a word in terms of its sound structure, and have to rely on a purely visual code in retrieving words from their internal dictionary or lexicon (Warrington and Shallice, 1979; Coltheart, 1980a).
It has been argued that this visual route to word recognition is an attribute of the right hemisphere (Saffran, Bogyo, Schwartz and Marin, 1980).
However, the implicit assumption that this hemisphere is incapable of phonological analysis is challenged by a recent finding with normal subjects (though supported by split-brain investigations — see Chapter 3).
For both left and right visual fields it takes longer to reject as "illegal" , in a lexical decision task, pseudo-homophones (letter strings that do not constitute words but sound like real words, e.g. "bloo" , "rayne" ) than letter strings that look like real words but do not sound like real words.
Homophonic real words (e.g. rain, reign), however, take longer to be responded to than non-homophonic (real) words in the RVF but not in the LVF (Barry, 1981).
Perhaps, then, the right hemisphere undertakes phonological analysis only when a search through the lexicon, reveals no entry for a particular letter string and a phonological "check" is made.
(This, of course, would require that the results of such a check are themselves compared with the visual representation, for otherwise pseudo-homophones would never be correctly rejected as non-words).
One of the factors in the argument for right hemisphere reading by deep dyslexics is that they are usually able to read words that are highly imageable, that is readily give rise to a visual image, but they are often unable to read words that are highly abstract (Richardson, 1975).
A number of studies with normal subjects have shown that ear (McFarland, McFarland, Bain and Ashton, 1978; Kelly and Orton, 1979 — but see Lambert and Beaumont, 1982) or visual hemifield asymmetry is negligible or reduced for concrete highly imageable words as compared with abstract, non-imageable, words (Ellis and Shepherd, 1974; Hines, 1976, 1977; Hatta, 1977; Day, 1977, 1979; Marcel and Patterson, 1978;.
Elman, Takahashi and Tohsaku, 1981) although negative results have also been reported (Orenstein and Meighan, 1976; Hines, 1978; Bradshaw and  Gates, 1978; Tzeng, Hung, Cotton and Wang, 1979; Schmuller and Goodman, 1979; Young and Bion, 1980b; Shanon, 1979b).
The suggestion has therefore been made that either the right hemisphere can process concrete words and/or that such words survive, better than abstract words, transmission across the corpus callosum from the right to the left hemisphere (Lambert and Beaumont, 1981).
The idea that the right hemisphere may be involved in processing highly imageable words is supported by data from temporal lobectomised patients which show a deficit in recall of concrete, highly imageable, words, leaving abstract words unaffected, when the lesion is on the right.
Contrariwise, left sided lobectomy affects abstract words but has little effect on recall of concrete words (Jones-Gotman and Milner, 1978).
While the above findings suggest that highly concrete words are equally well recognised in left and right hemispheres, it is conceivable that the relevant factor is not concreteness or imageability, per se, but some other factor which co-varies with imageability.
One such factor is the age at which words are learned.
Words with an early age of acquisition tend to be highly concrete (imageable) while words acquired at a later age tend to be abstract.
Ellis and Shepherd (1974) first drew attention to this but a number of experiments by Young and his colleagues have failed to show any influence of age of acquisition of words on dichotic listening (Young and Ellis, 1980) or tachistoscopic hemifield asymmetry (Ellis and Young, 1977; Young and Bion, 1980b) even when it is the age at which words are first read rather than heard that is under investigation (Young, Bion and Ellis, 1982).
However, in all these experiments only high imagery words varying in age of acquisition were used, which does not allow for the possibility that there is an interaction between visual field, imagery and age of acquisition.
In experiments by Beaton, Sykes, King and Jones (1982) low imagery words were used as well and the results suggested that there was indeed an interaction between these variables.
In terms of reaction time, the right hemisphere emerged as sensitive to manipulations in age-of-acquisition but not imagery.
These findings raise the possibility that the results with deep dyslexics, which appear to show a facilitating effect of highly imageable words on reading performance, might just as plausibly be attributed to the fact that such words tend to be learned at an early age in life.
Overall, it seems fair to conclude that the right hemisphere does possess some word processing capacity, probably more so for the written than for the spoken word, for concrete or early-learned rather than abstract or later-learned words and for receptive rather than executive aspects of language.
(For review of this topic see Zangwill, 1967; Searleman, 1977; Hécaen, 1978).
The implications of this right hemisphere linguistic capacity in the re-training of dysphasic (Glass, Gazzaniga and Premack, 1973; Sparks, Helm and Albert, 1976) and brain-injured dyslexic patients (Carmon, Gordon, Bental and Harness, 1977) have already received some attention.
SUMMARY
This chapter has reviewed evidence concerning language lateralisation in left and right handers.
Although is is undoubtedly the case that the left hemisphere has primary responsibility for language in the vast majority of right handers the proportion of left handers for which this is true is not entirely clear.
The tachistoscopic and dichotic listening techniques lack reliability and, by and large, have not been adequately validated against other criteria.
(An exception to this is the dichotic monitoring technique developed by Geffen which was discussed in Chapter 4 but this has not yet been applied to large scale studies of left handers.)
EEG, ECT and regional cerebral blood flow techniques are similarly unhelpful in this respect.
Lesion studies have their own problems of interpretation, while other methods which might conceivably be used to  establish cerebral dominance, such as dichaptic stimulation and the dual-task technique, have not been validated nor widely adopted in experiments with large numbers of left handers.
There remains the sodium amytal test which is accurate but suitable only for use with candidates for brain surgery.
With the proviso that such patients may have atypical cerebral organisation for speech the amytal test provides the best estimate we have of speech lateralisation in left and mixed-handers.
The figure of 70 per cent left sided speech in non-dextrals accords reasonably well with Levy's estimate of 63 per cent derived from the lesion data.
It should be noted, however, that the figure of 70 per cent applies only to one particular (and rather loose) criterion of non-right handedness.
The problem of determining by non-invasive means which left handers have right sided speech still resists solution.
The suggestion that hand posture during writing provides a ready indication has not lived up to its early promise.
Equally the idea that familial sinistrality is found in association with bilateral speech has given rise to conflicting findings.
It is possible that speech and language developed from pre-existing neural structures lateralised to the left cerebral hemisphere.
Left hemisphere control of sequential motor activity which lent itself readily to a symbolic gestural system may have been the evolutionary precursor to present day lateralisation of language.
It is becoming increasingly evident that the left hemisphere's control of language even among the fully right handed is not absolute.
The nature of the right hemisphere's contribution has yet to be determined precisely, but it may turn out that this half of the brain has a more elevated role to play than is customarily believed.