

EDITORIALS
Institutional care and elderly people
What do the changing patterns mean?
One of the aims of Britain's health and social services for the past 40 years has been to help old people to live in their own homes.
Although innovative schemes have made it possible to maintain at home people with disabilities that were once thought to require hospital or residential care, it is unrealistic to suggest that institutional care could be entirely dispensed with.
For patients with low levels of dependency, providing domiciliary care is cheaper than providing institutional care, but at high levels of dependency it becomes more expensive.
At some level of expenditure it presumably becomes inequitable for a disabled person to expect public support for the more expensive domiciliary care if this means depriving someone else of care of any sort.
Further problems identified by Kellett in this week's journal centre on the inequity and illogicality of NHS care being free while care under the rubric of the community, even if provided in an institution, carries a means tested price tag.
There seems nothing in the present arrangements to prevent two similarly disabled old people being in adjacent rooms in a nursing home, one of whom has her lifetime earnings bled down by ‘community care’ while the family of the other looks forward to an undiminished inheritance courtesy of the NHS.
Be that as it may, the potential advantages of long term care in a high quality private sector are considerable, particularly as this sector offers old people and their families wider choice than the public sector.
Autonomous nursing units may be able to offer their residents more adaptable care when they are free from the rigid timetables inseparable from hospital organisation.
Under experimental conditions, old people in NHS nursing homes may do at least as well as those in traditional geriatric wards, but the same cannot be assumed of units removed from the traditions and surveillance of a health or social services hierarchy.
American experience provides grounds for anxiety over the welfare of old people in an inadequately monitored private sector.
Two further concerns have been generated by the massive growth in the number of private residential and nursing homes following changes in social security regulations in the past decade.
First is the possibility of an unnecessary increase in the number of old people consigned to institutional care.
Secondly, the private sector may have been ‘creaming off’ clients with low dependency, who yield high profit margins, leaving the public sector to cope with more demanding patients without appropriate improvements in staffing and facilities.
In this week's journal Stern and colleagues report on two censuses carried out in 1979 and 1990 of elderly people in residential care in Leicestershire (p 827).
During the 11 years the numbers of residents in NHS geriatric and psychiatric beds fell by 41%; this fall was partly compensated for by a 37% rise in the number of patients in acute beds.
On the assumption that this transfer represents better access of elderly people to the best of modern medicine and surgery, it must be a good thing.
In contrast, the number of people in private sector homes almost quadrupled.
The total number of people aged 65 and over in institutions increased by 30% between the two censuses, but because of population growth this represents an increase in proportion of only 0.5%, from 4.2% to 4.7%.
Furthermore, this increase is entirely explained by the aging of the population between the two censuses.
These findings do not confirm fears of an overall increase in the number of old people looked after in institutions, and  the proportion of 4.7% remains commendably low by international standards (and lower than the national average of 5.1% in 1971).
This interpretation assumes that the objective need for institutional care has not been reduced by improved health and fitness of old people.
It also assumes that there has been no hidden export of Leicestershire's residents to cheap (and possibly nasty) nursing homes elsewhere in Britain, a practice that some other health districts have been accused of.
What of the process of ‘creaming off’?
Again the data seem reassuring in that in 1979, 27% of residents in public sector beds were defined as high dependency patients compared with 22% in the private sector; in 1990 the proportions were 26% and 29% respectively.
The comfortable interpretation of these data needs caution.
Dependency increases where care is poor, and homes taking in low dependency clients can soon make them more dependent by providing too few activities and too many sedatives.
Furthermore, the data were based on assessments made by care staff; in the public sector staff have an incentive to minimise the dependency of their clients as it is seen as an index of the quality of care being provided.
In the private sector a greater incentive might exist to show a need for higher fees to match high levels of dependency.
The Leicestershire data establish a valuable baseline but cannot allay the remaining anxiety over the quality of care once the private sector provides most institutional care (the government's decree).
Standards can be set, but arrangements for ensuring that they are maintained in the private sector are still inadequate.
Juniors' new deal meets its first deadline
On time — on paper
By 1 April most junior doctors in Britain will be contracted to work less than 83 hours a week and the first deadline of the new deal will have been met, on paper at least.
But many junior doctors are unhappy about what they have seen of the new deal so far.
Many fear that this first reduction in hours will mean an increase in the intensity of their work and a fall in their remuneration for it.
Managers were always going to hit the first target once they realised that a one in three rota without prospective cover fitted the limit of 83 hours a week exactly.
Regional task forces estimate, however, that the gap between the hours stipulated in most juniors' contracts and the hours that they will actually work is about five to 10 hours a week.
And the gap will become wider if no extra staff are employed to cover junior doctors' annual leave.
Hours may be the most emotive issue in the new deal but are only one aspect of juniors' working conditions that need improvement.
The new deal called for radical changes in the working patterns of all grades of hospital staff, for the removal of the inappropriate non-medical duties, and for better accommodation and on call facilities.
It supported the aims of Achieving a Balance by insisting that the answer was not employing more junior staff but more consultants and staff grade posts to release junior doctors from some of their service commitments.
It echoed reports of the Confidential Enquiry into Perioperative Deaths calling for the appropriate supervision of junior doctors, especially outside normal working hours.
The new deal emphasised that partial shifts were the best way of reducing juniors' hours in acute specialties and urged consultants to move to team working to facilitate this.
Units were to provide local solutions to local problems.
In the rush to meet the first deadline on hours much of the spirit of the new deal has been lost.
Undoubtedly progress has been made, but it has been patchy.
Radical changes in working patterns have yet to happen: apart from doctors in accident and emergency departments fewer than 1% of doctors are working full shifts and just over 2% are working partial shifts.
Most of the extra £12m that the government is giving towards implementing the new deal will go on funding new consultant posts, leaving individual units to fund the new support staff, such as phlebotomists, electrocardiography technicians, and clerical staff.
Some successful initiatives have happened — for example, Guy's Hospital has employed a nurse practitioner at night to supervise giving intravenous drugs and filter calls to junior staff.
In Scotland, where such initiatives have been centrally funded by the Scottish Office, many hospitals have introduced phlebotomists for the first time.
But when hospitals are struggling to stay within budgets such initiatives are not given a high priority.
Some juniors complain that partial shifts have been introduced to cut costs rather than improve the service to patients and reduce doctors' workload.
A shift system that improves junior doctors' working conditions is unlikely to save money.
The examples of partial shifts provided by the Department of Health look reasonable on paper but do not take annual or study leave into account.
Given the confusion over the definition of a partial shift, it is not surprising that so many consultants and juniors oppose them.
Many juniors resent more than one in three weekends being disrupted by work and dislike working a series of nights.
They are sceptical that a few extra consultants or staff grade appointments will really reduce their hours and complain that the new deal was set up by doctors' representatives not working in hard pressed specialties.
Although the Central Consultants and Specialists Committee has backed the changes in working patterns, task forces have given mixed reviews on consultants' commitment  to the changes.
Some are still concerned that they will have to take on juniors' duties and that abandoning firms will damage juniors' training and patients' continuity of care.
One of the biggest problems facing task forces has been collecting accurate data.
Regions had no accurate number of senior house officer posts, and the task forces unearthed an extra 1000 such posts last year.
Now they are concerned that they will fail to meet the next deadline of 72 hours for hard pressed posts by December 1994.
So far, many signatories to the new deal have resisted the painful structural changes that are necessary.
In the meantime task forces are trying to collect accurate data on actual hours worked as opposed to contracted hours.
The arguments for jettisoning the rota system are strong, but for juniors to be enthusiastic about its replacement they need a better understanding of partial shifts and their benefits and disadvantages.
They should take responsibility for designing shifts and accept that shifts should be changed rather than discarded if they do not work.
Managers and consultants must accept that shifts will never work unless duties are removed from junior doctors — both service work and inappropriate tasks.
Juniors must be paid appropriately for the hours that they work: if they are getting only three hours' rest at night they are working the equivalent of a partial shift and should be paid accordingly.
Purchasers could give the new deal a push by insisting that providers implement it.
Specifying the standard of a hospital's decor and food but ignoring the quality of its doctors' working conditions betrays a curious sense of priorities.
Task forces need more power.
With ministerial support they could have more financial control over juniors' posts and be responsible for verifying the information that units give to purchasers.
The new deal says that the number of hours worked, as opposed to those on duty, should be reduced to 60 as soon as practicable.
To do this requires managers, consultants, and juniors to move in the same direction.
That direction, however familiar and cosy it seems, is not back to rotas.
Enhancing the educational content of SHO posts
Supervisors, objectives, diaries, assessment, and feedback would all help
In recognition of the need to separate funding for training and service, postgraduate deans will from next month have budgets to provide half the basic salary costs of all approved posts in the medical training grades in NHS provider units and trusts.
A review of the training content of junior doctors' work is long overdue: a recent survey found that only 3% of juniors' working time was spent on training.
The senior house officer post is a good place to start.
This is a designated training post for doctors starting out in their medical careers, during which they should acquire greater responsibility for patient care and competence in a wide range of general skills.
Although senior house officer posts generally provide great experience, their educational potential often remains untapped.
Studies have shown that guidelines on training produced by the General Medical Council and the Council for Postgraduate Medical Education are not being followed.
For example, the amount and quality of teaching vary greatly and lack any systematic approach.
Consultants and senior registrars are not rewarded for teaching and seldom have been trained in educational methods.
Senior house officers rarely, if ever, have a named educational supervisor or mentor with whom they can discuss problems about their training.
The imbalance between service commitments and training is such that doctors have little opportunity to learn from their experiences, and little or no teaching takes place in protected time, when they would be free from service commitments.
In addition, obtaining study leave is either difficult or impossible.
Some of these problems — for example, study leave — could be solved by a minor increase in resources.
But the main restriction on senior house officers' training is the overwhelming dominance of service commitments over training requirements.
Changing this would require a vast input of resources: the best way forward would be to capitalise on all the training opportunities thrown up by the existing system.
How could this be done?
Traditionally, consultants teach juniors attached to their firm, and departments timetable teaching in the form of tutorials, case presentations, and the like.
But service commitments often prevent juniors from attending these meetings, and not all senior staff enjoy or are good at teaching.
New work patterns, such a partial shifts, mean that senior house officers are less likely to work for a single consultant and also make it more difficult for all junior doctors to attend teaching sessions at set times.
The solution would be to give all senior house officers a named educational supervisor or mentor who could coordinate an educational programme specially tailored to each senior house officer's needs.
Suitable educational supervisors could be recruited from among consultants and senior registrars.
They would need training and should receive remuneration; colleges and postgraduate deans should together be responsible for setting up such a system.
With each post should come a set of educational objectives setting out the knowledge and skills that the doctor should have acquired by the end of the post.
By comparing past experience with the set objectives the doctors, together with their supervisors, could establish their own personal objectives for the post.
Several colleges have produced suggested objectives, and in some places course organisers for vocational training schemes have worked with local consultants to set up educational objectives for senior house officers who are trainee general practitioners.
Armed with their set of personal educational objectives, doctors are in a much better position to identify what they can learn from their day to day work.
Such learning should be reviewed, preferably by the educational supervisor; doctors should describe what they have learnt and how they intend to apply it.
Later in the post it should be established how successful they have been in doing so.
This learning cycle has obvious similarities to the audit cycle, which should be familiar to both senior house officers and their consultants.
Using log diaries to record experience before taking membership or fellowship examinations is well established in some disciplines and could be used by senior house officers.
Such a record should include the educational objectives for the post together with a system for recording whether these have been achieved and applied.
Any problems could be recorded for discussion.
This record should be regularly reviewed by the educational supervisor, whose responsibility would be to ensure that senior house officers had every opportunity to meet their specified objectives and that any gaps in relevant experience were readily identified and rectified.
Other members of staff could also refer to the record to ensure the relevance of teaching and to avoid duplication.
After personal educational objectives have been set for each doctor the educational process should be completed by assessment of whether these objectives have been fulfilled.
Senior house officers could also be assessed in terms of whether their performance in post is satisfactory.
For trainee general practitioners satisfactory completion is mandatory under the terms of the NHS (vocational training) regulations.
Assessment of both performance and educational achievement could benefit senior house officers provided that it occurred sufficiently early in the post to enable improvements to be made.
It would therefore be appropriate for senior house officers to have a formal assessment session with their educational supervisor part of the way through the post and again at its completion.
Assessment is likely to have educational value, however, only if the outcome is fed back to the senior house officer.
Arguably, assessment of performance should not be mixed with educational supervision, though manpower considerations might necessitate such a dual role for the educational supervisor.
Feedback from the department to the senior house officers would close the educational loop.
It would also be helpful if departments could receive feedback from the senior house officers on the quality of their education.
Pilot schemes should now be initiated in several regions and compared with traditional models.
Implications for funding could then be deduced and a national policy for training senior house officers established.
Given that they will have their hands on the purse strings, postgraduate deans will be able to insist on substantial improvements in the educational content of senior house officer posts.
They must act on this opportunity to ensure that young doctors working in the NHS receive the training that they need and deserve.
Urinary incontinence in the community
Common and can often be successfully treated
Urinary incontinence is common.
In a survey reported in this week's journal MORI interviewed 4000 people aged 30 and over in their own homes on behalf of the British Association for Continence Care (p 832).
It found that 14% of women had experienced urinary incontinence, 5.7% within the preceding week; the corresponding figures for men were about half these.
Other studies have reported the difference between the sexes and suggested a prevalence of urinary incontinence in adult women leading independent lives of between 22% and 45%.
Whichever estimate is closest to the true prevalence, urinary incontinence is undoubtedly common in apparently healthy people, especially women.
Among women, the prevalence rises with increasing age and parity and deteriorating general health.
But even young, nulliparous, and otherwise totally healthy women experience urinary incontinence.
Although urinary incontinence may be no more than a nuisance in some women, for many it is far more troublesome.
Some two thirds of women for whom incontinence occurs at least weekly regularly wear some sort of protection (such as a pad) before leaving home.
They substantially change their lifestyles, restricting normal day to day activities such as shopping, travel, physical recreation, and choice of clothing.
Incontinent women believe that their incontinence has affected their physical or mental health, and they may develop difficulties in relationships with family and friends.
In a recent survey one in five incontinent women were afraid that they smelt and one in nine believed that sexual activity was compromised.
In the MORI survey only 13% of incontinent people had ever confided their problem to their spouse.
Incontinent adults seem to have limited confidence in the medical and allied professions.
Although half the incontinent people in the MORI survey had consulted their general practitioner, other surveys have suggested a much lower proportion.
No single explanation exists for this.
Clearly, some people do not consider that their problem is serious while others do not attend because of embarrassment or fear of surgery.
One study found that nearly two thirds of patients had had their incontinence for over two years before they first sought professional advice.
More than 90% of incontinent people, however, considered that their general practitioner would be sympathetic or helpful to their problem; almost half would welcome some form of treatment.
What form should treatment take?
Most incontinent women have either genuine stress incontinence or detrusor instability, or both, yet distinguishing between these two on the basis of symptoms is impossible in a quarter of patients.
Although symptoms may give some guide to the severity of  the incontinence, they do not distinguish absolutely between genuine stress incontinence and detrusor instability.
But not every incontinent patient requires referral to a urodynamic unit.
If she complains of stress incontinence but denies any urgency or urge incontinence her doctor can safely assume that she has genuine stress incontinence.
Treatment with pelvic floor exercises produces improvement in 70% of cases and continence in 40%.
If the patient complains of urgency and urge incontinence but denies any stress incontinence; if the history and examination yield no other abnormal features; and if the urine tests negative for protein, glucose, red cells, white cells, and micro-organisms then detrusor instability is the likely diagnosis and the patient should be treated accordingly.
Behavioural treatments, such as bladder retraining, are time consuming but effective, making up to 90% of patients continent.
Drug treatment requires less skill but is less effective.
The current drug of choice is oxybutynin, which in divided daily doses of between 5 and 15 mg may improve symptoms in up to 70% of patients but will make only half of them continent.
Its side effects of dry mouth and blurred vision are common.
Patients who fail to respond to these regimens or whose symptoms do not allow an accurate clinical diagnosis should be referred.
For women it matters less whether they are referred to a gynaecologist or a urologist than that they are referred to someone with an interest in urinary incontinence.
If surgery for genuine stress incontinence is required suprapubic surgery is generally more likely than vaginal surgery to make the patient continent, although the risk of complications is higher.
Clearly, doctors see only a small proportion of patients with urinary incontinence.
Potential patients should know that we have much to offer them in alleviating symptoms and improving their lifestyle, even if currently the options are limited and imperfect.
Filtering white cells from blood for transfusion
Some benefits but expensive
White cells in donor blood may cause problems like fever and infection in recipients, and 99.9% of them can be removed with modern filters.
Some haematologists thus believe that all blood should be routinely filtered, and something like four million filters were used in the United States last year.
Routine filtration in Britain would cost the NHS more than £50m a year.
Particular circumstances exist in which filtration may be useful, and a consensus conference held at the Royal College of Physicians in Edinburgh tried to identify them.
Few randomised controlled trials have been conducted using filtered blood, and most of them have been small, unblinded, and concerned with laboratory rather than clinical end points.
Filtered blood is widely used to treat recurrent non-haemolytic febrile reactions in patients who depend on regular blood transfusions.
The reactions will generally not recur if 90% of the white cells are removed, and this can be achieved either by using a filter at the bedside or by removing them in the laboratory.
To prevent the reactions from occurring in the first place, filtered blood has to be used from the very first transfusion and 99% of white cells have to be removed.
Unfortunately, removing this many cells at the bedside seems to be hard to achieve in the NHS.
The panel, nevertheless, put this indication in the recommended category along with giving filtered blood to prevent the transmission of cytomegalovirus in patients seronegative for antibodies to the virus.
Again 99% of cells must be removed to prevent transmission of infection, and in many communities — including Britain — it is usually more cost effective to transfuse blood screened for cytomegalovirus.
In several countries filtered blood is recommended in patients needing multiple transfusions to prevent HLA alloimmunisation and platelet refractoriness, which may lead to unstoppable bleeding.
The Edinburgh panel decided, however, that HLA alloimmunisation was simply a laboratory end point and that the evidence was inconclusive that filtered blood prevented platelet refractoriness and bleeding.
Prevention of platelet refractoriness.
Some evidence is available that the use of filtered blood in surgical patients may reduce rates of postoperative infection and of recurrence of cancer, but other studies have yielded negative results.
The panel concluded that these amounted to only possible indications.
The panel was confident that filtered blood was not indicated to prevent graft versus host disease (irradiation of donor blood is better and cheaper); to prevent transmission of HIV or hepatitis B and C viruses; or in patients undergoing routine surgical procedures (with the possible exception of patients with cancer).
Any further increase in the use of filters should await, the panel concluded, much more rigorous studies on the quality of life and on costs and benefits.
PAPERS
Effects of prematurity and intrauterine growth on respiratory health and lung function in childhood
Abstract
Objective —
To determine whether birth weight and gestational age are associated with respiratory illness and lung function in children aged 5–11 years.
Design —
Cross sectional analysis of parent reported birth weight, gestational age, and respiratory symptoms; parental smoking and social conditions; forced vital capacity (FVC), forced expiratory volume in one second (FEV 1 ), forced expiratory rates between 25% and 75% and 75% and 85% (FEF 2 5 —7 5 and FEF 7 5 —8 5 ), and height.
Setting —
Primary schools in England and Scotland in 1990.
Subjects —
5573 children aged 5–11 (63.3% of eligible children) had respiratory symptoms analysed and 2036 children (67.1% of eligible children) had lung function measured.
Main outcome measures —
Symptoms of asthma, bronchitis, occasional and frequent wheeze, cough first thing in the morning, and cough at any other time and lung function.
Results —
Birth weight adjusted for gestational age was significantly associated with all lung function measurements, except FEF 2 5 —7 5 .
The association remained for FVC (b =0.475, 95% confidence interval 0.181 to 0.769) and FEV 1 (b =0.502, 0.204 to 0.800) after adjustment for gestational age, parental smoking, and social factors.
FEF 7 5 —8 5 was the only lung function related to gestational age.
Respiratory symptoms, especially wheeze most days (adjusted odds ratio 0.9, 0.84 to 0.97) were significantly associated with prematurity.
Every extra week of gestation reduced the risk of severe wheeze by about 10%.
Conclusions —
Lung function is affected mainly by intrauterine environment while respiratory illness, especially wheezing, in childhood is related to prematurity.
Introduction
The possibility that intrauterine growth of the fetus might be related to health in childhood and adult life has recently attracted considerable attention.
Birth weight has been used as a measure of fetal growth but it is strongly dependent on gestational age.
Prematurity itself might influence subsequent health and so the effects of prematurity and birth weight (adjusted for gestational age) need to be clearly separated.
Low birth weight has been reported to be associated with reduced lung function or with respiratory illness in children, adolescents, and adults.
Children whose birth weight was under 2000 g were more likely to experience troublesome cough, but not wheeze, than controls and their measures of lung function were significantly reduced.
In a large sample of adolescents low birth weight was associated with increased prevalence of asthma.
Barker et al reported that low birth weight was associated with lower adult lung function but not with symptoms of wheeze.
These results seem to indicate some consistency in the relation between birth weight and lung function, but there is less consensus concerning the relation between birth weight and respiratory symptoms.
Reduced lung function has been associated with low birth weight regardless of whether the child had respiratory complications at birth.
So far only one report has used information for both birth weight and gestational age as independent variables in the analysis.
If poor nutrition in utero is the main cause of the poor lung function children with low birth weight and normal gestational age would be expected to have lower lung function values than those of the same birth weight who were born prematurely.
We evaluated children's lung function and respiratory symptoms in relation to both length of gestation and the birth weight adjusted for gestational age.
Subjects and methods
The national study of health and growth is an annual survey of children aged 5 to 11 years.
Information was obtained from English and Scottish samples selected by stratified random sampling of employment exchange areas with proportionally more children from poorer social groups.
These samples have been found to be very similar socioeconomically to a representative sample.
At each survey children are measured and parents are asked to complete a self administered questionnaire.
In 1990, 8799 children mainly aged 5 to 11 years were eligible for the study.
This was the sample used for the analysis of birth weight, gestational age, and respiratory symptoms.
Lung function measurements were carried out in children aged 6.5 to 11 years in a subsample of study areas, resulting in 3036 eligible children.
Parents reported whether their children had suffered from attacks of asthma or bronchitis during the past 12 months, whether they usually coughed first thing in the morning or at any other time, whether their chest ever sounded wheezy or whistling, and, if so, whether this symptom was present on most days or nights.
Lung function was measured with a spirometer attached to a spirogram and digital printout.
Each child had three recorded attempts without a noseclip and with a minimum exhalation of 1.5 seconds.
For each child forced expiratory capacity (FVC), forced expiratory volume in one second (FEV 1 ), and forced expiratory rates between 25% and 75% and 75% and 85% (FEF 2 5 —7 5 and FEF 7 5 —8 5 ) were recorded.
All data from the best blow, defined as the greatest sum of FVC and FEV 1 , were analysed.
Values for each lung function measurement were expressed in standard deviation scores calculated by the method of Bland et al .
The predicted natural logarithm (1n) of lung  function was derived from multiple regression analysis of 1n lung function on 1n height and 1n age.
The difference between 1n lung function and the predicted value was antilogged, and the difference between result and the mean of the distribution of the antilogged residuals calculated and divided by the standard deviation.
Standard deviation scores were used to overcome the problem of increasing mean and variance of lung function measurements in the age range 6.5 to 11 years.
If SI units had been used results would have had to have been reported by height, age, and sex separately and the sample size would have been too small for useful analysis.
Height was measured on a Holtain stadiometer to the last completed 0.1 cm as described by Tanner et al .
Respiratory symptoms were analysed by multiple logistic regression and lung function standard deviation scores by multiple linear regression.
The explanatory independent variables in the analyses were birth weight and length of pregnancy as reported by parents in the questionnaire.
Birth weight and gestational age were included as continuous variables.
Adjustments were made for the continuous variables triceps skinfold (measured as recommended by Tanner and Whitehouse, expressed as standard deviation scores calculated by the method of Cole) and reported maternal height.
The following categorical variables were used: father's unemployment (yes, no, or not known); father's social class (non-manual, skilled manual, semiskilled and unskilled manual, and not known); one parent in the household (no, yes, not known); mother's age at child's birth (<20, 20–23, 24–27, 28–31, >32, and not known); mother's education (primary education, secondary education, further education, and university education); number of children (one, two, three, four, five or more, and not known); maternal smoking in pregnancy (no, yes, not known); total number cigarettes smoked at home at the time of the survey (0, 1–4, 5–14, 15–24, 25 or more, and not known); free school meals (free, not free, not taken, not known if free, and not known); overcrowding (<1.25 people per room, >=1.25; people per room, not known); maternal and paternal asthma (no, yes, not known); and study areas (27 areas for the respiratory illness analyses and 17 for the lung function analyses).
In the analysis of respiratory symptoms age (as a continuous variable) and sex were also included as independent variables.
The continuous variable weight for height expressed as standard deviation score was adjusted for in the analysis of lung function.
Birth weight was analysed in relation to gestational age by the method of Bland et al .
Expected values of birth weight for gestational age were obtained by regressing the natural logarithm of birth weight on gestational age.
The ratio of the observed birth weight to the predicted birth weight for gestational age was used as a measure of birth weight for age.
Children with missing values for gestational age or birth weight were excluded from the analysis.
Results
After excluding children for whom data on the continuous variables were missing 5573 (63.3%) were available for analysis of respiratory illness by birth weight and duration of pregnancy.
In the lung function analysis 2036 (67.1%) of 3036 eligible children had useful information on all variables.
Valid assessment of lung function was not available for 418 children.
For the remaining children excluded from the analysis because of missing data on other variables the mean values for FEV 1 , FVC, FEF 2 5 —7 5 , and FEF 7 5 —8 5 were -0.065, -0.007, -0.08, and -0.043 standard deviation scores respectively compared with 0.024, 0.014, 0.018, and 0.004 standard deviation scores for those included.
For the 1775 children with information on respiratory illness but not included in that analysis because of other missing data the prevalence of asthma attacks was 7.5%, bronchitis 1.8%, cough first thing in the morning 6.8%, cough at other times 14.8%, chest ever wheezy 11.0%, and wheezy chest most days 3.6% compared with 5.3%, 2.1%, 4.2%, 11.3%, 12.3%, and 2.6% for those included.
Table I gives the mean values for FVC, FEV 1 , FEF 2 5 —7 5 , FEF 7 5 —8 5 according to birth weight and length of pregnancy.
For children with normal length of gestation there was a positive association between birth weight and lung function.
A similar association was observed for FVC and FEV 1 in children with a low gestational age but it was less clear for FEF 7 5 —8 5 and birth weight was unrelated to FEF 2 5 —7 5 .
Figure 1 illustrates the association between birth weight and FEV 1 and the lack of association between duration of pregnancy and FEV 1 .
Table II shows the regression coefficients for lung function measurements in relation to length of gestation and birth weight adjusted for gestational age.
There was a significant positive slope for each lung function measurement with birth weight in the unadjusted model, although the relation with FEF 2 5 —7 5 and FEF 7 5 —8 5 lost significance in the adjusted model.
Only FEF 7 5 —8 5 was associated with gestational age (p<0.05).
Prevalence of respiratory symptoms was not associated with birth weight, but children with lower gestational age tended to have a greater prevalence of  frequent and occasional wheeze regardless of their birth weight (table III).
Table IV shows the odds ratios for respiratory symptoms in relation to birth weight, expressed as the ratio of observed weight to expected weight for length of gestation, and gestational age before and after adjustment for potential confounding variables.
The odds ratios give the association with respiratory illness in relation to the independent variables for a change of one week in length of gestation and 50% in birthweight ratio.
The odds ratios of respiratory illness in relation to birth weight were not significantly different from one — that is, the 95% confidence interval included one — in the adjusted models and only cough at other times was significantly associated (p<0.05) in the unadjusted analysis.
Length of gestation was significantly associated only with wheezy chest most days (p<0.01) and cough at other times (p<0.05) in the adjusted models.
Prematurity was not associated with reported asthmatic attacks.
Discussion
We found that length of gestation but not birth weight was associated with respiratory symptoms, and birth weight but not gestational age was associated with most lung function measurements.
The association between length of gestation and respiratory illness was greatest for symptoms of wheeze most days.
Every extra week of gestation reduced the risk of wheeze most days in childhood by about 10%.
As this was a population study the results on lung function and respiratory illness depended on the majority of children who were term babies and had normal birth weight, with low birth weight or premature infants accounting for only a minority.
Our study has the strengths that the sample sizes were large, the measurements have been carefully standardised, the fieldworkers were trained to measure lung function in a standard manner, and a large number of possible confounding variables were included in the analyses.
A possible weakness is that information for both birth weight and length of pregnancy was obtained by parental recall.
Accuracy of parental recall of birth weight and length of gestation have been studied by Seidman et al .
They reported that recalled birth weight was accurate to within 100 g in three quarters of cases and a similar proportion of reported gestational ages were accurate to within one week when compared with hospital records.
In their study maternal age, the length of time from birth, and maternal education were not related to the accuracy of reported birth weight.
Tilley et al found that even 10 years after delivery 95% of mothers were able to classify the birth weight of a child in broad categories.
Moreover researchers have found that internal inconsistencies in hospital case notes are common, especially in children with a low birth weight.
Parents' reports of birth weight and gestational age are sufficiently accurate for analysis and not necessarily worse than hospital case notes; lack of accuracy would decrease rather than increase the strength of the observed associations.
birth weight and lung function
We wanted to distinguish the possible effects of birth weight and gestational age on lung function and respiratory illness as this approach could provide clues for the differing role of environment in utero and level of maturation.
Most of the studies on this topic use only birth weight in the analysis and many of them study small samples of very low birthweight children.
Our results confirm the relation between birth weight and lung function measurements reported in other studies.
We calculated the possible effect of birth weight for a given age of gestation on FEV 1 using the example of two children of 38 weeks' gestation with the same attributes adjusted for in the analysis but one having a birth weight of 2500 g and the other 3500 g.
If the expected FEV 1 for height and age were 1.5 l and the expected birth weight 3300 g the difference in their expected FEV 1 would be 0.026 l; this difference would  increase to 0.031 l for a lower gestational age with an expected birth weight of 2700 g.
The same two children with an expected FEV 1 for height and age of 2.25 l would have an expected difference of 0.039 l in FEV 1 if the expected birth weight were 3300 g and 0.047 l if the expected birth weight were 2700 g.
So the approximate possible effect of birth weight on FEV 1 would be about 2% of total FEV 1 .
Gestational age does not contribute to this relation.
As we adjusted birth weight for gestational age we can say that environment in utero is an important factor in explaining the association between birth weight and lung function.
The environmental effect on lung function is further supported by the finding in other studies that among low birthweight children poor forced expiratory function is not dependent on neonatal respiratory events or their treatment.
In one of these studies the FVC in low birthweight children was not lower than in a reference group.
In our study most measures of lung function were associated with birthweight.
Therefore we could not confirm that airway growth is more vulnerable than peripheral lung growth in low birth-weight children as Chan et al showed.
The association was strong and was not explained by confounding variables including parental smoking at home, maternal smoking during pregnancy, and a large number of social factors.
In other studies information on maternal smoking during pregnancy was not available.
We found that adjusting for maternal smoking in pregnancy did not change the strength of the association between birth weight and lung function so that the effect of environment in utero on birth weight and subsequently on lung function may be independent of smoking in pregnancy.
Differences in the regression coefficients and the 95% confidence interval between adjusted and unadjusted analyses were minimal in each lung function measurement, underlining the consistency of the findings.
Our analysis did not show any consistent association between the six respiratory symptoms and birth weight, although other researchers have reported associations with various respiratory illnesses.
Alho et al reported that both gestational age and birth weight were independently associated with wheezy bronchitis.
However, Chan et al found an association between birth weight and cough but not wheeze.
Barker et al also failed to find a significant association between birth weight and wheeze.
Greenough and colleagues showed that preterm babies who did not require respiratory support had a high prevalence of wheeze and cough in the first year of life.
The respiratory condition in this group of children improved with age.
Furthermore there is no consistency in the reported findings between the type of respiratory illness and birth weight.
gestational age and respiratory symptoms
We found a strong association between gestational age and most respiratory symptoms, especially wheezing most days.
Most epidemiological studies have not analysed respiratory symptoms in relation to birth weight and gestational age separately.
Studies published in the late sixties reported that asthmatic women were more likely to have babies of less than 37 weeks' gestation than non-asthmatic women.
More recently, Bertrand et al suggested a link between familial airway hyperreactivity and premature birth, but Chan et al were unable to support a role of maternal asthma in low birth weight.
We found no difference in the frequency of low gestational age in asthmatic and non-asthmatic women.
In addition maternal and paternal asthma were included in the regression analyses and did not modify the association between independent and dependent variables.
Thus a familial component is unlikely to be a confounding variable between gestational age and wheeze in children.
This could be because asthma is now better controlled during pregnancy than previously.
The relation between respiratory symptoms and length of gestation that we found persisted after adjustment for birth weight and other possible confounding variables.
Our analysis suggests that fetal immaturity at birth rather than intrauterine environment would have a role in the aetiology of respiratory symptoms in children.
The mechanisms through which prenatal events influence lung function differ from those that affect respiratory symptoms in children.
This explains the consistency of the relation between birth weight and lung function and the lack of it between birth weight and respiratory illness.
Immaturity seems to play an important part in the subsequent development of respiratory illness in childhood.
An evaluation of the multidisciplinary approach to psychiatric diagnosis in elderly people
Abstract
Objective —
To determine the accuracy of psychiatric diagnoses made by two community psychogeriatric teams operating a multidisciplinary assessment procedure.
Design —
Comparison of team diagnosis with independent formal assessment and consensus diagnosis by research psychiatrists.
Setting —
Two community psychogeriatric teams with similar operational policies in an inner London health district.
Subjects —
100 people aged 65–90 (70 women) newly referred to the teams.
Main outcome measures —
Concordance between team and research diagnoses.
Results —
Agreement between team and research diagnoses ranged from 90% to 99% for the specific psychiatric disorders studied.
There was no significant difference between medical and non-medical team members in their diagnostic performance compared with the research psychiatrists.
Increased diagnostic accuracy by team members was associated with longer experience of team working, regardless of the team members' professional background.
Conclusions —
The multidisciplinary approach to the assessment of referrals to these community teams for the elderly is not associated with misdiagnosis of psychiatric disorder.
Introduction
Wherever comprehensive psychogeriatric services have been developed, they have usually been organised around the activities of some sort of multidisciplinary outreach team drawn from the professions of nursing, occupational therapy, psychology, social work, and psychiatry.
There are good clinical reasons for this approach, since elderly people with mental disorder suffer from a complex range of mental, physical, and social problems and no one profession is adequately equipped to deal with all of these on its own.
In addition, there are considerable organisational advantages if the various professionals concerned act as a team; use of staff resources is more efficient, service planning and development are facilitated, and there is better management of the caseload.
In urban areas, where the range of health professionals at the primary care level is still variable, a fully multidisciplinary approach to the assessment and management of cases is a valuable means of compensating for the limitations of particular general practices.
For the most part, multidisciplinary psychogeriatric teams have developed as an enhanced version of the traditional service, with the consultant as the team leader and decision maker and all patients receiving formal psychiatric assessment at some point during their contact with the service.
In some areas, however, a different model of teamwork has evolved in which the tasks of assessment and management are shared, and not all patients are necessarily seen at any time by a psychiatrist.
This development is in part a response to the rapidly growing demand for psychogeriatric services as a result of demographic trends, and in part to an acknowledgment that the multidisciplinary nature of these services needs to be fully reflected in the way they are managed and delivered.
This approach to psychogeriatric service provision is enthusiastically endorsed by its supporters, but others have expressed misgivings — for example, one survey has reported that referring general practitioners were suspicious of initial psychogeriatric assessments by non-medical disciplines.
A commonly expressed concern is that assessment by non-doctors may result in misdiagnosis and subsequent mismanagement of cases.
This is an important issue, and one that teams deal with by routine case review in the presence of a doctor and psychiatric reassessment wherever there is any doubt.
This aspect of the teams' activity has not yet been formally evaluated.
We report the findings of a study in which the psychiatric diagnoses made as part of the case assessments by two similar multidisciplinary psychogeriatric community teams were compared with formal psychiatric assessment and diagnosis.
Method
the teams
The London Borough of Lewisham is served by two multidisciplinary community teams for mental health in the elderly, which provide assessment, treatment, rehabilitation and support services to elderly mentally ill people living in this area.
One team was established in 1984, the other in 1987.
The teams have similar operational policies, including an open referral system, and accept cases from a wide range of agencies.
Initial domiciliary assessments are carried out by either a medical or a non-medical team member by using a semistructured schedule that guides them through the various clinical, functional, social, and other components of the assessment.
All cases are presented and discussed at the weekly team meeting, after which an initial diagnosis is made.
Further specialist assessments by other members of the team may take place at any time during the episode of care if they are considered necessary.
the study
Between May 1990 and February 1991, 101 (27%) of 378 new cases referred to the teams and assessed by them were independently and blindly assessed by a research psychiatrist (GC).
These were cases in which the research interview could be carried out within one week of the team assessment, to minimise disagreement due to changes in the patients' condition.
To control for primacy effects, approximately half of the cases were interviewed by the research psychiatrist before the team assessment, and the remainder afterwards.
Eighteen patients admitted to hospital after team assessment were reviewed by the research psychiatrist and included in this study, but one subject who was seen first by the research psychiatrist and admitted after that interview as a matter of urgency was excluded, leaving a study sample of 100 cases.
The research assessment consisted of a structured psychiatric interview (the geriatric mental state (GMS)), a full medical and psychiatric history, a  physical examination, and a routine blood screen which consisted of a full blood count, liver function tests, thyroid function tests, syphilis serology, and determining concentrations of urea, electrolytes, serum glucose, vitamin B-12, and folate.
A collateral history was taken from other relevant informants wherever possible.
The findings of the research assessments were presented by the research psychiatrist to two independent consultant psychogeriatricians (JH, JL), and a consensus research psychiatric diagnosis was agreed.
So that the research and team diagnoses would be comparable, relatively broad diagnostic categories for both were used.
The research diagnoses were compared with the diagnoses made by the teams after initial case assessment and review but before any subsequent reassessment by another team member.
The data from the GMS interview were also analysed using AGECAT, a computerised algorithm which uses ratings on the interview to assign subjects reliably to diagnostic categories at various levels of ‘caseness’; AGECAT classification at the diagnostic syndrome case level was used as an independent criterion for comparison with both the team and the research diagnoses.
The data were analysed with SPSS/PC+.
The concordance between the teams' and the research diagnoses and between these and the AGECAT classification is expressed here in terms of percentage agreement, specificity, sensitivity, and the kappa (κ) and Yule statistics.
The κ statistic is a widely used measure of observer agreement, but its value can be misleadingly low if the base rate of the condition in question is less than 20%.
An alternative is the coefficient of colligation (Yule statistic), which is mathematically similar to κ but stable over a wider range of base rates.
Results
The age range of the study sample was 65–90 years (mean 78.2 (SD 6.64) years).
There were 70 women and 30 men.
The source of referrals to the teams is shown in table I, and the occupation of the initial assessor from the community teams in table II.
The proportion of study cases initially assessed by more senior, non-training grades of psychiatrist (consultant or clinical assistant) was significantly lower than that of all new referrals over the study period (7% v 20%; χ 2 = 8.57; p<0.01).
There was no difference in the proportions of patients with various diagnoses seen by the doctors and non-doctors, in terms of either team diagnosis or research diagnosis.
The study sample did not differ significantly from the totality of new referrals in terms of age distribution, sex ratio, or referring agency, apart from having a lower proportion of referrals from old peoples' homes (8/100 v 10/378; χ 2 =4.87; p<0.05).
The distribution of team diagnoses after assessment was similar to that of the new referrals as a whole (table I).
In seven cases the three research psychiatrists could not agree unanimously on the primary diagnosis; in these cases the majority opinion (2:1) was taken as the research diagnosis.
Overall, there was complete agreement between the team and research diagnoses in 86 cases, and partial agreement in a further three.
For specific diagnostic categories, the percentage agreement was 90%; and above, with associated κ and Yule statistics strongly indicating that these agreements were not attributable to chance alone (table III).
Dementia was the diagnostic category with the highest misclassification rate in relation to the research diagnosis; in three cases the team diagnosis was deferred pending further assessment and investigation.
The three cases of misclassification of delirium were due to the time delay between the team and research assessments; by the time of the second assessment, the delirium apparent at the first had substantially resolved to reveal an underlying depression or dementia, or both.
Table IV shows the diagnostic agreements according to the profession of the team assessor.
The performance of the two groups was similar across all diagnostic categories; overall, non-doctors performed slightly better against the research diagnoses, with complete agreement in 87 cases, compared with 82 for doctors, but this difference was not significant.
Table V shows the diagnostic agreements according to the experience of the assessor as a member of a community team for mental health in the elderly.
Those with greater experience performed better, with an overall complete agreement with the research diagnosis in 93 cases, compared with 78 for the less experienced team members (p=0.051, Fisher's exact probability (two tailed).
When compared with the GMS/AGECAT diagnostic syndrome case identifications, the team and research assessments performed comparably, showing good agreement in the more prevalent categories of organic illness and depression and lower concordance in rarer categories (table VI).
Discussion
This study shows that the psychiatric diagnoses made by these multidisciplinary psychogeriatric teams are very similar to those arrived at by formal research diagnostic assessment and review by psychogeriatricians.
If deferred diagnoses and the artefactual disagreements involving delirium are excluded, there was complete agreement in 89% of the cases and complete or partial agreement in 92%.
Of course, psychiatric diagnosis is not an error free process, and it is possible that in a proportion of the cases where there was diagnostic disagreement it was the research assessment that was in error; it should be noted that in some cases the research psychiatrists could not agree among themselves on the diagnosis.
It is important to emphasise that this study is not a full and formal validation of the teams' activities.
Firstly, it has examined only one aspect of the assessment process; it does not consider the functional, financial, behavioural, and social aspects, all of which are arguably as important as clinical diagnosis in planning patients' management.
Another important aspect of assessment not addressed by this study is that of physical disorder.
Secondly, this is not a comparative evaluation of different models of service, since the standardised diagnostic assessment carried out in this study by the research psychiatrist is not the same process of assessment that occurs in domiciliary visits performed by psychogeriatricians in more traditional services.
The close agreement between the teams' assessment diagnoses and those made by formal psychiatric review is reassuring, in that the multidisciplinary approach to initial assessment seems not to lead to misdiagnosis of patients.
In this study there was no significant difference in the diagnostic performance of doctors and non-doctors; in fact, this study indicates that the team members' experience of working in the community team is a more important determinant of diagnostic accuracy than their professional background.
Many of the initial assessments by doctors in this study were carried out by trainee psychiatrists who spent only six months with the team as part of their training; had the proportion of assessments by consultant psychogeriatricians and clinical assistants in the sample been more representative, the agreements between team and research diagnoses might have been closer still.
The teams involved in this study are mature and well managed, and the findings may not be relevant to ‘younger,’ less developed teams where greater medical supervision of and involvement in assessment is necessary.
All multidisciplinary teams operating this model of service require clear procedures, firm management, appropriate training, and ongoing professional and clinical supervision if they are to perform well — a point that is insufficiently appreciated by both supporters and critics of this model of service.
The role of the consultant psychogeriatrician in this service is different from that in the conventional model; rather than being the principal performer of the initial diagnostic assessments, he or she is directly involved in assessing only dubious, difficult, and urgent cases.
This frees valuable time for the supervision and training of trainee psychiatrists and other team members in the assessment and management of patients and for the developmental, managerial, and audit tasks that are increasingly necessary for the efficient running of a modern comprehensive psychogeriatric service.
Changing demography and limited resources mean that manpower issues will be increasingly important for the provision of health services in the years to come, not only in less glamorous specialties such as old age psychiatry but in all areas of medicine.
A broad and imaginative approach to this problem is needed; the  existing skill mix and the capacity of other health professionals to carry out tasks previously restricted to scarce and expensive professionals, such as doctors, must be examined.
The model of multidisciplinary teamwork that has emerged in old age psychiatry potentially provides a means whereby the valuable experience of the several disciplines concerned can be applied to the widest possible range of those who need it.
However, further evaluation is needed of the other important aspects of psychogeriatric assessment, and of the long term outcomes associated with this particular style of service.
Evaluating perinatal mortality rates: effects of referral and case mix
Abstract
Objective —
To evaluate perinatal mortality rates as a method of auditing obstetric and neonatal care after account had been taken of transfer between hospitals during pregnancy and case mix.
Design —
Case-control study of perinatal deaths.
Setting —
Leicestershire health district.
Subjects —
1179 singleton perinatal deaths and their selected live born controls among 114362 singleton births to women whose place of residence was Leicestershire during 1978–87.
Main outcome measure —
Crude perinatal mortality rates and rates adjusted for case mix.
Results —
An estimated 11701 of the 28750 women booked for delivery in general practitioner maternity units were transferred to consultant units during their pregnancy.
These 11701 women had a high perinatal mortality rate (16.8/1000 deliveries).
Perinatal mortality rates by place of booking showed little difference between general practitioner units (8.8/1000) and consultant units (9.31–11.7/1000).
Perinatal mortality rates by place of delivery, however, showed substantial differences between general practitioner units (3.3/1000) and consultant units (9.4–12.6/1000) because of the selective referral of high risk women from general practitioner units to consultant units.
Adjustment for risk factors made little difference to the rates except when the subset of deaths due to immaturity was adjusted for birth weight.
Conclusion —
Perinatal mortality rates should be adjusted for case mix and referral patterns to get a meaningful result.
Even when this is done it is difficult to compare the effectiveness of hospital units with perinatal mortality rates because of the increasingly small subset of perinatal deaths that are amenable to medical intervention.
Introduction
Evaluation in obstetrics is well developed, and the confidential enquiry into maternal mortality serves as a model for other mortality reviews.
The House of Commons Social Services Committee, however, has recently repeated its recommendation, first made in 1980, that epidemiological reviews of perinatal mortality rates should also be established.
The Department of Health has endorsed this by requiring regional health authorities to establish epidemiological surveys of all stillbirths and neonatal deaths.
In addition obstetricians conduct audits of their services and health authorities attempt to make purchasing decisions using, among other things, data on perinatal mortality.
While we welcome the use of such reviews, it is important that appropriate comparisons are made so that correct conclusions are drawn from differing perinatal mortality rates.
For example, how can the perinatal mortality rate of an affluent part of East Anglia, with its low incidence of congenital malformations, be compared with that of an inner city area in south Wales, where a higher incidence of congenital malformation is combined with social disadvantage?
Since the mid-1970s we have reviewed perinatal mortality rates in Leicestershire to describe the cause and number of perinatal deaths and to use this information to influence local services.
This report describes the referral patterns of women during pregnancy and the effect this has on the interpretation of perinatal risk; compares crude perinatal mortality rates between different maternity units; shows how adjustment for case mix influences the initial rates; and suggests ways of making analyses of perinatal mortality rates more relevant for evaluating obstetric and neonatal care.
Subjects and methods
sample population
In 1981 the population of Leicestershire was 845000, of whom about 60000 originated from the Indian subcontinent.
The data below relate to the 1179 perinatal deaths that occurred in the 114362 singleton deliveries to women resident in Leicestershire during 1978–87 regardless of place of delivery.
study design
We used a case-control design with cases defined as perinatal deaths occurring among women whose place of residence was Leicestershire.
The control for  each perinatal death was the next live birth born to Leicestershire woman in the intended place of delivery of the baby who died perinatally.
We collected data by reviewing case notes and interviewing the women.
We calculated standardised perinatal mortality rates for the delivery units by using logistic regression to estimate relative risks adjusted for confounding factors and then standardising these rates by multiplying by a constant chosen so that the standardised rate for all Leicestershire agreed with the crude observed rate.
The confounding factors were patients' characteristics that had been shown to be predictive of increased perinatal risk.
Maternal risk factors known at booking were age under 18 or over 35; primiparity or parity of more than three; being in manual or non-manual work; being less than 158 cm tall; attending antenatal care after 18 weeks' gestation; having diabetes; being a smoker; being of Asian origin; having a history of infertility; having a husband in social class III manual, IV, or V; and having a general practitioner not on the obstetric list.
Risk factors known before the start of labour were gestational diabetes, urinary tract infection, pre-eclamptic toxaemia, antepartum haemorrhage, more than seven days of inpatient care, and no antenatal care.
If a baby had a low birth weight this also increased the risk.
Our adjustment for these confounding factors meant that any remaining differences in perinatal mortality rates were more likely to have been due to differences in the care received by patients.
This was a two stage study, in which a detailed case-control study of a subset of data is undertaken within the framework of a large, less detailed dataset.
Such studies are particularly suited to subjects such as perinatal mortality rates; the comparatively rare perinatal deaths and their controls are nested within the framework of the large dataset of all notified births.
We used a logistic regression method for analysing our two stage study that allowed for the control sample being stratified and corrected the estimates for differing sampling rates in different strata (the different hospitals).
Although corrected estimates are easy to obtain, no software exists which correctly computes confidence intervals for the estimates of the regression coefficients.
Here we present approximate 95% confidence intervals for the crude rates.
The correction of the rates by logistic regression slightly increased the width of the confidence intervals, but this had little effect on our conclusions.
classification of perinatal death
Wigglesworth described the difficulty of devising a classification of perinatal death to satisfy obstetricians, neonatologists, pathologists, and epidemiologists.
His classification allowed all perinatal deaths to be categorised whether or not necropsy had been undertaken.
This review included deaths in more than 30 hospitals, most of which did not have paediatric pathology services.
Our method of classification was derived from that of Wigglesworth but slightly differed from it.
Using time of death in relation to delivery, gestation, and absence or presence of congenital abnormalities, we classified each death into one of four categories: congenital malformations; macerated stillbirths (prepartum stillbirths); asphyxia in labour (intrapartum stillbirths and early neonatal deaths at >=38; weeks' gestation); and immaturity (early neonatal deaths at <38 weeks' gestation).
classification of hospitals
Women in Leicestershire used 30 consultant units and nine general practitioner units during the study.
In this analysis hospitals 1 and 2 were the county's main consultant units, all the other consultant units were grouped together as hospital 3, and all the general practitioner units were grouped together.
During the study all but one of the general practitioner units were closed.
Results
We estimate that 13206 (12%) of the 114362 women were delivered at hospitals where they were not initially booked for delivery (table I).
Referral to other hospitals was particularly common for women who were initially booked for delivery at general practitioner units: 11701 (41%) of the 28750 women were delivered in consultant units.
These 11701 women had the highest perinatal mortality rate of any group shown in table 1 (16.8/1000 deliveries).
In contrast, the women who were booked at general practitioner units and delivered there had by far the lowest perinatal mortality rate (3.3/1000deliveries).
Thus nearly four fifths of the perinatal deaths that occurred among women booked at a general practitioner unit did so in a consultant unit.
When the perinatal mortality rate was calculated on the basis of the hospital attended at the start of labour the crude perinatal mortality rate in hospital 1 (12.6/ 1000 deliveries) was a third higher than that in hospital 3 (9.4/1000 deliveries).
No estimates of perinatal mortality rates were made for the units where few referrals and subsequent perinatal deaths occurred.
Table II shows the perinatal mortality rates for each of the four categories of perinatal death among women who were booked for delivery at a general practitioner unit.
The distribution of deaths in this group among the four categories was similar to the distribution of all perinatal deaths in the study.
In contrast, macerated stillbirths were underrepresented in the stillbirths that occurred at general practitioner units while deaths  due to asphyxia in labour were overrepresented.
This reflects the more predictable nature of macerated stillbirths and the less predictable nature of asphyxia in labour.
Adjustment for risk factors made little difference to the mortality rates except when birth weight was included in the adjustment for the deaths due to immaturity.
Table III shows the perinatal mortality rates for each of the four categories of perinatal death for the four places of delivery.
These data are equivalent to those produced by the registrar general.
Hospital 1, which had the highest overall perinatal mortality rate (table I), also had the highest perinatal mortality rates for congenital malformation and macerated stillbirth.
These two categories, however, are only indirectly affected by obstetric management.
Asphyxia in labour and immaturity are more directly affected by obstetric and paediatric management.
For these categories hospital 1 had the lowest perinatal mortality rates among the consultant units after adjustment for risk factors.
By far the greatest effect on the crude mortality rates was when mortality rates due to immaturity were adjusted for low birth rate.
Discussion
More than 100 years ago Florence Nightingale compared mortalities between maternity hospitals and suggested that differences in the construction of the hospitals might account for differences in mortality.
More recently mortality in hospital has again become a subject of concern, as has the difficulty of comparing mortalities in hospitals.
The problems of interpreting perinatal mortality rates have been described by Campbell and MacDonald Davies and Tew.
Over the past 15 years perinatal mortality rates have more than halved while the social and political pressure to measure and interpret them has increased.
We have shown that in over 110000 deliveries there are only small, non-significant differences in perinatal mortality rates between hospitals when the place of booking is considered and that these are further reduced when adjustments are made to allow for the risk factors known at booking.
Overall 12% of women were delivered at hospitals other than the one where they were initially booked.
Such changes occurred most commonly when women were initially booked to deliver at general practitioner hospitals: 40% of them were delivered at a consultant unit.
Perhaps not surprisingly, the women transferred to consultant care had the highest perinatal mortality rates.
For 70% of such women, however, the outcome was not amenable to intervention as the baby died before labour or death was due to a congenital malformation.
The transfer of these women from general practitioner care to hospital care accounts for much of the apparent mortality advantage of general practitioner units, a finding that contrasts with Tew's observations.
Adjustment for risk factors known before the start of labour made little difference to perinatal mortality rates, but such differences that occurred were in the expected direction.
For example, adjustment increased the low perinatal mortality rate for women who were delivered at a general practitioner unit and decreased the high rate in hospital 1, which had an accident and emergency department.
The small effect of adjustment for case mix may not be the same throughout Britain.
The two main city obstetric units in Leicestershire possibly care for women with differing risk profiles, so that the excess risks in one population are offset by different excess risks in the other.
Adjustment for birth weight had the greatest effect on the perinatal mortality rates due to immaturity: the rate among women who were booked at general practitioner units and were delivered at hospital 1 fell from 3.6 to 1.0.
This shows how important such adjustments can be for units that provide neonatal intensive care.
Perinatal mortality rates are affected by a broad range of biological, social, and medical factors.
As Wigglesworth suggested, only perinatal deaths due to asphyxia in labour and immaturity directly reflect the effectiveness of medical care, and these categories accounted for only 16% and 23% of perinatal deaths, respectively, in this series — an average of 46 deaths a year from an average of over 11000 births occurring in several hospitals.
In view of the factors discussed above it is most unwise to compare the effectiveness of hospital units by means of crude, unadjusted perinatal mortality rates.
Residential care for elderly people: a decade of change
Abstract
Objective —
To determine the changes between 1979 and 1990 in demography and dependency levels in elderly people in residential care.
Design —
Censuses of those aged 65 years and over in any type of residential care at midnight on 11 December 1979 and 27 November 1990.
Setting —
Leicestershire District Health Authority (population 865133, 1991 census), coterminous with county and social services boundaries.
Main outcome measures —
Age, sex, length of stay, and dependency levels (measured by activities of daily living).
Results —
In 1990 (1979), 6079 (4678) elderly people were enumerated in 241 (133) establishments, a 30% increase in the numbers of elderly people in residential care and an 82% increase in the number of establishments between 1979 and 1990.
Dependency levels rose between 1979 and 1990 in all but the geriatric sector, the greatest increases being found in private residential homes where the largest percentage increase in the number of residents had occurred.
Conclusions —
Dependency levels in residential care have risen substantially, particularly in the private sector, even beyond levels expected from the greater numbers of elderly people.
With the impending move to community care, dependency levels are likely to rise further, and more appropriate staff training and medical input to homes will become necessary.
Introduction
Substantial changes in the provision of long term care for elderly people have taken place over the past decade.
Increased interest in using NHS geriatric beds for assessment and rehabilitation has led to increased turnover and shorter length of stay, with an expansion of acute beds and a decrease in the number of long stay beds.
Government policy has been to close large mental hospitals and wherever possible to move to care in the community, with a resulting decrease in the number of psychiatric hospital beds.
At the same time, local authorities have been subject to increasing financial constraints, resulting in the level of provision of accommodation by social services remaining static or even contracting slightly.
The private residential sector, on the other hand, has expanded considerably, with greater numbers of both homes for elderly people and nursing homes.
The reasons for this are a political philosophy of increasing private provision coupled with changes in the funding arrangements for those entering residential care, specifically the introduction of supplementary benefit payments to those unable to afford the fees at private homes.
Entry then became based on financial rather than medical or social assessment, and in 1983 upper limits were set on supplementary benefit, resulting in a massive increase in the total national bill for supplementary benefits to people in private sector homes — from £105m in 1983 to £500m by 1986.
Concern that this uncontrolled expansion of the private sector had been siphoning off funds that might have been more cost effectively used in home based community care led to the government commissioning reviews of resource management and quality of care.
These formed the basis for the 1990 National Health Service and Community Care Act, the final phase of which is to be implemented in 1993.
The first census of people over 65 in residential care in Leicestershire was undertaken in 1976, with a second in 1979.
Given the changes over the previous decade, a further review of the size and distribution of the Leicestershire residential care sector was considered to be essential both to set an information baseline before the implementation of the National Health Service and Community Care Act and to document changes in the demography and levels of dependency of the residential care population.
This paper presents comparisons of the residential care populations in 1979 and 1990.
Methods
The survey population comprised all those aged 65 years and over who were resident in any type of ward, hospital, home, or hostel provided by the NHS, local authority social services department, or private and voluntary agencies within Leicestershire at midnight on 27 November 1990.
The time of year was chosen to be as close as possible to that of the 1979 census to ensure that seasonal mortality effects would not confound results.
The census was confined to homes containing four or more residents registered (under the provision of the 1984 Registered Homes Act) with the health authority or the local authority for purely practical reasons.
Homes with fewer than four residents are not, as yet, required to register with social services, and since no formal list of these homes exists, the size of this sector remains unknown.
Questionnaires were delivered to each establishment in the week before census night by members of the University of Leicester departments undertaking the survey, who explained the questionnaire to a senior staff member.
The questionnaire, covering demographic details and levels of health and functioning, was completed by care staff for each person in their  establishment on census night.
The information collected, which was directly comparable with that obtained in 1979, fell into two broad sections: demographic data, including date and place of admission, date of birth, sex, and marital status; and information on functioning of residents during the previous week in activities necessary for daily living such as mobility, continence, and the ability to wash and dress and to feed.
For each resident, mobility was assessed on four levels (fully ambulant, ambulant apart from stairs, needing attendant or aid, bedfast).
Washing and dressing and also feeding were classified as requiring no supervision, supervision only, or help on at least one occasion.
Urinary incontinence was classified as dry requiring prompting, occasionally incontinent, and frequently incontinent, and faecal incontinence was either present or absent.
A fuller description of the derivation of these questions on activities of daily living has already been provided.
As in 1979, individual questions were combined to form a total activity of daily living score ranging from 0 to 11, with higher scores denoting higher dependency.
statistical methods
The changes in specific variables (such as mobility) in the types of care between the censuses were assessed by forming cross classifications between the type of care, year of census, the variable of interest, age group, and sex.
(Age and sex were included to account for the changing age and sex structures of the populations between the censuses.)
The resulting tables were analysed by log linear modelling techniques using generalised linear interactive modelling.
Results
In 1990, 6079 residents were enumerated in 241 establishments, including 21 NHS hospitals, 160 homes for elderly people (46 run by the social services departments, 105 private residential, and nine run by voluntary agencies), 32 private nursing homes, and four hospitals or hostels for the mentally or physically handicapped (table I).
Twelve homes refused to take part and for these homes only basic information on the type of home, address, and number of beds was available.
All 12 homes, spread throughout the county, were in the private sector, nine being residential homes, two nursing homes, and one run by a voluntary agency.
The maximum number of residents in total in the 12 homes was 281, the smallest home refusing to participate having six beds and the two largest 41 beds.
The response rate in the 1990 census was 95.3% for establishments and 95.6% for residents (enumeration of establishments was complete in 1979).
These figures constituted an increase of 82% in the number of establishments and 30% in the number of elderly people resident since 1979 (table I).
Full details of the 1979 census have been published.
The proportion of people aged 65 years and over in residential care in Leicestershire was 4.2% in 1979 and 4.7% in 1990, similar to the national level of around 5%.
When these figures are broken down into age groups a strong increasing gradient with age is obvious (table II).
Estimates of life expectancy in residential care at specific ages can be calculated by using a method proposed by Sullivan which applies the age specific and age specific prevalences in five year bands to the 1990 population figures and death rates for England and Wales.
In 1990, men aged 65 years could expect to spend around six months of their 14.2 years of remaining life expectancy in residential care; for women of the same age this figure was 1.1 remaining years, an amount greater both absolutely and as a proportion of total remaining life expectancy (table III).
In fact, women at all ages spent proportionately  more of their remaining life expectancy in residential care than men.
The major demographic changes that occurred between 1979 and 1990, in particular the increase in very elderly people (85 years and over), had significant effects on the age and sex structure of the majority of the care sectors (table IV).
As a consequence of the changing age-sex distribution of the population over the decade between the censuses, we have grouped comparisons of other demographic and health factors by age and sex.
The total activity of daily living score was dichotomised into high dependency (score 7–11) and other.
Subsequent analysis showed that in all cases there had been significant changes in the proportions with high dependency over the decade between the censuses after age and sex standardisation (χ 2 =18.0, df=1, p<0.0001), and these changes were significantly different between types of care (χ 2 =61.2, df=6, p<0.0001)(table V).
Analysis of the separate components of mobility, washing and dressing, feeding, and urinary and faecal incontinence gave the same results.
Discussion
Unbiased estimates of dependency levels in the different sectors can be achieved only by high enumeration and response rates.
Despite the large increase in the private sector, which has no single administrative body to which all private homes belong, only 12 homes refused to participate in the 1990 census, rendering it most unlikely that the changes in both demography and dependency in any sector are a result of response bias.
Recording error on the part of staff, either purposeful or accidental, is less easily dealt with in a study such as this.
Where possible, data items were cross checked against one another and the establishments were asked to clarify the few inconsistencies that arose.
What is not clear is the direction of any bias that might have occurred.
Staff of private establishments in 1990 may have overestimated the actual disability of their residents, or the methods of care in these homes may lead to increased dependency.
On the other hand, some staff may have underestimated dependency in order that homes did not appear understaffed.
Although these biases cannot be refuted, in reality the staff completing the schedules tended to be those dealing with residents on a day to day basis, rather than home owners and managers, who might have been more concerned with the implications the results may have had for their establishment.
The changes that have occurred since 1979 in the pattern of long term care for older people in Leicestershire, above and beyond the aging of the general population, highlight some of the challenges that many local authorities face in implementing the final phase of the ‘Caring for People’ community care reforms.
Firstly, it is clear that a transfer of responsibility has taken place between the different forms of provision.
The reduction in the scale of long term geriatric provision has been accompanied by an increase in the provision of residential care and nursing homes.
Likewise, the decrease in the proportion of highly dependent people in NHS beds has been countered by increases in the proportions of dependent people in other sectors.
Many would also argue that this process has continued into the community, with a greater proportion of people with complex care needs now remaining in the community rather than entering some form of residential care.
Several researchers report similar results in particular sectors, though they have not shown the complete picture.
On the other hand, not all geographical areas have yet seen the same changes.
Our findings contrast with those of Campbell in South Belfast and Stott et al in Glasgow, since geriatricians in both Scotland and Northern Ireland have continued to provide long term care and the growth in the private sector began somewhat later than in England.
Although considerable variations remain in the levels of dependency (as measured by activity of daily living scores) of people accommodated in different forms of provision, this distinction seems to have narrowed since 1979.
This suggests that there is now a greater degree of overlap in the characteristics of people accommodated in different forms of care.
This blurring of the boundaries may be of little consequence to users of the service, but it does have implications for the type of care they receive and which agency remains financially responsible for arranging that care.
Though the number of people over the age of 65 is predicted not to increase over the next 10 years and to rise slowly thereafter, the profile of this group will change considerably.
Later cohorts of elderly people may be fitter, although medical science is unlikely to alleviate the major impact of chronic degenerative diseases.
Any further increases in dependency levels in local authority and private residential homes will have  implications for staff training and morale as well as for more frequent medical assessment.
Finally, both health authorities and local authorities are firmly committed to a policy of supporting older people in their own homes for as long as possible.
Surprisingly, the results of this third census in Leicestershire show that the proportion of older people in some form of residential care increased little over the past decade.
The greater absolute numbers of elderly people have been absorbed by the growing private sector despite a simultaneous collapse of long term provision in the NHS, and this has been widely attributed to the impact of the central government funding system for private residential care.
This remains the situation that social service departments will inherit in April 1993, when social services assume responsibility for private care.
Managing this situation while at the same time implementing the organisational, funding, and cultural changes that are required must be regarded as one of the foremost challenges facing local authorities.
GENERAL PRACTICE
Urinary incontinence in the community — analysis of a MORI poll
Abstract
Objectives —
To investigate the prevalence of urinary incontinence among people living at home, their responses to it, and its emotional and social effects.
Design —
Random sample of 4007 adults interviewed in their own homes.
Setting —
Random sample of 178 constituency sampling points throughout Great Britain.
Subjects —
1883 men, 2124 women aged 30 and over.
Main outcome measures —
Responses to questionnaire.
Results —
6.6% (125) men and 14.0% (297) women had been incontinent of urine at some time — 2.8% (52) men and 7.5% (159) women in the previous two months and 61% (124) of these for more than four years.
52% (108) had consulted their general practitioner at the onset of incontinence and a further 31% (65) later.
Doctors commonly took a urine sample (163, 54%), referred the patient to a specialist (127, 42%), and prescribed tablets (109, 36%); only 22% (66) carried out an abdominal, rectal, or vaginal examination.
Patients were not embarrassed in seeing their doctor and most thought they were treated sympathetically.
60% (265) of all those affected were concerned or worried about their incontinence, and in almost half incontinence limited their daily social activities.
Conclusion —
More people with incontinence seem to be consulting their doctors about it than has been found in previous studies, but the procedures carried out by general practitioners still seem to be suboptimal.
Urinary incontinence has a profound effect on the day to day lives of most of those who suffer from it.
Introduction
Despite great advances in differential diagnosis and management of urinary incontinence in the past 25 years the handicap that it imposes on the sufferer has not been explored to any extent, nor has the way in which help has been sought and the effectiveness of such help.
More than one year's delay in reporting the symptom to the family doctor has been recorded in over half of cases, the main reasons for this being the hope that it will go away and embarrassment in talking to the doctor about it.
Even when incontinence has been reported to the general practitioner the use of available facilities (for example, continence advisers) is limited.
To obtain a picture of the present prevalence of incontinence in the community, the handicap associated with it, and the current uptake of services, the British Association for Continence Care commissioned a poll from Market and Opinion Research International which was carried out in 1991.
Thirty two questions were asked.
Seventeen of the most relevant are the subject of this analysis.
Method
A random sample of 4007 adults (1883 men) aged 30 and over was interviewed in their own homes at geographically stratified sampling points throughout Great Britain.
Three quarters of the interviewees were women — reflecting the known greater prevalence of the symptom among women.
The data have been weighted back to reflect the profile of the population over 30 in Britain.
The instrument used was derived from discussion with four groups of members of the general public (with and without incontinence) who explained their attitudes and the perceived effect on lifestyle.
The questionnaire was administered by trained interviewers.
The symptom of incontinence was broached in the question ‘Have you ever suffered from any of these health problems?’— a list of 15 problems being shown on a card.
Problems included backache, chest pain, constipation, depression (feeling ‘down’ for long periods of time), and alcohol problems.
The third item on the list was ‘bladder problems, e.g. leaking, wet pants, damp pants.’
A positive answer registered the person as incontinent.
Results
prevalence
In all, 297 women (14.0%) and 125 men (6.6%) were, or had been, incontinent.
Table I shows prevalence by age, sex, and recency of the symptom.
The important figures for comparison with other surveys are 3.8% (72) men and 9.3% (197) women incontinent in the previous year and 2.8% (52) and 7.5% (159) respectively in the previous two months.
The expected increase with age and greater prevalence in women was found.
Table II analyses 203 subjects who were incontinent in the previous two months by duration of symptom (45% (92) for between four and 15 years and 16% (32) for over 16 years).
No important difference was found between the duration of symptoms in those incontinent in the previous two months and those incontinent in the previous year.
action taken
The action taken by sufferers on first realising that incontinence was a problem is shown in table III.
Again there was no important difference between those incontinent for two months or one year.
A total of 52% (108/209) consulted their general practitioner — significantly more men and rather more of the younger sufferers and those in full time work.
Respondents were asked the further question, ‘What did you do when you had the problem for some time?’
A further 31% (65) went to see their doctor — suggesting that over 80% had consulted their general practitioner at some time.
Fourteen per cent(29) did nothing about their incontinence when it first occurred — the main reason being that it was ‘not important enough.’
Only 13%  (26) spoke to their spouse about it, and fewer than 10% mentioned it to another family member or friend.
Six per cent(11) spoke to a nurse and 1% (two) referred themselves to a special clinic.
Action taken by general practitioners is shown in table IV.
It consisted principally of taking a urine sample (54%, 163), referral to a specialist (42%, 127), and the prescribing of medication (36%, 109).
More men than women were referred to a specialist.
Less than a quarter were given an abdominal, rectal, or vaginal examination — more of these being younger women.
Doctors also advised their patients to drink less tea and coffee, go on a diet, practise pelvic floor exercises (in each case 9%, 26).
Twelve patients (4%) were told to read a book or leaflet about incontinence.
There were definite regional differences in the action taken by general practitioners (data not shown).
For instance, twice as many subjects in Wales were referred to a specialist or given an abdominal examination than in Humberside and Yorkshire, and half as many were prescribed tablets.
Of 123 subjects receiving medication, 40 (36%) thought it was very effective and 36% fairly effective.
Of those consulting their doctor only 38 (13%) felt embarrassed in talking to him or her of their symptoms (no difference between men and women).
Ninety three per cent(279) found their doctor understanding.
Sixty (20%)(17 (15%) men, 43 (23%) women) consulted women doctors.
Those who were not incontinent (3584) were asked what they thought they would do and how they would feel if they were incontinent.
Ninety five per cent(3391) would go to their doctor and only 15% (492) said they thought they would feel embarrassed by so doing.
Ninety one per cent(3096) would expect their doctor to be understanding.
Of those, continent and incontinent, who felt they would be embarrassed the reasons were ‘too shy’(63, 33%), ‘too personal — a topic not spoken of’(54, 28%), ‘wouldn't like to admit wetting myself’(25, 13%).
There was little age or sex difference for these answers except ‘admit wetting myself’— 21% (13) of those aged 30–39 compared with 6% (two) of over 70s.
attitudes and lifestyle
Thirty four per cent(144) of all sufferers were concerned and 29% (121) were worried when incontinence first started (more men than women); 30% (125) felt embarrassed, 10% (43) smelly, and 8% (33) ashamed — in these cases more women than men.
Nine per cent(40; equal proportions of men and women) felt angry.
Regarding effect on lifestyle, 154 (36%) sufferers felt there had been a great deal or fair amount of effect (55 (45%) men and 99 (34%) women).
Only 97 (23%) felt no effect on their lifestyle (equal proportions of men and and women).
The figures are different to the perception of those not incontinent who were asked the same question: 71% (2564) thought that the condition would have a great deal or fair amount of effect on their lifestyle and only 20% (692) not much or none at all.
More details of the effect on lifestyle of sufferers are shown in table V. Only 30–45% (63–94) feel very confident in the major activities of social life.
All activities were more curtailed in older and male sufferers than in those who were younger and female.
Again, non-sufferers would have anticipated even greater restrictions resulting from incontinence.
The general restrictions imposed by incontinence (among all those incontinent at any time) were drinking less when going out (35%, 146), making a conscious effort to find out where public toilets are (33%, 141), going out less (15%, 65), and restricting activities such as lifting (10%, 43).
perceptions of causes of incontinence
Both sufferers and non-sufferers were asked about their perception as to the cause of incontinence (table VI).
In both groups one quarter perceived it to be caused by a medical condition, particularly more older male sufferers.
Twice the proportion of incontinent women aged 60 or over attributed their incontinence to childbirth than women non-sufferers in that age group (16% (22)v 7% (52)) thought likely.
Fifteen per cent(18) of men thought their incontinence was due to age or old age, compared with 5% (15) of women sufferers.
A very small proportion of sufferers thought that it was due to previous surgery (28, 7%) or to muscle weakness, anxiety, infection, overweight (14 (3%) or less in each case).
More non-sufferers attributed incontinence to anxiety, muscle weakness, or infection (6%, 201–5 in each case), whereas 20% to 30% had no opinion as to its cause — more non-sufferers, more men, and more subjects aged over 60.
Discussion
prevalence
Of the many surveys of prevalence of urinary incontinence few report only on people living in their own homes.
These in turn are complicated by differing definitions of incontinence, and in particular the following variables: when it last occurred; how frequently; and whether or not it poses a social or hygienic problem (no study addressed this question directly).
The method of information gathering (by questionnaire or face to face interview) may also affect the results.
In women younger than 65 years reports have fallen into two main groups — those finding about 50% prevalence and those reporting very much lower figures.
Jolleys reported 41% (343) of women of all ages having inappropriate leakage of urine, but in 232 (70%) of these it amounted to only dampening of underwear.
In those studies with lower prevalences it must be presumed that dampness was not regarded as incontinence (although the words ‘damp pants’ were included in the questions asked in the MORI poll).
In older age (60–75 or more) there is reasonable concordance between the present study and those of Thomas et al and McGrother et al , but differences with others are considerable.
The prevalence of incontinence according to the International Continence Society's definition — a condition in which involuntary loss of urine is a social or hygienic problem and is objectively demonstrable — is unknown.
effects
As 61% (124) of subjects first suffered incontinence four or more years earlier, there is inevitably a possibility of recall bias.
Just over half reported visiting their general practitioners at the onset and a further 31% at some time later — actions which they might be expected to remember.
Clearly they did take incontinence seriously.
The great majority were not embarrassed in approaching their doctor and were happy with his or her attitude.
Norton et al found that 25%-35% of women had delayed for five years or more before seeking medical advice.
Half of them felt too embarrassed to talk to their general practitioner and a similar proportion hoped that the symptom would go away.
Nineteen per cent of Norton et al 's subjects thought the symptom was normal.
The action taken by general practitioners was generally limited to taking a urine sample, referring to a specialist, or prescribing tablets.
In a minority of cases an abdominal, rectal, or vaginal examination was performed.
These results suggest that medication is often prescribed without clinical examination and probably without a diagnosis being made.
The fact that three quarters of those prescribed medication thought it to have been very or fairly effective may be thought to vindicate this as a first line approach, but side effects from anticholinergic drugs are common, and important diagnoses (for example, a neurological condition) may be delayed.
Fewer than 5% of those who consulted a doctor were referred to a nurse or incontinence clinic, a figure which accords with that of Briggs and Williams, who found 42 of 101 general practitioners surveyed never used the service of a continence adviser for older patients although the service was available to them.
There have been few studies of the social and emotional effects of incontinence.
In the present study 60% of incontinent subjects were concerned or worried about their incontinence and 34%-45% felt it affected their lifestyle considerably.
Non-sufferers regard incontinence as more handicapping than do sufferers, which suggests that these figures are no exaggeration.
Incontinence was seen as a moderate or severe social handicap by 37% of subjects in the present sample (the same as found by Wyman et al ).
Embarrassment (13%) and concern about smell (10%) were also similar to previous findings.
Norton et al reported that half of their sample of incontinent women felt odd and different from other people and 40% less attractive because of their bladder problems.
No figures are available to compare to those in this study as to people's perception of the causes of urinary incontinence.
It is notable that a quarter of both incontinent and non-incontinent subjects think it is due to a medical condition, a quarter of incontinent women that it is due to childbirth, and a quarter don't know.
This survey shows that the emotional, social, and hygienic effects of urinary incontinence remain considerable.
Medical advice is generally sought at some stage, but the action taken by general practitioners still seems to be suboptimal and shows considerable geographical variation.
Continuing efforts in public and medical education about incontinence are still required.
EDUCATION & DEBATE
Weighting in the dark: resource allocation in the new NHS
National allocation of resources to regional health authorities and by them to districts is now determined by a weighted capitation formula.
The national formula was derived from regression analysis, with hospital utilisation as an index of need for health care — a method which has fundamental limitations.
This paper argues that the search for an empirically based resource allocation formula of high precision in the name of promotion of equity is largely fruitless given the impossibility of measuring the true need for, and costs of, providing health care, especially with the limited data available.
The inclusion of measures of social deprivation is also poorly thought out.
The availability of data from the 1991 census, which included a question regarding longstanding illness, together with the intention of the Department of Health to review the weighted capitation formula using this information may stimulate much work but little light.
It is essential that the impact of resource allocation formula is justifiable on grounds other than the composition of any particular formula.
Introduction
Since the report of the Resource Allocation Working Party (RAWP) revenue allocations of regional health authorities for hospital and community health services have been moved towards targets derived from a weighted capitation formula.
The principles laid out by RAWP underlay regional targets until 1991, when a new formula was used.
The Department of Health is also keen that this formula should be used as the basis for sub-regional distribution.
As these resources affect the ‘purchasing power’ of the commissioning authorities the use of the formula is seen as a way of creating a level playing field for purchasers.
Resource allocation mechanisms are always contentious but because of reduced real growth in total funding in the current year debate over the way resources are shared between and within regions has intensified.
The National Health Service Management Executive is about to review the weighted capitation formula in the light of the 1991 census data.
Any change is likely to set the framework for the distribution of NHS finances for the foreseeable future.
It is crucial now to consider the fundamental issues which analysis ought to address.
Our concern is that the availability of data from the new census, together with the increase in access to computers since the last census, is likely to lead to a veritable orgy of statistical analysis, and, if the past is a reliable guide to the future, this analysis will obscure rather than illuminate fundamental issues in resource allocation.
This paper aims to explore some of the key issues, clearly set out some of the pitfalls, and provoke some deeper thought and debate about how new research can usefully inform resource allocation.
In particular, this paper will highlight some of the tensions between the empirical method of producing resource allocations based on statistical modelling of the available data and a more normative approach which allocates according to a more explicit theoretical rationale and political choices.
Effects of the new formula
There is much confusion within health authorities about the construction of the new formula which weights the age adjusted population of each region by the square root of its under 75 years, all cause, standardised mortality ratio.
The formula is derived from the review of RAWP, which carried out a detailed statistical regression analysis using ward based hospital utilisation data from six regions.
Though the RAWP review made some sensible changes to the national formula such as using all cause premature standardised mortality ratio, the resulting weighting was particularly contentious.
In the original RAWP formula standardised mortality ratio was included with a weighting (and elasticity) of 1 — that is, a 10% increase in standardised mortality ratio increased the weighting of that region, and hence its revenue target, by 10%.
The review of RAWP estimated an equation in which standardised mortality ratio has an elasticity of roughly 0.5, so the same 10% increase in standardised mortality ratio would lead to only a 5% increase in funding target.
(As the equation used a logarithmic scale a coefficient of 0.5 is the equivalent of the square root of standardised mortality ratio in the unlogged formula, which explains the use of the square root of standardised mortality ratio in the national weighted capitation formula.)
The reduced weighting of standardised mortality ratio in the final formula resulted in a shift in resources from the regions with higher premature mortality (predominantly in the north) to those with lower premature mortality (mainly in the south east) as shown in the first column of the table.
The large amounts of money involved mean that, though small, the percentage shifts have a considerable effect on resources received by each region.
The review of RAWP also examined the use of census based socioeconomic variables (so called‘social deprivation’ factors) to explain variation in health service use over and above that associated with the standardised mortality ratio.
However, despite the fact that various combinations of social variables were statistically significant predictors of utilisation none were included in the new weighted capitation formula.
The Department of Health decided to adopt part of the model (the reduced weighting for standardised mortality ratio) and ignore the index of social factors.
This pushed most regions further from their original RAWP targets than the full model would have done and increased the relative shift of resources to the south east.
The table shows how the funding targets of the 14 English regions are affected by the use of the reduced weighting of standardised mortality ratio and the effect that including the socioeconomic variables would have  had.
In the first nine regions, including the social variables would have resulted in a change of target allocations which opposed the effect of reducing the weighting of  standardised mortality ratio — that is, they act in the same direction as standardised mortality ratio.
In seven of these regions failure to include the social variables resulted in a reduction of target revenue of between 1.0% and 1.8%.
Problems with the new formula
empirical model
There has been criticism of the methodological validity and statistical soundness of the review of RAWP.
One of the aims of the review was to produce a formula which was empirically based as opposed to the original RAWP formula, which included standardised mortality ratio as a proxy for need on theoretical grounds.
This empirical emphasis is only sensible when the factors which policy makers think merit funding can be measured accurately enough.
As resource allocation is meant to embody the principle of equal access for equal need this presents the problem of measuring need for health care.
This concept may be classed as one which is ‘essentially contested’— that is, a concept whose application is inherently a matter of dispute.
based on utilisation
Utilisation measured by admission rates at the small area level was used as the measure of need, with an attempt to adjust for the current level of supply of health care facilities.
This raises two important questions.
Firstly, as there is consistent evidence of variations in use of services being explained by variations in supply, a formula based on variations in use between even small areas will partly reflect variations in supply.
Using measures which explain variations in utilisation in normative formulas is to confuse what is with what ought to be.
The reductio ad absurdum is a formula which funds the status quo through specious ‘objective’ measures.
Secondly, the objective of the weighted capitation formula is not to identify relative need or morbidity but to allocate resources with the aim of meeting these needs.
It is then also necessary to estimate the costs of treating that morbidity, something which neither RAWP nor the review attempted.
The fact that one area has 30% greater utilisation does not imply 30% more cost if the pattern of morbidity (case mix) is different.
But it is difficult to see how normative assessments of these variations can be made.
instability
The weighted capitation formula has been advanced not only as a mechanism for allocating national resources among the 14 regions but also for subregional allocation.
Given that it is based on a model which examined variation among electoral wards within only a few regions it could be argued that it is more validly applied at a local level.
‘Using measures which explain variations in utilisation in normative formulas is to confuse what is with what ought to be.
However, the model is unstable in that though the average weighting of standardised mortality ratio was around 0.5 (0.44) for the six regions, it ranged from 0.2 in Wessex to 0.72 for the Trent region, depending on which regional dataset is used.
The coefficients are likely to vary even more widely for those regions whose data were not included in the modelling exercise.
Empirical methods are fraught with problems.
They certainly provide no good evidence for reducing the weight given to standardised mortality ratios in the formula and there is no justification for encouraging the use of the national formula for subregional allocation.
As a result of the general confusion and criticisms of the national formula regions have adopted a wide range of different formulas for subregional allocation, often commissioning local research, some of which repeats the errors of the RAWP review.
Social deprivation
There has been considerable pressure to incorporate a measure of social deprivation in resource allocation formulas, and several regions have already included some form of deprivation weighting in their subregional allocation.
The rationale behind this is not always clear.
A common justification is that social deprivation is a cause of (or associated with) morbidity.
However, because deprivation is also associated with excess mortality some of this is already picked up by including standardised mortality ratio.
Though there is some additional variation in utilisation rates which is explained by social factors, it is relatively small and does not necessarily mean that additional variation in morbidity would be explained.
Another justification advanced is that social deprivation variables tap aspects of need for resources not adequately represented by morbidity measures — for example, that it is more difficult to provide services in a deprived area or that effectiveness is reduced by adverse conditions.
However, rarely are such rationales clearly worked out or attempts made to provide evidence in support of these claims.
In addition, it is claimed that people of different socioeconomic groups make different demands on the health service at similar levels of sickness or ‘objective’ need and that the cost of meeting these needs may also vary.
This, however, is mostly supposition and there is little evidence to support these arguments or to indicate the resource implications of this even if they are valid.
Even if true, there is little evidence to show that the bulk of hospital care is particularly sensitive to meeting the needs of deprived populations.
Several studies have recorded socioeconomic differences in the uptake of various forms of health care by individuals using data from the general household survey and the third national morbidity survey.
Weights have also been derived by using self reported chronic sickness as a measure of morbidity and a proxy for health care need.
However, these relations are likely to be geographically unstable.
Recent work has shown that the strong correlation between scores on  the Nottingham health profile and deprivation scores for the ward of residence for a sample of people in London was not reproducible in non-metropolitan areas.
There is little justification in using weights derived from individually based analyses in a regional formula for two main reasons.
Firstly, because they are derived without adjustment for standardised mortality ratio their use in a formula containing standardised mortality ratio will result in considerable double counting.
Secondly, as the weights are derived from analysis of individuals there is a serious problem of applying them at the level of wards or districts where the information is readily available only in aggregate.
This can result in a significant mis-estimation of the resource needs of the area.
‘best’ index of deprivation
Several other deprivation indices have been advanced and are used elsewhere.
However, the choice significantly affects the final geographical distribution and their use in resource allocation has been questioned.
There is an evolving industry where indices are developed which measure deprivation more accurately and attempt to identify the ‘best’ one.
These indices are usually validated against utilisation rates (see above) or by how well they correlate with various measures of morbidity available routinely.
Such efforts are, we believe, misdirected.
If it is decided that use of a measure of material deprivation is informative and conceptually sound, then simple measures based on easily available and regularly updated measures would be preferable to the opaque and statistically complex derived indices.
Data such as unemployment rates have been shown to perform as well as other, more complex indices and are likely to have a more stable social meaning across areas and over time.
This raises the question of why measures of deprivation are being put forward instead of morbidity measures.
The lack of a gold standard for health service need was a reason for using standardised mortality ratio in the RAWP formula.
The decision to use measures of deprivation as a proxy for need seems to sidestep the problem, with debate revolving around how well the proxy — deprivation — can be measured.
Indeed, discussions of this aspect often seem to consider the function of health services to be to compensate for deprivation itself rather than for its health damaging effects.
Even using apparently direct measures of morbidity is problematical, as reporting may be different between social groups, especially in response to general questions such as the ‘limiting longstanding sickness’ item in the general household survey and 1991 census.
The pattern of appropriate allocation is also highly sensitive to the morbidity measures used and it is not clear how variations in morbidity relate to actual resource needs.
Those health authorities which express most interest in refining formulas by varying the factors included tend to be those which have lost out with the current formula.
Commissioning research on the use of deprivation indices in allocating formulas is therefore often seen as a means of arguing more effectively for a bigger share.
It is difficult for conceptually sound research to be conducted in such an environment.
‘Commissioning research on the use of deprivation indices…is…seen as a means of arguing…for a bigger share.
In short, those who propose a deprivation weighting must decide whether this is to be additional to or a substitute for mortality.
If an indicator of social deprivation is additional to mortality, then how are the effects of each to be identified and understood?
We have described the problems of using data on utilisation of services which we see as offering no reliable way of weighting different indicators.
If an indicator of social deprivation is a substitute for mortality, then this means discarding the best available direct proxy for morbidity, which is after all what much of the NHS seeks to respond to rather than some ill defined concept of social deprivation.
Case for standardised mortality ratios and age weighting
Some regional health authorities have sought to abandon the use of standardised mortality ratios altogether.
One argument advanced for this is that it makes no sense to include mortality data in a formula for resource allocation as dead people make no use of health services.
To this there are two responses.
Firstly, standardised mortality ratios broadly reflect the cumulative morbidity and social experience of an area and provide more stable and comprehensive measures of morbidity than utilisation rates (or, indeed, contemporaneous deprivation indices).
It has been well established that death rates are highly correlated with the incidence of chronic diseases which are known to justify health service intervention.
Secondly, as Knox argued after publication of the RAWP report, people who are dying are among the heaviest users of services.
A famous American study indicated that as much as 28% of Medicare expenditure was spent on those in the last year of life.
In the United Kingdom it is not possible to get comparative estimates for individuals, but in England and Wales in 1984, 23% of non-psychiatric beds were occupied by people who died before discharge (G Bevan, unpublished observations).
Hence variations in mortality not only indicate variations in morbidity but also variations in the great need for services in caring for those with conditions with a high number of deaths.
Thus an important contribution to the age weighting in the formula which uses age related utilisation at national average rates is due to the utilisation of very elderly people who subsequently die.
It is therefore crucial to include standardised mortality ratios alongside age weightings to correct for variations in life expectancy.
A district with a high under 75 years standardised mortality ratio will tend to have people dying earlier than expected in the younger age groups, and applying national average rates of use of service to those groups will underestimate its relative need for health services.
Using utilisation data to derive age weights suffers from similar problems to those outlined for weighting standardised mortality ratio, though they are at least derived from individual as opposed to area based data and so are not subject to the ecological fallacy.
The national data on use of services by age may indeed not truly reflect needs of individuals at different ages; there is, after all, evidence of rationing by age, so the elderly may not get the health care they need.
But this raises ethical as well as clinical judgments.
There is a natural appeal in using age weighting in the formula based on the normative assumption that individuals in a given age group ought to have the same utilisation of services wherever they live.
It is hard to see what sense there is in, for example, assuming that individuals without a car ought to have the same utilisation of services wherever they live.
This is true for any social variables  including social class which are not necessarily geographically robust proxies for exposure to risk factors and for health care needs.
The issue of age weighting does, however, highlight a problem with migration of elderly people to retirement areas, which are then given a relatively high level of estimated need for health care resources.
Variations in need in the elderly are a particular problem for which there is currently no satisfactory indicator.
This requires further investigation.
The future: what value another review?
The Department of Health has signalled its intention to review the formula in the light of 1991 census data, again using small area analysis.
As by the time any new formula is developed and implemented the information will be nearly as out of date as that used in the RAWP review, any new analysis may be little more informative than the last with respect to the role of social variables.
Much attention will focus on the inclusion in the census for the first time of the self reported limiting, longstanding sickness item.
However, although the availability of new and more contemporary data generates much activity, interest, and publishable analyses, it might not cast much more light on the resource allocation problem for the reasons outlined above.
As all cause standardised mortality ratio is highly correlated with, and so is a good proxy for, chronic sickness it is not clear how much extra information the new census question will provide for mapping the distribution of health care need useful for resource allocation.
There is also, of course, a new problem with the 1991 census, of underrecording — probably because of the poll tax.
This threatens the reliability of both basic population data and attempts to use these new census data in social indicators to identify poverty.
‘By the time any new formula is…implemented the information will be…out of date.
More research using the new data can be useful, however, in exploring the sensitivity of the model to a variety of changes in assumptions and included factors.
For example, though the use of under 75 years standardised mortality ratio is more sensitive to regional variations, any measure of death rates with an absolute age cut off will be dominated by the mortality experience of men who have a shorter average life expectancy.
In order to compensate for this it would be worth exploring the effects of using, say, under 65 years standardised mortality ratio for men and under 75 years standardised mortality ratio for women, which will be based on similar numbers of deaths.
Other measures of mortality experience, such as years of potential life lost, which have different age weightings and are more sensitive to social class differentials, are also worth exploring.
It is also worth examining how mortality indices best combine with age weighting to reflect relative needs for health care.
Knox, for example, showed how the original RAWP formula essentially allocated resources according to crude death rates.
inevitable move to unvalidatable proxies
However, it must be recognised that a comprehensive and accurate empirically based resource allocation formula cannot be achieved.
This is because once the decision has been made to move away from incremental allocation based on historic spending the question of what merits funding is raised before issues of measurement.
This cannot be articulated in a sufficiently quantifiable form, and even those elements more amenable to measurement will not be able to be measured accurately.
Inevitably we are moved in the direction of using proxies which cannot properly be validated.
Once the use of a partial empirical model is accepted then it will be open to constant revisions and adjustments as new data become available.
It will also become the focus of political lobbying by health authorities who stand to gain by this or that factor being included.
The resulting contention and potential instability will hinder long term health care planning.
This is made worse by the lack of clear objectives for the health service to which the formula can respond and attempt to follow.
As long as the limitations are recognised and understood and those who allocate are seen to be acting fairly and using socially accepted criteria such as equity and efficiency, the use of rough, though conceptually sound, mechanisms (for example, the original RAWP formula) is most probably as good as we can get.
There are real limits to the use of statistical modelling in this area for two reasons.
Many of the factors (social or otherwise) which may affect either the need for or the cost of delivering health care are unevenly distributed, often in small pockets, and do not present in the same way — or have the same social meaning — in different parts of Britain.
These may take the form of problems which even if proved empirically to influence resource needs do so in such particular, local, and sometimes subtle ways that statistical models are unlikely to be sensitive enough to be helpful.
Modelling will tend to mask small but important variations which may be adequately understood only by local research.
For example, it has been shown in certain studies that providing health care to some more isolated rural populations is more expensive than in less sparsely populated areas.
However, it is impossible to produce some rural weighting which is generalisable to all rural areas.
Similarly the extra health care needs of homeless people which have been documented in parts of London reflect local conditions and cannot validly be applied to all areas.
More research needs to be done to attempt to understand these problems but statistical modelling is not appropriate.
It is not possible to measure accurately the cost of meeting health care needs, the magnitude of health care needs, or their proxies, and then proxies of proxies, down the line.
Therefore complex data derived methods which obscure rather than highlight the provisional nature or sensitivity of the models should not be developed.
accountability of commissioning authorities
As districts merge and form larger purchasing organisations and the overall variability between health authorities is reduced due to averaging, so increasing amounts of the variation will be contained within authorities and therefore beyond the reach of resource allocation formulas despite the devolution reflected in locality planning.
This should focus our attention more on the nature of health care commissioning activity.
What mechanisms are in place to ensure that health care services are purchased in a manner likely to result in equity between social groups and individuals?
This is an important issue which needs addressing given that commissioning authorities are not particularly accountable to the public and that an increasing proportion of purchasing power has devolved to general practitioner fundholders, who are not necessarily  geographically distributed in proportion to need.
The problems of developing a capitation formula for fundholders raises, of course, all the problems discussed here with two further complications: the small numbers of practice populations and the potential selection of patients by practices (cream skimming).
Public health physicians propose the technology of health needs assessment as the mechanism by which the purchasing process will be made to respond to the distribution of the population's needs.
However, there is little basis for confidence, since, as Frankel writes, ‘research activity has been concerned almost exclusively with the probability of neediness and not with the distribution of those who might be expected to benefit from particular interventions.
The established measures of need are…of uncertain relevance to the decisions about the need for health care that concern those engaged in commissioning provision.’
The preoccupation in the past has been with the total size of the health service budget, how it is shared out at the macro level, and how much activity it funds.
As the use of equity based financing mechanisms reduces the degree of inequality of allocation nationally the potential benefits to be derived from developing increasingly elaborate models for allocation are likely to be small.
Attention should increasingly be focused on how resources are used — the effectiveness and appropriateness of health service interventions — studying the distribution of indications for health care as a means of increasing not only efficiency but also equity within the context of democratically driven priorities.
The purpose of this paper has been to argue against weighting in the dark: an industry of resource allocation which is abstracted from research into and the management and delivery of health services.
As resource allocation is a ‘zero sum game’(that is, authorities can gain only at the expense of others) it seems essential to be able to explain why different formulas produce different results in terms other than the composition of the formulas.
The common failure to produce such explanations threatens to undermine the clear principles of resource allocation as stated in the original RAWP report and to bring NHS formulas into disrepute.
‘Authorities can gain only at the expense of others.
We do see scope for research into resource allocation but believe this ought to be quite different from the common practice of the 1980s of relating census variables to utilisation rates.
The new kinds of research we advocate would aim to produce clearer understanding of variations in need for and utilisation of health services, with the objective of identifying how resources can be used more equitably and efficiently.
These after all were stated in the original RAWP's terms of reference and remain as valid now as they were in 1975.
Is routine induction of labour at term ever justified?
Balancing the risks of prolonged gestation against those of induced labour is difficult.
Risks to the fetus increase slightly after 42 weeks’ gestation but women having labour induced are more likely to have instrumental deliveries or babies with low Apgar scores.
Since many women are now expressing a preference for minimal interference in childbirth the most acceptable management of post-term pregnancy seems to be increased fetal surveillance.
Each case needs to be considered individually and it is important that the woman is involved in the decision to induce.
Although the World Health Organisation defines term as 37–42 completed weeks of pregnancy (259–294 days), most pregnant woman and many midwives think of term as the expected date of delivery.
Women are given an expected delivery date that is calculated as 40 weeks (280 days) after the first day of the last menstrual bleed.
But it is uncommon for the baby to arrive on that date, and women find it disappointing and sometimes worrying if delivery does not occur soon after this time.
Perhaps we should reconsider whether it is necessary to give women a precise date on which they should expect their baby to arrive.
Accurate dating of pregnancy is important for other reasons, such as prenatal diagnosis and early identification of intrauterine growth retardation.
In addition, ultrasonographic dating has been shown to reduce the incidence of truly prolonged pregnancy from about 10% to as low as 1%.
Even among women who are sure of their dates the incidence of post-term pregnancy can be halved if an early ultrasound scan is performed.
This is important as the outcome for women whose labour is induced for ‘uncertain postmaturity’ is significantly worse than for those who have labour induced at 42 weeks' gestation.
Risks of post-term pregnancy
Perinatal mortality is lowest at 40 weeks' gestation and does not increase until after 42 weeks, and then only slightly.
But because some intrauterine deaths will always occur before 42 weeks it might seem sensible to deliver all babies at 42, 41, or even 40 weeks.
The problem is induction of labour.
Induced labour is longer and is associated with more instrumental deliveries, an increased risk of postpartum haemorrhage, and perhaps most importantly, a higher incidence of low Apgar scores than spontaneous labour.
If the point of inducing labour is to reduce risks to the neonate then it may be failing.
Many women see induction as interference with a natural process
Before intravaginal prostaglandins were used regularly to ripen the cervix women having labour induced were more likely to need caesarean section, which carries a risk of morbidity (and an increased risk of mortality) for the mother.
However, the Canadian multicentre post-term pregnancy trial group found that women allowed to go into labour spontaneously had a higher rate of caesarean section (24.5%) than those who had labour induced (21.2%) because of an increased incidence of fetal distress in the first stage.
Unfortunately, the group did not define fetal distress, and the increased incidence may have been related to the higher rate of meconium staining of the amniotic fluid in spontaneous labours, which is to be expected at a later gestation.
There was no difference in the incidence of meconium aspiration, one of the greatest neonatal risks of prolonged pregnancy; nor were any other differences in perinatal outcome recorded.
The intervention rate (instrument and operative delivery) in this large study of 3407 uncomplicated prolonged pregnancies, was 49% among women randomised to induction of labour and 51% for those who were monitored while awaiting spontaneous labour.
In the United Kingdom many midwives, obstetricians, and mothers would consider this an unacceptably high level of intervention in an otherwise normal physiological process.
Women who go into spontaneous labour before their estimated date of delivery are fortunate as the risks to both mother and baby have been shown to increase as ‘term progresses.’
But there is no evidence that inducing labour improves the outcome for mother or baby.
Many women see induction as interference with a natural process and it is one of the reasons why they write ‘birth plans.’
When to induce
If routine induction of labour at term cannot be justified, when should intervention occur?
Bergsjo et al suggested 43 weeks' gestation as induction at this time has a lower incidence of failure.
However, a fixed cut off point seems unnecessarily prescriptive.
Each case needs to be considered individually and timing of  delivery should be based on the woman's risk factors.
Earlier induction of labour would obviously be preferable for a 40 year old primigravid woman with a long history of infertility, even after an uncomplicated pregnancy, whereas it may be inappropriate for a 25 year old multiparous woman.
The state of the cervix (Bishop's score) should also be considered.
If delivery with an unfavourable cervix is thought essential it may be better to deliver by elective lower segment caesarean section under epidural block than to risk the need for an emergency caesarean section under general anaesthesia in the middle of the night.
Emergency caesareans carry a much higher risk of morbidity and mortality to the mother and asphyxia to the baby.
Recent data from King's College Hospital have shown an unacceptable incidence of unrecognised maternal morbidity associated with caesarean section and this may be compounded by the need for repeated operative delivery in subsequent pregnancies.
Alternatives to induction
Is there anything we can do for women who go past term?
Membrane stripping has been suggested to produce earlier spontaneous labour and have no complications, but it is also an intervention that many women would dislike.
The best policy is probably to offer increased fetal surveillance after 42 weeks (or earlier if risk factors are present) and to terminate the pregnancy if adverse features occur.
Pearce and McParland showed that the most sensitive measure in antenatal fetal surveillance is absence of end diastolic frequencies in the umbilical artery (assessed by Doppler ultrasonography).
This predicted 91% of fetuses who became distressed in the first stage of labour, and combination with ultrasonographic estimation of the volume of amniotic fluid improved prediction to 100% with only a slight fall in specificity.
Perhaps the most important part of managing post-term pregnancy is involving the woman and her partner.
The decision to induce or not should be discussed, and if possible the woman's views respected.
I discuss induction of labour at 42 weeks' gestation in an otherwise uncomplicated pregnancy and offer it if the cervix is favourable and the woman keen to be delivered.
I encourage women to have induction at 43 weeks' gestation because of the slightly increased risk to the baby thereafter.
Unfortunately, there is no ‘right time’ to induce nor any conclusive data on which to base a rational decision.
Lesson of the Week
Acute haemolysis induced by high dose ascorbic acid in glucose-6-phosphate dehydrogenase deficiency
High dose ascorbic acid can cause haemolysis in glucose-6-phosphate dehydrogenase deficiency.
The use of high dose ascorbic acid (vitamin C) has been advocated for a wide range of ailments for years.
Such treatments are generally thought to have few adverse effects and are often self administered.
We present a case illustrating the particular caution necessary in subjects at risk of glucose-6-phosphate dehydrogenase deficiency.
Case report
A 32 year old man born in Britain of Nigerian parents was admitted as an emergency case complaining of breathlessness, dark urine, and left subcostal pain radiating to the left shoulder.
His history included malaria caught in Nigeria at the age of 11 and treated uneventfully with quinine.
There was no family history of haemolytic crises and he had been healthy until December 1991, when he was found to have antibodies to HIV-1.
There were no known risk factors for HIV infection.
The exact source of the infection was unclear.
His CD4 lymphocyte count was 0.35×10/l.
He had remained well until June 1992, when he developed generalised lymphadenopathy and his doctors recommended that he should start zidovudine.
He had refused, however, and sought advice privately from a medically qualified nutritionist.
An extensive nutritional screen was performed, including measurements of blood mineral, vitamin, and fatty acid concentrations.
Among several abnormalities noted were low serum and red cell glutathione concentrations (red cell glutathione 1.1 mmol/l (normal 1.6–2.8 mmol/l), serum glutathione 3.2 µmol/l (normal 3.8–8.2 µmol/l)).
He was prescribed a course of multivitamins, essential fatty acids, and glutathione supplements.
He was also prescribed a course of high dose intravenous ascorbic acid, 40 g three times weekly, supplemented by 20–40 g ascorbic acid daily by mouth.
This proceeded uneventfully for about a month with no obvious evidence of either haemolysis or regression of lymphadenopathy.
The intravenous dose was increased to 80 g, and next day the patient became breathless and feverish and noticed that his urine was black.
His symptoms worsened over the next two days and he returned to the nutritionist.
Results of blood tests were: haemoglobin concentration 67 g/l, white cell count 12.7×10/l, platelet count 198×10/l, reticulocyte count 15.6%, bilirubin concentration  54 µmol/l (conjugated bilirubin 13 µmol/l), hydroxybutyrate dehydrogenase activity 557 IU/l (normal 100–280 IU/l), alkaline phosphatase activity 104 IU/l (normal 100–280 IU/l), creatinine concentration 93 µmol/l, urea concentration 7.3 mmol/l, sodium concentration 136 mmol/l, and potassium concentration 4.5 mmol/l.
His coagulation screen was normal.
Blood was detected in the urine on biochemical screening, but microscopy showed very few red cells.
A blood film showed changes typical of oxidative haemolysis.
He was admitted to hospital and encouraged to drink 4–5 litres of fluid daily with careful monitoring of renal function.
He was given folic acid by mouth.
A glucose-6-phosphate dehydrogenase assay performed on reticulocyte depleted blood confirmed deficiency with a value of 1.8 IU/g haemoglobin (normal 5.9–11.8 IU/g).
Haemoglobin electrophoresis showed sickle cell trait.
The haemoglobin concentration continued to fall for two days after his admission, reaching a nadir of 61 g/l.
On the third day his urine was clear and his renal function remained normal.
He made an uneventful recovery and was discharged home after four days.
Discussion
Ascorbic acid has been used in pharmacological doses for more than 20 years.
It has been proposed as useful in a wide range of conditions, including hypertension, colds, HIV infection, hepatitis A and hepatitis B, myocardial infarction, cancer, cataract, asthma, Parkinson's disease, schizophrenia, arthritis, cystinuria, alkaptonuria, myeloma, leukaemia, iron overload, methaemoglobinaemia, and immune thrombocytopenic purpura.
The evidence supporting its use in these conditions is variable, but there are few adequate clinical trials suggesting definite benefit.
In general the ascorbic acid is thought to act as a free radical scavenger or by a direct antiviral effect.
Its use in HIV infection stems from anecdotal reports of clinical benefit after high dose ascorbic acid and from subsequent in vitro experiments showing suppression of HIV replication in chronically infected T lymphocytes.
There are no published trials proving its clinical efficacy.
Despite little definite evidence supporting the use of high dose ascorbic acid, it is widely favoured by doctors and patients as healthy, natural, and without appreciable side effects.
Reported contraindications include renal insufficiency, chronic haemodialysis, some forms of iron overload, and previous oxalate stone formation.
We could find no reference to caution in people at risk of glucose-6-phosphate dehydrogenase deficiency.
However, there have been two case reports of haemolytic crises caused by ascorbic acid.
One concerned a black American man given 80 g ascorbic acid intravenously for burns; he subsequently developed acute haemolysis and renal failure and died.
The second report concerned two boys in India who developed acute haemolysis after a ‘binge of fizzy drinks’ containing 4–6 g ascorbic acid.
Glucose-6-phosphate dehydrogenase is an extremely polymorphic enzyme, essential in the metabolism of glucose and the production of reduced nicotinamide adenine dinucleotide phosphate in the hexose-monophosphate shunt, essential in the generation of reduced glutathione in the red cell for protection against oxidative stress.
The gene is found on the X chromosome, males being more severely affected than females.
Females may be variably affected by virtue of random inactivation of the X chromosome.
Roughly 10% of black Americans were found to have the mildly defective A glucose-6-phosphate dehydrogenase variant, more severe B variants occurring around the Mediterranean and in South East Asia.
It is the commonest enzymopathy affecting erythrocytes.
Affected subjects may be detected either by simple visual fluorescence or colorimetric screening tests or by direct assay of enzyme activity.
Acute haemolytic crises usually result from exposure to oxidant drugs, fava beans, bacterial or viral infections, or severe acidosis — for example, diabetic ketoacidosis.
It is perhaps surprising, therefore, that ascorbic acid, a known reducing agent, can precipitate haemolysis.
However, there were no other factors in our patient to account for the acute haemolytic episode, and ascorbic acid induced haemolysis in glucose-6-phosphate dehydrogenase deficiency has been reported.
Indeed, low concentrations of ascorbate have been shown to protect against haemolysis of glucose-6-phosphate dehydrogenase deficient erythrocytes in vitro.
However, higher concentrations were shown to produce haemolysis.
A study in rats showed reduced survival of glucose-6-phosphate dehydrogenase deficient erythrocytes in the presence of ascorbic acid.
The exact mechanism for ascorbate induced haemolysis in glucose-6-phosphate dehydrogenase deficiency is uncertain but is thought to entail generation of hydrogen peroxide and other reactive oxygen species, which rapidly exhaust the limited glutathione supply.
Of particular interest in this case is the fact that as part of a nutritional screen serum and red cell glutathione concentrations were measured and found to be low.
Low glutathione concentrations have been associated with increased risk of progression to AIDS in HIV positive people.
In our patient it seems probable that the low concentrations reflected the glucose-6-phosphate dehydrogenase deficiency.
It also seems plausible that the glutathione supplements might have protected the erythrocytes against oxidative stress, thus allowing the patient to tolerate up to 60 g ascorbic acid without appreciable haemolysis.
The indications for treatment with high dose ascorbic acid seem to be increasing.
Some of the diseases supposedly benefiting from such treatment are common in areas where glucose-6-phosphate dehydrogenase deficiency is also common — for example, hepatitis B and HIV infection.
Although ascorbic acid induced haemolysis has been described, the risk seems not to be widely appreciated, and indeed ascorbic acid does not occur on many lists of drugs to be avoided in glucose-6-phosphate dehydrogenase deficiency.
It is important to screen people at risk of glucose-6-phosphate dehydrogenase deficiency for this disorder before starting high dose ascorbic acid.
For Debate
Long term care on the NHS: a vanishing prospect
Because of the spectacular growth in provision the number of long stay beds in the private and voluntary sectors now dwarfs the number available for long term care in the NHS.
Continued financial pressure on the NHS has led many authorities to reduce their long stay provision or to buy places within the private sector, which are often cheaper than their own beds.
Nevertheless, the Department of Health's policy, as reiterated in a letter to Newcastle Health Authority in 1992 by Stephen Dorrell, states ‘Health authorities do, however, have — and will continue to have — a responsibility to provide or secure long term care for those people who need it by reason of the predominance of their continuing ill health.’
At the moment the NHS is in practice abrogating that responsibility.
It is time to recognise that fact and radically rethink the provision of long term care.
Current means of regulating demand
Private care is still largely confined to the elderly, which is where the conflict between the availability of beds and the needs of the relatives and the patient is most apparent.
When an old person becomes so demented that she or he cannot be contained in an old people's home the choice is between a private nursing home costing about £400 a week or a free bed in the NHS.
Why should anyone choose to pay?
Up to now there have been four methods of regulating supply and demand, all equally iniquitous.
The first method is for the NHS to provide such a poor service that no one would choose it.
This was the policy of the work house, in whose original premises most of these hospitals are sited.
Such a policy runs directly counter to the current policy of using the NHS to train staff in giving long stay care and provide a model for the private sector.
The second method is to use a waiting list so that only those whose condition is mild enough to enable care to continue at home will be admitted.
Those whose dementia progresses rapidly or who suddenly become  unmanageable because of aggression or death of the carer have no hope of admission.
In this way the NHS can show 100% bed occupancy and lots of cheerful staff and patients luxuriating in an unnecessary service.
This must be the worst system of rationing.
The third method is to allocate places to those who have the muscle to demand them.
In this service the middle classes — who might be able to afford private care — are admitted, and the burden of care falls on those least able to cope or argue their case.
The fourth is not so much a method as a means of disguising the reality of the other three from the public.
It involves using strict criteria for admission, such as failure in a nursing home or extreme restlessness and aggression.
This policy might have some justification if hospital long term care beds were separate from the private sector, but it carries no conviction when the NHS buys many of these patients places in the private sector.
We have shown no significant difference in disability between people in the nursing home and those in long stay hospitals (S Turner, personal communication).
The hospital staff have the skills to care for these patients such that after a month or two their behaviour improves and they become suitable for private care.
Because it is inhumane to shuttle people between facilities these patients usually remain within the NHS.
Possible solutions
There are three possible solutions to this problem.
Firstly, the NHS could provide good quality care for all who need nursing care — that is, those who are incontinent or immobile, those who wander, and those with additional psychotic features.
Secondly, the costs of nursing could be separated from ‘hotel’ costs, and the NHS would pay only for nursing.
Thirdly, there could be a charge (under clearly defined conditions) for all long term care.
The first solution is that of Pangloss.
In 1990 it was estimated that in the United Kingdom there were  318000 people in residential homes, including 126000 in nursing homes.
This compares with a total of 341000 beds within the NHS, of which 77000 are devoted to mental illness.
If all long term care was to be given within the NHS the number of beds would have to be expanded by at least a third and probably nearly doubled if, as is often the case, those in residential homes require nursing care.
Even though such a doubling of the number of beds would not produce a doubling in cost, since most long stay patients need only low technological care, it is difficult to imagine society accepting this burden.
The second solution sounds sensible and may well appeal to politicians.
But it only transfers the boundaries of health and social care, which are already too ill defined, to the care of the individual patient.
Two examples will suffice.
Many patients with Alzheimer's disease are too apraxic to guide liquid to their mouths or too apathetic to make the effort.
When a patient is clinically dehydrated pressing fluids is clearly nursing care, while presenting a client with a meal that includes fluids is social care.
At what point does social care become nursing?
Is it when a person needs help to lift a glass to his or her lips, or does it depend on the degree of dehydration?
Would the cost of care depend on the serum sodium concentration?
Likewise, when is making a bed nursing?
If a patient has a bedsore and is incontinent the frequent changing of sheets and incontinence pads might be regarded as nursing.
But making a bed once a day is social.
How often do patients have to wet their beds, or how inflamed must their skin be, to justify nursing care?
The opportunities in this model for passing the buck between the NHS and social services would be legion.
Clearly social drinking…but what happens when she won't drink?
A practical solution
The third solution is, however, a practical possibility provided that the criteria for changing from one system to the other are sufficiently clear cut to avoid too much special pleading.
I propose a limit of three months' free residential treatment.
After 13 weeks of inpatient care the health authority would charge a fixed fee, which could be set at the eightieth percentile of the fees charged by the private sector within a set area, or £500 per week.
This would be well under the cost of the facility for the authority but would encourage those who could buy their care more cheaply to do so.
Like other benefits, it would be means tested so that for some the care would remain free.
Clearly a complicated illness might merit an extension of the 13 weeks because transfer to private care would be inappropriate.
Thus a patient recovering from a hip replacement might develop a bleeding peptic ulcer before discharge, which would need further investigation and treatment.
Attempts to cheat the system, however, by discharging a patient briefly every three months could be thwarted by insisting that the period of discharge must last at least two weeks before the admission could be considered separate.
Any savings accrued by this system could be used to reduce the severity of the means testing, thus reducing the way small savers are currently penalised.
Drawbacks and special cases
The border between a free and charged service is always, however, a source of inequity, and I would not want to remove one anachronism to introduce others.
The three month limit should cover most acute illnesses, especially if it can be extended when necessary.
Someone might question why acute illness should merit free care while chronic ones should not.
The justification is that while someone is receiving acute care they have the prospect of returning to an independent life in the community, with consequent retention of personal housing.
Once it has been accepted that they need continuing care their responsibility for maintaining themselves is removed.
Those most likely to object to this solution are those who have chronic illnesses and are currently receiving care within the NHS.
The largest group are patients with chronic schizophrenia, a group which has already been exposed to the private sector through a move to community care.
This group is in many ways similar to the elderly, except that they are less likely to be able to contribute to care from their own resources and are therefore more likely to receive a free service wherever they are placed.
More difficult would be patients with a deep seated psychological problem which would require more than three months' treatment.
Examples include anorexia nervosa, personality disorders, and patients with resistant depression.
It might be appropriate to ask the Mental Health Act Commission to provide a second opinion on such patients at the end of their first three months with the power to extend the time for free treatment.
The same would apply to patients kept in hospital under a section of the Mental Health Act, since they would be unable to find alternative care outside the hospital sector by the nature of the section.
Patients requiring terminal care are already often cared for within hospices run by the private sector, so there would be no logic in excluding this group.
More contentious would be those few patients who are kept alive by such intensive care that there is no alternative outside the NHS.
Examples include patients on ventilators and those being fed intravenously.
One might argue that a three month deadline would be just that — a time after which teams looking after unconscious patients should make realistic decisions about their prognosis.
Those for whom free care might be extended should be only those with a realistic possibility of returning to self care in the community within two years.
Children below school leaving age would also be excluded as they could not be expected to live independently in the community in any case.
This would leave a difficult boundary for patients with learning difficulties so profound as to require treatment in a hospital or specialist residential home, the former  being free and the latter funded by social services and means tested.
Perhaps the conflict for the parent could be resolved by removing the means test until 16, while social services departments might be able to obtain central funding for this small group of children.
Not a comfortable option
Many will see this paper as a fundamental attack on the NHS, a means by which a free service slides down the slippery slope of privatisation.
They will be ignoring the slide that has already taken place — and is accelerating.
The structure that I have suggested is sufficiently robust to halt that slide and ensure that acute care remains free throughout.
Long term care could develop, allowing the NHS to use the highest standards and train the staff required to run the private facilities.
Patients and their carers would have a realistic choice freed from fears of favouritism and unfair influence.
Transfers to and from the private sector would be eased, enabling the NHS to concentrate its long term resources on those who need its special skills.
Cynical health authorities would find the closure of long stay beds a less enticing option.
Private homes would be free to compete on a more even playing field, no longer subject to the whims of the local health authority.
No one can pretend that this is a comfortable option.
It does indeed make those who require nursing care through no fault of their own shoulder the cost.
It does, however, remove the humbug which leaves the elderly to discover that our current free health service is a sham.
Countdown to Community Care
Mental health services — the user's view
This is one of a series of articles looking at the forthcoming changes to community care
The needs of people with serious mental illnesses have dominated much of the debate on reforming community care.
In this article Peter Campbell, who has used mental health services many times in the past, explains how the reforms could affect people like him.
He welcomes the thinking behind the changes, particularly the idea that people who use community care should take part in planning services, but he warns that implementing the new philosophy might prove very difficult.
Mr Campbell is secretary of a voluntary organisation for users of mental health services called Survivors Speak Out.
The views he expresses here are his own, and do not necessarily reflect those of Survivors Speak Out.
The past three months have proved difficult times for community mental health care policy.
As the starting date for the final and most substantial series of reforms approaches there are still major doubts and fears about the practicality and desirability of the changes.
The much publicised case of Ben Silcock and the health secretary's response to it have once again revealed important differences among mental health care providers about which care is most necessary; it has also emphasised underlying uncertainties about whether community care for people with a diagnosis of severe mental illness can ever really work.
A favourable consensus may still exist, but it carries a rather battered look.
In the face of such doubts a large number of mental health service users, including me, remain resolutely in favour of community care.
We believe it is not only a viable option but the only option that can lead to significant changes in our status, as recipients of services and as citizens.
We know that community care is no panacea and we share current anxieties that, without proper resources, institutionalisation may be replaced by neglect.
But it is hard to see how the wider transformations we seek can be established except on the foundations that community mental health services could provide.
In these circumstances our concerns are not that community care changes are a step too far, but that they will not go far enough to produce radical change.
Changing the location of care
It is certainly true that the location of care is changing.
Community mental health care does imply the closure of the large, asylum style psychiatric hospitals, not least because many of the resources for new services are tied up in the old institutions.
Closures have been taking place over the past 10 years.
Soon the speed and scope of the closure programme will increase.
A recent survey by the National Schizophrenia Fellowship has shown that 45 psychiatric hospitals will close by the year 2000.
Hospital closures are major events in the lives of many users.
As someone who has been admitted into psychiatric care 16 times in the past 25 years and has usually received acute care in asylum style settings, I shed few tears for the disappearance of these places.
While I do not dismiss the care and treatment I have received during those admissions, I did not have to spend many weeks in the ‘old bins’ to become aware of their shortcomings as therapeutic environments.
The isolation — I have only once been in an admission ward less than a dozen miles from my home — and the physical environment — inappropriate design, upstairs dormitories that must be locked all day, uninvolving regimentation — are aspects of a system of care whose inadequacies should not be underestimated.
Moreover, while there are good reasons for concern about the availability of services for ‘revolving door patients’ during the run down of the old psychiatric hospitals and while doubts remain over the capacity of district general hospital units to provide appropriate care to people in crisis, the relocation of the long stay population of psychiatric hospitals is achieving some successful results.
There is evidence to support the anecdotal impression that long stay patients both prefer and are capable of living in community settings.
Monitoring of people moved from Friern Hospital in north London and Claybury Hospital in Essex shows that they are not slipping out of the system and are enjoying a better quality of life with greater independence and a more varied social life.
With adequate resourcing and well designed support systems, relocation can enhance lives.
But the community care reforms imply more than a shift in the location of care.
According to the government's  rhetoric, a fundamental change in the relationship between the provider and the recipient of care and treatment will transform the nature of services themselves.
Thus the 1990 NHS and Community Care Act promises us a new approach to service provision that puts the needs of users and carers first.
At the very least individuals will become consumers rather than recipients of care.
At best their rights as equal citizens will be acknowledged and secured.
While service providers are struggling to address ‘needs led assessment,’‘individualised care packages,’ and ‘care management’service users are beguiled with talk of ‘increased choice,’‘user involvement,’and ‘patient empowerment.’
It is clear that something important is supposed to be happening.
But what does it really mean?
Behind the rhetoric, is the power of users, either as individuals or as an interest group, actually increasing?
You don't have to spend long in an old psychiatric hospital to be aware of the environment's shortcomings
Users are important
The role of users within the mental health system has developed rapidly over the past 10 years.
Although the relation between the growth of action by organised groups of service users and the increasing importance of health service consumerism is not straightforward, the shift towards community care and the ideological changes accompanying it have undoubtedly given users the opportunity to become important stakeholders.
In 1983, at the time of the introduction of the new Mental Health Act, seen then and now as a breakthrough for patients' rights, users were barely involved in the mental health debate.
Users were also comparatively powerless within mental health voluntary organisations.
Independent organisations of users were notable by their absence.
In 1993 there are more than 150 independent organisations of users in the United Kingdom.
Major voluntary organisations like MIND and the National Schizophrenia Fellowship work alongside these groups, both locally and nationally, and have adapted their own structures to represent users more effectively.
The Community Care Support Force and the Mental Health Task Force — two recently established government initiatives — both have user representation.
Up to half a dozen years ago any invitation by the government that offered users meaningful involvement in planning community care would have been seen as unrealistic and even cynical.
In current circumstances such involvement is at least a genuine possibility.
Even so there are no grounds for easy optimism.
All the evidence available points to the difficulty of involving users effectively in planning processes.
Research on the involvement of disabled people in preparing local authorities' community care plans in April 1992 illustrates some of the barriers.
Only one in eight local authorities had consulted disabled people before preparing a draft plan.
No social services department had produced a plan accessible to people with learning difficulties.
There was insufficient recognition that some of the voluntary organisations who helped with the plans do not adequately consult disabled people.
At the same time there are a series of practical problems affecting all consultation with users.
Service users are rarely paid for their time.
The conduct of meetings often excludes, alienates, or marginalises user representatives.
The representativeness of service users' involvement is questioned far beyond that of other interest groups.
Although the desire to involve users in planning and consultation is real enough, the unfriendliness of planning structures is not yet sufficiently recognised.
Effective involvement in the future may depend not only on more extensive support for user representatives but on overhauling the planning process.
What users can do
It is possible that influencing purchasers of mental health services will prove the most direct way of changing services.
In Newcastle a mental health consumer group has been working closely with purchasers over the past two years.
The group participates at all stages of the process, including defining needs, revising draft contacts, monitoring existing services through visits or surveys, and contributing to planning future services.
The group is already achieving some success, both in altering the detailed specifications in contracts and in challenging longer term mental health strategy.
Considerable funding has been found to support the effective functioning of the Newcastle group.
Perhaps purchasers or providers elsewhere would not be prepared to devote the necessary resources to involving service users in this way.
Experience in Newcastle suggests it could be money well spent.
I believe it is unrealistic to expect the community care reforms to transform services according to the wishes of service users.
There may be more room for choice in the new system and users may be in a stronger position to influence the planning of those choices, but the range of services is unlikely to widen.
Notable differences remain between what user organisations are demanding and what service providers are willing to provide.
Despite 10 years of pressure for 24 hour, non-medical crisis services such facilities hardly exist in this country.
In an era of choice and ‘needs driven’ care, adequate support for people wishing to withdraw from major tranquillisers is not only absent but opposed.
Funding restrictions may be partly responsible for these absences, but they also reflect the mental health system's capacity to resist new responses to mental distress.
Community care will not circumvent this and will not automatically produce care and treatment that is any less reliant on medication as a therapeutic tool.
These are not new issues; nor are they the only important issues for users.
But there is a danger that the current reforms will leave untouched fundamental assumptions about the lives and needs of service users.
People moved from Friern Hospital in north London are enjoying a better quality of life with greater independence and a more varied social life
What will happen to users?
What about the individual users?
Will their power increase even if the character of services remains substantially unchanged?
Will they have more control over their own care and treatment?
The new arrangements should provide more occasions when mental health workers sit down with individuals to discuss their care in a structured way.
The care programme approach introduced in April 1991 for people discharged from hospital and the individual needs assessments to be performed by care managers will permit greater involvement.
But it is currently unclear how comprehensive these new procedures will be.
A preliminary study by Research and Development for Psychiatry found that a quarter of health authorities had not implemented the care programme approach.
In some districts it has been impossible to make it available to everyone.
Care management is being introduced gradually and is focusing on those who are particularly vulnerable or need a wide range of services.
Evidence from pilot projects shows the real potential of care management to create flexible care and support controlled by the user.
Advocacy and representation
Real choices are informed choices, and the provision of good independent advocacy and information services will be essential to the effectiveness of the reforms.
Advocacy means representing and pursuing someone else's interests as if they were your own.
The importance of advocacy in mental health services has been emphasised by the government and this has been reflected in a growth in advocacy projects such as patients' councils and schemes for individual advocates in hospitals.
But advocacy services are not welcomed universally.
They threaten change in the day to day practice of mental health workers and require a reframing of one to one relationships with clients.
As a result it is perhaps not surprising that new advocacy schemes can be viewed with suspicion or seen as ‘troublemaking.’
Even where advocacy projects have been established, staff may feel that these are experimental embellishments to services rather than key elements of a new style of care.
In these circumstances the absence of full legal rights to advocacy and representation is particularly unfortunate.
The government's refusal fully to implement the Disabled Person's (Services, Consultation and Representation) Act 1986 leaves users dependent on the good practice of service providers, without clear cut rights to assessment or explanation when services are not provided.
Without a legal basis for users' role in the assessment process, without full rights to user representation, and without national minimum standards for community care, any increase in users' individual power may be illusory.
There is a danger of overestimating the impact of the community care reforms on the everyday lives of people with a diagnosis of mental illness.
As consumers of a health and social care system, our range of choice and our control of our own care may be extended.
But these gains will be limited.
As citizens in the community, we may find no change at all.
In the past few weeks the government has once again blocked an attempt to give disabled people legal protection against discrimination.
The destructive poverty ruling the lives of people dependent on benefits is likely to continue and may grow worse.
We may be becoming more visible.
Will we be less marginal?
The community care reforms have been linked with changes in attitudes within mental health services.
Their significance to service users will depend on transferring such change to the wider society.
LETTERS
Racial discrimination against doctors
Editor ,— A Esmail and S Everington are to be congratulated on their study of racial discrimination against doctors.
Many of us have thought of doing similar studies, but none of us has been brave enough to incur the wrath of the establishment.
As Richard Smith says, few doctors trained overseas will be surprised by the result.
The few who have attempted to query appointments at a local level have been met by shocked indignation and comments like: ‘The fact of the matter is that the applications that we receive from doctors from the subcontinent leave much to be desired.’
The fact of the matter is that there is no equality of opportunity, there never was, and we wonder if there ever will be.
As scientists and doctors we are encouraged to look for research evidence to support our hypotheses.
It is appalling that these two doctors were charged by the fraud squad and that they will be investigated by the General Medical Council.
What a terrible indictment on the medical profession if it pillories those of its members who are brave enough to find the research evidence to support what many have suspected but few have challenged.
We would strongly support the introduction of the principles of equal opportunity at all levels of appointments including shortlisting.
While some unconscious biases — based, for instance, on which medical school or university people attended — may not be wholly eradicated, recognition of incipient biases would be a first step towards achieving real equal opportunities.
Editor ,— A Esmail and S Everington's paper and Richard Smith's editorial draw attention to the important problem of racial discrimination in medical appointments.
Sadly, it is a problem that is all too familiar to doctors and others from ethnic minorities.
But Smith's tacit acquiescence with the notion that the method adopted by these researchers amounted to deception and that such deception needs to be justified (by pointing out the importance of the question being asked) should not go unchallenged.
These researchers sent out simulated applications to test the hypothesis that applicants with Asian sounding names were systematically discriminated against in the shortlisting process.
The finding that this was indeed the case is of interest because the potential employers professed to operate a policy of equal opportunities and because such discrimination is illegal.
A close analogy exists between what these researchers did and the inclusion of control specimens with every batch of samples in a laboratory assay, the purpose being the detection not only of random variation in accuracy but also the systematic errors introduced by sloppy work or dishonesty.
The use of decoys by police officers to aid in the detection of crime is a similar though less analogous form of deception.
Fraud is defined in the New Collins Dictionary and Thesaurus as ‘deliberate deception, trickery, or cheating intended to gain an advantage.’
Whatever the law might hold, no one could argue that the methods used by Esmail and Everington amounted to fraud, in so far as they had neither the intention nor the potential to gain an advantage.
The real fraud was committed by the appointing officers, who were inadvertently or, worse, deliberately subverting the publicly declared equal opportunities policy of their health authority or trust.
Esmail and Everington have come up with what could be a far more effective method of ensuring equal opportunities than any that Smith suggests.
I suggest that an outside agency such as the Commission for Racial Equality should use the method more widely, targeting hospitals selected at random.
Health service employers who mean what they say in their statements about equal opportunities would welcome such a monitoring process.
The fact that such monitoring was taking place might have a salutary effect on the behaviour of those responsible for selecting medical staff.
Discrimination in the job market is by no means confined to the medical profession.
Immigrant doctors in Britain may silently have put up with a lot of it in the past, but those born and educated in Britain have every right to expect that they will be judged strictly on merit.
It is the essence of professionalism not to allow extraneous considerations to influence your judgment.
Editor ,— I was shocked to read in the public press and in Richard Smith's editorial of the reaction to research conducted by A Esmail and S Everington.
As Smith points out, the use of such a covert strategy is well established in research that uncovers behaviour that is itself not merely unethical or immoral but illegal.
The work of Brown and Gay and others who were sponsored by the Commission for Racial Equality and used ‘actor studies’ is well known in race relations research and is respected beyond that.
How else can decision making in employment be researched?
No one, to my knowledge, attempted to press charges of deception against the BBC for its reporters' filming tactics in the series Black and White Britain screened a few years ago.
It is a relief to know that the police, at least, were sufficiently attuned to the realities of contemporary social research to drop charges even if a nagging doubt remains as to how or by whom they were set on to the investigators.
None of this, however, explains or excuses the General Medical Council's strictures as to what it apparently regards as acceptable professional behaviour.
I recently read Stacey's study of the council, published with its blessing and undertaken by the same means of ‘participant observation,’ albeit not apparently requiring the same degree of deception.
I thought that Stacey's conclusion was to the effect that the council had changed and was capable of internal reform.
Surely there is an expectation that members of the medical profession should undertake audit and research based activity; is not this intervention a restraint of that?
I trust that the profession and the defence unions will rise to the support of these two researchers.
Equally, I hope that their conclusions and recommendations will be carefully debated.
Ethnic monitoring — in employment as in the delivery of services — is clearly essential.
My only caveat is that ethnic origin should not be concealed from the selectors, who may find ways to deduce or guess at it.
They should rather be given explicit knowledge, thus preventing the usual defence of a claim of ignorance.
Editor ,— The results of A Esmail and S Everington's study on racial discrimination are no surprise.
I disagree, however, with the suggestion that ‘information identifying ethnic origin can be removed by the personnel department.’
This would not work and is wrong in principle.
McKeigue et al speculated that the discrimination occurred in shortlisting rather than in interviews.
I suspect that removing the information about ethnic origin would only postpone the discrimination to the interview stage.
The members of the shortlisting panel and interviewing panel are often the same, so when a doctor from an ethnic minority gets shortlisted the panel may already have considered his or her ethnic origin.
Even if it worked for senior house officer appointments it would not work for registrar appointments.
Nowadays, a doctor is highly unlikely to obtain a career registrarship without having published anything.
It is impossible to hide a name on a publication.
Anyway, what's wrong with our names that we need to hide them?
Editor ,— We sympathise with A Esmail and S Everington over the medicolegal problems resulting from their study but were sorry to note their observation on the ‘comparative unpopularity’ of psychiatry.
We recently published a study of predictors of shortlisting and appointments for training posts in psychiatry.
Not having an English name was associated with not being shortlisted at senior registrar level (4/18 v 8/14; p<0.05).
In our ‘real life’ study, however, having an English name was significantly associated with having obtained a British undergraduate education (p<0.001).
This in turn was associated with achieving a publication containing data (p<0.05), which emerged as the strongest predictor (p<0.001) of shortlisting for a senior registrar post.
Our results show the artificiality of comparing curricula vitae identical in all but name and the promotional value (for better or worse) of achieving publication.
Our paper nevertheless echoes Esmail and Everington's in concluding that ‘members of appointments committees should…become still more aware of their commitment to equal opportunities and their vulnerability to prejudice.
Editor ,— Richard Smith's editorial and A Esmail and S Everington's study expose nothing new.
Anglicising surnames is a well known practice to gain acceptance: Stanislav Cadinsky became Stanford Cade, Krishna Bhanji became Ben Kingsley.
There are Windsors, Mountbattens, Brittans, Weidenfeld, etc who have changed their names for reasons well known.
No fraud squad will ever investigate these.
These people did not try to deceive anyone.
To arrive at some truth and, for reasons of state, deception is also practised and accepted by society.
No, the essential problem is pigmentation.
We have seen the introduction of the Professional and Linguistic Assessment Board test and temporary registration with the General Medical Council and changes in the Home Office's rules on immigration, brought in to regulate the entry of overseas doctors.
Now we have a corps of locally born and educated doctors with foreign sounding names in search of a medical career facing the same circumstances others faced before.
Despite Smith's editorial and Esmail and Everington's short report the medical establishment in Britain will do little to correct the situation other than wonder how to find new barriers or regulations to stop the foreign sounding names appearing in applications before them.
Be that as it may, the editorial and short report will encourage the young doctors in question and will bring hope and faith in the fairness of the BMJ in drawing readers' attention to this issue.
Editor ,— A Esmail and S Everington's short report reminded me of a situation when I was executive dean of the medical school of the University of Manchester in 1970.
In those days the number of overseas students was smaller than at present, and one competent young man, with a foreign sounding name, graduated.
He came to see me some weeks later explaining that he had failed to get a job.
I suggested that he might think of removing the last three syllables from his name, which he did by deed poll.
He obtained the next job for which he applied and, as far as I know, has had a successful career subsequently.
The fortysomething barrier
Editor ,— Four groups of doctors suffer particularly from age discrimination during their attempts to move through the hospital training grades to consultant appointments: doctors who qualified abroad, those who entered medical school after the normal age of 18–19, those who have had prolonged illness, and women.
The average age at first consultant appointment is 38.
Senior registrar appointment committees assume that accreditation is necessary before someone is appointed to a consultant post and that accreditation will be granted only after four years of higher training (eight years for a doctor training half time under the PM(79)3 scheme).
As the chairman of the Joint Committee on Higher Surgical Training has indicated, appointment committees are reluctant to appoint anyone over the age of 35 for fear that they are so near the age of 40 that they will be unable to obtain a consultant post and will linger, blocking their senior registrar post.
The committees therefore discriminate in favour of candidates under the age of 35 at the expense of those who have taken longer to reach senior registrar level because they have had to start again after moving from another country, were older when they entered medical school, or have had time off for sick leave or maternity leave.
NHS employers are now belatedly acting to recognise equal opportunity in recruitment.
Failure to select a suitable candidate because of age is often a covert form of racial and gender discrimination.
Death rate from asthma
Editor ,— Our experience in a large rural health district (population 470000) contrasts with that of W T Berrill in West Cumbria and Margaret Judd and Kate Jolly in East and North Hertfordshire.
Since 1988 we have conducted a confidential inquiry into deaths due to asthma in our district.
During 1988–92 inclusive 30 deaths in patients aged under 65 were attributed to asthma.
These deaths and the diagnoses of asthma were reviewed by a panel of four or five physicians (chest physicians, public health physicians, and a general practitioner).
We concluded that 29 of the deaths were due to asthma, with confirmatory evidence in the 20 in which necropsy was performed (unpublished study).
Mortality from asthma in people aged under 65 seems to be about 40% higher in Norfolk than in Cumbria or Hertfordshire.
Possible reasons for this difference include a different prevalence of asthma, different access to care, different environmental factors, and different genetic factors.
Further investigations should yield interesting results.
Editor ,— J R F Gladman makes the reasonable point, following my observations in West Cumbria, that we should not underestimate asthma in elderly people.
In practice, however, it is relatively rare for elderly patients to be admitted with a severe, life threatening asthmatic attack compared with younger patients.
If the notes of elderly patients alleged to have died from asthma are examined it seems that most of them had fixed airways obstruction, with little evidence of having had asthma, and that most died of something else.
Figures from the Office of Population Censuses and Surveys for the Northern region for 1991 show that of 125 people recorded as having died of asthma, 65 were aged over 65 and nine were over 85, which surely stretches credibility.
Harrison, who with colleagues has comprehensively studied deaths from asthma prospectively in Norwich over five years in a confidential inquiry, reports an average of just under five (undoubtedly genuine) deaths from asthma a year in a population of almost half a million.
This indicates an annual mortality from asthma of just over 1/100000.
Unless there are an appreciable number of genuine deaths from asthma in people aged over 65 this supports my belief that the annual number of deaths due to asthma nationally is nearer 500 than 2000 (even allowing for some genuine deaths from asthma not certified as such and given that some areas such as West Cumbria and perhaps Hertfordshire seem to have a lower mortality than Norwich).
Finally, even if, as I believe, the lower figure is nearer the true rate, I do not doubt that all such deaths are of the utmost importance and will continue to represent a major therapeutic challenge and that perhaps nearly all will eventually be prevented.
In West Cumbria virtually all patients admitted with acute severe (and thus potentially fatal) asthmatic attacks are not receiving adequate regular supervision or continuity of care, and perhaps this is the clue to such a strategy being fundamental to the prevention of deaths from asthma.
Effect of alcohol on asthma
Editor ,— Ferruccio Berti and colleagues report possible effects of alcohol on asthma.
I was diagnosed as being asthmatic at the age of 48, although on reflection I suspect that I had probably suffered mild intermittent symptoms in childhood.
For about 10 years before the diagnosis was made, each time I drank whisky I would sneeze and develop symptoms of a rhinitis within about one minute of starting the drink.
I did not normally develop bronchospasm.
The evening before the diagnosis was made I had a double whisky and  developed sneezing and rhinitis, but on this occasion I developed severe bronchospasm within a few minutes.
With conventional treatment for the asthma (a beclamethasone diproprionate inhaler) the response to alcohol was greatly reduced, but experimentation with whisky showed that the asthmatic symptoms depended on the brand of whisky.
Other alcohols such as wines did not produce symptoms.
Gong et al reported that it was the congeners in alcohol and not alcohol itself that produced symptoms in asthmatic patients.
My inquiries have suggested that few doctors are aware of an association between alcohol and asthma.
I would naturally consider sympathetically any invitation to take part in clinical trials requiring ingestion of whisky for medicinal purposes.
Screening for prostatic cancer
Editor ,— Fritz H Schröder makes a cogent case against widespread screening for cancer of the prostate.
One crucial criterion in justifying a screening programme is that intervention is more effective in presymptomatic disease than after symptoms have appeared.
This has never been shown for prostatic cancer.
No treatment at any stage of disease has been shown to improve survival in an adequate clinical trial.
The statement that ‘radiotherapy and radical prostatectomy are effective in treating locally confined prostate cancer’(cited with a reference to an American consensus conference) is not justified by the available evidence.
Assessing treatment in early prostatic cancer is difficult.
Ten to 15 years of follow up is required, in a population with considerable competing risks of death.
Studies of series of patients who have been operated on report survival not much worse than that expected for the age matched general population, but they ignore the possible effects of length-time bias and case selection for operation.
In a series of 223 localised carcinomas managed expectantly five year disease specific survival was 94% and 10 year survival 85%, although the figure was much worse for poorly differentiated tumours (25% survival at five years).
In one randomised controlled trial of radical surgery 111 of 142 patients with cancer confined to the prostate were followed up for 15 years.
Survival curves were identical for patients who were and were not operated on and were only slightly worse than expected for the general population matched for age.
Another trial in 97 patients showed an advantage for surgery over radiotherapy in forestalling the appearance of distant metastases over five years.
Radical prostatectomy is a major operation with potentially serious morbidity (including impotence and urinary incontinence)— risks worth taking only once benefit has been established unequivocally.
In advanced disease hormone treatment (chemical or surgical castration or oestrogens) relieves symptoms and improves general wellbeing.
Early endocrine treatment may delay progression of disease but has never been shown to prolong survival.
Evidence that total androgen blockade (castration plus an androgen antagonist) is more effective than castration alone has not been confirmed in two other trials.
Though trials of screening for prostatic cancer are to be welcomed, surely a greater priority is to establish, through adequate clinical trials, the optimum management of localised prostatic cancer.
There is little point in making early diagnoses if we do not know what to do next.
Editor ,— We agree with Fritz H Schröder that screening for prostatic cancer is not presently justified.
Gaps in understanding of the disease and its treatment and the unsuitable characteristics of available diagnostic tools mean that prostatic cancer fails to meet most of the standard epidemiological criteria required for a successful screening programme.
We also agree that even effective treatment may not bring benefit in all cases of localised cancer because of competing causes of death and the slow rate of progression of disease in some cases.
We question, however, Schröder's implication that effective treatment exists, believing that his assertion that ‘radiotherapy and radical prostatectomy are effective in treating locally confined prostatic cancer’ is particularly misleading.
In an asymptomatic patient effectiveness implies improved disease specific survival.
No randomised trial has shown such effectiveness.
On the contrary, evidence indicates that disease specific survival rates quoted in uncontrolled trials cannot be interpreted as evidence of therapeutic benefit.
We suggest that the issue is not that ‘a considerable possibility of overtreatment’ exists but that potentially damaging and ineffective treatment may be undertaken outside the confines of a randomised controlled trial.
Over 20000 radical prostatectomies were performed in North America in 1991, and several centres in Britain undertake the procedure.
The cost to the patient is often high: some patients die, and impotence and incontinence are recognised complications.
A similar willingness to perform radical treatment for breast cancer in the absence of evidence from randomised trials led to the misguided mutilation of thousands of women by radical mastectomy.
The resource implications of such procedures are substantial.
Registrations of cancer show that the incidence of prostatic cancer in England and Wales is 39 per 100000 males.
On the basis of Schröder's figures this could lead to over 2500 radical prostatectomies a year.
This ignores the substantial number of additional cases that would arise if screening became widespread.
Tariffs for extracontractual referral indicate that the estimated cost to the NHS of such surgery exceeds £10.8 million.
If the only effect on health of such interventions is adverse this seems remarkably poor value for money.
Unbiased assessment of moderate differences in survival arising from treatment requires randomisation of large numbers of patients.
We should not consider the need for early detection of localised prostatic cancer until its treatment has been subjected to such assessment.
Editor ,— Fritz H Schröder's editorial is a measured evaluation of the issues surrounding screening for prostatic cancer.
Such an approach is vital with the increasing demands being placed on health professionals to detect and treat disease before it is clinically apparent.
I believe, however, that Schröder has amalgamated two issues — screening and treatment of early prostatic cancer — into one when they should be argued separately.
Whereas in breast and cervical cancer active treatment is instituted on detection of the disease, it is argued that screening would not be appropriate in localised prostatic cancer because no treatment is often the option chosen.
George has shown this to be a satisfactory option, reporting a five year survival of 80%, but this has never been compared in a randomised controlled trial with a treatment regimen.
The slow rate of progression to metastasis coupled with the predictable behaviour of localised prostatic cancer provides a window in which the diagnosis can be made before the disease has spread, with a possible reduction in the morbidity and mortality.
The high incidence of metastatic and thus incurable disease at presentation is sufficient evidence that a large group of patients might be helped if the disease was detected earlier.
The relatively inexpensive initial methods of screening available (that is, digital rectal examination and measurement of the prostate specific antigen concentration) and the advances in transrectal imaging with ultrasound and magnetic resonance imaging all serve to provide a sound backdrop for a screening programme.
Thus the real question seems not to be whether we should detect the disease but how best we should treat it if it is detected.
The controversy regarding treatment should not be allowed to detract from screening as improvements in current methods of treatment and the introduction of new strategies in management are likely to emerge; it serves to make the point that a randomised controlled trial comparing the different methods of treatment and non-treatment should also be instituted.
Mass screening is not feasible, but targeting groups at high risk and asking them to attend for screening is perfectly plausible.
These groups can be defined only by pilot programmes specifically designed to identify the characteristics of such groups.
The earlier detection of prostatic cancers that have not spread will surely allow us the opportunity to treat and cure some of these  patients.
Exactly which is the best treatment regimen is a separate issue.
Editor ,— Fritz H Schröder rightly emphasises that it is not known whether treatment of early prostatic cancer is beneficial or whether screening for the disease offers any advantage.
This debate will never be resolved unless it can firmly be established whether searching for early prostatic cancer on a community basis is worthwhile in clinical, resource, and social terms.
In Gwent we have embarked on a major study to do this and will be offering a prostate health check to over 10000 men aged between 55 and 70 in a study that is associated with the European programme concerned with early prostatic cancer.
We aim to complete the groundwork within 12 months but hope that concurrently British urologists will agree to work together in a randomised study of treatment for prostatic cancer confined to the organ.
Radical prostatectomy is likely to be one treatment arm.
We wonder, however, whether a surveillance arm would be acceptable to many ethics committees and patients now that informed consent is mandatory.
Editor ,— Though we agree with Fritz H Schröder that some of the intriguing scientific questions about the natural course of prostatic cancer could be answered in a randomised controlled trial of screening, we are concerned that the possible adverse effects of screening may be arguments against such an exercise.
Schröder estimates that the detection rate is 2.5%, which is 15 times the present incidence of 1.4 new cases/1000 men aged 60 to 74 in England and Wales.
Such a high ratio of prevalence to incidence suggests either a long lead time, which is not typical of the invasive cancers that are the intended target of the screening programme, or a large element of overdiagnosis of slowly progressive disease, or both.
We estimate that 150000 men aged 60 to 74 would be required in an evaluative trial for it to have an 80% chance of showing a 20% reduction in mortality over the ensuing 10 years, significant at the 5% level.
Given the incidence and case fatality in British men aged 60 to 74 at entry, such a 20% reduction in 10 year mortality would amount to 81 fewer deaths in the 75000 men offered screening.
On the assumption that 60% would attend for screening, 1125 of those might be diagnosed as having prostatic cancer at the first screen.
All these men (and presumably others with cancers detected at subsequent screening rounds) would be exposed to the risks of radical prostatectomy, which may cause impotency in up to 42% and urethrovesical stricture in 7%.
Radiation therapy may cause short term effects such as sickness and long term effects such as urinary and intestinal problems and fibrosis of soft tissue.
The adverse consequences to the health of men in their seventh, eighth, and ninth decades could thus be considerable and might well counterbalance the small benefit of screening in terms of reduced deaths.
Perhaps it would be wiser to concentrate research on the development of non-invasive biological markers to distinguish rapidly progressive from slowly progressive tumours as well as on the development of less invasive (for example, endocrine) treatment.
With such tools for diagnosis and treatment, screening for prostatic cancer would be much more feasible.
Author's reply ,— Kate Lawrence and colleagues criticise the concluding statement of the US National Cancer Institute's consensus conference (reference 9 in my editorial) that effective treatment of prostatic cancer is available.
I was careful to review the effectiveness of treatment and to state that no evidence of effectiveness of radiotherapy and radical prostatectomy is available from prospective randomised comparative studies.
The effectiveness of a procedure can, however, also be defined as its ability to eradicate tumour locally.
In this sense, with the usual limitations of any procedure applied to patients with cancer, the two available techniques are effective.
Local eradication of prostatic cancer probably occurs more commonly with radical prostatectomy than with radiotherapy.
Several times Lawrence and colleagues accentuate the damaging effect of treatment on patients with cancer of the prostate.
This is where I disagree.
Radical surgery for prostatic cancer has become acceptable so far as long term functional results are concerned: continence can be maintained or restored in virtually all patients, and potency is maintained in 50–70% of those who are potent preoperatively.
I made clear in the editorial that no randomised comparative trial is available and that there is an urgent need for such information.
Several attempts to carry out such studies, however, have shown the great logistic difficulties entailed, which may prevent such a study in the future.
A Scandinavian study uses a randomisation scheme which will probably prevent the group from obtaining a scientifically valuable result.
To my mind the only possibility of solving this problem lies in a large European prospective randomised screening study comparing screening with no screening and using mortality from prostatic cancer as its major end point.
Pilot studies for such a European protocol are currently being conducted.
Dangers of long waiting times for outpatient appointments
Editor ,— It is a fact of life that any specialist outpatient clinic will have a waiting list.
Priorities regarding the degree of urgency of an appointment must be decided on the basis of the information received in the referral letter.
It is salutary that in their report on the dangers of long waiting times for outpatient appointments at a urology clinic K German and colleagues say that five of the seven cases of prostatic cancer were detected on rectal examination and one by a raised serum prostate specific antigen concentration.
Unless general practitioners can be persuaded that a digital rectal examination is not a physical assault and that measurement of serum prostate specific antigen concentration is a sensitive screening test for prostatic cancer, no progress will be made in detecting prostatic cancer.
Both of these investigations should be mandatory in patients presenting with symptoms of bladder outflow obstruction, and if either is abnormal some priority can be afforded to the referral letter, particularly if the patient is aged under 65.
The authors do not state whether they actually treated the patients found to have prostatic cancer.
The patients' symptoms of bladder outflow obstruction may well have been due to benign prostatic hypertrophy and the coexistent prostatic cancer may have been an incidental finding.
For patients in the usual age group who present with symptomatic outflow obstruction and have ‘incidental’ well differentiated prostatic cancer confined to the gland, most urologists in Britain would perform a transurethral  resection to relieve the symptoms but adopt a policy of watchful waiting regarding the cancer.
In other words, the delay in initial diagnosis of a few months may not matter that much to the urological management of most such patients in Britain.
Reducing waiting lists requires more staff
Editor ,— K German and colleagues' paper and Catherine Pope's editorial emphasise the current attention directed at reducing waiting lists in the NHS.
Much of the debate has related to reducing waiting times for surgery rather than for outpatient appointments.
As in urology, in neurology waiting times for outpatient appointments are too long despite the unacceptably large numbers of patients seen in outpatient clinics.
Similar anxieties exist about the morbidity and mortality of patients who cannot be seen within a satisfactory time.
This picture is not specific to neurology services in this regional centre.
It is replicated at other centres and units in district general hospitals providing neurological services throughout Britain.
Waiting times in this centre exceed five months despite full clinics and extra, urgent cases being seen outside normal times set aside for outpatient clinics.
The medical problem is directly related to the inadequacy of available resources.
The necessary solution lies in additional consultant appointments and also additional staff in training grades.
These problems need to be addressed before waiting lists can be responsibly reduced.
A critical level of professional staff is required to provide adequately for the clinical needs of patients who are referred, irrespective of additional needs to provide excellence in postgraduate clinical training and research.
A substantial but prudent investment of finances is therefore essential to provide a safe service in which the clinical needs of patients are held to be primary.
It is not acceptable that patients with diagnostic problems in headache, cerebrovascular disease, multiple sclerosis, spinal tumours, pain, epilepsy, space occupying lesions, and dementia — to choose limited examples — should be kept waiting for skilled professional diagnosis, investigation, sympathetic management, and treatment.
Waiting times in one specialty do not correlate with waiting times in others.
The slogan ‘reduction of waiting lists’ as applied to elective surgery or outpatient appointments is simplistic and may have no relevance to actual or imminent medical needs of patients and their families.
Rectification of this unbalanced approach is overdue and should be brought to the attention of management and to politicians who reorganise the health service.
We are in a position to take a rational, professional lead in advising solutions to such problems, which are at the crux of proper provision for the health of the nation.
Waiting time for first outpatient appointment
Editor ,— Linda Beecham reports the planned use of ‘league tables’ of hospitals based on key indicators to allow the assessment of performance.
An obvious candidate for inclusion in these tables is the delay between referral and first appointment in outpatient clinics.
Yet Catherine Pope's editorial complained that ‘the wait for an outpatient appointment is invisible,’ with data on delays being scarce.
We have extensive data on the delays experienced by patients waiting to see a pain specialist.
They paint a dismal picture for patients suffering from chronic pain.
Waiting times for outpatient appointments have been collected prospectively in 10 outpatient pain clinics (eight in Scotland and two in the Northern Region Health Authority) over the past three years.
The median delay before a first appointment during 1992 was nine weeks in the five clinics based in district general hospitals (interquartile range 6–13 weeks) and three months in the five clinics based in teaching hospitals (interquartile range 7–18 weeks).
Patients with cancer are seen sooner in most pain clinics (median 25 days in clinics in teaching hospitals and just 10 days in clinics in district general hospitals), but these patients make up less than 3% of new referrals to pain clinics (patients with cancer are usually treated outwith outpatient clinics).
Delays before the first appointment have largely remained stable in four of the five pain clinics based in teaching hospitals (albeit at a high level); in the fifth clinic the median delay increased from 13 to 19 weeks between 1990 and 1992.
The median delay has substantially increased since 1990 in all five pain clinics based in district general hospitals: in three of these clinics it has more than doubled.
The patient's charter for Scotland emphasises the need for ‘action to help those who are waiting longest with significant pain’ and states that local targets for outpatient appointments ‘will rarely be more than nine weeks.’
There seems little prospect of the pain clinics in this study meeting these targets and maintaining their service within the constraints of existing resources.
Preventing congenital abnormalities
Editor ,— It is not clear what Andrew E Czeizel means by secondary prevention of congenital abnormalities.
They refer to secondary prevention as early detection and medical treatment or selective abortion.
Medical treatment was classified as mimicking physiological processes and, therefore, presumably not applicable for congenital abnormalities of the abdominal wall, abnormalities of the diaphragm, or oesophageal atresia.
Or are the authors referring to antenatal surgery?
There is a well established role for termination of pregnancy in certain congenital abnormalities.
We believe strongly, however, that the term prevention should not be used when referring to abortion.
Abortion does not prevent abnormal babies.
As Czeizel and colleagues point out, ‘it is not always clear whether the defect is so severe as to justify abortion or whether surgery might be successful.’
Certainly, we deplore the practice of aborting fetuses because they have gastroschisis or isolated tracheo-oesophageal fistulla or oesophageal atresia.
Since 1986 this unit has treated 54 patients with gastroschisis with eight deaths (four having either short gut or chromosomal abnormalities; 85% survival).
Such children may require parenteral nutrition for three to six weeks and careful introduction of oral feeds but thereafter develop normally without handicap.
Similarly, the survival of infants with tracheo-oesophageal fistula as an isolated abnormality is close to 100%.
Selective abortion of such children for these abnormalities cannot be justified when effective postnatal surgery is available and the outcome is likely to be good with a normal lifespan without disability.
Readers should be correctly informed about the long term prognosis of paediatric surgical conditions.
Editor ,— The way in which Andrew E Czeizel and colleagues present their conclusions based on Hungarian databases of congenital abnormalities is misleading.
They define congenital abnormalities as structural defects present at birth and claim that of the 65 cases/1000 live births in Hungary, 39 are preventable.
What is not clearly stated in the text but is easily deduced from the tables is that most of the proposed ‘preventive’ measures in these 39 cases/ 1000 are not really preventive at all but, rather, treatments carried out after birth: 15.7 are neonatal surgical procedures for congenital heart defects, pyloric stenosis, and inguinal hernia; 15.4 are standard orthopaedic procedures for congenital hip dislocation and club foot; and 1.8 are postnatal treatments for a variety of other conditions.
Only 6.3 of the potential interventions are truly prenatal interventions and therefore preventive in the commonly understood meaning of the word.
Of these prenatal interventions, 0.8 fall into the category of primary prevention (genetic counselling, avoidance of teratogens, and periconceptional vitamin supplements).
The remaining 5.5 apparently entail prenatal diagnosis (by chorionic villus sampling, amniocentesis, or ultrasonography) followed by selective abortion.
In other words, almost 90% of this proposed reduction in the true incidence of congenital abnormality at birth is to be achieved by destroying affected fetuses through selective, prenatal, non-voluntary euthanasia.
This draconian approach to handicap may be understandable in a country that, before escaping from communist rule, carried out over 50 abortions for every 100 live births.
Indeed, such seemingly cost effective proposals for reducing the incidence of handicap may well appeal to ideologues nearer to home in the midst of global recession.
But aren't the rights of the individual being made subservient to the interests of the state?
Can the end really justify these means?
Isn't this simply discrimination on the basis of handicap?
By all means let us seek to prevent congenital abnormalities, but let us not betray our Hippocratic tradition in the process.
Authors' reply ,— The introduction in our paper clearly differentiates the three levels of prevention on the basis of recent recommendations.
The main message of our paper was that the common pessimistic view concerning the prevention of congenital abnormalities is not correct.
We agree that primary prevention is the ideal, though its effects are limited in practice.
Congenital abnormalities are often considered to be defects that cause disability without the hope of a complete recovery.
Our findings show the high frequency with which tertiary prevention (early paediatric surgery) results in a complete recovery with no or minimal after effects.
We emphasised that secondary prevention — that is, prenatal screening and abortion of seriously malformed fetuses — is a last resort rather than an optimal solution.
In Hungary, as elsewhere, selective abortion is the individual choice of the parents.
Our results were not theoretical but based on what people actually choose to do.
We agree that success of medical genetics cannot be measured by the number of terminated pregnancies, any more than the success of surgery can be measured by the number of lower limbs amputated in patients with vascular stenosis.
We have suggested that a suitable way of evaluating medical genetics services is by measuring their effect on people's ability to have the family they want (that is, ‘reproductive confidence’).
It is not fair to give a political explanation for the Hungarian data.
We learnt prenatal diagnostic methods (screening of α fetoprotein concentration, triple testing, etc) from experts in Britain and have helped to develop new primary preventive methods.
Thus we were happy to take part in the Medical Research Council's vitamin study and to prove the efficacy of periconceptional multivitamin supplementation (a primary preventive method) in reducing the first occurrence of neural tube defects.
Screening for diabetes during pregnancy
Editor ,— R J Jarrett expresses many concerns about the existence of gestational diabetes.
One difficulty not mentioned arises from the definition of gestational diabetes, which includes abnormal glucose tolerance arising in or first detected in pregnancy.
A consequence of this is that women with undiagnosed non-insulin dependent diabetes, which is potentially as risky for the pregnancy as insulin dependent diabetes, are lumped together with women who have abnormalities of glucose tolerance that are trivial so far as the index pregnancy is concerned.
This is not an important issue for women of European origin, in whom non-insulin dependent diabetes is quite uncommon during their childbearing years, but in other ethnic groups it is a concern.
In our clinic we have managed 262 pregnancies in 203 women with diabetes over the past five years, 143 of whom had non-insulin dependent diabetes.
Of these, 85% were of Maori, Pacific Island, or Indian origin: these are ethnic groups with a high prevalence of non-insulin dependent diabetes.
Screening for gestational diabetes is practised in Auckland, and of the 143 women with non-insulin dependent diabetes, 87 were first found to have diabetes on screening in pregnancy; the disease was confirmed after delivery.
Using a composite score derived from factors significantly associated with the persistence of diabetes after delivery, we can now distinguish, with a high degree of certainty, women with non-insulin dependent diabetes from others with ‘gestational diabetes’ at the time  gestational diabetes is diagnosed (A Knox et al , New Zealand Society for the Study of Diabetes, 1992).
We believe, therefore, that for communities like ours, in which unrecognised non-insulin dependent diabetes is fairly common in young people, screening for gestational diabetes is justified.
Furthermore, at risk pregnancies can be defined accurately and treated accordingly; thus the requirements of a good screening test are fulfilled.
Management after life threatening events in young children
Editor ,— Martin P Samuels and colleagues' paper on diagnosis and management after life threatening events in infants and young children who received cardiopulmonary resuscitation suffers from the fact that the hospital provides a tertiary referral service and probably sees problematic cases.
Since 1977, when a detailed inquiry into child deaths was instituted in Gwynedd, no children admitted for life threatening events in the first four years of life have subsequently died (apart from two children with known epilepsy who have died during fits).
Some of our children classified as having died of the sudden infant death syndrome may have been suffocated, but none of them presented to hospital before their death if that was so.
And people who strangle their infants, thus causing their admissions, must give up the practice thereafter.
Samuels and colleagues seem to have been especially unfortunate in their experience of babies with prolonged expiratory apnoea (blue breath holders).
I am not aware of any deaths of babies with prolonged expiratory apnoea in Gwynedd although over 30 cases a year are seen in wards or outpatient clinics (the child population of Gwynedd is about 45000 with 2800 births a year).
Publicity and infants' sleeping position
Editor ,— The rate of the sudden infant death syndrome in Scotland fell before the national campaign aimed at reducing the prevalence of the prone sleeping position.
A survey in Scotland found that 87% of health visitors had changed the advice given to parents about the syndrome and that 54% stated that this change occurred before mid-1991.
This preceded the national campaign in the United Kingdom, which began in November 1991.
Furthermore, these health visitors cited journal articles and the mass media as the most important influences for changing advice.
Data from the New Zealand cot death study show that the prevalence of the prone sleeping position decreased before the campaign in New Zealand and suggest that other publicity, such as that generated by fundraising campaigns, may have had an influence.
The New Zealand cot death study was a nationwide case-control study carried out from 1 November 1987 to 31 October 1990.
Altogether 1800 control infants were randomly selected from all births in the study regions.
The figure shows the cumulative number of these infants placed to sleep prone.
The prevalence of the prone sleeping position was relatively constant at 41% until August 1990, was 24% for the next 12 months, and was about 8% for the final three months of the study.
The two changes in infant care practice had a temporal relation with mass publicity accompanying fund raising for the Cot Death Association.
The association's first ‘Red Nose Day,’ in September 1989, emphasised the size of the problem and the devastating effect on parents.
The fundraising part of the campaign was accompanied by items on television, in magazines, and on radio.
Some of these would have included the suggestion that sleeping prone might not be safe for babies.
By 1990 unpublished data from the New Zealand study confirmed the increased risk of the sudden infant death syndrome if an infant was placed to sleep prone.
In July 1990 a television advertisement by the Cot Death Association advised against placing infants to sleep prone.
Publicity for its 1990 Red Nose Day in mid-August used television, radio, popular magazines, newspapers, and pamphlets to spread messages about reducing the risks, particularly ‘sleep baby on the side.’
The wide publicity surrounding these two Red Nose Days and the change in the prevalence of the prone sleeping position preceded the national cot death prevention programme, which was formally launched in February 1991.
The change in the prevalence of the prone sleeping position has been associated with a 40% fall in the rate of the sudden infant death syndrome in New Zealand.
This analysis illustrates the potential health educational value of mass publicity surrounding fundraising activities.
Mothers' consent to screening newborn babies for disease
Editor ,— Neonatal screening for Duchenne muscular dystrophy has been introduced in Wales with close monitoring, social evaluation, and a continuing education programme.
This should result in uptake of the test being based on informed consent.
Once a test becomes routine, however, the same care is unlikely to be taken.
Even in this demonstration project one of the nine families with a positive diagnosis apparently entered the programme in ignorance.
Routine Guthrie testing  has been carried out for phenylketonuria since the mid-1970s and testing for hypothyroidism since the mid-'80s.
Our recent data on new mothers' knowledge of these tests suggests that  ignorance is widespread.
As part of the Cambridge prenatal screening study, 1387 women from nine hospitals in four regions completed a postal questionnaire six weeks after giving birth.
All but eight women knew where the test had been done (1209 at home and 163 in hospital, with more primiparous tested in hospital).
Most women (951) said that the test had been fully explained and 222 ‘knew about it already.’
The extent to which women thought that they were informed, however, was not reflected in the answers to a question about which disorders this blood sample was tested for (table).
Older, more educated women were more likely to answer the questions correctly, but only 51 of the 150 most educated women correctly identified hypothyroidism and 105 phenylketonuria.
Multiparous women were no more likely to answer these questions correctly than primiparous women.
Twenty one women answered ‘yes’ for all of the disorders; these women all stated that the Guthrie test had been fully explained, as did 250 of the 489 who answered ‘don't know’for all of the disorders.
Phenylketonuria was the disease that was most commonly identified correctly, but still by only 45% of the sample.
Only 20% identified hypothyroidism, even though this condition is more likely to be detected (three cases in our study).
Six of the districts used the Guthrie spot to test for cystic fibrosis, and in these districts 306 (37%) of the 964 women identified cystic fibrosis (correctly), compared with 42 (10%) of 409 in the other hospitals, who did so incorrectly.
Most new mothers do not know what the Guthrie test is for: a considerable number incorrectly believe that it will detect more disorders than is the case.
These results clearly challenge any notion that women are giving informed consent for their babies to be tested, even though they believe themselves to have been informed.
Medical management of Duchenne muscular dystrophy
Editor ,— James E Bowman states that patients with Duchenne muscular dystrophy are bedridden by the age of 12.
This should not be accepted as adequate medical management in the 1990s.
Most patients with Duchenne muscular dystrophy lose their independent mobility and may be confined to a wheelchair by the age of 12, but many spend some time standing with a suitable support.
Patients become bedridden only when they are terminally ill or if they are allowed to develop progressive scoliosis which results in intolerance of sitting.
This last can be prevented by modern orthopaedic treatment, but, unfortunately, many patients are still referred to a suitable orthopaedic clinic too late.
Not only does spinal stabilisation for early scoliosis in patients with Duchenne muscular dystrophy maintain sitting balance but it is also associated with a slower deterioration in lung function.
It is a major procedure in these patients, and, unfortunately, not all patients are fit enough for surgery at the time of referral.
Of 169 patients with Duchenne muscular dystrophy referred to the orthopaedic muscle clinic at the Royal Manchester Children's Hospital, 117 already had a scoliosis at the time of referral; three patients had a curve between 80° and 100° and eight patients had a curve in excess of 100°.
Some of the patients with a curve in excess of 100° were no longer able to sit because of the pelvic obliquity consequent on the scoliosis; they were bedridden not because of the Duchenne muscular dystrophy itself but because they had been allowed to develop such extensive spinal curves before referral to an orthopaedic muscle clinic.
Working with adult survivors of child sexual abuse
Editor ,— Does the surgical senior registrar who seems to have performed an unnecessary internal examination under anaesthesia without consent before an appendicectomy realise how lucky he is not to have been charged with battery?
According to the patient, she had made patently clear her refusal to allow him to perform a vaginal or rectal examination because of a history of child sexual abuse by her doctor father.
If the ideal course of action is not possible doctors must use their ingenuity to find another.
This was not a difficult patient, rather a difficult medical problem.
The surgeon apparently did not listen to his patient or respect her bodily integrity.
A defence of acting in her best medical interests fails: he could have tried to find a female gynaecologist, and, indeed, his female house officer had already examined the patient; a pelvic mass could have been shown by ultrasonography; if it was necessary to exclude pelvic disease a laparoscopy could have been performed before the appendicectomy; it is doubtful whether the examination under anaesthesia served any purpose as tenderness could not be elicited; and, finally, he could have asked the patient first whether an examination under anaesthesia was an acceptable compromise.
This patient was bound to be extremely distressed at finding that a male doctor had forcibly touched her intimately.
Waiting until she was anaesthetised and had no control over events re-enacted and reinforced the abuse begun by her father.
The examination under anaesthesia without consent is inexplicable (unless it was to punish her for having refused examination when conscious).
The surgeon also abused the patient, and it was a misuse of professional privilege that he did so.
Mothering skills of women with mental illness
Editor ,— The mothering skills of women with mental illness are important for the physical and mental health of their children.
Certain crucial issues are, however, confused in Louis Appleby and Chris Dickens's editorial.
On the one hand there is severe mental illness in mothers, possibly psychotic and requiring admission to specialist units.
Although the incidence of psychotic illness in women is significantly greater after delivery than at any other time, it is still relatively rare (about one or two cases per thousand).
On the other hand, there is postnatal depression, which is extremely common, occurring in 10–20% of mothers.
This condition is mostly dealt with in the community, which often means that it is not dealt with at all.
In inner cities the prevalence of depression among mothers of young children is even greater.
We now know that babies whose mothers are depressed continue to be affected even after the mother has recovered.
They tend to be more clingy and less competent, both socially and intellectually.
This was well summarised by Murray et al .
Many different factors contribute to the neglect and invisibility of maternal depression, not least the confusion between a rare psychotic illness and a common condition.
To deal with it and to prevent its persistent effects on children, doctors and nurses need more training to develop their psychological awareness and their counselling skills.
The ready availability of a screening questionnaire that mothers at risk can complete under supervision in a few minutes is potentially useful, but only if health workers and others can rise to the needs of depressed mothers.
This is a damaging epidemic which remains politically invisible but socially evident.
Screening for hypertrophic cardiomyopathy
Editor ,— We strongly support A L Clark and A J S Coats's conclusions that screening for hypertrophic cardiomyopathy is not justified at present and that more research is needed on both the effectiveness of early treatment and the natural course of minor abnormalities detected by screening.
We have recently been concerned by prominent publicity in the media in Wales relating  to the screening programme proposed by the Hypertrophic Cardiomyopathy Association and consider that more harm than good is likely to result from such a programme.
Even testing family members for the gene mutation may have serious and unforeseen consequences and should not be done without careful consideration and the fully informed consent of those being tested.
Clark and Coats rightly state that this ‘can have value in reassuring unaffected members of families where the mutation is known.’
The variability of the disorder, however, will inevitably mean that a proportion of such healthy people will prove to have the mutation, with uncertainty as to their prognosis and need for treatment or a change in their lifestyle as well as possible adverse consequences with regard to insurance and employment.
The implications could be even more important in a wider screening setting.
We suggest that the Hypertrophic Cardiomyopathy Association should use its energy and funds to support research to evaluate the effectiveness of screening, including the psychosocial aspects, rather than in promoting a so far unvalidated programme.
We are not aware of any such evaluation in progress, in Britain or the United States, and it will be increasingly difficult to undertake this if screening is adopted as part of clinical practice.
Editor ,— We wish to focus on two issues raised by the editorial on screening for hypertrophic cardiomyopathy.
Firstly, a distinction must be made between screening of family members of probands with the disease and screening athletes for cardiac disease, including hypertrophic cardiomyopathy.
We reiterate that first degree relatives of probands with hypertrophic cardiomyopathy, particularly the young, should undergo clinical examination, 12 lead electrocardiography, and two dimensional echo-Doppler evaluation.
The effort entailed and the disruption caused by screening the families of probands would not be warranted unless high risk patients could be identified and then effectively treated.
Algorithms detect most high risk patients, both young and old, and risk factor stratification shows that in about a third of them there is a likely or predominant initiating mechanism that is amenable to specific treatment — for example, paroxysmal atrial fibrillation with amiodarone; an accessory pathway with ablation; a gradient with β blockers, calcium antagonists, or myectomy; conduction disease with a pacemaker; refractory sustained ventricular arrhythmias with an implantable cardioverter defibrillator; and relative ischaemia in the presence of normal coronary vessels with nitrates and calcium antagonists.
Management is harder when risk factor stratification shows that a person is at increased risk but does not have a likely or predominant mechanism at which treatment can be targeted.
In those with non-sustained ventricular tachycardia during electrocardiographic monitoring treatment with low dose amiodarone has been shown to be effective.
Treatment in the young has to be decided individually, based on the relative risk and assessment of the most likely mechanism.
Randomised trials of effective treatment may not be feasible in hypertrophic cardiomyopathy as numbers of patients are small, event rates are low, and multiple initiating mechanisms requiring different treatments may be operating.
The goal must remain to improve risk factor stratification in order to target specific mechanisms.
Screening of athletes is a different issue.
Last autumn the Hypertrophic Cardiomyopathy Association and the National Sports Medicine Institute announced a joint project to assess the feasibility of screening athletes aged 15 to 30 for cardiac disease.
It will assess the value of a triage approach, using a questionnaire and then proceeding in selected subjects to clinical examination, electrocardiography, and two dimensional echocardiography.
It will also assess other potentially detectable cardiac conditions that would place the athlete at increased risk.
These include mitral valve prolapse, long QT syndrome, the Wolff-Parkinson-White syndrome, arrhythmogenic right ventricular dysplasia, and anomalous left coronary artery.
We recognise that many aspects must be investigated before any widespread national screening programme should be undertaken.
These aspects include the likely yield; the understanding of subjects, families, and sports institutes; the advice and counselling of those taking part; and the financial implications.
Low pick up rates, the inability to make confident diagnoses with current technology, and the potential problems of managing those with equivocal or definite disease may render larger scale surveys unnecessary, excessively problematic, or not cost effective.
Our pilot project aims to assess the feasibility of identifying people at risk, nothing more.
Community dermatology
Editor ,— Robin Russell Jones's letter suggests that dermatologists are unhappy with pressure from general practice fundholders to hold clinics in the community.
He and colleagues reviewed 70 referral letters from general practitioners and, not surprisingly, found that only 27% of the general practitioners had made the correct diagnosis.
This approach is fascinating for several reasons.
Not for the first time, hospital doctors have taken it on themselves to audit general practice activity rather than their own to support their viewpoint.
The approach also shows a lack of knowledge of the reasons why general practitioners refer patients to dermatologists.
Bradlow et al reviewed 3678 referrals from general practitioners to dermatology outpatient clinics and found that 26% of patients were referred for diagnosis or investigation, 14% for advice only, 63% for treatment or management, and 2% for a second opinion or reassurance.
Thus to analyse general practitioners' referrals solely on the grounds of diagnostic accuracy is to give an incomplete picture of why patients are referred to outpatient clinics.
Armstrong et al described dermatology as one of the hospital specialties in which there is a lot of pressure from patients for referral.
They speculated that this may be related to the fact that patients are referred with chronic or refractory conditions that have proved difficult to treat in general practice.
Russell Jones's comments regarding the practice of good dermatology and the requirements of ‘adequate eyesight and clinical expertise’ backed up by hospital based diagnostic and therapeutic facilities raise questions about why dermatologists often have a monopoly of these facilities and whether general practitioners should have open access to these facilities.
I ask these questions so that dermatologists can provide me with evidence of their effectiveness, efficiency, and value for money.
Any assessment of the quality of outpatient referrals should take account of the timeliness, effectiveness, and necessity of the referral from the viewpoint of the patient, the general practitioner, and the hospital doctor.
I suggest that, for the next meeting of the North West London Dermatology Audit Group, local general practitioners and general practice audit facilitators should be invited to attend and a joint audit on the quality and appropriateness of outpatient service should be undertaken by all parties.
Medical audit should relate to aspects of clinical activity over which one has some control so that change can be initiated if a problem is identified.
Otherwise isolated audit of general practitioners' referrals by hospital doctors is ‘dangerous nonsense.’
Editor ,— Robin Russell Jones says that dermatologists working in the community (presumably this includes private consulting rooms) would be incapable of providing an adequate dermatological service.
It should be possible to compare the cost effectiveness of community based clinics with that of hospital outpatient care.
I am sure that fundholding general practitioners would be willing to participate in such studies.
Perhaps the debate could then be continued on a more scientific level.
Editor ,— We are concerned that Robin Russell Jones should hold such a poor view of general practitioners' accuracy in making dermatological diagnoses and is so opposed to community clinics.
As prospective third wave fundholders we are exploring the possibilities of such clinics as one way of improving care for our patients, and we consider that dermatology is a suitable specialty.
To study the feasibility of such a clinic we looked at 104 consecutive dermatological referrals (August 1992 to February 1993) from doctors working in the practice (as part of the fundholding data collection exercise we have kept copies of all our referral letters).
The referring doctors included trainee general practitioners and locums as well as the partners.
Of the 104 referral letters, 91 (88%) offered a diagnosis, compared with Russell Jones's figure of 40%.
We received letters about 54 patients.
In 33 of these the diagnosis offered was confirmed by the consultant, giving a diagnosic accuracy of 61% compared with the 27% quoted by Russell Jones.
Eighteen patients had a skin biopsy or had a lesion removed, but no tests other than the usual histological examination were necessary.
Twenty six patients were given follow up appointments, either to assess treatment or to give the results of histological examination.
The waiting times for NHS appointments varied between 2 weeks (for those patients for whom urgent appointments were requested) and 21 weeks, with a mean of 13 weeks.
Disturbingly, however, 27 patients who had been referred between August and December had still not been seen by the end of the study.
Perhaps these were non-attenders, but if so we have not yet been notified by the hospitals.
It is rare in general practice to see dermatological problems that need sophisticated hospital investigations or intensive treatment; most referrals are for assessment of skin lesions or for second opinions.
Seeing patients in general practitioners' surgeries is no different from seeing patients in private consulting rooms — a practice that fails to provoke outrage among dermatologists.
A well run community service can deal effectively with most skin problems.
Most cases would not require hospital follow up, as our figures show.
This would allow dermatologists to concentrate resources on patients who need the technical support available in hospitals.
Academic obstetrics and gynaecology
Editor ,— In his comments on Richard Smith's editorial on academic medicine Brian L Pentecost states that, so far as training for consultant practice in the NHS is concerned, all specialties accept one year of research towards higher medical training.
This is not true.
The accreditation regulations of my college, the Royal College of Obstetricians and Gynaecologists, allow for up to one year of research during which the candidate has undertaken a regular clinical obstetric and gynaecological commitment.
I have spent three and a half years in research, leading to a PhD in molecular biology.
The research itself was laboratory based, although directly relevant to academic obstetrics.
During that time I held honorary NHS senior registrar status and, to maintain my clinical skills, was on call once a week as a resident registrar in obstetrics and gynaecology and did a full day's operating list once every two weeks.
Although this would seem to fulfil the requirements of the regulations, my application to have this experience recognised for just six months of higher training was rejected by the college without explanation.
In contrast, subspecialty trainees, undergoing training in the same institution and at the same time, are allowed a full year of credit but are not expected to undertake any general obstetrics and gynaecology during their subspecialty years.
This seems to indicate that the college considers that a subspecialist trainee can acquire general skills in a shorter time than an academic trainee.
There is an attitude of discrimination against academics within our specialty, highlighted recently by Thomas.
Although academic consultant appointments do not require accreditation, stigma is attached to those people who are not accredited.
There is a dire need to encourage juniors into academic obstetrics and gynaecology.
The number of vacant senior lectureships and chairs attests to this.
Until the specialty and, more importantly, the college recognise the value of an academic career and are willing to regard academics as equals, academic obstetrics and gynaecology will be an unpopular choice and will remain in the scientific shadow of medicine and surgery.
Continuing education needed for forensic medical examiners
Editor ,— The Today radio programme has reported that police surgeons or forensic medical examiners are to call for a ban on methadone for prisoners in police custody.
This is a response to the conviction of two forensic medical examiners of the manslaughter of a prisoner for whom they had prescribed methadone.
They had not, however, been trained in forensic medicine, and they prescribed several drugs in excessive doses after the prisoner had already been withdrawn from opioid drugs.
I urge that there should be no such hasty reaction to what is not only a tragedy for the patient and his family but a tragedy for two medical practitioners, their families, and their peer group of forensic medical examiners.
Practical, legal, and ethical difficulties arise in the management of supposed drug dependent people in custody.
A naive acceptance of what the prisoner says, especially when the supply has been illicit or there is no prescriber to consult, may result in overprescription of drugs intended for maintenance or withdrawal but resulting in intoxication or perpetuation of dependence, or both.
A decision not to prescribe or an underestimate of need, with justified caution, may aggravate or precipitate a distressing withdrawal state, which a doctor has a responsibility to prevent or relieve and may make the prisoner unfit to be interviewed.
Ideally, opioid dependent prisoners in custody should be stabilised with the right dose.
If they have been taking a prescribed drug this is likely to have been methadone, and if the daily dose can be established this can be prescribed.
If there is uncertainty about the dose it may be wise to prescribe methadone 20 mg and then review this in the light of the response.
To prescribe nothing could be unethical, uncaring, and perilous in terms of the investigation of the case and the pursuit of truth.
Some forensic medical examiners, however, are reluctant to prescribe methadone.
Some prefer dihydrocodeine, but this substitutes so poorly that large quantities may be needed, and it often leaves many prisoners suffering considerably.
Although methadone can be given in police custody only under supervision, its advantage is that it needs to be given only once daily.
I hope that the advice of the Advisory Council on the Misuse of Drugs will be sought.
Surely the most important issue, however, is the training and continuing medical education of forensic medical examiners.
There are diplomas in medical jurisprudence and forensic medicine and excellent courses of preparation such as that run by the Forensic Academic Group in the North.
If there is any hasty reaction it should be a requirement that all forensic medical examiners are properly trained and have provision for continuing medical education.
Male obstetricians and their patients
Editor ,— It is true, as James Owen Drife points out, that it has become at least partially acceptable for women to stereotype the worst of male behaviour and make fun of it, but somehow I find it hard to feel sorry for him.
As almost every woman who has ever complained about jokes against women has been told, ‘Where's your sense of humour?’
Part of the problem lies in his opening statement: ‘Eighty seven per cent of consultant obstetricians in Britain are male.’
Any complaint about medical treatment thus almost certainly is a complaint against a man.
Does he really believe that the woman who spent an hour asking questions would have passively accepted everything a female consultant told her with no queries?
If there is a power imbalance between patients and doctors this is doubly so between male doctors and female patients.
If male doctors have difficulty accepting or understanding this it is probably because they have not been in such powerless positions since childhood.
Drife should not be surprised that many women respond to a strange man with a conditioned response that arises from a long learning experience in a male dominated society.
Many women have learnt to be wary and to offer trust slowly.
Why, simply because he is a doctor, should he assume that women will come as trusting, respectful, and, above all, compliant patients who can be dealt with quickly?
Despite this Drife should take heart from the cartoons in the journals.
It has long been accepted that people make jokes about what frightens them and that groups who feel oppressed use humour as a way of releasing negative feelings to those in power.
He should hope that such cartoons continue.
While women use them as a way of releasing tension, frustration, and rage they will have the illusion of doing something while nothing changes.
A better solution to female patients being hostile to middle aged male obstetricians, of course, is to ensure that in the coming generation of doctors 87% of obstetric consultants are female.
Correction
Drugs, secrecy, and society
An editorial error occurred in this letter by J Kilgour-Christie and A H Watt (13 March, pp 721–2).
The first sentence of the fifth paragraph, which started ‘Risk attributable to drugs is poorly estimated,’ should have started ‘Risk attributable to disease is poorly estimated.’