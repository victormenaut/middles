

Comparing sign languages
The subjects of this chapter are comparative and international aspects of sign language.
These topics have been touched upon briefly in earlier chapters; they will now be brought together and discussed in greater depth, along with new material from current research.
As Battison and Jordan (1976) point out, writers in the past, by using expressions such as the sign language, have tended to present sign language as universal and easily understood.
They cite Long's (1918)The sign language , and Michaels' (1923)A handbook of the sign language of the deaf , and we can add to their list Nevins' (1895)The sign language of the deaf and dumb , and Guide to the silent language of the deaf and dumb (anonymous and undated).
The clear implication is that there is one universal sign language.
An author who studied the American Indian sign system used for ritual story-telling reported that the sign language of Indians, of deaf people, and of everyone else ‘constitute one language — the gesture speech of mankind, of which each system is a dialect’(Mallery, 1881).
A writer, Berthier, who was deaf himself, stated ‘For centuries scholars from every country have sought after a universal language and failed.
Well, it exists all around, it is sign language’(quoted in Battison and Jordan, 1976: 54).
Other writers answered the question of the universality of sign language with less certainty: ‘though all nations do not use the same mode of signs, one having a knowledge of the signs herein delineated will experience little, if any difficulty in understanding other modes, and of being understood by those who use a different mode’(Michaels, quoted in Battison and Jordan, 1976: 54).
Two more detailed and better considered responses to this question were those of Wundt and Tylor.
Wundt, a 19th-century psychologist, researched the signing of German deaf children with the aim of discovering the universal properties underlying all languages.
Wundt thought that the universality he perceived in sign language was related to the concreteness of its concepts:
Systems of signs that have arisen in spatially separate environments and under doubtlessly independent circumstances are, for the most part, very similar or indeed closely related; this, then, enables communication without great difficulty between  persons making use of gestures.
Such is the much-lauded universality of gestural communication.
Further, it is self-evident that this universality extends only to those concepts of a generally objective nature: for example, you and I, this and that, here and there, or earth, heaven, cloud, sun, house, tree, flower, walking, standing, lying, hitting, and many other such objects and actions perceived according to their basic features.
(quoted in Mayberry, 1978: 351)
As Mayberry points out, if sign language only has concrete concepts then the signs are iconic and universally understood.
Conversely, if sign language is universally understood, then it must be limited to concrete and picturable concepts.
Tylor, a 19th-century anthropologist, also studied sign language in an attempt to understand the nature of human communication and its origins:
With the advent of linguistic research on sign language from the 1960s onwards, attitudes towards universality of sign language changed considerably, often to the point where mutual unintelligibility between sign languages was reported, with researchers at pains to identify sign languages as completely different from each other.
Very frequently in the literature earlier discussions about sign language universality are described as myths or misconceptions.
As Mayberry (1978: 33) points out: Today it is common practice to begin papers by setting the record straight, so to speak, sometimes with what strikes the reader as being an unusually strong position regarding inter-sign language comprehension given the current state of knowledge.’
There are a great number of references, for example,(very often American) to the mutual unintelligibility of ASL and BSL (Mayberry cites Stokoe, 1972; Fischer, 1974; Lane, 1977 among others).
One by-product of regarding sign languages as  mutually unintelligible has been the attempt to create an international, artificial sign language, similar in aim  to Esperanto.
Gestuno, as it is known, was developed by the World Federation of the Deaf for use at international conferences of deaf people.
The attitudes of deaf people to its use is that it is no easier, and possibly more difficult, to understand than a foreign sign language.
The reasons for the shift from regarding sign language as one universal form of communication to seeing sign languages as highly different from each other are easy to understand, but the result has been confusion over what questions remain to be asked about the differences between sign languages.
Battison and Jordan (1976) asked five questions; although posed so long ago, the answers are not clear.
In this chapter we will discuss these questions and the preliminary answers we have, suggesting possible ways of answering them in the future:
(1)
Do deaf people around the world use the same signs?
(2)
Can signers understand each others' sign languages?
(3)
Can signers from different countries communicate with each other even if they don't know each others' sign languages?
(4)
Do signers have a clear idea of the separateness of different sign languages, or do they feel and act as if they are all basically the same thing?
(5)
What attitudes do people have about their own sign language and about foreign sign languages?
A sixth question should also be added: Do deaf people around the world use the same grammar?
This question is needed because even if signs were the same around the world, the grammar of sign languages in different countries might be different.
Battison and Jordan report several types of study to determine if signers from different countries understand each others' signing.
The first (Battison and Jordan, 1976) reports the results of an attitude survey among deaf people from different countries attending an international conference.
While they acknowledge that the data on their first two questions, as to whether sign languages are understood by foreigners, were mostly self-reports, they conclude that signs used in foreign countries, or even in different parts of the same country, are largely unintelligible in connected discourse.
This conclusion is based on comments such as:
A young woman from Lyons reported that she refuses to visit Paris without her friend who has been to Paris more often and understands the Parisians' sign language better.
A standard story, repeated by travellers and natives alike, holds that if you travel 50 miles in Britain you will encounter a different sign language that cannot be understood in the region you have just left.
(Battison and Jordan, 1976: 59)
Clearly, people's reports of communication difficulties and the actual difficulties encountered are different, as research on sign language in Britain has found one sign language, called BSL, albeit with dialectal differences.
Apart from anecdotal and self-report data, two other kinds of study have been reported.
In the first of these, lists of signs in dictionaries are compared (e.g. Woodward, 1978); in the second, referential communication experiments between signers of different countries are performed (e.g. Jordan and Battison, 1976; Mayberry, 1978).
It should be noted that the referential communication experiments of the type conducted by Jordan and Battison and by Mayberry are designed to answer question (2) rather than question (3).
In other words, signers are not asked to try to communicate information to a foreign signer, but are instructed to use their own sign languages when addressing a same- or different-language partner.
Even in this strict condition, signers performed better than would be expected for two unrelated spoken languages.
Of course, possible historical relationships between different sign languages should not be excluded as a reason for similarities between two sign languages.
There have been attempts to explore similarities in terms of historical links.
Most of the comparative work has been concerned with ASL and French Sign Language.
It is generally assumed that ASL is historically linked to the French Sign Language of the early 19th century, researchers seeing evidence of cognate signs in French Sign Language and ASL (fig. 8.1).
(Cognates are pairs of words or signs which are historically linked, as opposed to being coincidentally similar or borrowed.)
The most comprehensive sign language comparison is Woodward's (1978) glottochronological study.
Glottochronology is a technique developed for spoken languages which has a basic assumption that languages change at a relatively steady rate.
Thus, by comparing the percentage of cognate words in two related spoken languages it is possible to estimate fairly accurately the date at which they separated.
For example, we would expect to find a very high proportion of cognate words in British and American English but a much lower percentage if we compare English and German and still lower if we compare English and Russian.
When applying glottochronological analyses it is crucial that only cognate words are compared, and not words which are coincidentally similar, or which may have been borrowed from one language into another: to include these would give a false high rating of similarity.
In Woodward's study, signs from French Sign Language and ASL were compared.
Historical evidence would suggest that American and French sign languages began to go their separate ways in 1816, when French Sign Language was imported with the French deaf teacher Clerc; one would therefore expect a very high degree of similarity, as 1816 is very recent in glottochronological terms, and the percentage of cognate signs should be over 90 per cent.
Instead, Woodward obtained a cognate figure of 60 per cent.
This low figure he attributed to ASL being a creole, or combination of French Sign Language and at least one other sign language.
This is reasonable, as one would expect deaf people in the USA to have been   using some sign language before the imported use of FSL.
What is not explained satisfactorily in Woodward's paper is why the 60 per cent of similar signs were regarded as cognate, rather than coincidentally similar or loan signs.
An extreme version of the historical relationship approach is Anderson (1979) where large ‘pre-historic’ families of sign languages are postulated on   such evidence as whether the sign for ONE is formed with the extended thumb (A) or index finger (G)(fig. 8.2).
It is clear that the choice of signs for comparison will affect the results of such an exercise; a balance must be sought between too small a number and too great.
Generally, for spoken language glottochronology two lists have been used, a 100-word list and a 200-word list (which includes the 100-word list), both developed by Swadesh (in Samarin, 1967).
Woodward (1978) used Swadesh's 200-word list with some modifications; Stokoe and Kuschel (1979) have developed another 200-word list for sign language data collection.
None of these lists, however, is wholly useful for the study of urban deaf populations, as all three have been designed for anthropological study of one sort or another, and include words such as spear and dung .
The spoken language lists also include items not relevant to deaf populations.
The Stokoe and Kuschel list was developed for use by anthropologists on field work, and also does not include items relevant to deaf culture.
The list developed for the study reported here (Woll, 1983) contains in its full form 257 items, many of which do appear in the other lists.
The words which do not appear in other lists fall into several important groups: signs relevant to deaf culture, signs which might be subject to borrowing by languages in contact, signs where compounding is likely to occur, number and colour terms.
As with other dictionary comparisons, however, a number of ‘warnings’ must be given.
The first is that where dictionaries are used as a data source often little is known about, for example, how formal the sign is, whether there are other social or regional variants, how well the translation represents the meaning of the sign.
With the technique adopted in Woll (1983) of recording signers  translating a word list into signs, the data include only one signer from each sign language.
Therefore, when the term ‘British Sign Language’ is used, it can only mean signs used by a British signer.
Secondly, any subset of a lexicon, whether from a dictionary or word list, can only give a partial, and perhaps unrepresentative, view of language.
Thirdly, as mentioned above, because we know little about historical relationships between sign languages it is difficult to disentangle historical influences and similarities between signs arising from other causes.
This problem also appears in glottochronological studies of spoken languages, of course, as the example below illustrates.
The following are words meaning ‘mother’ in several spoken languages:
English: mother
Latin: mater
Russian: maht
Hebrew: imah
Chinese: ma
We already know that English, Latin and Russian are related languages, so we would see these data as revealing the common origin of these languages.
Hebrew is thought by some linguists to be very distantly related to the first three languages, and by other linguists not to be related, so the reason for the similarity cannot be definitely given.
It is fairly universally accepted that Chinese is not related to any of the four other languages, so the similarity cannot be because these words are cognate.
The Chinese word ma might be a loan word, it might be coincidentally the same, or the similarity might arise from another factor.
In fact, the widespread finding that the word for ‘mother’ in unrelated languages often includes the sound ‘ma’might lead us to look for sound symbolism as the underlying common factor.
The last observation about dictionaries or word lists is that they may under-represent similarities between different sign languages: for example, the American and British signs for WALK are quite different, but British signers would certainly use a sign resembling the American sign in certain contexts.
In other cases the particular translation of a sign may fail to show similarity: the Danish and British signs for WOMAN are different, but the British sign LADY resembles the Danish sign WOMAN; such information is not picked up by this method of data collection.
Word list translations have been obtained and analysed in 15 different sign languages.
The most striking finding from this comparison (Woll, 1983) is that the average percentage of similar signs in two different sign languages is 35–40.
This figure, of course, is much higher than one expects for two unrelated spoken languages.
Languages with a known close historical relationship show far higher percentages of similar signs: 80 per cent for British and Australian Sign  Languages.
Among other interesting observations from the study is the similarity of the Flemish and Walloon Sign Languages, the sign languages which are used by deaf people who belong to different spoken language communities in Belgium.
This finding suggests close interaction between deaf people belonging to these different groups.
In contrast, Flemish and Dutch Sign Languages, although found in adjacent countries with the same spoken language, are very dissimilar.
In terms of findings, Woodward's 60 per cent cognate score for American and French Sign Languages represents quite a low degree of similarity over what one would expect from any two unrelated sign languages, and this suggests that ASL and French Sign Language are not very closely related.
Another interesting finding relates to the signs illustrated in fig. 8.1.
In the 15 sign languages analysed, the following signs were found for LAUGH, HELP and (tell a) LIE, In all 15 sign languages, the sign for LAUGH was located at the mouth or lower cheek; the hand was either held with index finger extended, or index and thumb extended and moved from side to side.
In all 15 sign languages HELP was signed with the right hand lifting and moving forward the left hand, forearm or elbow.
In all the sign languages except Chinese Sign Language,(tell a) LIE was located at the lower face, with the hand moving sideways.
Clearly, the similarity between the French and American signs is not in itself indicative of an historical relationship.
What the data show is that the issue of sign universality cannot be easily described as confirmed or disproved.
Further attention must be devoted to sign forms and their derivation.
This can be seen in the context of new sign formation.
Apart from the word list, the comparative study reported above also included the signing of a text based on a picture book story The snowman .
In the recounting of this story, several objects are referred to for which most sign languages do not have already existing signs.
These include a skateboard and a punchball.
Eleven of the 15 signers signed ‘skateboard’ in terms of its shape (oval with pairs of wheels), its movement (forward and side to side) and how a person interacts with it (standing on the board, balancing with arms and body).
(The other four signers referred to only two out of three of these features.)
Similarly for ‘punchball’, the predominant way of signing it was threefold: shape (ball on a stick), movement (springs to and fro on a pivot) and how a person interacts with it (hands punching alternately); these three are salient features.
Signs in use for many referents reflect one or two of these properties, and thus we should not be surprised that comparisons of sign lists result in such a high degree of similarity, as the appearance, movement, and use of an object can be expected to be similar across different cultures.
Other similarities can be explained in different ways.
Nine of the sign languages studied used similar signs for AMERICA.
This form, which is also found in ASL, is likely to have been borrowed by other sign  languages from ASL.
This is the case for two reasons: many signers report another sign for AMERICA which is disappearing; the sign itself is not ‘transparent ‘, and there is no known link between the sign and any visual image.
In other cases, similar signs are found only among sign languages with known historical links.
The sign for BAD in BSL is formed with the little finger extended from the fist, and the same sign occurs in New Zealand, Australian and South African Sign Languages.
The similarity between signs can thus be accounted for by historical links, borrowing of signs through contact between signers, or cultural universal propensities to label concepts in particular ways.
Sign languages reflect all these processes.
Less is known of sign language grammar universals than of lexical similarities.
Throughout this book, however, we have drawn on examples from research in other sign languages and found parallel or identical structures.
Table 8.1 summarises some research on grammatical features in different sign languages which are also found in BSL and which have been discussed in this book.
Many of the features common to different sign languages are also found in spoken languages.
We can therefore attribute some similarities of grammar to universal properties of language, whether spoken or signed.
In a study of communication among signers from different countries at an international workshop, Moody (1979) noted that three features were found: grammar, mime and ‘international’ gestures.
The vocabulary required is rapidly and easily established through interaction between signers, clearly with a shared grammar, recourse to mime and a percentage of shared vocabulary.
The process of communication is greatly facilitated.
But perhaps the most important feature which makes communication possible across different sign languages is the shared culture of deaf people.
The deaf of all countries face similar educational experiences and suppression of their sign language.
This has helped to unite deaf people and provides a common experience as well as common linguistic structure on which to draw.
Learning and using BSL
While the study of the language is critical to the development of BSL and its acceptance, it is also true to say that there is a more pressing problem in relation to BSL, at least in the eyes of deaf people, and that is how to learn and use it.
Deaf people in the community appear to learn BSL easily, even if they have to wait until they have left school.
However, the learning of the language is not simply a matter of being deaf, since those who become deaf later in life very seldom achieve a fluency in BSL which allows them to be accepted within the community.
In one sense this is a hopeful sign, at least for hearing people, since BSL learning is not determined solely by the inability to hear but more probably by motivation and the identification of the learner with the community of users (see chapter 1).
From all the discussion so far, one would predict that BSL as a language should be no more difficult to learn than a foreign language, except, that is, for the fact that BSL is not a high status language and its users are often treated as failures.
Our discussion here will consider the variables normally found important in second language learning, and consider how they might be used to predict BSL learning.
In a final section, Krashen's (1981) theory of second language learning will be explored and its implications for BSL learners considered.
There has been very little research into BSL learning, and certainly no systematic analysis of the skills needed.
There has always been a lingering suspicion that BSL is a very difficult language to learn once beyond a few preliminary signs.
Indeed, the principal argument against its use in education has often been the claim that hearing people find it almost impossible to use effectively.
This is at least untrue in the USA, where there is a comprehensive system of further education for deaf people in which the medium is an accepted form of ASL which hearing instructors use.
Hansen (1980) maintains that hearing people can learn sign language to a satisfactory extent and can be successful in passive learning, i.e. understanding deaf people's signing, within a short time.
However, it is certainly the perception of people working in the field that the level of sign language skill exhibited by hearing people, even those who function as interpreters for deaf people, is much lower than it should be.
If deaf  people's link to the hearing world and to the information distributed by the hearing world is faulty, then unless they have recourse to a second hearing person who can act as a check they will be unaware of the faults of the first hearing signer.
Even if the faults are apparent, a deaf person would be very wary of criticising for fear that the interpreter would no longer co-operate and that even the slim link to what is being discussed in hearing company will be taken away.
Therefore, the analysis of hearing people's skills in BSL is not simply a matter of eliciting deaf people's views on hearing BSL users, but must take into account a societal element not apparent in the evaluation of skills in, say, french.
There are, nevertheless, many features of foreign language learning which will be familiar to those who are learning sign language.
In introducing the principles of language learning, Brown maintains:
Becoming bilingual is a way of life.
Every bone and fibre of your being is affected in some way, as you struggle to reach beyond the confines of your first language and into a new language, a new culture, a new way of thinking, feeling and acting.
Total commitment, total involvement, a total physical, intellectual and emotional response is necessary to successfully send and receive messages in a second language.
(1980: 1)
In fact, according to Brown it is virtually impossible to teach a language; what one can hope to do is to provide a situation where the complex variables which contribute are maximised.
These views simply emphasise what is often forgotten; that learning any language is a difficult task.
As a result, a great deal of the research on foreign language learning focuses on the problems involved, and usually on the errors made by the students of the second language.
BSL learning usually begins beyond what is normally considered an optimal age and should therefore be compared with the learning of foreign languages later in life.
There are usually problems.
The case of Zoila highlighted by Shapira (1978) is almost certainly a typical case.
Despite Zoila's everyday contact with English speakers in the USA, her use of English after three years of learning was very poor.
Shapira's explanation is that Zoila had reached what was for her a satisfactory level of interaction and was not motivated to progress.
Her initial negative view of English and the tolerance of her poor English by others meant she could ‘get by’ with her deviant grammar and limited vocabulary and articulation.
Shapira's view is that she still used English through a translating frame from Spanish and had not fully embraced the language form.
This may be compared with the apparent slowness of hearing people's learning of BSL.
Schumann's (1977) model of ‘social and psychological distance’ seems particularly applicable to Zoila's case.
The closer one is to a second language group, either socially or psychologically, the greater the probability of adequate learning.
Social distance can be expressed as a series of  questions constituting a rating scale.
In sign language terms these would include:
Do hearing people control the fortunes of deaf people politically and economically?
Do hearing people tend to occupy more influential positions in technology than do deaf people?
Do hearing people have a significant role in raising the level of deaf people's lives to help them fit into society better?
Is the hearing community much larger than the deaf community?
Is the contact of the learner with the target language group likely to be intermittent rather than extensive?
Positive answers to most of these questions (which is what would be typical) indicate a poor language learning situation according to the model of social distance.
We should go through the questions again, substituting ‘English’ for ‘hearing’and ‘French’for ‘deaf’.
We can see that the social distance between french and English is much less.
Hearing people are members of the dominant culture, who usually wish to preserve their hearing status and whose length of stay among deaf people is often no more than a few hours at a time.
Sign language is therefore less accessible than french, for example.
According to Schumann, the greater the distance the more likely is the pidginisation of the target language.
This happens with Latin American workers in the USA and it also happens with ASL users (Fischer, 1978).
In order to overcome such a learning situation, Schumann suggests that psychological distance must be minimised.
This is done by high motivation and especially by immersing one's own identity in that of the culture of the target language group.
In learning sign language the opportunities for doing this are relatively few, and so sign language learning takes place in a less than ideal environment.
Nevertheless, it is of some importance to try to establish what the effect of this learning environment is on the actual communication between deaf and hearing people.
Kyle, Woll and Llewellyn-Jones (1981) have described the opportunities available to BSL learners, and it is quite clear that these are less than adequate in relation to decreasing social distance.
Even though one would probably not question the desire to minimise psychological distance, since most students are highly motivated and continue to attend courses for very long periods, it is clear that there is little loss of personal identity and very little contact with deaf people.
Courses primarily of the one-hour-a-week variety and based on vocabulary with English — sign equivalents can do no more than serve as an introduction.
Unfortunately they may also prove a hindrance if BSL is presented only as manual English, through the tutor's adherence to English or through the other necessity of providing English syntax for deaf people one is in contact with, since ‘it will help their English’.
In this instance, the caring role of the learner may well interfere with the task of adequately learning the language.
The extent of the problem will be discussed later in this section, but clearly there are other factors in language learning and some hearing people do learn to use BSL and achieve communication fluency with deaf people.
Our framework for understanding this is, as with social distance, based firmly within the literature of second language learning.
Virtually all the settings in which sign language is learned can also be found in second language learning.
Languages can be learned because the student has a specific purpose for his own development (such as improving his career prospects), or because he has an interest in the culture or the language itself.
Languages can be learned ‘at home’, where there are few opportunities for mixing with the native users of the language (such as evening class french) or they can be learned in a second language situation, either in the country in which that language is native or in one's own country where the language is used for a specific purpose (such as learning English in parts of Africa where it is used as the commercial language).
Each of these situations exists in sign language learning, although the total immersion options are usually reserved for those people with deaf relatives.
It is possible, then, to systematically examine these factors which are often proposed in describing spoken language learning and to indicate how they might apply in the sign language situation.
Strategies for language learning
Given that an individual has a purpose in seeking training in a second language, there is a whole range of in-built techniques for learning which the student can bring to the learning environment.
Most of these techniques have been described in psychological terms and are particularly useful in explaining the errors a new student makes in using the language.
Most of the functioning of an individual is now considered by cognitive psychologists to be controlled by strategies of one sort or another.
The learning process consists of the acquisition of adaptive knowledge in the form of new facts or new strategies.
The knowledge is adaptive when it can be fitted into an already existing framework within the individual but allows an extension of his capabilities.
Learning occurs not because the person is somehow ‘ready’ for the next stage but because he is able to organise the incoming information in a satisfactory way.
The human system is geared to this acquisition, and even when what is learned appears to be maladaptive or produces negative traits, it derives from a natural process.
Errors made in the learning of a language, whether it is a first or a second one, are often indicative of the range and type of strategies used.
One useful strategy in  language learning is generalisation, but it is most noticeable when it exists as over-generalisation.
The child who uses goed or comed is guilty of over-generalisation, while in sign the use of repetition to convey occurrence over a long time would be appropriate in WAIT-WAIT-WAIT, meaning ‘wait for ages’ but not in KEEP-KEEP-KEEP, where it would probably mean to ‘keep three’things rather than to ‘keep over time’.
However, most of the time generalisation works appropriately and it is absolutely essential since the student will never experience all occurrences of the words or signs of the language.
It has to be possible to produce spontaneously original sentences which are based on implicit rules which allow generalisation.
The learner's ability to do this quickly and effectively from an early stage is obviously an important feature of language growth.
However, not all strategies, though natural, are productive.
Interference from the native language is probably one of the most noticeable aspects of the early stages in second language learning.
It is often apparent in sophisticated users of the language, and shows up as recurrent mistakes, usually of syntax, one school of thought, however, to be discussed later, considers this another strategy and not interference).
In sign language learning, because of the greater status of the learner over the native user, the first language intrusion may frequently go uncorrected, as occurred in the case of Zoila.
The importation of English grammar into BSL is a particular feature of low status languages, where the learner's language interference may continue unchecked until there is a communication breakdown and where it is usually the lower status person who accepts the responsibility for the breakdown.
A further complicating factor is that English interference in BSL occurs at times under the guise of improving the English skills of deaf people, so that the interlanguage (a variable form of signed English) may be given a higher status than the original language.
The hearing learner then seeks only to master the interlanguage, which has no cultural base, and which therefore lacks the social depth of either language.
Avoidance is a negative strategy seen in language learning.
It is most likely in communication settings where topics about which the learner is unhappy are avoided or ignored.
As a strategy in the general learning situation it can be particularly damaging, and this is also true of language learning.
In sign, it can be seen in the learner's apparent acknowledgement of comprehension of a statement by the deaf person which the hearing learner in fact has not understood, or it involves an immediate switch of topic by the hearing learner to something in which he feels more competent, without answering the deaf person's query.
This latter tactic often succeeds because of the unwillingness of the deaf person to try to force the point or to contradict the hearing person.
As is becoming apparent, sign language is a language at risk; a language  which may be dominated by the learner to the extent that a distorted view of discourse with a native signer will be obtained.
This is even more of a problem: it will not only damage the perspective of the learner but it will also effectively bar him from experience of the full language, since the native users will be unwilling to use it in his presence.
This of course takes us into the domain of attitudes and feelings of the learners, and is an area more influenced by emotion.
Affective factors
If we consider the commitment required for the task of learning a language then it is not surprising that there is a large affective or emotive component in the eventual success of the learner.
It is a factor recognised for a very long time in relation to language learning.
There may be a number of reasons for this, but a very likely one relates to the whole question of our treatment of people within the community who are different.
As was pointed out by Kyle (1981b), the field of special education engenders an isolation whereby children are viewed as totally unique, and their development is a personal co-operation with the adults around.
The teacher's relation with a child is much more intense and long-lasting than for a teacher of a normal child, since they will be together in close contact during a longer period of growth.
This is no bad thing at all, but it tends to produce a conflict of knowledge and practice.
The resulting adult — child interaction is clouded by this conflict.
The conflict arises in two major ways: firstly, the most basic need of all, to understand the functioning of the child, is confounded by a need to hide this functioning, since it is this which makes the child most different from the community.
So the teacher of a blind child, while allowing all along in the child's education for the difficulties he encounters, still prefers to emphasise to everyone the sameness of the child (his skills and achievements).
The teacher of the deaf also alters the child's educational environment but still proclaims his hearing ability (i.e. the ‘residual’ hearing).
Neither of these situations is in itself damaging, except that it may produce a denial of the actual preferred functioning of the child.
Sign language is a particularly obvious stigmatising feature for the young deaf child, and so produces very negative feelings in the teacher (as exemplified in appendix 1), and thereby in those, such as parents, influenced by the education process.
Any difficulty of sign language learning anses because of this negative feeling and not vice versa .
Secondly, and perhaps inevitably arising out of the first situation, the young adult who joins the sub-culture of deafness and uses sign language has, in the community's eyes, given up the search for sameness and therefore society's help comes in a ‘care for the disabled’ package.
This has traditionally given lower role  status to those who work in the field, but has also made their language learning goal an educational and care one.
The task of interpreting has been seen in the UK only in terms of social service, often voluntary, but never in an enabling framework.
So while interpreters working from spoken English to sign language are called upon to work for nothing as a service to these normal, intelligent ‘disabled’ people, those in the foreign spoken language interpretive role, where language users are equal, may rise to occupy one of the highest status roles in diplomacy, and correspondingly command high financial rewards.
The point of all this is that the personality of the individual who chooses to learn sign language must therefore be one which can resolve these tensions or pressures from the community and invoke sufficient motivation to ensure success.
The motivation issue is not an easy one to discuss, since it is an item which is seldom adequately defined.
Gardner and Lambert (1972) examined two kinds of motivation —‘instrumental’ motivation and ‘integrative’motivation.
The former is one based on the career needs of the individual, and refers to the need to achieve a particular level (passing an exam or reading technical material in that language), and the latter occurs when the learner seeks to identify with the culture and become part of it.
They claim that better language proficiency occurs when integrative motivation is prominent.
Language teachers may tend to present the view that it is the only way to learn the language.
However, research on Indian students learning English suggests that to learn the language for commercial purposes it may also be effective to have instrumental motivation.
Brown (1980) takes this as evidence that there is a range of language contexts and that these may be influenced rather differently by these aspects of motivation.
Therefore it would also seem possible to learn a functional sign language without a positive desire to become deaf on the part of the hearing learner; nevertheless, it has been the case in the past that those who have learned sign language have often been cast in the integrative mould and have had their views devalued by the hearing community because of it.
They are seen as deaf ‘camp-followers’.
The self-esteem of the individual learner of sign language must therefore be particularly strong and will be apparent in his convictions as well as in the ability to exhibit empathy in relation to the other users of the language.
Each of these features appears and re-appears in the literature on the effectiveness of language learning, and they are equally potent factors for sign language learning.
Socio-cultural factors
Much of this area has been introduced by the analysis of social distance; there are, however, other social factors which are of some importance.
The acquisition  of a stereotype by a subgroup of the population usually works to its detriment, and although perhaps preserving a grain of truth in relation to the subgroup's activities, it is also misleading for members of the whole population who use the stereotype.
It may conflict with views discovered by the language learner in his environment and so produce a culture shock which has to be resolved.
The discovery of deaf tutors in a sign language class causes a review of the concept of ‘the deaf’ as disabled, since for the first time the student may be in a learning situation where the person whom he feels he should be helping is actually shown to be more competent than he is.
Particularly noticeable is the discovery that the supposedly communication-handicapped deaf people communicate more effectively than hearing people.
Attitudes can then be shown to be important in the learning of a language, whether signed or spoken.
The fact that deafness is an emotive area of practice anyway tends to heighten these factors and can determine the eventual success of the learner.
How we seek to describe these attitudinal variables has always been a problem, and how they can be easily harnessed to the task of language learning has still to be adequately determined.
Equally difficult to quantify are the variables of age and experience, although they are expected to play an important role in language learning.
Age factors
Intuitively, one feels that older learners are at a disadvantage in relation to learning a language, but research shows the situation to be rather more complex.
Age effects were discovered by Oyama (1976) in studying Italian learners of English, at least in terms of their acquisition of the phonetic aspects of the language.
It has been suggested, however, that there are different strategies at work for adults and children, the former requiring more formal language learning situations and perhaps  benefiting more from a grammatical approach (Krashen and Seliger, 1975).
It has also been found that age effects can be explained in terms of speed of learning of the language, which is much faster the younger the learner.
Snow and Hofnagel-Höhle (1978) showed the advantage of adolescent learners over adults for learners of Dutch, but add that older learners have an advantage over the very young in learning rule-governed aspects of the language, though their teenage group were superior to the adults.
Like Oyama, they found little difference in the acquisition of the phonetic systems of Dutch.
Fathman (1975) also uses speed of learning as the explanatory variable for younger people learning more effectively, but she points out that the order of acquisition in second language learning does not change with age.
We have, therefore, some agreement on the existence of effects which seem  linked to age of the learner; however, there may be a number of confounding factors.
Krashen (1981) suggested length of residence (LOR) in the second language environment and ‘reported use’ of the second language as key variables.
It seems that younger people are likely to have more contact with the community (to go on exchanges, visits etc.) and have more use of the language (at school, with peers of the second language community).
The main effects reported, however, are on children.
Walberg, Hose and Raster (1978) showed the significant relationship between LOR and proficiency in English with Japanese children in the USA, but also point out that the rate of learning slows down very quickly over time, so that in the first two months the child learns as much as he will in the next five months, the next year and so on.
However, Krashen (1981) maintains that LOR ‘works’ to the extent that it also indicates greater interaction with the community.
Attempts to measure interaction level are usually based on self-report studies, which do have methodological problems.
Nevertheless, Schumann (1977) found a relation between proficiency in English and subjects' report of the amount of contact with English in work time.
For BSL and its community we can see that both of these opportunities may be less available to hearing learners.
Bearing these two variables in mind, the argument for age effects becomes less clear and Krashen (1981) maintains that age itself may not be an effective predictor of attainment or even rate of attainment.
In a review of the field, Krashen, Long and Scarcella (1979) can conclude:(1) adults are faster than children through the early stages of second language development (if time and exposure are controlled);(2) older children are faster than younger children; and (3) those who have natural exposure to the second language in childhood reach a higher level of proficiency than those who begin as adults.
There are great difficulties in measurement of proficiency but adults probably acquire more, faster because of their already developed knowledge and because the level of their communication is higher and more complex.
In BSL these points are equally applicable and levels of skill and prediction of skill can be discussed in these terms.
Kyle et al.(1981) report a national study in the UK on the levels of performance of those using BSL.
The results indicate problems for hearing people in using sign language effectively which might be traced directly to the problems of the language learning situation.
Using a series of specially devised tests of production and comprehension it was possible to identify a pattern of sign language learning among social workers for the deaf in the UK which is different from that for second language learning.
Not only does BSL learning apparently take much longer (‘beginners’ were people with up to three years' experience) but only the beginner group showed the normal pattern of  understanding being better than production.
Even when age of acquisition and age at time of test are controlled there is a consistent gap in favour of production over comprehension of BSL for groups of signers with average six, 12 and 20 years' experience (Kyle, Woll and Llewellyn-Jones, 1981).
In fact there is little change in understanding of BSL across these groups.
More experienced people do not seem to understand more of BSL.
Measuring language performance in this way, of course, misses much of the qualitative essence of language use.
The appropriateness of grammatical construct and the use of idiom are not adequately illustrated.
In reality, from the study of the videotapes made of the language performance of most of the 150 people who took part, the language level actually being achieved did not bear a great similarity to the BSL as used by deaf people.
Even where the signers had deaf parents there was still a very strong influence of English on the syntax of the signing.
Use of idiom was almost totally lacking in the samples of signing collected, partly because these were fixed tasks of description of pictures rather than conversational (though even in conversations which we recorded with interpreters the signing was dominated by English), and partly because there is a feeling that BSL in its deaf form is somehow inappropriate for the formality of a test situation.
The question of whether those taking part actually had sufficient command of BSL to make a conscious decision to withhold that form of signing is rather debatable, since virtually all those involved had difficulty with the deaf people's signing which they had to translate.
We therefore have a situation where language acquisition seems to be geared towards an interlanguage rather than deaf people's BSL.
The degree to which this has occurred can be seen from the analysis of different signers presented in Kyle, Woll and Llewellyn-Jones (1981).
Transcripts of hearing people and deaf people signing a sequence of three cartoon pictures were compared in a number of ways.
Three signers were presented as illustrations: a deaf man (signer 1), a hearing man with eight years' experience (signer 2) and a hearing man whose parents were deaf and who learned BSL as a first language (signer 3).
The first possibility in relation to BSL — English mixtures is to use speech in conjunction with sign.
It appeared that signer 2 very clearly used speech throughout, one presumes to make lip-reading easier for a deaf audience.
However, the penalty was that English grammar dominated his description and there were, therefore, long sequences where signing stopped and only English was produced, since there were no direct sign-for-word translations.
Signers 1 and 3 also used lip-patterns in conjunction with English, but these supported the signing and never appeared on their own.
The use of English forms was also clear in a notable example where the English expression to dress-up forced signer 2 to make the sign DRESS with an  upward movement (which means to UNDRESS in BSL) when the BSL sign properly carries a downward movement.
In practice, these features were repeated frequently throughout our samples.
Two further indicators of BSL use are simultaneity and mime, or direct visual representation.
Again, signer 2 differed notably from the others in his inability to use two lexical items simultaneously.
In miming aspects of the events, signer 2 also used inappropriate mime which only partly visually represented the actual event.
If comparisons are made by deaf people of these signers, they comprehend and value the signers in the order 1, 3 and 2.
It appears that deaf people using BSL, sign in a more recognisably BSL way than do hearing people who have acquired BSL as children; for those who have to learn BSL as adults (like signer 2) their target seems to be a form of BSL greatly influenced by English.
The grammar of English is carried over into the signing and presumably evaluation of the adequacy of BSL is based on the ease with which it can be fitted to this English format.
It is commonly accepted that educated deaf people prefer hearing people to use English-based sign and Woodward (1973) has suggested that the normal form of communication between deaf and hearing people is pidgin Sign English.
The truth of the first point needs to be examined in terms of the degree to which comprehension takes place, and the inevitability of the second needs to be questioned.
The learning of English-based sign places severe limitations on the learner's understanding of BSL as used by deaf people and forms a barrier to understanding of the deaf community and its culture.
Kyle, Woll and Llewellyn-Jones (1981) attribute most of these difficulties to the problem of courses in BSL which are currently provided in the UK, as tending to strengthen the Englishness of sign use among hearing people.
Schumann's (1977) social distance model does fit the data reported very well, where hearing people's strong motivation to ‘learn in order to help’ low status deaf people makes the acceptance of BSL as a language more difficult.
To what extent the level of knowledge of BSL is acceptable, given the needs of deaf people for interpreters and social workers, cannot really be estimated from the data, which is relative to the types of measurement used.
Certainly it would appear that foreign language learners who would have six years' experience at school followed by three years' university training plus a year in the country of that language, are treating the learning task much more seriously than sign language learners.
Not surprisingly, therefore, they appear to be reaching a higher level of competence.
We have tried out these tasks with users of French and do find much greater levels of competence.
If one is prepared to act on this view of the need for more extensive training and greater access to deaf people, there are still other series of factors concerning language learning to be accounted for.
Kyle   et al.(1981) describe a further series of measures which relate to the factors presented above but which allow us to consider some basis for the prediction of sign language skills.
Predicting skills in BSL
Age of first contact with BSL
In the total sample of those working with deaf people described in Kyle, Woll and Llewellyn-Jones (1981) only 23 per cent were native users of sign language (i.e. had deaf parents).
For all the others there had to be a process of acquiring sign after the age of 15 years, with the average being somewhere in the mid-20s.
In fact this seems to be the critical variable, and statistical analysis of sign measures proves significant.
Fig. 9.1 illustrates the nature of the relationship.
Those people who learned before the age of 20 years, the majority of whom had deaf parents (some had deaf siblings), are able to translate effectively just under 60 per cent of the information on average.
Unfortunately there is a confounding factor of experience in this: the earlier sign has been learned the more experience one is likely to have had in using it by the time the sign language testing occurs.
When these were matched and pairs of hearing signers  were established, only eight pairs were found in our data where people acquiring sign before the age of 25 years had similar experience to those who had acquired it after the age of 30 years.
Nevertheless, the difference between these proved to be significant in favour of better translation skills in those learning before the age of 25 years.
Needless to say, the results must be interpreted with care.
Although there is evidence that those who choose to learn sign language after the age of 30 years will not reach the level of understanding of those who begin earlier; and although there is a declining performance as the age of sign language learning increases, it does not mean that all those over the age of 30 years cannot learn BSL, nor that they will be unable to communicate.
Each of the factors of length of residence or contact, and amount of use of the second language, must be taken into account.
The effect can also be interpreted as evidence that training courses in sign language for those over the age of 30 must be structured very differently, and there is no doubt that we need to consider the learning requirements of this group much more carefully.
We can see that age of acquisition may be taken as a predictive factor for current sign language training but that it is not a pure, uncontaminated variable.
Experience tends to improve performance but has a lessening effect as the age of acquisition increases.
However, the second language literature has been able to go beyond this simple finding and attributes the age effect to the various underlying variables of motivation, as well as degree of contact.
The problem with adult learners is that they already have strategies for grammatical analysis and can efficiently use context in communication.
This makes their speed of acquisition initially faster, but with the lack of knowledge of BSL grammar and rules the only strategy available is to impose English rules.
It is this aspect which then makes them more likely to produce the interlanguage of signs in English order.
There is, therefore, a need to re-examine training methods for those who come into contact with deaf people later in their careers, since it would appear that the methods currently available underestimate the complexity of this second language learning situation.
Cognitive factors
There is a general acceptance among educators that intellectual ability is a critical factor in learning in virtually all educational settings.
More recently, intelligence as a predictor has been replaced by the variety of cognitive processes available to an individual.
These processes turn out to be as widely varying as the tasks upon which they are to be used, and we are therefore only in the very beginning stages of understanding how they combine to predict emerging skills.
In second language learning situations factors such as reasoning ability are often semi-controlled by having those with lower levels of ability ‘streamed out’.
So lower ability children in British schools may be given less language training.
More recently, however, a move towards providing language experience (rather than language instruction) for poorer ability groups has indicated that levels of proficiency in language use may be reached by a wide range of people.
It is relevant here to ask the simple question of how processes commonly related to intelligence are predictors of sign language learning.
A measure of perceptual reasoning was used in the battery of measures given to the hearing signers in the study (Kyle et al.1981).
This consisted of two sub-tests of Cattell's Culture Fair Test (Cattell, 1973), which is highly loaded on ‘g’, the core factor of intelligence.
They are non-verbal tests, though there are verbal instructions which had to be translated into sign for deaf participants.
The test is very brief and the scores are additive.
One also expects direct perceptual skills to be a feature of sign learning.
Mills and Jordan (1980) examined timing sensitivity as a predictor of ASL learning, and discovered positive correlations between ability to discriminate patterns differing only in timing of onset of components of the pattern, and grade scores for sign language proficiency.
Although significant, their correlations were low, and the relationships accounted for a small proportion of the variance in the sign language performance scores.
For our purposes a new measure was developed, based on the principles of the ACER Speed and Accuracy Test (Australian Council for Educational Research, 1962) designed to predict office skills and visual awareness.
items consisted of two pairs of hands which were either similarly or differently orientated, and pairs of faces which had either the same expression or a different one.
Participants under time pressure had to designate as many pairs as they could as either the same or different.
Two measures of language sensitivity were also used in the battery of tests.
These consisted of measures of language knowledge elicited in limited time.
They were developed by Gerver (personal communication) and his tests were slightly adapted for our purposes, but consisted of a tape-recorded message which had errors inserted in the story (error detection) or had whole words omitted (cloze).
The errors were either semantic, where a similar part of speech had been inserted; or grammatical, where the wrong verb tense was used; or vocabulary, where a nonsense word had been inserted.
Participants listened to the story read at an even pace of around 120 words per minute and had to write down all the errors they could detect as they heard them or insert the missing word.
In cloze they were scored for the grammatical accuracy as well as the semantic correctness of their suggestions.
Gerver (1980, personal  communication) had reported a high correlation between these measures and foreign language interpreting abilities, and it appeared to make little difference which language the text was presented in.
Our passages were audio-recordings in English.
A final measure dealt with the area of cognitive style.
The concept of field dependence was first discussed by Witkin (1950) and has since been discovered to be a relatively stable trait of the individual.
Field independence allows the individual to separate the parts of an item or a situation from the whole, and implies an analytic approach to problems; however, field dependence emphasises the whole object and allows one to deal efficiently with material which does not require decomposition.
There are, therefore, both positive and negative aspects to the concept, and it is not simply another way of describing intelligence.
There is a wide-ranging literature on the subject.
There is a relation to age, with younger and very old people being more field-dependent but with those over 24 being in a period of relative stability, having reached greater field independence.
Field independence also relates to one's sense of separate identity, or developed sense of one's own feelings and needs.
Less developed field dependence often goes with greater need to rely on other people for evaluation of one's own attitudes.
More field-dependent people are literally more attentive to people's faces and remember them better (Crutchfield, Woodworth and Albrecht, 1958).
More field-dependent people are likely to be open to influence from those in a position of authority (Bell, 1955).
The embedded figures test, which highlights these factors, has been used in a wide range of cross-cultural situations to support research work, and broadly differentiates types of perception arising within different cultures.
It consists of outlining hidden geometric shapes in larger complex figures.
In summary, those who are primarily field-independent tend to be more self-confident and are associated with a freer, more independent democratic culture.
Field dependence tends to arise in those who are more socialised and group-orientated in a society which emphasises order; these people tend to have stronger perceptions and feelings for others.
The prediction in relation to language learning is to some extent confusing.
Brown (1980) suggests that field dependence should correlate highly with natural language experience approaches to language instruction, while context independence should relate to more rigorous classroom-orientated learning.
Naiman, Frohlich and Stern (1975) support this conclusion in showing significant positive correlations between field independence and school children's French learning.
Also field independence increases with age, so that one would tend to predict better learning with grammatical approaches with older people.
Krashen's (1978)‘monitor’ model of language learning tends to reinforce this.
In examining the results of these cognitive tests there are few systematic differences emerging.
Deaf people perform rather less well in nearly all of these measures.
This is particularly the case for reasoning, where the group of deaf people performs much less well than hearing groups.
Although the test is claimed to be culture-fair and the instructions were presented in BSL, performance was lower, giving weight to the view of Kyle, Woll and Llewellyn-Jones (1981) that deaf people are subject to a test effect which generally depresses scores.
in addition, and perhaps against the prediction, deaf people tend to be much more field-dependent.
One might interpret this in relation to stronger group orientation, as expected of those who are field-dependent, nevertheless the task might be expected to be easier for those who are more used to visual processing.
This did not appear to be the case.
The cognitive factors which are significantly related to sign performance in hearing signers are reasoning, cloze and embedded figures, with the last one being most highly related to sign-to-English translation.
The more one's reasoning abilities are developed the better one's anticipation of the syntax and vocabulary of English, and the greater the field independence then the better the performance in sign language tasks.
This latter effect is the more strikingly consistent when age effects are taken out.
Nevertheless, when combined analysis is carried out it is age of acquisition which has the larger effect than any of the cognitive variables.
In summary, there is positive predictive value in tests of cognitive abilities in relation to sign language proficiency, but the effects are not as consistent as one might hope and they are outweighed in magnitude by the age at which sign language is learned.
Attitude variables
In view of the lengthy discussions on the nature of the deaf community, one might expect language attitude effects in learning sign language.
Burstall (1975) reports that primary and secondary school attitudes towards learning French are strongly related to success in the language.
However, McDonough (1981) points out that it is quite possible to consider the favourable attitude to the language simply as a result of success in its use.
Oller, Baca and Vigil (1977) support the view that positive attitude towards the target language group is a predictor of language learning.
However, there are specific problems in measuring language attitudes, particularly with rating scales.
Attitudes towards deafness are notoriously difficult to deal with.
Schroedel and Schiff (1972) claim that deaf respondents were significantly more negative in attitude towards deafness than hearing respondents.
Deaf people also imagined hearing people to hold more negative attitudes than they actually did.
This is mirrored in a survey by Bunting (1981) in the UK, where it appears that the general public hold some realistic and generally favourable views of deaf people even though there is no understanding of the language needs of pre-lingually deaf people.
Kyle et al.(1981) were unable to show any consistent pattern of attitude to the deaf community as related to sign proficiency.
Generally speaking, more positive attitudes to rated concepts of the deaf community tend to go with better skills, but these relations would not meet statistical criteria.
In effect it implies a very complex situation in relation to attitudes and one which cannot be resolved here.
Whether attitudes towards BSL can be altered or not, those who come into work with deaf people will have to approach the task of learning BSL and it may be that the weight of sign learning must rely on motivation to the task and the cognitive and age factors.
Learning BSL: some theoretical considerations
The more the study of BSL has progressed, the more it has been seen to fit general language principles.
The more exploration of BSL learning that has taken place, the more relevant second language learning research becomes.
The major difference which appears from the beginning is that sign language does not require voice and therefore allows the possibility of a mixing of two language codes, something which rarely occurs in the spoken situation.
(Certain aspects of borrowing in spoken languages imply a mixing of codes.)
The language form which becomes the target for many acquirers of BSL is therefore not BSL itself but rather some pidgin sign form incorporating a great deal of English syntax.
We believe this arises out of a lack of knowledge of the nature of BSL, together with the factors described as social and psychological distance which, when producing significant effects, predict the creation of some pidgin form.
The pidgin form used (and it can exist with or without fixed English syntactic markers) has naturally given way in the USA and Scandinavia to a greater interest and access to the sign language as used by deaf people.
in effect, in the classroom teachers find their signing intelligible to the deaf children but they cannot understand the sign language used by those same children among themselves.
Our interest in exploring BSL learning is justified by this trend, which is beginning to be apparent in the UK also.
in any case, the task of learning any form of the language seems to be governed by the same variables as demonstrated in the preceding section.
Krashen (1981) has offered a set of postulates concerning second language acquisition which forms a coherent model of this language task and it is useful to consider how BSL satisfies the series of five hypotheses which Krashen sets out:
The acquisition — learning distinction This point concerns the difference between language acquisition (the process whereby children learn their first language, which is usually subconscious and constitutes ‘picking-up’ the language naturally) and language learning (conscious knowledge of the rules of the language).
The hypothesis is that adults have available both ways of developing competence in a second language.
An earlier view of second language knowledge was that only children could acquire while adults learned , but Krashen maintains that adults do not lose their language acquisition device and make considerable use of natural learning of the second language.
For BSL, evidence on the distinction has been difficult to acquire.
in the studies described earlier, those who were most proficient in BSL were those learning it as a first language (albeit with English as another first language).
Of those who have developed BSL skills later in life, few will have had the opportunity of language exposure which would be available for, say, English people learning French in France.
Relatively few have had the chance to ‘acquire’ the language simply through contact with deaf people in their culture and community.
That it must be language acquisition therefore which is taking place is clear, not only because of these simple observations but because of the fact that the rules of BSL have never been researched sufficiently until now for there to be a language learning situation.
Hearing BSL learners cannot use the traditional language learning approaches of dealing with grammar in the written language or phonology in the language laboratory, since there has simply not been enough information available.
One can see, therefore, that the first part of Krashen's hypothesis is supported in BSL learning.
Adults are at least able to acquire, even though this may not be at a sufficiently high level of competence.
The fact that the language acquired in this way often has English grammatical rules added to it, may be indicative of the adult's need to learn as well as acquire.
it is clear that BSL learners need to have more access to both options if BSL competence is to be achieved.
Natural order in acquisition This hypothesis states that the discovered natural order of development of first language competence also applies to second language learning.
One would expect this to occur in natural acquisition situations, such that adults' and children's interaction with others can be compared.
The hypothesis primarily deals with errors in syntactic rule formation rather than vocabulary and is illustrated in such comparisons as:
How he can be a doctor?
(Kilma and Bellugi, 1966; learning first language)
and
What she is doing?
(Ravem, 1974; child learning second language)
Unfortunately there is no evidence to offer from BSL since the natural order of emergence of BSL has not been studied at all.
Preliminary work on ASL has  begun (Bonvillian, Orlansky and Norvak, 1983; Scroggs, 1983) but these still mainly deal with the surprising findings of earlier development of signed versus spoken language (see chapter 4).
If natural order is an important feature of second language acquisition, then it is a pressing problem for those interested in BSL.
The monitor hypothesis This is a development of the first hypothesis and suggests that acquisition processes create the utterances in a second language (producing fluency), but learning monitors this production.
The ‘monitor’ corrects or edits the output of the second language user.
In order to use the monitor however, the speaker must have sufficient time to mentally prepare the utterance (usually this means it cannot be used in conversation), must be concentrating on the form of the message itself and must have complete knowledge of the rule, or rules, which have to be brought into use.
Evidence for the distinction comes from the differences in error pattern between situations where these conditions are met (e.g. written grammar tests) and those where they are not.
Krashen maintains that in practice it is difficult to encourage monitor use, but that it has the advantage of being able to draw consciously on language competence to produce utterances at levels which have not yet been acquired.
This is a very interesting proposal for BSL, not because we can see the conscious efforts of BSL learners to match their signing to BSL grammar but rather because there is a matching to English grammar.
What this means is that the rule-based competence which the monitor offers to the BSL learner is the already established grammatical knowledge of English.
The learner is taking BSL signs, acquired through contact with users, and monitoring the output to English syntax.
This is most noticeably the case when we examine education (chapter 12), and it is probably this situation which comes closest to a monitor situation.
The teacher with a prepared lesson and a captive audience which may not interrupt has a much greater opportunity to actively edit the signing she is producing.
In addition, of course , the goal of deaf education is the production of English literacy and communication, so that the teacher can legitimately impose rules of English on the form of signing.
it is therefore very close to a situation where the learned competence is that of a first language (in the absence of rule-based knowledge of the second language) monitoring the creation of a message in the second language from signs which have been acquired.
it is rather difficult to know whether this is support for Krashen's proposal or not, but it certainly implies the separation of the process of meaning construction from the determination of final output form.
This certainly occurs in a great deal of BSL use.
The input hypothesis This is probably the core of the whole theory.
The  hypothesis suggests that if natural order is valid, then in order to move from one stage to the next highest stage the acquirer must understand input from this next highest stage, where understanding is concerned with meaning and the form of the message.
This is a particularly powerful idea and one which has not really been considered in BSL, though it has begun to be practised in BSL teaching (see appendix 2).
The input hypothesis is fairly revolutionary in second language terms generally.
Normally one expects the individual to acquire a structure then practise it until he achieves competence in it in communication; but the input hypothesis says the opposite is true: in order to acquire structure, we first need to deal with meaning.
Krashen adds a further two parts to the hypothesis.
Firstly, input at the next highest level need not only contain information at that level, since if the user understands the message then automatically the next stage is provided.
The implication for teaching is that texts or situations should not be devised where only the next level of ‘difficulty’ is provided, since these are not necessary.
Secondly, production of the language does not need to be taught: it emerges itself in time, through the understanding.
Krashen presents a range of evidence supporting this hypothesis from first and second language acquisition work.
in child language understanding always precedes production and, what is most important, the adult dealing with the child constantly modifies her output to be ahead of the structures which the child is producing (Wells, 1981).
in the second language situation the speaker often modifies his output to the perceived competence of the acquirer, as the hypothesis predicts would be effective.
In addition, second language acquisition is characterised by a ‘silent period’ where little production is offered by the acquirer despite the obvious development of comprehension.
The existence of this silent period is to be expected in virtually all natural acquisition settings, but in a formal classroom setting the individual may not be allowed to have a silent period.
The adult being taught is asked to produce very early in his development.
Newmark (1966) claims that this causes the learners to fall back on first language rules, i.e. they use the syntax of the first to speak the second.
This seems to be exactly what has happened in most BSL situations — the form of instruction has been formal and production-based, and we have a very strong concentration of skills on the interlanguage of English syntax coupled to BSL signs.
As was pointed out earlier, hearing users of BSL are not progressing to full competence in the language and are very likely to use English syntax for sign-based messages.
Krashen explains why:
use of L1 (first language) rules is hypothesised to be the result of the first language knowledge when a second language We is needed in production but is not available.
It  may temporarily enhance production but may not be real progress in the second language.
The real cure for ‘interference’ according to Newmark is not drill at the points of contrast between the two languages Newmark and Riebei, 1968).
Drill will, at best, produce learning and as we have seen, this is only a short term cure.
The real cure ‘is simply the cure of ignorance’(Newmark. 1966); real language acquisition.
This can happen only when they acquirer obtains comprehensible input.
(1981: 29)
The affective filter hypothesis .
This concerns the factors of affect and attitude already described in some detail, and we have explored how negative affect will tend to produce less contact with users of the language.
However, Dulay and Burt's (1977) concept of the filter goes further.
Those whose attitudes are negative and who consequently will have a powerful filter, even when they understand a message in the second language, will not allow it to reach that part of the brain responsible for language acquisition.
In Krashen's terms, the filter exists outside the acquisition process so that even those with a great deal of contact with users and a considerable amount of comprehensible input may never reach competence or fluency.
Selniker (1972) describes the individual as ‘fossilizing’.
Kyle, Woll and Llewellyn-Jones (1981) describe BSL users with over 20 years' experience of work with deaf people who still describe BSL as a ‘secret language’ among the deaf, or ‘their language’, or ‘low verbal language’.
It is also clear from the results that the lack of acquisition arises from this over-protective filter emerging in negative attitudes towards deaf people.
Krashen's (1981) views are particularly relevant to the study of BSL, not only because they lay the base for a fundamental re-examination of teaching methods (see appendix 2) but because they allow us to understand more clearly the language learning problems of BSL acquirers.
These problems are by no means unique to language in a signed mode and, as before, what appears to be true of spoken languages also can be shown to occur in BSL,
Conclusions
From this very brief review of second language learning, it can be seen that BSL acquirers have a great deal in common with those struggling with any spoken language.
What makes BSL different are the emotional and social factors attached to deafness and the more obvious opportunity to mix both English and BSL in production since they, superficially at least, occupy different media.
While age has emerged as a predictor of the current linguistic achievement in BSL, it need not always be the case if BSL teachers are able to learn from the second language literature.
A greater awareness of the possibilities for adults in both acquiring and learning should allow a better exploitation of their obvious motivation to achieve fluency in BSL.
The question of which form of BSL is to be attained, whether it is an English-based form or a deaf form, remains to be established.
It seems likely that any hearing user must understand both and certainly needs BSL in order to adequately construct visually appropriate sequences in a signed English form.
But there may be a major question as to which form is suitable on which occasion.
Chapter 13 looks at the requirements of educators in using signed messages and argues that even in a teaching environment where English has to be reinforced the teacher requires access to both BSL and signed English.
On this basis we may stress the need to revise language teaching methods to come more in line with second language acquisition.
Krashen's views on language acquisition are very helpful in characterising BSL and its users but, conversely, BSL is an appropriate test case for the input hypothesis and the monitor.
Both seem to apply, but not quite in the way envisaged by the theory.
Even this preliminary comparison, therefore, allows us to predict a fruitful interchange of ideas among those interested in second language acquisition and those involved in the training in BSL skills.
THE PSYCHOLOGY OF SIGN
Much of our previous discussion has concerned the outward features of BSL, its linguistic structure as seen in communication and the measurement of skill in the language.
This has proved to be a very proper framework for the analysis of communication.
Nevertheless, the internal processes which underlie the way we perceive and think must be of relevance to an understanding of the way sign language works for deaf people.
in this type of study the psychologist has tended to identify difference in a way which has implied deviance.
Deaf people may be seen as handicapped and failing and our studies can easily be presented in this way.
However, the study of difference has acquired a newer meaning and can now be seen in the light of a test of our theories of development and language, and in a way which does not isolate a particular group under study.
Social perspectives on cognition have come to accept cultural differences not as deficits but as important variation.
In the past a deficit approach has been used to construct developmental theories where the missing parts in the subgroup's culture can be added.
The stages of development were identified:
so that modifications could be introduced in the physical, social or educational environments of these children which would help them achieve at the same level of conceptual development as is found in children from western societies.
(de Lemos , 1974: 380)
The fact that this approach to cultural differences is now largely discounted is a powerful aid to the acceptance of deaf people.
Curran (1980) maintains that experimenters in the West have an implicit ethnography which allows them to share processes and experiences with their subjects.
When this is not the case, as with non-Western cultures (and as it might be with deaf people), then the theories produced may be of limited value.
The evaluation of processes in sign which are presented in this chapter arise in this context, such that results are available to inform our theories of perceiving and remembering as they apply to spoken language.
We have examined these processes in three different areas: perception as far as it can be determined from neurophysiological and laterality studies, remembering in a short-term memory context, and organisation in recall as it occurs in story-telling.
Perceptual processes
Evidence from studies on auditory deprivation
By most reckoning, the study of neurological differences arising from sensory deprivation at birth is a difficult one.
While we have accepted that visual deprivation from birth produces considerable neurological change in animals (e.g. Borges and Berry, 1976, for cats) there is little information on similar studies with auditory deprivation.
It is also true that studies of this kind tend only to highlight differences without revealing the qualitative nature of the differences.
So, although we can show that deprivation produces loss of function on certain tasks, these studies do not indicate how the loss may be combatted, if at all and, from a psychological point of view, they do not give any idea of how this changed processing affects other aspects of function.
As one would predict, the few experiments on auditory deprivation confirm that there may be extensive loss of functioning.
Kyle (1978, 1980a) reviews some of the evidence from the study of animals deprived of sound at birth.
Batkin et al.(1970) show that for rats there are problems of perception of sound at a later stage if temporary deprivation occurs at birth.
Stein and Shuckman (1973), in a study of direct cortical stimulation after deprivation, demonstrate poorer response in the auditory cortex after deprivation of sound.
Ruben and Rapin (1980), in a thorough review of the literature, show that development of auditory perception is crucially dependent on early stimulation.
They draw implications in the world of a deaf child's hearing through the early fitting of a hearing aid and point out that even under these advantageous circumstances a deaf child's functional hearing may not be comparable to that of hearing children at the same sound levels.
Loss of auditory stimulation at birth or shortly after is therefore not simply a loss of some hearing experience, but may create a loss of potential auditory processing at a later stage.
The language choices of deaf children may be limited (Conrad, 1980) and this limitation may make the acquisition of spoken language extremely difficult.
Even after the appropriate hearing experience is restored at the periphery, even though sound stimulation can be heard through the aid, the higher processes for dealing with sound may no longer be available.
it is a tempting leap to suggest that sign language may be the natural alternative development when auditory deprivation occurs at birth, but it is clear that objective evidence on this is not easily obtained.
Evidence from hemispheric studies
Since the development of neurophysiology, the search for localisation of function within the brain has been intense.
The fact that the cortex consists of two hemispheres which may be doing different things has particularly excited writers in recent years.
Split-brain studies have science fiction overtones which have led to their widespread publicity in more recent times.
However, the interest of neurophysiologists has a considerably longer history.
The idea that language might be localised came from the studies of Broca (1861), who was the first to observe that aphasia arises as a result of unilateral left hemisphere lesion while no similar effect occurred with right hemisphere lesions.
Wemicke (1874) confirmed this and showed that auditory comprehension was linked to the left hemisphere.
Although there has been intermittent interest in this area since that time, it is only more recently that there have been suitable techniques for more effective study.
Direct cortical stimulation (Penfield and Roberts, 1959) and intra-carotid injection of sodium amytal (Milner, Branch and Rasmussen, 1964) confirmed that for right-handed people language function was primarily controlled by the left hemisphere.
There are difficulties in these techniques and it has proved more effective most of the time to use techniques which involve perception rather than direct interference with brain processes.
In this way normal healthy people may be tested without inducing any damage in their brain.
The principal techniques are dichotic listening tasks and visual hemifield identification tasks.
The latter technique allows the presentation of signed stimuli since it involves brief visual presentations of material.
Because of the nature of connections between eye and brain, information falling on one side of the retina is transmitted firstly to one hemisphere.
If the position in space of an object is varied, its image will fall on a predetermined part of the retina which transmits to right or left hemisphere.
Information in the right visual field (RVF) goes firstly to the left hemisphere.
However there are a number of important controlling factors: firstly, the subject fixates centrally (usually he has to report a digit which is presented in order to confirm this central fixation); secondly, the stimulus is exposed for less than 200 milliseconds to avoid eye movement; thirdly, the visual angle of the stimuli from the fixation point should be between 2.5° and 5° (otherwise, confounding effects occur).
The use of these parameters in this type of study confirms the left hemisphere or right visual field advantage (RVFA) for verbal materials and the right hemisphere or left visual field advantage (LVFA) for visual materials (Cohen, 1977).
Cohen also suggests that the reason for this dominance is that the left  hemisphere is specially suited to serial processing while the right controls spatial processing.
Sasanuma et al.(1977) confirm this idea in a study of perception of the two scripts of Japanese:Kana perception (this script is phonetic) shows a left hemisphere advantage (LHA) while Kaji (non-phonetic) has a right hemisphere advantage (RHA).
This makes, therefore, for the very tempting prediction that sign language perception should show a RHA, since it appears to be spatially organised.
Results have not always been clear.
It is normally found that although hearing people report more words presented to the RVF rather than to the LVF, deaf people show minimal asymmetry for both English words and drawings of signs (Phippard, 1977).
Kelly and Tomlinson-Keasey (1977), Scholes and Fischler (1979) and Ross, Pergament and Anisfeld (1979) all showed slight LVF advantage for English words among deaf subjects, but these results did not reach significance (although they were significant for hearing people as a RVFA).
Other studies indicate a RVFA for both deaf and hearing people for English words but with hearing people showing a stronger effect (McKeever et al., 1976; Manning et al., 1977; Poizner, Battison and Lane, 1979).
Unfortunately, there were differences among these studies in measurement and in the subjects chosen, so direct evaluation is difficult.
Studies involving the perception of statically presented signs, however, tend to produce greater agreement and a general LVFA.
Processing signs has clear right hemisphere involvement (Lubert, 1975; McKeever et al., 1976; Manning et al., 1977; Poizner and Lane, 1978; Poizner, Battison and Lane, 1979).
Discussing these.
Poizner (1979) infers that spatial processing dominates in sign perception even though these lexical items may normally be experienced in temporal sequences, just as in spoken language.
This view may not, however, be generalisable to the more common experience of perceiving moving signs where temporally salient cues are present as well as spatially salient cues.
Poizner, Battison and Lane (1979) included moving signs in their study by simulating movement from combined still frames of strategic points in the moving sign.
This gives an impression of fluent, though probably ‘speeded’, motion since the ‘sign’ must be executed in a stimulus duration less than eye movement latency.
The study has no fixed hypothesis since analysis of the motor sequence of the sign might lead to a LHA while spatial analysis would produce a RHA.
The result showed a slight, statistically insignificant, RHA, which was taken to suggest that sign language processing was more bilateral than spoken language processing.
There is, however, some difficulty in the study in relation to the choice of stimuli and in the fact that only neutral facial expression was used — while it is clear that facial characteristics are important to the holistic perception of the sign.
In relation to the choice of stimuli there are two critical parameters: movement and position.
Moving signs, while using some form of sequence information, can either be temporally redundant (i.e. have position features which are similar at the start and finish of the sign) or be temporally salient (i.e. have position features which are different at the start and the finish of the sign).
These two types are labelled ‘spatial’ and ‘temporal’signs, respectively, in fig. 10.1.
In each case, Tab and Dez remain constant (though secondary Tabs may change) and the movement is simple; but in the one case the movement produces no additional spatial information while in the other the spatial information changes at the end of the sign.
This aspect of moving signs was studied by Evans (1981) in an unpublished short study in Bristol.
Using the normal constraints for visual hemifield studies, four conditions were administered to a small group of eight severely/profoundly deaf native signers (i.e. with deaf parents):
(1)
English high frequency three-letter words printed vertically to prevent scanning, presented 3° from the visual fixation point
(2)
Statically recognisable signs in BSL which were bilaterally symmetric about the midline of the body, presented 4.4° from the central fixation point: these BSL signs included LOVE, READY, FRIEND
(3)
Moving signs where orientation and position were similar at the start and finish of the sign, and again the symmetric principles were observed: examples include PLAY, BICYCLE, CHANGE  
(4)
Moving signs where orientation or position changed between start and finish: examples include TICKET, BOOK, TABLE
The stimuli were constructed as in Poizner, Battison and Lane (1979) by combining four still frames to produce a stimulus duration of 160 milliseconds.
Stimuli were presented either to the right or left of a fixation point which had a digit presentation for the same duration as the sign or word stimuli.
Only trials where the digit was correctly reported were used in analysis, to ensure that the stimulus was presented to the appropriate hemisphere.
Figure 10.1 shows the percentage difference in correct identification of stimuli between visual fields for each condition.
There are significant differences between visual fields for condition (1) for both deaf and hearing controls and for condition (2), but not for conditions (3) and (4).
Examining responses in these last two conditions and accepting responses where, apart from the Dez parameter, the sign was reported correctly, produces the results as shown in fig. 10.2.
Since reports were in sign the lexical identification of individual items often derived from the other parameters.
In this case, condition (4) shows a significant effect, but not condition (3).
Repeating these measurements with laterality coefficients (Marshall, Caplan and Holmes, 1975) to take into account error rates, simply confirms these findings.
The results are in line with the simple prediction that moving signs which have temporal (i.e. locational) salience will be more easily perceived in the RVF.
Deaf people show LHA for words and temporally salient signs, and RHA for statically presented signs.
No asymmetry is present for moving but temporally redundant signs.
These results have to be treated with some caution because of the small numbers of subjects involved (though most studies have this limitation) and the weaker effects for conditions (3) and (4).
However, they are indicative of a feature of sign use which is critical to studies of this sort.
One might claim that the signer is simply being flexible.
Where there is temporal, sequential information of importance, then this will be most effectively dealt with in the left hemisphere, while if the information is static and only spatial then right hemisphere processing may be sufficient.
When both types of information are available and the temporal cues are redundant, then there may be little advantage.
The findings cannot be neatly tied up and one or two loose threads are left, but the likelihood is that general processing of signed sequences proceeds through left hemispheric involvement in a similar way to spoken language.
There are circumstances, however, where the visual — spatial characteristics of signs may work to advantage in the perception and processing of BSL.
This implies a situation similar to that of the perception of Kana and Kanji script in Japanese subjects, and also to that of the perception of English words and pictures.
In both cases hemispheric processing is differentially invoked by the system.
In summary, studies of perception from a neurophysiological base are not conclusive.
Auditory deprivation studies suggest that deaf people will have problems in speech and auditory processing even though auditory experience is reinstated by the use of hearing aids.
This does not mean, however, a corresponding lack of left hemispheric processing (where speech is apparently localised).
Deaf people in some conditions of sign presentation provide evidence of LHA when temporally salient cues are available, but at the same time show the superficially confusing effect of RHA for statically perceived signs.
It is clear that sign language perception will involve both hemispheres.
Short-term memory
Just as the study of perception of the language used by deaf people starts from the discovery of difference, so does the study of memory.
Conrad and Rush (1965) showed that deaf children do not exhibit the same type of coding in memory tasks as do hearing children.
Since that time, researchers have struggled to try to establish just what the form of representation is that is used by deaf children.
Despite the early view that deaf children are poorer in short-term memory tasks than hearing children, Conrad (1979) has shown that if proper controls are exerted deaf children's memory capacity is no different from that of hearing children.
Memory tasks, when they involve serial recall, produce well documented effects in hearing people according to the nature of the stimulus material.
Words presented visually or auditorily are less well recalled when they are similar sounding than when they are different sounding.
Coupled with a series of similar findings in different paradigms, it is taken to mean that hearing people, when processing potentially verbal material, use a code based on speech to represent and retain the items over short periods of time.
Conrad (1971) has shown that this has a developmental pattern and Baddeley (1979) has linked it to the development of reading.
The fact that deaf children do not spontaneously use anything like this speech code and also read poorly reinforces this link.
Since psychologists see this short-term memory code as critical to general thought and functioning, the obvious question arises as to what deaf people do to mediate learning if they do not use a speech code.
A number of studies have suggested that a visual — spatial code might be available (O'Connor and Hermelin, 1973), or that dactylic coding (fingerspelling) may be used (Locke and Locke, 1971; Hoemann, 1978), or that both may occur (Domic, Hagdahl and Hanson, 1973).
The most obvious candidate for the mode of representation is, however, sign coding, and evidence has been presented by Bellugi, Klima and Siple (1975).
In serial recall for signs they demonstrated primacy and recency effects in the recall curves and indicated that substitution errors made by deaf subjects coincided with sign-confusable items.
The study involved the writing down of English glosses for the signs, and the fact that deaf people had poorer recall overall may result from this cross-modal task.
Klima and Bellugi (1979) maintain, however, that similar results are obtained when subjects make their responses in sign.
Kyle (1980b) describes a series of experiments which examine the nature of serial recall in sign.
The results agree with Bellugi's interpretations, though certain striking differences between speech and sign coding begin to emerge.
While serial position effects are found and there is evidence of the use of a visual store in the final items of the list, there is no evidence of ‘articulatory’ enhancement of recall in sign that one gets from overt rehearsal of spoken items.
Hearing people have significantly better recall for items which they vocally repeat at presentation, while deaf people find it more difficult to recall items when they have to overtly repeat the sign when it is presented.
There is no obvious effect of ‘signing aloud’.
Since the effect is confined in hearing people to the final items in recall, it suggests a different form of coding in sign.
At the same time, recall suppression was discovered when deaf subjects were instructed to hold blocks of wood while watching the presentation of items, in a way similar   to suppression experienced by hearing people in tasks where they have a redundant phrase to say aloud at presentation.
These results are therefore not unequivocal in their support for sign coding.
Kyle (1981b) has compared deaf and hearing-bilinguals (i.e. People equally fluent in spoken English and sign) in serial recall tasks, offering presentation in sign or in words, and response in sign or words.
The bilinguals behaved usually as English speakers, and clearly showed all the normal effects of speech coding (homophone/non-homophone differences and overt rehearsal better than silent rehearsal).
Deaf people too tended to prefer recall of words, but showed no effects of overt rehearsal of words.
Fig. 10.3 shows the direct comparison of recall efficiency for two bilingual groups and a deaf group.
Silent serial recall of   similar-sounding words (homophones) or signs sharing the same handshape (non-homophones in English) was used as a base for considering the effect of overt rehearsal either in sign (into sign), or in words (into words).
The study is more filly reported in Kyle et al.(1981) but fig. 10.3 emphasises the lack of effect of sign coding in deaf people.
In the first half of the figure deaf recall effects are no more different from their baseline silent recall than are hearing-bilinguals'.
In the second part, however, hearing people's recall is different.
They have a huge facilitation effect of words overtly rehearsed, although this applies only when the words are not confusable in sound.
Deaf people, too, seem sensitive to the same patterns but do not recall as effectively with overt speech rehearsal.
The results probably show that all subjects an relatively unfamiliar with a serial recall task involving signs and that deaf people tend to be sensitive to the language base of speech coding though they do not have a significant facilitation in overt rehearsal.
This can be seen most easily in fig. 10.4.
It seems that there is the possibility of using a sign code, but it does not express itself among deaf people in this sort of task as clearly as speech coding does in hearing people.
Shand (1982) gives further evidence for an interpretation of short-term memory effects in keeping with sign coding.
Predictably the study is a small-scale one with no indication of whether recall is serial or not.
It also uses English recall, as does Klima and Bellugi's (1979) work, and this must affect the output code, which is seen to be most important in the work outlined above.
Further work on the short-term memory paradigm by Poizner, Bellugi and Tweney (1981) produced confirming results that deaf people do use serial processes in a way similar to hearing people.
They appear to be insensitive to semantic and iconic similarity but differ on decrement in performance with signs which are similar in their physical components (i.e. handshape, movement etc.).
In addition, work on inflected signs (Klima and Bellugi, 1979) suggests effects similar to the abstraction of meaning arising in spoken words.
In this case, however, the results could be interpreted in keeping with an ‘English gloss’ mediation and with the effects of additional length of lists.
Siple, Brewer and Caccamise (1980) present results which point in the same direction.
Deaf signers exhibit effects of language knowledge on the form of coding inferred from results of short-term memory experiments.
In an important study, Shand and Klima (1981) found suffix effects which could be explained in sign coding terms.
These effects occur when sets of items are followed by an item which does not have to be recalled.
This final item reduces the amount of recall because it occupies coding capacity which is normally occupied by the list of items.
The discovery of sign suffix effects is a further part of the jigsaw of sign processing effects.
In trying to summarise these findings, it may be said that linguistic knowledge does appear to be the important variable.
Both deaf and hearing people do interpret stimuli presented for memory in terms of linguistic knowledge of both the task and the stimuli themselves.
This capability never excludes either a sign or a speech coding and with increasing attention results are pointing to a great division in the effects, with deaf people showing greater use of sign-based coding when responses are made in sign.
Thinking and remembering
In this area of interest one normally looks at the classic work of Bartlett (1932) as providing the first base for the complex analysis of how people's thought and language come together in their recall of complex materials.
Bartlett's work was a reaction to the strict controlled experimenting of Ebbinghaus, using nonsense materials, and he set out to establish that the process of learning involved a restructuring on the part of the individual towards a better organisation from his own point of view.
Bartlett was particularly concerned with stories, and in his method of serial reproduction people re-told the same story at varying intervals up to several months after it was presented.
The results supported his view that in recall people make an ‘effort after meaning’ and in so doing they make characteristic changes to their recall.
Characteristically stories became shorter over time, and the individual relies on particular detail around which to structure  the recall.
A ‘schema’ for the story is established and the recall is tailored to this, producing particular transformations of detail and of order in the story.
The individual sees the story in one way, which becomes rationalised over time, and the language used to re-tell the story should reflect the power of the whole process.
Despite the length of time since Bartlett published his work, much of his approach remains unchallenged as a view of the inference process at work in recall.
Bransford and McCarrell (1975) show clearly that without inference comprehension may not take place effectively in textual material, and that particular contexts produce different structures of organisation and comprehension.
in effect, knowledge and thinking about events are determined by the degree to which the events can be organised to fit our personal knowledge and meaning system.
The way in which the process of understanding works can be seen only in the way we produce a response or description of some kind.
Language provides the vehicle for this, and the syntax and content of the recall or response tell us much about the way the individual thinks and remembers.
In saying this, of course, we are simply restating the fundamental question of psycholinguistics and it is not to be expected that there is some answer to the problem of explanation or even a commonly agreed way of investigating the issues involved.
The problem in relation to deaf people is nevertheless a challenging one since not only is their language different in vocabulary and grammar from spoken languages but it is also largely carried out in a different medium.
Accepting even a weak Whorfian view that language used influences thought and representation to some degree, then one might expect great differences in the way that deaf people structure information.
There has been a traditional tendency to expect just that.
Deaf people even after they began to be educated, were thought only to deal with concrete information, to understand only the here-and-now.
BSL was discouraged because people felt that it would chain the deaf person to a concrete, visual mode of thinking.
Even though we should now have reached beyond this view there is still lingering uncertainty as to what the world of experience and thought is when perceived through a language such as BSL.
Myklebust (1964) claimed there was an ‘organismic shift’, at least producing a different experience of events but probably producing different thought.
If blind people's drawings of objects (more or less as they would be touched) reflected their thoughts, then deaf people's writings obviously showed a difference.
Unfortunately, both circumstances particularly highlighted skills which were difficult to acquire or monitor and could hardly act as evidence on the nature of thought.
The fact that blind people can talk makes their world more accessible; the fact that we can now  begin to describe BSL makes it much more likely that we can get an effective picture of how sign language reflects the internal organisation of deaf people.
Evidence on cognition in deaf children has never been clear-cut.
Green and Shepherd (1975) used the Semantic Differential (a technique to examine how meaning is assigned to concepts) to show that deaf children share major dimensions of meaning with hearing children but lack a factor concerning abstract meaning and have an additional one of sensory judgements based on vision and touch.
Furth's (1966) view is that there is an experiential deficit which appears repeatedly in test situations, but this does not coincide with a cognitive deficit.
Meadow's (1980) review is more positive in separating the linguistic academic achievement from cognitive achievement; in the latter, deaf children appear to be very similar to their hearing peers.
In more specific terms of the language, Newport and Bellugi (1978) were able to show that deaf people are not deficient in category structure in ASL because there appear to be no signs for category names such as‘tool’ or ‘furniture’.
ASL compensates by using compound signs such as TABLE/CHAIR etc. for the concept of furniture.
This can also be shown to be true in BSL, indicating that surface features of languages may be used in different ways to express conceptual material but that these differences should not be seen as deficits.
Siple, Fischer and Bellugi (1977) were able to demonstrate that semantic aspects of ASL signs are stored (for recognition purposes) similarly to lexical items in the English language.
This simply means that meaning shared by words or signs allows them to be located close together in the system which allows them to be identified internally.
It is possible to see from these studies that differences between deaf people and hearing people are small when the language differences are taken into account.
However, nearly all the studies deal with the structure of the system of storing meaning or of the language itself and not with the dynamic processes of thinking and remembering.
Story material is unfortunately very difficult to deal with, and recent work tackles only simple linear structures in the story.
Mandler and Johnson (1977) maintain that such a linear sequence (i.e. ‘he did this, then he went there, then this happened’ etc.) is an ideal structure and the more a story conforms to this the better will be the recall.
They also make a specific suggestion that causally connected episodes will be better recalled than temporally connected episodes.
Both of these are major considerations in comparing deaf and hearing recall; unfortunately they are not so easily realised when stimulus material is non-verbal.
Chafe (1977) too has examined the problem of explaining people's understanding and subsequent recall of stories or events.
His stimulus material was a  film and he particularly noted the expression of parenthetic information (asides, or personal expression of feeling) in the recall of such events (something which does not appear in recall of verbally presented stories).
In describing his principles for applying schema to the understanding of events he makes a number of points of relevance here.
Firstly, that in dealing with experience the individual breaks it into parts, or chunks and sub-chunks.
These are still only ideas and it is at a later stage that they become language.
However, the language units which do arise are ‘propositions’, and central to each of these is a verb, attached to which is an agent and object.
Secondly, in determining the language units to be used some form of categorisation takes place so that we decide whether to call the agent Fred', or ‘the fat boy’, or ‘Paul's son’ or ‘he’.
Chafe (1977) maintains that the categorisation arises as a result of the experience itself, the needs of the discourse, and especially the centrality of the word to be used as indicative of the category.
This last part corresponds to Rosch's (1973) idea of prototypes in concepts, where certain words are more typical of the concept.
However, the major point here for us is that if the chosen word is central to the category meaning which is to be conveyed then it will be produced without modification.
Where the needs of discourse or the story require more specific information then a modifier is used: ‘the boy’ becomes ‘the small fat boy’or ‘he obtains the ticket’becomes ‘he secretly obtains the ticket’.
While English tends to modify by use of adjectives or adverbs, BSL tends to use inflection especially in relation to the verb and it is this which makes its story formation rather different.
Thirdly, in re-telling a story there is an element of personal feeling to be injected, a re-living of the original experience.
This is mental imagery, though not only visual, and it leads to and encourages a reconstruction of events and a process of creativity.
There are very large individual differences in this and it can affect each of the stages so far mentioned.
This brings Chafe's view of the processing closer to that of Bartlett, where recall is based on the production of particularly salient features of the original and the reconstruction of other features around these.
This comes clearly into focus with a realisation that the differences in recall at different times by the same person are to be understood through this creativity process.
Chafe (1977:244) criticises the typical psycholinguistic tree structures which assign agents and roles to the words used in the recall as being ‘able to capture only certain decisions that were made during certain particular verbalisations.
They show not what was known about the event, but only some aspects of how it was talked about’.
Chafe's view is that the event is held in some abstract form which allows the recreation of sub-chunks and propositions on the basis of the needs of the story situation at that time.
We do, therefore, have a framework for beginning to examine the recall by deaf people in BSL and for making meaningful comparisons with English recall.
While story grammars seem ideal for working with simple English written stories they have problems where the surface structure (particularly verb tenses) do not correspond to the ideal structure as set out in Mandler and Johnson's (1977) approach, or where in fact there is no verbal structure (as in the silent film, to be discussed).
Nevertheless, there is a specific prediction to be examined and that is whether causally connected episodes are better recalled than temporally connected episodes.
Chafe's (1977) approach offers potentially more for the study of recall.
He understands events as wholes broken into chunks for recall and created as propositions by identification of central aspects, most closely corresponding to the verb in an utterance.
Critical is the view that the event is stored and that the particular realisation of it in linguistic form is variable and does not depend on stored information of agent, recipient and so on.
Kyle (1982, 1983) has reported a study of recall in BSL and English by deaf, hearing and bilingual subjects.
The stimulus material was a short silent comedy film made by Mack Sennet around 1925.
The story concerns the misdemeanours of a husband when he goes dancing with another woman when he is supposed to be at a boxing match.
Transcriptions 1 and 2, in BSL glosses and English, indicate the story content.
In their recall task the subjects were asked to watch the silent film, and then a deaf or hearing person was introduced who had not seen the film.
They were then asked to recall the story they had just seen in either sign (deaf and bilinguals) or in speech (hearing people).
Approximately one hour later, they were brought back to the same room and asked to retell the story again.
Transcribed stories in English and in glosses for BSL were analysed with a simple propositional analysis based on the work of Kintsch and Keenan (1973).
in practice, propositions occurred in English most commonly as clauses, for example:
…they recognised his name….(1 proposition)
or
…
Perhaps he hopes/they would have gone to bed (2 propositions)
In BSL, propositions existed where translations into English syntax, given the non-manual characteristics and contextual meaning, would produce a proposition as above.
These included examples such as:
POSTMAN GAVE WIFE ENJOYED HIMSELF DANCE
In addition there are fifteen main visual events in the story, and they are interwoven both in time and cause.
The story occurs in a temporally accurate sequence so that there are quick changes of scene, i.e. ‘meanwhile back at the ranch’, but no flash-backs or alterations of the temporal sequence.
We are therefore interested in two aspects here, the temporal order in recall and the propositional content and structure in BSL as opposed to English.
Temporal order
If Bartlett's (1932) original view is correct we ought to expect changes in the pattern of recall of events.
One would predict according to Mandler and Johnson (1977) that it is the temporal order which would be altered most.
In reality, the stories were recalled over only a short period of time and major event   alterations did not occur, but both deaf and hearing people recalled the main episodes equally well and there was no significant difference in the number of events recalled.
What is different is the order of events in the recalls.
Hearing people distorted the temporal sequence much more than did deaf people, with bilinguals coming somewhere between.
Fig. 10.5 shows the extent of the difference.
interestingly, hearing people seemed to increase in their re-arrangement over time while there was very little difference in BSL.
The fact that English tends to make these ‘order errors’ is not particularly surprising since its system of tenses and conditional structures allow easy reference to events out of sequence, for example:
he makes his way home.
Unknown to him the whole contest had been broadcast and his wife and mother-in-law had heard his name…
The results tend to agree with Mandler and Johnson (1977) for English but not for BSL.
in addition, it is not clear that the re-ordering is in the direction of simplifying the causal structure of the story.
It seems more likely that the re-telling arises directly from the capabilities of the language as well as the perception of the subject as to what makes the ‘good form’ of a story.
However, the temporal recall issue is related to the form of propositions available.
Propositional structure
The fact that Chafe (1977) has suggested that information concerning agent and recipient is not necessarily stored by the individual in a specific arm is perhaps fortuitous in our comparison of English with BSL.
The description of BSL as an  inflecting language would allow, and indeed predict, a much more flexible approach to the construction and use of propositions.
Since BSL is visual, then the feeling of being in the story must be more pronounced.
if the overall recall is not significantly different, but there are differences in sequence of recall, then one must consider aspects of the surface structure as the key to the communication of the same message.
The focus of this is the language itself and, in particular, the use of ‘verbs’ within it.
In many cases the notion of verb is not so easy to deal with in sign language.
Supalla and Newport (1978) discuss ways of dealing with noun — verb distinctions in ASL, and Deuchar (1983) comments on it for BSL.
Supalla and Newport (1978) maintain that nouns and verbs are separated by frequency of movement, but in BSL PILL has two movements while to TAKE-A-PILL has only one, but BRUSH has one movement while to BRUSH-UP or SWEEP has more than one; this distinction, therefore, is not simple.
It is appropriate to discuss a number of features of verb inflections.
Edwards and Ladd (1983) suggest verbs do not inflect for tense or person in BSL, but though this is true for a number of verbs it is not true for some of the most frequently used verbs.
Not only do these verbs inflect for person, they very often incorporate the person and/or object of the sentence.
Basic verbs such as DRINK, EAT, LIVE, BUY, WORK, LOVE, CHEAT, WIN, TRY, ALLOW, ARRANGE, BREAK are not inflected in common use for tense or person: time and person are indicated by the use of adverbs or by pronouns.
However, some verbs are inflected spatially in order to incorporate information on person.
The verbs HAVE and AGREE vary in space according to which person ‘has’ the object or agrees.
This is also true of COME, which indicates location as well.
This links with a second category of verbs, where movement indicates both agent and recipient.
Verbs such as GIVE, TEACH, HIT, SEE, HELP and TEASE fall into this category.
Other verbs incorporate size into movement and provide additional meaning by their inflection.
So the signs PICK-Up, PUT, THROW and PULL can indicate subject, object and size of the object.
in each of these verbs the use of an additional marker of subject, object or pronoun, is optional.
When they are incorporated into the verb itself it provides BSL transcription with its typically clipped appearance (see transcript 1).
Most verbs also inflect for aspect, and Klima and Bellugi (1979) describe a whole range of aspectual modulations, including (for BSL) continuative (e.g. WAITING: WAITING-FOR-AGES).
Frequentative (e.g. GIVE: AWAYS-GIVING) and intensive (e.g. GIVE: GIVE-AWAY).
In effect, BSL (like ASL) has a colossal range of ‘present tenses’ and while very few verbs inflect for tense as do SEE: SAW or GO: WENT: GONE, there is an immense range of tense and aspect information available in the inflected forms.
One can see that BSL invites the omission of specific storage of agent and recipient, since the meaning of the proposition may be included in the verb itself.
it probably constitutes a very pure form of the storage that Chafe envisages.
Using only the gloss of BSL is therefore rather misleading.
The three glossed signs from transcript 1 (KNOCKED, CAME, WHAT?) represent three propositions with the meaning that someone knocked at the door, the person inside came and tried to find out what it was.
Stokoe (1980) has highlighted this type of one-sign sentence in ASL, where one can see the use of direction and movement to provide the full meaning.
Such one-item propositions also occur in English in other commentaries:
…at home/ (and) realised/that…
or
she just arrived/…a postman/ and he's…
In each case one constructs the meaning from the context and following referent or clause.
It is particularly this aspect of BSL structure which not only creates the concentration of meaning in a few glosses but is frequently brought into use by deaf people.
The metric used to study this is simply the proportion of propositions in recall which are one-item propositions: fig. 10.6 shows the results.
Deaf people are much more likely to use this device in their recall, at least in the surface structure.
Bilinguals come somewhere between, indicating that there may be an influence of both the language itself and the internal processing of deaf people.
It must be remembered, however, that this is only, in the end, a way  of reflecting differences in the languages.
If Chafe (1977) is correct, then BSL would represent a language which tends to emphasise the storage and recall of events, whereas English requires much more superficial specificity in recall.
BSL therefore stores story information and re-tells it in a way which would occur for all languages, but spoken language surface structure (reflecting only a specific point in time and context) would tend to hide this in its effort for reconstruction of meaning.
BSL looks imaginal; one gets a clear insight into the happenings of the story; it is impossible to understand it unless the receiver of the message enters into the perspective offered by the story-teller.
In English this does not necessarily happen, although one might claim it is precisely this device which good story-tellers invoke, even in English.
BSL therefore provides a great deal of aspectual information directly for the receiver, while English sets out the same story in a different way, allowing alteration of event structure without destroying meaning.
De Matteo (1977) has argued that one has to understand sign language in terms of its visual imagery and he has particularly highlighted the syntactic devices used in ASL which derive from a visual representation of events.
In the stories told above, it is obvious that the richness of aspectual information comes from their visual — spatial characteristics and that there is an appeal to the visual imagery of the receiver in telling the stories.
The idea that the syntax of BSL has to be understood through its visual presentation also seems reasonable and in agreement with De Matteo.
The final stage of the claim, that BSL consists purely of visual images in the story-teller and that BSL functions only at the visual concrete level, however, goes beyond the information given.
Even if it were true, it now seems very likely that the storage of non-verbal story material by the use of imagery is a process used in every language.
Fauconnier (1981) discusses ‘mental spaces’ as the basic representation of all language and cites ASL as a particularly clear example of this.
It seems that BSL also falls within the class of languages which demonstrate the use of imaginal processes in their construction.
in this chapter we have gone deeply into the structure of BSL from a cognitive psychological perspective.
The fears that BSL consists of a limited, concrete visual language localised in the right hemisphere, can be discounted.
BSL does not follow the normal rules of processing as specified by the predominantly verbal sequential tasks which psychologists have used.
The realisation that those tasks usually only tap a subset of language behaviour, has come only very slowly.
However, the gain to psychology, and our treatment of language, may be very great.
The idea that speech coding in memory may be only a subset of motor  memory processes, including sign language behaviour, opens up a new possibility for psychological research.
The fact that psycholinguists have begun to see ‘deep’ language processing as much in terms of images as linguistic propositions allows the incorporation of BSL work within the framework of all language work.
Understanding of BSL, however, has to come first to be of value.
In chapters 11, 12 and 13 we consider the application of such an understanding.
BSL processing involves sequential and spatial codes, uses direct visual representation for its syntax while displaying the same complexity of meaning as English.
It is self-evident that those who use BSL professionally, given this awareness, can exploit these attributes to the full.
SIGN LANGUAGE INTERPRETING
It may appear rather odd that a book on an emerging language devotes a chapter to the process of translating meaning from that language to another and vice versa (especially when this second language will be, virtually always, English), but the development of BSL, and its community of users is so bound up in its treatment by hearing people that it is essential to have some discussion on the matter.
While spoken language interpreting is an accepted and highly skilled profession, sign language interpreting is mainly carried out by those in a caring or managerial role with deaf people.
While, for example, French — English interpreters may be either French or English nationals (or indeed from another community) BSL interpreters are drawn solely from the hearing English-speaking community.
Their knowledge and use of this second language is therefore of some importance in considering BSL and deaf people's role in society.
There are some obvious prerequisites for the interpreting role if the member of a community is to be fairly represented and have the opportunity to participate fully in decision making.
One expects the interpreter to influence the content, context and spirit of a message as little as possible in keeping with relaying it meaningfully in the second language.
In all interpreting it is not only the technical skill of the interpreter which is important but also his attitude to the job and to the particular situation in which it has to be carried out (R.W. Anderson, 1978); also important is his awareness of the different expression of the same meaning in different cultures (‘the sense’ of the message; see Seleskovitch, 1978).
For BSL interpreters there is often the added complication of role conflict between their social work/educational job and their impartial relay of meaning as an interpreter.
If attitudes towards deaf people influence the learning and using of BSL, then they almost certainly affect BSL interpreting.
In this case interpreting is taken to mean both consecutive and simultaneous interpreting.
In the first the message is received in full and is then given out to the person; in the second the message is received and is simultaneously translated into the second language.
The relayed message is the source language, while the second language is the target language.
As far as BSL is  concerned, virtually everyone who learns some signs is at some stage called upon to interpret by a deaf person, and this is most likely to be from English into BSL.
In effect this means a very broad definition of the situations where interpreting occurs, ranging from conference simultaneous interpreting to casual conversational interpreting which may be consecutive.
As is the case for spoken languages, deaf people will expect and experience both simultaneous and consecutive interpreting.
There has been a tendency more recently, however, for deaf people to be wary of consecutive interpreting where they may feel information is added to, or subtracted from, the message (Allsop and Kyle, 1982), even though for spoken languages it has usually been felt that consecutive interpreting is much more effective and much easier to check for the validity of the interpretation (Herbert, 1978).
The essence of discussion in this chapter is therefore the expression of meaning of one language in another language.
The purpose is to compare what we know of spoken language interpreting and its effectiveness with developing awareness of the needs of deaf and hearing people in using BSL.
Spoken language interpreting
It is easily forgotten how old the task of interpreting is, but how new the profession of interpreter is.
Herbert (1978) suggests that conference interpreting began only during the First World War, while before that international conferences were held in French.
For most of the time this involved consecutive interpreting, i.e. making notes of what the speaker said and then at the end (of perhaps an hour's talk) repeating the speech in the target language.
it was only just before the Second World War that simultaneous interpreting became possible (as well as acceptable) at conferences.
With the provision of booths and sound systems, most conference interpreting is now of the simultaneous variety but, as is frequently pointed out by interpreters themselves, the most common use of interpreting is in some personal consecutive mode and not in conferences.
It is also clear from Herbert's comments that the process of interpreting is generally not well understood by even those who use interpreters, and features like the interpreting lag, or the change in pace of the interpreter according to the speaker's rate, may often be mistaken for some problem in the interpreter's rendition of a message.
In practice, spoken language interpreters are highly educated and highly trained.
Complete fluency in the first and second languages is taken as prerequisite for training (and one would expect a working interpreter to command at least four or five languages).
The preoccupations of spoken language interpreters in discussing their task do not then concern language  competence but only interpreter competence (Gerver and Sinaiko, 1978).
This competence revolves around the intended meaning of the message and therefore places the responsibility of flexibility of expression and clarity of grammatical presentation on the shoulders of the interpreter.
Namy suggests that simultaneous interpreting is:
What is most striking in ‘poor interpreting’ is the lack of use of perfectly idiomatic expression in the target language (it is this particular aspect of BSL which has proved most difficult to research).
This is a most basic aspect of interpreting, and requires that the interpreter fully understands the grammar and culture of the target language user.
Unfortunately there is also an added complication: the distinction between language meaning and message meaning (Pergnier, 1978).
Language meaning is what is conveyed by each unit or group of units in a language, the commonly agreed meaning of a word or phrase.
Unfortunately, in most languages translation of units produces ambiguity, i.e. the French word glace could mean in English ‘ice’, ‘glass’, ‘window’, ‘mirror’ and so on.
However, the use of the unit in the language is agreed within the community because of characteristic speech habits.
Message meaning on the other hand corresponds to the intended meaning, is usually unambiguous and mostly determined by context.
So the request for une glace in a restaurant unambiguously refers to ice-cream and it is this aspect which must be interpreted.
Pergnier explains that the language user would not himself be concerned with the possible ambiguity:
This idea is so fundamental to the principle of interpretation that it is expressed, in slightly different forms, by various writers.
Seleskovitch (1978) perhaps encompasses both Namy and Pergnier in what she terms the ‘keyhole’ principle: the fact that language meaning through translation may not convey message meaning and the corollary that message meaning is expressed through different salient characteristics.
So, in English there is a keyhole , but in French it is a trou de serrure i.e. a hole with a lock ; in English it is a bedroom , but in French it is a room for lying down (chambre à coucher ).
It is not that English people do not lie down in the bedroom, or that French people do not have keys, but rather they choose different salient characteristics for the expression of that specific meaning.
It is therefore this intention of the speaker (within the message) which has to be interpreted .
One can therefore extract a very simple theme in the work on spoken language interpreting: it is the intended meaning which must be first understood, and then transposed into the target language by the interpreter.
It supposes complete access to the language meaning (the range of interpretations of that element of the message) and developed ability to convey the message meaning in the target language.
The interpreter presents the message in the way the speaker does in his source language, and would do in the target language if he could.
Sign language interpreting
If spoken language interpreting is a young profession then sign language interpreting is in its very early infancy — in many parts of the world it has yet to be born.
As with sign language research, Scandinavia and the USA have been in the forefront of developments, though each draws on different traditions, the first for the recognition of language difference needs, the second for the equalisation of society and integration of minority groups.
The US has a greater experience, having had a Registry of Interpreters for the Deaf (RID) since 1964, and now has a widespread network of interpreting provision.
With qualifications for interpreting provided by an assessment board and now through training at college level, and with the emergence of full-time workers, interpreters have reached professional status and have set out guidelines for their profession and for their deaf users.
The use of registered interpreters is seen as sufficiently important now for Freeman, Carbin and Boese to warn:
In Denmark, although there is assessment and provision of interpreters there is no training course but a series of starter courses to support the skills that the interpreters (usually people with deaf parents) already have (Hansen, 1980).
The  report of Domingue and Ingram (1978), for the USA, indicates the emergence of the profession both in terms of status and in concerns for interpreter efficiency, and it is on this basis that we begin to look at the processes involved, comparing signed with spoken interpretation.
In terms of professional development the UK lags somewhat behind, having no fully recognised body of interpreters (although such an organisation may now be close to recognition) and, as far as we can make out, only one full-time interpreter in the whole country.
There is no government funding for training and assessment, nor is there legislation for interpreters.
Rather it is a historical fact that interpreters are provided in court (see the Jean Campbell case, 1817, referred to in chapter 3) and only recently has research to examine interpreting been undertaken.
Much of our discussion in the latter part of this chapter draws on this research.
As one might predict from the history of interpreting in the USA and Scandinavia, it is within the field of education that the basis of an interpreting service is laid.
There is no requirement in the UK for colleges to provide any sort of support for deaf students.
in effect, using BSL in further and higher education is still seen by many as part of the ‘handicap of deafness’ and something to be overcome in education rather than used.
Interpreting in schools, colleges, courts, meetings and so on is provided by individual arrangement usually with a social worker for the deaf, though in most personal circumstances (job interviews etc.) deaf people say they prefer to use a relative or friend (Kyle and Allsop, 1982b).
In these circumstances, our developing knowledge of interpreting and language in general is critical in providing a framework for evaluating interpreter effectiveness and understanding the process in which he has to be trained.
BSL interpreting effectiveness
In an attempt to identify the component skills and abilities necessary for an interpreter to be regarded as ‘good’, Brasel, Montanelli and Quigley (1974) asked interpreters and deaf people to rate features of their abilities.
Generally, these people rated ‘accuracy in transmission of concepts ‘, or getting the message over, as the most important, and ‘fast fingerspelling’ as the least important.
A similar, but slightly expanded, study was carried out with British interpreters (Kyle, Llewellyn-Jones and Woll, 1979).
The results of this study indicate general agreement between the hearing and the deaf subjects.
The deaf group were unanimous in putting ‘accuracy of transmission of concepts’ as absolutely essential and, interestingly, rated ‘the ability to understand all signs used, no matter which part of the country they came from’, higher than did the hearing group.
The imbalance in our treatment of the two languages clearly reflects the traditional non-acceptance of sign language as an entity capable of mastery by hearing users.
This same attitude is shown in existing interpreter assessment procedures; for example, that used by the American Registry of interpreters for the Deaf, where sign language is split into articulatory features such as clear fingerspelling, lip movement and appropriate facial expression, for scoring.
The fact that this is deemed necessary is probably also a reflection of the lack of formal sign language teaching and the understanding of the process itself.
Brasel (1976), in a study of fatigue, replicates Gerver's (1972) findings with spoken interpretation, that interpreter fatigue after very short periods of interpreting (30 minutes) begins to introduce an error rate which after an hour is statistically significant and unacceptable.
The over-use of interpreters (e.g. interpreting all day at college for a deaf student) is probably typical of the early stages of development of the interpreting profession (Herbert, 1978) but one hopes this can be quickly overcome as better provision is made.
Murphy (1978) reports a simple study on effectiveness where interpreted information to deaf people was compared with oral lectures to hearing people.
Deaf people did 16 per cent less well in a comprehension test than did hearing people, giving rise to three possibilities: that sign language is less efficient; that deaf students are less knowledgeable and able to take in less information; and that sign language interpreters are not efficient.
Murphy rejects the first, accepts the second and does not actually consider the third at all! in fact it is probably the key, since in an earlier part of his discussion he opens up the possibility of interpreting not only into ASL (or BSL) but also into a manual English form.
In relation to chapter 9, this means interpreting into the interlanguage, a practice which would be considered rather dubious in spoken language interpreting.
The grounds for such a choice are the requirements of the deaf viewers themselves.
Those with a better use of spoken and written English may prefer a sign representation more tied to English.
As we will argue later, this is almost certainly what happens in most BSL interpreting and the message produced will be, at best, ambiguous.
Llewellyn-Jones (1981a) describes the assessment of interpreter effectiveness and indicates a much lower performance by interpreters than one would hope for.
Taking a perfect performance as the comprehension of hearing people working from memory of an audio-recorded message, deaf people's performance after interpretation was, on average, around 60 per cent.
Llewellyn-Jones (1981a) also looked at lag behind the speaker and though his concern was for individual comparison, a general conclusion is that the usual 2 — 3 seconds lag of the BSL interpreter behind the speaker is not sufficient for the message to be both understood and presented to the audience in a form which can be  understood.
The form of presentation used involved very strict adherence to English grammatical rules.
Lederer (1978) describes a similar study for spoken language interpreters, where a 3 — 6 seconds' lag occurs as a base level but with a great deal of interpreting occurring much further behind the speaker's words.
In fact, the interpreter expects this because of his training and the need to understand the message.
The shortest lag occurs where the interpreter does not understand the message and merely transposes the message from one language to the other; in BSL the transposition occurs from English to signed English, or from BSL to spoken signs.
In deaf — hearing interaction, however, it is possible to consider the interlanguage as a usable form.
We have argued that much communication is English-based, and in education it constitutes a real choice since a purpose may be the teaching of specific English structures through sign.
As Llewellyn-Jones (1981b) points out, interpreters frequently claim that it is audience feedback that determines which target language form is used.
Experimental study fails to confirm this claim.
Llewellyn-Jones (1981b) examined experienced interpreters in feedback and non-feedback situations and found no difference in target language use (in both cases they used a signed English variety).
in addition, when negative feedback (i.e. lack of understanding, questioning looks) was provided there was no noticeable alteration in signing style from when positive feedback was provided.
These BSL interpreters appeared to be using only a single register, and this corresponded to a signed version closely tied to the English of the original message.
This would count as a very serious mistake in spoken language interpreting.
In BSL to English interpreting a strikingly similar pattern emerges.
Llewellyn-Jones (1981b) compared simultaneous and consecutive interpreting situations and discovered significant differences in the same interpreters.
in the consecutive mode it was much more likely that the message would be interpreted into an English form which followed all the grammatical rules, while in simultaneous translation there was a clear tendency to follow BSL structure while speaking the words.
Interpreters were more likely to produce non-English sentences and omit or use incorrectly, referents in the message during simultaneous interpretation.
For example, a message was interpreted as:
On Saturday i arrived — you were waiting for your friend — yes — waiting, waiting — friend came — you walked to deaf club — sitting in deaf club — waiting…
Manchester?
Waited and waited — the bus came — quickly got in the bus — quickly — the bus went quickly and they arrived in Manchester.
There is no doubt that this form of target language is unacceptable to English speakers, who might dismiss the interpreter or, more likely, assume that this was a function of the deaf person's lack of knowledge of English (and feel that the  interpreter was doing a good job).
If this BSL — English is unacceptable in English, one must also question the validity of interpretation in sign language forms which follow English structure.
In both circumstances the deaf minority have to struggle to participate in community life if their contributions do not sound like English and if their failure to understand the interlanguage interpretation is put down to their poor general knowledge or low mental ability.
One can accept that it is a complex and difficult issue as to which target language is acceptable, but clearly deaf people's abilities are not being realised in contact with the hearing community.
It perhaps is a function of the early stage of interpreter development in the UK (though there are only a very few positive indications that the situation is different in other more developed countries) and one can expect a change of provision, attitude and therefore skill.
However, the process of interpreting is still not fully understood for BSL, and it is upon this that effectiveness of training hinges.
In examining a model, the following discussion also applies to much of spoken language interpretation, and although the BSL/ signed English issue is perhaps unique, there may be a considerable amount to be exchanged between spoken and signed language models.
BSL interpreting: a process model
The features of sign language interpreting so far described, and the possible registers available, suggest something rather different from the linguistic models of Seleskovitch (1978) and others.
The latter deal primarily in a currency of meaning while the former have still a conflict concerning the appropriate register for the target language.
In using a cognitive approach to the task of interpreting it may be possible to find a base for comparing the language systems.
Generally speaking, psychology has concentrated on the processes involved in dealing with verbal data as it arrives in the individual.
There are processes described for perception, immediate recall, attention, short-term memory, recognition and a whole range of rules whereby recall occurs.
We understand that a code must be invoked in order to handle the grammatical aspect of what one person says, but the question of how we extract information from running speech remains the subject of much debate (Marslen-Wilson and Welsh, 1978).
Moser (1978) typically deals with the way information is broken down in interpretation from sentences and context into meaning, and one can only presume that she proposes a similar process for the reconstruction of the message in the second language.
However, it is probably this stage which separates interpreters from ordinary individuals.
Hitch and Baddeley (1978) have proposed a model of working memory, developed from what has become the basic modal model in psychology, which   gives a focus for our discussion (fig. 11.1).
Auditory information in the form of one language enters the system and is filtered to reduce environmental noise.
The speech left provides for an internal speech code which passes through a working memory system where it can be examined.
The examining is controlled by an executive which oversees the analysis of the message and determines how it fits the context, probably discarding the surface grammar of the message by parsing in some way, and then establishes the meaning of the utterance.
The system has the option of calling into action an articulatory loop, a form of silent speech rehearsing which gives the system more time either to accept more information or to examine the message in greater detail.
This system links with the important child development stage of overt verbalisation of things to be remembered.
Even in adulthood, difficult material may often be overtly rehearsed, giving rise to further auditory input.
Given fluent processing of first language material, the articulatory loop may never consciously intrude into the interpreter's performance.
One can then envisage the model of fig. 11.2, where source language material is interpreted into meaning and this provides the instructions for translation to the target language.
This calls into use a response buffer which produces articulation of the translated message.
It is not clear whether this articulation makes use of the working memory system or is independent.
However, it is very likely that articulating a second language interferes with the processing of the first during simultaneous interpreting.
For this reason, spoken language interpreters are specifically trained to reject the effects of their utterance of the target language.
Because we are dealing with running speech, the articulatory loop should seldom be used in dealing with the source language (unless it is in an abbreviated code)— a simultaneous interpreter   will claim to analyse the meaning directly and have little knowledge of sound features in the source language.
The technique used to train suppression of the interference is ‘shadowing’, whereby the listener reproduces in speech word-for-word a source language message in that source language itself.
Since this creates an echo, because of the lag of a second or two, the effects of hearing the echoed message are initially disconcerting and generally cause the subjects to stop processing the source language properly.
With repeated practice the interference between heard and spoken messages becomes much less and the information channelled through the response buffer should be lost at the filter as it re-enters the system.
The articulatory loop should also be seldom used since it would slow down processing of a message whose speed is beyond the control of the interpreter.
The loop could act only as a monitor to be interrogated in the case of breakdown of comprehension.
In spoken language interpreting it is claimed that the interpreter has to improve his memory ability and his tolerance of lag and therefore, if the loop is used at all, it must contain information specifically coded to carry language markers.
This may seem rather unlikely in the very limited capacity loop in the model and may simply be a fraction of semantic memory.
In either case, the articulatory loop could not be used in quite the same way as Hitch and Baddeley (1978) propose for memory, but would be more similar to its function in reading, where it is largely suppressed.
From Llewellyn-Jones' (1981a, b) findings, there must be a question as to whether BSL interpreting is actually occurring most of the time.
Since the target language seems to be signs in English order in most cases, we have a situation as shown in fig. 11.3.
Here the English source dominates; information is only superficially analysed and often meaning is not accessed (subjective reports of   not being able to recall the material presented are not infrequent).
The message to be output then simply acquires a sign vocabulary, and the response buffer has speech and sign mixed.
This may arise even in circumstances where there is a knowledge of BSL and therefore some way of encoding its meaning.
This could not happen in spoken language interpreting since the buffer would have two spoken codes vying for one output.
A second problem concerns the nature of analysis of the source language and its functioning in an articulatory loop system.
If the task required of the listener is to shadow the message then the articulatory loop will be a useful device in establishing an appropriate lag and in maintaining information long enough for it to be recognised and repeated.
It should be suppressed in spoken language interpreting, but in sign language interpreting it may not be, since speech and sign, at least on the surface, will not compete for the same articulator.
The BSL interpreter can still shadow and produce the language form he expects.
The preferred lag Llewellyn-Jones (1981a) mentions, of 2 — 3 seconds, would fit with the normally suggested duration of the loop — interpreters may simply be shadowing.
The advantage in using the loop is that the message would not have to be completely understood.
Unfortunately, instead of being silent, rehearsal of this form can become overt.
Sign interpreters can be seen to ‘break down’ under the stress of an  increasing use of articulation to maintain the information in memory for it to be recalled and analysed.
The interpreter in this situation becomes increasingly conscious of the lag in his articulation behind the speaker, and the increasing mismatch of messages lead to greater whispering to ‘block out’ the source message.
He begins to hear his own voice, echoing the speaker and causing shadowing aloud effects.
Inevitably that produces omissions, and may lead the interpreter to stop altogether or to ask the speaker to slow down.
The system is then being driven by working memory.
As this becomes overloaded, i.e. as more information arrives in the message, an untrained interpreter tends to do one of the following:
(a)
give up a slightly time consuming analysis of meaning, and simply produce word-for-sign or sign-for-word translations
(b)
leave out sections of the message in order to be able to catch up, or guess at sections of a deaf signer's message
(c)
stop the speaker or signer, and ask for a repeat of the information
In sign-to-speech interpreting there may be a slightly different process occurring.
Although some interpreters have difficulty due to insufficient BSL knowledge there is again a tendency to incompletely process the meaning.
In this instance, the grammar of BSL is rejected and the parser tends to look only at surface structure and provides word-for-sign matches.
For most of the time this works imperfectly and simultaneous interpretation of BSL to English is frequently marked by the interpreter requesting repetition or further information from the deaf person.
This occurs because the ‘shadowed’ message this time does not match the dominant language structure, i.e. English, and constant monitoring and additional concentration is required.
One can see that the task of interpreting will share similarities in its processes no matter which languages are being used.
Spoken language interpreting, because it takes place only in one medium (i.e. sound), ensures that two languages cannot be mixed directly, and the use of an interlanguage is discouraged from the earliest stages of language learning.
What is trained in the spoken language interpreter is the direct analysis of meaning and the active suppression of any interference effects from the production of the target language.
In BSL interpreting, at present, many of the processes seem to be active which need not be and ought not to be.
The fact that the target language is not speech allows the interpreter to do something which is superficially easy: to shadow the source language without analysing it.
The effort in this makes it expedient that an output form is found as quickly as possible.
Under stress this becomes a simple word-for-sign or sign-for-word match which solves the immediate  problem but does not give meaning.
The fact that the problem recurs is inevitable given the constant shadowing and articulation.
BSL interpreting is therefore a task of some difficulty.
There are a number of confounding factors in our deliberation, such as level of knowledge of BSL and the styles involved, attitudes which do not treat BSL as an adequate language code, and the pressures and difficulties of the interpreting task itself.
Many of these factors appear in spoken language interpreting, but they are better understood and training aims to overcome the weaknesses of the individual interpreter.
Presenting a model of these factors gives no prescriptive power over the language analysis in BSL or speech, but it is a framework whereby we can see separate elements in the task.
Attitudes to the task (R.W. Anderson, 1978), stress (Gerver, 1976), conditions (Parsons, 1978) and actual language knowledge (Longley, 1978) all have additional effects on the interpretation, and have to be taken into account over and above the actual process if we are to consider the training implications.
BSL interpreting training
As one would expect, training programmes, after an initial emphasis on ethics and aspects of the situation (e.g. court interpreting), have begun to focus on the interpreting task itself, and are much more likely to follow a pattern similar to spoken language interpreting.
In the UK, and in the USA, the first step has been to try to set up an assessment procedure (Simpson, 1981); then to consider how training might best be implemented.
The training, which has yet to take place in the UK in a formal way, will draw on what has been written on language techniques and the specific situation of the deaf community.
Understanding the process is of considerable importance however, and it is this which has been focused on here.
The considerations of language are over-riding ones, nevertheless, and it is useful to end by reviewing a number of the conditions for spoken language interpreting assessment.
Keiser (1978) reviews the selection and training of conference interpreters.
He maintains that because of the highly complex activity, interpreters should be highly educated and already fluent.
The basic examination should consist of:(a) an interview with frequent switching from language to language;(b) an improvised short speech in the first language on a topic chosen at random, to assess general knowledge;(c) non-technical information in one language to be rendered consecutively in a second language;(d) translation from a text off-the-cuff.
These tasks are meant to be stressful and to show how well the student can use the languages in difficult circumstances.
Unfortunately this constitutes only  the assessment of a candidate's suitability for entry to an interpreters' qualifying course.
Many conclusions can be drawn from this summary.
Sign language interpreting shares the process with spoken language interpreting and probably with general language comprehension but it differs in the situation of the users of the language and the community's attitude towards them.
This creates additional problems of target language suitability, problems which have yet to be solved.
Nevertheless, the point which comes across again and again in spoken language interpreting is that it is the meaning which is being translated.
This is not the language meaning (the words or syntax of the language) but rather the message meaning or intended meaning of the speaker.
Seleskovitch puts this most clearly:
Translating language meanings and obtaining the desired effect, i.e. a wording immediately intelligible to listeners, is impossible, not because there are doubts as to the intended meaning of words or phrases but because the resulting translation of such words and phrases would fail to carry sense adequately in the other language.
This is why interpreters have to grasp sense and remember the ideas behind the words.
(1978: 341)
BSL interpreters require the chance to develop the skills necessary to differentiate between language meaning and message meaning if deaf people are ever really to understand the sense of the interpretation.
Sign language in schools
As was apparent in the introductory chapters, sign language and education have historically been kept apart by those working with deaf people.
Sign language was something which adult deaf people might resort to if they had failed in their education; the principal aim of education was normalisation at best, but the realisation of a child's potential at the very least.
This is still valid as an educational ethos, but what comes to be questioned is the ‘potential’ and how it is to be measured.
If we believe that the deaf child begins life as communication-handicapped, then any development in the ability to speak or lip-read is an education success.
However, if we begin from the view that the deaf child is communicatively competent in sign language, given access to appropriate models, then all his learning goals can be reached through this language and the child becomes a second language learner in relation to English.
The former view finds its sole aim in relation to communication in English, the latter sees English as part of the general educational achievements required in a shared environment with sign language.
What must be most striking to readers is how little difference there is in these two underlying premises for educational activity.
Both ideals seem plausible, both effective in their own way and both derived from honest concern for the needs of children.
Where the divergence has arisen is in the statement of dogma into which educators have been lured.
The medical world looks for cures and, given a precise diagnosis, will set out a course of treatment which should lead to improvement in the patient's condition.
Educators too have become anxious in special education to provide a ‘treatment’ which will lead to normalisation.
Because of the nature of personal involvement in education (in a deaf school a teacher may be closely associated with the same child for a number of years) the form of treatment used relates to the personality and experience of the educator.
The success achieved with children incorporates these and can become the only way of dealing with children.
In publicising one's own methods it becomes only a short step to maintaining that this personal success is general success and can be achieved only through this personal approach.
And so the doctrine is set.
This happens in nearly all aspects of special education and can occur no matter from which premise we begin.
Deaf education has been associated with a great deal of  dogma which has had varying degrees of influence over the years.
The danger is obvious: education becomes a battleground of personalities and experience; objectivity and evaluation are pushed aside.
Sadly, we still find many examples of this problem.
Nolan and Tucker (1981), in writing for parents of deaf children, give no indication of the degree of language difficulty deaf children actually do face.
There are no mentions of the well researched and replicated findings on reading problems, nor of the nature of the speech problems experienced.
No mention at all is made of sign language in the book, even though 82 per cent of deaf young people report its use while still at school (Kyle and Allsop, 1982a).
However, there is great pressure on the authors to present an optimistic view to parents:
We believe that the language learning facility possessed by normally hearing children is also possessed by hearing-impaired children and that with the exception of some with severe secondary handicaps, hearing-impaired children learn the mother tongue naturally.
Of course, there will be variations in the level of functioning as there are with normally hearing children, but we know that oral language can be their root of thought and communication.
(Nolan and Tucker, 1981: 143)
One can easily understand this viewpoint since the potential of children has to be maximised and parents should be allowed to consider the ideal outcomes of their efforts.
Nevertheless, the product of the optimism is greater anxiety for parent and child when these ideals are not met.
The pressure is not alleviated by further statements which are over-dogmatic without consideration of their effects: ‘We are convinced, and our experience supports us, that the auditory mode can be the mode of information transmission for hearing-impaired children’(1981: 147).
This view is not supported at all in another contemporary parent's guide, Freeman, Carbin and Boese (1981).
in their book, discussion ranges over many methodologies in many countries and readers are offered choices.
It is this greater openness which will be required if deaf education is to assimilate the changes occurring in the community of deaf people.
While we are here concerned with the understanding and use of BSL, it is not our intention to maintain, particularly in relation to education, that this is the only method of approach.
The damaging feature of oralism in the last hundred years or so in Great Britain has been its total rejection of any other method of educating deaf children.
The personal elation and achievement experienced when a deaf child learns to speak recognisable words is great indeed, and has been so persuasive that many educators have perceived this experience as the only one which could possibly satisfy the deaf child as well as his teacher.
The pursuit of this goal for all children, often at the expense of objective examination of results, has been misleading and is ultimately unacceptable.
The danger is that the question of methodology can easily be turned to  dogma according to any premises.
In deaf people's case this becomes ‘BSL is the only method of teaching deaf children’.
Certainly information can be easily conveyed in BSL and it functions to a marked degree as an effective socialisation agent in deaf children whose parents are fluent in the language.
Nevertheless, there are a series of questions to be dealt with in exploring its applicability to the classroom.
Even with our limited experience in the UK of signing in the classroom, there are considerable pressures already to have the ‘correct’ use of signs, or to find the single, standard method of teaching in sign.
These pressures are valuable if they lead to early considerations of teacher skills in BSL, pupils' needs for BSL and manual English, and assessment of achievement levels as a result of the use of BSL.
But the chances of these considerations occurring still seem slim.
Any consideration of deaf education should begin with the question of levels of achievement in deaf children; very often in the past, however, there have been intervening arguments proposed which have directed attention from the central purpose of all educators.
Some of these points are still raised today, and it is as well to tackle them now prior to the examination of achievement.
Point 1.
Deaf children are no longer so unfortunate; technology and better methods make research findings of even recent years no longer applicable.
This is a frequent statement and is implicit in views such as those expressed by Braybrook and Powell (1980).
Our quotations from the 1790s and from the Times in 1880 (see chapter 3) indicate that the feeling is at least two hundred years old.
Bergman's (1979) comments on Sweden indicate that it is also a belief which has appeared in other countries.
The fact that it constantly re-emerges suggests that the deafness problem has not been solved at all.
Kyle and Allsop (1982a) examined how recent research on deaf children tends to confirm the usual findings of poor speech and reading performance.
If we consider Braybrook and Powell's (1980) surprise at finding 22 children with acceptable, natural speech abilities, and apply it to Conrad's (1979) national study of school leavers, we find that we should not be surprised at all.
Taking Conrad's population and suggesting good speech as 75 per cent words in sentences correctly identified by listeners (a higher cut-off than Braybrook uses), then in the hearing loss range 80 — 120dB (Braybrook's range), there would be 15 children.
Extending to the 6–16 years age range of Braybrook, we would predict a population of up to 150 from which the better speakers of his 22 were chosen; Conrad's figure excludes those placed in ordinary schools.
Point 2.
With the trend towards mainstreaming or integration, relatively few deaf children now need communication in anything other than speech.
They will mix with hearing children from the beginning.
This is a rather curious argument about sign language.
It implies that only deaf  people in deaf schools who are ‘isolated’ need to use BSL.
Not only do we have the situation in the UK where partial-hearing units (PHUs — integrated settings) are using Total Communication (e.g. Hegarty, Pocklington and Lucas, 1982), but young deaf people do not see the use of BSL as a function of their contact or lack of contact with hearing people.
Young deaf people expect to use speech and lip-reading with hearing people, but at the same time want BSL as their language, as a medium for information (Kyle and Allsop, 1982a).
The trend towards mainstreaming is an important one, but it does not alter the question of how the teacher of the deaf communicates with profoundly deaf children.
Point 3.
The numbers of deaf children are decreasing, and some causes such as rubella can be completely eradicated as medical prevention programmes improve.
The deaf community will soon be so small as to make considerations of BSL or signing irrelevant to education.
There is an element of truth in the very first statement as it applies to the UK.
There is no indication that the same is occurring in the world's most populous countries.
However, the numbers are decreasing as the birth rate decreases generally.
In recent years, the decrease in the number of deaf children has been greater than the general national decrease, though this is mainly in the numbers of partially-hearing children rather than deaf children.
So, there is an overall decline but technology may be selectively affecting those who are partially-hearing and they are less likely to appear in the statistics for special education (DES, 1981).
As far as medical intervention is concerned, 42 per cent of Conrad's national study had unknown causes, and a further 27 per cent had hereditary causes.
This means that 69 per cent are not susceptible to medical intervention at least for the present.
Deafness is not going to go away.
Point 4.
All normal deaf children can develop in the oral system.
It is only where there are additional or multiple handicaps that signing or fingerspelling should be considered, because in these cases there is an identifiable ‘syndrome’ preventing language acquisition.
We have already seen this statement in St John Ackers' postscript to the 1890 Education Act, but it has become popular again (Van Uden, 1981).
It arises from a series of acts of faith: speech is natural, language acquisition occurs naturally through audition; the oral approach incorporates this natural approach; children who do not acquire language in this way are therefore deviant, and thus defective.
By this reasoning the things which they do not do well become part of the ‘syndrome’.
Van Uden (1981) explains at length how ‘dyspraxia’ and defects in intermodal integration ‘endanger an education according to the purely oral way’.
His description of these two  conditions places them within the normal range of problems in profoundly deaf children:
The syndrome of dyspraxia of deaf children comprises that the child clearly suffers from dyspraxia or apraxia with dysrhythmia or arhythmia and that the child, his memory as  such being normal, shows a typical profile of a strong memory for simultaneously presented visual data and a relatively weak one for successively presented visual data.
(1981: 118)
The syndrome is seen as poor speech, e.g. ‘omission of phonemes (flower instead of flower )’ or avoidance of lip-reading by looking away.
The motor-sensory integration disturbance appears ‘especially in verbal behaviour, i.e. the integration of word and meaning and of the written and spoken forms of the words’(Van Uden, 1981: 120).
In practice it occurs when deaf children can write a word better than speak it.
The basic premise of this approach is so startlingly simple that it is rather difficult to explain how damaging it actually is.
Lack of speech development in deaf children becomes a function not of their lack of experience of spoken sound, but of additional handicap.
With a simple statement we have done away with the whole concept of deafness itself.
Children are either capable of speaking or not; those who are not use sign language because of their failure to speak.
Handicap is defined in terms of symptoms which were traditionally attributed to hearing loss.
It is a very simple denial of deafness and corrupts the most fundamental aspect of scientific investigation: the elements which are the outcome are said to be the cause.
According to the theory of dyspraxia presented above, the symptoms (poor and irregular control of articulation, better sight vocabulary than ability to speak words) become the cause of the problem.
Deaf children suffer from this ‘cause, and therefore the approach originally used, oralism, is not at fault in dealing with these additionally handicapped pupils.
Not only is this view totally unacceptable to the deaf community as active members of society and sign language users but there is no evidence in the UK that these ‘symptoms’ are in any way ‘causes’.
The problem remains one of deafness.
The developments in child language research, however, show parallel development of sign language and spoken language in young children.
The discussion of how a teacher can deal with the language capabilities of young deaf children is a lengthy one which can only be summarised.
As a prerequisite, some examination of the focal achievements of deaf children in schools is required.
In the UK this has been a function of the oral philosophy of education (until the last five years).
The achievements we consider below, therefore, arise in non-signing environments.
Achievement levels in deaf children
For the most part we are concerned with language achievement in English, but there are grounds for concern about numeracy (Wood, Wood and Howarth, 1983), about employment prospects (Montgomery and Miller, 1977), and about behaviour and emotional development (Denmark, 1981).
We have briefly discussed English speech and lip-reading skills in chapter 4; here we will be more concerned with ‘formal’ aspects: reading and writing.
The approach of classroom testing against the hearing norms has a long tradition among educators and researchers.
The findings are the same in virtually all cases: deaf children lag behind their hearing counterparts.
A pattern similar to that found in the UK is found also in the USA (Jensema and Trybus, 1976), in Scandinavia (Vestberg Rasmussen, 1973), and throughout the European Community (CEC, 1979).
The pattern will be dealt with rather cursorily here, since it has occupied the attention of numerous writers who have presented lengthy explanations of the problems (e.g. Swisher, 1976; Moores, 1978; Conrad, 1979).
However, it does have to be dealt with, since the effective cognitive growth of deaf children indicates a potential for educational growth which has not been realised.
The basis for this claim comes from the discovery of normal or near-normal intellectual functioning in deaf children (Vernon, 1967; Kyle, 1979).
In addition, evaluation within a Piagetian framework has led Furth (1966) to claim that cognitive skills are similar in deaf children, given equivalent exposure to the task requirements.
The argument is difficult to uphold in some respects since Furth's argument seems to be that deprivation of experience is at fault, but he does not provide any suggestions for an approach to maximising deaf people's performance.
However, it is in reading that the major problem of achievement lies.
Reading and writing are visual and motor skills, at least superficially, and are therefore in theory directly accessible to deaf people.
However, this is much too simplistic, and reading levels of deaf children are considerably depressed, as Conrad (1979) has reported in some detail.
In terms of closeness to hearing children's reading, deaf children are only within striking distance between the ages of 7 and 8 years and thereafter suffer significant decline in relative performance which produces very poor performance by the time they leave school.
The problem is serious.
Among profoundly deaf children (greater than 85dB hearing losses) aged 16 years, more than 50 per cent will read at a level below 7 years 10 months (Kyle et al., 1978; Conrad, 1979).
This sort of finding is repeated again and again (e.g. Savage, Evans and Savage, 1981).
Swisher (1976) in a thorough review of achievement in what she terms the ‘oral deaf’, found problems in speech (in word classes, in syntax and in length of utterance), in reading (whether through achievement tests, completion tasks, or direct analysis of morphology, phrases and so on), and in writing (where either limited or stereotyped production occurs).
Quigley (1979) confirms this and uses it as a basis for examining alternative language environments.
Wood (1981) also sees the problem in terms of language environments.
His suggestion is that teaching styles are related to the poor language performance.
His study shows a relatively high degree of ‘repair’ work by teachers in conversation with deaf children.
In effect, the communication interaction is disturbed by lower intelligibility, and teachers have to repeat and check utterances by their children instead of elaborating and extending conversation.
Deaf children's reading ability does increase over time, however, although it never reaches the levels of hearing children.
Wood, Griffiths and Webster (1981) maintain that this development occurs in a radically different way, producing characteristic word and syntax errors.
A series of papers by Quigley and his associates (e.g. Quigley et al., 1976) tends to confirm these differences in syntax knowledge and handling.
At least some of these can be explained by language or code interference between English and sign language (e.g. difficulties with the passive voice — BSL has no passive).
Although we have seen (in chapter 9) that this interference may be interpreted as a positive intermediate strategy by a second language learner, this still leaves open the question of how to utilise it.
In terms of strategy, Ewoldt (1980) maintains that deaf children do use psycholinguistic strategies for reading, indicating a sensitivity to the rules of English.
However, Goodman's (1967) view of reading, from which this is derived, is limited in its understanding of reading acquisition and, overall, the theory can be simplified to a basic strategy of ‘making sense of the task’ rather than being a direct help to reading progress.
The small study of children developing reading reported by Kyle (1981b) confirms the general view, but shows up the gap between vocabulary development, where progress is made throughout schooling, and sentence comprehension, where deaf children frequently reach a plateau at about the 8-year-old level.
It is obviously rather dangerous to talk too generally, and the above brief survey must be interpreted as only a guide to the average performance of deaf children.
There are rather similar findings for writing.
Swisher's (1976) review identifies the type of problems which occur in written work.
Sentences tend to be shorter and there is a preponderance of nouns and verbs, with only gradual increase in other parts of speech as children get older.
More recently there have been attempts to fit a transformational grammar framework to the written production of deaf children (Ivimey, 1976).
Quigley et al.(1976) report on the tendency of deaf children to try to fit subject — verb — object patterns on to all sentence constructions.
Quigley (1979) adds to this a tendency to interpret noun phrases as connecting to the nearest verb phrase, producing misinterpretation and limiting the range of written sentences.
However, what is perhaps most striking about written productions is how often they can be disambiguated by recourse to the sign language ‘rules’ which would govern that meaning.
Most  professionals working with the deaf have had the experience of receiving letters from deaf people which need to be signed in BSL first before the meaning is apparent.
As in any second language situation, the grammatical code which is relied on is the one which is already known.
In the case of deaf people it relates to BSL.
One can see even from this very brief review that deaf children's learning of English does not match that of hearing children.
The view that deaf children can learn through the auditory mode in exactly the same way as hearing children is not supported at all in the literature.
The ‘oral’ approach, whether one calls it a ‘natural’or ‘modern’approach, has been in operation since the time educators stopped learning BSL.
The technology has changed and the nature of the population in deaf school has changed, and there is no research to support the suggestion that the oral approach is viable for the deaf children in special education today.
Deaf children are competent learners of language, as we have seen in chapter 4; they are cognitively able, and will progress to an effective position in working society.
However, the major concern is how to maximise the effectiveness of schooling, and for this we have to examine the learning environment and subsequently the methodological considerations which have actually been presented.
The learning environment
This is one of the most difficult areas of functioning to describe effectively: it is also, perhaps, the most crucial.
Much of the research and theory which has informed our educational methodology has been superseded in recent times both in psychology and linguistics.
Up to the 1960s behaviourist models of learning pervaded educational practice.
Not only did children have to learn by association and reinforcement, their production had to be shaped to the correct response.
This was believed true of general learning and the learning of language.
Deaf education also derived its inspiration from a similar source and the texts available in the 1960s and early 1970s drew heavily on learning theories (Watson, 1967; Van Uden, 1970).
Brennan (1976), in a thorough critique of these approaches, casts doubt on the actual opportunities the deaf child has to acquire language.
She highlights Van Uden's insistence on imitation (and reward) as the teaching approach to language, at the expense of natural elaboration of utterances — as occurs with hearing children (this is one aspect of teaching style also taken up by Wood, 1981).
The pressure of this approach on teachers produces over-zealous correction of ungrammatical utterances at the expense of interaction.
Cazden's (1972) extensive analysis of hearing children interacting with parents shows  how little parents actually correct children's immature syntax, yet this has been a particular bulwark of educational approaches to deaf children.
Brennan puts it clearly:
Perhaps the most damaging aspect of the Van Uden model of language-learning is the assumption that it is permissible to concentrate on language structure at the cost of language function.
This is completely contrary to the present recognition of the priority of function neatly expressed in Cazden ‘s maxim ‘take care of function and the structure will take care of itself’.
(1976: 4)
Even though the method described by Braybrook and Powell (1980) has moved on since this time, it still does not reflect current knowledge of child language.
The ‘natural’ approach to English acquisition draws inspiration from Chomskyan theories that the child develops his own language form through his ‘language acquisition device’.
In effect, this appears to be what Nolan and Tucker are proposing in the quotation given on page 231, and in:
But he will not learn language because you want him to — he will learn it because he wants to .
This fact we believe to be fundamental to our understanding of how he will learn; he will learn language through an interaction between the efforts of his own brain and events in the outside world.
(1981: 143)
Increasingly, child language research has placed the weight on interaction, not on some innate device which produces grammatical utterances in the child.
Wells' extensive data (1981) indicate the critical importance of interaction.
It is discourse which propels language acquisition, and it is the shared meaning in interaction which is of critical importance.
It is this which is most at risk in children with limited hearing.
In one sense these findings may be seen as an argument for mainstreaming and it is appropriate to pause for a moment to consider this view.
There are considerable difficulties in evaluating educational provision when placement decisions have to be made, as Cave and Maddison's (1978) review of the literature shows.
Nevertheless, Hegarty, Pocklington and Lucas' (1982) examination of mainstreaming case studies is particularly informative here.
They consider two situations: one where unit provision is made available (on-site support in a special class) and one where children are individually integrated.
Generally, children are already selected for their communication ability, but although Hegarty, Pocklington and Lucas are optimistic about the provision they describe, it is clear that in language and interaction there are problems.
The presence of profoundly deaf children was viewed rather oddly in one situation:
The teacher in charge claimed that there were at least nine children who ‘linguistically could be good partials’ but not one was attaining anything like his or her true linguistic potential.
The presence of profoundly deaf children — even though by that stage  provided for in their own fairly self-contained class — was held responsible to a considerable degree.
(1982: 160)
However, what is most apparent generally in the provisions described is that deaf children are unable to interact, do not contribute to class lessons through speech, are subjected to distorted and exaggerated mouthings by teachers and pupils in order to convey specific information (i.e. not natural language interaction) and are unlikely to have secure peer group friendships.
There are claimed benefits in academic progress and in social and emotional maturity, but the solution to the basic problem of the language and learning environments cannot be taken to be solved in the mainstreaming option.
There have been a number of comparisons of learning environments for deaf children.
None of them are completely satisfactory because of the problem of control of ability and opportunity in the different settings.
The majority in recent times have favoured approaches with a sign language or fingerspelling element, though there have been studies to support written language as a most effective communication (White and Stevenson, 1975).
Brasel and Quigley (1977) present a well controlled study comparing ‘manual English’ with ‘average manual’(where little English was used by deaf parents), with ‘intensive oral’(parents trained in oral method) and with ‘average oral’.
The achievement results in English consistently followed the order above with the ‘manual English’ group out-performing all the others.
Brasel and Quigley's conclusion is that the early language environment offered by the use of signing improves the child's prospects in the learning of English.
This is a particular theme followed up by Conrad (1980).
His interpretation of his data is that the deaf child is linguistically deprived from the very beginning and it is this early lack of language stimulation which creates the problem.
He uses neurological studies of deprivation to show that early lack of speech is likely to produce later problems in speech perception and therefore production.
He attacks oralism as an additional depriving agent since it insists on having no further stimulation other than speech, when it is the language stimulation which is most important not the modality of stimulation.
In the logical development of this view it is the child who must choose.
This does not arise because of failure, but, rather, the use of Total Communication offers both spoken and signed stimulation which provides a range of alternatives for the deaf child.
From the earliest time, then, deaf children can have access to the language interaction which Wells (1981) insists is so important.
While Conrad tends to minimise the task for parents and professionals in learning BSL in a way which would allow it to be used with English, the fact remains that it is the language attitude which has to be altered.
Criticisms of the view of auditory deprivation (Bench, 1979) and of bilingualism (Arnold, 1982) tend to miss the point that language acquisition occurs through interaction.
Indeed, Arnold's claim that ‘the main enemy is deafness’ totally obscures all the previous research on the cognitive functioning of deaf children and the nature of child language.
Restrictions on the interaction of children with peers and care-takers necessarily limit the language access.
Both at home and at school, methodologies may fundamentally obstruct the negotiation of meaning and, in doing so, reduce the likelihood of deaf children enriching their language skills.
Both Brennan (1976) and Conrad (1979) suggest that for the profoundly deaf child, oralism provides this sort of obstruction.
The examination of this issue leads both Meadow (1980) and Freeman, Carbin and Boese (1981) to similar conclusions.
Meadow (1980) in particular emphasises early language intervention and proposes a form of Total Communication as the most effective approach.
She offers this view based on her earlier research that no evidence consistently indicates the supposed negative effects of signing on speech skills.
The problems of learning an additional system for parents are put to one side in stressing this need for early interaction.
The delay in placing children in Total Communication programmes frequently means that they are seen as ‘failures’, both by parents and by themselves.
The consequent problems are seen at every stage of subsequent development as the parents struggle to learn signing because their children were not ‘good enough’ to progress normally, and as the children have to come to terms not only with deafness but with the community of deaf people which has been shunned by their families.
Total Communication requires some explanation, both of concept and practice, and we will give this some attention in our next chapter.
Nevertheless, we can already detect the influence of the research which has led to it and its appeal to educators.
Garretson (1976), in considering the state of methodologies in schools in the USA, showed the tremendous acceleration in use of this approach.
He reported 88 per cent of schools he sampled had adopted a Total Communication approach and these, by and large, relied on the development of sign systems which more closely reflect English syntax.
The same change appears to be happening in the UK, but there are no easily available figures.
It is reflected throughout Europe, and in Tervoort's extensive study of 20 countries in Europe we can see the move toward the incorporation of signing in educational methodology: ‘There is no change in favour of oralism and there is an atmosphere of change in the other direction all over Europe’(1983: 143).
In general, the move is towards supporting the spoken language so that deaf children can more easily fit into the community as a whole, but perhaps the key  insight from Tervoort's study is the perception of the range of solution available to educators in different countries.
Tervoort describes four stages:
There appears to be a tendency to go from oral-only to speech with speech-supportive means such as fingerspelling or cued speech; from those there is a movement in the direction of these of sign to better disambiguate the spoken word; next comes a signed version of the spoke, language either with speech or without it depending on the circumstances; and finally.
the continue develops from signed Danish, Swedish, English and so on to Danish Sign Language, Swedish Sign Language, British Sign Language etc.
At that final stage the choice in favour of bilingual educational philosophy is a fact.
(1983: 146)
The critical point is that the four stages are progressive: educators move along from one to the other.
In any starting position, when the basis for change has been created the decision as to which stage should be contemplated is the key one.
The whole question of Total Communication philosophy depends on the point of entry into these stages.
We now need to consider how one makes this decision, how it is theoretically justified and whether the end point of bilingualism may be an inevitable consequence of the initial steps of educators.
Which sign language?
Inevitably when we reach the point of change in special education, the question is asked frequently and in different contexts and independently in different places, as to how the changes should actually occur.
However, the question in the way it is posed by educators usually calls for an answer in terms of commitment rather than of attitude in school or in society and the implementation has begun by the time the thought of research arises.
Action research has come about as a result of this common situation and what it tries to do is to evaluate what is already practice.
It acknowledges the lack of control groups and neat experimental designs and works with perceived values of change.
This type of situation does not permit classical techniques of research.
The widespread emergence of ‘action research’ is the rationalisation of this situation.
In these circumstances research monitors the extent of change and, most importantly, evaluates the degree of commitment engendered in those who participate.
The movements towards mainstreaming, towards earlier education and towards signing in schools, are of this type.
They have occurred because policy makers or practitioners have judged it to be appropriate to their views and implementation has begun.
This creates major difficulties for the examination of the effects of the change envisaged, but it does provide an explanation for the dramatic changes in policies which occur, most notably, in our case, the movement towards signing.
This is not to underestimate the importance of the change, but rather to try to understand its power and to understand the basis on which evaluation must occur.
Unfortunately evaluation is very difficult and has seldom been done in special educational practice.
Mainstreaming is a very good example of where our policies push beyond what our research has been able to show.
This is not to say that the policy-making is wrong or misplaced, but rather to make clear that our questioning of research and evidence is not always simple or effective.
The studies used as a basis for judgement are generally lacking in control because of the finality of educational decision making and placement (in the sense that we cannot return the child to an original or alternative placement a year later and be able to start from the same point again).
Key aspects are often ignored:
Teacher variables are rarely considered.
Programme variables where referred to at all are stated in gross terms.
It is assumed that the fact that teachers and pupils are together in a special classroom implies the presence of an educational programme relevant to the development of children; also that the presence of a teacher provides effective educational programmes…in practice none of these desiderata have been met.
(Tizard, 1974: 225)
Although this quotation concerns research in relation to mainstreaming, the same is obviously true of the implementation of educational methodology in deaf education.
It is perhaps trite to say that the educational policy is only as good as its actual implementation in the classroom , but it is a point overlooked in the search for a panacea in deaf education.
No method substitutes for the skill and sensitivity of the class teacher in the group interaction basis of a classroom.
A given administrative arrangement is neither good nor bad…what really counts is what is done with the group once it is established…
Among the questions which must be raised are the following: a.
How competent are the teachers in each setting for dealing with the specific characteristics of the child in question?
(MacMillan, 1971)
Again this draws on the subject of mainstreaming, and the subsequent questions raised,(b-e) deal with the actual level of functioning of children and other teachers in those circumstances.
In summarising the factors which lead them to believe in mainstreaming, Hegarty, Pocklington and Lucas (1981) return to attitudinal variables and cite the ‘enthusiasm of the headteacher’ and his ‘capacity to enlist the cooperation of staff’as key features.
What we can take from this contemporary debate is the realisation that although research can assess the effectiveness of signing in schools, the change to Total Communication is generally based on attitude or commitment, which minimises or ignores the teacher variable.
As a result, we can begin to understand Conrad's (1981) view that there is as yet no published evidence on Total Communication producing higher educational standards.
He relates this to the recency of developments and:
one would expect a large variation in the fluency with which teachers can instruct in sign language; many would have had no more than a relatively short course.
So it will inevitably be some time before this necessary information becomes available in any meaningful way.
(1981: 17)
However, we can point to a good deal of information on the effectiveness of signing in communication and in various aspects of language development (Moores, 1978; Quigley, 1979).
We have set out some of this in the previous chapter; here we are concerned with what methodologies are available within the overall heading of ‘signing in school’.
Types of signing available for education
This question ‘which types of signing should be used in deaf schools?’ is very like the question ‘which food is best?’.
The range of possibilities is considerable.
But one would tend, in the case of food, to ask for more details.
In what circumstances is the food to be produced, and what is the purpose of its use (to go on a diet, or to exclude certain elements such as meat)?
In addition, the food expert would want to know more about the local conditions and the alternative sources of nourishment available.
In practice the food expert would be likely to suggest a ‘balanced’ diet.
The same almost certainly is true of signing.
Local conditions, priorities and the actual setting in which the signing is to appear will determine suitability.
What is almost certain is that a range of methods is required, not a single one.
What is also clear is that no approach is simpler to use, to acquire, or to maintain, than any other; teachers and parents need access and knowledge of as many varieties of signing as possible.
Having said that, we can begin to distinguish the difference in type and, therefore, the difference in application of the methods of signing available.
We wish to make simple distinctions between sign languages (BSL, ASL and so on);sign systems , which will draw on sign language vocabulary but add features of the spoken language (signed English (UK), Signed Swedish, Seeing Exact English), or which have a manufactured vocabulary (Paget-Gorman Sign System);fingerspelling; sign vocabularies , which reflect the meaning of sign languages and spoken languages without necessarily adopting inflections from either (Makaton, Cued Speech); and Total Communication which involves a mixture of one or more of these with spoken language.
Sign language
The book so far has described what we know of BSL and its status as a natural language.
Sign languages and their dialects exist in every country we have researched, though the word ‘language’ may not be available to deaf people to describe it.
Hearing people may have had difficulty in access, but we have argued that this arises in the unequal status of the learner (hearing) and teacher (deaf).
Nevertheless, knowledge of sign language is crucial to every other application of signing and we will return to this point later.
Sign systems related to sign language
In Tervoort's (1983) survey he discovered six of his responding countries had a signed spoken language form (Finland, Ireland, Norway, Rumania, Sweden and  the Soviet Union), but he also discovered in a further five countries an ‘unofficial’ system of signs structured to reflect the spoken language.
In Denmark, Hansen (1980) describes a mixed language situation:
Signed Danish is a gestural/auditive language in which Danish is spoken at the same time as signs from the Sign Language are used for all words which have a concept, and as far as possible grammatical rules [are used]from sign language.
The number of pieces of information visually is equal to the number given auditively. (1980: 25)
This is perhaps the most fundamental principle of sign systems: no matter how much they are able to draw from a sign language they attempt to match their production to the spoken language which is produced simultaneously.
However, this signed Danish is much further along the way to sign language than the other approaches we will describe.
For example:
Spoken Danish: Where did you go to school?
Signed Danish (signs): WHERE YOU SCHOOL WHERE?
In signed Danish the words are spoken as in the upper line but only the signs in the lower line are articulated.
The last sign WHERE? takes the place of intonation in the Danish question where ‘school’ has rising intonation.
In Danish Sign Language the utterance would be: SCHOOL WHERE?
Hansen (1980) makes it very clear that signed Danish is not the same as the Signed English that has developed in the USA, and she believes it to be a more flexible and efficient natural language form.
At the same time:
Signed Danish is not Danish, when you cannot hear/distinguish the words — but another type of sign language, which has the primary advantage that hearing people can use it at the same time as they use spoken language, and the secondary advantage is that some — and only some — rules applying to the spoken language are conveyed to the deaf child.
(1980: 26 — 7)
Bergman (1979) also includes Signed Swedish under the title of a language, but her description of its history (and this history is repeated in many countries) makes it clear that the system has been constructed with specific aims in mind.
A committee comprising deaf and hearing people began in 1970 with a Swedish word list to establish which words had sign translations.
When the words had more than one sign equivalent, only one sign was used.
The principle aim of the approach was standardisation.
Extending this aim meant that signs had to be invented when no obvious word — sign equivalent existed.
The rationale for this approach is important since we see it repeated in country after country.
There are several reasons for the adaptation to Swedish…all of which are connected…with theories about SSL [Swedish Sign Language]and its role in the teaching of the deaf.
Adapting the ordering of signs to Swedish word order is supposed to result in the pupils learning Swedish with greater ease.
We know that the syntactic rules of SSL turn up in their written Swedish and so by analogy, children who grow up with Signed  Swedish should instead be influenced to use the correct word order.
Another advantage that Signed Swedish is supposed to have over SSL is that it is not ‘abbreviated’; every word is accompanied by a sign.
(Bergman, 1979: 16)
Additionally, the traditional uncertainty about sign language and its grammar was highlighted, in the need to link communication with speech and lip-reading.
Last, and perhaps most significant, was the fear that SSL was too difficult for hearing people to learn: Signed Swedish would be easier.
Bergman is openly critical of this emphasis:
SSL is claimed to be very difficult for (hearing) adults to learn; some go so far as to say that it is impossible.
What is meant is really that it is not possible to learn to sign like a deaf person, i.e. without an ‘accent’.
But of what other foreign-language learning do we demand that a native speaker of the language shall not be able to discover any deviations?(1979: 16–17)
We shall return to this specific point in considering all the systems; however, we should say that Bergman's (1979) discussion of Signed Swedish is perhaps the clearest examination of a sign system in relation to the native sign language.
Her conclusions are very important to our final discussion.
Distinct from Scandinavian developments have been those in the USA.
Bornstein (1979) provides an extended analysis of the different systems which have been devised as a result of the same pressures described above for Signed Swedish.
He picks out a number of similarly titled systems: Seeing Essential English (SEE I), Signing Exact English (SEE II), Signed English (SE).
These systems share a number of characteristics.
SEE I (Anthony, 1971) attempts to form compounds of base signs and signs for parts of words, affixes, prefixes and so on.
SEE II (Gustason, Pfetzing and Zawolkow, 1975) takes the compounding principle further.
Words like TODAY, TOMORROW and YESTERDAY become compounds because there are words/signs for TO + DAY, TO + MORROW, and YESTER + DAY.
SE (Bornstein et al., 1975) attempts to get round some of these problems by attempting to parallel meaning rather than form.
Marker signs are invented for inflected forms of English.
Bornstein (1979), however, is able to see weaknesses in all the systems.
The fact that it is impossible to borrow words from one language to another with exactly the same form and meaning means all such systems are a compromise.
The use of markers, while generally insufficient to mirror the complexities of English inflection, may well be still too complex for natural fluent use by English speakers.
The sign system thus involves a great learning task.
The use of signed English in the UK reflects the problems that all these systems produce both in development and use.
The particular principles adopted relate to attitudes and stated priorities, so there are schools where  something like the Danish approach is used, and other schools where committees have been formed to set out the principles of a formal system comparable to SEE or SE.
The predominant approach in the UK can be described as Manually Coded English (MCE), i.e. the priority everywhere seems to be to support the learning of English through simultaneous use of signs and English.
One problem this poses is that the Education Act (1981) specifically excludes from special educational provision children whose difficulties arise because of a non-English language background:
A child is not to be taken as having a learning difficulty solely because the language (or form of the language) in which he is or will be taught is different from a language (or from of language) which has at any time been spoken in the house.
(Education Act, 1981: ch. 60, 1.4)
Deaf children of deaf parents using sign at home may come under this rule; like ethnic minority children they must then be assessed in their native language prior to any Statement or placement.
This aspect of legislation has not yet been tested.
Although these systems are taught to teachers and are available for use in class, various factors appear to mitigate against full use of the systems by the teacher, and as we shall see when we discuss effects of the various approaches, something closer to the Danish system is often used.
Systems which are completely artificial .
The prime example of this type of system is Paget-Gorman Sign System (PGSS) which derives from a developed set of 21 hand-postures and 37 basic signs.
At times there may be an iconic overlap with BSL signs, but the system of inflection is totally different (fig. 13.1).
This system, devised to help deaf people learn language, is now used with children with severe learning disabilities as well(Rowe, 1982).
According to theoretical analysis by Crystal and Craig (1978), PGSS offers the greatest possibilities for accurately reflecting English.
In practice, as Rowe describes, it can be used with varying degrees of grammatical marking and would in fact be introduced to mentally-handicapped children in telegraphic form, slowly building to full English linguistic structure: e.g. (1) HALL,(2) GO HALL,(3) GO TO HALL,(4) GO TO THE HALL.
There are, in practice, no more than a handful of schools in the UK still teaching deaf children with PGSS.
Its use perhaps reached maximum interest in the 1970s but has declined as the move for MCE has developed.
However, there is still considerable use among children with severe learning disabilities.
Kieman, Reid and Jones (1982), in a survey of special schools using some form of signing, claim 34 per cent of schools responding have a PGSS programme and 33 per cent of children had some PGSS in their education.
These children included educationally-subnormal, physically-handicapped and autistic children.
It is   probably within these groups that systems like PGSS, which do not rely on contact with native signs, can be most effective.
The prime aim is spoken language and the system is meant as a stimulus and a support.
Because these systems are not ‘natural’ their structure is complex and even the knowledge of English can prove to be unhelpful when markers represent meaning and not form.
Fingerspelling
The origins of fingerspelling are rather difficult to trace, though there are better records than for signs.
In most languages with writing systems alphabetic fingerspelling has been available for over two hundred years.
The use of finger shapes to convey meaning can be seen even further back in Christian art where ‘secret’ signs were available for God, the Trinity, and so on.
Fingerspelling as it  exists today consists of a direct alphabetic representation of the language as it would be written down.
In BSL this is two-handed but in most countries the system used is one-handed (see fig. 6.12, page 125).
As far as can be made out, systems of fingerspelling have always come about by hearing invention.
Digiti lingua (1698) is the earliest published system which seems comparable to currently used fingerspelling in the UK, and this was written by a ‘friend to the deaf’.
However, alphabets were often designed for use among hearing people (Dalgarno, 1661) as a sort of linguistic exercise to show speech was not the only communicative agent.
Fingerspelling requires an unambiguous representation of each letter of the alphabet in order that words from the spoken language can be produced on the hands letter by letter.
Its concept is more or less universal, although its implementation is not.
In China, although a system has been proposed and taught, it is still not used by deaf people.
The same is true in Israel.
Both these countries indicate that the spoken language base is unnecessary for the specification of places and people (a particular use which hearing users make of fingerspelling), since fingerspelled names are not used.
A comparison of the UK and USA also indicates a difference in function and use of fingerspelling.
In both countries fingerspelling has become incorporated into sign language communication and deaf people will use fingerspelling with one another.
This produces a ‘borrowing’ from English which has been described by Battison (1978) for ASL, and Woll (1981) for BSL.
The descriptions indicate differences in use of fingerspelling such that BSL fingerspelling occurs primarily in place names and people's names, while in ASL initialisation of signs is a primary aspect of borrowing.
Initialisation involves a change of handshape to represent the first letter of the English translation of the sign (see chapter 6).
An important aspect of fingerspelling borrowing is the adoption of the fingerspelled representation, or part of it, as a sign.
We have described this process earlier (chapter 6), and it seems to occur in every case where fingerspelling has been available for some time and there has been a strong hearing influence.
Fingerspelling does not, therefore, stand alone as a system but has in most cases become part of sign language for adult deaf People.
There are educational approaches where it has been used as a method.
The ‘Rochester’ method of fingerspelling with speech and lip-reading has been in use in the USA for over a hundred years (Savage, Evans and Savage, 1981).
Interestingly, this system was initially supported by the oralist lobby (Bell, 1887).
More detailed description of the approach has been set out by Savage, Evans and Savage (1981) and an evaluation of its effectiveness within a Total Communication programme in the UK is provided, which we will examine in the context of all the systems.
Systems as partial support
We wish to examine two approaches under this heading: Cued Speech and Makaton Vocabulary.
The former is a system superficially like a support for lip-reading, but potentially of value in all communication.
The latter is a developmental vocabulary primarily used with deaf children with learning difficulties.
Montgomery (1981) classifies Cued Speech as a phoneme transmission system similar to the Danish Hand — Mouth system (Forchhammer, 1903).
The latter was used as a support within the oral method, while Comett (1975) would identify Cued Speech as a manual method.
The system involves classifying lip-patterns which look alike and providing cues to disambiguate them.
The cues require eight hand patterns and four hand positions, all executed by the dominant hand somewhere close to the side of the face.
They are therefore expected to be within the visual focus when children watch the teacher's face and lips.
The system has been taken up in many countries, including the USA, UK and Australia, but effective evaluation has still to be done.
Certainly added visual information helps lip-reading, but, since Cued Speech is based on spoken phonemes to which deaf children may not have access, it is difficult to see how it affects language development as a whole.
The Makaton Vocabulary was devised as a ‘language enabling device’ for people with learning disabilities (Walker and Armfield, 1982).
It was originally used with deaf mentally-handicapped patients.
it consists of a developmental sequence of signs taken from a BSL dialect and carries a simple formal system of teaching the signs to children and adults.
The approach used is simple reward-based learning.
The basic vocabulary of around 350 signs can be combined in sentences as the child develops the ability to use and understand signs.
This latter aspect has developed without knowledge of BSL and has led to an uninflected form of signing which has been slow to change.
The system is now in widespread use.
Kiernan, Reid and Jones (1979) indicate its use in over 80 per cent of schools for children with severe learning disabilities.
Its use is greater than BSL or MCE (children with severe learning disabilities are eight times as numerous as profoundly deaf children).
Its prime value is with those with severe learning disabilities where communication growth is likely to be limited.
Nevertheless, the principle is that the 350 signs learned should be overtaken by the ‘release’ of spoken words, such that spoken English becomes the means of communication.
As Montgomery (1981) points out, the Makaton Vocabulary is not suitable for the general population of deaf children due to its limited vocabulary size.
The originators of the system claim its use with young deaf children in the normal range (Walker and Armfield, 1982), but would tend  to agree about its ideal application to severe communication and learning disabilities.
Total Communication
Total Communication involves the simultaneous use of one or other of the systems described above, together with oral language.
It was first adopted by Denton (1970) to describe practice at the Maryland School for the Deaf.
It is a description of a logical response to impaired communication in any ‘channel’ by the use of additional channels.
In itself it is not a new idea, and it shares much with the combined method which was the basis for deaf education in the UK in the 19th century.
Savage, Evans and Savage (1981) describe it as a revivalist term for a philosophy.
Montgomery defines it as follows:
mention should be made of Total Communication which is often wrongly equated with ‘simultaneous’ methods of speaking and signing ‘Siglish’at the same time.
More accurately, however, the Total Communication Approach is a philosophy rather than a method and as such is in contrast to ‘the oral-way-of-life’ oral-onlyism, or any restrictive, prohibitive, Limited Communication Approach.
The TC approach uses all communication channels available to children without the counter-productive forceful insistence on the use of more defective channels.
An encouraging, positive, relationship is part of the philosophy.
(1981: 4)
This philosophy offers the children more.
It fits the principles set out by Conrad (1980) in allowing language stimulation by making available a number of forms of code.
Unfortunately, it does not carry with it a directive as to which code or system is to be involved, or indeed whether any code is actually usable internally by the children who experience it.
The only thing in practice it excludes, at least in simultaneous mode, is BSL (even though the philosophy will allow it).
Evaluating the approaches
Given our general theme, that it has been attitudes which determine methods, it is perhaps not surprising for the reader to discover that the amount of research on the effects of the systems of signing is very small indeed.
There are, of course, major problems in evaluating programmes, as we have already discussed, but one could perhaps have expected more concern about the amount of information transmitted by each method and about how each works in the classroom.
PGSS and Makaton have received perhaps the least evaluation.
Kieman, Reid and Jones' (1982) review concludes that any evidence available is weakened by poor methodology and/or ineffective description of what was measured.
Fenn  and Rowe (1975) found PGSS use with deaf multiply-handicapped children produced some combining in sentences.
Inglis (1978) found some evidence of PGSS coding in memory in multiply-handicapped individuals.
There has been slightly greater interest in Cued Speech, but again the findings have mainly consisted of case studies or unsubstantiated claims.
Ling and Clarke (1975) found some limited evidence of better performance with Cued Speech as compared with speech-reading on its own, but performance in both was poor.
Clarke and Ling (1976) studied only eight children and conclude that Cued Speech produces better performance than speech-reading.
A more detailed, longer-term study by Mohay (1983) followed three children through early language development stages both pre- and post-Cued Speech programmes.
The Cued Speech programmes varied between 6 months and just over 2 years.
Her findings indicate many difficulties with Cued Speech and her conclusions do not support the proposal that Cued Speech aids spoken language development:
With the introduction of Cued Speech, the frequency with which the children used communicative gestures dropped dramatically without a corresponding increase in speech production.
Consequently the overall frequency of their communication was depressed.
(1983: 25)
The evidence for these systems is generally personal and tends to reinforce our view that it is attitude of the teacher or parent which determines adherence to a given system rather than any objective verification.
There is very little objective reason for choosing among these approaches at the present time.
Fingerspelling has been available longer and there have been studies of it.
Savage, Evans and Savage (1981) show that adding fingerspelling to lip-spoken messages increases comprehension significantly; unfortunately, this increase results in only 50 per cent understood at 14 years of age.
Moores, Weiss and Goodwin (1973) had slightly better findings with increase in comprehension of up to 61 per cent.
In general the gap between lip-reading with fingerspelling, and lip-reading alone is greatest for comprehension of larger units such as sentences, and least for single words.
These findings are similar to those of Klopping (1971) and Montgomery and Lines (1976).
Bornstein (1979), however, points out the problems of using fingerspelling which is meant to follow spoken language exactly.
A maximum of around five letters per second (very fast) gives only 60 words per minute transmission, when a normal spoken rate would be about 150 per minute (and that would include pauses).
To accompany fingerspelling, speech would therefore need to be slowed down considerably, or parts of the fingerspelling would need to be omitted.
This is what tends to happen (Reich and Bick, 1976).
Bornstein (1979) also suggests that fingerspelling would not be useful for young children since it involves fine perceptions and handshapes which they themselves may not be  able to form.
However, we have already seen that deaf adults use fingerspelling with infants (Maestas y Moores, 1980), and it is an important part of the Russian fingerspelling approach described by Moores (1978).
The most significant finding is that when signing is added to fingerspelling, communication level increases further.
Savage, Evans and Savage (1981) show that fingerspelling comprehension of 55 per cent increases to 76 per cent if signing is added.
Moores, Weiss and Goodwin (1973) similarly found comprehension to increase from 61 per cent to 71 per cent with the addition of signing.
Klopping (1971) produced the same pattern.
White and Stevenson (1975) offer further support for signing as part of Total Communication over oral methods, though their study was relatively small and involved an interpreter presenting information.
Sorensen and Hansen (1976) show that deaf children using Danish Sign Language for communication in pairs produce 70 per cent levels of comprehension.
The major question, of course, concerns educational effects of signing systems and these sorts of effects are most difficult to trace.
Savage, Evans and Savage (1981) could find no effects on reading performance of having introduced a one-handed fingerspelling system, though, not surprisingly, part of the difficulty arose in the methodology of the comparisons made.
Quigley (1969) did find the Rochester Method (fingerspelling with lip-reading) better than the oral method and also better than signing for producing success in English.
Brasel and Quigley (1977) reversed this finding in favour of signing producing the best English development.
The Manual English group (who had parents who were ‘language competent’ deaf persons) were better than the average manual group (whose deaf parents' written language was ‘grossly deviant from standard English’).
There is, however, some problem in this last comparison, since family income in the first group was $15,972, while in the latter it was only $9,300.
That is, although a socioeconomic factor weighting was used in statistical tests, the ‘class’ difference between the two groups is sufficient to explain the difference in outcomes in performance.
Gustason (1983) reports progress in reading performance, as measured in a test of syntactic abilities after a period in a programme using Signing Exact English, as compared to the norms for deaf children.
There was, however, no control of length of exposure or parent/teacher fluency and so the effects may be an underestimate of what can be achieved.
Gustason indicates that this may relate to attitude and shows further evidence on positive attitudes towards both ASL and Manual English among teachers, The problem which arose among deaf teachers was whether it was possible for teachers to use ASL in teaching.
It is this last uncertainty which influenced both Conrad (1979) and Meadow (1980) in suggesting that an MCE form of signing is most likely to satisfy deaf children's needs.
We are left with a picture of general support for the use of signing.
The evidence which exists is not comprehensive, nor does it adequately differentiate between different systems in terms of educational progress.
The least favourable reports are on systems which only partially embrace signing or fingerspelling, and systems based on fingerspelling alone are not possible unless speech is slowed down considerably.
This leaves signed English systems as the most likely candidates for success in education, but it is also appropriate to introduce the ‘bilingual’ possibility of sign language.
The purpose in doing so is to examine how signs can, in psychological and linguistic terms, actually form part of the cognitive system.
Signing for cognition
A major problem arises in the adoption of a signing approach, and that is its effectiveness, not from the teacher or parent ‘s point of view but from the child's point of view, as a device for carrying the cognitive processes.
Educators might argue, as did Alexander Graham Bell, that although sign language could be a vehicle for thought it was not the ‘right’ vehicle, nor did it produce the ‘right thoughts’.
Given our current state of knowledge of sign languages, it is obvious that these comments are no longer appropriate and that BSL can be treated as an effective cognitive component in development.
We have, therefore, two possibilities to offer at this stage of our thinking: a simultaneous approach offering a mixture of BSL and English presented concurrently by teacher and pupil, or a bilingual approach where both BSL and English are accepted and used as separate languages.
The latter, which seemed so strange even a few years ago, is now available as a result of our understanding of sign languages and of the developments in foreign spoken language learning.
Even ten years ago the idea that English-speaking children should be educated completely in a foreign language for every subject, including science, without actual specific prior tuition or without reinforcement at home, would have been considered strange to say the least.
Yet throughout Canada there are total immersion schools where children forego their parents' mother tongue to be taught wholly in French.
This has been the practice in many countries internationally, but our sudden realisation of its effectiveness in creating bilingualism has made it the major discovery in language acquisition.
The first point is that educating through a language which is not the parents' own, does not produce a deviant development.
Secondly, there is nothing to suggest that using two languages detracts from either one of them or that it produces continued interference.
Thirdly, the ease with which children can  switch from one language code to another has astonished educators.
We can therefore suggest that bilingualism is an acceptable concept within education.
There are differences for deaf children.
To have BSL in school we would need to have native users as teachers, i.e. deaf people or teachers whose parents were deaf.
The first is virtually impossible in the UK because of government legislation, and there are relatively few teachers with a native knowledge of BSL who have not been told in the past that it is an impoverished way of communicating.
A further difference is that the other language, English, is not learned naturally and probably has to be ‘taught’ rather than simply acquired through access.
For this the school has twin responsibilities for the presentation of both languages; it would need to be bilingual itself.
It is this approach which Sweden has begun to adopt.
Ahlgren (1982) describes the beginnings of this bilingualism where a ‘formal description’ of written and spoken language is being found through sign language.
That is, written and spoken language have to be taught through an awareness of Swedish Sign Language and the perspective this creates for the learning task.
This adds greater pressure to the bilingual setting, but is the first real attempt to consider the implications of bilingualism for deaf children.
We then find ourselves with these two approaches: the simultaneous and the bilingual.
Which offers the most effective cognitive code?
The first should create English-like codes, while the latter a natural language code different from English.
Virtually no work exists on this critical topic.
All that is available is simple theorising.
Baddeley's (1979) work on speech coding as basic to reading development has direct application in studies of dyslexic children, where speech coding can be shown not to occur.
Conrad (1979) shows deaf children do not develop speech coding easily and do not read well.
The purpose of MCE or BSL in education has to be to create a code upon which the processes for reading can develop.
As we have seen, however, sign codes, although they can be shown to exist and function as language codes (see chapter 10), do not behave in exactly the same way as speech codes.
The notion that MCE somehow models the speech code by allowing the child to see English word order, which can then be internalised, is not theoretically viable.
If one were to suggest that in order to learn French we should first practise and watch sentences such as‘He makes of the sun’ in order to prepare the way for the sentence ‘Il fait du soleil’, it would be ridiculed by modern language theorists.
In addition, the stated view that in MCE or Total Communication children receive bimodal or multi-modal stimulation, has to be examined very carefully.
From the hearing teacher's point of view what occurs is a mixture of modes: the oral/aural (through which verbal information passes for the teacher), the non-verbal  (facial expression etc., through which emotion is conveyed), and the manual (through which sign language passes).
From the profoundly deaf child's point of view the non-verbal is part of BSL, so the last two ‘channels’ are the same, and since the child does not hear effectively, the oral/aural ‘channel’is also primarily visual.
So, from the child's point of view what is experienced is visual and, thereby,unimodal .
The child is not choosing from modes but accepting this visual mixture.
Quite apart from this we can show that MCE is not performed consistently or accurately enough to provide effective codes even in this unimodal situation.
Teachers using simultaneous communication have been shown to present deficient models of English syntax in their signing (Marmor and Petitto, 1979; Kluwin, 1981).
The teachers are not untypical in their problems with two language codes.
Wickham (in press), in a study of teachers and children in the UK, shows the same problem of the ‘drop-out’ of information in teachers' use of simultaneous communication, Maxwell (1983), in a direct attempt to examine the effect of simultaneous communication using MCE on deaf children's writing, produces the results one might predict from the above and from our preceding discussion of BSL.
The children do not make a direct transition from structured signs into English written grammar; in fact, they rely on structures in ASL they already know, and this forms the basis of their task solution of writing down English from sign users.
The errors which occur could be explained in this way.
It seems likely that access to signing in school prompts the development among children of a ‘natural’ sign language which forms the language code, and that this occurs independently of the visual mixture offered by teachers.
This view receives support from the work of Livingston (1983).
None of this, of course, says that MCE cannot be effective.
We are presenting a view only that educational effects cannot be interpreted without a full understanding of sign language.
Parents, teachers and those professionals around deaf children need to understand the significance of sign language development and its emergence from what, in the past, they have often classified as playground gestures.
If on close inspection, educators can begin to understand the great importance of these supposed ‘gestures’ in portraying the syntax and semantics of sign language communication, then a more effective view of the children's needs in language will emerge.
The possibilities of Total Communication are colossal if the practitioner really understands what the children actually perceive when they see teachers using it.
The full range of information available in Total Communication is only available to the hearing teacher; deaf children have to piece together what the visual mixture actually represents.
Not surprisingly, when we asked deaf people to examine videotapes of teachers using simultaneous communication, their rating of effectiveness closely matched their  rating of the teachers' use of facial expression.
The information available is primarily on a single dimension and it is evaluated in sign language terms.
We therefore return to our original view.
In choosing systems of educating deaf children with signs, it is attitude which has determined the choice.
The evidence is not sufficient for any protagonists of particular approaches to feel satisfied.
The theory of MCE is inadequately thought out and would not be supported in language learning fields.
At the same time, we have still a great deal of development work to do to make the bilingualism which has become so accepted in other language fields directly applicable to deaf education.
At least the beginnings of the attitude development are there.
Gustason's (1983) findings on positive views of ASL by teachers is augmented by Stewart's (1983) finding of attitudinal change towards ASL being part of deaf children's bilingualism.
While this is seen within Total Communication programmes in education, there is no doubt that acceptance of BSL, ASL and so on offers the greatest hope for the development of effective education for deaf children.
Only through awareness of, and agreement on, the value of each aspect of communication can we hope that educational methodology will progress.
The key is the understanding of deaf children's processing of their own language, and it is this which requires our immediate and continued attention.
Developments for sign language
Our entry into the field of study which encompasses the language of deaf people came about in searching for an educational solution for deaf children.
The swings of attitude so clear in the historical analysis of deafness had once again created a climate of opinion where the predominance of one methodology could be questioned.
The simplicity of our initial beliefs about how signs might be used to alleviate the plight of deaf pupils was quickly overwhelmed when we realised the extensiveness of sign language itself.
The motivation for our search was to see how signs might support the spoken message in schools, how deaf children could be given the benefit of the happy accident which allowed two modalities to be used simultaneously to present two languages.
Right from the first evening of video recording, when we realised that BSL (or deaf people's signing) was not only a manual language, because of its animated involvement of the deaf person, it became clear that the key to understanding the learning task for deaf people lies in the examination of the language itself.
BSL is fundamental to the cognitive and linguistic representation which deaf people use.
This awareness was a growing one, not a sudden flash of illumination, not a conversion at all but rather a slow, painful, at times embarrassing progress towards competence in communicating with deaf people.
The more video recordings we collected, the more we talked to hearing professionals, the greater appeared the gulf between what hearing people told us about deaf signing and what deaf people were actually doing.
The direct questions we needed to ask of deaf people could not be asked adequately, since we were only language learners.
In the end, the understandings we have offered here came about indirectly from the actual learning process itself and contact with the deaf community as much as from the direct questioning we felt necessary at the initial stage.
The fact that these understandings are incomplete or ineffectively explained arises because of our intermediate stage of knowledge.
To expect a full grammatical statement of BSL after a research history which can be traced only to the mid-70s, would have been optimistic in the extreme.
All we have attempted is to provide the groundwork for expanding our comprehension of the structure of BSL and its relationship with other languages.
Perhaps that should be our first and major point: that BSL should be researched and evaluated as a language, and that this language, though apparently different in medium, shares similar grammatical processes with many spoken languages.
The sequence of studies we have carried out have derived from the tools available to us in the context of psychological and linguistic expertise.
These tools have often proved to be too language-specific and have often highlighted our need to re-evaluate concepts of language and communication.
The simple search for a solution to deaf children's educational needs had to be set in the broader context of the internal representation which BSL obviously offered to deaf people.
It became clear that we needed more time and more study before we could support both Conrad's (1979) and Meadow's (1980) conclusions that deaf children need the early support of speech-based signing.
As it turns out, our long way round through the deaf community, its history, sign language, memory and interpreting has given us an understanding of the concept of Total Communication and of how it might fit into the world of deaf people.
The priorities for the deaf community will have to come from deaf people themselves but the effective use of Total Communication by deaf and hearing people offers a way towards a sharing of views.
This is still an unbalanced sharing since spoken language drives the interaction between deaf and hearing; but it is a beginning.
It appears from Tervoort's (1983) work that Total Communication is an inevitable beginning for most countries.
Simultaneous combination of signs and speech usually confirms the dominance of the spoken language and its predominance as the target for the deaf in hearing society.
This may be vital for education but in adult life it can become a great barrier to deaf people's attempts to have access to information.
The language dominance case should not be overplayed, however.
Deaf people are in a situation which many minority cultures share.
Their chosen language is undervalued by the community at large and does not carry the technological information and knowledge that society's official language has come to have.
Minority groups under pressure change, and do so in a few generations: they become bilingual and accept the culture of the larger society.
But it is here that the difference re-emerges.
Deaf people have changed in the past, and continue to change as other minority groups do; they adapt and accept the broader society.
They establish their national identity with hearing people, and live and work with hearing people.
Deaf people's integration and acceptance of hearing society is constantly underestimated in extent and in the effort involved.
The one aspect of minority groups' change which is at present unavailable to deaf people is the adoption of spoken language: that is, unlike other groups, they do not acquire a substitute mother tongue for their own language.
If one accepts this, even if only for the present and not as an inevitable  fact for the future, then a responsibility lies with hearing society to meet not only the communication requirements of deaf people but also to understand and be able to work with this group in their language.
This has been recognised periodically since the 17th century.
Hearing society, however, has not taken up this responsibility nor seen that all society's members have a right of access to society's knowledge.
Statements on the supposed needs of deaf people can in turn be questioned by members of the deaf community themselves.
Their efforts to meet society's linguistic and cultural priorities have been immense.
The fact that these efforts go unrecognised has been a major element in the ‘failure’ labels attached to many deaf schoolchildren.
The deaf community might well attach the label ‘failure’ to much of hearing society's attempts to provide services to meet their needs.
The principal component, as always, is lack of language proficiency.
Nevertheless, recognition of the primacy of both languages under consideration would lead to more adequate performance at every level.
In suggesting that minority groups change and are integrated into society, we do not see this as a subtle attack on the deaf community.
BSL is not under threat in this sense.
Its status, once ensured, not only in theory but in practice, offers opportunities for increasing involvement for deaf people and ready access to accumulated knowledge.
Through the provision of proficient BSL interpreters in employment, further education and in law, an enormous range of choice is offered to deaf people.
BSL would be enhanced by this recognition and use.
When we apply these views to early childhood we begin to have a clearer picture of deaf children's future.
The educational problems we began with can be interpreted in a more realistic and systematic way.
The ‘fatal’ choices offered to parents and teachers at every stage of the child's schooling can thus be examined in the light of development, not as part of a race against failure.
Throughout, our view has been that it is teachers who are closest to children, and together with parents they are responsible for deciding how to use the tools at hand.
We have argued strongly that BSL is one of those tools and a very powerful one for language growth.
It is also a desirable one for the profoundly deaf young person and should be recognised for this positive value rather than for the negative one of its non-Englishness.
BSL will always be present in deaf schools despite the continued denial, in some circles, of its existence.
The choice of method within deaf education is obviously a major one and the lack of positive research to inform the choice is an added problem.
The purpose of our work has been to try to look at all aspects of sign language which might help those who make choices.
It would be foolish to see the outcome as  additional pressure, or as a thesis that only a single method should be available.
Our view is that knowledge of BSL is a key to the curriculum and to the teacher's function but that unless it is supported by appropriate methods the teacher's role will be limited.
Schools use methods to produce specific skills in children; these methods and the skills of teachers can be separated from the language of interaction.
Just as people can be educated in Welsh, or in immersion schools in Canada in French, so we can predict situations where BSL might be the sole medium.
One could propose BSL as appropriate in a class learning politics, or economics, or geography and in the same school find a signed English form in the teaching of English or science, or foreign languages.
One might quibble with these distinctions, but the proposal is simple: BSL is a language for conveying information and will be optimal where accurate and immediate knowledge is the goal; methods imposed on this medium will be tailored to specific educational goals and these will be a function of the priorities of teachers, parents and society.
The realisation of this will be a major step for progress in the deaf community.
In the last analysis, the study of BSL offers real insights to educators, psychologists, sociologists and linguists.
It is a newly discovered (or perhaps re-discovered) complex, natural language, linked to a cognitive representation which carries all the information of a society with limited sound.
At every level, it allows the test of theories.
Through research on this and other natural signed languages, greater understanding of the universal features of language, of how languages are created and learned and of how minority language groups relate to majority culture will be achieved.
We are only beginning to work out these implications and our chapters of research can only be a base for others to examine in greater detail how our theories work.
BSL research has only just begun and a great deal more will emerge in the coming years.
The prospects of interchange at the research level between deaf and hearing people are very good.
If acceptance can be achieved at this level, then there is great scope for development.
In the sections where we have dealt with the psychological aspects of sign language we can see a great deal of information of relevance to psychological theories themselves.
Just as spoken language was seen as central to education, so cognitive theories have relied on speech coding as a key process.
The fact that some deaf people appear to use a completely different form of coding just as effectively, makes it essential that some re-assessment of the models be made.
In the same way, second language learning approaches and applications such as interpreting have all drawn on spoken languages from communities which have  separate cultural and geographical identities.
The needs of people to learn the language which is not speech, and to use it to interpret for members of the deaf community, test these theories to their limits.
In each case, our conclusions have been tentative and we are content for the present to have made the links between these diverse disciplines and the study of sign language.
There remain a great many questions to answer for psychological and linguistic theories.
The way they are answered will benefit both hearing and deaf communities alike.