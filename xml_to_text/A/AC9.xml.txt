

Metalwork: Artifice and artistry Michael Cowell and Susan la Niece
Even after overcoming the tremendous technical difficulties of mining and smelting metals, the end result of all this endeavour was a raw material that still required the considerable skills of the metalsmith to turn it into artefacts, whether practical, artistic or both.
These skills are perhaps no better illustrated than by the finds from the ship-burial at Sutton Hoo.
This burial mound, probably for the Anglo-Saxon King Redwald, contained a rich treasure which gives a startling insight into the wealth of the ruling classes in seventh-century East Anglia.
It includes, amongst other objects, drinking vessels, iron weapons and chain mail, huge silver dishes imported from the eastern Mediterranean, a lyre, ivory gaming pieces, fine gold personal jewellery and regalia, and coins.
Understandably, the splendour of the goldwork — inlaid with garnets backed by gold foil to enhance their appearance — attracts immediate attention (plate 5.1).
But the skills involved are at least equalled by those lavished on some of the base metal objects, such as the iron sword with its complex design of pattern welding (see p. 88) and the intricately cast and decorated escutcheons on the hanging bowls.
The study of metalwork such as that from Sutton Hoo provides a variety of information about an individual site and the technical competence of the culture which created the artefacts: for example, suggesting the source of materials used, establishing the technology employed to prepare and alloy (mix) the metals, and determining how the artefacts were fabricated and decorated.
In some cases this involves experimental work to test particular theories of how certain processes were carried out and the ways that artefacts were constructed.
The quality or many of the individual objects makes the site of Sutton Hoo exceptional.
However, their archaeological importance is enhanced compared with that of equally fine stray finds because of the association with other artefacts from an excavated context.
The humble iron rivets, for example.
were all that remained of the boat at Sutton Hoo.
Individually they are of little importance, but collectively.
and excavated in their original positions, they are fundamental in establishing the ships lines.
The amazing variety of metal artefacts in the ancient world was created with only a few different metals: copper, tin, lead, silver, gold, iron, arsenic and zinc.
Initially the latter two metals only occur in alloys as they were not generally isolated in metallic form until the medieval period.
Copper and iron were most commonly used as both are tough and easily shaped.
Silver and gold are rare and were prized for their monetary value, appearance  and resistance to corrosion.
The remaining metals were mainly used to modify the properties of the others by alloying and for specialised functions in construction such as joining by soldering.
All of these metals were already in widespread use in their own right or in alloys over two thousand years ago and some have much earlier origins.
Native (natural metallic) copper was probably first used about the eighth millennium BC. and the earliest smelted metals, copper and lead, date from the fifth or sixth millennium BC.
Perhaps surprisingly, even today most of these metals are still of considerable importance and few ‘new’ metals have superseded them except for certain specialised uses; one metal unknown to the ancients which is used in large quantities today is aluminium.
Metal is one of the most versatile materials known; it can be melted and poured into a mould of almost any shape, hammered into thin sheets, drawn into fine wires and extruded as rods and pipes.
Most importantly, when a metal artefact is damaged or becomes redundant, the metal can easily be melted down and recycled into another artefact.
Furthermore, any number of metal components can be joined together to make complex shapes, leading to an almost limitless variety of products.
Some of these basic shaping methods were used to manufacture artefacts in metal from the very beginnings of metallurgy, when only native metals were available.
However, the quantity of metal available from native sources was limited in most parts of the world and consequently the major use of metals and alloys for artefacts was dependent on developments in smelting (see also Chapter 4).
Developments in alloying
Copper alloys
Copper was the first metal to become available in quantity for general use and the metal and its alloys have retained their importance to the present day.
Much early copper contains a small percentage of arsenic and this, arsenical copper, was the first alloy to be put to practical use throughout the ancient world.
Initially the manufacture of arsenical copper was accidental.
Arsenic is very volatile and was unobtainable by ancient smelting techniques, but arsenic minerals commonly occur in association with copper ores and an alloy with a few per cent can be obtained by smelting these.
However, once the properties of the alloy were appreciated, the ores were no doubt deliberately selected, or arsenic minerals may have been added to molten copper.
Arsenical copper could never have been easy to make or work with; during smelting, clouds of poisonous arsenious oxide are produced and in re-melting the alloy some of the arsenic may be lost.
It is not surprising, therefore.
that tin bronze replaced it.
Although tin sources are rarer than those of arsenic (or arsenic-rich copper), the metal is much easier to smelt and can be added in precisely controlled amounts to the copper.
Tin bronze had almost completely superseded arsenical copper by the end of the second millennium BC although the scale of this change varied considerably throughout the Old World.
Brass is another important alloy of copper (made with zinc), which first appears during the latter half of the first millennium BC and was widely used from the Roman period onwards.
It has an attractive yellow colour and in certain properties, such as its ductility, it is superior to bronze.
As with arsenical copper, there were difficulties in the manufacture of brass, because zinc metal is also highly reactive and volatile and was not isolated in quantity until the fifteenth century AD in India.
The alloy was produced by a process called cementation.
This involved heating zinc ore and charcoal with metallic copper in a closed vessel to about 1000°C.
The zinc, which at this temperature is liberated as a gas, is absorbed by the copper to form the alloy.
A process essentially the same as this was used for brass-making in Europe until the nineteenth century, when it became more economical to alloy metallic zinc directly with copper.
Iron Towards the end of the second millennium BC, but particularly during the first millennium BC, developments in smelting technology meant that iron became available.
Because of their superior strength and durability, iron and ultimately steel (the alloy with carbon) largely replaced copper-based alloys as the preferred materials for the manufacture of many functional items such as tools and weapons.
The greater abundance of iron ores over those of copper also meant that iron was more readily obtainable and cheaper.
Gold, silver and lead
Many other metals and alloys were of course discovered and used throughout the ancient world.
though few could rival iron and those based on copper for the sheer amounts used in artefact manufacture.
Gold and silver have attracted particular attention because they were used to make prestige items such as jewellery and regalia.
As a native metal, gold required no extraction by smelting.
However, it commonly occurs as a natural alloy with silver, and methods were therefore developed to purify the gold.
This was done by reacting the silver in the alloy with salt at high temperatures, leaving the gold unaffected.
Metalworking remains at Sardis in Turkey suggest that this process, called ‘parting’, was employed there in the sixth century BC to refine gold from the river Pactolus.
Most ancient silver was extracted from argentiferous (silver-rich) lead by cupellation, a process dating back to at least the second millennium BC, which involved oxidising the lead to molten litharge (lead oxide), leaving the relatively unreactive silver as the metal.
Lead was first used at about the same time as copper, though it was seldom used to make artefacts in its own right.
Lead was far more important as a metal added to bronze to modify its properties and to alloy with tin to form pewter and soft solder.
Soft solder is of course an aid to artefact manufacture as opposed to a raw material for overall construction, and is one of a whole range of alloys with more specialised applications in metalwork.
Metal properties and selection
Depending on the materials available, the choice of what metal or alloy to use for a particular artefact would be influenced mainly by its intended function and how it was to be manufactured.
Although many artefacts are made of pure metals, rather more are made of alloys.
The main reason for using alloys is to modify the mechanical and physical properties of metals to suit the item being manufactured.
By mixing metals it is possible to make alloys which are tougher, more ductile, have a different colour, a lower melting point, or flow more easily when molten than the individual component metals.
Bronze
Bronze illustrates the variety which is possible with copper-based alloys.
By alloying tin with copper to make bronze we obtain a metal which is much tougher than copper alone.
It is also more suitable for casting because its melting point is lower and the tin reacts with gases dissolved in the molten alloy, preventing porosity.
The precise properties of the alloy depend on the amount of tin added.
Up to about 10 per cent of tin gives an alloy that is red to gold in colour and ductile enough for easy shaping by hammering, provided that the alloy is annealed (heated to remove internal stresses).
Working without annealing increases the hardness but also makes the alloy brittle and ultimately liable to crack.
By selective working, though, part of an object such as a cutting edge could be made harder.
With 15 to 20 per cent of tin or more, the alloy becomes brittle and almost unworkable, although it can still be cast to shape, and as more tin is added it becomes whiter in colour.
The alloy is nevertheless still useful for a variety of purposes.
It is sonorous and therefore very suitable for making bells.
When polished it is also highly reflective and was thus widely used for mirrors.
The decorative properties of high-tin bronze were also exploited, for example in the surrounds to the escutcheons on the Sutton Hoo hanging bowl (fig. 5.1).
The properties of bronze can be further modified by introducing other metals such as lead.
Adding lead makes the alloy easier to cast because the melting point is reduced and the fluidity is increased.
The molten alloy will penetrate all parts of the mould more quickly before solidifying, thus allowing the craftsman to make more detailed and intricate castings.
However, lead is only slightly soluble in copper and forms a separate metallic phase in the alloy.
This means that leaded bronze is relatively weak and may explain why the statuette in Figure 5.2, which has a particularly high lead content of about 30 per cent, was broken at the neck.
Heavily leaded alloys were therefore not generally used for artefacts which required high mechanical strength.
In addition, too much lead spoils the finish of mercury- or fire-gilding (see page 90), so leaded alloys were avoided if this particular decoration was to be applied.
Iron
Although the mechanical properties of copper-based alloys are readily modified by working and heat treatment, they are not as versatile as iron in this respect.
Provided that iron contains some carbon, introduced by carburisation (heating under charcoal), it can be hardened by quenching, that is by cooling rapidly in oil or water.
The metal may be somewhat brittle after this but a final tempering process (heating to a moderate temperature, followed by slow cooling) relieves the internal stresses, leaving a hard and durable finished product which is mechanically stronger than bronze.
The whole process produces characteristic structural changes in the metal which can be detected by microscopic study of sections through the artefact.
The first known use of carburisation and quenching of iron dates back to the eleventh and tenth centuries BC in Cyprus and  Palestine.
Although the processes were used spasmodically after that, they were not applied consistently and effectively until the Dark Ages and the medieval period.
The study of metal use
The vast majority of functional objects and many prestigious artefacts have long been manufactured from copper and its alloys.
The analysis of these metal objects can range from simply identifying the composition of an individual item or its component parts to studying the general development of metal use.
The technique of atomic absorption spectrophotometry (AAS)(see glossary) is often used to analyse copper-based metals.
Apart from quantifying the alloying metals, it also measures trace metals which can sometimes be used to ‘finger-print’ an individual supply of metal (fig. 5.2).
The applications of copper-based metals were extensive, and as new alloys became available through developments in smelting they were exploited in new ways.
Evidence of how the properties of these metals were manipulated can indicate the technical level of a society at any given time.
To build up an impression of how metal use developed, many and various artefacts covering a long time span need to be examined.
The chronological introduction of different alloys can then be compared between different cultures and geographical areas.
A typical study of ancient Egyptian tools and weapons, particularly axes, shows that four copper-based metals or alloys were used from the early third millennium BC to the middle of the first millennium BC: ‘pure’ copper; arsenical copper (an alloy of copper with up to h per cent of arsenic); tin bronze or leaded tin bronze; and iron.
In a study of metal development such as this it is essential to examine datable or chronologically ordered artefacts.
Some Egyptian axes can be dated by association with datable material in excavation contexts and occasionally by an inscription.
However, the principal indicator is often typology, the way axe shapes changed over time to accommodate different methods of hafting and specialisation in use (fig. 5.3).
When the proportions of the dated axes made from the four copper-based metals are arranged chronologically (fig. 5.4), a trend is evident.
During the third millennium BC most axes were made of unalloyed copper and few were of arsenical copper, but by the middle of the third millennium arsenical copper gradually supplanted copper and this, in turn, was replaced by tin bronze and also some leaded tin bronze.
This development was of course gradual and there were long periods when several alloys were in use.
The alloys are entirely typical of other cultures in the Near East and elsewhere, but the Egyptians were rather slower to adopt tin bronze.
This may have been as much due to tradition as to limited supplies or tin.
Consistent with its fluidity and lack of strength, leaded bronze is mainly confined to decorative axes requiring detailed casting which were probably not produced for functional use.
Similar studies have been carried out on axes from the British Isles and, whilst the same alloys were used, the time scale of their introduction and use was quite different.
The advent of copper began much later, in the middle of the third millennium BC; whilst arsenical copper was used, it was replaced by tin bronze at a much earlier date.
by the beginning of the second millennium.
Arsenical copper use was therefore very shortlived in Britain, compared with Egypt.
Admittedly, the British Isles had substantial tin deposits, a resource which Egypt does not seem to have possessed.
As well as charting chronological developments in alloying, it is also possible to examine those changes dictated by the specialised use of artefacts.
We know, from representations of Egyptian axes on wall paintings, that initially the same type of axe was used as both tool and weapon.
Gradually, however, different shapes developed to suit the respective functions, and the visual appearance of the separate tool and weapon types suggests that different alloys were used for each.
In fact, the tools turn out to be either simply copper or arsenical copper (none are made of bronze), whereas weapons are never made of copper alone and most are tin bronze.
The few weapons that are made of arsenical copper contain more arsenic than the tools, thus making them potentially harder.
The weapons were therefore a superior product at the forefront of developments in alloying.
The extra cost of a harder and more lasting cutting edge was a wise investment — warriors would have had little time to re-sharpen their blades in the heat of battle!
An alloy which was not available to the ancient Egyptians because the required technology had not been developed was brass (oreichalcum or oreichalkos to the ancient writers), the alloy of copper with zinc.
The Romans produced coins from this alloy which, in the first century AD, contained about 25 per cent zinc.
They did not have to isolate zinc metal to do this but used the cementation process described on page 76.
Artefacts made of brass before the Roman period (that is, before the end of the first millennium BC) are rare, although there are numerous historical references to oreichalcum before this.
Many of these references indicate that the process originated in Asia Minor, in particular the region of Phrygia, near zinc ore deposits which are known to have been worked in antiquity.
This association was confirmed by analysis of early first-century BC Greek coins (fig. 5.5) from the region; some of these coins proved to be made of brass typical of the cementation process and they thus pre-date Roman use of the alloy.
They are probably the earliest reliably dated brass artefacts known.
A major restriction in the cementation brass-making process was the limited amount of zinc which could be introduced into the alloy.
Using the ancient method, the maximum zinc content was about 28 per cent, but as the process developed this increased to about 33 per cent .
To make brass containing more zinc than this required access to zinc metal.
Another disadvantage of the cementation process was that impurities from the zinc ore, such as iron, became incorporated into the alloy and had a detrimental effect on its mechanical and corrosion-resistant properties.
Such features enable us to recognise brass made using metallic zinc as opposed to cementation.
Analyses of Chinese statues and coins show that they did not make much use of brass until about the sixteenth century AD.
When they did make extensive use of it for coinage, however, the high zinc and low iron content of the coins indicates that they must have used metallic zinc rather than cementation.
Precious metals
In antiquity all metal was a valuable commodity and rarely wasted.
Metal extraction was difficult, sources of non-ferrous ores are particularly scarce and these, and the smelting sites, were often far removed from where the majority of the artefacts were eventually used.
Even base metals were probably recycled, as evidenced by finds of non-ferrous scrap metal hoards from, for example, the Late Bronze Age in Britain.
Traditionally, gold and silver were the most highly prized metals although occasionally other metals or alloys were equally in demand.
For example, Plato, writing in the first century AD, says that some regarded oreichalkos (brass) as being above silver, and more recently, in the nineteenth century, when aluminium first became available as an expensive novelty it was used in place of silver for prestige items.
As one would expect, the composition of precious metal artefacts has always been heavily influenced by economic factors and it became common practice to modify their value by alloying them with baser metals.
However, this also has a desirable practical side-effect.
Pure gold and silver are soft metals but, when alloyed together or with copper, a harder alloy is produced that is more resistant to wear and distortion.
This is clearly an essential attribute for articles of jewellery and functional items such as tableware.
Roman silver dishes, for example, are usually made of high purity silver, typically over 94 per cent , but also contain a small percentage of copper (about 3 per cent ).
The Roman refining techniques were such that they could easily have produced silver containing only traces of copper (under 1 per cent).
Therefore, the small amounts of copper were almost certainly added deliberately to harden the alloy without significantly debasing the silver.
The chemical analysis of precious metal artefacts can be difficult because their value and decorative finish usually prevent sampling.
The technique of X-ray fluorescence (XRF)(see glossary) is often used for these because of its non-destructive capabilities (fig. 5.6).
Alloys of gold and silver with baser metals have long been controlled by established standards, first for coinage and then for plate, such as the English sterling standard guaranteed by a hallmark.
Items were tested for compliance with such standards by assaying, a method of analysis, and by the use of a touchstone, a dark-coloured stone on which the colour of a streak of the alloy indicates its quality.
The sterling standard for silver (925 parts per thousand of silver with the remainder being mainly copper) has its origins in the fourteenth century and has continued virtually without interruption to the present day.
During the period from 1697 to 1720, however, the higher Britannia standard became the legal requirement.
Silver of this period should conform to the Britannia standard but does not always do so.
The maker's marks on some English watchcases suggest that some manufacturers continued to make their cases from sterling silver and this has been confirmed by analysis.
Occasionally the inner and outer cases of the same watch were made of silver of different standards.
Although the using up of old stock may be one reason for this practice, watchcase-makers were probably also reluctant to use Britannia silver because it is a softer alloy than sterling.
Apart from the increased likelihood of abrasion on an item being constantly handled, it was also important that the case did not become distorted, thus preventing precise closure.
A guarantee of the quality and quantity of precious metals for the purposes of exchange is coinage.
Until the last hundred years or so, the purchasing value of coins was closely related to the intrinsic value of the metal they were made from.
The value of this precious metal could be modified by alloying with baser materials.
The most direct way of revealing a society's economic state is therefore to study the quality.
or fineness, of its currency.
The most common pattern is one of debasement, that is, increasing amounts of base metal in the alloy (possibly coupled with a decrease in the weight of the coin), followed by occasional reforms.
A classic example of this was the debasement of the English silver coinage by Henry VIII to raise additional money for his treasury.
The systematic reduction in the standard from sterling (92. 5 per cent silver) to one containing only 33.3 per cent silver caused widespread inflation.
The coinage standard was subsequently reformed under Edward VI and Elizabeth I.
Although we are now familiar with coins bearing precise dates.
this was not usually the case with ancient coin series.
Trends in coin fineness can therefore often help to place an otherwise undatable series in chronological order.
For example, a study of the debasement trends of sixth-to seventh-century AD European gold coinage provided a basis for dating the Sutton Hoo ship burial.
The thirty-seven Frankish gold coins.
three coin blanks and two ingots found in the Sutton Hoo purse (plate 5.1) belong to the Merovingian series.
Unfortunately Merovingian coins do not carry explicit dates although some examples can be dated by, for example, association with other coins in hoards.
When these dated issues were analysed a fairly steady debasement trend was discovered and this allowed the approximate fineness of the coinage at any particular time to be charted.
By comparing  the fineness of the Sutton Hoo coins themselves with this trend, it was possible to say that the basest and therefore latest coins in the purse were made in the 620s AD, thus defining the earliest probable date for the ship burial.
Manufacturing techniques
The choice of manufacturing technique is to some extent governed by the metal or alloy used and by the intended finished shape.
For objects which need some thickness of metal, like ingots or axes, casting is the obvious method, while others, like fine wire or thin sheet metal, need extensive working.
In many cases, however, the method used is not immediately obvious.
For example, a bowl may be formed by casting, by hammering up the sides from a fiat disc, or by a combination of casting (for the basic dish shape) and working up details, like the rim.
In rare instances, there is still evidence of manufacturing methods, for example the clay moulds used for casting bronze bridle bits and other equestrian equipment found at the Iron Age site of Gussage All Saints or stone moulds for weapons (fig. 5.7).
Other clues to the manufacturing process might be found by examining the object itself.
In casting, the molten metal may have squeezed between the joins of a mould, solidifying as a seam-like ridge known as a casting flash.
Casting flashes can often be seen running down the sides of objects such as bronze palstaves (fig. 5.8), which were cast in two-part moulds.
The ends of the chaplets (metal pins used to hold a clay core in position inside the mould of a hollow statue or vessel during casting) may show up as small patches of a different alloy on the surface of the finished piece.
The clay core is usually removed after casting but the chaplets, which are made of an alloy with a higher melting temperature so that they will not melt during the casting process, become embedded in the metal.
Similarly, concentric lines radiating from the central pip on the base of a Roman silver dish reveal that it was finished on a lathe (fig. 5.9), and the impressions left by the craftsman's hammer can be seen on the sides of a brass Islamic jug.
Where none of these clues are apparent, the answer may sometimes be found by examining the internal structure of the metal itself.
Polished metal looks as smooth and featureless as glass to the naked eye but, unlike glass, it is a crystalline material; it solidifies as a network of tiny grains which can be seen if the metal is etched with a dilute acid and examined under a microscope (fig. 5.11a).
If a lump of cast metal is hammered and annealed, the structure will be modified (fig. 5.1 lb).
The microstructure seen is influenced by the composition of the metal and the treatment it has received.
It was this characteristic of metal which revealed the manufacturing history of a bronze stand of the Italian Late Bronze Age (1250–900 BC).
It belongs to a group of stands and tripods made in Cyprus and Sardinia which were probably used to support round-bottomed ceramic vessels.
The stands are composed of a series of metal rods (fig. 5.10), and two possible methods of construction had been proposed.
Either they were made up of a large number of bronze rods, hammered to shape and soldered together.
or they were cast by the lost wax process from a model made of wax rods.
There was no decisive evidence from examination of the surface, from analysis or from radiography, of which technique had been used.
However, examination of the microstructure of the metal at a convenient break provided conclusive proof that the stands had been made by casting: the structure is typical of a cast bronze, with 15 per cent lead in the alloy (fig. 511c).
Joining techniques
Many metal objects are made of more than one component.
Mechanical joins such as rivets are easily recognised but, from as early as 2500 BC in Sumer, smiths developed methods of joining one metal with another of a lower melting point.
Soldering alloys are usually categorised as either ‘soft’ or ‘hard’.
The main difference between the two is the melting point of the solder.
A temperature of 450°C is usually accepted as the upper limit for soft solders, whereas hard solders have a higher melting point.
In antiquity, regardless of the metal being joined, soft solder was generally tin or lead or an alloy of the two.
Soft solder joins like a glue, without significant interdiffusion (or exchange) with the metals it bonds, leaving the composition of metal and solder essentially unchanged.
Hard solders, on the other hand, were usually of the same metal as the object they were used on, but alloyed with a few per cent of another metal in order to reduce the melting point.
For example, the ideal composition for a solder to attach a silver handle to a silver jug would be 28 per cent copper and 72 per cent silver.
This is the silver copper alloy with the lowest melting point (780°C).
known as the eutectic composition.
Hard solders join by interdiffusion at  high temperatures with the metals being bonded, so that composition at the join will be somewhere between that of the solder and that of the object.
Soldered joints are often difficult to spot visually, but radiography is helpful for detecting them if the solder is denser than the rest of the object or if there is a cavity at the joint.
The technique used is much the same as that used in hospitals to find fractures in bones; where the metal is broken the film is blackened by the X-rays which pass unhindered through the break; where the metal is densest, more of the X-rays are stopped and the film remains pale.
The image in Figure 5.12 of an inlaid Islamic brass ewer is formed by X-rays passing through the ewer and on to a sheet of film beneath it.
Unlike a conventional photograph, an image of both sides of the ewer is produced on the radiographic film.
The silver inlays show up as pale areas because they are denser than brass to X-rays.
What the X-rays reveal, which cannot be seen on the surface, are the soldered joins at the neck, handle and base as well as around the hole for the missing spout.
The tin lead soft solder used on the ewer is very dense to X-rays and appears as white patches on the radiograph.
Radiography can reveal the original construction of an object even when it is so corroded that no external evidence is left.
The great ship mound of Sutton Hoo.
which was probably the burial place of the East Anglian King Redwald who died in the seventh century AD. contained a wealth of fine metalwork including a sword.
Its hilt was decorated with fine garnet work but the blade was broken and rusted.
However.
a radiograph of the pieces revealed that it had not been made from just one piece of iron, but from many welded together.
Using the radiographic evidence, an experimental replica of the blade was made by a modern smith from eighteen laminated rods of twisted wrought iron welded in the same way.
The result, when polished, was a beautiful interwoven pattern on the surface of the blade (fig. 5.13).
In most cases metal is joined with metal, whether it is riveted, soldered or welded.
However, radiography of the fine pair of Celtic bronze wine flagons from the site of Basse Yutz in France seemed to show that the bottoms of the flagons were not attached to the sides.
further investigations disclosed that they were in fact glued on with a resinous adhesive which appeared transparent to the X-rays.
Indeed, use of organic adhesives in metalwork may have been more common than would appear from the surviving archaeological record.
Joins on silver or gold objects made with silver and gold solders cannot usually be distinguished by radiography because they are approximately the same density as the metals they join, although they can sometimes be identified by colour difference or porosity when seen at high magnification.
Some joins.
such as the fine solder work required for gold filigree and granulation, cannot be seen even at high magnification.
Spot analysis by microprobe or EDX analysis (see glossary) in a scanning electron microscope (SEM)(see glossary) can detect the solder points by the minor changes in composition.
Figure 5.14 shows a panel of gold filigree work from an eighth-century Irish paten as seen in a scanning electron microscope.
Etruscan goldsmiths used minute granules of gold.
less than 0.5 mm in diameter.
The use of conventional solders to attach minute granules of gold presented great difficulties to the goldsmith who had to keep them in position during soldering and avoid flooding the delicate work with solder.
These difficulties could be overcome by using finely ground copper carbonate rather than metal, and mixing it with an organic glue.
The glue held the granulation in place and turned to carbon when heated.
reducing the copper carbonate to metal.
The copper metal reacted with the gold to form a bond.
There was no surplus solder to spoil the work, but this makes it very difficult to detect.
The most important factor in choosing a solder is that it must have a lower melting point than the pieces to be joined.
Where several components had to be soldered together it was vital that the heating for the last piece to be attached did not melt the solder already in place.
If the heat could not be sufficiently localised to avoid this, then the first solders had to have a higher melting point than the subsequent ones.
X-ray fluorescence (XRE) analysis (see glossary) of solders used on Roman silver suggests that the Roman silversmith did indeed use several different solders which could have given him a working temperature range from the melting point of silver (960°C), down to 180°C.
It has to be remembered that the analysis of a soldered joint will not be identical to the composition of the original solder alloy because, unlike adhesives, hard solders bond with other metals by diffusion.
This means there will be some exchange between the solder and the metal which will alter the composition of both.
Decoration and finishing
Metal lends itself to a wider range of decorative techniques than most other materials because of its physical properties, particularly its ductility, which allows it to be twisted into wire or inlaid with other metals and even other materials such as gemstones.
It can be engraved, embossed, covered with filigree wire, enamelled, patinated and plated.
The range of decorative techniques which have been at some time applied to metalwork is a subject for many books, not just a few pages.
This section will therefore only touch on some of the techniques which have become better understood as the result of scientific research.
There are several approaches, the first being study at high magnification using an optical microscope or scanning electron microscope (SEM)(see glossary).
The second is analysis, for which the method will be dictated by the material, potential sample size and the information needed.
Replication experiments are another possible approach.
Attempting to copy a decorative technique can confirm or disprove that it produces the same appearance and microstructure observed on the original item.
and it is also useful to assess the practical difficulties of the technique.
In practice, a combination of scientific approaches is usually needed.
Plating
Gilding, silvering and tinning (all involving the application of a thin layer of metal on to another metal) have been used since the third millennium BC for decorative or practical purposes and also for deception.
The earliest examples involved simple mechanical attachment, but it was not long before more permanent and more economical methods of gilding and silvering were developed.
In the Roman Imperial period copper and bronze statues and silver and bronze jewellery were commonly gilded.
Significant levels of mercury can be detected in the gilding of many but not all these artefacts.
The presence of mercury indicates the use of a technique known as mercury- or fire-gilding.
Gold dissolves in mercury at room temperature to make an amalgam (an amalgam is an alloy of mercury).
This property allows the gold to be applied in semi-liquid form over all or part of the object.
The object is then heated to drive off the mercury (which boils at 357°C).
leaving a thin surface plating of gold.
Because over-heating the gilding will ruin the finish, this stage is not carried to the extent of driving off every trace of mercury, so some evidence of the plating technique is left.
However, analysis shows that not all Roman gilding contained mercury.
Pure gold can be beaten out to form very thin sheets; according to Pliny, writing in the first century AD, 25 g of gold could be beaten into 750 leaves each 10 cm square.
Burnishing alone can cause gold leaf to adhere to a clean metal surface, but adhesives like egg white were also used.
Unlike mercury-gilding, there is no positive analytical evidence which can identify gold leaf, but it can often be recognised when viewed in cross-section at high magnification.
Leaf-gilding usually shows only minor variations in thickness and a superficial bonding to the metal below.
The overlapping  edges of the sheets of gold leaf are very characteristic (figs. 5.15a and b).
Analysis of a large number of gilded Roman ‘bronzes’ has revealed that most of those which are mercury-gilded are in fact made of copper.
They contain very low levels of alloying elements, particularly lead, which can dissolve in the amalgam layer and leave unsightly grey patches in the plating.
It was found that gold leaf was generally used by the Romans to plate high-lead bronzes, although at later periods the choice of gilding method was not governed by the metal composition.
To identify the method used.
it is necessary to see how the plating layer is bonded.
This is usually impossible from surface examination of the object.
If the edge of the plating does not provide enough information, a minute flake of plating, as small as 1 sq mm, can be mounted on its end in an epoxy resin for easy handling.
Once the resin has set hard, the block and sample are ground flat, then polished with fine diamond paste.
When viewed at high magnification with an optical microscope or scanning electron microscope, much is revealed about the plating technique which is simply not visible on the surface of the object.
This examination technique is illustrated by a pair of micrographs of silver plating (figs. 5.15c and d), both of which are sections through ancient silver coin forgeries.
In each case there is a copper core with a plating of silver which superficially appears to be identical on the two coins.
But when the cross-section is viewed at high magnification, it becomes clear that different plating methods have been used.
In the first example there is a white outer skin of pure silver, with overlapping joins at each end.
Between this and the core is an alloy of copper and silver (light grey in the photo).
This is a solder attaching two discs of silver foil cupped around the copper core like the foil wrappers around a chocolate penny.
The second example has no joins in the outer skin, only a copper-silver alloy coating, indicating that it was plated with molten metal rather than foils.
The mercury method, so popular in the Roman period for gilding, can also be used for silvering bronze and brass.
Mercury silvering was certainly practised in the medieval period, but the Romans silvered jewellery, tableware and horse trappings by coating the copper alloy with soft solder (tin and lead), wrapping it with silver foil, then heating until the solder melted and secured the foil.
The reasons for the difference in treatment of gilding and silvering by the Romans is not clear.
Unlike gold, silver needs regular polishing to keep it bright.
As the foil plating was thicker it may have been found more durable than mercury plating.
Not all plating was of precious metal.
Tin has a low melting point (232°C), and tinning simply involves wiping a thin layer of molten tin over the surface of copper, bronze or brass.
It dates back to at least the fifth century BC and is still carried out today at the roadside in parts of Asia.
Tinning was used either for decorative purposes, for example on Merovingian jewellery, or for more practical purposes, such as providing a reflecting face on Roman bronze mirrors.
Analysis of these mirrors shows high levels of tin on the reflecting surface, but although all these mirrors are superficially similar, there are in fact two quite different types.
Many are bronze mirrors with a normal tin content of approximately 10 per cent, which have been tinned to produce a silvery reflecting surface.
The second type has no separately applied coating; instead the whole mirror is cast in a high-tin bronze alloy containing about 25 per cent tin.
This alloy is naturally silvery in colour and is much more hard-wearing than a thin layer of tinning, but it requires a high degree of skill to control the casting conditions.
The two types of mirror look much the same after being  buried for centuries, but when the microstructure is examined at high magnification, as in Figures 5.15e and f, it is possible to distinguish between tinned bronze and the high-tin alloy.
Niello inlay
The scientific research into the history of plating technology relies almost entirely on microscopy and element analysis, but these techniques cannot provide a complete picture of many of the non-metallic inlays used by the ancient metalworkers.
One example of this is a black inlay material known as niello, which is found on gold.
silver, bronze and brass items from as far apart as first-century AD Rome and nineteenth-century AD Moscow, ninth-century AD Persia and thirteenth-century AD England (fig. 5.16).
We know that niello is a metal sulphide, made by heating metal filings with sulphur, but could there be a continuity of tradition amongst the metalworkers of cultures so widely separated by time and geography?
Certainly there are visual differences; first-century Roman niello is often poorly preserved but fifteenth-century Italian niello, even in badly damaged pieces, still fills every detail of a finely engraved design.
To study such inlays, the method of analysis must identify any differences without damaging the object.
Inlays may be very small in area and are often closely mixed with corrosion products from the metal into which the niello was set, so the analysis technique also has to distinguish the niello inlay from corrosion and the metal of the inlaid object itself.
X-ray diffraction (XRD) analysis (see glossary) is ideally suited to this sort of problem as it requires only a minute sample and, most important, it identifies the mineral or compound present.
XRD is able to identify the metal sulphide used to make the niello and to distinguish it from the metal and from the oxide, chloride and carbonate corrosion products which contaminate the sample.
Thus, where element analysis by X-ray fluorescence of the inlays on two silver Anglo-Saxon disc brooches shows both to have a major component of silver, with some copper and sulphur.
XRD analysis identifies one inlay as silver-copper-sulphide (AgCuS) and the other as silver-sulphide (Ag 2 S) contaminated with copper carbonate (CuCO 3 .
Cu(OH) 2 ) from the corroding base silver alloy of the brooch.
A survey of niello composition, from the Roman period to the twentieth century, has identified the beginnings of a change in composition in the sixth century in Northern Europe when, perhaps for economic reasons, copper as well as silver was added to the crucible with the sulphur.
A second and more fundamental change occurred in the tenth and eleventh centuries in Europe and in the Islamic world, when lead was added to the ingredients for the inlay.
This had the effect of significantly lowering the melting point of the niello, allowing it to be melted into finely engraved designs.
Niello produced according to the Roman niello recipe decomposes before it melts.
It therefore had to be applied as a paste, not a liquid, and did not bond well to the metal; hence the observed differences in preservation between Roman and later medieval niello.
paint and patination
Pigment identification is another field to which XRD analysis is well suited.
Many early pigments are naturally occurring and brightly coloured minerals, usually metal salts, and often only minute traces remain.
We do not necessarily think of pigments in the context of metalwork, but there are traditions of painted metal statues.
For example a study of the Buddhist statuettes of Tibet and the Himalayas has identified the blue copper mineral azurite, red lead and cinnabar (red mercury sulphide) on the head-dresses.
The blues are normally found on the ‘peaceful’ deities and the reds on the head-dresses of the ‘angry’deities.
A more durable method of colouring metals is to patinate them.
This is usually done by chemically inducing a thin surface coating of corrosion.
Metal is easily corroded, but the skill lies in producing an attractive colour which is even in tone and texture.
Japanese metalworkers have made the skill of patination into a sophisticated art form, producing naturalistic scenes with flowers, animals and people, using different-coloured inlays (plate 5.2).
The best known in the West is probably shakudo , which is a copper alloy with a deep black patina, but other copper alloys were patinated to produce colours ranging from shades of grey and brown through to green.
From as early as the 1860s, Western scientists have been interested in how these colours were produced.
Analysis has shown that it is not just the recipe for the pickling solution which affects the colour but, more fundamentally, low levels of alloying elements added to the copper.
The shakudo alloy contains 1 to 5 per cent of gold in copper.
The greys and browns are produced by varying the proportions of silver added to the copper, often with traces of gold and arsenic.
Patinated metalwork is not just confined to Japan.
Pliny describes a much sought-after metal called Corinthian bronze, an alloy of copper with gold and silver, which took on a purplish hue.
It has been argued that this is a description of a patinated alloy.
Analysis of a small Roman plaque with a black patina and gold inlays proved it to be largely copper with traces of silver, gold and arsenic, adding weight to the view that this patination technique was practised in the West as well as the East.
Another distinctive type of patinated metalwork, known as bidri , has been made since the seventeenth century or earlier and is produced in India to this day (fig. 5.17).
Again the patina is a deep black and contrasts with brightly polished silver, brass and gold inlay decoration.
However, in this case the patinated metal is zinc, which would not be expected to turn black on pickling as zinc has no black corrosion products.
This has been explained by analysis of the metal which reveals that copper is also present in the alloy.
Experiments in pickling different alloys of copper and zinc have shown that only alloys with between 2 and 10 per cent of copper in the zinc will take on the black patina, and the silver and brass inlays are unaffected by the pickling solution.
Conclusion
These are only a few examples of the applications of scientific research to metal artefacts.
Clearly one cannot hope to give a comprehensive survey of the history of metals and metalworking in a single chapter.
Rather we have attempted to show the potential of analysis and technical studies to increase our knowledge of the past.
Such research provides a means of tracing the progress of technological change: for example the development from the early exploitation of native metal to the alloying of copper with arsenic or tin to make bronze and then to the large-scale manufacture of brass (copper-zinc alloy) by the Romans.
Metal analysis can reveal fluctuations of economic prosperity, through evidence of coinage debasement, the imposition of gold and silver standards, or scarcity of precious metals for prestige items.
Study of manufacturing and decorative techniques can provide an insight into contacts between cultures.
New trade  routes may be traced by the spread of metalworking skills and the import of rare and exotic materials such as gemstones and ivory for jewellery.
The study of metalwork from an archaeological site, whether a burial site like Sutton Hoo or a major settlement like York, which has a whole range of artefacts and materials, provides an opportunity to build a picture of the place of technology and metals in the context of the economic prosperity and social hierarchy of the society.
The potential information which can be extracted from a metal artefact by analytical and technological study extends far beyond providing accurate factual information for museum labels and excavation reports.
6.1 left Hispano-Moresque dish in lustre and blue (MLA G5170).
This dish has a Valencian shape but the crowded design is Malagan; neutron activation analysis shows it to be Valencian.
Diameter 420 mm.
6.3 right Two medieval floor tiles:(a) from the chapel of Leo X in Castel Sant' Angelo, Rome (MLA 1883.11–6.9), of Genoese or Spanish origin (140 mm square), and (b)far right made in Seville (MLA 1900.7 -18.1), one of a group analysed for comparison.
115 mm square.
6.2 Discriminant analysis results of neutron activation data for Spanish tin-glazed pottery known to be from Malaga, Valencia and Seville.
Each symbol represents the analysis of an individual object; samples of unknown origin can be assigned to their source by their position on such a diagram.
6.4 Italian maiolica pharmacy bottle of ‘Orsini-Colonna’ style showing a bear hugging a column (MLA 1852.11–29.2).
Neutron activation analysis has shown that this series of pieces was made at Castilli in southern Italy.
height 450 mm.
6.5 The distribution of flint axes from the source of mines in southern Britain.
Each pie chart shows the proportion of axes found in three areas, classified as to whether they came from the south Downs, Wessex, East Anglia or other mines (after Craddock et al, 1983).
6.6 Interior of typical flint mine gallery at Grimes Graves, Norfolk, showing the black flint seam at the foot of the wall.
6.7 below Marble horse from the Mausoleum at Halicarnassus, about 350 BC (GR S1002).
Height 2.4 m.
Identified as pemtelic marble by stable isotope analysis.
6.8 above Stable isotope analysis for carbon and oxygen of the marble sculptures from the Mausoleum at Halicarnassus, including the horse indicated by H (fig 6.7), superimposed on the data for Classical marble quarries.
The ellipsis represent 90 per cent coincidence limits for the samples from named quarries.
6.9 Large Igbo-Ukwu roped vessel of leaded bronze in the form of a water pot (now in the National Museum of Nigeria, Lagos).
Analysis of this unique vessel suggests it was made from local Nigerian copper.
height 320 mm.
Tracing to Source Michael Hughes
The first question one tends to ask about any object in a museum is where did it come from?
In many cases, pinpointing provenance, where an object of a particular type was made, enables us to identify it quite specifically.
For example, the tin-glazed pottery made in Europe from the Renaissance onwards was produced in many styles: that made in the Low Countries (known as Delftware) is of a specific range and type which varies from one production centre to another and is different again from the maiolica of Italy and the lustreware of Spain.
An object's appearance is the first way we recognise where it comes from: a Volkswagen ‘Beetle’ is an instantly recognisable shape even if the VW badge has fallen off the car; likewise we recognise a Rolls Royce.
Much of the expertise of a museum curator or an archaeologist lies in being able to offer a reasonably accurate identification of an object just on the basis of looking at it and handling it.
From experience and familiarity he or she builds up a mental pictorial encyclopaedia based on study of museum collections, information from archaeological research and accumulated knowledge from books and papers describing objects of particular periods and cultures.
However, from time to time the curator's instinct for identification comes up against scholarly puzzles.
Differences of opinion exist among scholars; sometimes the appearance gives very little to go on — details may have been rubbed off or we may only have a small fragment of a large object to examine; two or more origins may be possible contenders and it may be impossible to decide which on stylistic grounds alone.
All such cases need an alternative approach to the problem of origin and it is natural to turn to scientific techniques to see if they have something to offer.
The problem then needs to be formulated in scientific terms and this requires the object to have some property which is unique to its origin, but which varies from place to place and is not significantly modified by manufacture; the property must also be scientifically detectable.
Either the composition of the object or its microstructure are the obvious candidates.
For metal objects, as we have seen in Chapter 5, the bulk composition was very much under the control of the metalsmith rather than being unique to origin.
Hence most provenance studies are of ceramic and stone materials, where the composition and microstructure of the basic raw materials is relatively unaffected by the manufacturing process, although we will see that metals too can be provenanced in some circumstances.
If an object is to be sourced, the first step is to determine the composition of  the raw materials of the most probable sources.
More usually for ceramics, the scientist examines the composition of groups of similar objects of known origin to build up a comparative database.
An appropriate scientific technique has to be chosen for this task, and experience of analysing antiquities suggests that there are certain requirements of such a technique.
For example, in most cases only small amounts of material can be removed from an object: the analysis technique must therefore be quite sensitive.
The differences in composition are sometimes quite subtle so the technique must also be accurate and precise.
Identifications need to be made clearly, which requires us to investigate as many features of the object as possible.
This is like forensic science, where the more ‘matches’ one finds between two fingerprints, the greater the certainty that they belong to the same person.
Normally we need to look at large numbers of objects (tens, or perhaps hundreds): the analytical technique must therefore give results in a reasonable amount of time per sample and cope with large numbers of objects.
This requirement eliminates a lot of the older classical chemical techniques and indeed some of the ultra-modern high-tech instruments which can only handle a few objects per day.
Different techniques are chosen for different materials.
The aim is always to select an appropriate method, one which answers the question as clearly as possible.
There is no reason to use a difficult and probably expensive analytical method if a much simpler and quicker visual examination under a microscope provides the same answer.
Some materials still resist easy answers — gold is an example.
There is a continual need to appraise existing techniques, to seek refinements and to search out new instrumental methods of examination which have more to offer in speed, accuracy or range of elements found.
In ten years' time we shall no doubt still be using the techniques discussed in this chapter but we may also have opened up new avenues of research by widening the range of materials examined and by using other scientific techniques which at present are only at the development stage.
Ceramics
Two general approaches have been much used: thin-section petrography and chemical analysis of the body fabric or composition.
Petrography
Thin-section petrography is a standard geological technique, fundamental to determining the mineralogical and textural characteristics of rocks; it can be applied in just the same way to ceramic materials.
First, a small fragment of material is removed and stuck to a glass slide; it is then carefully ground away until it is only 0.03 mm thick.
At this thickness most rock-forming silicate minerals are translucent and the thin section can be viewed in transmitted light using a polarising microscope.
Particular minerals can be recognised by their characteristic optical properties  so that individual grains and rock fragments can be identified.
Textural characteristics — such as the size, shape and orientation of grains — can also be observed.
Although clay minerals are generally too fine-grained to be reliably identified, features such as clay pellets and parallel alignment of the platy clay particles, which may result from forming processes such as wheel-throwing, can be recognised.
Examination of thin sections of ceramic materials may yield information about ancient technology (e.g. type and amount of added temper, mixing of clays, and method of forming).
Such examination may also help us to determine provenance by revealing inclusions characteristic of particular geological sources.
Textural analysis, which involves studying the size, shape and proportion of the inclusions, can be useful when the inclusions are not distinctive in other respects.
It may sometimes be possible to associate together vessels which have inclusions with similar textural characteristics, and even to suggest possible sources.
The following example from Iron Age Britain shows how scientists use thin-section petrography to decide whether pottery found at a site is local or imported.
Hengistbury Head is a low sandy promontory jutting out into the English Channel near Bournemouth.
Evidence of human occupation here goes back to the Upper Paleolithic and Mesolithic periods (Early and Middle Stone Ages) but its period of greatest activity was in the Late Iron Age, from roughly 100 BC to 50 AD, when it became a trading centre and port for people and goods from the Continent.
Today, it is being slowly eroded on the south face by the sea.
It was excavated by Bushe-Fox in 1911–12, and has been excavated more extensively within the last ten years by Barry Cunliffe, using the latest archaeological techniques.
During the excavations, the Iron Age settlement yielded large amounts of pottery.
Because Hengistbury was a port, we were especially interested in identifying which pieces of pottery were local and which imported, and in trying to find their sources.
To do this, a selection of the Late Iron Age pottery (c.100–50 BC) was studied.
In thin section a Dorset-based type of hand-made pottery known as Durotrigian ware (named after the Iron Age tribe, the Durotriges) shows a very sand-rich fabric (plate 6.1a: left-hand side).
The white or greyish grains embedded in the dark clay matrix are composed of the common mineral quartz.
This was probably deliberately added by the potter as sand temper, to ‘open up’ the clay fabric, allowing water vapour to escape so that the pot would be less liable to crack during firing (see Chapter 2 for further discussion).
Most of the hand-made Durotrigian pottery analysed in thin section had the distinctive appearance of Plate 6. 1a, with a fairly coarse sand temper.
On the grounds of petrology. this sandy ware seemed to be locally produced Dorset pottery, made from the local Tertiary clays of the Poole-Wareham region.
In contrast to these local pottery types, there were also wheel-made vessels decorated with raised cordons or bands on the body.
In thin section these have a dramatically different appearance (plate 6.1b).
Under the polarising microscope they contain coarse grains which show multicoloured areas, corresponding to interference colours caused by the presence of particular minerals.
While quartz gives grey and white interference  colours, the bright colours of Plate 6.1b are produced by an amphibole mineral (pale colour to yellow to red) and the black and white stripey pattern by the feldspar mineral plagioclase.
(These two minerals form a rock type known as an amphibolite.)
Other very distinctive thin sections were found for vessels with a distinctive rilled decoration which contain the minerals feldspar, mica and quartz: these are fragments of a granite.
Both the amphibolitic and granitic minerals can be matched with the rock types found in northern Brittany but not in Dorset.
Taken together, the petrological analysis of the black cordoned and rilled micaceous wares recovered at Hengistbury Head and the known geology of the region leave no doubt that these wares were imported to southern Britain in the Late Iron Age.
chemical composition
The provenance study of ceramics is one of the most active research fields involving chemical analysis.
This is partly because we need to understand and classify the vast amounts of pottery recovered from excavations at archaeological sites, and partly because of the high success rate of such analytical projects.
But the real explanation is found in the nature of pottery.
On the one hand it is made from clay which, after being extracted and processed, is a durable material which outlives other materials in aggressive soil conditions.
On the other hand numerous studies have shown that clay from one locality, if not always of a single composition, has at least a reasonably uniform and limited compositional range, whereas clays from different locations (towns, countries, continents) have different chemical compositions because they reflect differences in the underlying geology.
The chemical composition of clay may differ in major elements, like aluminium, iron, sodium or calcium, or in the minor or trace elements present at very low concentrations, such as chromium, uranium, barium or lanthanum (one of the rare earths).
Fashioning and firing a pot does not affect the clay composition but care must be taken, since potters frequently mix additives into clay to prepare it, and burial of pottery in the ground has some slight effects on its composition.
In ancient times the most common additive, or temper, was quartz sand, which simply dilutes the concentrations of the chemical elements.
The chemical effects of burial on the pottery are few and generally well known.
Neutron activation analysis
Neutron activation analysis (see glossary) was developed in the mid-1940s, following the introduction of nuclear reactors.
It remains one of the most sensitive methods for chemical analysis ever developed.
At present it is also the most popular method of analysis for provenance studies in archaeology, but it may not always be so, since scientists are continually looking for new instrumental methods of obtaining a comprehensive chemical analysis of a material.
Mass-spectrometry techniques (see glossary) are currently receiving attention because they are superior to other  methods in sensitivity and the range of chemical elements to which they can be applied.
However, routine chemical analyses of large batches of samples has yet to be achieved.
Instrumental neutron activation is still selected most frequently because of its sensitivity, accuracy and the wide range of elements which can be measured in a single sample.
For ceramic provenance studies, a sample of the ceramic body fabric is taken, using a non-contaminating drill such as synthetic sapphire.
This produces a powdered sample of the interior body fabric of the ceramic (about 50 mg are needed).
Batches of about sixty samples, each sealed in a pure silica tube, are irradiated, together with six samples of a standard clay of already known chemical composition.
Typically, the chemical analysis for each sample yields results on over twenty elements.
Laboratories located next to a reactor can increase the number of elements to between thirty and thirty-five.
This is because they can include additional short irradiations for elements with isotopes of very short half-lives, from a few minutes to a few hours, although this increases the analyst's work.
A typical provenance project could involve analysis of a hundred to two hundred samples of pottery and it would clearly be impossible to make sense of all two thousand to four thousand quantitative elemental analyses without the use of modern multivariate statistical computer programs.
Such programs take a comprehensive analysis (more than twenty elements) on each sample in turn, and compare it with perhaps a hundred to two hundred other samples to try to find a close ‘match’.
Essentially it is like the forensic scientist trying to find two chemical ‘fingerprints’ which match for as many elements as possible.
Eventually the program will organise all the samples into groups having the same or similar ‘fingerprints’.
Each of these pottery composition groups represents the same clay.
Working out why these different groups have emerged then becomes a matter of closely integrating the archaeological and scientific information: the key to understanding the results is close co-operation between the archaeologist and scientist, who need to work together in order to extract all the latent information in the analyses.
The use of neutron activation analysis is best explained by the following case study.
Medieval Spain had a vigorous ceramic industry with many local potters producing ceramics with a galaxy of brightly coloured and lustred designs on a white background.
This is tin-glazed pottery and it was exported widely.
For example it was packed into the holds of ships sailing to the New World, to satisfy the expatriates' desire for Spanish tableware in their overseas posting.
Sherds of such pottery have been found on sites along the eastern seaboard of the United States, including Florida, the Caribbean islands and parts of South America such as Venezuela.
The most famous tin-glazed pottery of Spain was lustre pottery; it was also exported and found its way into the wealthy households of medieval Europe.
The first lustre pottery produced in Europe was made by Arab potters working in Spain.
The Muslim potters of Malaga in the Kingdom of Granada became justly famous for their wares and lustre pottery was subsequently made by both Muslim and Christian potters in the Christian town of Valencia.
Both lustre and blue-on-white wares were made  from the mid-thirteenth century to the late fifteenth century at Malaga and a typical example of a wide dish decorated in lustre and blue is shown in Figure 6.1.
The designs fill the surface of the ceramics almost completely.
From the late fourteenth century onwards, however, very similar pottery was produced at Valencia, a long-established pottery-making centre.
It is thought that the potters had migrated from Malaga in response to the increasing pressure of the sea blockade of southern Spain by Christian ships.
Later, Valencia came to dominate as the major lustreware centre.
But before this both centres produced very similar ranges of designs and there are considerable difficulties in distinguishing on stylistic grounds alone between late Malaga and early Valencia lustre pottery.
This is where neutron activation analysis enables us to source them with certainty.
As a first step, sherds of known origin from the two centres were analysed.
The results were then evaluated using several statistical techniques mentioned in Chapter 9 (see page 158).
A preliminary test with principal components analysis was followed by cluster analysis using the program CLUSTAN and finally discriminant analysis to test For chemical differences between the products of the two sites.
Figure 6.2 shows the results of discriminant analysis in graph form: the compositions of the pieces of pottery from Malaga, Valencia and Seville can be clearly differentiated from each other.
There are also composition sub-groups which for Valencia at least are related to quality of the wares.
The splendid lustreware dish shown in Figure 6.1 has already been referred to.
From a purely art-historical viewpoint it presents a puzzle: the shape is Valencian but the style of decoration is Malagan.
Analysis showed it to have a definite Valencian chemical composition: in Figure 6.2 it is part of the Valencian sub-group with black filled circles.
From this one can infer that it belongs chronologically to that transition period in Spanish  ceramics when the displaced potters of Malaga had set up afresh in Valencia but were still using the traditional designs of Andalusia in their new environment.
Analysis has also helped to ascertain the origin of the tiles in the chapel of Leo X in the Castel Sant' Angelo in Rome (fig. 6.3a).
It was recently suggested that these might be the products of an Italian maiolica workshop rather than Spanish as has long been believed.
Maiolica made in Renaissance Italy was also tin-glazed and painted with such vibrant colours that the ceramics seem to glow with a Mediterranean light.
A neutron activation analysis study of these ceramics (such as the  pharmacy bottle in Figure 6.4) has so far tested pieces known to be local products from over twenty maiolica centres in Italy.
The composition of the Leo X tiles does not compare with any of these, including those from the postulated source at Genoa, but they are almost identical to the composition of contemporary tiles definitely known to have been made at Seville, such as the example in Figure 6.3b.
In the discriminant analysis diagram (fig. 6.2), these Seville tiles form a compact group into which the Leo X tiles closely fit; this demonstrates that the Leo X tiles are Sevillian.
Anthony Ray has recently reached the same conclusion on art-historical grounds and we know that Seville was an important centre for the manufacture and export of tin-glazed pottery.
Among the Italian maiolica ceramics analysed was the pharmacy jar of Figure 6.4, which is one of a number in the same style.
Their origin has been disputed but analysis has now shown that their compositions are consistent with being made at Castelli in southern Italy.
Stone
The parallel approaches of petrology (or thin-section petrography) and chemical analysis, which have been so successfully applied to ceramics.
have also solved some questions about stone objects.
In addition another technique, stable isotope analysis.
has been used to identify the sources of white marble used in the Classical world.
Microscope study of stone axes
Petrology has been particularly helpful in identifying Neolithic stone axes made from the hard rocks which predominate in western Britain from Cornwall to Scotland.
From the seventeenth century onwards antiquarians recognised that the polished stone axes found at numerous sites in Britain were made of stone that was not available locally.
They speculated on how far it would have been necessary to travel to obtain the stone, and whether one could precisely locate its origin.
Modern petrological studies have gone a long way towards answering this question: polished hard-rock axes seem to have been made from stone obtained from a limited number of outcrops.
Sometimes there is actual evidence of extensive roughly prepared axeheads (as in the great outcrops towering above the Langdale Valley in the Lake District).
while in other cases the geological sources have been identified fairly exactly by petrology even though there is little archaeological evidence of working at the outcrops themselves.
Just how far the raw material travelled from source to customer is illustrated by the outcrop of greenstone rock in Mounts Bay, Cornwall: many axeheads made from this rock are actually found in East Anglia on the Essex coast (some 5 50 km from Cornwall) and in south-eastern England along the Kent and Sussex coasts.
We therefore know that there was long-distance transport of stone axes in prehistoric Britain, which may have begun with carriage of axes from the axe factory to a secondary distribution centre, from where they were traded out into the surrounding area.
Our knowledge of the identification and distribution of stone axes in Britain has been gained from a very long-running co-operative research effort involving archaeologists and petrologists: over the last fifty years more than 7500 axes have been examined petrologically.
Well over thirty distinct hard-rock types, each representing a different rock outcrop, were utilised for artefacts in the prehistoric period.
Some of these rock types are quite exotic — for example the rare porcellanite from Northern Ireland — whereas others, such as the granite type known as dolerite, occur in many different areas of upland Britain including Wales.
Chemical analysis of flint axes
The most enduring and widespread artefacts from the earliest times are made of flint, a hard rock which fractures to give sharp edges ideally suited for making knives, axeheads and arrowheads.
In Great Britain such artefacts are particularly common from the Paleolithic through to the Bronze Age.
An astonishing variety of artefacts was made from flint, requiring a craftsman's skill to chip the blocks of flint to the required shape.
How and where were the raw materials obtained and transformed into useful items for hunting, food production, woodland clearance and so on during the Neolithic and Early Bronze Age (roughly 4000–1500 BC)?
Enough is known from archaeology to realise that in many cases chance finds of flint nodules or fragments provided the raw material for small tools.
On the other hand, archaeological study has also shown that in specific locations across southern Britain (and elsewhere in Europe) there were large-scale exploitations of flint resources, in effect flint mines.
Attention has been focused on the composition of these deposits to see if we can link implements to specific mines.
Flint is regarded by geologists as a particular form of chert, a chalcedony: that is, a material which is almost pure silica with small inclusions of water.
The chemical properties of flint at first seem very unpromising since so much of its chemical make-up is a silicon-oxygen network, and is the same in flint found anywhere.
But there are trace amounts of other elements entrapped within the flint.
Because it forms slowly over geological time in the Cretaceous chalk, minute amounts of clay dispersed in the chalk are incorporated within the flint.
These trace amounts of clay can be analysed chemically and research has shown that the flint taken from the major flint mines scattered across southern Britain (fig. 6.5) has a particular chemical composition for each mine.
This composition ‘fingerprint’ is consistently found for flint from the same mine but differs between mines.
As the amounts of these chemical elements trapped in the flint are so small, it is necessary to use a sensitive analytical technique, namely atomic absorption spectrometry (see glossary).
This technique has been used to find the amounts of elements such as iron, sodium, potassium, aluminium, calcium, magnesium, lithium and phosphorus in the flint, and it was the concentrations of these elements which were different for different mines.
Neutron activation was not chosen because those elements which it can measure in flint (as compared to pottery) are more erratically distributed than those measured by atomic absorption (the major elements in clay), and this makes it harder to distinguish the products of any two mines.
Recently inductively coupled plasma spectrometry (see glossary), which is related to atomic absorption, has also been successfully applied to flint analysis.
In this project over a thousand flints from across southern Britain, including unworked flint nodules collected from the known mines, were analysed.
All flint mines in southern Britain are located on the Chalk (fig. 6. 5).
A typical Neolithic mine is not very different from our contemporary idea of a mine even though these are over 4000 years old and the interior of the mine at Grimes Graves is shown in Figure 6.6.
Raw flint from the mines as well as finished artefacts were analysed, mainly hoards of flint axeheads found far from the mines, and there were some unexpected results (fig. 6.5).
The pie charts in the diagram show the proportion of flint artefacts which originated from the major flint mining areas of the South Downs, Wessex and East Anglia.
In the South-East, as one would expect, the South Downs mines supplied the raw material for more than half the axeheads analysed from that region.
However in East Anglia the South Downs group still supplied a large proportion (this time somewhat under 50 per cent of the axeheads), whereas East Anglian sources, such as Grimes Graves, had apparently cornered only a small proportion of the market.
Many of the analysed axeheads are datable stylistically to an early period, before mining operations began at Grimes Graves.
However there is still the slightly bizarre picture of flint being carefully transported from the South Downs northwards over 350 km, along the Icknield Way into East Anglia on the Chalk ridge which contains countless tonnes of flint nodules perhaps 1 0 m below the surface.
As well as showing how far flint was traded in prehistoric times in Britain, the analyses have shown that the largest proportion of the flint used to make axeheads was deliberately mined, in many ways like the hard rocks used for axes (see page 106).
Stable isotope analysis of white marble
Sculptures in white marble from the Classical world of ancient Greece and Rome have for centuries delighted and inspired the ordinary observer as well as other sculptors, painters, architects and art historians (fig. 6.7).
That a range of quarries was exploited in the Mediterranean area is not in doubt, but particular sculpted pieces cannot always be attributed to particular quarries on purely visual grounds.
Some alternative method of assigning sculpture in white marble to its quarry source has been long sought.
Petrographic methods have provided some indications because the grain-size of the white marble from some quarries is very distinctive, but not all quarries can be distinguished in this way.
In 1972 a research paper by American scientists showed that the stable isotope ratios for oxygen and carbon in white marble varied from quarry to quarry, and more extensive research since then has confirmed that such measurements provide a ‘signature’ for the marble quarries of Italy, Greece and Turkey, which were the main sources of Classical marble.
For convenience the patterns can be shown on graphs (fig.6.8) as a series of statistical ellipses which represent 90 per cent of the results from each quarry.
If a measurement on an ‘unknown’ marble fragment is then plotted on this graph and it falls within one of the ellipses, the fragment can probably be assigned to that quarry.
However the picture is not absolutely clear, as will be obvious from Figure 6.8, since some of the ellipses are rather large and some overlap: without additional information it would not be possible to say which of the pair (or more) of overlapping quarries was the true source.
In practice when items of archaeological information, such as the date of the sculpture and its style, are taken into account, we can eliminate some quarries because they are not operational  at that date or because we know the sculptors were working in certain places and it is highly improbable that they were using distant rather than local sources.
Each case has to be considered on its merits where an ambiguous answer emerges from the stable isotope data.
In the last few years trace element analysis of the marble has been introduced as an additional aspect of characterisation.
Because marble is ultra-pure calcium carbonate, the technique for trace analysis has to be very sensitive and instrumental neutron activation analysis has proved ideal for this.
Quarried blocks of marble and finished sculptures have been analysed by neutron activation and the results have been very encouraging.
By a happy coincidence, those quarries which have proved difficult to separate by stable isotope analysis have very different trace element compositions, and some with very different stable isotopes are rather similar in trace elements.
Several research groups have concluded that the combined use of visual examination of grain size, stable isotopic analysis and trace element analysis may successfully distinguish all the major quarries of the Mediterranean region.
The application of stable isotopes to white marble is exemplified by the programme of analysis of the sculptures from the Mausoleum at Halicarnassus dating to about 350 BC.
(Halicarnassus, modern Bodrum, lies on a peninsula in south-western Turkey.)
The Mausoleum was a major structure commissioned by the Mausolus dynasty, consisting of a white marble building surmounted by a series of large sculptured figures and with extensive use of decorative sculpted friezes in the architecture.
It was an impressive monument and, as the local area lacks high-quality building or sculptural marble, the white marble used in its construction had to be imported.
The aim of the project was to identify the types of marble used for specific functions and to associate unidentified fragments with known parts of the building.
The most outstanding decorative element of the Mausoleum was the series of massive free-standing sculptures arranged high up on the podium of the monument, executed in fine marble.
At the apex stood a chariot with a four-horse team: one of the horses is shown in Figure 6.7.
Samples from the horse were analysed, and the isotope results showed that quarries high up on Mount Pentelikon were the source, rather than the more numerous and better-known quarries at the foot of the mountain.
Penteli was an important quarry near Athens in Greece and recent research has distinguished between the products of the upper and lower quarries.
Two fragments of the chariot were also tested: one, a wheel, was also of Pentelic marble but the axle was of Ephesian marble (Ephesus was a major port on the west coast of Turkey, north of Halicarnassus).
The impressive free-standing sculptures on the podium of the building were shown to be made of two types of Pentelic marble.
However, the marble used for the building came from these two sources.
Analysis has shown that the figureheads are of Parian marble (from the Aegean island of Paros), a particularly fine-quality marble, which was expensive because it was mined from underground.
However, the less important constructional blocks with carved decoration were from quarries  in the Dokimeion-Iasos region of Turkey.
Two different sources of marble within this same quarry group were exploited for the roof and the wall blocks.
The overall picture which has emerged from the analyses is of more or less consistent use of the same marble quarry for the same elements of the monument, but that a variety of marble types were selected for different purposes.
Finer grades (such as Parian or Pentelic) were used for the most important statuary, and lower-quality and more local marble, mainly from south-western Turkey, was used for the main architectural building blocks of the monument.
The analyses have also shown much interesting detail: sub-groups have emerged when marble fragments have been found to have extremely similar isotope ratios, which suggests they came not only from the same quarry but from the same part of the quarry.
Metals
Finding the provenance of metal objects presents a more difficult problem for archaeological science.
Unlike stone, flint or ceramics, the raw material has to undergo drastic changes before it is made into the finished artefact.
Metals do not, with the exception of gold, a limited amount of copper, and meteoric iron, occur as the free metal in nature: they usually occur as metallic minerals which have to be smelted.
The smelting process alters the chemical composition of the original ore so that there is usually no simple chemical correlation between ore and metal.
Re-melting and alloying further complicate the situation.
However, there are occasions when the trace element pattern of a metal object bears some traces of the elements in the original ore.
The trace elements in Sassanian silver provide one example, copper from the Hartz mountains has a very distinctive pattern of high concentrations of arsenic, cobalt, nickel and antimony, and there are a significant number of similar studies.
However, generally speaking, of the numerous ancient metallic artefacts still in existence, relatively few can be provenanced purely through elemental analysis.
Can any other approach help?
In the early 1970s geological research highlighted the fact that lead ores carried distinctive isotope ratio signatures', depending upon the geological period when they were laid down as deposits.
The discovery of the usefulness of lead isotope ratios was quickly applied to archaeology and has proved highly successful in provenancing lead-containing objects from antiquity.
Research began on lead objects from the Roman era, lead ingots, and so on.
But the technique was soon applied to objects which contain substantial amounts of lead, particular glazes and glasses rich in lead, such as enamels.
The search for other materials to analyse has now progressed to copper alloys.
Heavily leaded bronzes are obvious candidates for analysis.
However research has shown that even in copper objects containing no deliberately added lead, the small amounts of lead present in the original ore (and transferred to the finished metal during smelting) contain a ‘signature’ in lead isotope ratios of the copper ore body.
The situation can be complicated if the metalworkers added small amounts of lead, or added pieces of scrap at the  casting stage, because the ‘signature’ of the lead will no longer be that of a single source and sorting this out seems well-nigh impossible.
One recent example is the research on the bronzes excavated in the 1950s at Igbo-Ukwu in south-eastern Nigeria and dated around the tenth century AD (fig. 6.9).
These splendid and intricate bronze castings are enigmatic: they appear on the scene without apparent precursors and with no obvious descendants.
This, the technical skills required to make them, and the apparent lack of copper resources in Nigeria have prompted many scholars to conclude that they were made away from sub-Saharan Africa, although no convincing stylistic links with other cultures, including those of the Mediterranean, have emerged.
Chemical analysis and technical study of these bronzes have shown that they have an unusually high silver content (up to 1.2 per cent silver) which, by comparison with analyses of other ancient bronzes, suggests that one principal source of metal was involved.
Considerable technical skills were needed to make the bronzes, but the metalworkers used a very small range of techniques.
Thus, where one would expect a large basin to have been made from sheet metal, it was instead cast with walls of amazing thinness.
(Such aspects also suggest technical isolation of the metalworkers.)
Recently lead-zinc-copper deposits have been noted in the Benue Rift some 100 km from Igbo-Ukwu, raising the possibility of ancient exploitation of these local copper resources.
For some of the bronzes, lead isotope ratios have now been obtained on lead extracted from the samples, and from two lead ore samples from the Benue Rift.
This research showed  that one group of bronzes had very similar lead isotope ratios to the Benue Rift ores, while others had isotope ratios which, although different to the ores, could result from Benue Rift material being mixed with another (and geologically younger) source.
The Benue Rift deposits are spread out along 600 km, so they cannot yet be said to have been adequately characterised, but the technical, stylistic, compositional and lead isotope evidence now points to the Igbo-Ukwu bronzes originating within Nigeria.
Conclusion
This chapter has outlined the range of materials to which scientific techniques have been applied in order to discover a particular object's provenance.
Even for the materials described here, all the combined scientific efforts have still only made comparatively small inroads into the accumulating list of unsolved questions.
Other materials continue to present challenges to the scientist, including many of organic origin such as tars, waxes and oils.
So far virtually only those organic materials with structures visible to the microscope (e.g. pollen) have received detailed attention.
However, the range of scientific techniques will also grow, no doubt enabling us to provenance materials with greater speed and accuracy in the future.
7.1 In radioactive decay, after each half-life (T1/2) the number of atoms remaining is halved: if there are A to begin with, after one half-life there will be A/2 atoms remaining; after two half-lives, A/4 remain; after three A/8, and so on.
This time axis shown is for radiation.
7.2 Whalebone plaque dated to 1480 plus/minus 80 BP (see p.122); however; the whale could have had an apparent radiocarbon ‘age’ at death of several centuries (MLA 1987.10–5.1; OxA-1164).
Height 320 mm.
Marine environments show a reservoir effect due to slow mixing of carbon through ocean waters and upwelling of deep ocean water depleted in 14C.
7.3 Horse mandible from Kendrick's Cave (Great Orme's head, Llandudno, Wales), AMS dated to the late Upper Palaeolithic or very early Mesolithic (PRB 1959.12–3.1).
If dated by conventional radiocarbon, it would have been totally destroyed during measurement.
It is one of the few examples of mobiliary art of the period from Britain.
7.4 High-precision radiocarbon calibration curve based on Irish oak (courtesy of Gordon Pearson).
7.5 Section of Stuiver and Pearson's high-precision calibration curve for the recent past (courtesy of the authors).
the highest and lowest lines show the error term on the curve (centre line) at each point.
Large wiggles mean that a single radiocarbon result can correspond to more than one calendar result (see fig. 7.8); distinguishing between the different calendar possibilities cannot then be achieved by radiocarbon alone.
7.6 above left Polished section of the trunk of an oak showing the well-defined rings (courtesy Jonathan Pilcher).
7.7 above In dendrochronology a master curve is produced, starting with a living tree and extending the timescale using timbers with overlapping patterns (courtesy of Ulster Museum, Belfast).
7.8 The intercept method of calibration: the calibration is shown schematically without its error limits; these are incorporated in the overall error, θ.
Note the effect of the shape of the curve on the size of the calibrated date range; more than one range is possible.
7.9 Beaker period burial from Barnack, Cambridgeshire.
Here the body is accompanied by a Beaker, a copper dagger, an archer's wrist guard and other items.
7.10 Natural TL glow curve (N) from a sample of pottery, and one produced by addition of a beta radiation dose in the laboratory to an identical sample (N + Β).
The additional TL produced by the laboratory dose enables the TL sensitivity of the pottery to radiation to be determined.
The thermal glow from the sample, due to heat alone, is curve B.
7.11 Pontnewydd Cave under excavation (courtesy National Museum of Wales).
Questions of Chronology Sheridan Bowman
Most people wear watches, some keep diaries: we continually monitor the passage of time and keep records of the sequence of events.
Public buildings such as libraries house less personal records in the form of newspapers, parliamentary accounts and other documents.
We live in a historical period; written records are kept and we tend to assume that our records are correct and that we can accurately reconstruct the events of the past.
However, historical documents are not always true records of the past.
For example the so-called ‘Dark Age’ of European history, following the decline of the Roman Empire, has a dearth of written records, and those that do survive are questionable.
In Britain, for instance, unravelling any facts from the many legends associated with King Arthur is no easy task.
In this case it is open to question whether the authors of the limited number of extant documents were writing about contemporary events or were recording what they believed to have happened, based on oral tradition.
Indeed, the documents themselves could have been transcribed many times through the ages.
Inevitably scribes would have corrected what they perceived to be ‘mistakes’ and undoubtedly the story would also have been embellished on occasion.
Nor were records necessarily kept with the intention of providing a precise calendar of events.
For example, the tens of thousands of cuneiform tablets found at Kanesh (modern Kültepe in Turkey) are largely monetary accounts (lists of goods transported and letters regarding merchandise).
It is obviously difficult to infer the chronological framework of a town from its stocklists alone.
If history is potentially unreliable and incomplete, what of the prehistoric period for which we have no written records at all?
Here archaeology is usually the sole source of information.
As in geology.
the ordering of the strata (layers) of sediment on an archaeological site provides us with a relative dating technique.
A layer high in the sequence will have been deposited later than a lower one, and, provided there has been no disturbance, the artefacts in the higher level will be younger than those underlying.
But how much younger, and how do the artefacts on one site relate temporally to those on another?
Similarity of style could suggest similar age, but dissimilarity does not necessarily imply the opposite.
The style of an artefact does not inherently tell us its age — independent dating techniques are required.
Dating techniques are many and varied, with similarly diverse applications.
Some are based upon the effects of seasonal change and are  therefore directly related to the orbit of the earth about the sun, which provides us with a useful unit of time, the year.
Dendrochronology, varves and ice core dating are such techniques, based respectively on the annual formation of tree rings, lake sediment layers and polar ice-cap layers.
Each ring or layer must be differentiable from the adjacent ones and be formed annually.
Thus tree rings are differentiated by the types, density and size of cell laid down at different times of the year; varves by the gradation in particle size resulting from sedimentation of debris released into rivers and carried to lakes by the annual melt of glaciers; and ice core layers by differences in dust content and acidity.
Dendrochronology is the most directly useful for dating archaeological sites, but, perhaps surprisingly, even polar ice core dating can occasionally be very useful.
Ice cores record events, such as major volcanic eruptions, which affect global dust and acidity levels.
Thus they have provided evidence that helps to date the eruption of Thera (modern Santorini) which virtually destroyed the Minoan town of Akrotiri in the seventeenth century BC.
Less frequent rhythms in the earth's orbit produce more dramatic climatic changes and form the basis of some of the relative dating techniques.
Thus evidence of glacial and interglacial periods, such as the type of flora and fauna present, can sometimes be used to assign a sequence to events, but, as with any relative dating technique, events are only set in order.
To assign them to a calendar scale and determine the sizes of the intervals between them requires absolute dating methods, such as those described above or those based on radioactive decay.
A radioactive isotope of a specific element decays in a defined way (see fig.7.1).
Knowing how much was there to start with and how much remains determines how much time has passed.
The simplest radioactive methods are based on decay of a radioactive isotope into a stable one.
Radiocarbon and potassium-argon dating fall into this category.
In the former, to a first approximation, the initial amount of radiocarbon in an organic sample is taken to be that in the atmosphere now, but many adjustments are made to this assumption as will be seen below.
In potassium-argon dating of volcanic rocks, the radioactive potassium isotope is in a known proportion to the non-radioactive one and decays to argon.
The radioactive potassium has a very long half-life (1250 million years) so that the amount lost is extremely small relative to the total amount of potassium present and cannot be measured.
However, argon, being a gas, is at zero concentration when the rock solidifies from the molten state, so the amount of argon produced is measured.
Some radioactive methods, like uranium series dating, involve a chain of decay: one radioactive element decays into another which in turn decays.
Uranium series dating is particularly used for dating stalagmitic calcite.
When the calcite forms it incorporates uranium dissolved in the ground water.
The various decay products in the uranium chain are not present as they are not soluble in water, but they build up in a defined way, according to the decay rates of the individual isotopes in the chain.
From this brief summary of a small proportion of the scientific dating techniques, some common principles of their application emerge.
The  dating method itself must have a definable ‘zero time point’: for example, the tree ring formed this year in dendrochronology; the solidification of a volcanic rock in potassium-argon dating; or the formation of a calcite layer for uranium series.
This definable zero-point must have some relevance to the archaeological site being dated: potassium-argon dating of a piece of volcanic rock will date the formation of the rock, but it does not necessarily provide any useful information for the archaeologist; the rock may simply be part of the geological environment of the site.
On the other hand, if archaeological finds are sandwiched between two volcanic rock layers, then the dates for them will bracket the date of the archaeology.
Whether upper and lower date limits (terminus results) such as these provide the archaeologist with a sufficiently detailed chronological picture will depend on a number of factors — the nature of the site and sequence to be interpreted, the archaeological questions being posed, and the samples available for dating — and the relevant dating methods would then need to be assessed.
As the general reading list at the end of this chapter testifies.
a whole book could be written on any one of the scientific dating techniques, so selectivity must be exercised when covering the subject in a single chapter.
Only radiocarbon and thermoluminescence, the techniques which the British Museum has ‘in house’, will be discussed in any detail.
But this is not simply a parochial choice.
Radiocarbon was developed forty years  ago and is still the scientific dating method most commonly used by archaeologists.
Thermoluminescence is a complementary technique in the material and date range to which it is applicable; it also enables the authenticity of ceramics to be tested.
Any mention of radiocarbon dating necessarily involves at least a reference to dendrochronology, and the basic principles of this powerful technique are therefore also outlined (see p.125).
Radiocarbon dating
Basic principles
Radiocarbon dating is based on carbon — a common yet remarkable element.
Together with hydrogen, it is a component of all organic compounds and is fundamental to life.
Carbon has three naturally occurring isotopes, that is, atoms of the same atomic number but different atomic weights.
These are designated 12C, 13C and 14C in scientific notation, the letter C being the symbol for elemental carbon and the isotopes having atomic weights 12, 13 and 14 respectively.
They do not occur equally; modern carbon consists of 99 per cent of 12C and 1 per cent of 13C, whereas 14C is present at the level of only one part in a million million.
Unlike 12C and 13C, 14C is unstable and therefore radioactive: hence the name ‘radiocarbon’ is used for this isotope which, because of its scientific designation, is also called ‘carbon fourteen’.
Both here and in Chapter 8, the scientific notation (14C) will be used when referring to the isotope itself, and the word ‘radiocarbon’ when discussing the dating technique generally.
The rather unusual characteristic of 14C is that it is continually being formed.
This occurs in the upper atmosphere when neutrons produced by cosmic rays interact with nitrogen atoms.
As soon as they are formed, the 14C atoms rapidly combine with oxygen to form carbon dioxide which is chemically indistinguishable from carbon dioxide containing either of the other carbon isotopes.
This carbon dioxide mixes throughout the atmosphere, dissolves in the oceans and, via the photosynthesis process and the food chain, enters all plant and animal life known collectively as the biosphere.
Under certain circumstances, in particular if the production rate is constant, there is a balance between formation and decay, and the 14C concentration in the atmosphere therefore remains constant.
Thus, in principle, all living organisms have the same level of 14C relative to 12C.
When a plant or animal dies it ceases to participate in carbon exchange with the biosphere and no longer takes in 14C. If 14C were stable, its concentration relative to 12C would remain constant after death, but, since it is not.
the level falls at a rate determined by the radioactive decay law.
This law states that the number of atoms of a radioactive element is halved after a given amount of time has elapsed.
This amount of time is naturally enough called the half-life (T½;).
The relationship between the number of atoms remaining and time is shown in Figure 7.1.
In principle, therefore, if the concentration of 14C atoms remaining and the initial, or equilibrium, concentration can be evaluated by experiment, then one can determine  the amount of time which has elapsed since death.
For 14C, the best estimate of T½; is 5730 years.
In general, the materials which can be dated by radiocarbon are those which once formed part of the biosphere, and hence are organic.
For example, the most commonly preserved sample types occurring on British sites are bone, shell and charcoal, but on some sites — or in other areas of the world — a different range of materials might remain.
Wood and other plant remains such as ropes, cloth, reeds and seeds may be well preserved in arid environments or if waterlogged.
Many other materials, such as antler, horn, tooth, ivory, hair, blood residues, wool, silk, leather, paper, parchment, insects and coral, are also datable by radiocarbon.
The principles of radiocarbon dating are fairly straightforward, but in practice there are many problems.
One fundamental assumption is that the atmosphere has had the same 14C concentration in the past as now, and this in turn assumes, amongst other things, that the production rate of 14C has remained constant.
In fact there have been considerable variations in the atmospheric 14C production rate.
Radiocarbon results cannot therefore give a true measure of age and we need some method by which to convert them to calendar dates: this is the process of calibration (seep.124).
Nor can it be assumed that all parts of the biosphere have the same 14C concentration.
Firstly, in any biological pathway, differential uptake (fractionation) of the lighter isotopes of carbon occurs.
In addition, some of the carbon available to an organism may come from a source that is not in equilibrium with the atmosphere; the problems caused by this are called the ‘reservoir effects’.
For example, carbon in fresh water can have a variety of sources, including atmospheric carbon dioxide, but also soil humic material and limestone (calcium carbonate).
Thus freshwater shells and aquatic plants may not give true radiocarbon ages (see also fig. 7.2).
Whereas fractionation can be accurately corrected for, reservoir effects cannot.
Another factor is whether or not the death of a plant or animal necessarily coincided with the point at which it ceased to exchange carbon with the environment.
The outstanding example of radiocarbon age at ‘death’(or more usually felling) is wood.
It is well known that trees grow by the addition of rings, usually (though not always) annually.
Once formed, rings soon cease to exchange with the biosphere.
Hence, if one considers a long-lived tree, say a three-hundred-year-old oak, the innermost heartwood will give a radiocarbon result three hundred years older than the sapwood.
Indeed, this is as it should be.
However, if part of that heartwood were found on an archaeological site, the radiocarbon result would not provide the date of usage of the wood, but rather a date three hundred radiocarbon years earlier, and more if it has been seasoned before use or re-used.
This is the ‘old wood effect’.
Measuring radiocarbon
Once a sample is accepted for dating, the first task in the laboratory is to remove any likely sources of carbon contamination, such as carbonates and humic acids from the burial environment.
After this pretreatment, the sample is converted to a form suitable for the particular method of radiocarbon dating to be used.
These methods for detecting 14C are based on two fundamentally different principles.
The nucleus of a 14C atom is unstable so there is a finite probability at any instant in time that it will decay.
When it does, it reverts to nitrogen (14N) and a beta particle is emitted.
Because it is electrically charged, the beta particle can be detected fairly easily.
This is the basis of conventional radiocarbon dating.
A more efficient method for detecting 14C is to measure the number of atoms present, or a proportion of them, by mass spectrometry.
In a magnetic field, a moving charged particle is deflected from the straight path along which it was travelling.
When charged particles are travelling at the same velocity, and are subject to the same magnetic field, the heavier particles are deflected the least.
Detectors at different angles of deflection then receive particles of different mass.
However, normal mass spectrometers are not sensitive enough to detect 14C and to reject all other elements or molecules of very nearly the same weight, such as 14N. As this nitrogen isotope makes up some 80 per cent of the atmosphere it is very common relative to 14C. The techniques of nuclear physics were brought to bear on this problem in the late 1970s, and it was shown that 14C could be detected using what is now referred to as accelerator mass spectrometry, AMS.
In AMS the charged particles are subjected to large voltage differences so that they travel at very high speeds.
This enables various devices to be used in order to discriminate against the much more abundant elements and molecules which would otherwise swamp the 14C signal.
The disadvantage of AMS is the high cost of establishing such a facility (around a million pounds sterling, nearly two million dollars) and of running it.
Its great advantage over conventional techniques is the small sample size needed: typically 1000 times smaller.
Most conventional radiocarbon laboratories require a sample that will yield about 5 g of carbon.
This is equivalent to about 10 g of charcoal, 50 g of wood or 200 g of bone, but depends on the state of preservation of the sample and degree of sample pretreatment to be undertaken.
Small objects (fig. 7.3) that would have been totally destroyed if dated by conventional 14C can now be sampled for AMS, 5; and the benefits in dating art objects are obvious.
Likewise in archaeology AMS has enabled us to date samples as minute as individual seeds, which can tell us a great deal about the origins of agriculture and the domestication of cereals.
Whatever the technique, radiocarbon results are given in uncalibrated years BP, where 0 BP is defined as AD 1950 and the half-life used to calculate a radiocarbon result is not the more accurate value of 5730, but the Libby half-life of 5568 years (named after Willard Libby, the founder of the technique).
Use of the wrong half-life is automatically taken care of in the  calibration of a conventionally calculated date.
In addition to determining the radiocarbon ‘age’, the laboratory must estimate the uncertainty on the experimental measurement.
For radiocarbon ‘ages’ below about 10,000 years, the error term is typically plus/minus 50–100 years (at the 68 per cent confidence level: see glossary).
High-precision laboratories can produce results with error terms of less than plus/minus 20 years; they employ very carefully controlled measurement procedures, but they also require samples three to four times the size of those used by normal-precision, conventional laboratories.
In conventional radiocarbon dating the maximum age that can be measured is determined by the count rate, additional to that from 14C, caused by radiation in the environment.
It therefore varies from laboratory to laboratory, but is typically in the region of 40,000 years.
For AMS, the upper age limit is determined by other factors such as machine stability and the degree of modern contamination introduced in the processing of very small samples; the values tend to be similar to those for conventional radiocarbon laboratories.
The lower limit for both techniques is determined by the mutual interference of the fossil fuel and bomb effects.
In the early half of the twentieth century, the burning of fossil fuel such as coal, in which the 14C had totally decayed away, diluted the atmospheric 14C concentration relative to 13C and 12C. Nuclear weapons testing had an even more dramatic effect on atmospheric 14C content.
The neutrons thereby produced in turn produced 14C by interaction with 14N. This simulated natural cosmogenic production, albeit in large bursts, and roughly doubled the atmospheric 14C content as measured in about 1965.
Radiocarbon results of less than two hundred years are therefore usually described as ‘modern’.
Calibration of radiocarbon results
The existence of radiocarbon in nature was predicted before it was detected, and this prediction was sufficient for an American scientist called Willard Libby to perceive the basis of a dating method.
The theoretical aspects were formulated in the mid-1940s and the first dates were published in December 1949.
During the 1950s, with advances in techniques for detecting 14C, discrepancies of several centuries began to emerge between radiocarbon ages and historical ages for the Egyptian Old Kingdom.
Of course, the validity of the historical ages was not proven beyond doubt, but it was realised that tree rings could provide the truly ‘known-age’ material needed to test the accuracy of the new technique.
The radiocarbon discrepancy was confirmed and it became clear that radiocarbon results would need to be calibrated to convert them to calendar ages.
Since there is no theoretical way of predicting the correction factor, empirical calibration curves were needed to link radiocarbon ‘age’ with known age.
In the 1960s, a continuous tree-ring sequence stretching back some eight thousand years was established by Wesley Ferguson, an American dendrochronologist.
The first calibration curve using this was published by an American scientist, Hans Suess.
High-precision calibration curves now exist which confirm the two features apparent in Suess's curve.
First there is a long-term trend caused by fluctuations in the earth's magnetic field strength.
This trend has a maximum deviation from true age of about nine hundred years too recent at the beginning of the fourth millennium BC.
On the other hand, in the middle of the first millennium AD, radiocarbon produces ‘ages’ that are too old by a century or so (fig. 7.4).
The second  feature takes the form of ‘wiggles’.
These are superimposed on the main curve, and only last a few decades, but can have deviations on the radiocarbon axis of a century or so (fig. 7.5).
They are probably produced by variations in sunspot activity.
Any variations in production of 14C are rapidly distributed throughout the atmosphere, so a calibration curve of radiocarbon ‘age’ versus calendar age for one material and one geographical region will serve as a global calibration curve.
Once the calendar timescale has been produced using dendrochronology, groups of ten or twenty tree rings are dated by radiocarbon to provide the y-axis of the calibration curve.
The basis of dendrochronology lies in the fact that, in temperature climates where there is a contrast between the seasons, trees grow by the addition of an annual ring.
The growth region is a thin band of cells called the cambium, which lies between the bark and the sapwood.
Division of these cells adds new bark to the outer side of the cambium and new sapwood to the inside.
The well-defined rings (fig. 7.6) are due to the difference in the cells produced at different times of the year.
For some species, the width of each ring depends on prevailing climatic conditions, such as temperature and rainfall.
Thus, for a living tree, counting backwards from the cambium layer gives the age of a particular ring, and its relative thickness indicates whether the growing season was good or bad in that year and locality.
Trees of a single species growing in the same locality should have a similar pattern of ring widths, uniquely defined by their common history.
This is the basis of cross-dating: being able to associate a tree-ring sequence of unknown age with one of known age by matching one pattern with another.
Long chronologies (‘master curves’) are established starting with living trees, or timbers where the ‘zero age, ring is present and the year of felling known (fig. 7.7).
The timescale is then extended by using large felled timbers with patterns sufficiently overlapping the existing chronology to be certain of a unique match.
In dendrochronology the timescale of the master chronology is accurate to within one year.
It is therefore a very powerful dating technique making it possible to date the right archaeological samples (see p. 144) to the year of felling, as well as providing the accurate calendar timescale necessary for radiocarbon calibration.
In converting radiocarbon results to calendar dates, the wiggles in the calibration curve are the real problem.
One consequence is that calibrated dates are not central dates with an error term, but a range or ranges of dates.
In fact, there is currently no consensus on exactly how to calibrate a radiocarbon result.
Essentially there are two approaches: the intercept and probability methods.
A brief description of the intercept method should provide a flavour of what happens when a radiocarbon result is calibrated.
As shown in Figure 7.8, the calendar dates corresponding to t+$ and t-$ are found (where t is the radiocarbon result and $ is the error term, which includes the laboratory's estimate of the experimental error on the result and the error on the calibration curve, combined statistically).
Using the values t+$ and t-$ gives 68 per cent confidence ranges (see glossary); for 95 per cent confidence, t + 2$ and t — 2$ must be used.
If the calibration curve is ‘wiggly’, there will be multiple ranges.
Note also the increased size of the calibrated range relative to the uncalibrated one where the slope of the curve is effectively less than 45 degrees, and the decreased size where the slope is steep.
It must not be assumed that the most likely date is in the centre of the range; to quantify the distribution of the calendar dates, one of the probability methods (which require computerisation) must be used.
Although calibration complicates the process of interpreting the radiocarbon results, it is essential.
There are several periods in the calibration curve where events that are separated in calendar time by several centuries appear approximately contemporaneous from their radiocarbon results.
The worst of these is for the period corresponding to the British Early Iron Age (c.800–400 BC).
There are also periods where the curve is so steep that apparently large differences in radiocarbon results arise from events separated by relatively small amounts of real time.
Only after calibration can we begin to assess the true temporal relationship of events dated by radiocarbon.
To distinguish calibrated dates from true historical dates, the conventions cal BC, cal AD and cal BP (where 0 BP is AD 1950) are used.
Using radiocarbon dating
When radiocarbon dating was developed and first used in the late 1940s and 1950s, the complexities of the technique were not fully appreciated.
For the best results in a given situation, archaeologists and radiocarbon scientists must work together, from the planning of a sampling strategy to the interpretation of the results.
As we have seen, the interpretation is complicated by the need for calibration, and the involvement of statisticians is increasingly valuable.
Once the archaeological problem has been formulated, whether or not radiocarbon can be used to resolve issues of chronology will depend on a number of factors, such as the type of samples available, the nature of the contexts and events to be dated and the likely age range once the radiocarbon results are calibrated.
The interplay of these factors is illustrated by the following case studies.
British Beaker chronology
The second half of the third millennium BC saw the introduction of the first metalworking into Britain.
This very early phase of the Bronze Age was also marked by the appearance of a distinctive ceramic form called the Beaker, which also lends its name to this period of transition from the Neolithic to the Early Bronze Age.
Beaker pottery is characterised by often skilfully made vessels with an S-shaped profile and zones of geometric decoration produced by impressing twisted cords, stamps or combs into  the clay.
Much time would have been invested in making these fine vessels, and many were apparently viewed as prestige items fit to be placed with burials of the period (fig. 7.9).
Often only a Beaker accompanies the body, but occasionally other grave goods occur.
such as copper-alloy knives, archers' wristguards of stone and, in some instances, even personal ornaments made of gold.
Beaker pottery is very widespread in Europe and there is little doubt that the style was initially introduced to Britain from the Continent.
However, the chronological development of Beaker styles and the possibility of further Continental influence were open to conjecture.
Through past study a broadly accepted relative chronology for Beaker pottery had been developed.
This was based on classification of the proportions of the bodies of the vessels and the decorative motifs employed.
Until recently, there were few radiocarbon results for material directly associated with Beaker pottery.
Furthermore, of these few results, a substantial number were for charcoal, with all the attendant problems of possible age offset due to‘old wood’(see p. 121).
Hence neither the relative nor the existing absolute dates were totally satisfactory.
To remedy this situation, the British Museum initiated a research programme of radiocarbon dating.
The aim was to locate forty to fifty samples well associated with Beaker pottery in a variety of styles.
The obvious choice of sample was the skeletal material in the Beaker burials themselves, because for bone there is no time delay between death and cessation of 14C exchange with the biosphere.
Also, the association is good between sample and context (bone and grave), and between context and event to be dated (grave and the act of burial).
The theoretical basis of the project was  therefore straightforward, but in practice it proved significantly less so.
Museums and archaeological collections throughout Britain were contacted and, although many were willing to help by providing samples for dating, problems emerged.
Much of our knowledge of Beaker burials derives from excavations conducted in the last century, when the principles of good archaeological practice were only just beginning to be formulated.
Where bone from burials had been retained, the frequent lack of adequate documentation made it impossible to associate definitively one particular skeleton with a given Beaker pot.
Many frustrating searches and months later, the total number of samples collected was only twenty-eight and, worse still, nearly half of these had to be rejected, either because of carbon contamination introduced during conservation treatments, or because the sample was too small to give a reasonably precise result.
Fortunately, samples from recent excavations have subsequently become available, and the project has now produced twenty radiocarbon results: more than doubling the previous total for actual skeletons from British Beaker burials.
What of the results?
As always, the need to calibrate the radiocarbon ‘dates’ means that normal statistical tests cannot be applied.
It is therefore impossible to test statistically whether samples associated with a particular type of Beaker pot are earlier or later than those linked to another.
However, graphical plots of the date ranges show no clear chronological pattern.
The foundation of many theories of Beaker pottery development and the effects of Continental influence must therefore be re-examined.
Early mining in Wales
Trying to be highly selective in the type of sample submitted for radiocarbon dating can be very frustrating, as illustrated by the Beaker project outlined above.
It is nevertheless essential in the majority of situations where there is a specific question on the chronology requiring an accurate and reasonably precise answer.
Not all contexts allow such careful choice, however, and it has to be decided whether a set of radiocarbon results using less than ideal samples provides better dating evidence than the archaeology alone.
One such case is the search for evidence of early mining in Britain.
Much is known about the metal artefacts produced in the British Bronze Age, but until recently very little was known of the copper sources exploited (see Chapter 4).
Mines have very few chronologically distinctive features.
Unlike habitation sites, they have little domestic refuse and, unlike cemetery sites, they do not normally contain burials.
Consequently, there are rarely any really diagnostic ceramic or metal artefacts that can provide any clue as to their age.
On the other hand, there are two recurring characteristics of certain copper mines: the use of firesetting and pebble-stone hammers.
Some would argue that these provide clear evidence of prehistoric exploitation, whilst others see them as highly practical, and therefore long-lived, mining methods.
The problem boils down to a lack of independent dating evidence.
Like other debris, there is a limited amount of organic refuse suitable for radiocarbon dating, and what there is tends to be charcoal from mature oak.
Although the wood is presumed to have been used for  firesetting. the association between mining activity and the sample is rarely certain.
Thus, when there were only one or two dates for supposedly early mine sites, their relevance had to be interpreted with care.
Now, however, for Welsh copper mine sites alone there are fifteen radiocarbon results.
all of which calibrate to the Early or Middle Bronze Age; such a body of evidence cannot be chance.
Thus the long and laborious process of collecting anything that might conceivably be datable has paid dividends, placing several Bronze Age mines firmly on the map.
Thermoluminescence dating
Basic principles
The principles of thermoluminescence (TL) dating are reasonably straightforward, but the details of the TL mechanism are not fully understood — even by solid state physicists!
The principles of TL dating are here outlined for pottery, for which it was first developed; its extension to other materials is discussed later.
Thermoluminescence is a property of crystalline materials, such as quartz and feldspars, which are found in pottery.
These minerals receive radiation both internally, from the ceramic, and externally, from the burial environment and cosmic rays.
The ceramic and soil contain minute quantities of uranium, thorium and potassium which are radioactive, and when these decay they produce alpha, beta and gamma radiation (potassium contributes only to the beta and gamma components).
These radioactive elements have very long half-lives, so the flux of radiation is effectively constant for the archaeological periods of interest in TL dating.
Alpha, beta and gamma radiation, together with cosmic rays, are referred to as ionising radiation because they interact with atoms, removing electrons from them, and the atoms then became ions.
In this way the radiation loses energy, which is imparted to the electrons of the material.
The amount of energy lost to the material per unit weight is referred to as the ‘radiation dose’.
When minerals such as quartz and feldspars have received a radiation dose and are then heated, they emit light.
This is thermoluminescence (‘heat-light’); it is produced because of the radiation dose, and is additional to any red-hot glow produced by heat alone.
Thermoluminescence is emitted because crystal lattices contain defects, and electrons produced by the ionising radiation may become trapped at one type of defect (a ‘trap’).
This is only one of the things that can happen to the electrons, but it is the one which is of interest in the production of TL.
Depending on the nature of the defect, electrons may remain trapped for long periods of time; such a trap would be referred to as ‘deep’.
If heat is applied, the electron may be able to escape from the deep trap.
Again, however, many things can then happen to it; if it is to produce TL, the electron must recombine with another type of defect, and the recombination process must produce energy in the form of light.
This type of defect is referred to as a ‘luminescence centre’.
The intensity of the TL produced by the deep traps is roughly proportional  to three factors: the amount of radiation received per year; the TL sensitivity of the sample (i.e. the amount of TL produced per unit of radiation dose); and the time, in years, that has elapsed since the sample was last heated.
The last of these factors is the age of the pot, because its initial firing by the potter in antiquity would have ejected all the trapped electrons (thus ‘zeroing the TL clock’), from which time the electron population in deep traps would have steadily built up.
The basic age equation is: where the ‘natural TL signal’ is the TL measured on the first heating of a sample in the laboratory.
In principle, therefore, if the three factors on the right-hand side of the equation can be measured, then the pot can be dated.
In practice the situation is not quite so simple, and many measurements and checks must be made by the TL scientist, only a few of which will be mentioned here.
The upper age limit of TL dating depends on the stability of the signal, on the saturation level of the TL material and on the annual radiation dose.
The stability of the signal is usually determined by the depth of the trap: the deeper it is, the more stable the signal.
However, other factors can also affect stability (see, for example, anomalous fading, p. 1 33).
Saturation occurs when the TL signal no longer increases significantly with the addition of further radiation; this is due to the filling of the traps with time.
The radiation dose which produces saturation is related to the concentration of defects in the crystal.
However, the time at which this level of radiation dose is reached depends on how quickly the radiation dose is received; the lower the dose rate, the longer it will take to reach saturation.
In consequence, it is not possible to attach a single number to the upper age limit of TL; rather it is specific to each type of sample and each archaeological site.
The few generalisations that can be made are discussed at appropriate points below.
Determining TL age
The TL produced by archaeological samples such as pottery is weak and its measurement therefore requires sensitive light-detecting equipment such as a photomultiplier, which converts the light signal to an electrical one.
The signal is plotted as the temperature of the sample is increased, up to 500°C typically, and the output is referred to as a glow curve (fig. 7.10).
So-called ‘artificial’ glow curves can be induced in the laboratory using alpha and beta radiation sources.
Thus the TL sensitivity of the sample to radiation can be determined.
In fact, this involves taking a large number of TL measurements to check or correct for changes of TL sensitivity and non-linear growth of TL with dose.
Some of the checks for stability of TL signal involve the use of the plateau test.
This compares the shape of  the natural TL glow curve (see fig. 7.10) with that induced by a laboratory dose: at low temperature the signal is not stable and the ratio of the TL signals varies, but at temperatures above about 300°C there should be a plateau.
The radioactive components in the pottery and the soil are uranium, thorium and potassium, which can be readily detected by analytical techniques such as neutron activation analysis (see glossary), and their contributions to the dose rate then calculated from knowledge of how they decay radioactively.
However, particularly for the gamma-ray contribution, more direct measurement of the radiation dose is usually employed.
The gamma radiation has a range of about 30 cm, and for a typical sherd of pottery, this means that the soil contributes the majority of the gamma dose.
If this contribution is to be representative of the burial environment within a 30 cm radius, it is best measured in situ , either using small metal capsules containing a highly TL-sensitive material buried for about one year, or using a calibrated gamma ray spectrometer.
There are many measurements involved in evaluating a TL age, each of which is subject to measurement errors.
To improve precision, it is usual to date several samples from the same archaeological level to determine the mean age.
Even so, the resulting error term is still typically plus/minus 5–10 per cent of the age, at the 68 per cent confidence level (see glossary).
However, occasionally, if it proves impossible to measure any one of the factors in the age equation accurately, no TL date for a site may be obtained at all.
Other TL-datable materials
For a sample to be datable by TL it has to be crystalline but non-metallic.
It also has to have some mechanism by which the latent TL signal is zeroed  that can be related to an archaeological or geological event of interest.
Thus, for pottery dating, quartz and feldspars satisfy the initial criteria, and the zeroing mechanism is the firing of the ceramic.
Heat also resets the TL clock in a range of other materials:
volcanic minerals and sediments underlying a lava flow
clay, other than pottery, which has been deliberately subjected to heat (e.g. walls and bases of kilns and hearths, metal-production debris such as tuyeres and furnaces, core material remaining in bronzes after casting on a clay core), or heated accidentally (e.g. daub from a house burnt down in a fire)
stones, such as flint, heated either deliberately (e.g. cooking stones heated in a fire, then used to boil water) or accidentally
vitrified materials, such as glass itself or slag from metallurgical processes.
At first sight the last category might not seem to fit the dating criteria since glass is strictly speaking amorphous rather than crystalline, but it can have a sufficiently crystalline structure for TL to be produced.
However, even if the natural TL signal can be measured, the dating of both glass and slags is rarely satisfactory: glass gives problems because of its transparency, which allows the TL signal to be bleached by light (see below), and slag can be very inhomogenous in its radioactivity content.
The feldspars in volcanic lava flows can also be problematic.
Indeed, it was the initial attempt to date these which led to the discovery of anomalous fading.
This is the name given to rapid loss of the TL signal from that part of the glow curve normally thought to be stable.
A safer approach is to date quartz within the flow, or from the underlying sediment heated by the flow.
Dating baked clay and burnt stone are perhaps the most interesting archaeological applications of TL, because these — in particular burnt flint — allow the dating of sites older than about ten thousand years, when the first pottery began to appear.
Because of its low internal radioactivity, flint is especially good for dating the Palaeolithic back to at least 250 ka (1 ka = 1000 years).
Apart from heat, there are two other main zeroing mechanisms: crystal formation and exposure to sunlight.
Without a crystal structure, there can be no TL; hence, the formation of a crystal such as calcite is ‘time zero’ for TL dating.
It is important to date stalagmites or flow stones, rather than stalactites, since the formation of the latter is not readily relatable to any archaeological event.
With stalagmitic calcite, the position of the calcite in relation to the archaeological levels will provide at least a terminus result, and in some cases the archaeology may fortuitously be sandwiched between two datable calcite layers.
If there is detrital material in the stalagmite, such as clay and limestone, it will not have a zero TL signal at the time of the stalagmite's formation.
The amount of detrital material determines the lower level of TL dating of calcite.
The useful age range may therefore be 20–300 ka, although its true limits have not been adequately explored.
In some of the early work on TL dating of ocean sediments, it was thought that the TL observed was produced by foraminifera or radiolaria and that the zeroing mechanism was the formation of their shells.
In fact it was the sediment particles attached to the shells which were producing the TL.
These were most likely to have been zeroed by the action of sunlight prior to their deposition on the sea bed.
In recent years, TL has increasingly been applied to the dating of terrestrial sediments.
Loess, in particular, is an obvious sediment for TL dating since it is fine-grained.
Also, while being transported by wind, it will have been exposed to sunlight for a considerable time prior to deposition.
Perhaps more than any other application of TL, sediment dating has fired the most interest.
This is largely because of its enormous potential for dating geological processes and sedimentary sequences.
The lower limit of TL dating of sediment is closely linked with uncertainty about how far the sediment was bleached in antiquity, and this led to development of the optically stimulated luminescence (OSL) technique.
On the other hand, the apparent upper limit of TL dating of sediment seems to depend on the methodology used, and there is currently no consensus on the matter other than that this limit is at least 100 ka: many dates are being produced well in excess of this value, but there are rarely independent and reliable age estimates against which to compare them.
Having ranged rapidly through the materials that are datable by TL, we must not forget that it is also widely used in authenticity testing of both ceramics and the casting cores of bronzes.
These applications are discussed in Chapter 8.
Using TL dating
Pontnewydd Cave
Pontnewydd Cave (fig. 7.11) is situated near Rhyl in North Wales and is one of only two British sites having hominid remains of the Middle Pleistocene period.
It also exemplifies the potential, and some of the problems, of TL dating beyond the range of radiocarbon.
Continued involvement of TL scientists through the different seasons of excavation has enabled them to collect samples and bury capsules to measure the associated gamma radiation dose rate, burying a capsule one summer and retrieving it the next.
For calcite dating by TL, the use of TL capsules is essential.
A gamma spectrometer cannot be used because a hole about 5 cm in diameter is required for the probe; it is extremely hard work to drill the 1 cm hole needed for a capsule, and anything larger would be impossible!
Also, many calcite layers are relatively thin and surrounded by non-calcite levels; removal of a 5 cm diameter part of the layer could well result in an unrepresentative measurement of the gamma dose rate.
The chief difficulty in dating Pontnewydd Cave arose because the gamma dose rates varied locally within the cave deposits.
The infill of the cave is made up of a wide variety of materials, from silts to large stones, and the radioactive content of these materials is similarly variable.
Those which are datable, the stalagmites and burnt flints, have low concentrations of the radioactive elements uranium, thorium and potassium, as does the limestone which is also found within the deposits.
However, other stones and sediments interspersed with these contain far greater amounts of radioactivity.
It is not always possible to measure the gamma dose rate at exactly the spot where a sample for dating is found, since the excavation of the sample will have removed much of the material surrounding it.
Capsules have to be buried as near as possible, but there is no guarantee that the measurement will be truly representative.
The burning of flint samples should be directly associated with the date of occupation of the site.
TL dates of three burnt flints have been measured at the British Museum, and these straddle a mean of 190.000 years BP, but there is a large variation about this mean because of the inhomogeneity of the radiation environment in the cave outlined above.
Measurements on a single burnt flint, carried out in Oxford.
also indicated an age of about 200,000 years.
Some of the deposits from which the burnt flints derived were overlain by an undisturbed stalagmitic floor.
The dating of this floor, which has been carried out using both TL and uranium series dating (see p. 118), generally confirms the occupation dates obtained from the burnt flints.
By the TL method, the stalagmitic floor is dated to around 170,000 years BP.
The uranium series measurements give a slightly older date of 205,000 years BP, but given that the uncertainties in each of these figures are typically 20 per cent, the two techniques can be said to agree with each other .
Such margins of error and variation in results may seem large, but they have to be viewed against the alternative: no independent dates at all.
The picture of the history of Pontnewydd Cave that emerges from these and other date measurements is now fairly well established.
The occupation of the site, at the cave mouth, occurred around 200,000 years ago.
Within a few thousand years, the debris left by the occupants — including some of their remains, their artefacts and the burnt flints — was incorporated in a deposit which was forced into the cave from the outside by water.
Upon  the upper surface of this deposit, stalagmitic floors formed, and continued to do so intermittently and in different parts of the cave, until a further inflow of material entered the cave between 80,000 and 30,000 years ago.
The growth of stalagmites resumed on top of this fresh deposit when the climate warmed up around 18,000 years ago.
Bermondsey Abbey
Although TL really only comes into its own beyond the range of radiocarbon dating, it can also provide answers to specific archaeological problems where no suitable radiocarbon samples exist.
Excavations at Bermondsey Abbey in south-east London uncovered a large drain.
Not a prepossessing feature in isolation but, to the archaeologist, understanding the origin of the contents of the backfill of this drain could play an essential part in unravelling the history of activities on the site as a whole.
The backfill material contained a considerable amount of pottery, which was stylistically attributable to the second half of the eleventh century AD, along with much burnt clay or daub thought to derive from wattle walls.
Stratigraphically the ditch was backfilled before the construction of the first phase of the priory church and was thus before AD 1090.
The mystery was the origin of the large quantities of daub.
This daub could have come from one of three distinct periods.
One possibility was that it was Roman material introduced when the drain walls had collapsed, for the drain had been cut through Roman deposits.
A second possibility was an origin in the Middle Saxon period in the first half of the eighth century AD: evidence for this occupation comes from both documentary sources and finds from the site.
The third alternative, and the most straightforward interpretation, was that the daub was contemporary with the backfilling of the drain.
Given the possible mixed origins of the backfill, dating the daub by other associated material such as charcoal could not solve the problem.
Provided the gamma dose rate, which had possibly changed at some point in the history of the daub, was not a dominant contribution to the TL age, TL could solve the mystery.
The gamma dose rate proved to be only about 20 per cent— reasonably typical for clay materials.
Three pieces of daub were dated and provided an average age and standard error of 830 plus/minus 40 years.
In other words, the true date lies between TL 1080 and 1240, with 95 per cent confidence, clearly demonstrating that the third alternative holds: the daub is broadly contemporary with the backfilling of the drain and coincides with clearance of buildings in the eleventh century AD to make way for the building of the priory church.
Radiocarbon or thermoluminescence?
For a particular archaeological site, the choice of dating method depends largely on the materials available and the age of the site.
If we had to choose between radiocarbon and TL dating, then we would have to take into account that radiocarbon is used for organic materials and has an upper age limit of about forty thousand years, whereas TL is applied to  inorganic samples and can be used beyond the range of radiocarbon.
Another factor to bear in mind is that, unlike TL dating, radiocarbon is independent of the archaeological burial environment, provided that potential contaminants have been removed in the pretreatment process.
In situations where both methods could be used, the choice depends on the association between the sample and the event to be dated, as well as on the likely error terms.
TL typically produces an error term of plus/minus 5–10 per cent of the age, i.e. plus/minus 50–100 years for a TL age of 1000 years, plus/minus 100-200 years for 2000 years, and so on.
In contrast, radiocarbon typically produces error terms of plus/minus 50–100 years, independent of age, for ages less than about 10,000 years, after which the error increases.
However, unlike TL dates, radiocarbon results have to be calibrated and the size of the resulting age range depends on the form of the calibration curve in that period (fig. 7.8), although the radiocarbon age range will generally be smaller than the corresponding TL one.
Hence TL is normally used in the following situations: beyond the range of radiocarbon: when no organic material has been preserved on the site: when the association between the event to be dated and the radiocarbon content of the organic samples is poor; or for the few periods where the age range on a calibrated radiocarbon age is larger than the corresponding TL error term.
Whatever the technique — be it radiocarbon, TL, or one of the many others — there are optimal circumstances under which it works best.
Occasionally there are situations where two techniques can be used, and there may be good reason to apply both so that they provide supporting evidence for each other(for example , see p. 134 for the use of TL and uranium series dating at Pontnewydd Cave).
Concluding remarks
Scientific dating techniques, and none more than radiocarbon, have revolutionised the archaeologist's understanding of human cultural development.
Before the advent of radiocarbon, chronologies for later prehistory in Western Europe were often based on presumed linkages, however tenuous, with those civilisations of the Near and Middle East which had historical calendars.
The chronological extrapolation to Western Europe then required the postulation of models about the rate of diffusion of ideas.
Thus Stonehenge was presumed to postdate the tholoi of Mycenae, and the time taken for agriculture to spread to Britain was thought to be so great that the inception of the Neolithic was placed at about 2500 BC.
Radiocarbon, particularly once the need to calibrate was accepted, has shown that the development of Stonehenge lasted several centuries with Mycenae being only contemporary with the final phase; thus the independent invention of megalithic monuments had to be accepted.
Just as dramatically, radiocarbon dating has shown that the Neolithic was introduced to Britain at least 1500 years earlier than previously believed.
Radiocarbon alone cannot provide the absolute dates that archaeologists require.
Calibration of radiocarbon results relies totally on the provision by dendrochronology of a reliable calendar timescale.
precise to the year.
The origins of dendrochronology lie in climate studies and it was then applied to dating.
But the benefits have come full circle, for the long master chronologies subsequently established for archaeological dating and calibration of radiocarbon results are now of just as much value to climatologists studying cycles in weather patterns associated with factors like sunspot activity and variations in the earth's orbital parameters.
Beyond radiocarbon, other techniques such as TL are providing dates that can aid in the understanding of human evolution.
For example, it is now known that in Israel anatomically modern humans were present some 90,000 years ago and that there was human occupation of Australia 50,000 years ago.
Much earlier still, potassium-argon dating has provided a chronological framework for the early hominid finds in East Africa.
Between them, the scientific techniques available thus span very wide time ranges and are indispensable in the continuing search for answers to questions of chronology.
Further reading  
Spotting the Fakes Paul Craddock and Sheridan Bowman
A wide range of scientific methods can be usefully employed to unmask fakes and fraudulent restorations, in much the same way that forensic methods are used in criminal investigations.
However there is one obvious question to ask about authenticity testing: if scientific dating methods can be used, why bother with any other techniques?
It is, after all, the date of the object that is in question.
The simple answer is that not all materials lend themselves to scientific dating.
We must therefore resort to more indirect methods, such as the variation with time of copper-alloy composition or technology of production.
Indirect methods require the establishment of appropriate databases against which to compare the composition, or other characteristic, of the questionable object.
Here, the value of well-documented museum collections or excavated finds cannot be overstated.
In contrast, dating techniques do not require this comparative material; they tell us immediately whether or not the object is genuine — at least, they do in theory!
There is another less obvious reason why other techniques might be applied in an authenticity study, even when a dating method can be used.
The material with which a major museum has to deal, both within its own collections and on offer to it, will have come from a wide variety of sources.
Very often the history of an object is not known at all and there may be reason to believe that it is not all that it purports to be.
The problem is often not just whether it is genuine or fake, but rather how much is original, and what has subsequently been done to the object, when, by whom and why.
A badly damaged object may have been repaired, or the whole object may be a confection of previously unassociated fragments.
A genuine but mundane antiquity can have its value increased enormously by the addition of a unique feature, or of a historical association such as a royal cipher.
Given the complexity of many of the objects, and the almost endless possibilities of treatment that could have befallen them, the scientist needs the collaboration of the art historian, in addition to a very wide experience of antiquities and knowledge of the technical processes of the past, in order to reconstruct as much as possible of a particular object's background history.
Some of the scientific methods and problems encountered are exemplified below by specific case histories.
The main approaches to the scientific detection of fakes are: the study of composition and methods of construction to see if they match the supposed age of the object; examination for evidence of aging, such as the formation of a patina; and the application  of archaeological dating techniques, which can at least give an indication of age and in some cases an actual date.
Scientific dating techniques
The most widely used dating techniques for authenticity testing are thermoluminescence, radiocarbon and dendrochronology: how they work is outlined in Chapter 7.
In their application to authenticity testing the first consideration is whether the sample size required is likely to inflict unacceptable damage.
The object may prove to be genuine, but this is little consolation to the owner if it has been largely destroyed during the authentication process.
Radiocarbon dating
Until relatively recently, radiocarbon dating would have fallen into the largely destructive category.
Conventional radiocarbon dating normally requires sample sizes which will yield a minimum of 1 g of carbon.
This may not sound much but it is equivalent, for example, to about 400 sq cm of cloth or 50 g of bone.
The advent of small sample systems, in particular accelerator mass spectrometry (AMS, see p. 122) has placed all but the very smallest objects within reach of radiocarbon: AMS only requires about 1 milligram of carbon.
The sample preparation procedures are the same as those used for radiocarbon dating, care being taken to avoid contamination.
The range of objects tested covers the whole spectrum of datable materials found on archaeological sites but also encompasses more exotic items such as embroidered silk and carved ivory.
All of the caveats that apply to radiocarbon dating apply to its use in authentication.
One might even have to be careful about possible re-use of materials which would produce a radiocarbon result older than the true age of manufacture of the artefact.
It was, for example, quite common in the last century for ivory objects to be carved from mammoth tusk that had been preserved in the permafrost of the Siberian tundra since the last Ice Age!
The application of radiocarbon dating is usually relatively straightforward, and the dating process will produce a result with an error term that is just as good as for any archaeological sample.
In many authenticity studies there is rarely a problem in distinguishing very recent from ancient.
Indeed, an artefact made since about 1955 will give an apparent radiocarbon age that is some time into the future because of the excess radiocarbon produced in the atmosphere by nuclear weapons testing (the ‘bomb effect’, see p. 123).
To interpret a radiocarbon result in terms of calendar age requires that it be calibrated (see p. 124).
Where problems can arise is in distinguishing between possible dates in the last few centuries, but prior to the bomb effect.
A canvas may be perfectly genuine if shown to date to the seventeenth century, but be a fake if it is nineteenth century.
Here radiocarbon cannot help.
The calibration curve is so wiggly in this region that the possible alternative date ranges encompass both periods (see figs 7.5 and 7.8).
The most well-known application of radiocarbon must be the dating of the Shroud of Turin.
This linen cloth, some 4.25 m in length, bears the shadowy image of the front and back of a man who appears to have been scourged and crucified, and it is therefore believed to have been Christ's burial shroud.
Its history is known with certainty back to about AD 1350, when it was in the possession of the de Charny family in France.
Even then it appears to have caused something of a religious furore, being declared by some to be a fake and by others to be the true Shroud.
In 1898, the first ever photograph of the Shroud showed that the image, when seen in negative, is strikingly life-like (fig. 8.1).
This discovery and subsequent medical findings fuelled suggestions that the cloth could conceivably be genuine.
Despite the large size of the Shroud, removal of the area of cloth needed for normal radiocarbon dating would have inflicted unacceptable damage.
Thus it was not until the AMS technique had been perfected that a fragment of the linen could be removed for dating.
This fragment, measuring only a few square centimetres, was divided up and samples, the equivalent of about 50 mg in weight, were given to three accelerator laboratories in Oxford, Zurich and Tucson.
The British Museum was asked to participate in the certification of the sampling and the statistical analysis of the results.
The calibrated radiocarbon result was AD 1260–1390 (at the 95 per cent confidence level: see glossary); this accords well with the Shroud's first appearance in France.
However, until it can be properly established how this striking image came into being, the mystery will not be completely solved.
Indeed, the controversy raised in the fourteenth century over the authenticity of the Shroud has been revived rather than settled by the radiocarbon date.
Thermoluminescence dating
If AMS is used, there is no fundamental difference between radiocarbon as applied to authenticity testing and archaeological dating.
This is not the case with thermoluminescence (TL) dating, which requires several grams of pottery.
This is rarely a problem for dating an archaeological site where fragments of broken pottery tend to abound, and it is usual to date several sherds from the same context to provide an average age and better precision.
Clearly, however, one cannot remove such a large sample from a fine ceramic artefact on offer to a museum.
The other problem is that part of the radiation dose which induces the TL signal is from the environment the object has been kept in, and the precise storage history over the lifetime of most antiquities is not known.
These two problems can be overcome but at a price in terms of the overall precision and accuracy of the result.
A sample weighing about 30 mg is drilled from an inconspicuous area of the object, usually the base.
This sample size is just sufficient to allow a limited number of measurements to be done.
From dating studies on archaeological ceramics, we know that the environment does not make the largest contribution to the annual radiation dose of ceramics, and a  likely range of environmental radiation values can be assumed in estimating the TL age.
This is normally adequate to distinguish recently made objects — fakes — from those genuinely manufactured in antiquity.
In addition to pottery, the core material from bronzes that have been cast using a clay core (see p. 84) can also be tested by TL, since this ceramic material has normally been fired to a sufficiently high temperature to ‘zero the TL clock’.
Porcelain can also be TL tested, but it is such a hard ceramic that a drill cannot be used to take the sample because of the heat generated and the spurious luminescence signals produced.
Samples can, however, be taken by using a diamond-impregnated coring bit.
The small cylinder of sample removed is then sliced, like a loaf of bread, and the slices are used for the TL measurements.
Thermoluminescence has had a major impact on the antiquities market starting from about 1970 when the first tests were made in Oxford.
No longer does evidence of authenticity have to rely solely on stylistic criteria, which can be unreliable.
Museum collections worldwide have also been shown to have their share of fakes, as the TL testing of the British Museum's collection of seventy Zapotec ceramics can demonstrate.
The Zapotec culture flourished in Oaxaca in southern Mexico between about AD 200 and 800.
It produced distinctive pottery vessels in human or animal form, which are now found in large numbers in collections throughout the world.
Many Zapotec pottery vessels, however, have long been suspected of being forgeries.
The British Museum's collection, much of which was collected last century or in the early half of this century, was shown by TL to contain some twenty forgeries, most of which had, in recent years, been suspected to be modern.
That so many museum curators have been deceived by these fakes is less surprising when seen in the context of both the style itself and the history of archaeology in Oaxaca.
Relatively little was really known of Zapotec culture until the excavations at the Monte Alban and other sites in the 1930s.
Except for the earliest styles, Zapotec pottery was largely mould-made and decorated with applied decorative motifs often cut from flat sheets of clay and easily copied.
The use of genuine pre-Hispanic moulds has also caused confusion.
The ‘basket’ with rodents included in Figure 8.2 would attract suspicion because the form itself is not within the canon of Zapotec work.
However, the animal figures which decorate the body of the vessel are from a genuine figurine mould and therefore in perfect Zapotec style.
There is good evidence that a flourishing trade in false antiquities existed at the turn of the century, and its products filtered through to the United States and Europe.
In the 1920s and 1930s a large percentage of the so-called ancient material which would have been familiar to interested collectors was the product of this well-established manufacture.
Dendrochronology
As the name implies, dendrochronology is specific to the dating of wood.
This technique is highly precise, to the year or even season of felling, if the sample is adequate.
Herein lies the problem: the wood needs to be of a  species for which there is a ‘master chronology’(see p. 125) and there must normally be at least a hundred tree rings in the sample to be dated to ensure a unique match with the master pattern.
If the date is to be precise to the year of felling, the bark must also be present, otherwise an estimate must be made of the number of missing rings corresponding to likely wastage by the carpenter.
Furthermore, to determine the date of actual usage, allowance must be made for seasoning of the timber.
Dendrochronology is most commonly used in the art world to test the authenticity of panel paintings.
This is feasible because the panels were prepared from radial sections of the timber rather than tangential ones, since the latter would warp.
Many panels have more than enough rings to be datable, and the most popular timber was oak, for which long master chronologies exist.
If the date of felling of the tree can be determined and shown to postdate the death of the artist, the painting is clearly a fake.
Indeed, if only heartwood is present but the last ring itself post-dates the artist's death, this too condemns the piece.
Interestingly, dendrochronology can also demonstrate when the panels are taken from the same tree because of the close similarity of the ring patterns.
It can therefore be used to associate paintings, if not to the same artist, at least geographically.
Other methods of detecting fakes
Anachronistic use of materials
Through the ages, the composition of synthetic materials, such as metals, ceramics and glass, has changed as the sources of raw materials have changed and new processes have been discovered.
As already described in  Chapter 5, we are beginning to define the range of composition of materials used by many of the principal civilisations of the past, and to discover when and where particular materials, such as brass, were first used.
This information is extremely useful in authentication studies.
One can compare the composition of the suspect piece with the range of composition of genuine pieces of comparable period.
This applies to both the major components which the craftsman deliberately mixed together to form the final product, and also to the trace elements of which he was probably ignorant, but which can indicate the likely source of some of the materials, thus enabling us to distinguish the genuine from the spurious.
One must be careful to differentiate between compositions which are unusual and those which are plainly impossible.
Thus, if one had a bronze with, say, 2 per cent of tin, where the tin content of the comparable genuine bronzes lay between 5 and 10 per cent, this would be unusual and would count against the piece but it certainly would not condemn it.
If, however, the suspect piece turned out to be an aluminium bronze (as was recently the case with some coins purporting to be Anglo-Saxon), then one could reject it straight away because aluminium, and thus aluminium bronze, was not known before the nineteenth century.
Sometimes the analysis can be quick and quite definitive.
For example, two very similar copper-alloy statuettes both purport to be Etruscan of the sixth century BC (fig. 8.3).
Both are technically very fine castings and well finished.
But surface analysis by X-ray fluorescence (see glossary) shows that one is a leaded tin bronze, quite appropriate for the period, whereas the other is of brass, the alloy of copper and zinc, which did not become common until the Roman period over five hundred years later.
Thus, on these grounds alone, the second figure is most unlikely to be ancient.
In all probability it was made as an innocent copy in the nineteenth century.
However, one has to beware of jumping too rapidly to conclusions on the basis of a single surface analysis without considering all the possibilities.
For instance, when one of the British Museum's most magnificent Etruscan bronze vessels was similarly analysed on the surface and found to contain zinc, there was understandably some consternation.
Subsequent analysis of a sample drilled from the interior showed it was of bronze with no zinc present at all.
The explanation was that the vessel had been  electrochemically cleaned to remove the worst of the corrosion at some time after its excavation in the nineteenth century.
In this treatment the vessel would have been wrapped in a zinc foil, placed in a solution of weak acid and then an electric current applied.
During the process the bronze was bathed in a solution of zinc salts and, unless it was carefully washed afterwards, some of these zinc salts could persist in the remaining patina on the surface.
This example illustrates well that one has to be aware of the range of possible treatments and restorations to which even perfectly genuine objects could have been subjected.
The composition of glass also changed through the ages: most glass from the early civilisations of the Middle East were soda glasses with relatively high sodium contents, and low lime and lead contents compared with modern glass (see Chapter 3).
Modem glass also tends to contain a greater range of other metals such as arsenic and zinc.
Thus, when a series of Egyptian canopic jars of blue glass purporting to belong to the New Kingdom of the second millennium BC came under suspicion stylistically, they were analysed and found to contain high levels of lead and some arsenic, thereby confirming the doubts of the Egyptologists.
Trace elements can also be diagnostic.
For example, almost all sources of silver naturally contain a little gold, and ancient silver artefacts typically have gold contents in the range of 0.1 to 1.0 per cent .
Not until after the medieval period was it economically viable to recover amounts as small as this, and so the gold content of silver artefacts can be a useful indicator of their antiquity.
A number of supposedly late Roman silver ingots, of the type distributed to the army on special occasions such as the accession of an emperor, appeared on the market fairly recently.
All were in perfect condition, and the inscriptions seemed rather unusual: analysis failed to detect any gold at all, strongly suggesting the ingots were made from modern refined silver.
Sometimes the composition of the solders used to hold together the components of the objects can themselves be indicators of age.
Modern gold solders often contain several per cent of cadmium, small amounts of which significantly lower the melting point of the alloy without affecting the colour of the metal too badly.
Cadmium is a very volatile metal that has to be prepared by distillation; as this was not achieved until 1818, solders containing cadmium cannot be ancient.
A whole series of quite spectacular pieces of supposedly Dark Age jewellery and belt fittings, including the well-known Lombard Treasure, appeared on the art market at the beginning of this century (fig. 8.4).
Quite apart from unusual stylistic characteristics, cadmium-containing solders had been used extensively.
The British Museum acquired some of these pieces knowingly, as examples of modern fakes, and by examining the pieces in the scanning electron microscope (see glossary) using microanalysis and digital-mapping techniques it has been possible to plot the concentration of the cadmium over the soldered surfaces.
It has recently been suggested that some ancient solders did contain cadmium, using the cadmium sulphide mineral greenockite as source of the metal.
However, in many years of examination of ancient jewellery, cadmium has never  been found in pieces from excavation, or from otherwise unimpeachable sources, but only in pieces that were suspect on other grounds.
So far we have considered man-made materials where the composition reflects the processing, but the composition of materials such as stones and gems, which were used without chemical modification, can also sometimes indicate their source, and thereby the authenticity of artefacts made from them.
An example of this is a jackal's head, purportedly ancient Egyptian, and carved from the semi-precious stone lapis lazuli (fig. 8.5).
X-ray diffraction (see glossary) revealed the presence of the calcium silicate mineral, wollastonite, in the lapis.
We know that all the lapis lazuli used in the ancient Middle East came from a single source in the Badakshan Valley, Afghanistan, but this source does not contain wollastonite.
However, lapis from the region of Lake Baikal in Siberia does contain wollastonite, although this source was not worked until the nineteenth century.
The lapis in the jackal's head is therefore unlikely to be ancient.
The ratio of stable isotopes in marble (see glossary) can also be used to determine provenance, and has been particularly useful in checking the integrity of statuary recomposed from fragments (see p. 109).
Anachronistic technology
The way in which things are made has changed slowly through the millennia and much more rapidly during the last two centuries.
Thus the techniques used to manufacture and decorate an object are indicative of its authenticity.
To the trained observer, careful study under a binocular  microscope can reveal how an object was made and decorated, and also reveal any discrepancies or anachronisms in a fake antiquity.
For example, since the medieval period, wire has been made by drawing thin metal rods through progressively thinner holes.
This leaves long parallel striations running along the wire.
In antiquity a variety of methods were used, including strip twisting and block twisting.
Both these methods leave very characteristic helical seams which can be seen on examples of wires made by the two methods in Figure 8.6a and b, taken from genuine antiquities.
A modern drawn wire from a fake is shown for comparison (fig. 8.6c).
The methods used to cut stone and gems can also be indicative of age.
For instance, the teeth on the famous supposedly Pre-Columbian crystal skull, said to be from Mexico (fig. 8.7), have been cut with an abrasive wheel.
Although this technique has a long ancestry in the Old World it was unknown in the Americas until the Spanish conquest in the sixteenth century.
This would seem to suggest that the head cannot belong to the Aztec civilisation.
But this remarkable object may not be a completely modern fake.
It could have been made by the indigenous people immediately after the conquest, or alternatively features such as the teeth could have been cut much later on the head.
Artificial aging
Having produced the fake, there is then the problem of making it look old.
This is a two-fold process: first the wear that the object could have received during normal usage must be replicated, and then the decay and corrosion of centuries of neglect or burial must be induced.
Real wear is the cumulative result of a vast number of very minor rubs and abrasions from a variety of preferred angles concentrated at a number of areas such as extremities or where one component rubs against another, such as on the links of a chain or the catch of a clasp.
Wear cannot therefore be simulated by just sand-blasting the whole object, nor even by concentrating on the vulnerable parts with a coarse file.
On one fake astrolabe examined recently the faker had clearly got bored and resorted to an angle grinder to wear down the edges, leaving very characteristic scratches; unfortunately most fakers are much more painstaking!
Patination
After long exposure to the air or burial in the ground most materials corrode.
Thus, over a long period of time, stone, glass and metals acquire a distinctive patina which the faker must try and imitate.
The patinas on copper alloys were often appreciated in their own right and a study of the patination is central to all authenticity studies.
It is essential to have a good appreciation of the possibilities of recent treatments, such as over-restoration or repatination, so a brief history of patination is given here.
As far as we know, the ancients intended their metalwork, both artistic and utilitarian, to be kept in a brightly polished metallic state, with the possible exception of special alloys such as Corinthian bronze.
We tend now to think of Classical bronze statuary, for example, as being covered with a fine green or deep brown patina, and moreover that this was their original state.
But, on the contrary, the evidence suggests that these statues were kept bright.
For example, contracts survive to pay for the regular cleaning of the bronzes in Roman temples and where statues are depicted as part of landscapes or street scenes on contemporary wall paintings they are always shown as bronze-coloured, never patinated (plate 8.1).
The first people to have appreciated and replicated patinas seem to have been the Chinese.
This is perhaps not unexpected, given their reverence for the past and their long tradition of scholarship and collecting stretching back over several millennia.
The bronzes that the Chinese so eagerly collected came from burials and were usually covered in a fine green patina.
Supply of ancient bronzes exceeded demand and forgeries were very prevalent.
Over a thousand years ago bronzes were being produced in the style of the early pieces and given an artificial patina.
This was done by applying a mixture of ground-up malachite and other minerals to the bronze (plate 8.2).
The result is superficially quite convincing, but would not deceive anyone with experience of genuine patinas.
Very probably at least some of these patinated bronzes should be regarded as legitimate copies rather than as fakes, rather as today the British Museum produces and sells resin copies of some of the more famous antiquities.
Serious study and collecting of antique metalwork only began in Europe during the Renaissance.
The patina the bronzes had acquired during burial was much admired, and people assumed that they had originally been patinated.
The belief grew that the original patination had been black, possibly based on some rather oblique remarks in Pliny's Natural History on treating bronzes with bitumen.
Some dealers and collectors were not above altering or even removing the genuine patina and treating the surface to give the appearance they felt it should have had.
The collector Richard Payne Knight is a prime example.
His superb collection of mainly Classical antiquities passed to the British Museum in the early nineteenth century and includes hundreds of small bronzes.
Almost all of these are now covered in a spurious black patina (plate 8.3); indeed one can go through the sculpture galleries of the Greek and Roman Department and pick out the Payne Knight pieces from a distance, before checking against the registration number which invariably begins with 1824.
More seriously, the possible repatination of an otherwise quite genuine piece has to be carefully considered in authenticity studies, and demonstrates again the importance of a close acquaintance with antiquities generally, and an especial awareness of the potential vicissitudes that could have befallen them.
Throughout the eighteenth and nineteenth centuries there was a steady increase i-n the number and sophistication of methods for chemically patinating copper alloys.
These techniques were developed for the perfectly legitimate ‘bronzing’ and ‘antiquing’of patently modern metalwork, but could also be used by the faker with less honest motives.
Changes in taste, coupled with a general decline in craft techniques, have meant that the use and range of chemical treatments has declined in this century, although in the Far East the beautiful patinated Shakudo alloys (see p. 95) are still produced by the traditional chemical treatments.
Partly inspired by this continuing tradition, there has been a recent revival of interest in Europe and North America emanating from art schools, where the subtle nuances of colour and texture of a chemically patinated surface are more appreciated.
The faker has more immediate problems: the false patina must simultaneously look attractive, stay firmly in place, and appear genuine.
One method is to grind up a suitable mixture of the correct minerals and stick it to the surface.
Alternatively a patina can be induced on the surface of the metal, either by treatment with suitable chemical concoctions or by rapid weathering in an extreme environment.
Italian fakers traditionally encouraged the rapid development of a patina by such measures as exposing the bronze on the workshop roof for some months, or by burying the piece in a dunghill.
Fortunately these approaches create difficulties for the faker and also leave clues for the scientific investigator.
If the patina has been stuck on, then it is often possible to detect the organic binder or glue quite easily, either by application of various solvents, or by exposure to ultra-violet radiation.
Many organic binders contain molecules which fluoresce when excited by ultra-violet radiation.
This is well exemplified by the ancient  Chinese fang ding vessel, shown in Figure 8.8a.
In Figure 8.8b the makeup used to disguise repairs fluoresces under ultra-violet radiation.
Also the junction between the uncorroded metal and the applied patina is very sharp, whereas a patina which has developed over a long period of time will have eaten into the metal in a very irregular and quite characteristic manner that is very difficult to imitate.
One problem for the faker trying to develop a patina in situ is that the chemicals which give the most attractive patinas also give totally the wrong minerals, which can be detected quite easily by X-ray diffraction.
In addition, rapidly developed patinas tend to be rather loose and powdery.
This section has concentrated so far on metals, reflecting the interest in metal patinas, but other materials also develop distinctive surfaces over time and some work has been done both by fakers to replicate them and investigators to differentiate the fake from the genuine.
The early fakers of marble statuary used a variety of treatments to tone down the too obvious freshly carved surfaces, ranging from cold tea to the more sophisticated repeated acid bath treatments used by more recent fakers.
However, as with their metal counterparts, the false patinas on stone may look convincing but when viewed under high magnification and analysed are petrologically and chemically quite distinct.
Another branch of stone patina faking is to be found in a very different area of collecting.
In the late nineteenth and early twentieth centuries there was a passion for collecting prehistoric flint implements, and quite  high prices were paid for prize specimens; not perhaps in the same league as the prices paid for Classical sculpture, but quite enough to encourage the fakers.
The products of their industry were of course quite fresh and unpatinated, whereas the genuine flint artefacts had a white or brown patination especially if buried in chalky soil.
This could be replicated, at least superficially, by boiling in a concentrated caustic soda solution to give a white patination; the addition of a few rusty nails would then turn the patina brown.
However the texture of these patinas is not very convincing as they tend to be rather matt and powdery, and are quite easily recognised under the microscope.
Glass that has been buried usually develops a distinctive iridescence and onion-skin texture.
This is caused by the slow leaching of elements from the unstable early soda glasses, and has so far proved impossible to replicate.
This patination is very difficult to induce artificially.
At best the faker can try and render the surface somewhat weathered and pitted by treatment with hydrofluoric acid, but the presence of fluorides in the surface can be easily detected.
Restoration
Deceptive restoration or alteration and embellishment of antiquities is another area of faking.
Scientific examination can be used to assess the extent of repairs or new work, and to pick up the joins and fillers used to disguise them.
Where an object has been heavily restored, radiography can frequently ‘see’ through the carefully applied make-up.
This is clearly illustrated by the small Islamic jug in Figure 8.9.
To the unaided eye, the  jug does appear slightly restored, but the true extent of the restoration is starkly revealed by the X-rays, which pass more easily through the relatively light plaster make-up than through the denser ceramic.
Similarly, damage to the ancient Chinese fang ding and the lead solder used to repair it are clearly visible on the radiograph (fig. 8.8c), in which the X-rays pass easily through the restorer's plaster and false patina.
Additions and embellishments can be more difficult to detect, and here of course the cooperation of the art historian is essential.
It would be of no great help to pronounce the body of an object genuine if the interest, and hence the value, lay in the inscription.
For example, a small Egyptian gold pendant in the form of a shell (now in the Egyptian Department of the British Museum, EA 65281) is very probably ancient, but it bears an engraved cartouche purporting to be of the Twelfth Dynasty in the early second millennium BC.
The crudity of the cartouche and various internal anachronisms raised suspicion.
On careful examination it became clear that the cartouche had been engraved.
In this technique a V-profile chisel, the graver, is pushed over the surface of the metal in order to remove a sliver of metal.
To do this the graver must be very hard and strong.
The technique of engraving was therefore not really feasible until iron and steel tools came into use at the end of the second millennium BC, yet this piece purports to be many hundreds of years older.
Where it is suspected that a piece is made up of unrelated fragments, the composition can sometimes be studied to sort out which fragments are original, or at least which ones belong together.
This problem is especially common with Classical marble statuary which in the past was often highly restored before being sold.
Stable isotope analysis (see glossary) can be used both to provenance the marble used and to solve some particularly knotty problems caused by over-enthusiastic restoration, where fragmentary pieces were re-assembled, frequently incorporating new pieces of marble, to make the statue appear whole.
The British Museum has in its collections a marble panel, recomposed from fragments, belonging to a Roman sarcophagus (GR 1805.7–13.135).
The fragments have a long and complex history since their discovery, dating back to at least the sixteenth century.
Some earlier drawings show the panel as considerably less complete than it is now, suggesting that pieces were added in the eighteenth century, as was the common practice with fragmentary works.
However stable isotope analysis shows that all the fragments belong to one piece of marble, demonstrating the overall integrity of the piece, and also that the marble is likely to have come from the quarries at Carrara in Tuscany.
The limits of scientific expertise
The examples used above to demonstrate particular approaches or methods tend to suggest that each problem has a neat and unequivocal solution.
Usually the situation is much less clear-cut.
Scientific examination adds another dimension of evidence to authenticity studies which, taken together with the art historical evidence, can allow us to make an attribution with much more confidence.
There are the rare cases, as with the  bronze and brass Etruscan statuettes described above, where a few moments spent performing a surface analysis can unequivocally solve a problem, which might have remained a stylistic conundrum for ever.
But more often scientific examination will add to the store of information without finally solving the basic problem.
The following example, although not strictly an authenticity examination, uses the same approaches and shows the application of scientific detection in a related sphere of the British Museum's activities.
A number of small bronze figurines have been found in several locations in southern Britain.
They bear some resemblance to figurines of the Italic culture of central Italy of the mid-first millennium BC.
If they were genuine imports into prehistoric Britain then they would be of some importance in suggesting trade networks.
However, none of them has been found in an archaeological context and they have aroused considerable suspicion: they could be relatively modern copies loosely based on Italic originals; they could be genuine prehistoric imports; or they could be perfectly genuine figures brought to Britain relatively recently as curios and since discarded or lost.
Scientific examination has shown that they are made of bronze similar to that used in genuine Italic figures from Italy and the patination appears to have developed over a long period, suggesting that they are not modern copies.
Useful though this information is, however, it still leaves the central question open of whether the figures came to Britain in antiquity or more recently.
This particular problem is likely to remain unsolved until a similar figure is recovered from an excavation site.
Usually the art historical and scientific approaches to the same problem reach broadly the same conclusion, even though it may be necessary to rely heavily on one of the approaches to make sense of the other.
However, just occasionally, the evidence of the two disciplines is in apparent contradiction.
A good example is provided by the famous life-size bronze statue of a youth, found at Magdalensberg (fig. 8.10).
It is, or more correctly, was  the most important antiquity to have been found in Austria and has pride of place in the Kunst Historiche Museum in Vienna.
The piece has an apparently unassailable history.
It was dug up in the sixteenth century and achieved fame almost immediately, entering the imperial collections, and being drawn by artists such as Apianus in 1534.
Only in the nineteenth century did excavations reveal a major Roman temple to Mercury at Magdalensberg, and the youth was almost certainly the cult statue.
Further, the statue has an inscription on one leg mentioning a specific family and once again only much later was this name encountered on Roman pottery as an important family firm of merchants in that region.
Thus the archaeological evidence would seem to establish the authenticity of the statue beyond all reasonable question, but some stylistic doubts were raised and the statue was examined scientifically by an international panel of scientists, including members of the British Museum Research Laboratory.
Their findings were equally unequivocal.
Thermoluminescence dating of the clay core suggested that the statue was only a few centuries old, and this was supported by technical examination and analysis which showed that the casting technology and the metal used were quite typical of the Renaissance, and equally unlike those used by the Romans.
Examination of the metal showed that it had always been in a clean condition with no evidence of corrosion, suggesting that it had never been buried.
The apparent conflict of evidence is still not completely resolved, but there is a possible explanation.
It is known that shortly after its discovery, a copy, now lost, was made and sent to Spain.
Is it possible that the statue which was scientifically examined was actually the copy, and the original — the only complete Roman bronze statue to have been discovered north of the Alps — was sent off to Spain, never to be seen again?
8.1 The facial image of the Shroud of Turin, viewed in negative (courtesy British Society of the Turin shroud).
8.2 Zapotec ceramics tested by TL.
From left to right: genuine figure of a deity (ETH 1849.6–27.20), height 320 mm; fake ‘basket’ of rodents (ETH 1940 Am 2.43), diameter 355 mm; and fake figure of a deity (ETH 1946 Am.16–7), height 400 mm.
8.3 below left Two Etruscan banqueteers; the statuette at the back is bronze (GR 1813.12–1.1) but the other is brass (GR 1918.1–1.113).
Length 330 mm.
8.4 left Fake ‘Lombardic’ brooch (MLA 1930.11–6.1), one of a number of pieces made at the beginning of the century.
The brooch purports to belong to the Dark Ages, but uses a modern cadmium gold solder to hold together the components.
Diameter 57 mm.
8.6 Three methods of making wire:(a)above and (b)right are ancient,(c)far right is modern.
In (a) a thin strip of metal is tightly twisted to produce a hollow tube rather like a very thin drinking straw.
In (b) a thin rod of square section is twisted and then rolled.
In (c) a thin rod is passed progressively narrower draw plates.
The very characteristic marks left on the mire show how it was made and this can indicate the likely age of a piece.
8.5 left Fake Egyptian jackal's head of lapis lazuli (EA 64075).
All ancient lapis came from a single source in Badakshan in Afghanistan.
However, the composition of this piece shows it came from Lake Baikal in Siberia, a source not exploited until the nineteenth century.
length 98 mm.
8.7 Crystal skull (ETH 1898–1), said to be from Mexico.
The striking head is difficult to parallel stylistically, and the teeth seem to have been cut with an abrasive wheel which would not have been available in the Americas before the Spanish conquest.
Height 210 mm.
8.8 Three images of a Chinese fang ding vessel (OA 1973.7–26.4) probably made in the eleventh century BC.
It was subsequently badly damaged but the clumsy repair is skilfully disguised by deceptive restoration.
height 222 mm.
(a)left By ordinary light the fang ding appears intact.
(b)above Under ultraviolet radiation the make-up disguising the repairs fluoresces.
(c)left X-rays pierce right through the object, revealing the massive breaks.
The very white areas in the cracks are lead solder.
8.9 Restoration revealed by radiography.
This small Islamic jug (OA 1952.2-14.1) of the ninth century AD appears intact below when viewed by ordinary light, but X-rays show that it is extensively repaired right , especially around the rim.
height 116 mm.
8.10 Life-size bronze figure of a youth.
This statue, now in Kunst Historishche Museum in Vienna, was until recently believed to be the Roman statue found at Magdalensberg in the sixteenth century and as such the only complete Roman statue ever found north of the Alps.
However, recent scientific examination by an international team of scientists suggests that his is an early copy of the original now lost.
Height 1.7 m.
Computing and mathematics: Putting two and two together Peter Main
Centuries ago, mathematics was dubbed ‘handmaiden of the Sciences’, and with good reason.
The earliest discoveries in mathematics were made by the great physicists and astronomers in the course of their work, and in those days great scientists had to be great mathematicians.
The power and wide-ranging applications of mathematics quickly gave it recognition as a discipline in its own right, whose theorems have now been brought to bear on problems in every field of knowledge.
Computers, and the programs that control them, rely no less on the past creativity of mathematicians.
The youngster of today who comes to grips for the first time with a personal computer little imagines the wealth of mathematical inventiveness invested in the design of the software and in the electronic circuitry itself.
Statistics, a multi-faceted sub-discipline of mathematics, has its own long and proud history, boasting such famous exponents as Isaac Newton, Edmund Halley and Florence Nightingale.
Statistics grapples with the quantification of such nebulous concepts as probability, certainty and error.
Computer science, though one of the younger disciplines, relies like so many others on mathematics, and this happy relationship works both ways.
Increasingly, the practical application of many mathematical techniques depends on the computer's ability to carry out calculations with faultless accuracy at ever more extraordinary speeds.
Applied mathematics and computer science are distinct disciplines, but they are now locked for ever in an inseparable embrace.
Together, they underpin rather than oversee the disciplines they serve, and reliance upon them can be so complete that procedures simply cannot be carried out without their aid.
For example, neutron activation analysis (see glossary), one of the techniques used to determine the composition of ancient ceramics, would be impossible without a computer program, since the calculations required are so complex and extensive that not even the most resilient individual armed with a pocket calculator could possibly complete them in a single lifetime.
A less obvious aspect of the power of mathematics and computer science derives from the abstract, or generalised, nature of the procedures they employ; in solving one problem one is often, perhaps unwittingly, solving another apparently unrelated problem.
We will see some instances of this fascinating phenomenon in the following sections, as we take a brief look at applications of mathematics and computing to the study of museum collections and the wider spheres of archaeology and prehistory.
In the service of the museums
Counting loose change
It is standard practice in museums to ‘register’ objects as they are acquired, and the register is the primary record of a museum's holdings.
A small collection can be monitored regularly by carrying out a check of all objects against the register, but in the case of a very large collection this may well be impracticable.
The British Museum has (or is believed to have) some 5 or 6 million objects, so that a conventional stock-take of the entire collection could occupy all the qualified staff for five or six years and could be exhaustive only if all other duties were suspended for the duration.
However, a branch of statistics called ‘sampling theory’ can be applied, which will allow conclusions about the entire collection to be inferred (to within a known degree of certainty) by checking on a small percentage of it.
Statistical sampling is widely used in scientific experiments and market surveys.
It also has applications in field archaeology where financial or time constraints preclude excavation of more than part of a site, and where it is therefore important that the excavated part yields as much information as possible.
Sampling theory has been of value in various areas of museum work, from assessing the long-term resources required for conservation treatment of the British Museum's large collection of Babylonian clay tablets, to ensuring that a given ‘kill rate’ in insecticides used for paper conservation will provide effective treatment.
A sampling programme carried out in the Coins and Medals Department in 1979 checked some 10,000 of the estimated 600,000 objects in the collections.
The results indicated that, with a high degree of probability, more than 99.8 per cent of the total collection could be accounted for.
Of course, this can only be verified by a complete inventory, but the important point is that the sampling methods used, and the way in which the results were extrapolated to apply to the whole collection, are based on a sound mathematical theory which is widely used and tested in other fields, and therefore carried sufficient weight to satisfy the Museum and its auditors.
Good housekeeping
A long-term solution to the management of huge collections of material is to enter details of all objects and their whereabouts into a computer database and to keep the information up to date thereafter.
Such a project began in the British Museum in 1978, using a computer originally purchased for scientific work, but now transferred to a ‘super-minicomputer’ which runs powerful database software.
The main objectives of the documentation project are threefold.
Firstly, and most importantly, it will eventually form a complete inventory of the collections.
Secondly, it will enable us to locate each object more quickly and easily.
Finally, much extra information is being recorded, such as provenance, cultural associations and so on, which will allow the database to be used as a powerful research tool.
To record such information for over five million objects is  clearly an immense undertaking which will continue well into the future, and entails considerable staff costs, powerful computer hardware and highly sophisticated software (see Chapter 1 0).
It is the software that is of most interest here since that is where the ‘intelligence’ of the facility resides.
To give but one example, it allows us to search a database of tens of thousands of objects looking for ‘wooden bowls from Ghana which are greater than 12cm wide’, and to get an answer within seconds of posing the question.
It will even take account of the fact that some relevant objects may not be described as ‘wooden’ at all, but as being made of ‘beech’, ‘mahogany’, ‘deal’or the like.
All the information about an object is stored on the computer within what is called a hierarchical database, meaning simply that the information is broken down from broad categories such as‘geography’ into more specific ones such as ‘continent’, ‘country’, ‘region’and so on .
One can visualise this as a tree-like structure with broad categories branching out into narrower ones.
Such structures are indeed referred to in computer science jargon as trees, and the technical literature abounds with pleasing arboreal metaphors such as roots, branches and leaves.
To retrieve our wooden bowls, two other tree-like structures are necessary: an index to the database allowing us to find all wooden objects quickly without checking every one, and a thesaurus which remembers that ‘beech’, ‘mahogany’ and so on are all forms of wood.
These three types of tree, although slightly different in form, have abstract mathematical properties in common which are embodied in the theorems of a rather obscure branch of mathematics called graph theory.
By progressing from the sampling of collections to storing details of every object in a computer database, we have therefore simply transferred our allegiance from sampling theory to graph theory.
From words to pictures
Words are not the only type of information we may wish to include in a computerised record of museum collections.
What about pictures?
Modern technology allows us to use lasers to record images from photographs or video cameras on to videodiscs, and to access each picture or frame instantly by quoting its frame number.
Although this may well be a valuable facility, it really forms no more than an appendage to the database, since we cannot search a videodisc image for details within it in the way we can search text.
If we know the frame number corresponding to an object's picture, we can display the picture, and that is that.
The possibilities become more interesting when we begin to ask questions such as‘What objects in this database are similar in shape to this one?’.
In fact this is a commonly asked question, since shape is of great significance in the study of certain classes of ancient artefacts.
It plays an important role in defining typologies which can be then be used to help date or provenance new examples.
It should be emphasised that the shape discrimination required is usually much more subtle than could ever be achieved by verbal shape descriptions, and that the heavier tools of mathematics need to be applied.
We are in fact attempting to persuade a high-powered  calculating machine to imitate the process of human shape perception.
While the human eye is extraordinarily good at doing this, the process by which it does so is not well understood and hence can be only imperfectly imitated.
If the human eye can do better, why even try?
In practical situations, the problem is one of quantity of information.
Although it is quite reasonable to ask a human being to search by eye through a moderate number of drawings of artefacts it is not reasonable where thousands are involved.
From this point of view, the capacity of an electronic computer for tireless number-crunching should have something to offer.
By attempting to imitate a human cognitive process, however, we are straying into the notoriously difficult sub-discipline of computer science known as artificial intelligence, and anyone working in this field would agree that many of its problems have yet to be solved.
It is nevertheless of interest to look at one approach to such problems, since this area of research demonstrates, perhaps as well as any, how a close liaison between mathematics and computer science can be of service to the museum archaeologist.
As an example of a class of artefact whose outline shapes are of particular interest to the expert, let us turn to bronze axes dating from the Early Bronze Age of southern Britain (fig. 9.1).
The outline of such an axe can be measured very precisely and processed by various techniques of  coordinate geometry (including, incidentally, one originally invented by marine engineers to measure the shape of ship hulls) to give a final mathematical ‘fingerprint’ of the axe's shape.
These fingerprints are in such a form that they can be easily compared one with another; that is to say the computer can calculate a measure of ‘shape difference’ between any two axes.
This shape difference measure is the fundamental building block by which we can create large databases of outline shapes that can be searched efficiently.
Trees return once more to help us in this endeavour.
Figure 9.2 shows what a very small part of a large database of axe shapes might look like.
The whole should be imagined as a huge and intricate multi-branched tree which has been designed so that axes similar in shape (as determined by the shape difference measure) lie in branches near each other.
Suppose now that we wish to search the database for axes similar in shape to some given axe.
Since the relevant ones will be concentrated in one area of the inverted tree they can be quickly located by moving from the root downwards and along the correct branches, without ever having to search the whole database.
Shuffling things about
Imagine now a slightly different problem.
Suppose we are given some outline drawings of axes.
Can we use a shape difference measure to classify the axes into groups of similar types on the basis of their shapes?
In other words, can a computer imitate the process the archaeological expert carries out by eye when he constructs his standard typologies?
There is more than one way to tackle this problem, but a very widely used and mathematically elegant technique called multi-dimensional scaling can help us.
It was invented in the 1950s by psychologists, and solves a more general problem than the one we have posed.
Given any group of objects, and the ability to measure difference (or dissimilarity) between any pair of the objects, how can we position the objects in two dimensions in such a way that their physical separation reflects the measure of dissimilarity between them?
In other words, we want dissimilar objects to be far apart and similar ones to be close together.
If we can achieve this, we have gone a long way towards solving the axe typology problem since groups of similarly shaped  axes would appear as distinct clusters on the page and could be easily identified by eye.
Two points about multi-dimensional scaling should be stressed.
Firstly, it is perhaps surprising that the procedure is very difficult to do by hand, even for a small number of objects, and is quite impossible for a large number.
To appreciate this, imagine that you ask a friend to mark thirty numbered points randomly on graph paper (unseen by you) and that you are required to discover their positions, with no information other than the distances between any pairs you request.
The problem can be solved, but quite complex mathematics and a computer are required to solve it.
Secondly, the technique can be used for any type of dissimilarity; shape difference is just one example.
This means that multi-dimensional scaling has applications in many areas of work, as we can see from the following examples.
When petrological thin-sectioning (see glossary) is carried out, many separate items of data may be collected from each artefact studied, making it difficult to see those groupings of artefacts that have features in common.
Multi-dimensional scaling can help to clear the murky waters.
The process of examining thin sections is a painstaking and laborious one, since each slide has to be viewed individually under a microscope and various aspects of appearance judged and recorded.
The scientist has to remember a great deal of information before he can even begin to look for patterns in the data.
The burden can be eased by introducing the following procedure.
For each thin section, the scientist makes a decision on what he regards as its significant features (such as size or shape of particular mineral inclusions) and then scores each feature, for each thin section, on a simple scale from one to five, without giving any thought at this stage to similarities and differences.
These scores are then combined to give overall measures of dissimilarity between each possible pairing of artefacts — exactly the form of information required for multi-dimensional scaling.
The computer then does the hard mathematics and produces a diagram showing broad groupings of similar material (fig. 9.3).
An imaginative application of multi-dimensional scaling by the statistician David Kendall serves to illustrate how widely the technique can be applied.
It is known that many medieval villages in England became deserted through decline and shift of population, and the ravages of disease.
It is perhaps less well known that a number of them became ‘lost’ as building stone was re-used and land ploughed over.
The lost villages are known to have existed mainly through references in medieval parish records of births, marriages and deaths, but their location is unknown beyond the parish in which they lay.
It was common practice for marriage registers to record the places of abode of the newly-weds, and what Kendall did was to use this information to construct a crude measure of dissimilarity between villages based on frequency of intermarriage over a long period.
The underlying assumption was that the likelihood of marriage between people from different villages drops off with increase in geographical distance between the villages.
The multi-dimensional scaling configuration resulting from processing the ‘degree of intermarriage’ values might therefore be expected to reflect geographical location of the villages.
Kendall was able to check his results to an extent, since much of his data related to villages whose location was known, and this gave him some confidence in suggesting the locations of the lost villages.
Kendall never claimed, of course, that this method could ever be accurate enough to pinpoint where the archaeologist should sink his spade, but rather that it could help in choosing between a number of possible locations to which the search had been restricted on other grounds.
Weights and measures
Let us now turn to another example of how mathematics, through the breadth of its applications, allows us to attack more than one problem  with a single weapon.
Quantum analysis is a branch of statistics designed to test a very specific hypothesis, namely that a set of measurements is ‘quantised’, and thus occurs in multiples of some basic measurement unit.
The method concerns itself both with what the underlying unit actually is, and also with how likely it is that we are observing a real effect rather than some random one.
In the early 1960s, Alexander Thom, a retired Scottish professor of engineering, sparked off a great deal of interest and controversy in the archaeological community through his claims for the existence of a ‘megalithic yard’, an ancient unit of measurement used by the builders of megalithic monuments.
Such claims in fact go back as far as 1926, but it was with Thom's careful measurement of many stone circles and alignments in Britain and Brittany that a scientific analysis of the problem could be attempted.
Thom's theoretical analysis was based on the work of S.R. Broadbent, a statistician whose quantum hypothesis allows the extent to which data are quantised to be assessed objectively.
There is still some disagreement among experts about whether the methods Thom used were appropriate.
The arguments surrounding the issue, important in assessing Thom's work, were also vital to an investigation of gold-weights made by the Ashanti people of Ghana.
These objects are actually made of brass, but are believed to have been used for the weighing of gold dust (fig. 9.4).
Like the dimensions of stone circles, the weights of these objects seemed to peak in definite weight bands, suggesting that they were made to preset weight specifications.
This observation was the starting point for a study of a large sample of gold-weights from three museums.
This study showed up some fascinating differences: the figurative pieces — small models of porcupines, antelopes and so on— showed no convincing evidence for quantisation, but the geometric pieces did, as can be seen in the frequency charts of the weights (fig.9.5).
The geometric pieces were clearly made as utilitarian  objects, and in fact were designed to weigh in multiples of 1.46 g.
Another conclusion that emerged from this study was that around one thousand objects would need to be sampled to be able to detect the sort of peaks which were actually present.
In the gold-weight study there was no problem: by gathering data from the British Museum, the Museum für Völkerkunde in Berlin, and the Pitt Rivers Museum in Oxford, over 2,500 objects were studied.
This leads us to one of the main problems in this sort of computer-based study.
The computer allows us to make almost unlimited calculations, and indeed the larger the sample the better for statistical applications.
But the labour involved in studying the objects and producing the data, be it weighing, chemical analysis or whatever, means that the scope of investigations has to be limited in some way.
So the need to record sufficient data to enable definite conclusions to be reached has to be balanced against the requirement to make the best use of staff time and resources.
This is an area where the concepts of sampling theory, mentioned at the start of this chapter, can again prove useful: sampling schemes can balance these two objectives by determining the minimum labour that must be invested to be satisfied that the correct conclusions have been reached.
In the service of archaeology
Rank and position
Let us now move away from the store-rooms of museums to the wider world of archaeology in the field.
What do computers and mathematics have to offer us here?
Our first example comes from a cemetery complex in Humberside dating from the Iron Age.
Computer studies of cemeteries abound, and range from surveys of a number of cemeteries and their geographical distribution to very detailed studies of an individual one.
Our site is actually two separate but contiguous cemeteries at the neighbouring villages of Rudston and Burton Fleming (fig. 9.6).
These graves and their contents had been studied long before computers became commonplace, and gave indications of two different burial rites: one involving burial with pig bones and metal goods but no pottery, and the other involving sheep bones and pottery.
Surprisingly, the ‘pig’ graves tended to lie with the long axis pointing north-south and the ‘sheep’graves east-west.
When features are as obvious as this, one hardly needs a computer to detect them.
In this project, however, we wished to go further and to investigate whether the pig graves differed from the sheep graves in terms of the age, sex or apparent wealth of the incumbents.
The number of cross-tabulations involved is very large, and significant trends are easily lost.
If all the data are initially entered into a computer database, the power of a database management system makes it easy to present different views of the data to the researcher, allowing more subtle and complex associations to emerge.
At a more sophisticated level, computerised methods of a technique known as discriminant analysis can be invoked.
This is particularly useful where the bodies have to be grouped into categories such as male/female, child/adult, or even into groups with different racial or familial origins.
Sometimes it is obvious to which group an individual should be assigned, but where it is not.
information such as basic measurements of bone dimensions can be added to the computer's database and discriminant analysis can then predict the group that is most probably correct.
This procedure is akin to the methods now being used for computerised medical diagnosis, where the symptoms are fed in to the computer and the most likely illness is predicted.
Indeed we hope it may be possible to predict some of the medical problems our Iron Age ancestors were subject to, using just these methods.
We can see, then, how computers help to develop and extend information, as well as merely acting as the storage medium.
The investigation has now entered a new phase where demographic characteristics of the Iron Age population are being modelled (albeit crudely, since the information available from the Iron Age is very sparse).
Perhaps surprisingly, the methods of modern-day actuarial statistics, where ‘lifetables’ are constructed on behalf of insurance companies to help them estimate the probable lifespans of various classes of individual, have come to our aid in this project.
Getting below the surface
The application of computer technology in the excavation process itself has been a major area of growth over the last decade.
Personal computers  are now commonly found in site huts, even in remote locations where they can be powered by car batteries.
Modern scientific excavation techniques yield prodigious quantities of data, and the abilities of even quite simple personal computer database programs to organise, tabulate and sort this information offer the archaeologist very obvious benefits.
Such computer software is rapidly becoming the archaeologist's workhorse, both during the excavation process in circumstances where immediate feedback is desirable, and afterwards to help in preparing the final published report.
Invaluable as this sort of computing may be, the archaeologist's spade reveals more interesting and mathematically challenging problems.
Much archaeology involves looking for underlying patterns within a jumble of visual detail.
In extreme cases the search for order among the chaos can become too difficult for the human eye alone.
At sites such as Petters Sports Field in Surrey, archaeologists have uncovered large numbers of post-holes (remains in the soil showing where wooden posts once supported structures).
Such configurations (fig.9.7) can be difficult to interpret for two reasons.
Firstly, the marks one sees in the ground at any particular level may in fact result from many successive building phases, since the holes will commonly have been dug through earlier material and to varying depths.
Secondly, an individual post-hole  cannot easily be assigned to any particular building phase, since any datable artefact found within it could either pre-date or post-date the structure for which the hole was dug.
Nevertheless, provided that it is possible to make informed assumptions about the likely shapes and sizes of buildings at particular periods, a computer can be programmed to search for particular configurations of post-holes that might result from such a structure and ‘peel them off’, to reveal a simplified picture of earlier building phases.
The mathematical techniques for doing this were invented fairly recently, and, unlike most of those we have so far mentioned, were developed from scratch to solve a particular archaeological problem.
At sites where a number of periods of occupation overlie one another, the archaeologist has to identify and record very large numbers of what are referred to as contexts — divisions of the excavated material that can be distinguished in some way from their neighbours.
At Runnymede Bridge, the computer has been brought in to record and check relationships between contexts and to sort them into continuous sequences, thus ultimately helping the archaeologist interpret the sequences as a record of past human activity.
Accurate surveying of contexts in three dimensions is clearly a major part of the excavation process.
Modern surveying equipment such as Electronic Distance Measurement devices greatly facilitate this, not least because of their ability to store survey readings on data loggers, small electronic devices that record a large number of readings in a form that can later be easily transferred to a personal computer (fig. 9.8).
Clearly there are few barriers to filling the site's personal computer with survey data, but what can be done with it?
The excavation process is destructive.
After a site has been filled in again only artefacts, notebooks and the photographic record remain to aid the archaeologist in the long post-excavation period when he or she has to decide what it all meant, and publish details of what was found.
How valuable it would be to be  able to reconstruct what the site looked like while excavation was in progress.
Provided that enough information was recorded at the time, we can indeed use the techniques of three-dimensional computer graphics to achieve this.
A particular excavated level (corresponding, for example, to a bronze Age occupation floor) can be ‘modelled’ on a computer screen and the power of coordinate geometry embodied in a sophisticated computer program allows us to view it from any angle and at any elevation.
Distributions of artefacts of particular types can be superimposed exactly where they were found, to help in the search for significant patterns.
Furthermore, a digital graph plotter can reproduce the whole visual image on paper, with pinpoint accuracy, in a minute or two.
Figure 9.9 shows a computer reconstruction of an ancient land surface.
What does the future hold
This brief survey has provided at least a taste of current applications of mathematics and computers in the service of museums and archaeology.
What does the future hold?
Museums and archaeology both suffer from chronic under-funding, and at present there seems to be no cause for optimism that this situation will change.
Constrained resources will inevitably act as a brake on research and new developments, but there are other factors which work against this, and give us reason to be encouraged.
Field archaeology attracts a great deal of interdisciplinary interest since it offers so many varied and interesting problems.
There is greater incentive in archaeology than in many other disciplines for applied mathematicians and statisticians to develop new techniques, or to apply existing ones in novel situations.
Since 1973, an annual conference devoted to the applications of computing and mathematics to archaeology has been held at varying locations in Britain.
It provides a forum for the sharing of ideas among archaeologists, computer specialists and mathematicians.
During the conferences floppy disks containing home-grown software are exchanged like coinage, and between conferences software and messages continue to be exchanged by electronic mail.
The attendance has increased steadily over the years and the conference attracts more and more international participants.
The will and skill to move forward are therefore not in short supply.
Another major factor offsets the impoverished state of museums and archaeology and in the long term this will have a far more profound effect.
Quite simply, computers are becoming cheaper and more powerful all the time.
Archaeology and museums have not, of course, contributed to the massive commercial pressures underlying this trend, but to a large extent they can sit back and reap the benefits.
Nowhere is the pace of development more apparent than in computer graphics.
Software and hardware that allow us to display reconstructions of scenes in three dimensions are, as we have seen, already available, but are steadily increasing in sophistication and falling in price.
True integration of text and graphical information within databases is an area of major development effort among  computer manufacturers, and offers great potential benefits for the curation of museum collections.
Desk-top publishing already promises exciting possibilities for reducing the cost of publishing excavation reports.
Archaeological units are also being tempted by the impressive capabilities of geographic information systems, which in essence allow maps to be stored, displayed, overlaid and updated on a computer screen.
Laser light can now give us more than just music in our ears.
Compact discs can store data too, and act as a superb archiving medium for large databases, while videodiscs give instant access to thousands of high-quality photographic images on one 14-inch disc.
Further in the future, laser light looks set to replace electricity itself, driving computers a hundred times faster than the fastest now available.
Developments in the world of computing move close to the speed of light.
The challenge for museum curators and archaeologists in the 1990s is to keep abreast of them, and to exploit them to the full.
9.1 An artist's impression of an Early Bronze Age bronze axe from Devon.
Measurements taken from such a drawing allow a computer to compare axe shapes, and so also draw smooth and accurate reconstructions.
(The axe outlines in fig. 9.2 were drawn by computer in this way.)
9.2 left A schematic impression of part of a computer database of axe shapes, structured as an inverted ‘tree’.
The database is searched by following the ‘branches’ of the tree downwards.
9.3 right A multi-dimensional scaling configuration of thin sections from Roman tiles, showing six groups of similar tiles.
Each spot represents one thin section, and a typical thin section from each group is shown alongside.
9.4 Brass gold-weights made by the Ashanti people of Ghana:(a)far right shows a ‘figurative’ type (length 106 mm), and (b)above shows a selection of six ‘geometric’types.
9.5 Distribution chart of the weights of 1208 geometric-types Ashanti gold-weights from the collections of the British Museum.
The arrowed peaks show clearly how weights tend to concentrate around multiples of a basic weight unit.
No evidence was found of similar quantisation with figurative gold-weights.
9.6 A group of north-south oriented graves within barrows excavated by the British Museum at the village of Burton Fleming in Humberside (courtesy Tony Pacitto).
9.7 Distribution of post-holes:(a) found during excavations at Petters Sports Field in Surrey;(b) and (c) show an archaeologist's interpretation of the structures that gave rise to medium depth and deep post-holes, respectively.
9.8 Electronic Distance Measurement device in use at the British Museum's excavation at Torbryan Caves in Devon.
As the operator takes readings they are recorded automatically on the attached ‘datalogger’, to be transferred later to a personal computer (courtesy Cath Price).
9.9 A computer with graphics software installed can process the data from a surveying instrument and reconstruct a three-dimensional impression of the land surface.
Computing the Collections: The art of successful flea handling Lea Jones
The British Museum's collections contain a pair of dressed fleas from Mexico.
Sceptics may baulk at such an idea, but given the attested presence of such equally implausible-sounding objects as a block of portable eighteenth-century soup (ex Captain Cook), Inuit seal-gut underwear, African cobweb hats and other equally exotic objects, the concept of dressed fleas may seem more acceptable.
This chapter addresses the problem of handling these fleas, not as extraordinary ideas, nor even as physical entities, but as units of information.
Each object in a museum comprises a potential body of information, of both administrative and academic significance.
These units may be every bit as difficult to define and handle, conceptually at least, as the fleas themselves.
The role of documentation and the devices for handling information in a museum context often remain hidden to visitors, who are nonetheless  bombarded with information from the moment they enter any large museum or art gallery — in the form of signs indicating the way to the cafeteria, ground-plans of the premises, or, more obviously, labels and information panels associated with the gallery displays.
Few people, however, are aware of how object-related information is generated, gathered, structured and subsequently applied.
The processes that generate information about an object within a museum are many and varied, raising problems of both theory and practice, particularly when a major institution considers computerising this information.
The art of information handling is complex.
There are no absolutely right or wrong ways to apply it, only good or bad practices.
The diversity of museum collections in general requires that these practices be sufficiently flexible to accommodate the unusual object or set of circumstances, and yet sufficiently disciplined to ensure that realistic standards can be established and maintained.
Within every institution (and indeed, individual) may be found the polarised views of the pedant and the pragmatist.
The former will cling rigidly to formulae regardless of the situation, nit-picking over tiny detail but sometimes unwittingly missing the larger issues.
The pragmatist is more flexible, recognising that exceptions do arise and must be practically catered for.
Both attitudes have a valuable role to play when considering an issue such as how to computerise a major corpus of information which exists in a variety of document types of varying degrees of complexity and intelligibility.
The British Museum has a sound history in the field of documentation, even if our predecessors were on occasions less rigorous in their practices than are current staff.
In 1756 the Museum was compiling records of its acquisitions in bound ledgers called ‘The Book of Presents’ and in 1836 the then single Department of Antiquities began to complete bound Acquisition Registers of a type still in use today (fig. 10.1).
There are now ten curatorial departments, and a project of ten years standing, systematically computerising data about the collections, offers the means of sophisticated information retrieval.
There is now a general awareness of the desirability of providing accurate and well-maintained inventories of the holdings of all major publicly funded institutions in order to guard against the loss of objects.
However, it has also been recognised that it is impractical to impose a universal method of inventory control across all museums and art galleries.
The diversity of collections even within a single museum demands instead a flexible series of management devices.
These typically comprise the registration of objects, location of the items, stock-taking and auditing processes, as well as the longer-term creation of catalogues and other adjuncts to research.
General collections management processes (i.e. the formal documentation of an object on acquisition — or ‘accessioning’, monitoring object condition, recording of object movement, loan processing, storage environment, etc.) are, however, becoming more generally standardised as a result of the work and influence of bodies such as the Museum Documentation Association.
All these processes generate and use  documentation.
The mere presence of an object on museum premises entails some form of associated documentation.
Not surprisingly, many museums experience difficulty keeping pace with such large-scale demands for recording and, latterly and increasingly, retrieval of this information.
However, with recent advances in information technology it has been shown that automation of all or some of these processes will provide an effective way forward.
A major problem facing established museums is the natural variation in recording practices that have developed with time.
It may be, for example, that the attribution of inventory numbers follows not one but many forms, each with its own idiosyncratic syntax.
Objects may move between departments, as new departments are formed either by evolving from existing ones or merging with others (fig. 10.2).
When this happens, items may not be re-registered but will retain their original identity.
The original documentation similarly remains with the original department that created it.
There are practical reasons for this arrangement: any  manual system of record-keeping relies either on heavy duplication of information, sited wherever that information may be routinely required, or on a complex system of cross-referenced card-indexes which provide guides to relevant documentation.
In either case, the time, expertise and sustained communication required to make this system work place heavy demands on staff who normally have other priorities.
Automation of an information system provides an effective solution to these problems if only by centralising the information concerned.
Centralised records provide the means by which many people may have access to the same body of information, regardless of their physical situation.
It may also be argued that, provided a computer record is sympathetically laid out, it is more readable than many handwritten entries found in registers, where handwriting, variations in content and idiosyncrasies of style may conspire to confuse the reader.
As a preliminary to automation, a major process of review is necessary in order to establish the nature, content and application of the information categories and of the documents containing them.
Without such a review there is a serious danger that existing documentation problems may simply be automated along with the data, thus perpetuating rather than resolving them.
Equally, this important preliminary is vital to the success of choosing a suitable computer system.
Along with the review of existing data, a clearly defined set of objectives needs to be defined.
At the most basic level, major museums must satisfy a requirement to produce inventories, regardless of any additional or subsequent developments.
‘Great fleas have little fleas…’:
What is an inventory?
An inventory should contain sufficient information to enable the unequivocal identification of an object.
The object name, its identification number, and its location are the very minimum categories of information that may usefully be called an inventory.
The creation of an inventory and an audit trail addresses various problems, both of theory and practice.
To be genuinely useful, it is essential to include some reference to the number of elements involved in any one ‘object’ described as a single item.
Without a clear understanding of ‘how many’ as well as‘what’and ‘where’, there cannot be a confident system of collections management.
This prompts a further question: how should this indication be expressed?
How, for example, should one handle the dressed fleas and their garments in terms of a computer record?
The pedant might create a separate physical record for each item: the fleas, plus the individual garments.
Theoretically (it would be argued) these items may become detached from the flea and be lost in the collections.
Should they be found, it would be necessary to have a physically separate record to enable specific identification of this object to be made.
The pragmatist might acknowledge this point but would offer the further thought that, under normal circumstances, it is unlikely that a flea's stray garment could be mistaken for anything else, and that the flea. its garments and any other intimately associated paraphernalia would be more sensibly and  helpfully handled as a single record.
A text description of the item(s) covered by the record should allow the information to be both recorded and retrieved without having to split it between several records.
In this way all the fleas and their items of clothing may be recalled successfully.
Furthermore, they would be viewed as a single entity from a collections point of view.
But (the pedant may pursue the point), what if the flea and its garments were housed in separate locations?
Then say so in the record, the pragmatist would counter.
In this way the flea gets to keep its clothes on — at least in the records, if not the collections.
It is indeed possible for a theoretically single item to have more than one location simultaneously, typically the case with temporary locations and compound objects.
A bowl may require conservation, or need to be photographed, but its associated pedestal may not.
Thus the bowl will change its location, whilst that for the pedestal remains the same (i.e. the permanent location for both the bowl and pedestal).
However, the true condition and nature of an object can only really be judged by physically checking it.
This, too, is a major element in an inventory.
‘…upon their backs to bite 'em’: Hazards of locating the collections
The collectors of the eighteenth and nineteenth centuries evidently had few qualms about braving remote and inhospitable peoples and places, and their donations to the Museum collections occasionally reflect the intimidations and perils they faced in acquiring them — precisely what Museum staff experience when confronted with some of these legacies.
Darts that are literally ‘dressed to kill’, with curare and other nerve poisons, can be particularly difficult to handle, psychologically as well as physically.
Gloves do not provide total protection against accidental nicks.
The darts, the lumps of poison and the raw materials from which it is extracted all provide a challenge for others with a taste (figuratively speaking) for excitement.
(It should be made clear that, in the vast majority of cases, the poison is so aged that its potency is thought to be negligible.)
A frisson of concern ran through the staff when it was discovered that items have only been routinely fumigated against pathogens since the 1950s.
Anthrax, it appears, is a remote but potential hazard.
Parts of people present another unusual challenge (fig. 10.3).
The Egyptian department's assorted examples of the embalmer's art extend from the full body to three lone penises (gilded).
These examples vie with other reminders of some of the more arcane uses to which human technical ingenuity has been applied: the production of shrunken human heads from South America, or indeed dressed fleas from Mexico.
In all cases, the challenge to the documentation specialist remains the same: how to do justice to the objects in order to create an accurate and sufficiently detailed record of the object to allow it to be identified with confidence.
Possibly more terrifying than the prospect of being run through with poisoned weapons, gassed by noxious organic exhalations from embalmed bodies, or turning black with anthrax, is the very real prospect of an object  disintegrating in (or falling from) one's hands.
Museum staff are trained in the handling and care of objects and are well aware of some of the obvious dangers.
For example, a crispy one-hundred-year-old nest of leaf boxes that snugly fit their storage device is best left snugly fitted in their storage device and observed in situ during inventory checks.
Handling objects of this sort may well result in extensive (and expensive) damage.
The awful prospect of dropping a priceless Ming vase, everyone's idea of a nightmare, is minimised by working in pairs, with one person observing the necessary details from a safe distance and the other handling the object.
A more recent development in information technology, that of interactive videodisc, may provide the means of avoiding some of these hazards.
If an image can be provided of the more inaccessible, fragile or minute objects, students and visitors may view the record and image simultaneously without anyone having to handle the items.
This has several advantages: fragile items will be spared the cumulative damage resulting from repeated handling and removal from storage facilities.
In addition, museum assistants or other personnel whose task it is to prepare the objects for visitors and to supervise their access to the collections may have more time for other tasks.
‘And little fleas have lesser fleas’: What price detail?
A limited inventory is exactly that.
It cannot offer any greater insight into the object, the circumstances of its manufacture, or the cultural framework  from which it derived.
The inventory does not constitute ‘information’ but ‘data’.
There is no automatic association, for example, between the object's name, its provenance and its physical location within the Museum.
Thus, a list of object names from such a database will only be a list of names, not a list of names according to country of origin or date of manufacture.
This would constitute information — data plus a contextual framework allowing a larger picture to be revealed.
But how detailed should (or can) this information be?
Clearly much will depend on the availability of information in the first place.
Some register entries are so rudimentary that they are unable to support anything more than a basic inventory.
Other registers and sources, such as departmental file cards and reports, can be used to enhance a basic level of data so that it truly constitutes information and, as such, is useful for the production of books, catalogues and as a research tool.
Different departments require a different degree of detail for different research applications.
The quantity of detail and the resultant record size will also affect the amount of time involved in the creation of a single record.
In a perfect world, where resources are unlimited, all available data could be accommodated.
Sadly, this is not possible.
Constraints of finance, manpower and time all conspire to limit what may be achieved, and compromises are inevitable.
The enhancement of records into research tools must remain secondary if the primary objective is producing an inventory.
However, some middle way between a basic inventory and a fully detailed record is possible.
Information about materials and techniques of manufacture, geography of find-spot and manufacture, and a short free-text description of the object are examples of the information categories currently included in the British Museum's inventory.
However, the enormous diversity of objects within and between the collections does mean that a degree of flexibility is necessary to provide a sensible selection of fields that reflect the variation in object type.
For example, different aspects of a picture, a coin and an Egyptian mummy would need to be emphasised if they are to be distinguished from other objects of the same sort.
Despite limitations imposed upon the quantity of information recorded, there are ways to guarantee quality and to maximise the usefulness of the available information.
How data are input is directly relevant to the way the same information is retrieved from the system.
Control of the quality of data can be vitally important.
In most systems, if a word is misspelt or miskeyed, that piece of data can only be retrieved if the same format is used during the retrieval process.
One means of controlling the way data are typed into a record is by a so-called ‘authority list’.
This can be useful in situations where a set number of allowable words or phrases may be used when adding data to a specific part of the record.
Any word or phrase not recognised by the computer as being on the authority list will cause the list of available choices to be displayed.
The person entering the details must then choose an option from this list and the computer will then add the choice to the record automatically.
An example of how this might be applied to an  inventory record would be to control the format of named collections, e.g. ‘Sloane Bequest, Miscellanea’.
Without controlling the way in which this collection name is entered.
it is possible that the retrieval of records bearing such information might be wholly or partially unsuccessful.
Another similar but more sophisticated device for use in record systems is a ‘thesaurus’(fig. 10.4).
A thesaurus (see Chapter 9) is essentially a database in its own right, with each word constituting a record, cross-referenced to other records or terms through a series of relationships which can be broad, narrow or related (e.g. ‘metal’ is a narrower term of ‘inorganic’, but it is a broad term of ‘iron’.
In turn, iron is a related term to ‘steel’.)
Each term is also designated as either ‘preferred’ or  ‘non-preferred’, i.e. deemed suitable for inclusion in a record, or not.
Non-preferred terms are not absolutely forbidden for use in the records, but no relationships are attached to them, and this has implications during information retrieval.
Supposing someone requires a list of all the metal items in a large collection.
Without a thesaurus, the records would need to be searched by naming all the metals individually, but without knowing which metals have actually been recorded in the records.
This is clearly cumbersome and possibly unsatisfactory and many users might be tempted to abandon the process before achieving their ends.
In contrast, use of a thesaurus would require only the broad term (in this case, ‘metal’) to be stated, plus the relationship to be investigated (in this case the narrower terms).
In this way all records with named metals will be retrieved, as well as those that only possess the term ‘metal’.
An additional element found in the thesaurus is a ‘scope note’.
These offer the opportunity to record additional insights into the content or application of a term, particularly if there is some ambiguity involved.
This is especially useful in a museum context, where vast numbers and types of objects representing different specialisms may be united by the thesaurus.
A particular problem requiring resolution concerns the status given to scientific names for plants and animals.
The problem arises when more common, everyday names are available.
Take the human flea, or Pulex irritans .
The pedant's argument might be that Pulex irritans is a very specific term for an otherwise undistinguished little insect.
It provides precision, ‘flea’ being too vague and potentially confused with other types of flea, such as the dog flea, or (disaster!) the water flea.
The pragmatist might suggest that precision is fine only so long as everyone understands the term: in fact,Pulex irritans is less obviously a flea, than ‘flea’.
The pedant, persistent as ever, could insist that Pulex irritans is the proper term for a flea and it therefore ought to be provided for those who understand it.
The pragmatist could agree, pointing out that the scope notes for each term could be used for precisely this purpose, adding that, unless a scientific name has no more common alternative, it should remain non-preferred, with an alternative preferred term supplied.
The thesaurus functions not only as a retrieval aid, but also as a reference facility.
People are often uncertain as to the exact nature of the enquiry they wish to make concerning the Museum collections.
Sometimes this uncertainty is due to ignorance of the contents of the records and the way in which objects are referred to, particularly in large and varied collections.
Browsing through the thesaurus allows the user to move between ideas and concepts, on the one hand, and individual terms — either as an alphabetical list, or as separate records in which all the terms that are related in any way are displayed, along with the scope notes.
The user is then able to make a detailed search of the database, armed with the knowledge of its potential contents and the spelling of the terms involved.
This aspect of information handling in museums is a lexicographic task, involving the definition, refinement and structuring of the terms employed in a computerised record.
‘…
And so ad infinitum’: Where will it all end?
The task of computerising the collections of an institution like the British Museum is a substantial one, but the day will come, some years hence, when all departments have had all their documentation computerised and all their objects checked.
However, there will still be the ongoing task of maintaining the system that has been created.
A database requires maintenance, not merely because new records will have to have their content assessed and controlled, but because when new ideas permeate the academic disciplines, this too should properly be reflected in the terminology used in the construction of records.
A database should be as dynamic as the institution that creates it.
Its production is not a once-and-for-all process but a tool in its own right, complementing the many other processes that contribute to the Museum's development.
10.1 Page from an old British Museum register dating from 1908.
10.2 diagram showing the evolution of the curatorial departments within the British Museum since its foundation in 1753.
10.3 Mummified head from the Egyptian collections.
10.4 Example of a thesaurus display.