

4 Causes of Depression
Our knowledge of morbid mental states is much less definite than our knowledge of many physical disturbances.
We are not likely to find a cause as precisely as the tubercle bacillus can be shown to produce tuberculosis.
We find, in every case of mental disorder, antecedent happenings, no single one of which is the cause, but all of which contribute.
Certainly one is the last straw, and may be blamed as the exciting factor.
But that is often wrong, because it may be the lightest straw in the whole bundle.
(National Council for Mental Hygiene, 1927)
Depression is the most prevalent of all psychiatric disorders described as the common cold of psychiatry.
A certain degree of depression regularly accompanies serious physical illness (Greer, 1985), and one in four working-class women with at least three young children at home experience clinical depression at some point during a one-year period (Brown and Harris, 1978).
And as depressed parents can have a deleterious effect on their children's behaviour and vulnerability to psychiatric disturbance (Rutter, 1966), the number of people who can be affected in some way by the disorder is substantial and marks it out as one of the most important psychiatric conditions.
But comparing depression to a cold is misleading in so much as it implies that the condition is not only common, but mild.
In reality, depression can sometimes be serious and deadly.
Most people who commit suicide are depressed (Robins, 1981), and suicide is one of the top ten causes of death in most European countries (Kreitman, 1983).
Someone who is mildly depressed finds his everyday life to have lost its pleasure and interest.
Everything requires extra effort and provides less gratification than before.
He feels excessively tired  and preoccupied with ordinary bodily discomforts.
Hopes, plans and pleasant memories are hard to keep in mind, and realistic worries take prominence.
He can usually continue to work and meet his everyday obligations and may seem normal to acquaintances.
But to himself and those close to him, something is not right (Brownsberger et al., 1971).
Someone who is more severely depressed may feel physically ill as well as gloomy.
His thinking, speech and movements may be slowed (psychomotor retardation), or he may be tense and restless (agitation).
He will quite likely suffer from insomnia, sleeping for short periods, dozing fitfully and perhaps lying awake through the early hours of the morning.
These lonely hours may be the time he reaches his deepest despair.
He may also lose weight, lose interest in sex and suffer from obscure pains (Brownsberger et al., 1971).
The experience has been described as a sense that the self is worthless, the world meaningless and the future pointless (Beck, 1973).
Numerous theories have been formulated to explain the disorder, from many different perspectives: psychoanalytical, social, behavioural, cognitive and biological.
Understanding of the disorder has progressed in all these directions, and several attempts have been made to combine some of these ideas in an integrative model (e.g. Akiskal, 1979; Gilbert, 1984).
The advantages of the disorder in evolutionary terms have also been considered.
Given that natural selection has not eradicated the disorder, despite its association with suicide, with the possibility of reduced fertility, and impaired efficiency in behaviour, it is likely to have had some value.
John Price (1968) has made two suggestions: perhaps temporary moods of pessimistic caution have proved to be advantageous in avoiding predators, or perhaps depressive behaviour has evolved as part of the complex behaviour which maintains the stability of man's community.
A dominance hierarchy is known to exist in many aggressive animal communities.
Perhaps elated behaviour has evolved in connection with a rise in the hierarchy, depressive behaviour with a fall.
The causal sequence is unimportant, that is, whether the elation or depression came before or after the rise or fall, as the importance of the behaviour would be that ‘he should stay down quietly and not try to make a comeback for some considerable time’!
These ideas may seem fanciful, but Price justifies such speculation as leading us to consider and test new hypotheses which might otherwise not have been considered.
For example, the first model  would suggest some research into neuroendocrine mechanisms of hibernation in relation to depression; the second to studies of changes in dominance both in animals and man (that is , a person's standing in his group of acquaintances).
In fact, it could be argued that too little has been made of the naturalness of depression — that to a large extent it develops as an understandable reaction to life circumstances.
Many theories (conditioning ideas for instance), emphasise the maladaptive aspects of depressive thoughts and behaviour, and the distortion by depressed people of the threatfulness of experience.
There are likely to be more opportunities for prevention if the social factors themselves are of causal significance in clinical depression, rather than the person's distorted interpretation of their threatfulness.
And some of the best research evidence on the development of the disorder points towards this conclusion.
Psychoanalytic theories
The similarities and differences between grief and depression have had a central role in the development of psychoanalytic theory.
In Mourning and Melancholia, published in 1917, Freud proposed that loss was central to both these states.
But whereas normal grieving focuses on different aspects of the lost person, the depressed person seems to be grieving over an inner loss.
For the depressed person, the loss may be of a more ideal kind and may relate to aspects of himself that destroy his security of self-esteem.
He may also be very hostile towards himself, belittling himself.
By contrast, self-regard is not usually diminished in normal grieving.
The importance of loss and low self-esteem to depression has been accepted by many.
However, there is a good deal of disagreement about how they come about.
Freud believed that the depressed person had developed from childhood with high dependency needs.
He was therefore always vulnerable to disappointment — since he needed too much, he could never get enough.
As Brownsberger and colleagues (1971) describe it because his needs are chronically unfulfilled, he has feelings of frustration and anger.
Such a person is in a serious bind because expressing his anger will drive away or make hostile the very people he is dependent on.
Therefore, he must hold in his  anger, which seems to eat away at his insides, leading ultimately to feelings of helplessness and self-reproach…
It usually comes as a surprise to discover how angry the patient is, because superficially and consciously he blames no one but himself.
The cause of the anger is a loss, real or symbolic.
The unleashing of the anger against the self causes a catastrophic fall in self-esteem.
Of course, this is a gross oversimplification of a complex and much more wide-ranging theory; a comprehensive review of psychoanalytic ideas can be found elsewhere (see, for example , Ellenberger, 1970; Gilbert, 1984).
Only those ideas which can be traced through many different formulations on depression in the seventy years since Freud's book was published are touched upon here.
Many other psychoanalytic theories have been developed since Freud.
Some very valuable ideas have been put forward in recent years by John Bowlby (Bowlby, 1969; 1973; 1980).
Loss is also central to Bowlby's theory, but the losses which are the basis of vulnerability are real and not imagined and centre on a person's failure to make or maintain a stable and secure relationship with his parents early in childhood.
Mourning and depression are not seen as overlapping through different processes; rather, early loss or bereavement actually produces the vulnerability to psychiatric disorder (which may not necessarily be depression).
Bowlby's formulations, known as ‘attachment theory’, suggest a strong causal relationship between the person's early experiences with his parents and his later capacity to make affectionate bonds.
Bowlby believes that we have an instinctive (inherited) need to maintain proximity to attachment figures, because this has had evolutionary survival value.
We have therefore developed behaviours designed to maintain proximity to, and protection from, caregivers when those relationships come under threat, such as distress calling and clinging.
A range of emotions are consequential upon the making or breaking of close relationships — anger or anxiety when they are threatened, depression when they are lost, joy when they are reestablished.
Early attachment behaviour is crucial to understanding later psychiatric problems.
Certain experiences can predispose a child towards feelings of helplessness, towards a propensity to interpret information in a negative way, and towards a continuing perception of irretrievable loss.
For instance, he may have found it impossible to meet his parents' aspirations for him and never attained a secure  relationship with them, or he may have repeatedly been told he was unlovable and incompetent, or he may have experienced actual loss of a parent.
Ideas from the psychoanalytical school have been extremely influential, and can be seen to have filtered through into a wide range of theoretical models of depression.
In particular, the concepts of loss, attachment, self-esteem, anger against the self and helplessness have been important.
Psychological theories
Both behavioural and cognitive theories are relatively recent developments, and have begun to have some impact only in the last decade or two.
Gilbert (1984) provides a valuable summary of many of their approaches.
Some of the ideas incorporated in these theories are clearly recognisable from psychoanalytic formulations.
But while psychoanalysts often drew many of their ideas from clinical experience with mentally ill patients, many recent psychological approaches have studied how depressive thinking can be induced experimentally in students.
This is true of two interesting and important cognitive theories, the first of which has proved to have considerable usefulness in the treatment of depression and the second in understanding some of the biological mediators of depression.
Beck's cognitive theory of depression centres on the development of a negative view of oneself, and life in general, which can lead to depression (Beck, 1973).
Once again, childhood loss is seen as the origin of this negative view.
The loss may be an object or person, or perhaps an aspiration which held some considerable positive value to the person.
If the evaluation of the loss becomes generalised, the person will see himself as a loser, lacking in skills and opportunities to make the future rewarding.
Beck suggests that we have an automatic style of thinking which to a large extent determines the conclusions we derive from experience.
The person prone to depression has a tendency to interpret events negatively.
However, he does not have this negative interpretation of all events or all the time — otherwise he would be permanently depressed.
It is only in the pursuit of important goals that he may see himself in a negative light, and only during the recurrence of situations similar to the childhood loss that brought the negative schema into existence.
For instance, the child may have been stigmatised  by a physical handicap and rejected by peers for a number of years.
In adulthood, he may over-react to rejection from peers — a rebuff from someone he hoped to date perhaps.
He would tend to make an extreme and absolute judgment of his worth.
He may also learn other negative cognitive schemas.
A distressing failure in something which was important to him, athletic ability perhaps, may lead to him making a negative judgment about himself every time he experiences any difficulty in competitive activities in the future.
Each time this judgment is made, it reinforces the negative self-image.
The key notion is that it is not events themselves which produce depression, but their meaning to the individual person.
It is the person's cognitive schema which translates events into their internal representations.
Seligman has also suggested that a maladaptive style of thinking can be learned which predisposes a person to depression.
He identifies one particular cognitive style as crucial: helplessness (Seligman, 1975).
The theory originates from experiments with rats in which the animals were confined in a small space and given electric shocks.
In some instances the rat could learn that, following a particular response, he could prevent the delivery of the electric shock.
In others, no response would affect the arrival of the shock.
Similar types of set-up were also tried with students confined in a room with a loud noise.
The findings were, essentially, that those rats or students receiving the uncontrollable unpleasant experience began by making determined efforts to stop or escape it, but after a lack of success, eventually became passive and helpless.
What was of most interest, however, was that these subjects then performed less well in subsequent trials when the outcomes were made controllable than did those animals or students who had previously been in controllable situations.
These findings were considered to have direct implications for the development of depression.
‘Learned helplessness’ describes the individual's learned expectations that events are largely impervious to his influence and that unpleasant outcomes are probable.
This can produce all the negative attributes of depression.
These include passivity and intellectual slowness (motivational deficits), a belief that one's actions are doomed to failure (cognitive deficits) and the emotional component of depression.
It is not the uncontrollable event, however, which is crucial as a determinant of depression but  the expectation of a lack of control over stress which is argued to be a sufficient condition for depression (Seligman, 1975).
However, these proposals meant that Beck's and Seligman's explanations were in conflict (Gilbert, 1984).
According to Beck's theory people prone to depression have a tendency to blame themselves for negative outcomes.
In Seligman's theory, negative outcomes are seen as uncontrollable by the person himself.
A good deal of research has been stimulated by the learned helplessness model and by the question of how we attribute causes to different events.
Laboratory studies in which researchers have set up tasks in which failure could be induced experimentally have indicated that depressed people have a tendency to blame themselves if they get the task wrong, and the ease of the task if they get it right.
This is more in line with Beck's ideas.
This and many other weaknesses in Seligman's theory led to a reformulation (Abramson et al., 1978).
The new formulation is based on attribution theory.
Attribution theory maintains that the causes of events cannot be observed, but are construed by the individual to render the environment meaningful.
The cause may be attributed either to internal factors (self) or external factors (others, the world) and to stable factors (such as ability or task difficulty) or unstable factors (such as luck).
Abramson and his colleagues suggest that when a person is unable to resolve a problem he attributes his helplessness to a cause.
The cause may be stable or unstable, internal or external, global or specific (that is, extended to all areas of life or felt only in relation to a particular problem).
These attributions will determine whether future helplessness will be chronic or acute, broad or narrow, and whether or not self-esteem will be lowered.
That is, the generality of the depression will depend on whether the person's helpless views extend to all areas of his life; the length of the depression will depend on how stable his helpless attitudes have become; and self-esteem will be lowered if the person has internalised his helpless attitudes and sees himself as a failure.
Finally, they suggest that the intensity of the depression will depend on how strong is the expectation of uncontrollability and on how important the outcome of the situation is seen to be.
People who ‘typically tend to attribute failure to global, stable and internal factors should be most prone to general and chronic helplessness depression with low self-esteem.’
In abandoning the notion that the uncontrollability of events themselves was crucial  in favour of personal attributions, the learned helplessness theory is now in line with a cognitive view of depression.
Unusually, Abramson and his colleagues spell out the potential preventive implications of their ideas.
First of all, they suggest that it may be possible to identify those people at risk of depression, that is, those who tend to make global, stable and internal attributions for failure, before they become depressed.
Attempts could then be made to force the person to criticise and change his attributional style.
Secondly, people living in social situations likely to produce vulnerability may also be identified, that is, where undesirable outcomes are very probable, and highly desirable outcomes unlikely.
Here a change of social circumstances would be needed if vulnerability were to be reduced.
Thirdly, it may be possible to help people who have a tendency to exaggerate the unpleasantness or desirability of outcomes not to ‘catastrophise’ about uncontrollable outcomes.
This may reduce the intensity of future depressions.
Finally, a life history which encourages people to expect to be able to control the sources of suffering and nurturance in their lives should be protective against depression (Abramson et al., 1978).
This last suggestion has also been made by Garber and her colleagues (1979), who describe several experiments to demonstrate that when people first face controllable unpleasant situations before experiencing uncontrollable unpleasant situations, they are less helpless in later similar circumstances.
Thus, if people achieve a fair degree of mastery over outcomes and have experience in controlling and manipulating the sources of reinforcement in their lives before they are exposed to uncontrollability, they should be more resilient to depression.
It may be possible to devise some kind of training programme for certain difficulties to achieve this effect.
The model of learned helplessness has many appealing aspects and presents clear avenues for research.
Much work has already been generated on the biological mechanisms involved.
However, it can by no means be described as a complete model of depression.
Furthermore, it has been criticised for not distinguishing between types of depression and confusing sad affect and clinical depression (Buckwald et al., 1978).
Most of the work and examples seem far more applicable to the former than to the latter.
Biological components
Adherents to a disease model of mental illness have shown considerable interest in the possibility that disorder is inherited, either a given condition itself, or some related psychological dysfunction.
This possibility can best be studied by examining twins growing up together or in different homes.
Identical twins have the same genetic constitution and usually a similar upbringing.
Fraternal twins have different genetic profiles but a similar upbringing, while identical twins who have not been brought up together will have the same genetic make-up but different social environments.
The role of environment and inherited characteristics can then be separately assessed by studying how often both twins with each type of background suffer from psychiatric disorder.
Considerable evidence has accumulated that there is a genetic component to bipolar depressive disorder, that is, where both manic and depressive episodes occur.
In 1968, Price reported that the 97 identical and 119 fraternal twin pairs studied up to that date had shown substantially different concordance rates for depression (68 per cent and 23 per cent).
Even when environmental factors were controlled by studying identical twins reared apart, the concordance rate remained the same.
Severe unipolar depression, that is, depression of a similar type and severity to the bipolar condition, but without alternating swings towards mania, also to some extent seems to run in families.
The mode of genetic inheritance is thought to be more complex than for bipolar depression, partly because the morbidity risk for relatives of affected individuals is much lower (Akiskal, 1979).
The evidence for genetic inheritance is much less strong for the less severe forms of depression.
There are many ways in which biological factors may be implicated in depression.
Erlenmeyer-Kimling (1979) suggests one possible link between genetic and social factors.
A good deal of depressive illness is known to follow adverse life events and it is known that human infants show considerable variation in response to separation from their mothers.
Suppose a propensity to react more or less negatively to the environment is inherited, but is also affected by environmental circumstances.
Two children (A and B) may both inherit a tendency to react negatively to stress.
But should A have a childhood characterised by a high degree of stress — a discordant family setting and numerous changes of residence perhaps — he will become increasingly  vulnerable to succeeding stresses.
If child B has had a relatively unstressful childhood, he will attain adulthood with a lower vulnerability than A. Child C, who also had a stressful upbringing, but inherited a tendency to react much less strongly or negatively to the environment, will also be less vulnerable in adulthood than A. However, there has so far been little cross-fertilisation between research on genetic factors in depression and research on life events.
Knowledge is growing on the physiological effects of life stress.
For instance, environmental events can produce alterations in the brain levels of neurotransmitters, particularly serotonin and norepinephrine (see Akiskal, 1979).
These transmitters modulate many of the functions impaired by depression — sleep, appetite, motivation, pleasure and so on.
A depletion of transmitters is therefore likely to be associated with impaired performance and to render the organism more vulnerable to frustration, loss and other life stresses that are expected to increase adaptive demands.
The evidence is complicated and inconclusive, and different types of stress seem to have different effects.
Furthermore, the biological factors which predispose certain individuals towards a depletion of these neurotransmitters have not yet been established.
However, it may be that for bipolar disorders there is an inherited deficit, while for milder disorders the deficit may come about in other ways (Akiskal, 1979).
Akiskal (1979) has attempted to integrate psychosocial and physiological factors into a unified model of depression.
He lists ten factors which he believes research has shown to be related to the incidence of depression: life events; social support; developmental object loss; coping skills; monoamine depletion; monoamine oxidase level; borderline hypothyroid function; impact of puerperium; alcoholism; and familial and genetic factors.
He argues that most of these causes are neither necessary nor sufficient, but contributory.
He illustrates this point using the life event of separation.
Separation is not a sufficient cause of depression, because a depressive response of clinical proportions is not observed in more than 10 per cent of those who experience it…
Separation is not a necessary cause for depression because many depressions develop in its absence…
Separation is not a specific cause for depression, as it precedes the onset or exacerbation of other forms of psychiatric disorder…
Separation may result from clinical depression and, therefore, it may aggravate or maintain a pre-existing depressive condition…
Finally, separation may precipitate hospitalisation rather than the depressive disorder.
Each of the factors known to have importance in depression are therefore seen to be contributory and not capable of acting alone in bringing about an episode of depression.
All are thought to converge on one ‘final common pathway’ leading to depression, in the diencephalon of the brain ‘as a functional derangement of the neurophysiological substrates of reinforcement’.
However, as Akiskal has no data to enable him to elaborate on the processes involved or the interaction of the contributing factors, his model does not yet have any practical value.
A psychosocial model of depression
While the psychological and biological theories focus their explanations on the person's depressive predisposition, important recent work has been conducted on prevailing environmental factors which bring the psychological factors into play and cause the depression to become manifest.
Research on the role of stress in psychiatric disorder has grown markedly since the Second World War when the numbers of psychiatric casualties brought an awareness to the general public of the prevalence of mental illness.
As screening procedures prior to recruitment had ensured that mentally ill or emotionally disturbed men were not enlisted, it was reasonable to see stress, rather than predisposition, to be of critical importance (Weissman and Klerman, 1978).
One of the most useful studies of the role of life events and difficulties in depression has been conducted by George Brown and Tirril Harris and their colleagues in London over the last fifteen years.
They developed their ideas in part from important work by Paykel and his colleagues on the association between life events and depression and other psychiatric conditions.
Paykel was one of the first researchers to categorise life events according to their meaningfulness and show the qualitative differences between events preceding different disorders (Paykel, 1978).
Previously, a quantitive method developed by Holmes and Rahe (1967) was commonly used to describe events, which simply assessed the degree of life change consequent upon them.
And much of the theory advanced by Brown  and Harris to explain the role of life events in depression drew on the ideas of cognitive psychologists like Beck.
Brown and Harris's model therefore provides a framework within which many of the ideas emanating from different perspectives can be brought together.
Biological factors could also easily be incorporated as additional vulnerability factors (see Akiskal, 1979).
Furthermore, in emphasising external social factors in the causal process, it provides the most hopeful model for a consideration of prevention, as social factors may be more readily modified than other contributing factors.
For these and two other reasons, this model will be described in some detail.
Brown and Harris have conducted a series of studies based on intensive interviews with large numbers of women in the community.
They are well known for their methodological rigour, and they study factors relating to depression of clinical significance, that is, their cases have symptoms at least as numerous and severe as those treated by psychiatrists in out-patient settings.
By contrast, many other formulations lack either systematic research evidence to substantiate them, or their evidence is collected from experimental studies using normal, or perhaps unhappy, students.
Brown and Harris described the foundations of their model and their first major survey in their book Social Origins of Depression published in 1978.
To begin with, they were largely concerned with the current, rather than past, experiences of their sample of women.
They suggested that there are three main sets of aetiological factors in depression: provoking agents, vulnerability factors, and symptom formation factors.
Stressful life events, such as discovering a husband's affair, and long-standing difficulties, such as a husband's continuing unemployment causing financial and marital strains, can often be found to precede the onset of a depressive disorder.
Such events and difficulties were termed ‘provoking agents’.
In order to explain why only some women but not others who experience such problems develop depression, they suggest that other social factors (such as a lack of a confiding relationship in marriage) make some women more vulnerable than others.
They suggest that vulnerability factors are usefully conceived as only raising the risk of depression in the presence of a provoking agent.
A third set of variables, which will not be discussed here, were included in the model because they influenced the form and severity of the disorder rather than contributing to its onset.
These were called ‘symptom-formation   factors’.
The model was diagrammatically represented as shown in figure 4.1.
The measure of life events used was one which had been developed by Brown over a number of years and represents a major methodological improvement over previous approaches.
It not only enables the categorisation of events in a meaningful way, but also allows the context of the event to be considered.
So, for instance, a birth would in all instances have been rated by Holmes and Rahe as entailing a high degree of change.
To Paykel, it would have been considered a positive event or ‘entrance’ event which he would therefore not expect to correlate with depression.
But Brown and Harris's Life Event and Difficulties Schedule (LEDS) would not lump all births together in this way.
If it was planned and wanted, it would be rated differently to the unplanned birth to an older woman which dashed her plans to take up a job which would enable the family to move to a more satisfactory house.
These ratings of a specific meaning were made possible by a two-stage assessment procedure carried out by the members of the research team, rather than using self-rating questionnaire methods.
Interviewers first decided whether a situation was eligible for inclusion by using a set of highly developed criteria provided for them.
Secondly, qualities of the event were explored and rated: their characteristics, prior experience and preparation, immediate reactions, consequences and implications.
This provided the basis for contextual ratings, the most important of which was found to be long-term threat.
Ratings were made by a team of researchers with no knowledge of whether or not the woman was a case, or what she  had said about her response to the event.
They used their own judgment about how much threat would be involved for most people in those circumstances.
The main part of the study took place in Camberwell, South London.
The subjects were women aged eighteen to sixty-five years.
One hundred and fourteen residents of the borough who were inpatients or out-patients at three local hospitals, thirty-four depressed women attending local GPs and a random sample (excluding ethnic minorities) of 458 women living in the community were interviewed.
All hospital patients had been given a diagnosis of primary depression uncomplicated by any underlying condition such as alcoholism, but were also given a full clinical interview (PSE) by the research psychiatrist.
The rest of the women were given a shortened version of the PSE and possible ‘cases’ were re-interviewed by a psychiatrist.
Given that they were not receiving psychiatric treatment, it was important to double-check that their symptoms were indeed similar to those of the women who were.
All the women were also given a full social interview about their family, employment, housing, financial circumstances, crises, marital relationship, events and difficulties of the previous twelve months.
The clinical interview provided information about the severity and diagnosis of disorders, but also enabled researchers to measure onset and course using a concept of change-points: a point in time when an increase or decrease in the number of symptoms led to a noticeable change in a woman's psychiatric state.
Depressed women were described as onset cases if their symptoms had begun (at a caseness level), at some point during the previous twelve months, and as chronic cases if their symptoms had begun before this.
Women with clusters of symptoms not severe or frequent enough to be classified as cases were labelled borderline cases, although some women with one or two symptoms were rated as normal.
The researchers found 17 per cent of their random sample of Camberwell women to be sufficiently severely depressed to be considered cases at some time in the year: 8 per cent onset and 9 per cent chronic.
The great majority were suffering from depression.
A further 19 per cent of this sample were judged to be borderline cases.
Life events were three times more common among depressed patients and depressed women in the community than among nondepressed women (61 per cent, 68 per cent and 20 per cent ), but  only if the events constituted a marked or moderate long-term threat and focused on the woman herself or jointly with someone else.
These were termed severe events and were assumed to have a causal role.
Non-severe events were not more common in patients or onset community cases, and events of extreme severity did not produce depression if their effect was only short-term.
Most of the events classified as severe could be interpreted as involving some kind of loss or threat of loss: finding out about a husband's unfaithfulness, a life-threatening illness to someone close, or redundancy from a job held for many years.
The loss or disappointment could concern a person or object, a role or an idea.
Severe events involving short term threat, on the other hand, rarely involved loss and were situations where the threat was over within ten days and there were no serious long-term consequences.
One example might be where a newborn child developed an infection requiring special care, but recovered in a few days.
The onset of depression usually followed a severe event quite rapidly — within a matter of weeks and sometimes even days.
However, there was some evidence that events could act over a period as long as six months or even a year, particularly in the patient series.
Furthermore, evidence was described to support their contention that the events were of formative importance, and were not merely serving to trigger depression in a woman who would shortly have become depressed anyway.
Brown and Harris found that it was not only discrete events which could provoke depression.
Long-term difficulties were capable of playing a similar role.
Problems like overcrowded home conditions or a husband's alcoholism, which had been going on for at least two years and which were rated as major difficulties (1–3 on a 6-point scale of severity), were found to occur in the lives of a great many more psychiatric cases than normal women.
Two-thirds of both patients and community cases experienced major difficulties compared to only 20 per cent of the sample of normal women.
However, only one in five of the women who experienced a severe life event or major difficulty subsequently developed depression.
The authors therefore examined the data for explanations as to why some women were more vulnerable than others, or, expressed another way, why some women seemed resilient to, or protected from, or were able to cope with adversity such that they did not develop clinical depression.
Four ‘vulnerability’ factors were identified: the absence of a close, intimate, confiding relationship with someone; loss of mother through separation or death before the age of eleven years; three or more children under fifteen years living at home; the absence of a job outside the home.
The model predicts that vulnerability factors can only be expected to be revealed amongst women experiencing major difficulties or who have recently experienced a severe event.
The percentages quoted are therefore proportions only of the women who were classed as having a provoking agent.
Among the random sample of women in Camberwell experiencing a severe event or major difficulty, only 10 per cent of those with a close, confiding relationship with their husband or boyfriend developed depression.
This compared with 26 per cent of the women without an intimate tie with husband or boyfriend, but who reported a confiding relationship with another person (seen at least weekly), and with 41 per cent of those who had a confidante seen less than weekly or who had no such relationship at all.
Loss of mother, through separation or death, was a second vulnerability factor: 47 per cent of women who had lost their mother against 17 per cent of remaining women developed depression following a provoking factor during the year under study.
And comparing those women with three or more children at home against those with fewer or no children, 43 per cent and 17 per cent respectively became depressed.
Finally, having a job outside the home decreased vulnerability.
The effect of this factor, however, could only be detected when the other vulnerability factors were also considered.
Among women protected by a close, confiding relationship with their husband, not having a job was unimportant and did not increase their vulnerability.
Those who were already more vulnerable, however, due to lack of such a relationship, were half as likely to develop depression following a provoking agent if they worked outside the home.
If they also experienced one of the other two vulnerability factors, having a job again afforded some protective effect.
All of the women without a confiding relationship or a job who also experienced one of the other vulnerability factors became depressed.
Of the four factors, a confiding tie with a husband or lover was seen to be the most important, in that this could protect against depression whether or not any one of the other three vulnerability factors was present.
These vulnerability factors were identified among the random sample of women in Camberwell.
A comparison of those women who  had become hospital patients with women in the community who were not depressed did not, however, fully replicate these findings.
In particular, the depressed patients did not have a substantially higher rate of early loss of mother, nor were they much more likely to have three or more children at home.
The authors argue that this is not evidence that their model is incorrect or inapplicable to treated cases, but that, to a certain extent, the factors which make women vulnerable to depression also make them less likely to receive psychiatric help.
Among women in the general population, having three or more children at home was found to increase a woman's vulnerability to depression in the face of provoking agents.
But it is easy to accept Brown and Harris's cautious suggestion that this same factor may make it difficult for the woman to get treatment.
To begin with, a general practitioner may be less likely to diagnose her symptoms as depression, seeing tiredness and other problems as understandable consequences of looking after three young children.
He or she, and, for that matter, the woman herself, may also feel it is likely to be difficult for her to be able to attend a hospital out-patient department.
If this interpretation is correct, this will mean that women with children will be under-represented among treated patient samples.
As a statistical association was found between having three or more children at home and the early loss factor, this might also help to explain the lower rate of early loss among treated patients when compared with cases identified in the community.
When the authors looked at the proportion of the community experiencing vulnerability factors, important social class differences emerged.
Working-class women were found to have more vulnerability factors than middle-class women, which largely explained class differences in the rate of depression.
Having established their basic model, the authors go on to describe their speculative theory of the processes involved (see Figure 4.2).
Two main concepts are crucial: self-esteem and hopelessness.
They suggest that any average person would have some feelings of hopelessness in response to the sorts of provoking agents they describe, but that women with low self-esteem would be less able to handle such feelings and more likely to allow them to generalise.
The vulnerability factors are argued to contribute to low self-esteem, or, as protective factors, to high self-esteem.
This is why vulnerability factors only become of causal significance when a severe event occurs or major difficulties exist.
A close relationship was thought to provide a sense of being valued.
Hence the lack of an intimate relationship, or the presence of a critical and uninterested husband, was suggested    as associated with a sense of being less valued.
In such circumstances, social activities or a job outside the home might compensate to some extent by providing alternative sources of value.
But three or more children would limit a woman's opportunities for social activities considerably.
One child might easily be taken along or left with a babysitter.
Three children present more difficulties.
And not having experienced ‘good enough’ mothering was suggested as setting a long-term personality of low self-confidence.
To some extent, this factor was linked to adult depression through its association with other vulnerability factors.
Perhaps the lack of self-confidence led the woman to marry a man she knew to be unsupportive in case she was not asked by anyone else.
Perhaps she lacked confidence to find a job outside the house or manage contraception efficiently.
Depression is not an all-or-nothing matter, however, and events which might provoke clinical depression in vulnerable women may produce borderline-case depressive illness in women who are more protected in terms of these four factors.
Some examples of the kinds of events and difficulties which provoked depressive illnesses in the sample are given in the Appendix.
Many of the events do not appear to be amenable to prevention.
Some of the difficulties, however, could clearly very often be reduced, or the woman's ability to cope with them enhanced by being introduced to helping resources grants for home improvements, arrangements to pay off debts in more manageable ways, or marriage guidance counselling.
Furthermore, while the effects of events in producing depression were often so rapid that there would scarcely be time to intervene after the event and before depression, major difficulties, by definition, had existed for at least two years, giving ample time for preventive intervention.
In fact many of the severe events arose out of long-term difficulties.
There are also many potential avenues for prevention through the vulnerability factors, and it would seem important to discover whether in practice vulnerability can be modified through preventive programmes.
Perhaps during social education discussions in schools, more emphasis could be put on the importance of considering the long-term supportiveness of a potential marriage partner, of thinking through one's aspirations for work and children and taking positive steps to achieve one's hopes rather than letting things ‘just happen’.
There could be more awareness of the ways in which women with children can get out of the home to meet socially or take up outside employment, and more facilities to increase those opportunities.
A psychoevolutionary perspective
A rival theory concerning the role of close relationships in depression to the Brown and Harris model has been put forward by Scott Henderson.
He developed his original perspective from Bowlby's ideas about man's instinctive needs to maintain close attachments.
The evolutionary advantage of pair bonding to protect offspring and male group relationships to facilitate hunting is well recognised.
Henderson's theory therefore centred on the belief that a lack of social relationships is atypical, that an inability to form social ties is disadvantageous, and the loss of or non-availability of important others likely to be emotionally distressing (Henderson, 1974).
Depressive symptoms are interpreted as abnormal ‘care-eliciting behaviour’— behaviour intended to bring important others closer when a person perceives himself deficient in the receipt of care.
After several cross-sectional studies with colleagues, he carried out a large-scale prospective enquiry in Canberra (Henderson et al., 1980).
He expected to demonstrate that social support was related to depression independently of stress (Figure 4.3A).
People lacking supportive relationships were expected to be prone to depression whether or not they experienced major difficulties or threatening events.
Alternative models are that support is protective against depression only when people have disturbing events or living circumstances and otherwise is unrelated to depression, as suggested by Brown and Harris (Figure 4.3B).
Or it could be related to a third confounding variable such as personality and this latter variable related to risk of depression (Figure 4.3C).
An example of 4.3C would be if a person's withdrawn, defensive personality made it  difficult for her to establish close friendships, and if those same characteristics of personality, rather than her lack of friendships, made her prone to depression.
Using the General Health Questionnaire and their own measures of social interaction and of recent life experiences, Henderson and his colleagues interviewed a large random sample of adults in Canberra.
The measure of social interaction rated the availability of six provisions of social relationships: attachment, social integration, opportunity for nurturing others, reassurance of worth, a sense of reliable alliance and the obtaining of help and guidance.
It also enabled an assessment of the adequacy of the provisions in the eyes of the respondent.
A modest negative association was found between neurotic symptoms and availability of attachment and social integration.
However, a much stronger negative association was found between neurotic symptoms and the perceived adequacy of social relationships.
It also seemed that the perceived adequacy of close relationships was of most importance to women, while for men it was the perceived adequacy of more diffuse relationships that was crucial.
In the longitudinal part of the enquiry, the investigators examined the possible causal role of support.
They interviewed a random subsample of 323 adults at four-month intervals on three further occasions.
A lack of social support at the first interview was found to be associated with the presence of psychiatric symptoms (GHQ scores) at the second interview among those who had initially been well (GHQ score less than 4).
There was a much smaller association between adversity measured at the first interview and symptoms at the second.
They therefore concluded that a lack of social relationships was a causal factor in the onset of neurosis.
However, the relationship between symptoms and support was stronger when adversity was higher, disproving their expectation that support was important independently of adversity.
Because their correlations were strongly linked to their rating of the respondent's perceived adequacy of their social relationships but not to their availability, they conclude that it is not therefore the actual social environment of people which is important to the development of neurotic symptoms, but rather that, when faced with adversity, it is those individuals who view their social relationships as inadequate who have a substantially increased risk of developing neurotic symptoms.
From their results they argue that this is not so  much an objective assessment of the functioning of their personal networks, but a judgment based on the ‘intrapsychic needs of the respondent, in terms of‘dependency’ or anxious attachment' (Henderson, 1982).
In other words, it is the personality of the individual which is crucial (as in Figure 4.3C).
This line of argument is bound to be disappointing for those looking at aetiological studies in search of implications for prevention.
It means that ‘attributes of the individual which are biological or constitutional are likely to be more powerful than properties of the immediate social environment or other ecological variables’(Henderson, 1982, p. 228.)
It means that the reason there seems to be an association between low social support and vulnerability to neurosis is because the same attributes of personality that make a person vulnerable to depression also make a person see their friends and relatives as unhelpful, whether or not they are around and available to help.
So we have the disappointing conclusion, from the point of view of prevention, that people with a neurotic type of personality are more likely than other people to develop clinical neurotic symptoms when faced with adversity.
But we are given no clues as to why some people should develop such personality traits.
As it stands, the crucial implication of these findings, if they are correct, is that increasing the availability of support for people with adverse living circumstances in an attempt to prevent depression would not be expected to be effective.
These fundamental differences in the explanations of Brown and Harris and those of Henderson and his colleagues about the role of social support in the aetiology of depression have prompted a search for the reasons for their discrepant findings.
O'Connor and Brown (1984) suggested that one explanation may be that Henderson did not differentiate between the actual support provided in terms of confiding and frequency of contact and the attachment felt for the person named.
They argue that the people to whom one feels most attached will not necessarily be those who provide support.
O'Connor and Brown maintain that truly supportive relationships (frequent contact and high level of confiding) reinforce a positive evaluation of self and are protective of mental health.
On the other hand, feelings of attachment to a person named as very close are not related to either.
In a study by this research team of married women in North London, feelings of attachment were not associated with self-esteem or depressive symptoms.
A second point, raised by Brown  and his colleagues (1986c) concerned the decision by Henderson to analyse the role of support only for those women completely free from any psychiatric symptoms.
This may also have caused the effects of support to be obscured.
Many women with adverse living circumstances at the first interview will have had one or two psychiatric symptoms and would be particularly likely to benefit from social support.
The existence of these symptoms, however, will have caused these women to be omitted from Henderson's analysis.
But perhaps what these discussions about Henderson's research illustrate most graphically is the considerable conceptual and methodological difficulty of conducting research on social support.
These issues will be discussed further in chapter 7.
Social and psychological factors relating to vulnerability and onset: evidence
It is clear that Brown and Harris's model of depression provides the most scope for preventive formulations, that it is the most complete model of depression available, and has been most systematically researched.
Henderson's alternative explanations have not been substantiated, but Brown and Harris's basic model has been confirmed and supplemented in further studies both in Islington in London and in a rural community in North West Scotland, and the original findings have been replicated by other investigators in other areas (see Brown and Harris, 1986 for a recent review).
What other evidence is there to confirm the importance of some of these factors?
(i) Life events
An increased rate of major events has repeatedly been demonstrated to occur in a period prior to the onset or recurrence of a variety of psychiatric disorders (Dohrenwend and Dohrenwend, 1974; Lazarus and Cohen, 1977; Brown and Harris, 1978; Paykel, 1978; Kennedy et al., 1983).
Follow-up studies of people experiencing particularly traumatic events such as bereavement have also shown a high rate of associated depression and anxiety.
For instance, Parkes and Brown (1972) interviewed sixty-eight young people in Boston on three occasions during the year after they had been bereaved.
Compared to a matched sample of non-bereaved people, more of the bereaved received hospital treatment and experienced disturbance of sleep, appetite and weight.
Their consumption of tranquillisers, alcohol and  tobacco increased and their income fell.
Up to fourteen months after the event, bereaved persons still showed more depression and a higher incidence of autonomic symptoms (dizziness, fainting, trembling, nervousness, chest pain, sweating and palpitations).
Paykel (1979) describes his research in New Haven in which the life experiences of 185 depressed patients receiving hospital treatment were compared with the experiences of a random sample of the same number of adults in the general population over a six month period.
He tried various ways of categorising events — as desirable (arrival of a wanted new baby) or undesirable (compulsory redundancy) or according to whether they represented exits from or entrances to the subject's life.
Patients reported about three times as many undesirable events in the six months preceding their illness as the comparison group over the same period.
There were no group differences for events rated as desirable.
If the same events were re-categorised as ‘exits’ or ‘entrances’, a similar pattern emerged: exit events were more common among the depressed group, but entrance events showed no group differences.
Interpersonal arguments and difficulties were also a more common feature of the experiences of depressed patients than of the comparison group.
Further evidence to suggest that events are important in depression according to their threatfulness rather than according to the amount of change they signify comes from a study by Tennant and Andrews (1978).
They interviewed a random sample of eighty-six people in Sydney about recent life events, and used the General Health Questionnaire (GHQ) to gather information about any psychiatric symptoms.
They found a closer association between GHQ scores and events when those events were categorised according to their emotionally distressing impact than according to change in lifestyle.
However, these kinds of events are not only of importance in depression; they are implicated in a variety of illnesses.
Paykel (1979) pointed out that events are also more common in the lives of schizophrenic patients in the six months before their first admission and in the six months prior to suicide attempts.
In fact, in his research, suicide attempters reported the most events, followed by people with depression, then those suffering from schizophrenia, and lastly the general population.
The exit-entrance distinction was found to be more specific for depression, and people who attempted suicide not only had an excess of exit events, but also an excess of entrance events.
People who had attempted suicide were also particularly likely  to have experienced an excess of events beyond their own control, which were rated as undesirable, and scaled as major or intermediate in terms of upset.
However, Paykel argues that specificity is, at best, weak, and therefore concludes that the same events may result in a variety of disturbances.
Other investigations have made a link between events and onset of physical disturbances such as an infarct, streptococcal infection, and gastrointestinal disorder (see Craig and Brown, 1984).
However, it appears that when the measurement both of the disorder and of the type of event are attempted at a high level of specificity, then more specific correlations are revealed.
There is some evidence that particular characteristics of events are more likely to be implicated in one disorder than another.
For instance, Finlay-Jones and Brown (1981) were able to show a markedly higher rate of events characterised by danger in the lives of general practice patients suffering from a recent onset of anxiety or from a mixture of anxiety and depression than in the lives of depressed and non-case patients.
Events characterised by loss, on the other hand, were more commonly experienced by patients with a depressive disorder.
One of the pitfalls of this kind of research is that, far from events causing a particular disorder, the causal sequence may actually be the reverse.
That is, the insidious onset of the disorder and tendency of the person to behave in an unusual way brings about certain events like changes of jobs or relationships before more obvious symptoms of disorder appear.
This possibility can be guarded against by distinguishing between independent and dependent events.
Independent events are those which are most unlikely to have been brought about by the behaviour of the respondent, such as a husband's car accident which happened while the woman was at home.
Finlay-Jones and Brown found the relationship between loss events and depression and between danger events and anxiety remained after dependent and possibly dependent events were removed from the analysis.
This encouraged the authors to argue for some causal role for these specific event types.
The magnitude of the link between events and depression has been estimated in various ways.
Paykel (1979) calculated that the risk of a person developing depression increases sixfold in the six months following an exit event.
Tennant and Andrews (1978) used their Australian sample to calculate that if social support and a person's coping skills were poor, and their stress scores high, then their risk  of neurosis was over 40 per cent.
But even these figures can be misleading in the same way as would a statistic relating risk of lung cancer as a percentage of all smokers.
A very small proportion of cigarette smokers develop lung cancer, but almost all people with lung cancer are or have been smokers.
This is similar to the position on life events.
Less than one in five people experiencing a severely threatening event or long-term difficulties will develop depression (Brown and Harris, 1978), but from a review of ten community surveys of depression using the same Life Event and Difficulty Schedule, Brown et al.(1987) found at least 76 per cent of depressive illness in the general population to be brought on by severe events or major difficulties.
However, there has been considerable controversy over the meaning of the link between events and depression — whether in fact the existence of a psychosocial stressor makes a depressive response so understandable that it should not be considered a disease.
Following this logic, only those depressive conditions where a stressor is apparently absent should be considered as ‘real’ depression, which is also sometimes assumed to be more likely to include psychotic symptoms and biological dysfunction.
This is a long-running debate which will not be documented here.
But it now seems to be established that there is no clear-cut difference in the role of environmental factors in so-called ‘neurotic’ or ‘psychotic’depressions (see Paykel et al., 1984).
But the important consideration for prevention is the identification of methods of intervention which will make serious depressive illnesses less likely to occur.
It is relatively unimportant what these conditions are called as long as they are characterised by a sufficient number of symptoms of depression to be definable as cases.
Psychosocial stressors are common enough in such conditions to warrant attention.
While a number of depressive illnesses treated by psychiatrists seem to have no link with environmental stress, many more do.
Furthermore, Calloway et al.(1984a; 1984b) found that depressed patients with the most clear signs of biological dysfunction had no less chance of having an antecedent stressor.
Paykel (1979) provides a useful model to describe the process by which life events can lead to physical or psychological disorder (see Figure 4.4).
Firstly, the significance of the event in terms of its meaning is important.
Then other current stresses and supports in the social environment may moderate its consequences, such as outside employment and confiding relationships.
Paykel separates these from the person's specific vulnerability to events, or to particular events, which has developed from personality attributes or developmental experiences.
Vulnerability to specific illnesses, of genetic or environmental origin, will also sensitise a person to particular types of events.
Finally, illness behaviour will determine whether or not the individual regards himself as ill and seeks professional treatment.
This approach takes into consideration the person's past history and current circumstances which may cause them to be especially susceptible to respond adversely to particular types of event.
The person may also have other genetic or environmental reasons to be susceptible to one type of disorder rather than another.
This idea, that the event is of particular significance when it matches the vulnerability of the individual, has recently been further amplified by Brown and his colleagues (1987), following a longitudinal study of depression among women in Islington, North London.
They found that a severe event was of most aetiological significance if it threatened a role, person or idea to which a woman was particularly  committed (established in an interview one year before) or if it matched a long-standing major difficulty in the woman's life.
For example, a woman highly committed to her parenting role would be particularly sensitive to an event which threatened her view of herself as a good mother, such as discovering her child had been regularly truanting from school.
Had she been less committed to parenting, perhaps because her children were older and seen to be less in need of her support, or had it been an event which threatened a role or idea to which she was less committed, perhaps losing a part-time job which she did not enjoy, the effect would be less threatening.
Similarly, events arising out of long-standing difficulties would increase risk of depression: where, for instance, a husband left home after years of arguing and discord; a child was arrested for burglary after a long history of behavioural problems at home and school; or a substantial fine was incurred after a long period of extreme financial difficulty (Brown et al., 1987).
(ii) Past loss
There is a long history of concern for the potential significance of childhood parental loss through separation or death, and the development of emotional and behavioural problems in childhood and later life.
John Bowlby's discussions about the fundamental importance of a continuous, warm mother-child relationship to mental health have been particularly influential over the last three decades (Bowlby, 1951; 1969; 1973; 1980).
A large number of empirical studies have attempted to confirm this link.
Despite the volume of research, however, the relationship has remained in doubt.
Some of the studies have demonstrated a clear association, others show no relationship, while the findings of others have been equivocal.
Investigators who have reviewed the research have come to quite opposite conclusions.
Granville-Grossman (1968) examined seventeen studies on parental death, ten of which used a control group, and seven studies on parental deprivation (that is, broken homes due to parental death or separation).
Because, in numerical terms, fewer showed a relationship with depression than those which failed to do so, he concludes that the relationship is probably absent.
Some years later, Crook and Elliot (1980) conducted a similar review and came to similar conclusions, suggesting that social class is a  confounding variable that has led to a spurious association in some studies between loss and depression.
On the other hand, Birtchnell (1970) and Nelson (1982) disagree.
Nelson reviewed sixteen studies on early parental death, severity of depression and attempted suicide and came to the conclusion that a relationship between early loss and severe depression and with attempted suicide has been established.
The studies examined were all controlled ones with samples divided according to severity of depression and controlling for age, social class and sex.
Nelson argues that the failure of other reviewers to come to the same conclusion was because they used vague definitions of depression and failed to take into account the severity of the disorder.
Brown and his colleagues (1986a) have also pointed out that many studies have failed to take into account the current circumstances of their samples.
If, as Brown and Harris (1978) suggested, early loss acts as a vulnerability factor, rather than being of aetiological significance in its own right, then the relationship between loss and depression would be expected to be strongest in the presence of a psychosocial stressor.
Samples with relatively unstressful lives would probably fail to show a higher rate of depression among those with early loss.
A recent study by Brown and his colleagues (1986b) in Walthamstow, North London, was set up specifically to explore the intervening links between childhood parental loss and adult depression.
If their earlier positive results could be replicated, then it was important to study how early loss could increase vulnerability to depression.
There seemed to be at least two possible mechanisms.
The external circumstances surrounding the loss, such as the disruption caused or discordant family relationships leading up to the loss, may be the most important factors, as Rutter (1981) has argued.
Bowlby (1980), on the other hand, gave greatest weight to the disruption of the mother-child bond, which he suggested led to particular ‘cognitive biases’.
These biases, resulting from disordered mourning, might involve compulsive caregiving to others, ambivalence and anxiety in relationships, or a show of independence from close ties.
Of course, both external and internal factors of this kind may be operating.
The external factors, like an unhappy home setting and difficulties associated with living with one parent, could indirectly raise the risk of depression by making unwise choices more likely — early marriage, or dropping out of school, perhaps — and hence leading to higher levels of adverse life events.
The internal factors, leading to cognitive  biases, might result in poorer relationships, less self-esteem, and more helplessness.
These in turn could again both contribute to vulnerability and increase the occurrence of adverse events.
A sample of 225 women was selected from general practice registers to include a large number of women who had lost a parent in childhood.
The interviews covered the psychiatric history of each woman, current psychiatric state, and detailed information about their loss of parent and parenting arrangements which followed.
The importance of loss of mother to rates of adult depression was confirmed.
Depression in the previous twelve months was experienced by three times more women who had experienced maternal loss or separation (of at least one year) in childhood than by women with no such childhood experiences.
Death of father was unrelated to adult depression, although separation from father was associated with a slightly raised risk of depression.
Summarising a complex analysis of a good deal of qualitative data, two factors emerged as of particular importance in linking childhood parental loss and adult depression: the quality of the caring relationship which followed the loss, and teenage relationships with the opposite sex.
An examination of the parenting arrangements following loss of mother showed that indifference and a low level of control had characterised the childhood experiences of a number of the women found to be depressed.
These two aspects — marked or moderate parental indifference (neglect, lack of interest and attention), and low parental control — were combined into an index of ‘lack of care’.
Firstly, lack of care was associated with at least a threefold increase in the risk of depression, whether the women were working-class or middle-class, and whether the loss was by separation or by death.
Secondly, a much higher proportion of working-class women experiencing early loss and premarital pregnancy (PMP) were found to be depressed than women in the same group without PMP.
Among middle-class women, early marriage played a similar role in increasing risk of depression.
Early sexual relationships and lack of care were associated with each other in increasing the risk of depression.
For example, early marriage only raised the risk of depression for middle-class women if lack of care had also been experienced, and lack of care, particularly institutional care, raised the risk of premarital pregnancy occurring.
One other linking factor then became important with respect to PMP, namely, how the young woman dealt with the situation.
Those coping   effectively, who decided to marry the child's father for other reasons besides the pregnancy, or who arranged adoption or termination of pregnancy, were less likely to become depressed.
Many more middle-class than working-class girls fell into this group, which was thought to explain why PMP seemed less important for them.
Those who coped less effectively, and allowed themselves to become trapped into unsatisfactory lifestyles, were found to be more likely to become depressed, perhaps because they had reduced their chances of achieving a dependable, intimate relationship with their husband, or increased their chances of stressful lives.
Finally, there also seemed to be some evidence than an internal bias towards helplessness (similar to Seligman's concept) was implicated at some stage, in making PMP more likely or leading to poor coping responses.
From all these complex intervening circumstances, they conclude that two strands of influence will have an impact on self-esteem and the development of depression following childhood loss (Fig. 4.5).
This model shows one route linking early loss to depression for working-class women through premarital pregnancy, and poor coping, making continued working-class status more likely.
As such they are ultimately subject to a higher rate of vulnerability factors and  provoking agents.
In particular, they will often have an unsatisfactory marital relationship, a factor central to a woman's vulnerability to depression.
The second strand shows the link between the cognitive sets and coping styles which develop from ‘lack of care’ when it occurs following loss of mother.
Thus the alternate routes could be seen either as a personality pathway or an experience pathway, which are probably closely interrelated.
A further study by this research team, in Islington, North London, has confirmed that the importance of maternal loss is explained by the quality of care following loss.
In fact, a lack of care was found to be a vulnerability factor in the absence of maternal loss, while the reverse was not true.
They interviewed nearly 400 women, approximately half of whom had experienced a recent provoking agent.
One third of those with childhood lack of care were depressed, compared to one-sixth of those without lack of care.
Considering loss of mother without controlling for lack of care did not produce a statistically significant difference in their rate of depression (Bifulco, et al., 1987).
This is a particularly interesting finding from the point of view of prevention as it indicates a much larger risk group.
The number of people who as children were separated from their mother, or whose mother died, is likely to be relatively small.
Many more children, however, will be subject to a lack of care in the terms described by these researchers.
(iii) Premarital pregnancy and institutional care
The model showing the significance of loss of mother to adult depression by Brown and his colleagues given above suggests that not only is loss of mother an independent vulnerability factor in the aetiology of depression, but that both premarital pregnancy and institutional care could also be considered as vulnerability factors (see Harris et al., 1987a).
They are considered together here because of their close association with each other— girls experiencing institutional care also show a particularly high rate of premarital pregnancy (Quinton et al., 1984).
Over the last twelve years, Quinton and Rutter and their research team in London have collected a considerable amount of fascinating information in their study of the links between childhood experiences and parenting behaviour (with special reference to children received  into the care of the local authority).
This research is of particular importance for a consideration of prevention because the findings demonstrate a clear link between a very similar notion of childhood lack of care to that of Brown and his colleagues, premarital pregnancy and later emotional vulnerability and psychosocial difficulty, but also show that the chain of adverse experience tends to continue into successive generations.
Lack of care is often repeated: ex-care women in their study were considerably more likely than a comparison group to suffer a breakdown in their own role as parents, resulting in one in five of their children also being admitted into institutional care.
The wealth of qualitative data collected in this research reveals a number of valuable clues for prevention in the life history of children experiencing poor parenting.
For this reason it will be described in some detail.
Eighty girls who had lived in one of two children's homes in 1964, when they had been subjects of a study by Jack Tizard and his colleagues, were traced and interviewed by Quinton and his colleagues, when they were aged between twenty-one and twenty-seven years.
A similar-aged comparison group of women was found who had also participated in a previous study.
Information on childhood history, family, peer and work experiences was obtained, as well as detailed information on current circumstances.
Comparing the two groups of women, twice as many of those reared in an institution had become pregnant and given birth to a surviving child by the follow-up interview.
And two-fifths of the ex-care women had become pregnant before the age of nineteen years, while none of the comparison group had done so.
Marked differences also existed in their relationships with the father of their children: less than two-thirds of the ex-care women but all the comparison women were living with the father of their child.
Serious failures in parenting were also evident in the ex-care sample: one-fifth of their children had been taken into care and as many as one-third of the women had experienced some form of transient or permanent parenting breakdown with at least one of their children.
This occurred with none of the comparison group mothers.
Parenting breakdown meant that the child had been looked after by someone other than its mother for at least six months.
There were also substantial group differences in parenting at the time of the interview.
Parenting was described as ‘poor’ if there was a marked lack of warmth or a low sensitivity to the child's needs and  difficulties in at least two of the three areas of disciplinary control (consistency, effectiveness, style), and as ‘good’if none of these difficulties occurred.
Two-fifths of the ex-care sample had a rating of poor parenting, compared to one in nine of the comparison group.
Observational data confirmed these findings, as do the results of other studies.
For example, in their intensive observations of mothers with their first born 20-week old babies, Wolkind et al.(1977) found that those women who had been separated from either or both of their own parents in the context of a disrupted early family life interacted with their babies considerably less than the rest of the mothers.
The ex-care women studied by Quinton and his colleagues were not only more likely to have parenting problems than other women, however.
They also had a wide range of other social problems.
In particular they had considerably more marital difficulties, and were much more likely to be currently suffering from psychiatric disorder.
These findings were similar to the results of an earlier retrospective study by the same research team of forty-eight families who had a child (aged five to eight years) admitted into residential care (Quinton and Rutter, 1984a; 1984b).
The mothers of children admitted into care expressed less warmth and showed less sensitivity in their parenting, and their child control was less effective, than in a comparison group of families.
They were more likely to be single mothers, have large families and poor housing circumstances (sharing beds, no play space).
Both mothers and fathers of children admitted into care were more likely than a comparison group to have a psychiatric disorder.
The researchers concluded from these two studies that parenting problems were brought about through long-standing problems in social relationships.
Many mothers with parenting difficulties had a long history of emotional problems themselves, and seemed generally lacking in sensitivity to their children's anxieties and needs rather than deficient in specific child management techniques.
Taken together, the two studies suggest a causal role for the experience of poor parenting in childhood in later poor psychosocial functioning.
However, a substantial minority (31 per cent) of the ex-care women studied prospectively showed ‘good’ parenting (Quinton et al., 1984).
A number of factors could be identified which helped to explain the apparent resilience of these women.
Firstly, positive school experiences were found to be important.
They were rated as positive if the subject had two or more of: examination success; a positive assessment  of school work or relationships with peers; or a clearly positive recall of at least three aspects of school life.
Forty-three per cent of ex-care girls without positive experiences, compared to 6 per cent of those with positive experiences, had poor social functioning in adult life.
The relationship also held for parenting.
However, positive school experiences were not related to outcome among the comparison sample.
Secondly, the events which followed the girls' departure from institutional care were important.
Those returning to a discordant family environment were much more likely to become pregnant than those who returned to a harmonious family or remained in the institution until achieving independence.
Ninety-three per cent of the discordant family subgroup had a child (often as a teenager) compared to 51 per cent of those remaining in the institution, and 30 per cent of those going to harmonious families.
The adverse circumstances appeared to be part of a chain of events: girls experiencing early disrupted parenting before being admitted into care were most likely to return from the institution to a discordant home.
They were then at even higher risk for teenage pregnancy and marrying for a negative reason (i.e. to escape stressful circumstances or because an unwanted marriage was forced by pregnancy).
The chain continued, as quality of parenting was also found to be associated with the presence or absence of a supportive marital relationship, and whether or not the spouse also showed psychosocial problems.
Unfortunately, ex-care women were much less likely to experience the protective effect of a non-deviant supportive spouse, firstly because they were more likely than comparison women to marry men with problems, and secondly because they were much more likely to be without any kind of spouse.
A harmonious relationship with a non-deviant spouse was more likely among those who planned their marriage or cohabitation.
‘Planning’ was judged to have taken place if the girl had known the man for at least six months before cohabitation and if she cohabited for positive reasons rather than because of outside pressures such as pregnancy or the need to escape from an unhappy home.
Girls who reported positive experiences at school were much more likely to be ‘planners’.
The discussion which followed their results is very much in line with the ideas of Brown and Harris.
Quinton and his colleagues suggest that girls with positive experiences of school acquire a sense  of their own worth and of their ability to control their own destinies, which in turn helps them to cope and resolve their difficulties and plan their own future.
The comparison group of girls had many other sources of self-esteem, which was why a positive school experience was much less important to them.
Childhood adversities also affect parenting indirectly through their effects on choice of spouse.
If, however, through planning or chance, the women ended up with a supportive non-deviant spouse, they were no more likely to experience parenting problems than the comparison group of women.
The adverse childhood experiences therefore seemed to act in two ways.
They increased the likelihood of a chain of events which put the woman into a position in adult life where she was more likely to experience further social difficulties.
They also acted to decrease the woman's coping skills, making her more likely to become depressed or a less sensitive parent when faced with social difficulties or a lack of marital support.
Quinton and his colleagues point out that there are therefore a number of opportunities to break the chain of adverse circumstances, and suggest several potentially fruitful areas for intervention.
The first occurs at the transition from the institution to independence, when the girls were often in need of help and about to launch themselves on a course in life from which it might be hard to turn back.
Advice and support at this time could aim to minimise the chances of a girl returning to an unhappy discordant home and to parents with whom she may largely have lost touch.
This would remove the incentive to marry as an escape from an intolerable environment.
A second possibility would be to try to help the individual to become a ‘planner’.
Institutional rearing and other adverse childhood experience is liable to produce a feeling that one is in the hands of fate, thus anything to increase the young person's social problem-solving skills and their belief in their own ability to control what happens to them might be helpful.
Children at school need to be able to find a range of opportunities to derive self-esteem other than from academic achievement, and to have social conditions conducive to establishing good peer group relationships.
Sex education needs to be educational in the broadest sense and encourage foresight in all aspects of life, discouraging feelings of hopelessness and inevitability.
Thus they emphasise the need ‘to focus on personal changes that will enhance self-esteem, self-efficacy and confidence, and increase coping skills…and on environmental  changes that will increase  opportunities and make it more likely that later social circumstances will be beneficial’.
Thus both Quinton and Rutter (1983) and Brown and Harris and their colleagues (Harris et al., 1987a) have shown that pregnancies are more common amongst girls with childhood lack of care than in a comparison group.
Both have also documented a high level of family discord in the homes these girls left and to which they sometimes returned.
Both have charted important links between these adverse childhood experiences and adult psychosocial functioning.
Brown and Harris have illustrated the extent of the link with psychiatric disorder.
Of the sixteen women in their survey who were currently working-class and had been in institutional care, ten had premarital pregnancies.
Seven of these ten were clinically depressed at interview.
Two others (of the sixteen) were also depressed, so out of the nine who had been in care and were currently depressed, seven had also had premarital pregnancies.
Premarital pregnancy was therefore almost invariably a link between institutional care and later depression.
In Quinton and Rutter's sample, 42 per cent of ex-care girls had already become pregnant by the age of nineteen years.
Both these studies have emphasised the importance to these women of marrying supportive husbands, which markedly increases their chances of avoiding parenting difficulties and depression.
Both conclude that a supportive marital relationship (and Quinton and Rutter would add ‘past positive experience of schooling’) act as a protective factor when a woman is facing marked social difficulties.
There are close similarities too in the factors suggested by these investigators as leading to good marriages.
Brown and Harris highlight the girl's success in coping with her premarital pregnancy, Quinton and Rutter her planning ability.
Both emphasise the role of feelings of helplessness, of behaving as if one is a victim of fate, as important in the process leading to a range of adult psychosocial difficulties.
There would seem to be ample justification for preventive interventions aimed at reducing feelings of helplessness, if it were possible, and of enhancing feelings of self-esteem for women raised in institutions or for other reasons experiencing a marked lack of care in childhood.
Both of these important studies describe childhood lack of care as the starting point for a life history of misfortune and a high risk of depression.
If the chain is unbroken and poor parenting and  depression results, the same sequence of events may well be replicated in the next generation.
Origins of schizophrenia
Schizophrenia is primarily a thought disorder, whereas depression is dominated by a mood disorder.
It is described as a psychosis, which is characterised by a distortion in the person's perception of reality.
In psychotic disorder, thinking, emotions, attention and communication can be affected, seriously interfering with the person's ability to function in a way which might be considered normal.
Hallucinations and delusions are common features.
Cutting (1985) has collected a number of personal accounts of people's early subjective experiences of the condition.
The following illustrates many of the perceptual disorders which may occur:
There was a tremendous feeling of claustrophobia, of being trapped.
Traffic was too loud.
Too many people on the pavement.
Walls were moving in on me.
I'd panic when the house was getting too small, then I'd go outside.
But outside the noise was too great.
Nowhere, nowhere I could cope.
Not even safe in bed…
All the bright colours frightened me most, orange and red…
I recognised people everywhere…
I had all these thoughts in my head but when I spoke it was just noise, just high-pitched noises came out.
It had lost its meaning.
I could understand other people's language but not my own.
(Remitted schizophrenic, in Cutting, 1985, p. 182)
Schizophrenia is also currently defined as a functional psychosis.
This description assumes that the disorder cannot be attributed to any known specific abnormality of the brain.
As such, schizophrenia can be distinguished from progressive degeneration disorders of the brain like senile dementia, the delirium or dementia which may sometimes follow severe head injury or drug abuse, and the effects of neurological conditions like Huntington's chorea or brain tumours.
Like depression, schizophrenia can take different forms.
One person may function well in most areas of life, but be paranoid and hostile in certain circumstances.
Another may be bizarre in manner and appearance, passive and withdrawn.
Such differences have encouraged the view, which has been held by many psychiatrists since the disorder was first identified, that schizophrenia is in fact a group of related conditions.
These conditions are assumed to have the same final common pathway of biochemical interactions, and lead to a similar series of consequences (Warner, 1985).
Unlike the situation for depression, however, only the barest bones of a model have yet been developed to describe its aetiology.
Research and theory on the origins of schizophrenia have developed simultaneously in a number of very different directions which can broadly be categorised as genetic, organic and psychosocial.
Each decade since the turn of the century has seen influence swing from one camp to the other (see Cutting, 1985).
In the 1940s an interest in genetic studies came to the fore, although several German investigators had already been following this line for some years.
Geneticists produced and analysed statistics, primarily relating to morbidity levels among relatives of individuals suffering from schizophrenia.
Twins were often studied to chart how often both would develop the condition.
By contrast, environmentalists often focused instead on the meanings of the symptoms they observed in their patients, and drew attention to the rearing and experiential difficulties a person may have undergone during their formative and developmental years.
During the 1950s those seeking organic explanations were encouraged by the discovery of similarities between schizophrenia and the effects of hallucinatory drugs like LSD, and by the efficacy of the newly introduced neuroleptic drugs.
A host of aetiological hypotheses has been formed, which have frequently been untestable and based on data that had been unsystematically selected or of dubious validity (Rosenthal, 1968).
The conference in 1968 on the transmission of schizophrenia, reported by Rosenthal and Kety, brought together researchers from each camp, and is probably the time at which all sides came to agree that both genetic and environmental factors must be implicated in some way.
It is now generally agreed that some kind of predisposition to schizophrenia is inherited, but that certain environmental factors will increase the likelihood that the disorder will occur and recur.
Interestingly, much of the psychological research is now being used  to argue for an organic cause.
The information about the difficulties of conveying the intended meaning of language, and about the problems in memory and attention experienced by many people with schizophrenia, has been combined with neuropsychological knowledge to suggest the possibility of a dysfunction of one of the two hemispheres of the brain, probably the right side (Cutting, 1985).
The evidence for genetic, organic and psychosocial factors in the development of schizophrenia is summarised below.
Genetic evidence
A number of studies have now firmly established the existence of a genetic component in the transmission of schizophrenia.
Kestenbaum (1980) quotes the lifetime risk of developing the disorder as between 0.8 per cent and 1 per cent in the general population, which rises to 13 per cent for a child with one schizophrenic parent, and to 3540 per cent for a child with two schizophrenic parents.
The twin studies conducted by Gottesman and Shields (1972) found a concordance rate among identical twins (that is, the frequency with which both twins develop the disorder) of 42 per cent , compared to 9 per cent for fraternal twins and siblings.
Rosenthal's work in Denmark has also been very influential.
He has studied the offspring of women with a history of schizophrenia who have been adopted by non-schizophrenic mothers.
He found that these adopted children still developed schizophrenia more often than a comparison group of adopted children whose biological mothers had no known record of mental illness (Rosenthal, 1968).
This means that the high rate of schizophrenia among close relatives of an affected person cannot be explained away in terms of the effects of living with someone with schizophrenia, and any unusual relationship which might have developed between them.
Rosenthal's own research, and his review of other genetic studies, also leads him to argue that the high probability that identical twins will either both develop or both remain free of schizophrenia is explained by their identical genetic constitution, rather than by a tendency on the part of their friends, relatives and parents to behave towards each of them in a very similar way.
Rosenthal points out, however, that although these studies have established a genetic component, over half the twins (50–60 per cent) with the same genotype as their schizophrenic partners do not develop schizophrenia.
It cannot therefore be described as an  inherited disease.
The feeling is, rather, that a certain genetic vulnerability is inherited which may or may not lead to schizophrenia.
The exact method of genetic transmission is still controversial.
Different investigators have argued for a partial dominant gene, a two-gene theory, a polygenic theory, and a combination of genes of incompatible traits.
A single gene may be responsible in that although the identical twin concordance rate is only 40–50 per cent, there has been some suggestion that the other twin often has some schizoid features of personality which may be the same disease in a much milder form (Emery, 1975).
Other facts, however, such as a much lower than expected rate in more distant relatives, make a single gene theory seem unlikely.
On current evidence, polygenic inheritance is the most likely mechanism (Cutting, 1985).
Among children at high risk of developing schizophrenia, that is, those with a first-degree relative with the illness, there are as yet no reliable means of predicting whether or not they will also develop the disorder.
Research is continuing into possible immunological, biochemical and psychological markers.
Given that the involvement of genetic factors is no longer in dispute, two questions need to be answered.
Firstly, just what is it that is inherited, and secondly, how and which environmental factors cause the disorder to become manifest?
The answer to both these questions remains unresolved, but a good deal of informed speculation has been generated.
Organic causes
A great deal of research evidence points to some kind of organic disorder in schizophrenia, but its causal significance is unclear.
There are essentially three groups of differences between the brains of people with schizophrenia and the brains of non-schizophrenic persons: anatomical, biochemical and functional.
There is also a well-established link between schizophrenia and a number of physical conditions, including epilepsy, Huntington's chorea, virus infection, trauma at birth and head injury in adulthood (Cutting, 1985).
Firstly, there are anatomical reports of ventricular enlargement and cortical atrophy in people with chronic schizophrenia, and of a thickening of the corpus collosum and cerebral atrophy (Cutting, 1985).
The most important evidence relating to such differences has come from CT brain scans (computed tomography), which have shown appearances  suggestive of slight cerebral atrophy in at least a quarter of schizophrenic patients in varying diagnostic subgroups and at varying stages of the disorder.
This particular difference is not, therefore, thought to be confined to one subtype of the illness, or to be a result of treatment procedures (Warner, 1985).
It may, however, be an indicator of some earlier brain injury (perhaps from obstetric complications or viral infection) which served to increase the vulnerability of the person to schizophrenia.
However, it should perhaps be made clear that for most people with schizophrenia, their brains appear completely normal as far as can be made out when looked at under the microscope.
Secondly, biochemical differences in schizophrenia certainly exist, but then they also exist between people who are angry and those who are watching television.
But particular abnormalities in biochemistry have been linked to schizophrenia since it was first discovered that hallucinatory drugs could induce a psychosis.
The most well-known biochemical theory relates to the activity of one of the neurotransmitters, dopamine, at the synapses between nerves.
Since emotion and thought are regulated by a complex system of transmissions between nerve cells, and since acute stress can lead to an increase in dopamine turnover, this could in theory precipitate a psychotic episode.
However, there is so far only scant evidence to support this hypothesis.
Thirdly, there have been a number of studies which have found abnormal levels of arousal and an inability to maintain attention among people with schizophrenia.
Heart rate and skin conductance have been used as measures of arousal, and unusually high levels have been reported (e.g. Venables, 1964).
Responses in experimental tests, such as reacting to one of a range of flashing lights, have been used to study selective attention.
It seems that people with a history of schizophrenia may also have some difficulty in ignoring irrelevant stimuli (such as other distracting flashing lights), and therefore in maintaining concentration.
These two attributes together would mean that a high level of stress would cause the individual to become overwhelmed.
The need of schizophrenic patients to sometimes withdraw would then be explicable as a protective response from further stimulation.
The anatomical differences revealed by CT scans have also been found to correspond to the development of schizophrenia in identical twins.
Enlarged ventricles have been found in an identical twin who  develops schizophrenia, compared to the one who does not.
This has encouraged Cutting (1985) to argue that schizophrenia represents an imbalance of the brain hemispheres, that is, that the right hemisphere is dysfunctional and its contribution to mental life diminished, while the left hemisphere becomes relatively more active and dominates the right.
Certainly, this hypothesis fits the evidence well.
It would explain the abnormalities of emotion and language, because of the specialisation in function of the two hemispheres.
The right hemisphere is more concerned with emotion than the left and therefore its dysfunction would explain many characteristic features of emotion disorder in schizophrenia.
The left hemisphere is responsible for the construction of spoken language, but the right contributes to its intended meaning.
Thus hemisphere imbalance again fits the data well, since the most outstanding disorder of language in schizophrenia is a reduced ability to convey intended meaning, while phonemes and syntax are largely undisturbed.
Cutting's thesis of right hemisphere dysfunction and left hemisphere overactivation can also explain the characteristic disorders of attention, perception and thought.
Hemisphere imbalance may seem to explain schizophrenic symptoms, but like a good deal of the information on the development of schizophrenia, it has not yet been backed up by a convincing aetiological model.
Cutting has only two suggestions for how hemisphere imbalance might arise, neither of which are pursued in his book.
He believes perinatal trauma to be a likely contributing factor, because this in theory could produce damage to the right hemisphere.
He also suggests that right hemisphere dysfunction may be inherited, and perinatal brain damage may increase the likelihood of this becoming clinically apparent in later life.
He argues that the imbalance acts to increase the person's risk of schizophrenia by making him or her more susceptible to social influences (Cutting, 1985, p. 391).
But just how genetic, organic and social factors interact is not at all clear.
Psychological causes
Many psychological theories have grown out of the observations of the often abnormal communication styles of families of schizophrenic patients.
The factors argued to have causal significance have included: the family's effect on the child's ability to maintain attention; linguistic disturbances of parents; decision-making processes; and overprotection.
The conference in 1968 reported by Rosenthal and Kety concluded that none of these factors had yet been convincingly established as having a causal role.
The situation has not much changed.
In 1975 Hirsch and Leff produced a scholarly review of the literature on abnormalities in family interactions.
They drew on studies of individual cases, questionnaire surveys, studies of the interactions of parents of people with schizophrenia in small group situations, data from tests of abnormal thought processes of parents, and of abnormalities of their communication and language.
From these they summarised what they judged to have been established.
Firstly, they found from eight of the better designed studies that ‘mothers of schizophrenics are more concerned, protective, and possibly more intrusive than control mothers both in the current situation and in their attitudes to the children before they showed signs of schizophrenia’.
They noted, however, that it was possible that excessive protectiveness could result from having an abnormal child rather than the reverse.
Apart from possible personality abnormalities, there is evidence that individuals who later develop schizophrenia more frequently suffered ill-health or mild disability in early childhood than other children.
Secondly, they found a large number of studies which showed that parents of people with schizophrenia have greater marital disharmony than controls.
Disharmony is indicated by open or tacit conflict, expressed hostility, opposition of spontaneously expressed attitudes, and difficulty in reaching agreement.
Thirdly, several of the studies focusing on mothers of people with schizophrenia showed them to be more likely to be psychiatrically disturbed, and in particular, more schizoid than mothers of normal children.
Once again, this association might be explained as the consequence of bringing up a child vulnerable to schizophrenia.
Finally, studies investigating the communication styles of parents were found to produce conflicting results.
However, one of the more sophisticated studies seemed to indicate that parents of people with schizophrenia can be reliably differentiated from the parents neurotics or normals.
This work, by Singer and Wynne (1966), demonstrated communication abnormalities characterised by disruptions, vagueness, irrelevance and lack of closure (such as answering with a question or giving contradictory information).
These communication styles can be expected to induce difficulties in the listener's ability to focus attention and handle the meaning of what is being said.
They describe some typical conversations in which comments from  one person did not link in an expected way to preceding comments — where there seemed to be a very loose connection between what one person said and the next.
The effects were believed to have enduring consequences on the child's thought processes and predispose to (rather than precipitate) schizophrenia.
However, Hirsch and Leff's attempt to replicate this study, also reported in their book (1975), failed to find the same degree of gross communication disorder as that claimed by Singer and Wynne.
They did, however, find a higher rate of deviance in communication style, particularly among fathers, which was largely accounted for by overtalkativeness.
Although some bizarre interchanges therefore seem to be real occurrences in these families, the research has so far been unable to convincingly demonstrate a causal link between such communication abnormalities and the development of schizophrenia in the child.
Prospective studies throw more light on the antecedent factors but only one study has followed up high-risk young people for a sufficient number of years to provide any helpful analyses.
In 1962 Mednick and Schulsinger in Copenhagen examined 207 high-risk children, born between 1941 and 1954, whose mothers had chronic severe schizophrenia.
They also studied a comparison group of 104 subjects (a low-risk group, children of normal mothers).
By 1967, twenty of the sample had experienced one of a variety of psychiatric disturbances ranging from schizophrenia, to extreme schizoid states, to antisocial behaviour.
Mednick and his colleagues (1981a) describe four characteristics of the sick group which they considered to be distinguishing features:
(1) They experienced considerably more early separation from parents, primarily through psychiatric hospitalisation of the mother.
(2) Teachers reported disturbing, aggressive behaviour at school.
(3) They showed a more rapid rate of recovery from momentary states of autonomic imbalance (measured by galvanic skin response, GSR).
(4) Seventy per cent of the sick group had suffered from the effects of serious pregnancy and/or birth complications as babies.
Of interest too was the finding that high-risk subjects who did not  experience a breakdown had fewer perinatal problems than the low-risk subjects.
This suggested to the investigators that there may be a special interaction between genetic predisposition for schizophrenia, and pregnancy and delivery complications (Mednick et al., 1981a).
Perhaps the high-risk individual needed a trouble-free birth in order to stand a good chance of avoiding schizophrenia.
A further follow-up in 1972 collected more detailed diagnostic information.
By this time ten of the 207 high-risk subjects had died, seven by suicide, two by accidental causes and one by a natural cause.
None of the low-risk subjects had died.
Thirteen of the high-risk subjects were diagnosed as schizophrenic.
The investigators reported from a previous publication in which they had compared these thirteen subjects with twenty-nine borderline schizophrenics, thirty-four neurotics and twenty-three high-risk subjects with no mental illness.
This enabled them once again to draw up a profile of those high-risk subjects who developed schizophrenia, which turned out to be similar to that reported at an earlier stage of the research.
The thirteen children who developed schizophrenia could be characterised by the following factors: their birth had been relatively difficult (longer and more complicated than average); most of them had been separated from both parents and many placed in children's homes at a young age; they posed a disciplinary problem to their teachers; and some years earlier they had had a rapid autonomic nervous system (ANS) recovery rate.
Furthermore, the high-risk children who developed the disorder could be distinguished from high-risk children who had so far shown no signs of developing the condition by the seriousness of the schizophrenic illness suffered by their mothers (as judged by the age at which their symptoms had begun).
However, there seemed to be important sex differences in the way these early factors related to the development of schizophrenia.
The age at which the mother's illness had begun was the only factor directly related to the presence of schizophrenia in women.
In men this factor was only related because of its association with separation.
Separation, perinatal complications and ANS recovery responsiveness related to the development of schizophrenia in boys (Mednick et al., 1981a).
Behavioural precursors of schizophrenia included a poor emotional rapport in the psychiatric interview, and parental observations that he or she had been a passive baby, with a short attention span in childhood, and often impolite behaviour, while  school reports often noted that the child was isolated, uneasy about criticism, easily upset, and disturbed the class (Parnas et al., 1982).
Finally, evidence is accumulating that a person's emotional environment influences his or her likelihood of suffering an acute psychotic episode if he or she already has a history of schizophrenic disorder.
If the person lives with a family member with whom he has an intense relationship, characterised by a high level of criticism and overinvolvement, his risk of relapse is much higher than it would be in a less intense atmosphere (Brown et al., 1972; Leff and Vaughn, 1981).
Not surprisingly, this finding has led to further speculation about the role of hostile, critical and overprotective parenting in the first onset of schizophrenia.
However, despite some thought-provoking case studies collected by Leff and Vaughn (1985) which illustrate the sorts of unusual parent-child relationships which they have found, there is little good research to inform the debate.
The findings of Doane et al.(1981) from their five-year follow-up of sixty-five disturbed (and therefore considered high-risk) adolescents provide some tentative indication that such abnormal parenting may have some causal significance, but the evidence is not that strong.
They assessed both communication deviance and affective style at the first interview with families, that is, aspects such as disruptive speech, closure problems, unclear communication of ideas, and statements that were supportive, critical, guilt-inducing or intrusive.
They found that the two measures did not separately hold any predictive value, but in combination they discriminated well between families in which a child developed some schizophrenic symptoms and those whose child remained free of such symptoms.
As these young people were already disturbed these factors cannot be claimed to have predated disturbed behaviour, but they did exist prior to the appearance of psychotic-like disorders.
The investigators suggested that the combination of communication deviance and critical, intrusive or guilt-inducing affect from parents meant that their adolescent child had ‘little recourse through communication with them for exploring, clarifying, or correcting his feelings of unworthiness, rejection, or isolation’.
These ideas are in some ways similar to one of the psychoanalytical theories of schizophrenia, popular in the 1960s, Bateson's ‘doublebind’ hypothesis.
This also states that the individuals concerned must be in an intense relationship and that it is impossible or very difficult for the victim to ‘escape from the field’.
The bind arises when the  speaker expresses two or more messages which are incompatible, at different levels of communication.
For example, the subject's mother may be verbally expressing affection while her facial expression and movements convey contempt or a lack of concern.
The individual is  prevented from commenting on the inconsistencies in that if he attempts to do so, he is met by condemnation that increases the confusing bind (Bateson et al., 1956).
A wide range of organic and psychosocial differences between people who suffer from schizophrenia and a random sample of the general population have been identified.
Yet the great mystery of schizophrenia remains — it is still unclear precisely what role, if any, such factors have had in bringing about the first onset of the disorder.
Many of the differences identified predate the emergence of any specific schizophrenic symptoms.
But this does not mean they caused them to appear.
For instance, a child may inherit a predisposition to schizophrenia, which causes him to have certain childhood adjustment problems, which in turn bring about unusual family communication styles.
This means that family and school problems may be common antecedents of schizophrenia, but have no causal role in bringing it about.
Alternatively, it may only be when family relationships are poor that the inherited predisposition is likely to lead to schizophrenia.
Do obstetric complications leave an invisible injury which later manifests itself in combination with a certain inherited characteristic as a particular vulnerability to schizophrenia?
Or does a difficult birth seem to be associated with schizophrenia because it causes the mother to feel overprotective or guilty towards the child who started life so badly?
In which case, it would be the mother's behaviour, rather than any brain damage, which had causal significance.
These are just some of the many possible answers to this fascinating riddle.
Psychosocial factors in the course of schizophrenic disorder
The evidence on social factors related to the course of schizophrenic disorder is still the most valuable information available for prevention.
Once the disorder has developed, the impact of environmental circumstances on its course and outcome is relatively easily established: the difficult issue of reconstructing family relationships and other environmental circumstances as they existed before the appearance of symptoms is unnecessary.
All that is needed is a reliable  assessment of current circumstances.
Two sets of findings in particular suggest preventive strategies that could considerably reduce the prevalence of acute psychotic episodes.
Both relate to the social environment of the person with an established schizophrenic illness: while he is being treated for the disorder in hospital, and after he has been discharged into the community.
A study by Wing and Brown (1970) suggested that people with schizophrenia were likely to respond to understimulation by withdrawal and regression.
Their controlled study showed that the social withdrawal and poverty of speech of chronic patients varied from one hospital to another according to the severity of ward restrictiveness, absence of personal belongings, and the length of time that patients were left to do nothing.
On the other hand, overstimulation, especially in emotionally arousing circumstances, was likely to result in an acute exacerbation of symptoms.
The latter finding arose from an observation by Brown and his colleagues (1966) that patients discharged to live alone or in a hostel often fared rather better than those who went to live with a spouse or parent.
They went on to develop a method of rating family relationships from interviews in the relatives' home (the Camberwell Family Interview, Brown and Rutter, 1966).
Interviews were tape-recorded so that a trained rater could play back the tape and rate the relatives on: critical comments, hostility, overinvolvement, warmth and positive remarks.
The rater took account of the tone of voice as well as what was being said.
Critical comments, hostility and overinvolvement, generally termed ‘expressed emotion’(EE), on the part of the relative most closely associated with the patient have been shown to be related to risk of relapse (Brown et al., 1972; Vaughn and Leff, 1976).
Maintenance medication and a reduction of time spent in face-to-face contact with a high ‘EE’ relative was shown by these studies to reduce the risk associated with living in a high ‘EE’home.
This meant that there were essentially three variables which could affect risk of relapse: level of EE, level of contact, and maintenance medication.
Brown and his colleagues (1972) studied 101 patients, Vaughn and Leff (1976), 128.
Of those returning to a high EE home, 58 per cent and 51 per cent of these two samples relapsed within nine months.
This compared to 16 per cent and 13 per cent of those going to live with low EE relatives.
However, where the level of contact with the high EE relative was greater than thirty-five hours per week, risk of relapse rose to 79 per cent and 67 per cent of the  samples.
If patients lived with a low EE relative, the major tranquillising drugs produced a relatively small reduction in relapse rate.
But for patients in high EE homes, the continued use of these drugs reduced the relapse rate over a nine-month period among Brown and his colleagues' sample by one third (66 per cent to 46 per cent), and in Vaughn and Leff's sample, by about one half.
As each of the three variables seemed to be related to risk of relapse, it followed that those living in high contact with high EE relatives and failing to maintain prophylactic medication should be at greatest risk of relapse, while those living with low EE relatives and continuing to take their medication should have the lowest risk.
Vaughn and Leff (1976) found the relapse rate to be 92 per cent compared to 12 per cent for patients falling into these two extreme groups over the same nine month period.
Furthermore, intervention programmes aiming to reduce the level of expressed emotion among relatives high on this index, or alternatively to reduce their level of face-to-face contact, have shown that relapse rates can be reduced in this way (e.g. Leff et al., 1982; 1985; Falloon et al., 1982; and see chapter 9).
These findings add considerable weight to the claims that emotional arousal is of causal significance to relapse.
Taken together, these studies provide numerous practical indications for the management of schizophrenia.
Brown and Birley (1968) argued that people who have a history of schizophrenia have a high sensitivity to their social environment even when they have no apparent symptoms.
This idea of an optimum arousal level which may easily be upset by under- or overstimulating conditions has also been put forward by Venables (1964).
This means that people who have suffered or are currently suffering from schizophrenia need to be able to withdraw from arousing circumstances, but that the extreme understimulation which could sometimes be found in an old-fashioned mental hospital should equally be avoided.
Patients in understimulating environments also show a high level of arousal.
This information is potentially very valuable for those in a position to help families to find the best ways of supporting the patient at home in the process of rehabilitation.
They could be taught, for instance, that the patient may sometimes need to withdraw from social contact with his or her family.
This might help them to see his lack of social responsiveness as a symptom of his illness and something for which they should make allowances rather than as an  unfriendly act or a personal slight on their company.
However, this kind of educational process needs to be carried out with extreme care.
Information which places guilt for the patient's illness on the family might only serve to reinforce their overprotective and critical communication styles, which may have arisen in the first place for just this reason.
Indeed, the widespread public belief in the role parents may have in causing adjustment problems in their children, and the guilt, shame and stigma associated with such views, may become circular.
Warner (1985) points out that living with someone whose actions can be unpredictable and distressing, and whose emotional responses are unrewarding, is difficult enough.
But with the reactions of society to the disturbed person and to his relatives, these problems may be sufficient in themselves to produce distorted patterns of family interaction.
Birley and Hudson (1983) and Berkowitz and her colleagues (1984) have given sensitive descriptions of the ways in which the family might best be helped.
Not surprisingly, given the sensitivity to arousal, life events have also been found to play a role in bringing about an acute relapse.
Brown and Birley (1968) found 46 per cent of their sample of schizophrenic patients to have experienced an independent life event (one unlikely to have been a consequence of the previous illness) in the three weeks before onset, compared to 14 per cent of a comparison group of factory and office workers in the three weeks prior to their interview.
Paykel (1979) also reported an excess of life events in the six months before a patient's first admission for schizophrenia compared to a general population sample in New Haven.
Unlike the situation for depression, however, the events implicated in schizophrenia will not necessarily be those which appear threatening or unfavourable.
Exciting or arousing events like being promoted or winning a competition may have a similar effect (Brown and Birley, 1968).
However, while it might seem that in high EE homes, people with schizophrenia would be particularly vulnerable to relapse after a life event, Leff and Vaughn (1980) failed to find an excess of events in the weeks preceding relapse for patients in high EE homes.
In fact, nine of the ten patients experiencing a life event in the latter study were in low EE homes.
They conclude that the onset or relapse of schizophrenia is associated either with high EE or with an independent life event.
Both Brown and Birley (1968) and Leff and Vaughn (1980) found that life events tend to be concentrated in the three weeks before the onset of schizophrenic symptoms.
It is uncertain whether neuroleptic medication is protective against the effects of life events, although it is well accepted to be protective against high emotional arousal.
However, it may be helpful to adjust the dose at the critical time.
It may also be feasible to prepare patient and relatives for predictable events or even to avoid such situations altogether (Brown et al., 1972).
A model of schizophrenia
The most well-recognised factor in the aetiology of schizophrenia is that a genetic vulnerability is inherited.
Trauma at birth may also play some part in forming the newborn infant's predisposition to develop the disorder.
One possible explanation of the condition is a dysfunction of the right hemisphere of the brain and an overcompensation by the left side.
The person will have a high level of emotional arousal and be particularly sensitive to social influences which can affect arousal.
Relapse of florid symptoms and possibly their first onset can be precipitated by stressful events.
Relapse in the absence of a precipitating event is most likely to occur when the patient is living in a situation characterised by high expressed emotion between himself and a relative with whom he has a high degree of contact.
Neuroleptic medication provides some kind of protective effect against relapse.
Reducing the amount of time a patient spends in face-to-face contact with relatives with whom he lives in a ‘high EE’ environment, or changing their communication styles, will also be protective.
The association of factors such as psychiatric illness of parent, marital disharmony, overprotectiveness and abnormal thinking and communication may or may not be relevant to onset or relapse, or may simply be another result of the same genetic constitution which produced a child vulnerable to schizophrenia.
Equally probable is that the pre-schizophrenic child and the schizophrenic adult produced some of the abnormalities of the parents.
It is clear that, as with depression, a complex interactive multifactorial model is needed to explain the cause and course of schizophrenia.
As with depression, a range of factors may contribute to a person's vulnerability to the disorder, and other factors may act to precipitate its appearance.
A range of social and environmental circumstances of the individual will determine the subsequent course and outcome of the illness.
Strauss and Carpenter (1981) conceptualised the development of schizophrenia as essentially having four  levels.
The first stage is the prenatal and perinatal period when a person's genetic constitution is determined, birth trauma may occur, and the early mother-child bond established.
What happens at this stage will determine the infant's predisposition to schizophrenia.
The developmental stage follows, when maladaptive learning and abnormal family communication patterns may each perhaps contribute to the young person's vulnerability to schizophrenia.
A number of factors may then precipitate a psychotic episode, including emotionally arousing events and a stressful environment.
Finally, the course and outcome of the disorder will be affected by the same kinds of events and environment, and by certain treatment and rehabilitation measures.
These not only include the now standard pharmacological treatments, but also the patterns of institutional care, and, Warner (1985) would argue, the broader social environment as it affects reintegration and the social role rehabilitation of the individual (including the labelling, stigma and social isolation which may occur).
Hirsch and Leff (1975) have also put together several possible models of schizophrenia.
These might be combined with the formulation above and adapted as shown in Figure 5.1.
This model is complex, but is just the first step in explaining the development of schizophrenia.
Little progress has been made in terms of developing a theory of the disorder which would provide greater understanding of how and why these factors relate to each other.
The theories which have been advanced so far have not been adequately tested in empirical research so as to gain credibility.
Nevertheless, the model does show that a good deal is now known about the illness, and this information provides both promising avenues for future research and implications for preventive intervention.
The search for physiological, psychological, social, biochemical or other markers which will facilitate the identification of high-risk children with some accuracy needs to continue.
Possible research approaches include following up infants experiencing some perinatal trauma who also have a close biological relative with schizophrenia in the hopes of identifying other indicators of risk.
Several longitudinal studies of this nature are already under way(e.g. Wrede et al., 1981).
Until further progress has been made to facilitate the identification of people at risk of schizophrenia, there is not a firm basis for large-scale intervention programmes.
However, even at this stage, much might be learned from some experimental intervention trials, both    about aetiology and prevention.
Perhaps, for instance, educational programmes for parents of disabled or ill children might be evaluated to see if reducing any over-involved or overcritical parenting styles reduces the child's later risk of schizophrenia.
Families where there is both a record of schizophrenia and where the index child was born after a particularly long or difficult labour would be particularly suitable targets.
In terms of preventing relapse among people with an established schizophrenic illness, a concern for the social environment to which they return needs to become as much a part of standard procedures as is the administration of maintenance medication.
The relatives of schizophrenic patients should routinely be involved in treatment programmes (Leff, 1985).
Where the home environment seems to be unsupportive in as much as it is highly arousing, strategies to increase the social distance in key relationships, or to modify their ways of interacting, would be helpful.
Daytime employment, sheltered work, or a place at a day centre or day hospital may be one answer, or removal to a hostel or group home.
Adherence to the maintenance drugs regime will nearly always be helpful to people treated for schizophrenia in the process of rehabilitation, but is likely to be especially important for those remaining in living circumstances that are far from ideal.
Monitoring and encouraging drug maintenance is largely an administrative task which requires flexible hospital and clinic opening times, a local register of patients needing regular treatment, and for social and clinical services to maintain a constant link to ensure continuous monitoring (Freeman, 1978).
Finally, for those people with a family member with schizophrenia whose distress and disturbed behaviour may dramatically affect them, there must also be preventive implications for themselves in their involvement in the treatment programme.
Marjorie Wallace (1985) has collected accounts from seventy-five families of schizophrenic sufferers from all over the country, who paint a harrowing tale of fear, loss and powerlessness as they watch a member of their family gradually disintegrate.
Often a son or daughter will have been on the brink of a promising career when they developed their first symptoms.
One-third of sufferers will never experience a second episode, but for the rest it may be a lifetime's struggle against repeated attacks, each one taking its toll.
It seems likely that for a parent or spouse, the experience may well be comparable to the sorts of events and difficulties implicated in depression.
For their own sakes, as well as the patient's, they need information about the condition.
They need to understand the importance of the regular drug treatment, and they need to be supported in their efforts to deal with their own guilt, depression and daily stress of living with a person with schizophrenia.
They can be helped to relate to the disturbed individual in the most supportive manner (Leff et al., 1982), and to help him develop positive skills (Falloon et al., 1982).
But they also need to have their own anxieties answered (for example, about side-effects of the drugs), and, in dealing with a severe and recurring disorder, they need periodic relief from their caring responsibility, advice on financial supplements available and a knowledge of good ways of coping with difficult behaviour on the part of their disturbed relative.
Prevention in childhood
It has long been assumed that the origins of many adult disorders lie somewhere in childhood or earlier events.
Whether a biological or psychosocial perspective has been taken, events of aetiological significance have been sought in the individual's formative stages, from fertilisation and intrauterine development, to parent-child relationships in early and middle childhood.
However, the preceding chapters have shown just how many possible mediating processes may explain the apparent link between childhood risk factors and adult disorder.
Any factor found to occur more often than would be expected by chance in the childhood histories of adult psychiatric cases could be linked to disorder in at least three ways.
Firstly, the antecedent factor may be a direct cause of childhood psychiatric disturbance which has a continuous of intermittent course into adulthood.
The same kinds of symptom may be present throughout, or the disorder may manifest itself in different forms at different life stages, perhaps as conduct disorder or delinquency in childhood, but in adulthood as alcoholism or even schizophrenia.
Secondly, there may be a continuity of psychiatric problems only if the risk factor also persists.
Perhaps a lack of supportive parent-child relationship is associated with childhood problems, but only if the person continues to lack a close supportive relationship in later life will psychiatric problems continue or recur.
Thirdly, the factor may not result in any significant childhood disturbance, but may produce disorder in later life as other risk factors accumulate.
For instance, maternal psychiatric disorder may have a deleterious effect on the mother-child relationship not serious enough to produce a disorder in the child, but may also set in motion a chain of other, more powerful adverse events.
The child may be separated from his mother while she receives treatment, her marriage may collapse and the  family break up, and subsequent living circumstances may be stressful and socially deprived.
Any one, or a combination of all these events may turn out to have key importance in the later development of disorder.
There are, undoubtedly, some aetiological links between early life experiences, events in later childhood and adolescence, and circumstances in adult life.
In recent decades, considerable progress has been made in identifying personal and social factors which can be damaging or protective, and some of the complex interrelationships between events and circumstances that contribute to psychiatric risk (Rutter, 1985).
Although our understanding is far from complete, there are many valuable pointers to the elements likely to be necessary in effective prevention.
In this chapter, some of the evidence will be reviewed which sheds some light on three questions.
What do we know about the determinants of childhood disorder?
Under what circumstances does childhood disorder continue into adulthood?
And what do we know about childhood determinants of adult disorder which might be amenable to preventive intervention?
The following does not attempt to be a comprehensive review of the aetiology of childhood disorder, but to reveal some of the important factors which will have to be considered in conceptualising prevention through intervention with children.
Determinants of childhood disorder
Emotional and conduct disorders are the most frequently encountered psychiatric disturbances of childhood.
And as Wolff (1983a, p. 37) points out, ‘despite important constitutional, social and medical disadvantages which often contribute to their genesis, the disorders themselves are most helpfully explained on the basis of psychological mechanisms.’
Children with conduct disorder behave in a way seen as troublesome to others and do not conform to expected social norms.
They may fight with other children, be difficult for their parents and teachers to control, or steal.
Their disobedience may include running away from home, disruptive classroom behaviour at school, precocious indulgence in alcohol or addictive substances, and sexual promiscuity (Shaffer, 1983, p. 9).
Three out of four will be male, and one in three doing poorly in their schoolwork.
Their parents will often have marital problems (Rutter et al., 1970).
Children with  emotional problems may, for instance, be excessively afraid of strangers or of separating from their parents.
They may be unduly withdrawn or subdued.
They are equally likely to be male or female and there is no characteristic family disturbance (Rutter et al., 1970).
Children and adolescents may often have a combination of conduct and emotional problems.
There are other, less common disturbances in childhood and adolescence, including childhood psychosis, the hyperkinetic syndrome and anorexia nervosa.
Of course, shyness, fears, depression of mood, disobedience, fighting, stealing and temper tantrums are often part of ordinary day-to-day behaviour.
It is only when the frequency and magnitude of each behaviour is sufficiently marked and sufficiently prolonged to impede the child himself in his daily life or cause distress to his family or community that it can be defined as disorder (Rutter et al., 1970).
In looking for causal explanations of disorder, Wolff (1983a) argues that both scientific and subjective explanations are needed.
This is because in children, even more than in adults, pathological behaviour is the outcome of an interactional process.
Age is the most obvious factor that will change the subjective interpretation of events.
Young children will often, for instance, feel a sense of responsibility for adverse events in which they in fact had no role at all , and hence experience a good deal of anxiety.
Children may also react to deprivation or lack of attention by showing difficult or aggressive behaviour.
If interpreted by the parent as hostile and rejecting behaviour, and responded to in turn by punishment and rejection, a mutually reinforcing pattern of hostile interaction may begin.
A large number of factors have been identified as contributing to the development of childhood psychiatric disorder in some way.
(i) Age
The child's developing cognitive capacities mean that events which at one age produce little or no anxiety may, at another, be extremely distressing.
Mother-child separation at four months of age may not be too disturbing, as the child will not yet have formed a lasting selective attachment to her.
The reasons for a separation and its temporary nature can be explained to a ten-year-old child, so that anxiety can again be minimised.
But at age two or three years, a  threat of loss is understood, but the reasons for the separation and its temporary nature may not be.
From three years onwards, children can experience a fear of injury, and illness and accidents may generate excessive anxiety (Wolff, 1983a).
Fears, phobias and nightmares are also at their height at ages three to five.
At around six years of age, the child enters a wider social group and can perceive stigma, and experience a loss of self-esteem (Wolff, 1983a).
He may then become fully aware of any physical, social or educational disadvantages he possesses.
(ii) Sex
Boys are constitutionally more predisposed to the development of aggressive behaviour than are girls (Wolff, 1983a).
There may also be some sex-linked predisposition to developmental disorders such as enuresis, encopresis and retarded reading as these tend to occur more often in boys than girls.
Boys also seem to suffer more than girls when family discord and family disruption occur.
There are several possible interactive processes to explain these findings.
There has been some suggestion that parents are more likely to argue in front of their sons than their daughters; that a disturbed parent is more likely to pick on a son than a daughter; and that mothers may transfer negative experiences with their husband into negative expectations of their sons.
Furthermore children tend to identify with the parent of the same sex.
Fathers are more often aggressive and also are more often absent from the home.
If the mother denigrates her husband, it is more likely that a boy will become particularly anxious (Wolff, 1983b).
(iii) Temperament
A longitudinal study by Thomas and Chess (1977) of 141 children from predominantly middle-class homes in New York showed a marked continuity of temperamental disposition.
The mothers had been interviewed periodically since the children were two or three months old about such characteristics as the child's activity level, adaptability, distractability, persistence and quality of mood.
Active children tended to have been active, difficult babies, and passive children withdrawn babies, low in persistence.
Such characteristics inevitably help to shape parent reactions, which in turn affect the  child's adjustment.
For instance, it has been noted that when ‘parents are depressed and irritable they do not take it out on all their children to the same extent: often one is more or less scapegoated.
The target child tends to be the temperamentally difficult one’(Rutter, 1979a, p. 57).
(iv) Brain damage
Rutter (1977) has shown that brain-damaged children are at greater risk of psychiatric disorder than undamaged children, possibly due more to abnormal brain activity rather than to a straightforward loss of brain function.
The crucial cognitive effects of damage are due to both general intellectual impairment and specific reading retardation.
However, some of the increased risk will be caused indirectly through the stigma associated with scholastic failure, the increased likelihood of difficult temperamental characteristics, and scapegoating or overprotection on the part of his or her parents.
If the condition requires frequent hospital admissions and a restriction of physical activity, further adverse effects may occur.
(v) Low intelligence, educational retardation
The surveys by Rutter and his colleagues in the Isle of Wight revealed a high correlation between psychiatric disturbance and intellectual retardation (Rutter et al., 1970).
Retarded children were over three times as likely to be disturbed as children in the comparison group (23 per cent versus 7 per cent).
Furthermore, one-third of severely retarded readers had conduct disorders.
The high level of social maladjustment among children attending schools for the moderately educationally retarded has also been well documented.
Newton and Robinson (1982) found half of the sixteen-year-olds in four inner London ESN(M) schools to be maladjusted, as rated by the Bristol Social Adjustment Scales, while in South Wales, Chazan (1964) reported a similar proportion: 50 per cent of the boys, 32 per cent of the girls.
(vi) Schooling
The Isle of Wight and London surveys (Rutter et al.1975a; 1975b) found markedly differing rates of behaviour problems and reading difficulties between one primary school and another.
The children  were followed up some four years later at secondary schools so that the possibility could be considered that such differences were attributable to initial differences in their ability and adjustment rather than being caused by the schools (Rutter et al., 1979).
Differences between schools remained, and were not explicable in terms of differences in intake, family characteristics or primary school attended.
It was concluded that good schools can, and do, exert an important protective effect against behavioural disturbance.
The quality of the schools as social institutions appeared to be more important than their size, administration, or the age of the buildings.
A ‘good’ school had a balanced intake of ability levels, widespread opportunity for pupil participation and individual responsibility, good classroom management and discipline, often an academic emphasis, and a wide use of rewards and incentives.
A preponderance of low-ability children, or of disadvantaged or ethnic minority children, was associated with raised delinquency rates.
As described in chapter 4, Quinton and Rutter (1983) found that positive school experiences appeared to help foster planning skills in girls brought up in care.
In late adolescence and young adulthood, planning skills were in turn related to social functioning and parenting behaviour.
A positive experience of school was not only a reflection of examination success, but may also have resulted from good relationships with peers or a positive memory of several other aspects of school life.
It seemed that for girls lacking a source of selfesteem in their home lives, schools could be particularly important in this respect.
(vii) Parental mental illness, marital discord, family break-up
These three factors must be considered together because it seems that both parental mental illness and parental separation or divorce may have a particularly damaging effect on the children if they are associated with prolonged overt marital discord, especially where the child becomes directly involved.
Rutter (1979a) quotes research evidence to show that both maternal psychiatric disorder and paternal criminality are associated with disturbed behaviour in the children.
Sons of aggressive, sociopathic fathers are particularly prone to conduct disorder (Robins, 1966).
High rates of depression among mothers of young children and a strong association between maternal depression and disturbance in the children have been found by  Richman (1978) and Crook and Wolkind (1983).
Similarly, Pound and her colleagues (1985) found that a long history of depressive illness in a mother, or a combination of depression and personality problems, was associated with problems (especially of sleeping) in her children.
A catalogue of past and present social difficulties was associated with the mothers' depression.
They argue, however, that marital discord (common among the depressed sample) added to, rather than was responsible for, the effects of maternal depression on the child.
A constellation of social difficulties has also been found to characterise parents who severely physically abuse their children.
Baldwin (1977) traced all child victims of severe abuse (damage on the scale of multiple fractures, internal injuries, brain damage and death) who were under the age of five years and living in North East Wiltshire over an eight-year period.
Fathers or father surrogates were often unemployed, families moved home frequently, father figures changed or left the family home often, mothers were very young (average age twenty-one years) but already had an average of three children.
The parent figures as a group showed gross excesses of psychiatric disturbance, physical illness and disability, and criminality, and the abusing parent had often been subjected to physical or mental abuse or neglect in their own childhood.
Severe abuse was viewed by Baldwin as an outcome of overwhelming stress in families profoundly disabled by illness, personality disorder, inadequacy or incompetence.
Similarly, Delozier (1982) has described the histories of eighteen ‘typical’ abusing mothers, which show that their childhood contained much more by way of threat of abandonment and harm than that of a comparison group of mothers.
Parental divorce has often been assumed to have deleterious effects on children.
However, it is more likely that the marital conflict which precedes the separation and the stressful events which follow it are the real sources of difficulty.
Hetherington (1979) found that if marital separation led to a cessation of hostilities and conflict, this seemed somewhat less damaging for children than remaining in a discordant, unhappy, but intact home.
Hetherington (1979) charts the common problems which accompany divorce.
For instance, mothers often experience downward economic mobility as income from the father drops, sometimes requiring moving to more modest housing, which in turn may involve loss of friends, neighbours and a familiar educational system.
Mothers caring for their children on their own may need to find outside employment, and the strain of the dual role may result in a chaotic lifestyle where the children get less attention, household chores remain undone and mealtimes and bedtimes become erratic.
In the first twelve months marital conflict present before the divorce often increases, and parents become inconsistent, less affectionate, and lacking in control over their children.
Following this period, parenting usually improves again, and most children readjust.
Vital to this readjustment, however, is a continued supportive relationship with the parent with whom the children live, and the involvement of the spouse in supporting the children and the divorced partner in their parenting role (Hetherington, 1979).
In the long term, the quality of life which the divorced or remarried family make for themselves becomes the most important factor in determining whether any disturbed behaviour persists (Wallerstein, 1984).
In a stressful home environment, whether the difficulties are due to parental mental illness or family discord, it seems that a good relationship with one parent (or both parents), characterised by a high level of warmth and the absence of severe criticism, is protective.
Only a quarter of children with a good relationship and living in a discordant home showed a conduct disorder in a study reported by Rutter (1979a), compared to three-quarters of those lacking such a relationship.
Furthermore, a longitudinal study which charted the progress of children in discordant homes, also reported by Rutter, documented the marked reduction in psychiatric risk which followed a substantial improvement in the home environment, when compared to the progress of children remaining in unhappy, quarrelsome homes.
(viii) Mother-child separation
The influential work of John Bowlby has led many people to believe that any kind of mother-child separation during the first few years of a child's life should be avoided.
He showed that many young children separated from their mothers for admissions to hospital or a residential nursery experienced an acute stress reaction followed by disturbing behaviour lasting many months.
Bowlby argued that this was a direct consequence of the damaging effect of the separation on the emotional bond between mother and child (Bowlby, 1951; 1973).
Rutter (1981) argued, however, that it is the circumstances  surrounding any separation which are crucial, and that separation per se is not necessarily harmful.
Nevertheless, children between the ages of six months and three and a half years appear to be often adversely affected by hospital admissions lasting longer than one week, or by repeated admissions.
Douglas (1975) showed from a long-term follow-up of a birth cohort of over 5,000 children that such admissions were associated with troublesome behaviour at school, and to low reading scores at age fifteen years.
Quinton and Rutter (1976) replicated this finding, and were able to show that disorder resulting from hospital admission was not explicable in terms of other medical factors such as persisting disability or low birth weight.
However, children from unhappy, disrupted or deprived homes were most likely to be damaged by the experience.
Approximately 4 per cent of the general population experience multiple hospital admissions in childhood, and two-fifths of these are likely to show later disturbance.
The overall numbers involved are therefore not insubstantial.
In the absence of adverse circumstances, however, it seems that most short-term parent-child separations will not usually be associated with any psychiatric risk.
Children are not at increased psychiatric risk if their mother goes out to work, for instance, providing the alternative day care arrangements are of good quality, ensuring continuity of caretaking, adequate love and attention and opportunity for play and conversation.
Indeed, the findings of Brown and Harris (1978) suggest that a job outside the home may in certain circumstances help to maintain a mother's mental health, in which case it may be beneficial to her relationships with her children.
However, if the timing of the mother starting work coincides with other disturbing events such as death of the father, it may well be interpreted as a threatening event and lead to some distress.
While short-term separation of parent and child under favourable circumstances is unlikely to be damaging to the child, long-term separations can have more serious effects, particularly when they occur in the first three to four years of the child's life.
Children cared for by grandmothers or foster mothers during their first three or four years often have great difficulty when they return to live with their natural parents or a new step-parent.
Child psychiatrists see many emotionally and behaviourally disordered children with such experiences (Wolff, 1983a).
Children brought up in community homes are also over  represented among psychiatric clinic attenders.
Their parenting experiences prior to reception into care is thought to contribute to their high rate of psychiatric disorder (Rutter, 1981).
When children have been taken into care at a very early age, and have lived in institutions until after their third birthday, or have experienced several changes of foster mother during this time, they have sometimes failed to form any secure affectional bond or attachment.
These circumstances have been linked with a raised probability that the child will later develop a syndrome labelled ‘affectionless psychopathy’(Rutter, 1981; Wolkind, 1974).
This personality disorder is characterised by a lack of guilt and an inability to keep rules or form lasting relationships.
Evidence in this area has led to the conclusion that institutions are not capable of providing adequate parenting for the very young child and to the statement by the Royal College of Psychiatrists (1983) to the Standing Committee on Children in Care in Britain that no child under the age of three years should ever be placed in a residential nursery.
(ix) Bereavement
Raphael (1982) provides qualitative descriptions of the experiences of thirty-five children aged between two and eight years in twenty families in which either the mother or father had died in the previous two to eight weeks.
She documents the considerable difficulties involved for researchers in approaching bereaved families and countering the disapproval of many outside agencies.
Those families in which a parent died from an illness known in advance to be terminal seemed to be better able to respond to the needs of their children, and to prepare them for the loss with information and emotional support.
Sudden, unexpected deaths were found to present particular difficulty to the bereaved parent in communicating events and supporting the reaction of his or her children.
Children were often given confusing information, not taken to the funeral and generally left with a poor understanding of the finality of the event.
Raphael also suggests that bereaved parents who felt particularly unsupported themselves, lacking contact with the grandparents, for instance, were especially likely to be oblivious to, or deny, their children's needs at this time.
These circumstances (unexpectedness and lack of a supportive network) have been linked to a raised probability of disturbed conduct and emotional disorder among young children  following bereavement.
Once again it seems that the consequences of the death on family life, rather than the direct effects of the loss, may be crucial.
Often the surviving parent becomes depressed, the family may break up and there may be social and economic privation (Parkes, 1972).
However, research on parental death in childhood at the time of the loss is sparse.
(x) Interactive processes
From this brief examination of some of the factors which can affect childhood psychiatric risk, it is apparent for each one of the examples that they are relevant only if certain other conditions prevail.
Many traumatic events may be overcome without lasting damage if, for instance, the child has a continuous, warm, secure relationship with one parent or parent-substitute.
Accidental death of a child's twin brother may be highly disturbing at five years, but have much less impact at five months.
An alcoholic father may not be as disturbing to the temperamentally easy daughter who is seldom the target of her father's aggressive outbursts, while her more difficult brother may be regularly physically and emotionally battered.
One short hospital stay may cause minimal difficulties in adjustment to a child returning to a happy home life.
Another child, repeatedly admitted for treatment, or whose home life preceding and following his hospital stay is characterised by family discord, may be adversely affected by the experience.
It seems that, to a certain extent, the effects of stress are cumulative, but not in any straightforward additive way.
The indications are that the existence of one difficulty increases the probability that other stresses will also occur.
Children with difficult or disadvantaged home circumstances are more often admitted to hospital and residential care than other children.
A child whose mother has just started full-time employment may only be likely to be disturbed by this event if he has also recently lost his father.
Yet it is in precisely this sort of situation that a woman who has hitherto chosen to stay at home with her children may need to seek work.
Such patterns of stress may be so much more damaging than the sum of their separate effects because their co-existence leads to a different attribution of meaning to them on the part of the child.
A good relationship with one parent may, for example, be protective against the effects of mental illness in the other parent, if it enables  the child to see the ill parent's behaviour for what it is, and not as a rejection of the child or caused by the child.
In fact, many childhood difficulties may not, in isolation, raise psychiatric risk at all.
A child who is enabled to cope well with a parent's illness, say, may well become more competent and resilient to adversity in the future.
(xi) Implications for prevention
Some risk factors in childhood may be amenable to prevention.
Examples include the prevention of brain damage through: adequate perinatal care; prompt treatment of status epilepticus; the reduction of child abuse; and accident prevention (particularly road accidents).
Immunisation for teenage girls against rubella also reduces the chance that pregnant women will catch and transmit the infection to their unborn children, with possible resultant brain damage; and biochemical screening of pregnant women to detect phenylketonuria enables the condition to be treated promptly in the newborn infant (Graham, 1977).
Treatment of parental mental illnesses may also be seen as potential preventive approaches for childhood disturbance, as can efforts to help disadvantaged families find ways of resolving their multiple problems, and strategies to reduce overt marital discord.
In this respect, it would seem to be more important that family relationships improve, whether or not husband and wife remain together, rather than urging parents to ‘stick it out for the sake of the children’ in unhappy marriages.
Many workers in Britain have argued in favour of special family courts for divorcing families, and for divorce conciliation services, to help couples who wish to separate do so as amicably as possible (see for example, Parkinson, 1982).
The public concern and media coverage of cases of severe child abuse has produced a plethora of professional reviews suggesting ways victims can more rapidly be ascertained and recommendations for action when child abuse is suspected (DHSS, 1974).
If one child in a family is maltreated, others in the same family are at high risk.
Baldwin (1977) found that if the eldest child was abused, the likelihood that the second eldest would be abused was 78 per cent.
If the two eldest were abused, 64 per cent of the third eldest were too.
In cases of abuse as severe as those assessed by Baldwin, the ascertainment of one child should enable early ascertainment of abuse to subsequent children.
When the risk factor cannot be eradicated, or the stressful experience avoided, an alternative approach to prevention is to focus attention instead on the child's resources for coping with the problem.
Perhaps he can be helped to interpret the events as less threatening.
If a child must face a prolonged period of hospitalisation, say, he could relatively easily be prepared in advance with information about what will take place, and allowed to experience graded separations in happy circumstances, such as overnight stays with friends.
In hospital, the parents can be enabled to spend as much time as they wish with their sick child, and efforts can be made to keep to the child's familiar routines (Rutter, 1979b).
Or if an adult hospital patient with young children is known to be terminally ill, it should be possible to provide some kind of support for the spouse and the children in preparation for their loss, in order that they may work through their grief and come to terms with their new situation.
However, for most pre-school children, their sense of meaning and their self-esteem derive primarily from their interactions with their mothers.
Yet multiple disadvantages are common in young families.
Maternal depression, poverty and other social difficulties are highest among this section of the population, and these hazards are associated with a high rate of child disturbance.
Few women are prepared for the difficulties of running a home and bringing up young children.
Their knowledge is likely to be based on their memories of their own parenting.
Since the traditional extended family network seems to be playing less and less of a role in supporting the young parent there may well be a need to substitute this source of information, advice and emotional support.
Parenting education might begin in schools and continue over the first few years of married life (Pound et al., 1985).
Postnatal support groups and mother and child playgroups are possible sources of companionship and parent education.
More than specific child management skills, parents need to be aware of the level of understanding of their child, his anxieties, frustrations and emotional needs.
Parents of low birth weight or handicapped children also need to be encouraged to avoid becoming overprotective, and communicating their anxieties to their children (Graham, 1977).
From the age of five years, schools may play a protective role.
The findings of Rutter and his colleagues on the social structure of schools speak for themselves (see above).
It also seems that it might be helpful if teachers were aware of those among their pupils with  particularly unsupportive home lives, that is, with few sources outside school from which they might derive a sense of their own value.
They might make special efforts for these children to maximise the chances that they will have some sort of positive experience in their school lives.
It might be success on the sports field or in drama, a role as form captain, or enjoyable extra-curricular events.
And finally, those children with reading difficulties need to be provided with remedial programmes as early as possible, and concerted efforts need to be made to minimise the sense of stigma they might experience because of their intellectual or physical disadvantage.
Does childhood disorder continue into adulthood?
Although a well-respected body of opinion favours the belief that an enduring emotional attachment between mother and baby develops during the infant's first year of life and the quality and strength of this bond is of paramount importance to the individual's future social and emotional development (Bowlby, 1951; Rutter, 1981), there is a surprising lack of research which has succeeded in demonstrating a continuity in the development of psychopathology.
Efforts to chart continuities in maladjustment almost invariably fail to find more than a small relationship between early attachment or infant behaviour and later emotional or behavioural adjustment, and although very early relationships and behaviour are seen to be very important, most researchers aiming to demonstrate this fact end by concluding that discontinuity rather than continuity is the rule (e.g. Lewis et al., 1984; Fischer et al., 1984).
Inevitably they argue that life stress events and family demographic variables are also important, and it may be the failure of much research to take these variables into account (and probably the problems of doing so) which explains why a stronger relationship between early attachment and behaviour and later adjustment is not found.
There is very little evidence, either, that young children with emotional disorders (anxiety, fear, depression) are more likely to suffer psychiatric disorders in adulthood than their more well-adjusted peers.
However, there does seem to be some consensus of opinion and parallel findings to demonstrate continuity in the area of disorders of conduct (Robins, 1966; Rutter and Madge, 1976).
Of course, one of the main difficulties in this kind of research lies in the collection of accurate information about events and experiences  over a period of twenty years or more.
If adults are asked about their childhood, it seems highly likely that their memories will have become distorted or lost over the years, and that they will be coloured by the person's present mood state, particularly by the existence of any psychiatric disorder.
Hence a depressed person may well remember their childhood as considerably less happy than they would have done if asked the same questions before the onset of their current depressive symptoms.
The ideal source of information is therefore that collected prospectively, that is, from subjects in their childhood who are then followed up and re-interviewed many years later.
For this reason, the study by Robins (1966) is probably still one of the best sources of descriptive evidence.
Robins came across the intact records of a child guidance clinic in St Louis, of children who had been in trouble between 1924 and 1929.
She successfully traced over 90 per cent of these individuals some thirty years later, and collected information about them from interviews and records, including assessments by psychiatrists on the presence of psychiatric disturbance.
Altogether she followed up 345 white American children who had been referred to the child guidance clinic for anti-social behaviour, 130 other referrals and 100 individuals who had attended neighbouring elementary schools who had not been referred for any specialist help, and who therefore provided a comparison group.
Her most well-known finding was that the
prognosis for children referred for anti-social behaviour is much less promising than that for children referred to child guidance units for other reasons.
For anti-social boys — the risk of future arrests was 71 per cent…
For anti-social girls — the risk of divorce was 70 per cent and for boys — 50 per cent.
Half the men and one-third of the women were heavy drinkers.
Children with other kinds of referrals are more like the comparison school children at follow up— less of a problem both to society and to themselves.
She went on to say that
it would follow from these findings that the children currently being referred to clinics for anti-social behaviour are the group for whom successful intervention is the more urgently needed, to prevent personal misery for them as adults, for their spouses and children, and for the persons whom they will rob or swindle.
The former clinic patients with anti-social behaviour were considerably more often diagnosed by the research psychiatrists as having a sociopathic personality than were the comparison group.
They were also slightly more often diagnosed as suffering from alcoholism, schizophrenia, hysteria and chronic brain syndrome.
They did not have a higher rate of manic depressive illness or anxiety neurosis.
As well as being powerful predictors of sociopathy, anti-social symptoms were also better predictors than non-anti-social symptoms of hysteria and alcoholism.
In fact, many of the non-anti-social symptoms in childhood seemed completely unrelated to adult psychiatric status.
For example, children who were fearful, withdrawn, shy, had tics, were hypersensitive, had speech defects, insomnia, nightmares or temper tantrums were no more likely to have psychiatric disorders as adults than those lacking such traits in childhood.
The anti-social childhood behaviours which were found to be significantly associated with adult sociopathy were: pathological lying, lack of guilt, sexual perversion, impulsiveness, truanting, being a runaway, physical aggression, a poor employment record, premarital intercourse, theft, incorrigibility, staying out late, having ‘bad’ associates and recklessness.
The presence of six or more of these factors showed the strongest relationship with sociopathy, and their frequency and seriousness also increased the relationship.
But as Robins points out in a later paper, a wide variety of anti-social childhood behaviour predicts a wide variety of adult deviant behaviour, rather than, as some have claimed, particular behaviour being predictive of specific offences (e.g. conduct disorder predicting property but not person offences).
Three of the studies in which she has been involved — that described here, a follow-up of normal young black men, and a follow-up of Vietnam veterans — have supported her contention that deviant behaviour of various types in childhood or adolescence forms a syndrome which tends to continue in about half the cases to adulthood.
Thus, conduct disorder in childhood indicates a high probability that a person will be arrested for a criminal offence in adulthood, but does not predict the type of arrest (Robins and Ratcliff, 1980).
Robins argued that disturbed behaviour in fathers tended to lead to similar disturbances in their children, particularly their sons, as it was a much better predictor of conduct disorders in the children than was the behaviour of the mother or siblings.
The relationship was strongest where the father showed a wide range of disturbed  behaviour: excessive drinking, desertion, arrests, failure to support the family and a tendency to change jobs frequently, with long spells of unemployment.
This was also thought to explain, at least partly, the high rate of conduct disorder among children in low socioeconomic groups with discordant home backgrounds.
This raises another major problem in studying continuities in pathology, that of disentangling continuity of disorder from the continuity of causal social stressors.
For instance, childhood conduct disorder may often lead to anti-social behaviour in adulthood, but this may reflect either the continuity of the disorder or the different effects of the same social stress acting first upon a child and later upon an adult (Graham, 1983).
The assumption which seems to prevail in the literature on conduct disorder is that certain disordered personality characteristics are formed which tend to continue, although the data on continuities in adverse social conditions which would confirm this assumption is by and large absent.
However, the implication is that intervention should focus on the prevention or early treatment of the disorder.
Robins suggests that early identification of disorder should be possible through the school system, as most of her sample were already in obvious social difficulties before the age of ten years.
As lack of discipline at home had been found to be important to later sociopathy, she recommended improved discipline at school for such at-risk youngsters: a more vigorous role in preventing truancy, supervision for completion of assignments, controlled use of leisure time and so on.
Judicial action and institutionalisation were not recommended, as such action seemed to be associated with a higher rate of later sociopathic behaviour among her sample.
If a good deal of conduct disorder could be prevented or successfully treated in childhood, it would seem that such intervention should have considerable impact on the prevalence of personality disorder and sociopathic behaviour among adults.
Success would, however, be less important to the prevention of disorders seen and treated by adult psychiatrists than to the problems dealt with by the criminal justice system.
These sorts of childhood problems are only weakly linked to adult schizophrenia and alcoholism, and completely unrelated to manic depressive illness or anxiety neurosis.
Modifying early childhood experiences as a preventive intervention in adult disorder
In chapters 4 and 5, a range of childhood and early adult experiences were described which probably have some causal importance in depression and schizophrenia.
Being brought up in an institution or by neglectful parents, a pregnancy, early marriage, and showing poor planning skills were considered to have a causal role in adult depression.
Perinatal complications among babies born with an inherited predisposition towards schizophrenia may be implicated in the later manifestation of this disorder.
Some of these factors can be found in the descriptions provided by Robins (1966) of the childhood histories of the child guidance patients who later developed psychiatric problems.
Although the study was primarily concerned with the continuity of anti-social behaviour, there were also twenty-nine men found to have alcoholism, twenty-three men diagnosed as schizophrenic, twenty women described as ‘hysterics’ and thirty-two male and thirty female ‘other neurotics’who were predominantly either undiagnosed or anxiety states.
Many of the same factors seem also to have occurred in the childhood histories of adults developing different disorders, suggesting that, as illustrated by Figure 3.1 (page 36), in different combinations the same factors may play an aetiological role in different disorders.
For instance, apart from the group labelled ‘other neurotics’, a high rate of broken homes was characteristic of the whole group of adults with disorders when compared to child guidance patients found to be well as adults.
Furthermore, an abundant sexual experience was common in childhood among the women described as having hysterical or sociopathic disorders, and strikingly inadequate discipline had been a feature of their homes.
In fact, over 80 per cent of the women with hysterical or sociopathic disorders had, as children, lived away from both natural parents at some time, and over a third of the men diagnosed in adulthood as schizophrenic had been taken into care during childhood.
Only the ‘other neurotic’ group were indistinguishable as children from those who grew up to be well; if anything, their home lives were slightly more adequate than those of the comparison group.
What are the practical implications of following these pointers?
(i) Perinatal complications, parental mental illness, parental overconcern
There is a distinct possibility that perinatal trauma interacts in some way with an inherited predisposition towards schizophrenia to increase psychiatric risk.
The children of women with schizophrenia followed up by Mednick and his colleagues (1981a) who eventually developed schizophrenia were more likely to have had perinatal complications than those who had had a non-traumatic birth.
Further, Cutting (1985) cites research evidence which shows that in monozygotic twins discordant for schizophrenia, it is the identical twin experiencing the more complicated birth who is more likely to develop schizophrenia.
This suggests that it may be beneficial to provide more intensive antenatal care for pregnant women with a history of schizophrenia, and to be particularly cautious in the management of their deliveries.
Overinvolvement by close relatives seems to be implicated in relapse of an established schizophrenic illness.
But as yet no feature of parenting has been convincingly established as being a causal factor in the first onset of the disorder despite observations by numerous investigators that parent-child relationships are often atypical in a number of ways.
Even without evidence of a causal role in schizophrenia, the reduction of overprotective parenting may be seen to be a valuable preventive strategy for other psychiatric problems.
Child psychiatrists provide many clinical accounts of the high level of overprotection among parents of children with emotional disorders, especially if such children have a physical handicap or illness or other evidence of fragility (Graham, 1977).
It seems likely that just as extremes of neglect may have long-term deleterious consequences, so may overprotection.
Clinicians could perhaps reduce the transmission of anxiety to disabled or ill children by more positive reassurance and support to their parents, and by helping parents whose children have recovered from complications at birth to realise that they are no longer in any danger and can be treated like other children.
Mutual aid groups and health visitors may also be able to support parents and encourage them to foster their child's independence where it is apparent that a parent is showing extremes of protectiveness towards their child.
(ii) Parental neglect, indifference, low control and parental loss
As described in chapter 4, the research by Brown and Harris and their colleagues showed that prolonged lack of care in childhood was a causal factor in adult depression (Brown et al., 1986b; Harris et al., 1986).
Following the loss of their mother by separation or death, those children who experienced either marked indifference or markedly low control from their fathers or substitute parents were three times more likely to be depressed when interviewed in adulthood than women with no such experiences (Brown et al., 1986b).
There was some indication, too, that the child who was showing signs of a helpless approach to life and one or more symptoms of childhood disturbance (truanting, bedwetting, stealing, fearfulness and so on) as well as experiencing a lack of care was especially likely to be depressed in adulthood (Harris et al., 1987c).
The assessment of parental indifference was based on the lack of parental interest shown in friends, school work, jobs and in adequate feeding and clothing of the child.
Parental control, relating to restrictions and rules for behaviour, was judged to be low when supervision was so negligent that the child was left more or less to do as she pleased.
This often occurred when the father alone had parental responsibility and was too busy or preoccupied to provide adequate care.
It seemed that as mothers had usually hitherto had primary responsibility for child care, they were less likely than single fathers to neglect this function when trying to combine it with the role of breadwinner (Harris et al., 1986).
From the point of view of prevention, this suggests that when a lack of care arises in the context of marital separation or parental death, some kind of support for the single parent may be particularly valuable.
Support may help a bereaved parent to cope with his or her own feelings of loss, and thereby be better able to recognise their children's needs and vulnerability.
Practical advice and assistance would also aid this process.
The provision of a home help, information about financial benefits for single parents, advice and suggestions for managing the household, parental and financial tasks would be useful.
Much of this support could be gained from voluntary befriending schemes, single parent advice groups and possibly the kinds of ‘divorce workshops’ that have gained a degree of popularity in American mental health centres.
However, as it was found to be the lack of care which followed  the loss of a parent, rather than the loss itself, which explained the child's increased risk of depression in adulthood, the same vulnerability can be expected to result from lack of care in intact family homes (Harris et al., 1986).
And of course, most instances of lack of care will be in intact homes.
These families are likely to be considerably more difficult to identify and to involve in preventive programmes.
Mothers characterised by a high level of indifference towards their child or children are unlikely to look out for mother and toddler groups in their locality.
It may be possible to reach some of this group if and when they attend health centres for antenatal care or child health check-ups.
However, a more successful method may be through the health visitor, in her visits to mothers in their own homes.
She is particularly well-placed to set up mothers' groups in her locality, and to encourage those she visits to attend.
She could maximise the possibility that women would form supportive friendships which would outlast the group by bringing together women who seemed likely to get on well.
And she could use these groups to provide some forms of education for parenthood.
Alternatively, a more deliberate intervention in the form of a one-to-one (mother-to-mother) voluntary befriending scheme for mothers having marked parenting difficulties might be instituted.
In fact several projects of this nature are currently operating and are having considerable success in improving the social, emotional and educational environment of the home (see chapter 9).
Some British health and social services are setting up family units, also specifically aimed at this hard-to-reach group.
Staff will go to some trouble to enable families to attend.
They aim to improve family relationships and parenting skills in order to reduce the possibility of family break-up.
As yet their methods of doing so are ill-defined.
(iii) Substitute parenting
Between 1976 and 1980, there were over 95,000 children in the care of local authorities in England (DHSS, 1982).
Roughly one-third of these children were in institutions (community homes and approved schools, or assessment centres), one-third boarded out with foster parents, and one-third in their own homes.
Children who have been adopted after being received into care are not included in these figures.
When the level of parenting available to a child is bad enough to make it appropriate for the state to intervene on his or her behalf, long-term planning to ensure continuing of good-quality substitute parenting should be essential.
Adoption offers the most secure future.
Otherwise, a long-term plan involving the natural parents and foster parents needs to be conceived with their cooperation as soon as possible (Rutter, 1982).
Institutions cannot provide good parenting, but may be a valuable bridge between the child's own family and other permanent homes.
The very high turnover of caregivers in institutional settings is perhaps the major way in which they differ from ordinary family life.
Quinton and Rutter (1983) quote a figure of fifty or more parent figures during the first five years in a residential nursery as being common.
They have made some suggestions for ways of improving the parenting provided, but there are serious practical problems in achieving a good standard of care.
Of course, these straightforward ideas mask substantial ethical and practical problems associated with state interference in family life.
The complex issues which are raised cannot be satisfactorily considered within the brief discussions presented here.
A detailed consideration of when and how it is in the child's best interests for the state to intervene in his family life can be found in Goldstein and colleagues (1973 and 1979).
They expound their policy of minimal state interference to find the ‘least detrimental available alternative’— one in which child placement and procedure for child placement ‘maximises, in accord with the child's sense of time, the child's opportunity for being wanted and for maintaining on a continuous, unconditional and permanent basis, a relationship with at least one adult who is or will become the child's psychological parent’(Goldstein et al., 1979, p. 189).
These far-reaching discussions recognise both the child's right to autonomous parents and family privacy, but also the parents' rights.
They suggest that people other than the child's biological parents should be able to earn those rights if they have become the child's long-term caretakers.
If a good mothering experience can be provided even in late childhood, it can overturn all the bad experiences and provide a good model for the person's own mothering as well as boost her self-regard.
Harris et al.(1987b) describes, by way of example, the case of a girl who had had numerous foster placements which broke down progressively more rapidly.
The girl seemed likely to continue into adulthood with substantial social and emotional difficulties.
However, when a particularly successful foster placement led to the girl's adoption the girl changed considerably.
She thought more highly of  herself and in later years was successful in establishing a mutually supportive and caring marital relationship.
She was not judged as having an elevated risk of adult psychiatric disorder, despite her early disadvantage.
The transition period after leaving institutional care has also been documented as a critical time, when young people may be forced to return to the unhappy home situation from which they had been removed years earlier.
Where this is the case, early marriage, often preceded by premarital pregnancy, is a common escape route for girls (Rutter et al., 1983), and this in turn substantially raises the likelihood of adult depression (Harris et al., 1987a).
Practical support at the time at which young people raised in care are forced to leave their residential homes to help them settle into satisfactory new home environments, perhaps by helping them to get flats with friends or places in small half-way hostels with friends and supplying a realistic preparation for independent living, might avoid many difficulties.
Additionally, a more flexible attitude by social services to enable the young person without fully satisfactory living arrangements to go to, to stay on as long as necessary at the home, would be preferable to sticking rigidly to a somewhat arbitrary age cut-off time.
There may well be a case for social workers or child care workers to be appointed with this resettlement role as their particular brief.
According to Grosskurth (1984), some innovative schemes along these lines have already been set up by a few progressive British local authorities, but it seems that they are as yet rare, and reach only a minority of the people in need.
She reports that while only a small proportion of all eighteen-year-olds live independently, a majority of those reared in care have to do so, and these are often ill-prepared, have meagre financial help and currently have limited prospects of finding work.
Few authorities were felt to have a coherent policy on supporting their older children.
Grosskurth suggests such a policy should include not only housing provision, but an adequate preparation for coping with independent living after years of dependent living in institutions.
A disproportionate and disturbingly high number of care leavers join the ranks of the single homeless.
(iv) Premarital pregnancy, early marriage and ‘planning ‘
There were at least 60,000 live births to teenage mothers in 1980 in England and Wales.
A further 36,000 teenage pregnancies were  aborted in the same year (Wells, 1983).
Wells calculates that as approximately two-thirds of teenage pregnancies going to full term were reported to be unplanned in a study in South West England, effective contraception therefore has the potential for avoiding 76,000 unwanted teenage pregnancies each year.
Teenage mothers are more likely than older mothers to have an unstable family background, to have poor or no educational qualifications, and to be unemployed at the time of conception (Wells, 1983).
More successful education about birth control measures and more approachable advisory services may be part of the answer, but many unwanted pregnancies seem to occur among experienced contraceptors who give up without specifically wishing to become pregnant (Wells, 1983).
An important factor in avoiding pre-marital pregnancy would seem to be the girl's own attitudes and behaviour in taking control of and planning her life.
Quinton and Rutter's (1983) study of girls raised in care showed that girls who were ‘planners’ in other aspects of their lives were considerably less likely to become pregnant.
Similarly, Harris and her colleagues (Brown et al., 1986b; Harris et al., 1987b) suggested that helpless attitudes and ways of thinking are a link between childhood lack of care, premarital pregnancy and depression.
Quinton and Rutter (1983) have suggested that school experiences may be critical sources of selfesteem for children lacking supportive home lives, and that this in turn enhances their capacity to plan their lives.
An interesting, if somewhat methodologically weak, study by Flaherty and his colleagues (1983) on adolescent pregnancies seems to be in line with this notion of planning ability.
They compared groups of virgins, non-contraceptors, contraceptors and pregnant girls on their ability to anticipate the consequences of actions, to generate solutions and plan steps to implement them, in a variety of hypothetical problems unrelated to contraception.
They found no group differences in the girls' abilities to anticipate consequences of actions.
However, pregnant girls gave the least number of alternative solutions to the problems, and were least competent at describing the steps an imaginary protagonist should take to achieve her aims in five stories.
Together, these studies suggest that knowledge about contraception and about family planning services, and the desire to become pregnant, by no means fully explain premarital pregnancy.
In fact, Flaherty and his colleagues (1983) were unable to find any evidence that intervention programmes with teenage childbearers offering  intensive family planning education had any success at all in preventing repeat pregnancies, though others have had less discouraging experiences (Osofsky et al., 1973).
Sex education in schools may therefore have most impact if it aims to discourage helpless attitudes, by emphasising to young people that they are in control of their own lives, encouraging them to see themselves as active rather than passive, and in discussing what they might do in the event of an unwanted pregnancy.
This last issue is of course the last link in the chain leading to high vulnerability to depression.
If the girl avoids becoming trapped, through an unwanted pregnancy, into an unsatisfactory lifestyle with an unsupportive or absent marital partner, she may still break out of the adverse chain of events.
(v) Interactive processes, problems of intervention
It seems clear that throughout the developmental period, certain factors can be identified which in certain circumstances will increase a person's future psychiatric risk.
In nearly all instances, however, it is the chain of adverse circumstances with which the factor is associated which accumulate to generate this risk.
Only if an intervention is effective not only in eliminating this factor, but also in transforming the person's lifestyle such that he or she is removed from this conveyor belt of risk, can the effects of the intervention be expected to be apparent ten or twenty years later.
The difficulties in achieving such effective intervention can easily be imagined.
This is not to say, however, that prevention is impossible, simply that preventive programmes need to concentrate not only on the removal or modification of isolated stresses, but also on the factors surrounding and responsible for such stresses, for these may be of equal or even greater importance in the development of later psychiatric disorders.
Approaches to prevention: supporting troubled persons
In spite of very real gains in knowledge, there is a long way to go before we can fully understand why one person is more likely to become mentally ill than another.
Just how much is due to inherited characteristics, and how much to other biological factors or early childhood experiences is still uncertain.
But personal characteristics are certainly not the whole story.
Mental illness occurs in a context, and our understanding of factors in the current social environment which play a role in onset, recovery and relapse is growing.
In particular, life events of certain kinds have been implicated in a wide range of disorder, and some of the evidence to establish their role has been described in earlier chapters.
Environmental factors, as well as personal characteristics, affect the probability that events will be followed by disorder (and indeed also whether events will occur).
And environmental factors provide an obvious focus for a consideration of preventive options.
As is now possible with heart disease, perhaps preventive approaches will serve to increase the threshold for the appearance of illness.
This chapter will consider personal resources for dealing with personal environmental challenges.
The following chapter will extend the focus to consider the influence of factors in the wider social sphere — the effects of cultural values and practices.
Events, psychological distress and psychiatric disorder
Everyone experiences disturbing life events from time to time, and although they may cause a good deal of psychological distress, they cannot on the whole be considered to have a deleterious effect on health.
In fact the reverse case can be argued.
The person who  creates a crisis in a relationship which is not going well such that the two part company and he or she is able to establish a more suitable and rewarding partnership may do much better than the person who avoids crises and settles for a far from ideal partner.
The person who, despite their concern about the loss of a company pension, leaves an organisation after many years of service in a disliked job to try a new field may well do better, in health terms, than the person who sticks it out in the miserable job.
Even apparently adverse and uncontrollable events like suddenly needing to undergo urgent major surgery may well be an essentially positive experience if dealt with well.
Once it becomes clear that recovery is likely, it may, for instance, lead a person to re-examine their lifestyle and come to positive decisions about how they would like to improve it and make more of its good features.
It makes no sense to contemplate a general policy of reducing adverse events in people's lives, even if it were possible, unless perhaps they were crises which might unavoidably lead to the person becoming trapped into a highly stressful lifestyle.
Perhaps, for instance, a case could be made for discouraging risks that might lead to a person's loss of employment, if their chances of gaining another job were remote.
Similarly, for the teenage girl from a strongly Catholic family it might be particularly important that she avoid pregnancy in a relationship with a boy to whom she felt sure she would not like to be married.
Such events would be likely to result in long-term adversity-unemployment and financial hardship for the first person, loss of family support at the same time as facing the prospects of single parenthood or marrying an unsuitable man ‘for the sake of the baby’ for the second.
Being trapped by such circumstances may well increase the individual's likelihood of suffering a psychiatric disorder, because, by definition, they would become unable or restricted in capacity to deal with the developing difficulties.
However, earlier chapters have shown that life events are implicated in a range of psychiatric disorder, and that to a certain extent it is possible to specify the broad type of event which will precede a particular type of disorder.
Events which have been linked with depression, for instance, are those which, in the context of the person's current life, seem to pose a marked degree of long-term threat following a loss or disappointment, not least in the sense of failure to restore or replace that which has been lost.
The threat may be loss or disappointment concerning a cherished idea or aspiration, object, person or role.
Very often, they are events which are perceived  as moving the individual to the periphery of a social group, in effect into a more emotionally or socially isolated position (Gilbert, 1984).
Events which are severely threatful only for a few days, or which are of a relatively mild or even positive nature, are unlikely to be associated with depression (see chapter 4).
Many threatening events arise from social disadvantage (financial, housing, employment).
Many others might be described as acts of God — receiving a diagnosis of multiple sclerosis, for example.
Leaving to one side the possibility of major political and economic changes, most events of the sort implicated in depression are probably not amenable to prevention at an individual level.
Events which have been implicated in schizophrenia are of a more everyday nature (although it is possible that many also have a private meaning), and a very wide range of emotionally arousing events may trigger a relapse.
The event might not have any obvious long-term adverse significance and may in fact have seemingly positive rather than negative features, such as the reappearance and request to renew contact with a lover with whom a person had had an intense relationship a few years earlier.
How can such events be prevented?
Furthermore, where either depression or schizophrenia are provoked or triggered by an event, disorder typically follows so rapidly that intervention after the event and before the emergence of disorder is unlikely to be a practical possibility.
If it took a couple of weeks to trace and arrange to visit all the closest relatives of the victims of a train disaster, say, those most likely to become severely depressed might already have done so.
In which case, intervention must aim to help troubled people, as the title of this chapter suggests, so that their depression does not become seriously prolonged and severe beyond their ‘normal’ experience of grief.
However, although it seems at first sight that prospects for prevention associated with life events are bleak, there are nevertheless a number of realistic possibilities, and it is important to go through these.
To begin with, people who have suffered from schizophrenia are readily identifiable, and it may well at times be possible to make the lives of this high-risk group less eventful.
For instance, if good supportive accommodation and a job with a sympathetic employer could be found, this would immediately reduce the potential range of home and work-related events.
Moreover, it might be possible to resolve some of the difficulties that might arise before, say, eviction or redundancy became real possibilities.
Many, if not most, events implicated in depression do not occur out of the blue.
While this may not mean they are preventable, there is at least the possibility of fortifying the individual against their effects.
And certain existing circumstances often appear to influence the likelihood of their occurrence.
Previous difficulty in maintaining a pregnancy through to a live birth will be likely to be associated with a greater risk of a third or fourth miscarriage than if the woman's previous pregnancies had been trouble-free.
Hence some kind of additional support, information or psychological preparation for further failure might be instituted, and this might be valuable in preventive terms.
Marital break-up is often, if not usually, preceded by some years of turbulence and unreliability on the part of one or both partners.
A person whose poor health has caused progressively longer and more frequent absences from work will increasingly be at risk of losing his or her job.
Such circumstances might be called ‘event-producing situations’.
Furthermore, a history of failure in an important aspect of one's life will also be likely to affect the meaning and interpretation put on further failures, and increases the likelihood that in the context of the person's life, the event will pose a marked and long-term threat of loss — in the first example above, of the possibility of becoming a parent.
In fact, it is increasingly clear that in formulating realistic possibilities for prevention around life events in the person's current life, it will be essential to consider the person's past history.
It is the long-term lead-up to events which is often critical.
The identification of certain antecedent risk factors is needed in order that a high-risk group can be selected for whom events of certain types may indeed provoke or precipitate psychiatric disorder.
Such factors may include, for instance, a previous experience of loss which was dealt with badly, unresolved grief, past experience of failure, a lack of a sense of self-efficacy, a low self-esteem, a previous history of psychiatric disorder, and an absence of close relationships established over a long period of time.
The identification of risk and the reasons for high risk may then point the way towards meaningful and constructive attempts to intervene.
One important feature of such factors is that they will tend to shape the person's capacity to cope with adverse circumstances.
That is, to take actions to resolve difficulties and to draw on psychological resources to control the meaning of the event and to control the distress with which it is associated (Pearlin and Schooler, 1978).
Research on crisis support invariably focuses on the notion of coping, but the complexity of this idea is not always reflected in intervention studies.
Coping behaviour is associated with current external resources (money, information, practical help), which also relate to available supportive relationships, and with internal psychological resources (confidence, experience, knowledge).
Essentially three sets of concepts can be brought together in relation to life events to help conceptualise possibilities for prevention.
Certain qualities of events have been linked to a raised probability that a particular psychiatric disorder will develop shortly afterwards.
Certain circumstances are particularly likely to lead to the occurrence of such events.
Certain individual psychosocial characteristics will affect the interpretation of and response to a given event.
It might be argued, therefore, that if sufficient was known about people's lives, it would be possible to allocate the population to one of four risk groups:
(1) those who have recently experienced an event to which they were particularly vulnerable;
(2) those whose circumstances make them highly likely to experience an event to which they are particularly vulnerable;
(3) those who are vulnerable to particular types of event, but whose circumstances either make their occurrence unlikely, or provide resources for dealing with the event should it occur;
(4) those who are not especially vulnerable to any specific kind of stress.
The first two groups are those for whom preventive intervention may turn out to be justified.
Figure 7.1 illustrates in a general way  the likely sequence of contributing factors, and the two most promising points of intervention.
It is not put forward as a definitive model for how coping, support and events interrelate in the genesis of psychiatric disorder, because the issues are so complex that the diagram could be redrawn in several different ways and indicate several other likely relationships.
Rather, its purpose is to simplify the issues sufficiently to be able to put a coherent structure on the following discussions about some of the ways in which the various factors interrelate, and the possibility of intervention.
The subheadings throughout this chapter focus on each of the factors (a-k) in Figure 7.1 in turn, and their effects on the likelihood that events will be followed by illness.
Specific developmental vulnerability to disorder
The concept of a specific vulnerability is commonly used to explain why person A who experiences a severe event becomes depressed, but persons B, C, D and E do not.
Or why person D, who experiences a relatively minor but intrusive event which would have no adverse consequences for persons A, B, C and E, becomes floridly psychotic (arrow a, Figure 7.1).
Possible explanations include a biological predisposition to a specific disorder; the particular threat embodied in the event to the person's long-term plans and purposes; the significance of the event in the context of the person's previous history of failure or loss; and personal characteristics like a lack of confidence or self-esteem.
In schizophrenia, the first of these is the one we know most about.
In depression, less is known about biological vulnerability, but knowledge is accumulating about other explanations (see chapters 4 and 5).
Event-producing situations
Some specific developmental vulnerability factors are partly explainable in terms of their effects on the lifestyle of the individual, and on the extent to which the person is likely to experience threatening life events (arrow b, Figure 7.1).
A helpless approach to life and a low sense of self-esteem are two factors which have been suggested as being associated with a raised risk of depression following threatening life events (see chapter 4).
These same factors might also make it more likely that a person will experience the sorts of events to  which they will be vulnerable.
One of the explanations put forward by Brown et al.(1986b) for the link between childhood lack of care, premarital pregnancy and adult risk of depression, for instance, was that the early adversities militated against the child developing a sense of control over her life, and exercising it.
Hence unwanted pregnancy was more likely to occur, the girl was also unlikely to deal positively with this event, and likely to drift into an unsuitable, unsupportive marital relationship or single parenthood, and experience adverse events linked to her unsatisfactory lifestyle.
In this event-producing situation the risk of depression was considerably increased.
Other event-producing situations are unrelated to an individual's approach to life or personality characteristics.
Old age, for instance, is a time characterised by frequent losses of one's peers, a loss of function and independence, health problems and, not infrequently, increasing financial hardship.
Many ongoing difficult social circumstances, whether or not a direct result of the person's approach to life, may also erupt at some point into major crises.
A large family in unsuitable housing with financial hardship is more likely than families with greater material resources to find certain events stressful, such as unexpected financial crises leading to debt.
Such families are also more likely to have dangerous forms of heating, and less likely to be insured against damage by fire.
Poverty is clearly an event-producing situation.
Working in an industry that is in decline in an area where alternative employment is scarce makes job loss and consequent financial difficulty increasingly probable.
Caring for a relative with a progressive, relapsing illness or terminal condition makes future related adverse events almost certain (arrow c, Figure
It is undoubtedly possible to identify many event-producing situations.
The health services will know of people treated for psychiatric illnesses and a follow-up service or routine visit from community nurses should be able to recognise obviously unsatisfactory living circumstances.
Social services often know families in extreme financial difficulty.
Employers could provide advance warning of intended plant closures or major reorganisation.
Hospital staff will have some of their major surgery planned many weeks in advance.
They will know of patients likely to die in the near future and of patients recently permanently handicapped by their illness or injury.
Old people's homes will know of plans to move elderly people from their  own or relatives' homes into local authority or private care.
Police will know families of men arrested for criminal offences.
Gas and electricity accounts departments will know those customers whose financial difficulties are going to lead them to a cessation of supply.
Of course, serious issues of confidentiality would have to be resolved, but the potential for recognition is clearly there.
However, as has already been made clear, preventive programmes cannot be planned for everyone likely to face such events.
Additional knowledge is required to specify more closely the smaller proportion of troubled people who would be most susceptible to developing psychiatric disorder in the context of particular events.
Coping in event-producing situations
The aim of coping responses in event-producing situations (arrow d, Figure 7.1) must be either to reduce the likelihood that a severe event will occur (perhaps by seeking marriage guidance counselling to help resolve marital difficulties), or to prepare oneself emotionally for the distressing event which is likely or certain to occur (compulsory redundancy, say).
But unfortunately there are few descriptive accounts of people's efforts to reduce the likelihood that an event will occur, perhaps because effective responses are self-evident, or because they are not easily assessed by investigators in that successful action will have removed the difficulty.
Pearlin and his colleagues have discussed the effectiveness of commonly used coping responses to various chronic role strains of the sort likely to erupt at any time into major events (Pearlin and Schooler, 1978; Pearlin et al., 1981).
During interviews with more than 2,000 adults in Chicago they attempted to identify the conflicts, frustrations and other role strains encountered by parents, married couples, workers and breadwinners, the coping behaviours used to attempt to minimise their impact, and any current symptoms of depression and anxiety.
It might have been expected that strategies aimed to change the stressful circumstances themselves would be an important feature of the coping responses they uncovered.
In fact, very few responses of this kind were identified.
It seems unlikely, however, that this is a true reflection of the significance of such behaviour.
But leaving this to one side, Pearlin and Schooler do deal with some methods of mentally restructuring the meaning of the difficulty that are commonly used to reduce distress.
These strategies were exemplified in statements on the part of respondents such as‘count your blessings’, or ‘we're all in the same boat’, and in methods such as perceiving hardship as the forerunner of an easier future, or devaluing the importance of aspects which are noxious (such as an unpleasant boss and colleagues) and magnifying good aspects (such as the convenient location and reasonable pay of the job).
These are all examples of ways in which people learn to live with long-term social difficulties which they have not been able to change.
Many specific events also have something of this quality, such as requiring major surgery or needing to sell up and move from one's home to cover a business loss.
Because such potentially distressing events are predictable, but unavoidable, they are an ideal focus for an investigation of coping behaviours.
The way the time leading up to the event is used, and the success of the coping behaviours employed, may considerably affect its impact (Parkes, 1982a).
Indeed, the exercise of such anticipatory coping was one of Caplan's central notions for primary prevention.
The specialist draws the person's attention to the details of an impending hazard
and attempts to evoke ahead of time a vivid anticipation of the experience with its associated feelings of anxiety, tension, depression and deprivation.
He then helps them to begin to envisage possible ways of reacting, including mastery of negative feelings.
When the experience itself arrives, the hazards will be attenuated because they have been made familiar by being anticipated, and the individuals will already have been set on the path of healthy coping responses.
(Caplan, 1964, p. 84)
Of course, it is not always helpful to prepare for the worst if there is a possibility that the event may not occur.
The good general does not admit the possibility of defeat, and a doctor would rarely advise a patient that his tumour is probably cancerous until the possibility that it is benign has been ruled out.
However, as Parkes (1982a) points out, morale-boosting optimism is sometimes taken to absurd lengths, and much of the undoubted success of the hospice approach to the care of terminally ill patients stems from the recognition of this fact.
Here, staff appreciate that both fear and grief in the patient and his relatives can be reduced through anticipating the fact that they do not have much longer together and that this time can be used constructively to work through some of their anxieties and other distressing emotions.
This can be contrasted with hospital care where  either the patient or his relatives or both are not informed about the imminence of his death.
The possible consequence of such ignorance has been described by Parkes and Weiss (1983) in terms of the ‘unanticipated death syndrome’.
They characterise this as a combination of shock, anger and persisting illusions of the continuing presence of the dead person.
Cameron and Parkes (1983) cite, by way of example, the death of a woman who had spent her last weekend at home with her husband discussing plans for the future while sitting in the sun to regain her strength.
Her husband had not realised that she was dying, and the subsequent shock was so great that he became unable to care for his six-year-old daughter who also began to lose weight and perform badly at school.
Preoccupied with fears and thoughts of his wife, he was distressed, angry and suicidally inclined.
But how does a person normally prepare himself for frightening and distressing events?
Some important insights have been gained from the study of people who voluntarily undertake frightening events as part of a sport.
Epstein (1983) used the sport of parachute jumping as a natural laboratory for the study of fear and its mastery.
Because the event (the jump) is known in advance, the effects of practice and mastery could be assessed, and efforts made to influence the coping process.
The fear of novice and experienced parachutists was measured at several stages prior to a jump, using both the subject's own ratings of fear, and GSR scores (galvanic skin response, or the electrical resistance of the skin which is a physiological indication of emotional tension).
For novices, anxiety tended to mount steadily from the day before a jump to the moment of jumping.
However, for experienced parachutists, anxiety was usually high on the day before the jump but then steadily reduced to a low level by the time of the jump.
However, if a number of unexpected new experiences and distractions were introduced in this intervening period, the anxiety of experienced parachutists returned to the novice pattern.
Epstein concluded that management of stress among the experienced parachutists was not due to their repeated exposure to jumping in the manner of a conditioned response, but was a consequence of an active coping process that on each occasion was used to prepare them for the coming jump.
He goes on to argue that we can learn to cope with the anxiety associated with an anticipated event or with a recent unanticipated  event by mastering progressively greater amounts of stress.
It is possible to attend to moderately stressful cues and mentally explore and master their threat before proceeding to attend to more salient stimuli.
Those failing to take themselves through such graded stress inoculation may be reduced to falling back on an all-or-none defence mechanism in which awareness of the stressful event is completely blocked out, or is experienced in overwhelming intensity.
He suggests that this maladaptive strategy helps to explain the traumatic neuroses which sometimes follow events like bereavement, and which can be contrasted with successful adjustment in which the individual works through grief triggered by indirect reminders and gradually progresses to being able to respond to stronger reminders of the deceased.
Novice parachutists who blocked out fear completely up to the moment of the jump were often overcome with an overwhelming and incapacitating anxiety such that they not only did not jump but decided to give up jumping forever.
Such stress inoculation in the form of graded exposure to increasing levels of stress is believed by Epstein to be a natural healing process of the mind.
But it is also a procedure which can be taught.
It is already widely used in teaching people to overcome a range of fears, from phobias, dating anxiety, and anxiety prior to undergoing surgery, to readjusting to normal living habits for victims of rape (see Meichenbaum and Jaremko, 1983).
Context and meaning
For the professional footballer whose plans and aspirations require physical fitness, an accident involving a permanent disability is likely to be seen as disastrous.
For an office worker uninterested in sport the implications may well be less profound.
It would not be surprising if the loss of a job for a middle-aged manager who would have difficulty finding other similar employment within his field of expertise and at his age and occupational level was experienced as highly distressing.
To a younger worker who had not yet specialised and could more easily be re-employed without seriously losing status, the threat might be less serious.
As a woman's teenage children leave home, she may interpret the loss of the first as a welcome freedom.
When the last child leaves and she no longer has any daily parenting responsibilities, she may experience a crisis over the loss of status as mother, particularly if she has no other clearly defined role.
These examples illustrate, albeit crudely, the way the meanings of events (see arrow e, Figure 7.1) tend to link to a person's plans, purposes and roles to which they are more or less committed.
But while the perceived effect of events on future plans may be a critical factor in the development of affective disorder, such general interpretations of events do not appear to offer much scope for intervention.
As already noted, events on the whole cannot be prevented, and it will often be extremely difficult to recognise those for whom they present a particular threat to future aspirations.
The middle-aged manager might have well-thought-out ideas about how he would spend his enforced early retirement.
Likewise the middle-aged mother may also have had aspirations which had for many years been put aside until her parenting responsibilities were at an end.
However, events may also pose a particular threat when their interpretation is coloured by the past, rather than the future.
And here the implications for prevention become somewhat more realistic.
For instance, there is evidence that a long history of failure in an important area of a person's life makes them particularly vulnerable to depression in the context of a major loss or disappointment which could be interpreted as further evidence of their lack of competence.
In their prospective study of 400 working-class women with children in North London, Brown and his colleagues (1987) found a threefold increased risk of depression to follow severe events which arose from a long-standing social difficulty compared to women experiencing the same kind of event but without such a prior history.
A long experience of management problems with a child, for instance, increased the chance that a crisis such as the child's arrest for a criminal offence would provoke an episode of depression in the mother.
Silver and Wortman's review of research (1980) on how people adjust to major losses suggests something similar.
Past experience of losses of the same nature as a current loss was found to reduce the person's capacity to deal with the current loss.
Yet it is Gften argued that the successful adjustment to a major loss makes the person better able to deal with future losses (e.g. Caplan, 1964).
Their findings therefore seemed puzzling and they looked for possible explanations.
They suggested that the repeated occurrence of similar losses might increase the likelihood of believing oneself to blame for the event.
Perhaps the rationalisation the person devises for coping with the first loss is shattered by the second loss.
Perhaps the person experiences  an overwhelming sense of injustice which renders them less capable of dealing with the problem a second time.
This connection between past experience relevant to the current event and the interpretation of the event has also been described in studies of grief following bereavement.
Parkes and Weiss (1983) described the contexts in which clinical depression was particularly likely to follow bereavement.
Circumstances which may lead to chronic grief or clinging, for instance, included a previous ambivalent relationship with the deceased or a previous relationship in which the survivor felt either inferior or insecure.
As many as half the severe events documented by Brown and Harris in their studies of women in inner-city areas arose from long-standing difficulties.
This suggests that it may sometimes be possible to identify people likely to experience events which will match a long-standing difficulty before the occurrence of the event itself: a pregnant woman, for instance, who has previously had three miscarriages.
Coping with the event and the distress
Once an event with marked long-term threat has occurred, there are two stages of coping.
Firstly, the event itself must be dealt with (arrow f, Figure 7.1), and secondly, irrespective of its threatening implications, there will be coping responses for getting through and managing the resulting distress (arrow g, Figure 7.1).
At both stages, coping can have behavioural and psychological aspects.
The behavioural aspect is obvious.
Faced with worrying medical symptoms in one's child, signs that an elderly parent can no longer cope alone in their own home, or the sight of flames consuming the house around you — what you do is crucial!
And the success of actions in these circumstances would serve to reduce the potential long-term threat associated with the event.
The person who stays calm and takes steps to control the fire, or manages to get their child to the hospital before their appendix bursts, will undoubtedly be reducing the chances that the event will have serious long-term implications.
On the other hand, the person who discovers a lump under their skin but is too frightened to go to the doctor lest he diagnose cancer will be perpetuating the threatening situation — and this would hold even if the lump was in fact benign.
However, should the house burn to the ground and the lump finally be diagnosed as malignant cancer, the role for behavioural coping strategies is clearly reduced.
There may still be some possibilities, however, perhaps by filling as much of the waking day as possible with exhausting and demanding activity to reduce the time which can be given to introspection.
There is a considerable literature on the psychological strategies that can be effective in dealing with crises.
Pearlin and his colleagues (1981) found that the same sorts of cognitive strategies which were commonly successfully employed by people adapting to chronic role strains were also effective in helping to neutralise the threat of severe events.
About half their original sample had been given a second interview four years after the first.
During the interval, eighty-eight had been made redundant, downgraded or fired from work.
A statistical procedure, step-by-step regression analysis, correlated particular coping behaviours reported to have been used in response to this event and ten symptoms of depression assessed at the second interview.
They concluded that two kinds of response serving to control the meaning of the event by neutralising its economic threat were helpful.
The first involved the person comparing his lot with those in a worse economic position, or with times in the past in his own life when circumstances had been worse, or in the future when they might be worse.
Where they reported that they were able to see the present as better, existing symptoms were lower than average.
A second strategy involved demeaning the importance of money and monetary success.
Both approaches therefore involved attributing a new meaning to the situation.
Leaving aside the problem of time order in the research, and whether their findings do indeed reveal genuine causal effects of coping behaviour, it is unclear how relevant such strategies would be for the general run of threatening events.
It is less easy to see, for instance, how the meaning of a loss such as bereavement could be so readily reinterpreted, or whether such attempts do much to reduce the risk of depression.
There is in fact little evidence that coping responses play a role in the aetiology of major psychiatric disorder since it has not been possible so far to conduct experiments.
Investigators are therefore forced to reconstruct complex behavioural and psychological processes after the event has occurred and sometimes after the disorder itself.
It is always possible, therefore, that too much weight  has been given to the reported cognitive responses.
However, research concerning bereavement has been particularly revealing because some prospective work is possible.
Terminally ill people are not only identifiable, but their closest relatives are also easily located in hospital and hospice settings and from their contacts with clergymen and general practitioners.
Two components of necessary grief work have been identified, and have been summarised by Parkes (1982b).
Firstly, the bereaved person needs to accept, express and work through his feelings of sorrow and hostility, and to review his relationship with the deceased.
Secondly, he must extricate himself from his involvement with the deceased and search out new relationships as sources of rewarding interaction.
Silver and Wortman (1980), in their review of research on how people cope with a range of such major losses, conclude that two resources in particular seem to have some generalisable benefit.
The opportunity to talk about feelings and experiences, and to ventilate anxieties, sadness, anger or despair is important, as is the ability to find some personal meaning in the experience — for instance, following the death of one's child, believing that his or her suffering and treatment may in some way help other children with the same affliction in the future.
In general, research suggests that in the immediate wake of unexpected news of a major loss, such as finding oneself permanently disabled after a car accident, denial may also, in the short term, be an adaptive response as a means of buying time for the individual (Adams and Lindemann, 1974).
Conclusions about coping responses which have a protective effect against a wide range of events are more easily obtained when the events are likely to be associated with acute anxiety and fear rather than depression (e.g. Jaremko, 1983).
Jaremko notes that the person's first response to the threat will usually be a physiological one the pounding heart, as the body prepares for fight or flight.
This leads to an automatic psychological appraisal of the situation as threatening, and in turn to frightening thoughts and images, which in their turn feed back to maintain a rapid heart rate.
Physical skills such as slow breathing or chewing gum can reduce the heart rate and thereby lessen the automatic appraisal of the stressor as threatening.
The person may then use psychological strategies such as a sequence of self-statements to change the way he perceives the stressor and ensure that thoughts and images are less anxiety  provoking (Jaremko, 1983).
This active search for alternatives may include attempts to convert the threat into a challenge that promises growth and achievement (Lazarus, 1976).
Finally he can use ‘cognitive restructuring’ to replace negative self-statements like ‘It's going to be awful’with positive statements like ‘I'm sure I'll manage’(Jaremko, 1983)
These cognitive coping strategies might be viewed as internal resources for dealing with threatening events and chronic social difficulties.
As such they can be separated from external resources such as practical help, information and emotional support.
Social support
The extensive literature on the complex issue of social support has been reviewed many times.
That social support may play a major role in modifying the deleterious effects of stress on health and may also influence other aspects of health behaviour such as use of health services and the following of medical advice appears now to be widely accepted.
It is common for reviewers to cite evidence of effects on physical pathology from a study by Cassel (1976) who reported an increased prevalence of hypertension and stroke in groups deficient in social supports, and from work by Berkman and Syme (1979) who reported a raised mortality among adults deficient in social ties in a sample of 6,928 individuals studied prospectively over a nine-year period.
Investigators focusing on the ill-effects of life stress on mental health have also demonstrated the protective effects of social support (for example Cobb, 1976; Brown and Harris, 1978).
Gore (1978), and Bolton and Oatley (1987) have shown how various kinds of social support can cushion the impact of unemployment.
Others have shown its protective influence for the bereaved (Raphael, 1977) and against chronic work stress (House, 1981).
However, the research findings have not always been consistent and there has been controversy over their significance.
A number of investigators have failed to find the expected correlations between lack of support, stress and psychiatric disorder shown in Figure 7.1.
Some careful reviews of the evidence have helped to clarify the position.
By taking into account the adequacy of the research designs, ruling out findings from small samples, weak measures and poor statistical analysis, Kessler and McLeod (1984) revealed a considerable amount of agreement about the positive effects of support.
From  a review of twenty-five normal population surveys, they conclude that emotional support and perceived availability of support are both likely to buffer the effects of stress on health.
But in the absence of high stress they find no reason to conclude that emotional support has any general influence on mental health.
Kessler and McLeod also found plausible evidence in three studies that the buffering effects of emotional support might be at least as important in circumstances of chronic strain as for people facing the acute stress of major events.
Furthermore, they suggest that some researchers who have reported correlations between emotional support and health in the absence of life events might in fact be picking up a correlation between chronic strain and support.
Eight of the studies reviewed by Kessler and McLeod considered the effects of support on stress provided by affiliative networks as opposed to that from intimate relationships, that is, by assessing number of friends, community involvement and social activities.
They found no pervasive effect of membership in affiliative networks in the presence of stress.
They concluded, however, that it was possible that social networks have a modest association with mental health even though they offer little protection against acute stress.
This would concur with the conclusions of reviews of the much larger literature on support and health which does not specifically consider the effects of stress.
It may also be that informal support networks are valuable in managing chronic strain.
For instance, Neighbors and his colleagues (1983) found that prayer and the church were the most commonly cited responses of black Americans facing marked economic and family difficulties.
While evidence that social support in some way short-circuits the illness response to stress is now considerable, the nature of the support and the way in which it provides its effect remain matters for dispute.
Whether its effect is direct or indirect, as an antecedent or buffer, or whether it is availability or perceived availability that is important, are all issues which have been controversial.
(i) What quality of a relationship is protective?
House (1981) describes three ways in which social ties can be supportive.
They can provide: functional support (tangible help such as money, services); informational support (advice, knowledge); and emotional support.
Gottlieb (1983) describes the latter as ‘an  expression of reliable alliance with the respondents and a genuine concern for their well-being’.
But while some obviously see social support as something easily recognisable, emphasising that the supporter must actually be present or accessible during stressful episodes (e.g. Cassel, 1976), others, like Cobb, conceive of support in less down-to-earth terms.
Cobb argues that social support arises in the eye of the beholder, and is anything that influences the person to perceive himself as the recipient of positive affect; any information ‘leading the subject to believe that he is cared for and loved…esteemed and valued…’
(Cobb, 1976, p. 300).
Robert Weiss, who has conducted a number of intensive studies of adult relationships, has set out to identify the provisions of different kinds of social ties.
Close, intimate relationships such as may exist between marriage partners, are contrasted with those with other family members, friends and wider social contacts.
By way of illustration, he described the loneliness experienced by many recently separated couples, even when they have longed for the divorce, and despite a great deal of support from companions.
Another observation was of the isolation which can be experienced by the housewife, despite a close and happy marriage, when a move of residence deprives her of the company of friends.
Both intimate and friendship ties are therefore considered potentially important for well-being.
Two other types of bond are relationships organised around investments in the welfare of another (ordinarily one's own children); and relationships organised around an acceptance of someone as a valid source of support and guidance — the boss at work, the general practitioner perhaps, or the vicar (Weiss, 1982).
Weiss believes friendships to be important in so far as they reflect attitudes and behaviour that are supportive of the individual's own beliefs, and they provide a reassurance of self-worth by virtue of their acceptance.
Close attachments foster feelings of comfort and security, while investments in the well-being of others provides a rationale for one's continued striving, a sense of continuity through time, and an opportunity for reliving and mastering unsatisfactory early experiences of one's own.
He argues, therefore, that social ties may differ radically in function and should not be considered to provide some unitary benefit in terms of concepts such as emotional support.
He also emphasises the need to take into account the costs of relationships, and the possibility that in some instances, apparently supportive relationships can have a negative impact on well-being.
Research on the development of various types of psychiatric disorder has so far suggested that close relationships tend to play the most crucial role in increasing or decreasing vulnerability.
In the context of the earlier discussion on meaning, this might be interpreted as those relationships which help to establish and sustain a person's self-esteem in areas to which he is highly committed.
But it appears that it is more often the negative effect of a close relationship, rather than any positive effect, that is of significance in determining psychiatric risk.
Firstly, as the research on the course of schizophrenia described in chapter 5 showed, a high level of criticism and overinvolvement expressed by the key close relative in the home increased the likelihood that a person who had previously been treated for schizophrenia would suffer an acute relapse of florid symptoms.
Low expressed emotion, on the other hand, and a positive approach to fostering social competence by relatives could, along with maintenance neuroleptic medication, reduce vulnerability to relapse to a low level (Leff et al., 1982; Falloon et al., 1982).
Secondly, not only have Brown and his colleagues (1986a) confirmed that it is a close relationship that plays the key protective role in the development of depression (regular contact, fair level of confiding), but they also found that it was essential to consider both positive and negative aspects of such relationships for any satisfactory understanding.
For instance, women with a marital relationship characterised by negative interaction (discord, tension, coldness and indifference) were found to be over three times more likely to become depressed after a severe event (35 per cent versus 10 per cent ) than married women with a better relationship (Brown et al., 1986a).
Thirdly, discordant marital relationships have been linked with a raised rate of psychiatric problems in the children (Rutter, 1981).
And finally, a lack of interest in and control over their children on the part of parents has been argued to be a vulnerability factor for these children in adult depression (see chapter 4).
It therefore seems that not only is the absence of close supportive others linked to vulnerability, but so too can be the presence of close unsupportive others.
However, there are further complexities as described in a recent paper by Brown and his colleagues (1986a) who explain why even the presence of seemingly good close relationships sometimes fails to be protective against depression.
They show how important it is to consider the objectively quantifiable support provided within a relationship during a crisis.
In their longitudinal study, they were  surprised how many of the women who had been considered to have a supportive marital relationship when first interviewed became depressed after a later crisis.
When the lives of the women were examined in more detail, this finding was explained; quite often, support at the time of their first contact with the woman was not translated into effective support in a crisis in the follow-up year.
Married women were more likely than single mothers to be let down in this way, and such women were particularly likely to develop depression.
Indeed, the high risk of depression among women let down by a husband was not mitigated by any other form of support.
Married women whose husbands provided the support expected of them, however, had a low risk of depression following life events.
And for women in other circumstances, there was evidence that other types of support could be protective too.
Married women who had not been receiving support from their husband when they were first interviewed, and were therefore not expecting support from him during subsequent crises, had a much reduced risk of depression if they received help from someone else whom they had named as very close at the first interview.
Single mothers who had named a ‘true’ very close friend were also less likely to become depressed than single mothers without such friendships.
Other research findings also suggest that less intimate ties can, under certain circumstances, be important.
For instance, bereaved adults experience higher than expected levels of illness in the year following the death of their spouse, and among those most at risk of lasting psychiatric problems are people without a network of friends or relatives to whom they may turn for consolation (Parkes and Brown, 1972).
Parkes's (1980) review of random allocation bereavement counselling studies indicated that guidance offered to such socially isolated individuals by trained professionals (or volunteers backed by professionals) could reduce their psychiatric risk (see chapter 9).
In general, the research is clear in showing the critical role of support in the development of depression, but that the relationship between support, crises and depression is far more complex than many researchers have previously conveyed.
(ii) At what stage in the development of adverse events and psychological distress is social support most important?
The possibility of mounting preventive interventions to reduce psychiatric risk will depend on information about the timing, as well as the quality of effective support.
Is the existence of a supportive relationship before an event the critical factor, or can new supportive relationships mobilised at the time of the event be effective?
Perhaps both are important in different ways.
Existing ties may help to reduce the number of events experienced (arrow h, Figure 7.1), reduce the likelihood that events will be perceived as stressful (arrow j), and provide emotional support after the event (arrows i and k).
But mutual aid organisations which have proliferated over recent decades are based on an assumption that practical and highly specific emotional support after the event, and from new social relationships, is helpful.
Research which has attempted to untangle these issues has not, by and large, employed sufficiently sophisticated methods to clarify the picture.
Two often-cited studies are illustrative of the problems of measuring support and assessing its timing, and therefore the mechanisms through which it exerts its effects.
Gore (1978) studied the impact of unemployment at five points in time leading up to and following the shutdown of two companies.
Six weeks before and immediately after the closedown was assumed to be a more stressful time for the 100 men than one and two years later when 90 per cent of them had found alternative employment.
Social support was assessed from a thirteen-item index covering the individual's perception of wife, friends and relatives as supportive or unsupportive, frequency of activity with them, and perceived opportunity to talk about problems and engage in satisfying social activities.
Depression, self-blame, number of pre-defined illness symptoms, and level of serum cholesterol were also assessed.
One of the two companies was sited in a rural community, the other in an urban environment.
Men in the rural setting had longer periods of unemployment, but fewer symptoms of depression, suggesting that the broad social context played a role in adaptation (Gore, 1978, p. 159).
The rural men were found to have a higher average rating of social support, and to live in a more cohesive community judged by an atmosphere of concern about the threat to its economic base which was not apparent in the urban area.
However, despite a wealth of fascinating data, she was unable to  untangle the causal sequence and be sure about what came first in order to conclude when and how support had been protective.
Lin and his colleagues (1979) also set out to explain why support might be protective among 121 men and 49 women randomly selected from a Chinese-American community in the USA.
They assessed life events using the Holmes and Rahe checklist which ranks events according to the life change involved rather than their negative implications, and therefore includes seemingly positive events such as marriage.
Their concept of support was also very broad, and their assessment more of a quantitive than a qualitive one.
It included, for example, frequency of talking to neighbours, involvement in ‘Chinese activities’, and number of close friends living nearby.
High support was found to be associated with a low rate of illness, and a high level of events with a high rate of illness.
They argue that support acted as an antecedent protective factor, but as their data was not longitudinal, the relationships they found are open to alternative explanations.
As described earlier, Brown and his colleagues (1986a) have argued that they now have good evidence that the prior existence of a close supportive relationship is protective against depression if that person provides the support expected of them at the time of a crisis.
Although the crucial relationships were pre-existing, and of a close, confiding quality, their protective effect derived from the support during the crisis.
This means that it cannot be ruled out that new supportive relationships established at the time of a crisis might also sometimes be beneficial.
It may be that only when key supportive figures are lacking, or have been lost, that others in the wider social network (the health visitor, ‘befriender’ or social worker) can have a protective effect.
The importance of support is almost certainly to some extent bound up with self-esteem and the ability of the individual to cope with difficulties as they arise (Brown et al., 1986a; Pearlin et al., 1981) Given that adverse life events can bring about affective disorders, this is hardly surprising as a general conclusion.
However, the reverse situation seems equally, if not more important, and unsupportive, discordant close relationships can contribute to a negative selfesteem.
There is still a great deal to be learned about support, and there is no doubt that personal characteristics are also important.
Much controversy surrounds the relative importance of internal factors  (such as personality, intelligence and knowledge), and external factors (like social support) in determining coping skills.
The research by Henderson in Australia, described in chapter 4, has provoked considerable discussion about the role of personality in forming supportive relationships, and in perceiving relationships as supportive.
Furthermore, there have been suggestions that some types of support are effective for some types of stress but not others, and we do not yet know enough about the causal processes involved to be able to explain this (Gottlieb, 1983).
For instance, although close relationships are usually protective, they can sometimes interfere with an adaptive mode of defence such as denial, which a person might be setting up in response to a particularly threatening event.
Furthermore, adjustment to a new role in life may be best assisted by loose-knit networks, as when a mature woman leaves the domestic sphere to become a university student, or when adjusting to her newly divorced and single status.
Given the complexities which have so far been uncovered, we may increasingly need to turn to experimental intervention research to better understand the mechanisms of support for differing types of stressful situations.
What kinds of intervention are suggested?
Intervention at either of two points in developing events could be justified: in event-producing situations and after an adverse event (see Figure 7.1).
However, as suggested at the beginning of this chapter, the target group for the intervention should be particularly vulnerable in some way, that is, be predisposed biologically to a major psychiatric disorder, or be low in self-esteem, poor in coping skills, or low in support.
The event must to some extent match this vulnerability, in that in the context of the person's past history, say, its interpretation poses a particularly marked threat.
A note of caution should be added.
While the information assembled here facilitates the design and implementation of interventions that might reasonably be expected to be effective, chapter 9 shows that there is little firm evidence to demonstrate such effectiveness in many specific high-risk situations.
Before serious thought can be given to designing general population interventions, there needs to be an accumulation of clear results from experimental targeted interventions for people coping with one particular life event  or chronic strain.
The following are examples of interventions which might be instituted in this way.
Intervention Point A: event-producing situations
I have argued so far that people who are highly likely to experience an event with implications severe enough to provoke a depressive illness can sometimes be identified.
A history of failure in an area of life to which the person is highly committed not only makes him particularly vulnerable to depression following a further experience of failure, but can also raise the probability of further failures.
A man with a poor employment history, who has lost several jobs and experienced intermittent phases of unemployment, has a considerably raised probability of becoming depressed when he is again made redundant (Eales, 1985), but will also have a raised chance of being near the top of an employer's list for redundancy in so far as it is the policy of many employers to exercise a ‘last in first out’ policy.
It might be possible for people in such circumstances (perhaps when redundancies have been notified some weeks in advance) to be supported and perhaps taught techniques to cope with the anxiety and avoid being overpessimistic or ‘catastrophising’(see next section).
Other such opportunities might occur with people with recurring illness, or with couples considering divorce who have a long history of marital strife.
For people with long-standing difficult social circumstances that may throw up a crisis at any time, intervention might best combine practical help with a scheme to foster the person's sense of control over his or her life, to reduce their sense of hopelessness.
Some kind of befriending scheme using volunteers would be a particularly promising approach, perhaps with people who have come through similarly difficult circumstances.
Those with poor coping resources who might be particularly susceptible to depression may need to be helped to develop positive perceptions of their own capabilities and to lessen their perception of themselves as helpless and of low status.
Social workers and other primary care workers are well placed to identify people who have long-term social difficulties and poor coping resources.
Those who have suffered from several episodes of schizophrenia are often less socially competent in managing their domestic and occupational affairs than they were before their illness.
They are  therefore likely to be more prone to experience adverse events associated with accommodation and employment, events which might precipitate a relapse.
It might be possible to reduce risk if care was taken to ensure that, say, their landlady or employer was prepared to deal constructively with difficulties that arose, perhaps by involving a community psychiatric nurse as mediator.
Placement support which at the least minimised the chances that the ex-patient would be evicted from his home or sacked from his job the first time a problem occurred would seem essential.
It has also been found that unanticipated events and changes are more likely to precipitate a relapse of schizophrenia than events for which the person is prepared.
In a classic experiment reported in 1964, John Wing and his colleagues showed that long-stay schizophrenic patients given advance preparation for placements in an industrial rehabilitation unit were less likely to suffer a relapse than those who were unprepared.
An absence of information to aid the identification of those about to face a stressful event who would as a consequence be particularly susceptible to psychiatric disorder is obviously a good enough reason for not considering preventive intervention.
However, if the cost of the intervention was small enough, it might actually be justifiable to mount a programme on a population level.
For instance, a major operation, starting a new school and going on active military service are threatening events often known in advance of occurrence, but which only a small minority of people will find sufficiently distressing to make psychiatric disorder a likely consequence.
However, the examples also have in common an institutional setting which provides a ready opportunity for mounting large-scale intervention and it may well be more cost-effective in these circumstances to provide a preventive programme for all experiencing the event.
If children's anxiety in the transition to a new school can be eased by minimising the changes between class groups and between teachers at no extra cost, and no loss of educational effectiveness, it obviously makes sense to do so.
If military training can incorporate an element of preparation for the emotional experience associated with active service abroad which prevents even a small number of psychiatric casualties, it may well also help to maintain the morale of others and be cost-effective in these terms.
A simple leaflet routinely given out to patients before admission to hospital for common, straightforward operations, explaining the operation they are to undergo, common  after-effects, the discomfort and temporary impairment of function likely to be experienced, and so on, may prove to be helpful in the sense of increasing feelings of control and might well aid their recovery.
And for a very small number of patients it may also avert a psychiatric disorder.
Of course, such a leaflet should be a supplement to, and not a substitute for, a one-to-one preparatory discussion between patient and doctor, and may be inappropriate for less straightforward procedures.
Intervention Point B: vulnerable people, after the event
The ideal model for intervention after a threatening event has occurred to a vulnerable person is that suggested by Parkes (1980) in his recommendations for bereavement counselling.
His research on bereavement has led him to formulate a list of factors which make it possible to identify those likely to be at particular risk for psychiatric disorder.
As described earlier, they include those who lack other supportive relationships, or whose previous relationship with the deceased has left them with an overwhelming sense of guilt, leading to self-punitive grief.
Other circumstances predispose to the avoidance of grief including social pressures not to show emotion; a belief that they should, for instance, protect children from displays of grief; a fear of being thought to have broken down; or heavy use of tranquillisers to avoid the physiological accompaniments of grief.
Given that a good deal is also known about how people successfully adapt to bereavement (Parkes and Weiss, 1983), a possible format for intervention programmes is already available.
Intervention may be of a befriending nature, offering the person the opportunity to confide, and talk through his emotions, and gently guiding him towards a reassessment of his new position in life without the person he mourns.
Or it may take a more structured approach drawn from cognitive therapy techniques.
Cognitive theorists like Beck have drawn attention to the tendency on the part of many who are depressed to interpret even quite minor, as well as more serious events, in terms of some negative self-perception.
A friend failing to turn up for a date may reawaken deep-seated fears of abandonment.
He argues that it is common for a depressed person to grossly exaggerate the negative implications of events (sometimes called ‘catastrophising’): ‘I didn't get that job I'm not bright enough — I'll be unemployed or in low-level jobs  for ever— I'll be bored and boring-my friends will abandon me — my husband won't love me any more.’
Various types of cognitive therapy to bring an improvement in psychiatric disorders by altering maladaptive thinking appear to have been successful (Gelder, 1985).
Such maladaptive assumptions are a feature of depression itself, of course, and may not be present in the individual when he is not depressed.
However, it is possible that cognitive changes occurring in the early stages of a depressive disorder may initiate a vicious circle that can transform an otherwise mild and short-lived reaction into one that is more severe and protracted.
In this sense cognitive therapy might sometimes serve a preventive function.
Furthermore, some of these sorts of approaches have been modified for more general use with those who are not already suffering a psychiatric disorder.
One technique involves helping a person to break down a problem into more manageable subproblems and consider the merits of various possible solutions to each part.
After choosing a solution, a step-by-step plan of action is worked out.
The value of each tactic is considered not just for the problem itself, but as an approach that might be used again on a future occasion so that the person can learn how better to cope with future problems (Gelder, 1985).
McGuire and Sifneos (1970) describe the use of this approach for people who have recently experienced a serious loss of some kind bereavement, redundancy at work, or divorce.
Some stress management techniques for controlling anxiety, which have acquired a degree of popularity, also show certain similarities (e.g. Meichenbaum, 1977).
These methods have, for instance, been shown to considerably reduce the symptoms of people who become unduly anxious before taking examinations (Meichenbaum, 1972).
If a person has a tendency to interpret events according to a particular negative cognitive schema, then this must be represented in some neurobiological code in the person's brain.
And it seems that the biological state of an individual can undermine his perception of being able to cope — his level of fatigue, state of exhaustion or physical illness.
This means that some attention to internal fatigue levels may also be of help in dealing with stress.
Indeed, some hospitals have begun to experiment with providing complete physical rest as central to a treatment programme for cardiac cases, which is then followed by instruction on relaxation techniques through which  people may be more effective in controlling anxiety (e.g. Charing Cross Hospital, London).
With most major life events, it is likely to be very difficult both to identify people who have recently experienced an event and find out which of them are likely to be susceptible to psychiatric disorder as a consequence.
Although a wide range of mutual aid groups are now available, involving reciprocal aid among people who have in common one particular type of life stress, members typically only discover or are discovered by the organisation some considerable time after the event (Richardson and Goodman, 1983).
Their support is then usually too late to avert psychiatric disorder as research is clear in showing that most disorder associated with life events develops quite rapidly after the event.
However, many organisations could improve their preventive role by developing their out-reach methods and strengthening links with general practitioners and health visitors or other professional groups likely to have information on people currently facing those events.
The Stillbirth and Neonatal Death Society in Britain, for instance, has produced an information package for hospitals to attempt both to encourage a more sensitive approach by hospital staff to the management of stillbirth cases (such as in disposing of the body) and to increase the chance that families will rapidly be put in touch with their organisation.
Perhaps the easiest, if not the earliest way to identify the people who are not coping with recent events is to wait until their distress brings them into contact with health or social services.
The general practitioner is a first port of call for people with all manner of distressing circumstances.
A good GP could provide preventive counselling.
But where more intensive support is required, over a longer period, he or she needs to be able to put the patient into contact with a relevant mutual aid group, befriending scheme, counselling service, or psychiatric crisis support scheme.
Crisis intervention teams have developed as a part of statutory services in a number of areas in Britain.
Clients are usually only referred to them, however, when they are already suffering serious psychiatric problems.
Furthermore, people with a history of psychiatric disorder are more likely to be seen as suitable referrals by primary health care workers.
These services are described in more detail in chapter 9.
Voluntary services, however, may sometimes be mobilised for people whose distress has not reached pathological proportions.
The  non-professional also has a number of advantages over professional services.
They can avoid the role of help giver which casts the client into a dependent role.
If they have experienced difficulties similar to the client, or live in a similar social environment, they are more likely to be able to foster the client's own coping skills and to achieve a friendship on equal terms.
The principles of mutual aid are that members should be involved in a reciprocal supportive role.
For this reason, Gottlieb (1983) argues that support schemes must avoid casting the non-professional into a professional type of mould and recreating the provider-client relationship.
However, a major difficulty in ensuring the effectiveness of any support scheme is to reach in time the small proportion of the population least able to cope with their crisis.
Further work is needed to enable those specialist groups with support to offer to identify indicators of vulnerability and to find ways to reach their most needy group.